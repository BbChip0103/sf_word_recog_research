{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_BN(conv_num=1):\n",
    "    init_channel = 32\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=init_channel, strides=1, \n",
    "                      padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=int(init_channel*(2**int((i+1)/3))), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 512000)            2048000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                8192016   \n",
      "=================================================================\n",
      "Total params: 10,240,336\n",
      "Trainable params: 9,216,272\n",
      "Non-trainable params: 1,024,064\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 170656)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 170656)            682624    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2730512   \n",
      "=================================================================\n",
      "Total params: 3,418,736\n",
      "Trainable params: 3,077,296\n",
      "Non-trainable params: 341,440\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 56864)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 56864)             227456    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                909840    \n",
      "=================================================================\n",
      "Total params: 1,148,176\n",
      "Trainable params: 1,034,256\n",
      "Non-trainable params: 113,920\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 779,216\n",
      "Trainable params: 703,120\n",
      "Non-trainable params: 76,096\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 12608)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 12608)             50432     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                201744    \n",
      "=================================================================\n",
      "Total params: 294,416\n",
      "Trainable params: 268,752\n",
      "Non-trainable params: 25,664\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 4160)              16640     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                66576     \n",
      "=================================================================\n",
      "Total params: 146,256\n",
      "Trainable params: 137,360\n",
      "Non-trainable params: 8,896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 158,416\n",
      "Trainable params: 152,208\n",
      "Non-trainable params: 6,208\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 205,136\n",
      "Trainable params: 202,256\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 128)            82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 7, 128)            512       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 274,896\n",
      "Trainable params: 273,040\n",
      "Non-trainable params: 1,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8937 - acc: 0.4471\n",
      "Epoch 00001: val_loss improved from inf to 1.63084, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_4_conv_checkpoint/001-1.6308.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 1.8936 - acc: 0.4471 - val_loss: 1.6308 - val_acc: 0.4917\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1001 - acc: 0.6705\n",
      "Epoch 00002: val_loss improved from 1.63084 to 1.32516, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_4_conv_checkpoint/002-1.3252.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.1002 - acc: 0.6705 - val_loss: 1.3252 - val_acc: 0.6094\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7346 - acc: 0.7742\n",
      "Epoch 00003: val_loss did not improve from 1.32516\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.7346 - acc: 0.7742 - val_loss: 1.4050 - val_acc: 0.5933\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5048 - acc: 0.8520\n",
      "Epoch 00004: val_loss did not improve from 1.32516\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5051 - acc: 0.8519 - val_loss: 1.4219 - val_acc: 0.6159\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3642 - acc: 0.9008\n",
      "Epoch 00005: val_loss improved from 1.32516 to 1.29377, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_4_conv_checkpoint/005-1.2938.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3643 - acc: 0.9008 - val_loss: 1.2938 - val_acc: 0.6483\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2531 - acc: 0.9387\n",
      "Epoch 00006: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2533 - acc: 0.9386 - val_loss: 1.4333 - val_acc: 0.6254\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9560\n",
      "Epoch 00007: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1978 - acc: 0.9559 - val_loss: 1.3611 - val_acc: 0.6415\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9733\n",
      "Epoch 00008: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1457 - acc: 0.9732 - val_loss: 1.3604 - val_acc: 0.6513\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9799\n",
      "Epoch 00009: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1192 - acc: 0.9798 - val_loss: 1.4457 - val_acc: 0.6420\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9861\n",
      "Epoch 00010: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0926 - acc: 0.9861 - val_loss: 1.4357 - val_acc: 0.6569\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9866\n",
      "Epoch 00011: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0856 - acc: 0.9865 - val_loss: 1.6036 - val_acc: 0.6282\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9888\n",
      "Epoch 00012: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0751 - acc: 0.9888 - val_loss: 1.5300 - val_acc: 0.6557\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9916\n",
      "Epoch 00013: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0658 - acc: 0.9916 - val_loss: 1.4911 - val_acc: 0.6648\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9905\n",
      "Epoch 00014: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0633 - acc: 0.9905 - val_loss: 1.6573 - val_acc: 0.6417\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9907\n",
      "Epoch 00015: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0564 - acc: 0.9906 - val_loss: 1.5353 - val_acc: 0.6557\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9917\n",
      "Epoch 00016: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0562 - acc: 0.9917 - val_loss: 1.5752 - val_acc: 0.6713\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9929\n",
      "Epoch 00017: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0474 - acc: 0.9929 - val_loss: 1.5709 - val_acc: 0.6611\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9962\n",
      "Epoch 00018: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0357 - acc: 0.9962 - val_loss: 1.6295 - val_acc: 0.6625\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9935\n",
      "Epoch 00019: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0410 - acc: 0.9935 - val_loss: 1.7824 - val_acc: 0.6466\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9933\n",
      "Epoch 00020: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0418 - acc: 0.9933 - val_loss: 1.7133 - val_acc: 0.6571\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9958\n",
      "Epoch 00021: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0344 - acc: 0.9957 - val_loss: 2.5821 - val_acc: 0.5577\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9914\n",
      "Epoch 00022: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0469 - acc: 0.9914 - val_loss: 1.8463 - val_acc: 0.6448\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9942\n",
      "Epoch 00023: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0370 - acc: 0.9942 - val_loss: 2.0327 - val_acc: 0.6226\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9958\n",
      "Epoch 00024: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0296 - acc: 0.9958 - val_loss: 1.8292 - val_acc: 0.6403\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9936\n",
      "Epoch 00025: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0377 - acc: 0.9936 - val_loss: 1.7993 - val_acc: 0.6539\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9977\n",
      "Epoch 00026: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0222 - acc: 0.9977 - val_loss: 1.8396 - val_acc: 0.6571\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9935\n",
      "Epoch 00027: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0357 - acc: 0.9935 - val_loss: 1.8243 - val_acc: 0.6508\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9948\n",
      "Epoch 00028: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0338 - acc: 0.9947 - val_loss: 1.9808 - val_acc: 0.6369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9931\n",
      "Epoch 00029: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0348 - acc: 0.9931 - val_loss: 1.9095 - val_acc: 0.6511\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9959\n",
      "Epoch 00030: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0270 - acc: 0.9959 - val_loss: 1.9847 - val_acc: 0.6420\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9921\n",
      "Epoch 00031: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0407 - acc: 0.9920 - val_loss: 1.9581 - val_acc: 0.6427\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9949\n",
      "Epoch 00032: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0288 - acc: 0.9949 - val_loss: 1.9406 - val_acc: 0.6553\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9976\n",
      "Epoch 00033: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0202 - acc: 0.9976 - val_loss: 2.0730 - val_acc: 0.6320\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9979\n",
      "Epoch 00034: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0188 - acc: 0.9979 - val_loss: 1.9146 - val_acc: 0.6592\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9982\n",
      "Epoch 00035: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0167 - acc: 0.9981 - val_loss: 2.1124 - val_acc: 0.6345\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9948\n",
      "Epoch 00036: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0301 - acc: 0.9947 - val_loss: 2.0544 - val_acc: 0.6366\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9951\n",
      "Epoch 00037: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0265 - acc: 0.9951 - val_loss: 2.1169 - val_acc: 0.6438\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9949\n",
      "Epoch 00038: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0269 - acc: 0.9949 - val_loss: 2.0941 - val_acc: 0.6450\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9952\n",
      "Epoch 00039: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0281 - acc: 0.9951 - val_loss: 2.1249 - val_acc: 0.6413\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9948\n",
      "Epoch 00040: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0259 - acc: 0.9948 - val_loss: 2.0087 - val_acc: 0.6571\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9981\n",
      "Epoch 00041: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0157 - acc: 0.9981 - val_loss: 2.0678 - val_acc: 0.6550\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9977\n",
      "Epoch 00042: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0184 - acc: 0.9977 - val_loss: 2.1244 - val_acc: 0.6413\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9952\n",
      "Epoch 00043: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0257 - acc: 0.9952 - val_loss: 1.9823 - val_acc: 0.6646\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9956\n",
      "Epoch 00044: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0254 - acc: 0.9956 - val_loss: 2.1350 - val_acc: 0.6394\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9981\n",
      "Epoch 00045: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0159 - acc: 0.9981 - val_loss: 2.2120 - val_acc: 0.6359\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9956\n",
      "Epoch 00046: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0277 - acc: 0.9955 - val_loss: 2.3339 - val_acc: 0.6294\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9943\n",
      "Epoch 00047: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0279 - acc: 0.9943 - val_loss: 2.0888 - val_acc: 0.6555\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9971\n",
      "Epoch 00048: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0198 - acc: 0.9971 - val_loss: 2.4208 - val_acc: 0.6243\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9961\n",
      "Epoch 00049: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0226 - acc: 0.9961 - val_loss: 2.7235 - val_acc: 0.5924\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9968\n",
      "Epoch 00050: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0214 - acc: 0.9968 - val_loss: 2.3045 - val_acc: 0.6301\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9969\n",
      "Epoch 00051: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0201 - acc: 0.9969 - val_loss: 2.1594 - val_acc: 0.6513\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9985\n",
      "Epoch 00052: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0158 - acc: 0.9985 - val_loss: 2.2070 - val_acc: 0.6382\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9946\n",
      "Epoch 00053: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0261 - acc: 0.9945 - val_loss: 2.5767 - val_acc: 0.6159\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9963\n",
      "Epoch 00054: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0230 - acc: 0.9963 - val_loss: 2.2120 - val_acc: 0.6455\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9954\n",
      "Epoch 00055: val_loss did not improve from 1.29377\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0248 - acc: 0.9954 - val_loss: 2.5218 - val_acc: 0.6159\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 522us/sample - loss: 1.4314 - acc: 0.6021\n",
      "Loss: 1.4313814536309564 Accuracy: 0.6020768\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8451 - acc: 0.4377\n",
      "Epoch 00001: val_loss improved from inf to 1.63746, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_5_conv_checkpoint/001-1.6375.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 1.8450 - acc: 0.4377 - val_loss: 1.6375 - val_acc: 0.4910\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1640 - acc: 0.6478\n",
      "Epoch 00002: val_loss improved from 1.63746 to 1.09634, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_5_conv_checkpoint/002-1.0963.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 1.1641 - acc: 0.6478 - val_loss: 1.0963 - val_acc: 0.6683\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9463 - acc: 0.7142\n",
      "Epoch 00003: val_loss improved from 1.09634 to 1.00558, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_5_conv_checkpoint/003-1.0056.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.9463 - acc: 0.7141 - val_loss: 1.0056 - val_acc: 0.7056\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8074 - acc: 0.7583\n",
      "Epoch 00004: val_loss improved from 1.00558 to 0.99253, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_5_conv_checkpoint/004-0.9925.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.8073 - acc: 0.7583 - val_loss: 0.9925 - val_acc: 0.7004\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6982 - acc: 0.7908\n",
      "Epoch 00005: val_loss improved from 0.99253 to 0.98409, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_5_conv_checkpoint/005-0.9841.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.6981 - acc: 0.7908 - val_loss: 0.9841 - val_acc: 0.7181\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.8185\n",
      "Epoch 00006: val_loss did not improve from 0.98409\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.6027 - acc: 0.8185 - val_loss: 1.0517 - val_acc: 0.6969\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5346 - acc: 0.8420\n",
      "Epoch 00007: val_loss improved from 0.98409 to 0.91514, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_5_conv_checkpoint/007-0.9151.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.5349 - acc: 0.8418 - val_loss: 0.9151 - val_acc: 0.7482\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4656 - acc: 0.8623\n",
      "Epoch 00008: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4656 - acc: 0.8622 - val_loss: 1.0081 - val_acc: 0.7207\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3967 - acc: 0.8857\n",
      "Epoch 00009: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3968 - acc: 0.8856 - val_loss: 1.1286 - val_acc: 0.6893\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3445 - acc: 0.9023\n",
      "Epoch 00010: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3445 - acc: 0.9023 - val_loss: 0.9554 - val_acc: 0.7400\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3002 - acc: 0.9189\n",
      "Epoch 00011: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3004 - acc: 0.9189 - val_loss: 1.0799 - val_acc: 0.7144\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2626 - acc: 0.9319\n",
      "Epoch 00012: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2628 - acc: 0.9319 - val_loss: 0.9326 - val_acc: 0.7468\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2327 - acc: 0.9426\n",
      "Epoch 00013: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2327 - acc: 0.9426 - val_loss: 1.1493 - val_acc: 0.6886\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2030 - acc: 0.9517\n",
      "Epoch 00014: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2032 - acc: 0.9516 - val_loss: 1.3357 - val_acc: 0.6543\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1789 - acc: 0.9599\n",
      "Epoch 00015: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1790 - acc: 0.9599 - val_loss: 0.9857 - val_acc: 0.7410\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1601 - acc: 0.9644\n",
      "Epoch 00016: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1605 - acc: 0.9644 - val_loss: 0.9957 - val_acc: 0.7447\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9684\n",
      "Epoch 00017: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1470 - acc: 0.9683 - val_loss: 1.0375 - val_acc: 0.7419\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9766\n",
      "Epoch 00018: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1241 - acc: 0.9766 - val_loss: 0.9767 - val_acc: 0.7549\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9800\n",
      "Epoch 00019: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1091 - acc: 0.9800 - val_loss: 1.0641 - val_acc: 0.7361\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9819\n",
      "Epoch 00020: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1026 - acc: 0.9819 - val_loss: 1.0945 - val_acc: 0.7356\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9825\n",
      "Epoch 00021: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0971 - acc: 0.9825 - val_loss: 1.2918 - val_acc: 0.7023\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9839\n",
      "Epoch 00022: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0907 - acc: 0.9839 - val_loss: 1.0755 - val_acc: 0.7456\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9866\n",
      "Epoch 00023: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0815 - acc: 0.9866 - val_loss: 1.0850 - val_acc: 0.7459\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9858\n",
      "Epoch 00024: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0816 - acc: 0.9858 - val_loss: 1.1233 - val_acc: 0.7386\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9890\n",
      "Epoch 00025: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0677 - acc: 0.9890 - val_loss: 1.1433 - val_acc: 0.7349\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9892\n",
      "Epoch 00026: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0684 - acc: 0.9891 - val_loss: 1.1259 - val_acc: 0.7449\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9879\n",
      "Epoch 00027: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0711 - acc: 0.9879 - val_loss: 1.2075 - val_acc: 0.7256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9920\n",
      "Epoch 00028: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0560 - acc: 0.9920 - val_loss: 1.0940 - val_acc: 0.7529\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9931\n",
      "Epoch 00029: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0513 - acc: 0.9930 - val_loss: 1.1220 - val_acc: 0.7547\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9926\n",
      "Epoch 00030: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0494 - acc: 0.9925 - val_loss: 1.3020 - val_acc: 0.7156\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9899\n",
      "Epoch 00031: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0591 - acc: 0.9898 - val_loss: 1.1733 - val_acc: 0.7419\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9935\n",
      "Epoch 00032: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0451 - acc: 0.9935 - val_loss: 1.2171 - val_acc: 0.7314\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9943\n",
      "Epoch 00033: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0431 - acc: 0.9943 - val_loss: 1.2038 - val_acc: 0.7414\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9910\n",
      "Epoch 00034: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0501 - acc: 0.9910 - val_loss: 1.1490 - val_acc: 0.7480\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9920\n",
      "Epoch 00035: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0460 - acc: 0.9920 - val_loss: 1.2303 - val_acc: 0.7419\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9943\n",
      "Epoch 00036: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0405 - acc: 0.9943 - val_loss: 1.3561 - val_acc: 0.7181\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9909\n",
      "Epoch 00037: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0499 - acc: 0.9909 - val_loss: 1.2903 - val_acc: 0.7305\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9953\n",
      "Epoch 00038: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0354 - acc: 0.9953 - val_loss: 1.1600 - val_acc: 0.7503\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9958\n",
      "Epoch 00039: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0323 - acc: 0.9958 - val_loss: 1.2237 - val_acc: 0.7384\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9942\n",
      "Epoch 00040: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0379 - acc: 0.9942 - val_loss: 1.2989 - val_acc: 0.7258\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9908\n",
      "Epoch 00041: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0472 - acc: 0.9908 - val_loss: 1.3603 - val_acc: 0.7209\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9977\n",
      "Epoch 00042: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0246 - acc: 0.9977 - val_loss: 1.2227 - val_acc: 0.7475\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9939\n",
      "Epoch 00043: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0359 - acc: 0.9939 - val_loss: 1.2344 - val_acc: 0.7419\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9958\n",
      "Epoch 00044: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0306 - acc: 0.9957 - val_loss: 1.2641 - val_acc: 0.7375\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9938\n",
      "Epoch 00045: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0366 - acc: 0.9938 - val_loss: 1.3851 - val_acc: 0.7298\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9960\n",
      "Epoch 00046: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0282 - acc: 0.9959 - val_loss: 1.3474 - val_acc: 0.7331\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9915\n",
      "Epoch 00047: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0420 - acc: 0.9915 - val_loss: 1.2863 - val_acc: 0.7410\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9957\n",
      "Epoch 00048: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0295 - acc: 0.9956 - val_loss: 1.2959 - val_acc: 0.7431\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9956\n",
      "Epoch 00049: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0290 - acc: 0.9955 - val_loss: 1.3963 - val_acc: 0.7365\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9923\n",
      "Epoch 00050: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0396 - acc: 0.9923 - val_loss: 1.3786 - val_acc: 0.7233\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9962\n",
      "Epoch 00051: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0255 - acc: 0.9962 - val_loss: 1.2705 - val_acc: 0.7447\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9981\n",
      "Epoch 00052: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0197 - acc: 0.9981 - val_loss: 1.5069 - val_acc: 0.7121\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9929\n",
      "Epoch 00053: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0367 - acc: 0.9929 - val_loss: 1.2892 - val_acc: 0.7400\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9946\n",
      "Epoch 00054: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0302 - acc: 0.9946 - val_loss: 1.3021 - val_acc: 0.7391\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9958\n",
      "Epoch 00055: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0276 - acc: 0.9957 - val_loss: 1.3582 - val_acc: 0.7293\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9958\n",
      "Epoch 00056: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0259 - acc: 0.9957 - val_loss: 1.3498 - val_acc: 0.7342\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9936\n",
      "Epoch 00057: val_loss did not improve from 0.91514\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0323 - acc: 0.9936 - val_loss: 1.3992 - val_acc: 0.7352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_3_ch_32_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 558us/sample - loss: 0.9976 - acc: 0.7020\n",
      "Loss: 0.9975839767871988 Accuracy: 0.701973\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8809 - acc: 0.4211\n",
      "Epoch 00001: val_loss improved from inf to 1.59712, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_6_conv_checkpoint/001-1.5971.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 1.8809 - acc: 0.4211 - val_loss: 1.5971 - val_acc: 0.4729\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2201 - acc: 0.6260\n",
      "Epoch 00002: val_loss improved from 1.59712 to 1.06003, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_6_conv_checkpoint/002-1.0600.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 1.2200 - acc: 0.6260 - val_loss: 1.0600 - val_acc: 0.6834\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9932 - acc: 0.7028\n",
      "Epoch 00003: val_loss improved from 1.06003 to 0.94254, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_6_conv_checkpoint/003-0.9425.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.9935 - acc: 0.7027 - val_loss: 0.9425 - val_acc: 0.7135\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8576 - acc: 0.7448\n",
      "Epoch 00004: val_loss improved from 0.94254 to 0.81638, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_6_conv_checkpoint/004-0.8164.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.8578 - acc: 0.7448 - val_loss: 0.8164 - val_acc: 0.7713\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7670 - acc: 0.7773\n",
      "Epoch 00005: val_loss did not improve from 0.81638\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.7672 - acc: 0.7772 - val_loss: 0.8217 - val_acc: 0.7643\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6907 - acc: 0.7978\n",
      "Epoch 00006: val_loss improved from 0.81638 to 0.71660, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_6_conv_checkpoint/006-0.7166.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.6907 - acc: 0.7977 - val_loss: 0.7166 - val_acc: 0.7962\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6323 - acc: 0.8192\n",
      "Epoch 00007: val_loss improved from 0.71660 to 0.68162, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_6_conv_checkpoint/007-0.6816.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.6327 - acc: 0.8192 - val_loss: 0.6816 - val_acc: 0.8099\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5841 - acc: 0.8312\n",
      "Epoch 00008: val_loss did not improve from 0.68162\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.5841 - acc: 0.8312 - val_loss: 0.7066 - val_acc: 0.7987\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5352 - acc: 0.8472\n",
      "Epoch 00009: val_loss improved from 0.68162 to 0.62218, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_6_conv_checkpoint/009-0.6222.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.5354 - acc: 0.8471 - val_loss: 0.6222 - val_acc: 0.8232\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4953 - acc: 0.8598\n",
      "Epoch 00010: val_loss did not improve from 0.62218\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4955 - acc: 0.8597 - val_loss: 0.6535 - val_acc: 0.8097\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4640 - acc: 0.8698\n",
      "Epoch 00011: val_loss improved from 0.62218 to 0.57142, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_6_conv_checkpoint/011-0.5714.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.4639 - acc: 0.8698 - val_loss: 0.5714 - val_acc: 0.8418\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4279 - acc: 0.8785\n",
      "Epoch 00012: val_loss did not improve from 0.57142\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4279 - acc: 0.8785 - val_loss: 0.6246 - val_acc: 0.8265\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4015 - acc: 0.8867\n",
      "Epoch 00013: val_loss did not improve from 0.57142\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4016 - acc: 0.8867 - val_loss: 0.6305 - val_acc: 0.8253\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3779 - acc: 0.8935\n",
      "Epoch 00014: val_loss did not improve from 0.57142\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3779 - acc: 0.8935 - val_loss: 0.6171 - val_acc: 0.8241\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3506 - acc: 0.9023\n",
      "Epoch 00015: val_loss improved from 0.57142 to 0.53570, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_6_conv_checkpoint/015-0.5357.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3508 - acc: 0.9023 - val_loss: 0.5357 - val_acc: 0.8535\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3317 - acc: 0.9062\n",
      "Epoch 00016: val_loss did not improve from 0.53570\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3318 - acc: 0.9062 - val_loss: 0.5572 - val_acc: 0.8502\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3056 - acc: 0.9138\n",
      "Epoch 00017: val_loss did not improve from 0.53570\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3056 - acc: 0.9138 - val_loss: 0.6168 - val_acc: 0.8209\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2876 - acc: 0.9209\n",
      "Epoch 00018: val_loss did not improve from 0.53570\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2877 - acc: 0.9209 - val_loss: 0.6254 - val_acc: 0.8267\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2715 - acc: 0.9245\n",
      "Epoch 00019: val_loss did not improve from 0.53570\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2717 - acc: 0.9245 - val_loss: 0.7302 - val_acc: 0.7987\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2555 - acc: 0.9300\n",
      "Epoch 00020: val_loss did not improve from 0.53570\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2556 - acc: 0.9300 - val_loss: 0.5983 - val_acc: 0.8325\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2381 - acc: 0.9359\n",
      "Epoch 00021: val_loss did not improve from 0.53570\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2382 - acc: 0.9359 - val_loss: 0.5752 - val_acc: 0.8449\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9395\n",
      "Epoch 00022: val_loss did not improve from 0.53570\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2224 - acc: 0.9395 - val_loss: 0.6385 - val_acc: 0.8260\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9427\n",
      "Epoch 00023: val_loss did not improve from 0.53570\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2129 - acc: 0.9426 - val_loss: 0.5705 - val_acc: 0.8453\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1940 - acc: 0.9495\n",
      "Epoch 00024: val_loss did not improve from 0.53570\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1940 - acc: 0.9495 - val_loss: 0.6905 - val_acc: 0.8123\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1844 - acc: 0.9517\n",
      "Epoch 00025: val_loss did not improve from 0.53570\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1845 - acc: 0.9516 - val_loss: 0.6384 - val_acc: 0.8218\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1806 - acc: 0.9526\n",
      "Epoch 00026: val_loss improved from 0.53570 to 0.52797, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_6_conv_checkpoint/026-0.5280.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1805 - acc: 0.9526 - val_loss: 0.5280 - val_acc: 0.8535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9582\n",
      "Epoch 00027: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1602 - acc: 0.9582 - val_loss: 0.5749 - val_acc: 0.8430\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9619\n",
      "Epoch 00028: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1518 - acc: 0.9619 - val_loss: 0.5754 - val_acc: 0.8418\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9623\n",
      "Epoch 00029: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1489 - acc: 0.9622 - val_loss: 0.5697 - val_acc: 0.8507\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9673\n",
      "Epoch 00030: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1363 - acc: 0.9672 - val_loss: 0.6354 - val_acc: 0.8362\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9651\n",
      "Epoch 00031: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1369 - acc: 0.9651 - val_loss: 0.5666 - val_acc: 0.8546\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9702\n",
      "Epoch 00032: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1242 - acc: 0.9702 - val_loss: 0.5382 - val_acc: 0.8567\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9742\n",
      "Epoch 00033: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1127 - acc: 0.9741 - val_loss: 0.6377 - val_acc: 0.8388\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9696\n",
      "Epoch 00034: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1240 - acc: 0.9696 - val_loss: 0.5756 - val_acc: 0.8467\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9777\n",
      "Epoch 00035: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1016 - acc: 0.9777 - val_loss: 0.5612 - val_acc: 0.8567\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9790\n",
      "Epoch 00036: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0973 - acc: 0.9790 - val_loss: 0.6066 - val_acc: 0.8451\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9778\n",
      "Epoch 00037: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0984 - acc: 0.9777 - val_loss: 0.5616 - val_acc: 0.8565\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9763\n",
      "Epoch 00038: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1014 - acc: 0.9763 - val_loss: 0.6658 - val_acc: 0.8311\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9815\n",
      "Epoch 00039: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0862 - acc: 0.9814 - val_loss: 0.6121 - val_acc: 0.8521\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9815\n",
      "Epoch 00040: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0853 - acc: 0.9814 - val_loss: 0.6458 - val_acc: 0.8369\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9835\n",
      "Epoch 00041: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0800 - acc: 0.9834 - val_loss: 0.6792 - val_acc: 0.8374\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9834\n",
      "Epoch 00042: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0781 - acc: 0.9834 - val_loss: 0.7232 - val_acc: 0.8314\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9805\n",
      "Epoch 00043: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0821 - acc: 0.9805 - val_loss: 0.6016 - val_acc: 0.8505\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9853\n",
      "Epoch 00044: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0714 - acc: 0.9852 - val_loss: 0.5943 - val_acc: 0.8581\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9870\n",
      "Epoch 00045: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0690 - acc: 0.9869 - val_loss: 0.6084 - val_acc: 0.8544\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9842\n",
      "Epoch 00046: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0752 - acc: 0.9842 - val_loss: 0.6447 - val_acc: 0.8486\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9860\n",
      "Epoch 00047: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0680 - acc: 0.9860 - val_loss: 0.5657 - val_acc: 0.8616\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9885\n",
      "Epoch 00048: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0582 - acc: 0.9885 - val_loss: 0.6572 - val_acc: 0.8486\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9859\n",
      "Epoch 00049: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0683 - acc: 0.9859 - val_loss: 0.6373 - val_acc: 0.8512\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9921\n",
      "Epoch 00050: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0504 - acc: 0.9921 - val_loss: 0.6606 - val_acc: 0.8460\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9918\n",
      "Epoch 00051: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0488 - acc: 0.9918 - val_loss: 0.6853 - val_acc: 0.8425\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9879\n",
      "Epoch 00052: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0585 - acc: 0.9878 - val_loss: 0.6948 - val_acc: 0.8532\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9847\n",
      "Epoch 00053: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0662 - acc: 0.9847 - val_loss: 0.6073 - val_acc: 0.8579\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9911\n",
      "Epoch 00054: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0466 - acc: 0.9911 - val_loss: 0.6581 - val_acc: 0.8442\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9891\n",
      "Epoch 00055: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0537 - acc: 0.9891 - val_loss: 0.6518 - val_acc: 0.8484\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9935\n",
      "Epoch 00056: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0410 - acc: 0.9934 - val_loss: 0.8230 - val_acc: 0.8088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9832\n",
      "Epoch 00057: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0697 - acc: 0.9832 - val_loss: 0.6063 - val_acc: 0.8600\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9935\n",
      "Epoch 00058: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0390 - acc: 0.9935 - val_loss: 0.6983 - val_acc: 0.8470\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9916\n",
      "Epoch 00059: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0434 - acc: 0.9916 - val_loss: 0.6101 - val_acc: 0.8598\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9895\n",
      "Epoch 00060: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0517 - acc: 0.9894 - val_loss: 0.6217 - val_acc: 0.8628\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9877\n",
      "Epoch 00061: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0544 - acc: 0.9877 - val_loss: 0.6224 - val_acc: 0.8607\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9932\n",
      "Epoch 00062: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0380 - acc: 0.9932 - val_loss: 0.6594 - val_acc: 0.8453\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9925\n",
      "Epoch 00063: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0403 - acc: 0.9925 - val_loss: 0.6459 - val_acc: 0.8563\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9923\n",
      "Epoch 00064: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0419 - acc: 0.9923 - val_loss: 0.7056 - val_acc: 0.8488\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9905\n",
      "Epoch 00065: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0465 - acc: 0.9905 - val_loss: 0.5966 - val_acc: 0.8672\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9948\n",
      "Epoch 00066: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0330 - acc: 0.9947 - val_loss: 0.7607 - val_acc: 0.8344\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9911\n",
      "Epoch 00067: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0430 - acc: 0.9911 - val_loss: 0.6838 - val_acc: 0.8491\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9910\n",
      "Epoch 00068: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0418 - acc: 0.9910 - val_loss: 0.6842 - val_acc: 0.8479\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9930\n",
      "Epoch 00069: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0371 - acc: 0.9930 - val_loss: 0.6370 - val_acc: 0.8626\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9964\n",
      "Epoch 00070: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0273 - acc: 0.9964 - val_loss: 0.7214 - val_acc: 0.8423\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9903\n",
      "Epoch 00071: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0466 - acc: 0.9903 - val_loss: 0.6528 - val_acc: 0.8563\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9955\n",
      "Epoch 00072: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0296 - acc: 0.9954 - val_loss: 0.6526 - val_acc: 0.8588\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9933\n",
      "Epoch 00073: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0352 - acc: 0.9932 - val_loss: 0.7375 - val_acc: 0.8355\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9916\n",
      "Epoch 00074: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0414 - acc: 0.9916 - val_loss: 0.6716 - val_acc: 0.8565\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9937\n",
      "Epoch 00075: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0334 - acc: 0.9937 - val_loss: 0.7350 - val_acc: 0.8437\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9899\n",
      "Epoch 00076: val_loss did not improve from 0.52797\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0432 - acc: 0.9899 - val_loss: 0.7872 - val_acc: 0.8390\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 631us/sample - loss: 0.6205 - acc: 0.8224\n",
      "Loss: 0.6205333469565165 Accuracy: 0.8224299\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9010 - acc: 0.4200\n",
      "Epoch 00001: val_loss improved from inf to 1.45277, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/001-1.4528.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 1.9009 - acc: 0.4201 - val_loss: 1.4528 - val_acc: 0.5609\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1268 - acc: 0.6646\n",
      "Epoch 00002: val_loss improved from 1.45277 to 1.15555, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/002-1.1555.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 1.1269 - acc: 0.6646 - val_loss: 1.1555 - val_acc: 0.6424\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8639 - acc: 0.7506\n",
      "Epoch 00003: val_loss improved from 1.15555 to 0.74162, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/003-0.7416.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.8640 - acc: 0.7506 - val_loss: 0.7416 - val_acc: 0.8006\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6966 - acc: 0.7987\n",
      "Epoch 00004: val_loss improved from 0.74162 to 0.65066, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/004-0.6507.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.6967 - acc: 0.7987 - val_loss: 0.6507 - val_acc: 0.8137\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5894 - acc: 0.8309\n",
      "Epoch 00005: val_loss improved from 0.65066 to 0.60787, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/005-0.6079.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5893 - acc: 0.8309 - val_loss: 0.6079 - val_acc: 0.8365\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5066 - acc: 0.8559\n",
      "Epoch 00006: val_loss improved from 0.60787 to 0.52088, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/006-0.5209.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5067 - acc: 0.8559 - val_loss: 0.5209 - val_acc: 0.8551\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4396 - acc: 0.8739\n",
      "Epoch 00007: val_loss improved from 0.52088 to 0.47087, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/007-0.4709.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.4396 - acc: 0.8738 - val_loss: 0.4709 - val_acc: 0.8614\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3960 - acc: 0.8878\n",
      "Epoch 00008: val_loss improved from 0.47087 to 0.46341, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/008-0.4634.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3960 - acc: 0.8878 - val_loss: 0.4634 - val_acc: 0.8623\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3568 - acc: 0.8972\n",
      "Epoch 00009: val_loss improved from 0.46341 to 0.44027, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/009-0.4403.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3568 - acc: 0.8972 - val_loss: 0.4403 - val_acc: 0.8793\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.9066\n",
      "Epoch 00010: val_loss did not improve from 0.44027\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3239 - acc: 0.9066 - val_loss: 0.4537 - val_acc: 0.8770\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2909 - acc: 0.9195\n",
      "Epoch 00011: val_loss improved from 0.44027 to 0.37851, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/011-0.3785.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2910 - acc: 0.9195 - val_loss: 0.3785 - val_acc: 0.8935\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2659 - acc: 0.9254\n",
      "Epoch 00012: val_loss improved from 0.37851 to 0.35317, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/012-0.3532.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2659 - acc: 0.9253 - val_loss: 0.3532 - val_acc: 0.9078\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2468 - acc: 0.9301\n",
      "Epoch 00013: val_loss did not improve from 0.35317\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2468 - acc: 0.9301 - val_loss: 0.3668 - val_acc: 0.8996\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2226 - acc: 0.9380\n",
      "Epoch 00014: val_loss did not improve from 0.35317\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2230 - acc: 0.9379 - val_loss: 0.3693 - val_acc: 0.8956\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2070 - acc: 0.9434\n",
      "Epoch 00015: val_loss improved from 0.35317 to 0.33065, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/015-0.3307.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2071 - acc: 0.9434 - val_loss: 0.3307 - val_acc: 0.9071\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1877 - acc: 0.9493\n",
      "Epoch 00016: val_loss did not improve from 0.33065\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1879 - acc: 0.9493 - val_loss: 0.3400 - val_acc: 0.9071\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1767 - acc: 0.9515\n",
      "Epoch 00017: val_loss improved from 0.33065 to 0.30840, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/017-0.3084.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1768 - acc: 0.9514 - val_loss: 0.3084 - val_acc: 0.9117\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9538\n",
      "Epoch 00018: val_loss did not improve from 0.30840\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1654 - acc: 0.9538 - val_loss: 0.3524 - val_acc: 0.9052\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1509 - acc: 0.9598\n",
      "Epoch 00019: val_loss did not improve from 0.30840\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1510 - acc: 0.9597 - val_loss: 0.3586 - val_acc: 0.9022\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9597\n",
      "Epoch 00020: val_loss did not improve from 0.30840\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1460 - acc: 0.9597 - val_loss: 0.3127 - val_acc: 0.9131\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9656\n",
      "Epoch 00021: val_loss improved from 0.30840 to 0.30283, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/021-0.3028.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1295 - acc: 0.9656 - val_loss: 0.3028 - val_acc: 0.9101\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9702\n",
      "Epoch 00022: val_loss did not improve from 0.30283\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1189 - acc: 0.9702 - val_loss: 0.3049 - val_acc: 0.9166\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9713\n",
      "Epoch 00023: val_loss did not improve from 0.30283\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1117 - acc: 0.9713 - val_loss: 0.3278 - val_acc: 0.9087\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9723\n",
      "Epoch 00024: val_loss improved from 0.30283 to 0.29077, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/024-0.2908.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1090 - acc: 0.9723 - val_loss: 0.2908 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9754\n",
      "Epoch 00025: val_loss improved from 0.29077 to 0.28278, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_7_conv_checkpoint/025-0.2828.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0983 - acc: 0.9754 - val_loss: 0.2828 - val_acc: 0.9248\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9768\n",
      "Epoch 00026: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0934 - acc: 0.9767 - val_loss: 0.2981 - val_acc: 0.9171\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9756\n",
      "Epoch 00027: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0936 - acc: 0.9756 - val_loss: 0.2982 - val_acc: 0.9175\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9827\n",
      "Epoch 00028: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0741 - acc: 0.9827 - val_loss: 0.2862 - val_acc: 0.9222\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9821\n",
      "Epoch 00029: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0751 - acc: 0.9821 - val_loss: 0.3169 - val_acc: 0.9161\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9861\n",
      "Epoch 00030: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0654 - acc: 0.9861 - val_loss: 0.3081 - val_acc: 0.9173\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9855\n",
      "Epoch 00031: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0643 - acc: 0.9855 - val_loss: 0.3284 - val_acc: 0.9175\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9859\n",
      "Epoch 00032: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0627 - acc: 0.9859 - val_loss: 0.2945 - val_acc: 0.9220\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9869\n",
      "Epoch 00033: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0581 - acc: 0.9869 - val_loss: 0.3093 - val_acc: 0.9178\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9897\n",
      "Epoch 00034: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0515 - acc: 0.9897 - val_loss: 0.3552 - val_acc: 0.9026\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9907\n",
      "Epoch 00035: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0480 - acc: 0.9906 - val_loss: 0.3239 - val_acc: 0.9161\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9885\n",
      "Epoch 00036: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0512 - acc: 0.9885 - val_loss: 0.3151 - val_acc: 0.9185\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9871\n",
      "Epoch 00037: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0546 - acc: 0.9871 - val_loss: 0.3244 - val_acc: 0.9199\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9902\n",
      "Epoch 00038: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0458 - acc: 0.9902 - val_loss: 0.3189 - val_acc: 0.9173\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9908\n",
      "Epoch 00039: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0437 - acc: 0.9908 - val_loss: 0.2911 - val_acc: 0.9252\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9914\n",
      "Epoch 00040: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0409 - acc: 0.9914 - val_loss: 0.2946 - val_acc: 0.9259\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9945\n",
      "Epoch 00041: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0324 - acc: 0.9945 - val_loss: 0.3622 - val_acc: 0.9092\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9894\n",
      "Epoch 00042: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0459 - acc: 0.9894 - val_loss: 0.3049 - val_acc: 0.9229\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9934\n",
      "Epoch 00043: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0333 - acc: 0.9934 - val_loss: 0.3019 - val_acc: 0.9245\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 00044: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0400 - acc: 0.9916 - val_loss: 0.3125 - val_acc: 0.9192\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9915\n",
      "Epoch 00045: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0386 - acc: 0.9915 - val_loss: 0.3183 - val_acc: 0.9220\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9912\n",
      "Epoch 00046: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0396 - acc: 0.9912 - val_loss: 0.3062 - val_acc: 0.9255\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9961\n",
      "Epoch 00047: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0246 - acc: 0.9961 - val_loss: 0.2886 - val_acc: 0.9287\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9974\n",
      "Epoch 00048: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0217 - acc: 0.9973 - val_loss: 0.3528 - val_acc: 0.9180\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9899\n",
      "Epoch 00049: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0448 - acc: 0.9899 - val_loss: 0.3378 - val_acc: 0.9217\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9943\n",
      "Epoch 00050: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0298 - acc: 0.9942 - val_loss: 0.3177 - val_acc: 0.9159\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9937\n",
      "Epoch 00051: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0309 - acc: 0.9937 - val_loss: 0.3276 - val_acc: 0.9192\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9951\n",
      "Epoch 00052: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0251 - acc: 0.9951 - val_loss: 0.2940 - val_acc: 0.9308\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9933\n",
      "Epoch 00053: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0308 - acc: 0.9933 - val_loss: 0.3042 - val_acc: 0.9269\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9980\n",
      "Epoch 00054: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0173 - acc: 0.9980 - val_loss: 0.3653 - val_acc: 0.9166\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9924\n",
      "Epoch 00055: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0344 - acc: 0.9923 - val_loss: 0.3197 - val_acc: 0.9264\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9924\n",
      "Epoch 00056: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0331 - acc: 0.9924 - val_loss: 0.3185 - val_acc: 0.9285\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9958\n",
      "Epoch 00057: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0218 - acc: 0.9958 - val_loss: 0.3385 - val_acc: 0.9180\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9957\n",
      "Epoch 00058: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0235 - acc: 0.9956 - val_loss: 0.3201 - val_acc: 0.9245\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9960\n",
      "Epoch 00059: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0219 - acc: 0.9960 - val_loss: 0.3461 - val_acc: 0.9255\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9966\n",
      "Epoch 00060: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0205 - acc: 0.9966 - val_loss: 0.3534 - val_acc: 0.9166\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9950\n",
      "Epoch 00061: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0242 - acc: 0.9949 - val_loss: 0.3189 - val_acc: 0.9259\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9938\n",
      "Epoch 00062: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0276 - acc: 0.9938 - val_loss: 0.3176 - val_acc: 0.9250\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9979\n",
      "Epoch 00063: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0153 - acc: 0.9979 - val_loss: 0.3228 - val_acc: 0.9227\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9968\n",
      "Epoch 00064: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0178 - acc: 0.9968 - val_loss: 0.3393 - val_acc: 0.9224\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9945\n",
      "Epoch 00065: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0259 - acc: 0.9945 - val_loss: 0.3239 - val_acc: 0.9257\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9979\n",
      "Epoch 00066: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0149 - acc: 0.9979 - val_loss: 0.3192 - val_acc: 0.9248\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9977\n",
      "Epoch 00067: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0144 - acc: 0.9976 - val_loss: 0.3351 - val_acc: 0.9215\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 00068: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0327 - acc: 0.9917 - val_loss: 0.3271 - val_acc: 0.9262\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9976\n",
      "Epoch 00069: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0151 - acc: 0.9976 - val_loss: 0.3470 - val_acc: 0.9201\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9982\n",
      "Epoch 00070: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0130 - acc: 0.9982 - val_loss: 0.3334 - val_acc: 0.9250\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9980\n",
      "Epoch 00071: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0133 - acc: 0.9980 - val_loss: 0.3364 - val_acc: 0.9229\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9929\n",
      "Epoch 00072: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0267 - acc: 0.9928 - val_loss: 0.3333 - val_acc: 0.9194\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9954\n",
      "Epoch 00073: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0195 - acc: 0.9954 - val_loss: 0.3270 - val_acc: 0.9266\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9953\n",
      "Epoch 00074: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0209 - acc: 0.9953 - val_loss: 0.3290 - val_acc: 0.9241\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9983\n",
      "Epoch 00075: val_loss did not improve from 0.28278\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0125 - acc: 0.9983 - val_loss: 0.3337 - val_acc: 0.9224\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 642us/sample - loss: 0.3374 - acc: 0.9034\n",
      "Loss: 0.3374249934964462 Accuracy: 0.90342677\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7139 - acc: 0.4824\n",
      "Epoch 00001: val_loss improved from inf to 1.32595, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/001-1.3259.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 1.7139 - acc: 0.4824 - val_loss: 1.3259 - val_acc: 0.5863\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8444 - acc: 0.7524\n",
      "Epoch 00002: val_loss improved from 1.32595 to 0.66413, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/002-0.6641.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.8443 - acc: 0.7524 - val_loss: 0.6641 - val_acc: 0.8022\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5806 - acc: 0.8336\n",
      "Epoch 00003: val_loss improved from 0.66413 to 0.47678, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/003-0.4768.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.5806 - acc: 0.8336 - val_loss: 0.4768 - val_acc: 0.8677\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4417 - acc: 0.8750\n",
      "Epoch 00004: val_loss improved from 0.47678 to 0.42521, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/004-0.4252.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.4417 - acc: 0.8750 - val_loss: 0.4252 - val_acc: 0.8656\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3599 - acc: 0.8958\n",
      "Epoch 00005: val_loss improved from 0.42521 to 0.34625, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/005-0.3463.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3601 - acc: 0.8958 - val_loss: 0.3463 - val_acc: 0.8947\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2985 - acc: 0.9144\n",
      "Epoch 00006: val_loss did not improve from 0.34625\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2986 - acc: 0.9144 - val_loss: 0.3925 - val_acc: 0.8842\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.9280\n",
      "Epoch 00007: val_loss improved from 0.34625 to 0.26383, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/007-0.2638.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2552 - acc: 0.9280 - val_loss: 0.2638 - val_acc: 0.9206\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2207 - acc: 0.9388\n",
      "Epoch 00008: val_loss improved from 0.26383 to 0.23944, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/008-0.2394.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2208 - acc: 0.9388 - val_loss: 0.2394 - val_acc: 0.9269\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9447\n",
      "Epoch 00009: val_loss improved from 0.23944 to 0.22878, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/009-0.2288.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1957 - acc: 0.9446 - val_loss: 0.2288 - val_acc: 0.9304\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9512\n",
      "Epoch 00010: val_loss did not improve from 0.22878\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1747 - acc: 0.9512 - val_loss: 0.2333 - val_acc: 0.9297\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9573\n",
      "Epoch 00011: val_loss did not improve from 0.22878\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1527 - acc: 0.9573 - val_loss: 0.2368 - val_acc: 0.9334\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9623\n",
      "Epoch 00012: val_loss improved from 0.22878 to 0.21573, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/012-0.2157.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1370 - acc: 0.9623 - val_loss: 0.2157 - val_acc: 0.9369\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9667\n",
      "Epoch 00013: val_loss did not improve from 0.21573\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1220 - acc: 0.9667 - val_loss: 0.2496 - val_acc: 0.9262\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9709\n",
      "Epoch 00014: val_loss improved from 0.21573 to 0.21436, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/014-0.2144.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1079 - acc: 0.9709 - val_loss: 0.2144 - val_acc: 0.9327\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9741\n",
      "Epoch 00015: val_loss improved from 0.21436 to 0.18962, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/015-0.1896.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1001 - acc: 0.9741 - val_loss: 0.1896 - val_acc: 0.9411\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9774\n",
      "Epoch 00016: val_loss did not improve from 0.18962\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0862 - acc: 0.9774 - val_loss: 0.1980 - val_acc: 0.9418\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9789\n",
      "Epoch 00017: val_loss did not improve from 0.18962\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0820 - acc: 0.9789 - val_loss: 0.2196 - val_acc: 0.9357\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9818\n",
      "Epoch 00018: val_loss did not improve from 0.18962\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0709 - acc: 0.9818 - val_loss: 0.1965 - val_acc: 0.9415\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9863\n",
      "Epoch 00019: val_loss did not improve from 0.18962\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0613 - acc: 0.9862 - val_loss: 0.1942 - val_acc: 0.9394\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9832\n",
      "Epoch 00020: val_loss did not improve from 0.18962\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0672 - acc: 0.9832 - val_loss: 0.2011 - val_acc: 0.9411\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9877\n",
      "Epoch 00021: val_loss did not improve from 0.18962\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0523 - acc: 0.9877 - val_loss: 0.2100 - val_acc: 0.9408\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9877\n",
      "Epoch 00022: val_loss improved from 0.18962 to 0.18610, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/022-0.1861.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0525 - acc: 0.9877 - val_loss: 0.1861 - val_acc: 0.9457\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9913\n",
      "Epoch 00023: val_loss did not improve from 0.18610\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0418 - acc: 0.9913 - val_loss: 0.1915 - val_acc: 0.9457\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9914\n",
      "Epoch 00024: val_loss improved from 0.18610 to 0.18378, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/024-0.1838.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0403 - acc: 0.9914 - val_loss: 0.1838 - val_acc: 0.9436\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9925\n",
      "Epoch 00025: val_loss did not improve from 0.18378\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0358 - acc: 0.9925 - val_loss: 0.1994 - val_acc: 0.9429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9927\n",
      "Epoch 00026: val_loss did not improve from 0.18378\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0343 - acc: 0.9926 - val_loss: 0.2265 - val_acc: 0.9352\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9886\n",
      "Epoch 00027: val_loss improved from 0.18378 to 0.18331, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_8_conv_checkpoint/027-0.1833.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0451 - acc: 0.9886 - val_loss: 0.1833 - val_acc: 0.9474\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9961\n",
      "Epoch 00028: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0247 - acc: 0.9961 - val_loss: 0.2106 - val_acc: 0.9413\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9921\n",
      "Epoch 00029: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0374 - acc: 0.9920 - val_loss: 0.2032 - val_acc: 0.9429\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9927\n",
      "Epoch 00030: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0345 - acc: 0.9927 - val_loss: 0.1983 - val_acc: 0.9464\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9961\n",
      "Epoch 00031: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0222 - acc: 0.9961 - val_loss: 0.1945 - val_acc: 0.9462\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9959\n",
      "Epoch 00032: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0234 - acc: 0.9959 - val_loss: 0.2111 - val_acc: 0.9434\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9941\n",
      "Epoch 00033: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0270 - acc: 0.9941 - val_loss: 0.2135 - val_acc: 0.9397\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9932\n",
      "Epoch 00034: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0304 - acc: 0.9932 - val_loss: 0.2226 - val_acc: 0.9383\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9982\n",
      "Epoch 00035: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0144 - acc: 0.9982 - val_loss: 0.2113 - val_acc: 0.9441\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9959\n",
      "Epoch 00036: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0214 - acc: 0.9958 - val_loss: 0.1962 - val_acc: 0.9474\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9932\n",
      "Epoch 00037: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0293 - acc: 0.9932 - val_loss: 0.2313 - val_acc: 0.9387\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9955\n",
      "Epoch 00038: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0208 - acc: 0.9955 - val_loss: 0.1978 - val_acc: 0.9469\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9960\n",
      "Epoch 00039: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0188 - acc: 0.9960 - val_loss: 0.2300 - val_acc: 0.9401\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9973\n",
      "Epoch 00040: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0142 - acc: 0.9973 - val_loss: 0.2091 - val_acc: 0.9483\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9976\n",
      "Epoch 00041: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0133 - acc: 0.9975 - val_loss: 0.2287 - val_acc: 0.9376\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9945\n",
      "Epoch 00042: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0233 - acc: 0.9945 - val_loss: 0.1951 - val_acc: 0.9467\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9970\n",
      "Epoch 00043: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0160 - acc: 0.9970 - val_loss: 0.2033 - val_acc: 0.9499\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9987\n",
      "Epoch 00044: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0093 - acc: 0.9988 - val_loss: 0.2073 - val_acc: 0.9478\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9992\n",
      "Epoch 00045: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0092 - acc: 0.9992 - val_loss: 0.2171 - val_acc: 0.9460\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9941\n",
      "Epoch 00046: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0250 - acc: 0.9941 - val_loss: 0.2181 - val_acc: 0.9436\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9983\n",
      "Epoch 00047: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0107 - acc: 0.9983 - val_loss: 0.2261 - val_acc: 0.9462\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9943\n",
      "Epoch 00048: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0224 - acc: 0.9943 - val_loss: 0.2121 - val_acc: 0.9448\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9953\n",
      "Epoch 00049: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0193 - acc: 0.9953 - val_loss: 0.2163 - val_acc: 0.9471\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9992\n",
      "Epoch 00050: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0069 - acc: 0.9992 - val_loss: 0.2237 - val_acc: 0.9422\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9964\n",
      "Epoch 00051: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0161 - acc: 0.9964 - val_loss: 0.2788 - val_acc: 0.9317\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9933\n",
      "Epoch 00052: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0258 - acc: 0.9932 - val_loss: 0.1989 - val_acc: 0.9509\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9972\n",
      "Epoch 00053: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0148 - acc: 0.9972 - val_loss: 0.1941 - val_acc: 0.9509\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9996\n",
      "Epoch 00054: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0059 - acc: 0.9996 - val_loss: 0.2169 - val_acc: 0.9495\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9980\n",
      "Epoch 00055: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0108 - acc: 0.9980 - val_loss: 0.2395 - val_acc: 0.9439\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9980\n",
      "Epoch 00056: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0103 - acc: 0.9980 - val_loss: 0.2218 - val_acc: 0.9460\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9970\n",
      "Epoch 00057: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0112 - acc: 0.9970 - val_loss: 0.2536 - val_acc: 0.9427\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9952\n",
      "Epoch 00058: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0192 - acc: 0.9952 - val_loss: 0.2139 - val_acc: 0.9464\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9964\n",
      "Epoch 00059: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0154 - acc: 0.9964 - val_loss: 0.2039 - val_acc: 0.9499\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9987\n",
      "Epoch 00060: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0075 - acc: 0.9987 - val_loss: 0.2106 - val_acc: 0.9478\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9961\n",
      "Epoch 00061: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0151 - acc: 0.9961 - val_loss: 0.2028 - val_acc: 0.9534\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9989\n",
      "Epoch 00062: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0064 - acc: 0.9989 - val_loss: 0.2056 - val_acc: 0.9471\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9989\n",
      "Epoch 00063: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0076 - acc: 0.9989 - val_loss: 0.2444 - val_acc: 0.9418\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9926\n",
      "Epoch 00064: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0268 - acc: 0.9926 - val_loss: 0.2189 - val_acc: 0.9453\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9992\n",
      "Epoch 00065: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0059 - acc: 0.9992 - val_loss: 0.2107 - val_acc: 0.9481\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9991\n",
      "Epoch 00066: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0062 - acc: 0.9990 - val_loss: 0.2063 - val_acc: 0.9506\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9971\n",
      "Epoch 00067: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0126 - acc: 0.9970 - val_loss: 0.2376 - val_acc: 0.9441\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9945\n",
      "Epoch 00068: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0212 - acc: 0.9944 - val_loss: 0.2300 - val_acc: 0.9446\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9963\n",
      "Epoch 00069: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0149 - acc: 0.9963 - val_loss: 0.1896 - val_acc: 0.9520\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9992\n",
      "Epoch 00070: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0059 - acc: 0.9992 - val_loss: 0.1990 - val_acc: 0.9518\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9995\n",
      "Epoch 00071: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0048 - acc: 0.9995 - val_loss: 0.1982 - val_acc: 0.9541\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9991\n",
      "Epoch 00072: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0063 - acc: 0.9991 - val_loss: 0.2296 - val_acc: 0.9476\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9980\n",
      "Epoch 00073: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0098 - acc: 0.9980 - val_loss: 0.1953 - val_acc: 0.9522\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9984\n",
      "Epoch 00074: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0072 - acc: 0.9984 - val_loss: 0.2570 - val_acc: 0.9392\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9982\n",
      "Epoch 00075: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0086 - acc: 0.9982 - val_loss: 0.2130 - val_acc: 0.9497\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9988\n",
      "Epoch 00076: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0062 - acc: 0.9988 - val_loss: 0.2697 - val_acc: 0.9411\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9957\n",
      "Epoch 00077: val_loss did not improve from 0.18331\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0148 - acc: 0.9957 - val_loss: 0.2264 - val_acc: 0.9474\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 666us/sample - loss: 0.2575 - acc: 0.9267\n",
      "Loss: 0.25753685289206657 Accuracy: 0.9266874\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3533 - acc: 0.5842\n",
      "Epoch 00001: val_loss improved from inf to 0.91334, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_9_conv_checkpoint/001-0.9133.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3533 - acc: 0.5842 - val_loss: 0.9133 - val_acc: 0.7412\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5692 - acc: 0.8300\n",
      "Epoch 00002: val_loss improved from 0.91334 to 0.41847, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_9_conv_checkpoint/002-0.4185.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.5693 - acc: 0.8299 - val_loss: 0.4185 - val_acc: 0.8751\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3885 - acc: 0.8857\n",
      "Epoch 00003: val_loss improved from 0.41847 to 0.34442, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_9_conv_checkpoint/003-0.3444.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.3886 - acc: 0.8856 - val_loss: 0.3444 - val_acc: 0.8991\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2971 - acc: 0.9142\n",
      "Epoch 00004: val_loss improved from 0.34442 to 0.29002, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_9_conv_checkpoint/004-0.2900.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2970 - acc: 0.9142 - val_loss: 0.2900 - val_acc: 0.9122\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2400 - acc: 0.9308\n",
      "Epoch 00005: val_loss improved from 0.29002 to 0.27532, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_9_conv_checkpoint/005-0.2753.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2400 - acc: 0.9307 - val_loss: 0.2753 - val_acc: 0.9152\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2050 - acc: 0.9417\n",
      "Epoch 00006: val_loss improved from 0.27532 to 0.22591, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_9_conv_checkpoint/006-0.2259.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2050 - acc: 0.9417 - val_loss: 0.2259 - val_acc: 0.9327\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1730 - acc: 0.9503\n",
      "Epoch 00007: val_loss did not improve from 0.22591\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1733 - acc: 0.9502 - val_loss: 0.2557 - val_acc: 0.9231\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9536\n",
      "Epoch 00008: val_loss improved from 0.22591 to 0.21303, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_9_conv_checkpoint/008-0.2130.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1620 - acc: 0.9535 - val_loss: 0.2130 - val_acc: 0.9350\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9633\n",
      "Epoch 00009: val_loss improved from 0.21303 to 0.19570, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_9_conv_checkpoint/009-0.1957.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1318 - acc: 0.9633 - val_loss: 0.1957 - val_acc: 0.9427\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9686\n",
      "Epoch 00010: val_loss did not improve from 0.19570\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1142 - acc: 0.9686 - val_loss: 0.2126 - val_acc: 0.9355\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9741\n",
      "Epoch 00011: val_loss did not improve from 0.19570\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0975 - acc: 0.9741 - val_loss: 0.2014 - val_acc: 0.9404\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9723\n",
      "Epoch 00012: val_loss did not improve from 0.19570\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0987 - acc: 0.9723 - val_loss: 0.2116 - val_acc: 0.9406\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9807\n",
      "Epoch 00013: val_loss did not improve from 0.19570\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0751 - acc: 0.9807 - val_loss: 0.2074 - val_acc: 0.9387\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9833\n",
      "Epoch 00014: val_loss did not improve from 0.19570\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0665 - acc: 0.9833 - val_loss: 0.2209 - val_acc: 0.9364\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9840\n",
      "Epoch 00015: val_loss improved from 0.19570 to 0.19414, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_9_conv_checkpoint/015-0.1941.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0635 - acc: 0.9840 - val_loss: 0.1941 - val_acc: 0.9432\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9865\n",
      "Epoch 00016: val_loss improved from 0.19414 to 0.17026, saving model to model/checkpoint/1D_CNN_custom_3_ch_32_BN_9_conv_checkpoint/016-0.1703.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0548 - acc: 0.9864 - val_loss: 0.1703 - val_acc: 0.9495\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9883\n",
      "Epoch 00017: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0482 - acc: 0.9883 - val_loss: 0.1704 - val_acc: 0.9506\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9914\n",
      "Epoch 00018: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0379 - acc: 0.9914 - val_loss: 0.1856 - val_acc: 0.9427\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9915\n",
      "Epoch 00019: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0376 - acc: 0.9915 - val_loss: 0.1982 - val_acc: 0.9413\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9928\n",
      "Epoch 00020: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0330 - acc: 0.9928 - val_loss: 0.2102 - val_acc: 0.9385\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9946\n",
      "Epoch 00021: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0271 - acc: 0.9946 - val_loss: 0.2261 - val_acc: 0.9397\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9926\n",
      "Epoch 00022: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0321 - acc: 0.9926 - val_loss: 0.2042 - val_acc: 0.9404\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9951\n",
      "Epoch 00023: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0250 - acc: 0.9951 - val_loss: 0.2035 - val_acc: 0.9434\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9957\n",
      "Epoch 00024: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0215 - acc: 0.9957 - val_loss: 0.2150 - val_acc: 0.9413\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9964\n",
      "Epoch 00025: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0182 - acc: 0.9963 - val_loss: 0.2346 - val_acc: 0.9380\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9902\n",
      "Epoch 00026: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0371 - acc: 0.9902 - val_loss: 0.1917 - val_acc: 0.9483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9982\n",
      "Epoch 00027: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0133 - acc: 0.9982 - val_loss: 0.1826 - val_acc: 0.9497\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9929\n",
      "Epoch 00028: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0291 - acc: 0.9929 - val_loss: 0.1926 - val_acc: 0.9469\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9975\n",
      "Epoch 00029: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0138 - acc: 0.9975 - val_loss: 0.2424 - val_acc: 0.9411\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9970\n",
      "Epoch 00030: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0144 - acc: 0.9970 - val_loss: 0.2169 - val_acc: 0.9429\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9981\n",
      "Epoch 00031: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0113 - acc: 0.9981 - val_loss: 0.2303 - val_acc: 0.9399\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9936\n",
      "Epoch 00032: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0248 - acc: 0.9936 - val_loss: 0.1983 - val_acc: 0.9469\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9974\n",
      "Epoch 00033: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0135 - acc: 0.9974 - val_loss: 0.1964 - val_acc: 0.9478\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9920\n",
      "Epoch 00034: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0287 - acc: 0.9920 - val_loss: 0.2030 - val_acc: 0.9478\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9991\n",
      "Epoch 00035: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0080 - acc: 0.9991 - val_loss: 0.1876 - val_acc: 0.9527\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9977\n",
      "Epoch 00036: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0105 - acc: 0.9977 - val_loss: 0.2395 - val_acc: 0.9373\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9975\n",
      "Epoch 00037: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0117 - acc: 0.9975 - val_loss: 0.2361 - val_acc: 0.9436\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9895\n",
      "Epoch 00038: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0356 - acc: 0.9895 - val_loss: 0.2232 - val_acc: 0.9418\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9958\n",
      "Epoch 00039: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0174 - acc: 0.9958 - val_loss: 0.1847 - val_acc: 0.9548\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9969\n",
      "Epoch 00040: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0135 - acc: 0.9969 - val_loss: 0.1853 - val_acc: 0.9532\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9986\n",
      "Epoch 00041: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0078 - acc: 0.9986 - val_loss: 0.1894 - val_acc: 0.9532\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9994\n",
      "Epoch 00042: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0048 - acc: 0.9994 - val_loss: 0.1887 - val_acc: 0.9541\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9960\n",
      "Epoch 00043: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0161 - acc: 0.9960 - val_loss: 0.2080 - val_acc: 0.9504\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9980\n",
      "Epoch 00044: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0100 - acc: 0.9980 - val_loss: 0.1822 - val_acc: 0.9550\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9990\n",
      "Epoch 00045: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0062 - acc: 0.9990 - val_loss: 0.2292 - val_acc: 0.9481\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9964\n",
      "Epoch 00046: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0147 - acc: 0.9963 - val_loss: 0.3367 - val_acc: 0.9234\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9916\n",
      "Epoch 00047: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0285 - acc: 0.9915 - val_loss: 0.1928 - val_acc: 0.9506\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9923\n",
      "Epoch 00048: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0278 - acc: 0.9923 - val_loss: 0.2056 - val_acc: 0.9541\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9992\n",
      "Epoch 00049: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0059 - acc: 0.9992 - val_loss: 0.1840 - val_acc: 0.9550\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9966\n",
      "Epoch 00050: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0142 - acc: 0.9966 - val_loss: 0.1841 - val_acc: 0.9550\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9988\n",
      "Epoch 00051: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0070 - acc: 0.9988 - val_loss: 0.1897 - val_acc: 0.9578\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9995\n",
      "Epoch 00052: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0035 - acc: 0.9995 - val_loss: 0.2040 - val_acc: 0.9536\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9956\n",
      "Epoch 00053: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0155 - acc: 0.9956 - val_loss: 0.1872 - val_acc: 0.9548\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9995\n",
      "Epoch 00054: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0041 - acc: 0.9995 - val_loss: 0.2430 - val_acc: 0.9455\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9958\n",
      "Epoch 00055: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0149 - acc: 0.9958 - val_loss: 0.2140 - val_acc: 0.9462\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9943\n",
      "Epoch 00056: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0188 - acc: 0.9943 - val_loss: 0.2131 - val_acc: 0.9518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9996\n",
      "Epoch 00057: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0041 - acc: 0.9995 - val_loss: 0.2234 - val_acc: 0.9467\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9960\n",
      "Epoch 00058: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0155 - acc: 0.9960 - val_loss: 0.2071 - val_acc: 0.9495\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9994\n",
      "Epoch 00059: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0042 - acc: 0.9994 - val_loss: 0.1883 - val_acc: 0.9529\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9946\n",
      "Epoch 00060: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0188 - acc: 0.9946 - val_loss: 0.1929 - val_acc: 0.9534\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9992\n",
      "Epoch 00061: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0044 - acc: 0.9992 - val_loss: 0.1951 - val_acc: 0.9546\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9978\n",
      "Epoch 00062: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0092 - acc: 0.9978 - val_loss: 0.1909 - val_acc: 0.9536\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9990\n",
      "Epoch 00063: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0049 - acc: 0.9990 - val_loss: 0.1990 - val_acc: 0.9532\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9962\n",
      "Epoch 00064: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0141 - acc: 0.9962 - val_loss: 0.1907 - val_acc: 0.9574\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9988\n",
      "Epoch 00065: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0057 - acc: 0.9988 - val_loss: 0.2064 - val_acc: 0.9497\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9951\n",
      "Epoch 00066: val_loss did not improve from 0.17026\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0154 - acc: 0.9951 - val_loss: 0.1970 - val_acc: 0.9511\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 716us/sample - loss: 0.2286 - acc: 0.9294\n",
      "Loss: 0.22861972911552228 Accuracy: 0.92938733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    base = '1D_CNN_custom_3_ch_32_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_3_ch_32_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 779,216\n",
      "Trainable params: 703,120\n",
      "Non-trainable params: 76,096\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 743us/sample - loss: 1.4314 - acc: 0.6021\n",
      "Loss: 1.4313814536309564 Accuracy: 0.6020768\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 12608)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 12608)             50432     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                201744    \n",
      "=================================================================\n",
      "Total params: 294,416\n",
      "Trainable params: 268,752\n",
      "Non-trainable params: 25,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 731us/sample - loss: 0.9976 - acc: 0.7020\n",
      "Loss: 0.9975839767871988 Accuracy: 0.701973\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 4160)              16640     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                66576     \n",
      "=================================================================\n",
      "Total params: 146,256\n",
      "Trainable params: 137,360\n",
      "Non-trainable params: 8,896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 753us/sample - loss: 0.6205 - acc: 0.8224\n",
      "Loss: 0.6205333469565165 Accuracy: 0.8224299\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 128)           41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 158,416\n",
      "Trainable params: 152,208\n",
      "Non-trainable params: 6,208\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 800us/sample - loss: 0.3374 - acc: 0.9034\n",
      "Loss: 0.3374249934964462 Accuracy: 0.90342677\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 128)           41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 205,136\n",
      "Trainable params: 202,256\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 796us/sample - loss: 0.2575 - acc: 0.9267\n",
      "Loss: 0.25753685289206657 Accuracy: 0.9266874\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 128)           41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 128)            82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 7, 128)            512       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 274,896\n",
      "Trainable params: 273,040\n",
      "Non-trainable params: 1,856\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 895us/sample - loss: 0.2286 - acc: 0.9294\n",
      "Loss: 0.22861972911552228 Accuracy: 0.92938733\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_3_ch_32_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_3_ch_32_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 779,216\n",
      "Trainable params: 703,120\n",
      "Non-trainable params: 76,096\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 795us/sample - loss: 2.6633 - acc: 0.5915\n",
      "Loss: 2.6633056637158896 Accuracy: 0.59148496\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 12608)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 12608)             50432     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                201744    \n",
      "=================================================================\n",
      "Total params: 294,416\n",
      "Trainable params: 268,752\n",
      "Non-trainable params: 25,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 911us/sample - loss: 1.5827 - acc: 0.6972\n",
      "Loss: 1.5827084358607497 Accuracy: 0.69719625\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 4160)              16640     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                66576     \n",
      "=================================================================\n",
      "Total params: 146,256\n",
      "Trainable params: 137,360\n",
      "Non-trainable params: 8,896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 911us/sample - loss: 0.9241 - acc: 0.8164\n",
      "Loss: 0.9240950173430478 Accuracy: 0.8164071\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 128)           41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 158,416\n",
      "Trainable params: 152,208\n",
      "Non-trainable params: 6,208\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 900us/sample - loss: 0.3799 - acc: 0.9103\n",
      "Loss: 0.37989463620777564 Accuracy: 0.91028035\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 128)           41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 205,136\n",
      "Trainable params: 202,256\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 916us/sample - loss: 0.2958 - acc: 0.9340\n",
      "Loss: 0.29577742000946994 Accuracy: 0.9339564\n",
      "\n",
      "1D_CNN_custom_3_ch_32_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 128)           41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 128)            82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 7, 128)            512       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 274,896\n",
      "Trainable params: 273,040\n",
      "Non-trainable params: 1,856\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 929us/sample - loss: 0.2388 - acc: 0.9421\n",
      "Loss: 0.23883577216327623 Accuracy: 0.94205606\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
