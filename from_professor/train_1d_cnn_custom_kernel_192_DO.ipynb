{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO(conv_num=1):\n",
    "    kernel_size = 64\n",
    "    filter_size = 64\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3*kernel_size, filters=filter_size, strides=1, \n",
    "                      padding='same', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        target_kernel_size = 3 * (kernel_size//(2**(i+1)))\n",
    "        model.add(Conv1D (kernel_size=target_kernel_size if target_kernel_size != 0 else 3, \n",
    "                          filters=filter_size*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,368\n",
      "Trainable params: 16,396,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,866,640\n",
      "Trainable params: 5,866,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,421,968\n",
      "Trainable params: 2,421,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 1,306,896\n",
      "Trainable params: 1,306,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,202,576\n",
      "Trainable params: 1,202,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,030,672\n",
      "Trainable params: 1,030,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 989,840\n",
      "Trainable params: 989,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 1,010,448\n",
      "Trainable params: 1,010,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,102,864\n",
      "Trainable params: 1,102,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0319 - acc: 0.3415\n",
      "Epoch 00001: val_loss improved from inf to 1.63868, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_1_conv_checkpoint/001-1.6387.hdf5\n",
      "36805/36805 [==============================] - 33s 894us/sample - loss: 2.0317 - acc: 0.3415 - val_loss: 1.6387 - val_acc: 0.4764\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3607 - acc: 0.5784\n",
      "Epoch 00002: val_loss improved from 1.63868 to 1.50714, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_1_conv_checkpoint/002-1.5071.hdf5\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 1.3607 - acc: 0.5783 - val_loss: 1.5071 - val_acc: 0.5283\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0667 - acc: 0.6813\n",
      "Epoch 00003: val_loss did not improve from 1.50714\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 1.0667 - acc: 0.6813 - val_loss: 1.5396 - val_acc: 0.5185\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8546 - acc: 0.7493\n",
      "Epoch 00004: val_loss improved from 1.50714 to 1.50422, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_1_conv_checkpoint/004-1.5042.hdf5\n",
      "36805/36805 [==============================] - 31s 855us/sample - loss: 0.8548 - acc: 0.7492 - val_loss: 1.5042 - val_acc: 0.5365\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7001 - acc: 0.8024\n",
      "Epoch 00005: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.7002 - acc: 0.8023 - val_loss: 1.6578 - val_acc: 0.5250\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5714 - acc: 0.8456\n",
      "Epoch 00006: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.5713 - acc: 0.8456 - val_loss: 1.6717 - val_acc: 0.5218\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.8809\n",
      "Epoch 00007: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.4620 - acc: 0.8809 - val_loss: 1.7327 - val_acc: 0.5183\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3767 - acc: 0.9085\n",
      "Epoch 00008: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3768 - acc: 0.9085 - val_loss: 1.8468 - val_acc: 0.5176\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3267 - acc: 0.9249\n",
      "Epoch 00009: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3267 - acc: 0.9249 - val_loss: 1.8848 - val_acc: 0.5201\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2518 - acc: 0.9492\n",
      "Epoch 00010: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.2518 - acc: 0.9492 - val_loss: 1.9732 - val_acc: 0.5181\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9605\n",
      "Epoch 00011: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.2095 - acc: 0.9605 - val_loss: 2.0197 - val_acc: 0.5229\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1881 - acc: 0.9668\n",
      "Epoch 00012: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.1882 - acc: 0.9668 - val_loss: 2.1689 - val_acc: 0.5076\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1540 - acc: 0.9731\n",
      "Epoch 00013: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.1540 - acc: 0.9731 - val_loss: 2.1799 - val_acc: 0.5171\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9777\n",
      "Epoch 00014: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.1390 - acc: 0.9777 - val_loss: 2.2721 - val_acc: 0.5141\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9833\n",
      "Epoch 00015: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.1169 - acc: 0.9832 - val_loss: 2.3183 - val_acc: 0.5178\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9858\n",
      "Epoch 00016: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1009 - acc: 0.9858 - val_loss: 2.4585 - val_acc: 0.5085\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9863\n",
      "Epoch 00017: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.0902 - acc: 0.9863 - val_loss: 2.5237 - val_acc: 0.5064\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9875\n",
      "Epoch 00018: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.0867 - acc: 0.9875 - val_loss: 2.5817 - val_acc: 0.5062\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9883\n",
      "Epoch 00019: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.0752 - acc: 0.9883 - val_loss: 2.6537 - val_acc: 0.5115\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9857\n",
      "Epoch 00020: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.0920 - acc: 0.9857 - val_loss: 2.7254 - val_acc: 0.5034\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9882\n",
      "Epoch 00021: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.0740 - acc: 0.9882 - val_loss: 2.6971 - val_acc: 0.4994\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9890\n",
      "Epoch 00022: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.0735 - acc: 0.9890 - val_loss: 2.8240 - val_acc: 0.4966\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9919\n",
      "Epoch 00023: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.0563 - acc: 0.9919 - val_loss: 2.7925 - val_acc: 0.5092\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9908\n",
      "Epoch 00024: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.0652 - acc: 0.9908 - val_loss: 2.9296 - val_acc: 0.5085\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9908\n",
      "Epoch 00025: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.0617 - acc: 0.9908 - val_loss: 2.9348 - val_acc: 0.5066\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9918\n",
      "Epoch 00026: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.0545 - acc: 0.9918 - val_loss: 3.0058 - val_acc: 0.5066\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9917\n",
      "Epoch 00027: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.0549 - acc: 0.9917 - val_loss: 2.9640 - val_acc: 0.5059\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9917\n",
      "Epoch 00028: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.0499 - acc: 0.9917 - val_loss: 2.9992 - val_acc: 0.5057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9924\n",
      "Epoch 00029: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 851us/sample - loss: 0.0512 - acc: 0.9924 - val_loss: 3.0354 - val_acc: 0.5092\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9936\n",
      "Epoch 00030: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.0434 - acc: 0.9936 - val_loss: 3.0975 - val_acc: 0.5024\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9926\n",
      "Epoch 00031: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.0458 - acc: 0.9926 - val_loss: 3.1327 - val_acc: 0.5013\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9943\n",
      "Epoch 00032: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 851us/sample - loss: 0.0375 - acc: 0.9943 - val_loss: 3.2029 - val_acc: 0.5001\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9950\n",
      "Epoch 00033: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.0371 - acc: 0.9950 - val_loss: 3.2238 - val_acc: 0.5099\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9910\n",
      "Epoch 00034: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 852us/sample - loss: 0.0573 - acc: 0.9910 - val_loss: 3.2594 - val_acc: 0.5071\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9938\n",
      "Epoch 00035: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.0383 - acc: 0.9938 - val_loss: 3.2375 - val_acc: 0.5097\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9930\n",
      "Epoch 00036: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 852us/sample - loss: 0.0410 - acc: 0.9930 - val_loss: 3.2263 - val_acc: 0.5045\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9933\n",
      "Epoch 00037: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.0427 - acc: 0.9933 - val_loss: 3.2796 - val_acc: 0.4943\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9945\n",
      "Epoch 00038: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 853us/sample - loss: 0.0360 - acc: 0.9945 - val_loss: 3.3055 - val_acc: 0.5050\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9942\n",
      "Epoch 00039: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.0378 - acc: 0.9942 - val_loss: 3.3900 - val_acc: 0.4952\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9956\n",
      "Epoch 00040: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 851us/sample - loss: 0.0329 - acc: 0.9956 - val_loss: 3.3441 - val_acc: 0.5013\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9940\n",
      "Epoch 00041: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.0389 - acc: 0.9940 - val_loss: 3.4615 - val_acc: 0.5006\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9951\n",
      "Epoch 00042: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.0318 - acc: 0.9951 - val_loss: 3.4479 - val_acc: 0.4990\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9931\n",
      "Epoch 00043: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.0439 - acc: 0.9931 - val_loss: 3.4586 - val_acc: 0.4966\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9956\n",
      "Epoch 00044: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.0292 - acc: 0.9956 - val_loss: 3.5127 - val_acc: 0.4994\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9945\n",
      "Epoch 00045: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.0361 - acc: 0.9945 - val_loss: 3.4781 - val_acc: 0.5092\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9957\n",
      "Epoch 00046: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 853us/sample - loss: 0.0303 - acc: 0.9957 - val_loss: 3.5626 - val_acc: 0.5006\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9954\n",
      "Epoch 00047: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.0317 - acc: 0.9954 - val_loss: 3.5637 - val_acc: 0.4976\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9948\n",
      "Epoch 00048: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.0335 - acc: 0.9948 - val_loss: 3.5615 - val_acc: 0.5015\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9947\n",
      "Epoch 00049: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 852us/sample - loss: 0.0371 - acc: 0.9947 - val_loss: 3.5691 - val_acc: 0.4962\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9933\n",
      "Epoch 00050: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.0386 - acc: 0.9933 - val_loss: 3.6547 - val_acc: 0.4896\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9954\n",
      "Epoch 00051: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.0324 - acc: 0.9954 - val_loss: 3.6544 - val_acc: 0.4927\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9969\n",
      "Epoch 00052: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.0253 - acc: 0.9969 - val_loss: 3.6349 - val_acc: 0.5059\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9952\n",
      "Epoch 00053: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 851us/sample - loss: 0.0342 - acc: 0.9952 - val_loss: 3.7224 - val_acc: 0.4922\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9957\n",
      "Epoch 00054: val_loss did not improve from 1.50422\n",
      "36805/36805 [==============================] - 31s 852us/sample - loss: 0.0297 - acc: 0.9957 - val_loss: 3.6781 - val_acc: 0.4964\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 397us/sample - loss: 1.5956 - acc: 0.5009\n",
      "Loss: 1.5955962598509505 Accuracy: 0.5009346\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7802 - acc: 0.4313\n",
      "Epoch 00001: val_loss improved from inf to 1.26084, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_2_conv_checkpoint/001-1.2608.hdf5\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 1.7802 - acc: 0.4313 - val_loss: 1.2608 - val_acc: 0.6222\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1165 - acc: 0.6621\n",
      "Epoch 00002: val_loss improved from 1.26084 to 0.98988, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_2_conv_checkpoint/002-0.9899.hdf5\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 1.1164 - acc: 0.6621 - val_loss: 0.9899 - val_acc: 0.7095\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8637 - acc: 0.7418\n",
      "Epoch 00003: val_loss improved from 0.98988 to 0.89039, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_2_conv_checkpoint/003-0.8904.hdf5\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.8636 - acc: 0.7418 - val_loss: 0.8904 - val_acc: 0.7326\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6864 - acc: 0.7973\n",
      "Epoch 00004: val_loss improved from 0.89039 to 0.88377, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_2_conv_checkpoint/004-0.8838.hdf5\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.6863 - acc: 0.7973 - val_loss: 0.8838 - val_acc: 0.7377\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5379 - acc: 0.8411\n",
      "Epoch 00005: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.5378 - acc: 0.8411 - val_loss: 0.8846 - val_acc: 0.7510\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4160 - acc: 0.8793\n",
      "Epoch 00006: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.4160 - acc: 0.8793 - val_loss: 0.9125 - val_acc: 0.7498\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3153 - acc: 0.9118\n",
      "Epoch 00007: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.3153 - acc: 0.9118 - val_loss: 0.9623 - val_acc: 0.7417\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2419 - acc: 0.9337\n",
      "Epoch 00008: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.2420 - acc: 0.9337 - val_loss: 1.0561 - val_acc: 0.7365\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1805 - acc: 0.9526\n",
      "Epoch 00009: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.1805 - acc: 0.9526 - val_loss: 1.1152 - val_acc: 0.7389\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1391 - acc: 0.9655\n",
      "Epoch 00010: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.1391 - acc: 0.9655 - val_loss: 1.1698 - val_acc: 0.7382\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9726\n",
      "Epoch 00011: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.1142 - acc: 0.9726 - val_loss: 1.2039 - val_acc: 0.7431\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9792\n",
      "Epoch 00012: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0896 - acc: 0.9792 - val_loss: 1.2953 - val_acc: 0.7403\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9821\n",
      "Epoch 00013: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0781 - acc: 0.9821 - val_loss: 1.3742 - val_acc: 0.7331\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9854\n",
      "Epoch 00014: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0682 - acc: 0.9854 - val_loss: 1.3188 - val_acc: 0.7461\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9855\n",
      "Epoch 00015: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0639 - acc: 0.9855 - val_loss: 1.3758 - val_acc: 0.7405\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9864\n",
      "Epoch 00016: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0594 - acc: 0.9864 - val_loss: 1.4992 - val_acc: 0.7345\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9865\n",
      "Epoch 00017: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0575 - acc: 0.9865 - val_loss: 1.4921 - val_acc: 0.7307\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9894\n",
      "Epoch 00018: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0508 - acc: 0.9894 - val_loss: 1.4743 - val_acc: 0.7417\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9920\n",
      "Epoch 00019: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0405 - acc: 0.9920 - val_loss: 1.4424 - val_acc: 0.7417\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9905\n",
      "Epoch 00020: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0421 - acc: 0.9905 - val_loss: 1.5492 - val_acc: 0.7345\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9921\n",
      "Epoch 00021: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0396 - acc: 0.9921 - val_loss: 1.4802 - val_acc: 0.7503\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9929\n",
      "Epoch 00022: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0378 - acc: 0.9929 - val_loss: 1.6207 - val_acc: 0.7363\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9915\n",
      "Epoch 00023: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0397 - acc: 0.9915 - val_loss: 1.6308 - val_acc: 0.7358\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9934\n",
      "Epoch 00024: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0337 - acc: 0.9934 - val_loss: 1.5659 - val_acc: 0.7529\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9942\n",
      "Epoch 00025: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0311 - acc: 0.9942 - val_loss: 1.7478 - val_acc: 0.7195\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9914\n",
      "Epoch 00026: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0388 - acc: 0.9914 - val_loss: 1.6563 - val_acc: 0.7438\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9955\n",
      "Epoch 00027: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0257 - acc: 0.9955 - val_loss: 1.5991 - val_acc: 0.7461\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9918\n",
      "Epoch 00028: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0367 - acc: 0.9918 - val_loss: 1.7396 - val_acc: 0.7340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 00029: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0391 - acc: 0.9917 - val_loss: 1.6344 - val_acc: 0.7505\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9961\n",
      "Epoch 00030: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0239 - acc: 0.9961 - val_loss: 1.7181 - val_acc: 0.7338\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9930\n",
      "Epoch 00031: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0336 - acc: 0.9930 - val_loss: 1.6508 - val_acc: 0.7473\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9948\n",
      "Epoch 00032: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0258 - acc: 0.9948 - val_loss: 1.7035 - val_acc: 0.7494\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9949\n",
      "Epoch 00033: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0281 - acc: 0.9949 - val_loss: 1.7506 - val_acc: 0.7268\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9923\n",
      "Epoch 00034: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0335 - acc: 0.9923 - val_loss: 1.7102 - val_acc: 0.7449\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9952\n",
      "Epoch 00035: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0249 - acc: 0.9952 - val_loss: 1.7626 - val_acc: 0.7428\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9955\n",
      "Epoch 00036: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0243 - acc: 0.9955 - val_loss: 1.7338 - val_acc: 0.7508\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9958\n",
      "Epoch 00037: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0241 - acc: 0.9958 - val_loss: 1.7515 - val_acc: 0.7449\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9958\n",
      "Epoch 00038: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0233 - acc: 0.9958 - val_loss: 1.9696 - val_acc: 0.7137\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9956\n",
      "Epoch 00039: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0237 - acc: 0.9956 - val_loss: 1.7947 - val_acc: 0.7512\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9958\n",
      "Epoch 00040: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0231 - acc: 0.9958 - val_loss: 1.9199 - val_acc: 0.7275\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9957\n",
      "Epoch 00041: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0237 - acc: 0.9957 - val_loss: 1.9019 - val_acc: 0.7268\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9936\n",
      "Epoch 00042: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0301 - acc: 0.9936 - val_loss: 1.8090 - val_acc: 0.7463\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9968\n",
      "Epoch 00043: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0213 - acc: 0.9968 - val_loss: 1.9242 - val_acc: 0.7412\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9956\n",
      "Epoch 00044: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0240 - acc: 0.9956 - val_loss: 1.8235 - val_acc: 0.7400\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9966\n",
      "Epoch 00045: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0204 - acc: 0.9966 - val_loss: 1.9193 - val_acc: 0.7419\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9957\n",
      "Epoch 00046: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0235 - acc: 0.9957 - val_loss: 1.8282 - val_acc: 0.7435\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9952\n",
      "Epoch 00047: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0236 - acc: 0.9952 - val_loss: 1.9529 - val_acc: 0.7389\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9963\n",
      "Epoch 00048: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0206 - acc: 0.9963 - val_loss: 1.8859 - val_acc: 0.7456\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9973\n",
      "Epoch 00049: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0181 - acc: 0.9973 - val_loss: 2.0429 - val_acc: 0.7230\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9936\n",
      "Epoch 00050: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0337 - acc: 0.9936 - val_loss: 1.8813 - val_acc: 0.7449\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9970\n",
      "Epoch 00051: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0195 - acc: 0.9970 - val_loss: 1.8981 - val_acc: 0.7407\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9970\n",
      "Epoch 00052: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0195 - acc: 0.9970 - val_loss: 1.8677 - val_acc: 0.7468\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9950\n",
      "Epoch 00053: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0253 - acc: 0.9950 - val_loss: 1.9508 - val_acc: 0.7384\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9965\n",
      "Epoch 00054: val_loss did not improve from 0.88377\n",
      "36805/36805 [==============================] - 141s 4ms/sample - loss: 0.0204 - acc: 0.9965 - val_loss: 1.8742 - val_acc: 0.7538\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 797us/sample - loss: 0.9282 - acc: 0.7259\n",
      "Loss: 0.9281952437953415 Accuracy: 0.7258567\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8914 - acc: 0.3868\n",
      "Epoch 00001: val_loss improved from inf to 1.38199, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_3_conv_checkpoint/001-1.3820.hdf5\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 1.8913 - acc: 0.3868 - val_loss: 1.3820 - val_acc: 0.5609\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2320 - acc: 0.6216\n",
      "Epoch 00002: val_loss improved from 1.38199 to 1.04554, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_3_conv_checkpoint/002-1.0455.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 1.2321 - acc: 0.6216 - val_loss: 1.0455 - val_acc: 0.6741\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9648 - acc: 0.7075\n",
      "Epoch 00003: val_loss improved from 1.04554 to 0.86451, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_3_conv_checkpoint/003-0.8645.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.9647 - acc: 0.7075 - val_loss: 0.8645 - val_acc: 0.7368\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7909 - acc: 0.7664\n",
      "Epoch 00004: val_loss improved from 0.86451 to 0.80523, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_3_conv_checkpoint/004-0.8052.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.7908 - acc: 0.7665 - val_loss: 0.8052 - val_acc: 0.7682\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6746 - acc: 0.8025\n",
      "Epoch 00005: val_loss improved from 0.80523 to 0.69435, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_3_conv_checkpoint/005-0.6944.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.6745 - acc: 0.8026 - val_loss: 0.6944 - val_acc: 0.7945\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5795 - acc: 0.8275\n",
      "Epoch 00006: val_loss improved from 0.69435 to 0.65510, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_3_conv_checkpoint/006-0.6551.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.5795 - acc: 0.8275 - val_loss: 0.6551 - val_acc: 0.8109\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4882 - acc: 0.8560\n",
      "Epoch 00007: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.4883 - acc: 0.8559 - val_loss: 0.6703 - val_acc: 0.8141\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4283 - acc: 0.8732\n",
      "Epoch 00008: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.4284 - acc: 0.8732 - val_loss: 0.6600 - val_acc: 0.8155\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3513 - acc: 0.8958\n",
      "Epoch 00009: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.3513 - acc: 0.8959 - val_loss: 0.6653 - val_acc: 0.8155\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2917 - acc: 0.9128\n",
      "Epoch 00010: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.2917 - acc: 0.9128 - val_loss: 0.7377 - val_acc: 0.7987\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2367 - acc: 0.9310\n",
      "Epoch 00011: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2367 - acc: 0.9309 - val_loss: 0.7502 - val_acc: 0.8102\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1970 - acc: 0.9427\n",
      "Epoch 00012: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1970 - acc: 0.9428 - val_loss: 0.7476 - val_acc: 0.8237\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1650 - acc: 0.9533\n",
      "Epoch 00013: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.1650 - acc: 0.9533 - val_loss: 0.8018 - val_acc: 0.8171\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1347 - acc: 0.9610\n",
      "Epoch 00014: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1347 - acc: 0.9610 - val_loss: 0.8447 - val_acc: 0.8060\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9653\n",
      "Epoch 00015: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.1229 - acc: 0.9653 - val_loss: 0.8403 - val_acc: 0.8174\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9717\n",
      "Epoch 00016: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0986 - acc: 0.9717 - val_loss: 0.9246 - val_acc: 0.8004\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9737\n",
      "Epoch 00017: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0916 - acc: 0.9737 - val_loss: 0.9515 - val_acc: 0.8116\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9750\n",
      "Epoch 00018: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0902 - acc: 0.9750 - val_loss: 0.9562 - val_acc: 0.8137\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9782\n",
      "Epoch 00019: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0763 - acc: 0.9782 - val_loss: 0.9619 - val_acc: 0.8223\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9813\n",
      "Epoch 00020: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0678 - acc: 0.9813 - val_loss: 0.9622 - val_acc: 0.8181\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9837\n",
      "Epoch 00021: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0608 - acc: 0.9838 - val_loss: 0.9837 - val_acc: 0.8157\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9840\n",
      "Epoch 00022: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0594 - acc: 0.9840 - val_loss: 0.9924 - val_acc: 0.8211\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9794\n",
      "Epoch 00023: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0742 - acc: 0.9794 - val_loss: 1.0441 - val_acc: 0.7987\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9850\n",
      "Epoch 00024: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0563 - acc: 0.9850 - val_loss: 1.1179 - val_acc: 0.8109\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9862\n",
      "Epoch 00025: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0501 - acc: 0.9862 - val_loss: 1.0623 - val_acc: 0.8167\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9861\n",
      "Epoch 00026: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0510 - acc: 0.9861 - val_loss: 1.0316 - val_acc: 0.8176\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9868\n",
      "Epoch 00027: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0495 - acc: 0.9868 - val_loss: 1.1113 - val_acc: 0.8104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9850\n",
      "Epoch 00028: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0548 - acc: 0.9850 - val_loss: 1.1445 - val_acc: 0.8169\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9892\n",
      "Epoch 00029: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0419 - acc: 0.9892 - val_loss: 1.1364 - val_acc: 0.8106\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9892\n",
      "Epoch 00030: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0420 - acc: 0.9892 - val_loss: 1.1165 - val_acc: 0.8118\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9878\n",
      "Epoch 00031: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0450 - acc: 0.9878 - val_loss: 1.0980 - val_acc: 0.8225\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9886\n",
      "Epoch 00032: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0433 - acc: 0.9886 - val_loss: 1.0671 - val_acc: 0.8171\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9870\n",
      "Epoch 00033: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0471 - acc: 0.9870 - val_loss: 1.2395 - val_acc: 0.8116\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9904\n",
      "Epoch 00034: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0397 - acc: 0.9904 - val_loss: 1.1411 - val_acc: 0.8181\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9911\n",
      "Epoch 00035: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0370 - acc: 0.9911 - val_loss: 1.2228 - val_acc: 0.8109\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9894\n",
      "Epoch 00036: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0400 - acc: 0.9894 - val_loss: 1.1559 - val_acc: 0.8160\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9898\n",
      "Epoch 00037: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0410 - acc: 0.9898 - val_loss: 1.1750 - val_acc: 0.8132\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9896\n",
      "Epoch 00038: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0401 - acc: 0.9896 - val_loss: 1.1934 - val_acc: 0.8143\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9905\n",
      "Epoch 00039: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0383 - acc: 0.9904 - val_loss: 1.2349 - val_acc: 0.8097\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9889\n",
      "Epoch 00040: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0422 - acc: 0.9889 - val_loss: 1.2198 - val_acc: 0.8088\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9932\n",
      "Epoch 00041: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0291 - acc: 0.9932 - val_loss: 1.1272 - val_acc: 0.8290\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9924\n",
      "Epoch 00042: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0319 - acc: 0.9924 - val_loss: 1.1247 - val_acc: 0.8227\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9910\n",
      "Epoch 00043: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0354 - acc: 0.9909 - val_loss: 1.2150 - val_acc: 0.8153\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9898\n",
      "Epoch 00044: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0423 - acc: 0.9898 - val_loss: 1.1116 - val_acc: 0.8281\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9927\n",
      "Epoch 00045: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0310 - acc: 0.9927 - val_loss: 1.1828 - val_acc: 0.8279\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9940\n",
      "Epoch 00046: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0270 - acc: 0.9940 - val_loss: 1.2250 - val_acc: 0.8267\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9921\n",
      "Epoch 00047: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0328 - acc: 0.9921 - val_loss: 1.2099 - val_acc: 0.8253\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9922\n",
      "Epoch 00048: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0328 - acc: 0.9922 - val_loss: 1.2461 - val_acc: 0.8206\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9923\n",
      "Epoch 00049: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0309 - acc: 0.9923 - val_loss: 1.2614 - val_acc: 0.8272\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9919\n",
      "Epoch 00050: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0329 - acc: 0.9919 - val_loss: 1.2960 - val_acc: 0.8160\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9948\n",
      "Epoch 00051: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0240 - acc: 0.9948 - val_loss: 1.2916 - val_acc: 0.8106\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9910\n",
      "Epoch 00052: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0362 - acc: 0.9910 - val_loss: 1.2737 - val_acc: 0.8111\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9927\n",
      "Epoch 00053: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0317 - acc: 0.9927 - val_loss: 1.2400 - val_acc: 0.8230\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9934\n",
      "Epoch 00054: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0277 - acc: 0.9934 - val_loss: 1.2585 - val_acc: 0.8295\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9937\n",
      "Epoch 00055: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0281 - acc: 0.9937 - val_loss: 1.1705 - val_acc: 0.8258\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9924\n",
      "Epoch 00056: val_loss did not improve from 0.65510\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0308 - acc: 0.9924 - val_loss: 1.3139 - val_acc: 0.8078\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 873us/sample - loss: 0.7212 - acc: 0.7886\n",
      "Loss: 0.7212270665267794 Accuracy: 0.7885774\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9806 - acc: 0.3486\n",
      "Epoch 00001: val_loss improved from inf to 1.46296, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/001-1.4630.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 1.9805 - acc: 0.3486 - val_loss: 1.4630 - val_acc: 0.5295\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3543 - acc: 0.5693\n",
      "Epoch 00002: val_loss improved from 1.46296 to 1.18832, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/002-1.1883.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 1.3543 - acc: 0.5694 - val_loss: 1.1883 - val_acc: 0.6278\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0980 - acc: 0.6571\n",
      "Epoch 00003: val_loss improved from 1.18832 to 0.94940, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/003-0.9494.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 1.0980 - acc: 0.6571 - val_loss: 0.9494 - val_acc: 0.7088\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8703 - acc: 0.7397\n",
      "Epoch 00004: val_loss improved from 0.94940 to 0.83015, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/004-0.8302.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.8703 - acc: 0.7397 - val_loss: 0.8302 - val_acc: 0.7584\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7198 - acc: 0.7898\n",
      "Epoch 00005: val_loss improved from 0.83015 to 0.69140, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/005-0.6914.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.7198 - acc: 0.7897 - val_loss: 0.6914 - val_acc: 0.8062\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6072 - acc: 0.8232\n",
      "Epoch 00006: val_loss improved from 0.69140 to 0.66428, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/006-0.6643.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.6073 - acc: 0.8232 - val_loss: 0.6643 - val_acc: 0.8239\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5340 - acc: 0.8436\n",
      "Epoch 00007: val_loss improved from 0.66428 to 0.55408, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/007-0.5541.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.5340 - acc: 0.8436 - val_loss: 0.5541 - val_acc: 0.8430\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4606 - acc: 0.8671\n",
      "Epoch 00008: val_loss improved from 0.55408 to 0.51459, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/008-0.5146.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.4605 - acc: 0.8671 - val_loss: 0.5146 - val_acc: 0.8612\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4176 - acc: 0.8764\n",
      "Epoch 00009: val_loss improved from 0.51459 to 0.49397, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/009-0.4940.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.4176 - acc: 0.8764 - val_loss: 0.4940 - val_acc: 0.8628\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3776 - acc: 0.8890\n",
      "Epoch 00010: val_loss improved from 0.49397 to 0.49036, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/010-0.4904.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3776 - acc: 0.8890 - val_loss: 0.4904 - val_acc: 0.8724\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3427 - acc: 0.8976\n",
      "Epoch 00011: val_loss improved from 0.49036 to 0.48513, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/011-0.4851.hdf5\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.3428 - acc: 0.8975 - val_loss: 0.4851 - val_acc: 0.8714\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3169 - acc: 0.9043\n",
      "Epoch 00012: val_loss improved from 0.48513 to 0.47658, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/012-0.4766.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3169 - acc: 0.9043 - val_loss: 0.4766 - val_acc: 0.8719\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2901 - acc: 0.9122\n",
      "Epoch 00013: val_loss improved from 0.47658 to 0.46810, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_4_conv_checkpoint/013-0.4681.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2901 - acc: 0.9122 - val_loss: 0.4681 - val_acc: 0.8817\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2574 - acc: 0.9206\n",
      "Epoch 00014: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2574 - acc: 0.9206 - val_loss: 0.5257 - val_acc: 0.8705\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2389 - acc: 0.9268\n",
      "Epoch 00015: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.2389 - acc: 0.9268 - val_loss: 0.4903 - val_acc: 0.8689\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2187 - acc: 0.9332\n",
      "Epoch 00016: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2187 - acc: 0.9332 - val_loss: 0.5357 - val_acc: 0.8614\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2000 - acc: 0.9377\n",
      "Epoch 00017: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1999 - acc: 0.9377 - val_loss: 0.5044 - val_acc: 0.8789\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1798 - acc: 0.9451\n",
      "Epoch 00018: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1798 - acc: 0.9451 - val_loss: 0.5258 - val_acc: 0.8733\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1777 - acc: 0.9436\n",
      "Epoch 00019: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.1777 - acc: 0.9435 - val_loss: 0.5128 - val_acc: 0.8784\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9500\n",
      "Epoch 00020: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.1620 - acc: 0.9500 - val_loss: 0.5294 - val_acc: 0.8705\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9524\n",
      "Epoch 00021: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.1516 - acc: 0.9524 - val_loss: 0.5117 - val_acc: 0.8868\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9585\n",
      "Epoch 00022: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1349 - acc: 0.9585 - val_loss: 0.5278 - val_acc: 0.8800\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9585\n",
      "Epoch 00023: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.1333 - acc: 0.9585 - val_loss: 0.5451 - val_acc: 0.8842\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9638\n",
      "Epoch 00024: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1180 - acc: 0.9638 - val_loss: 0.6092 - val_acc: 0.8751\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9641\n",
      "Epoch 00025: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.1160 - acc: 0.9641 - val_loss: 0.5563 - val_acc: 0.8840\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9667\n",
      "Epoch 00026: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.1069 - acc: 0.9667 - val_loss: 0.6016 - val_acc: 0.8721\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9667\n",
      "Epoch 00027: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.1072 - acc: 0.9667 - val_loss: 0.6059 - val_acc: 0.8705\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9692\n",
      "Epoch 00028: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0978 - acc: 0.9692 - val_loss: 0.5862 - val_acc: 0.8791\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9694\n",
      "Epoch 00029: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0971 - acc: 0.9694 - val_loss: 0.6169 - val_acc: 0.8786\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9722\n",
      "Epoch 00030: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0932 - acc: 0.9722 - val_loss: 0.5906 - val_acc: 0.8845\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9765\n",
      "Epoch 00031: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0759 - acc: 0.9765 - val_loss: 0.6213 - val_acc: 0.8882\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9705\n",
      "Epoch 00032: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0975 - acc: 0.9704 - val_loss: 0.6901 - val_acc: 0.8696\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9729\n",
      "Epoch 00033: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0888 - acc: 0.9729 - val_loss: 0.6394 - val_acc: 0.8807\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9757\n",
      "Epoch 00034: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0782 - acc: 0.9757 - val_loss: 0.6566 - val_acc: 0.8758\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9792\n",
      "Epoch 00035: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0668 - acc: 0.9792 - val_loss: 0.6139 - val_acc: 0.8791\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9800\n",
      "Epoch 00036: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0680 - acc: 0.9800 - val_loss: 0.6624 - val_acc: 0.8821\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9772\n",
      "Epoch 00037: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0732 - acc: 0.9772 - val_loss: 0.6363 - val_acc: 0.8803\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9803\n",
      "Epoch 00038: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0647 - acc: 0.9803 - val_loss: 0.6412 - val_acc: 0.8875\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9807\n",
      "Epoch 00039: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0638 - acc: 0.9807 - val_loss: 0.6805 - val_acc: 0.8651\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9801\n",
      "Epoch 00040: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0643 - acc: 0.9801 - val_loss: 0.6755 - val_acc: 0.8786\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9823\n",
      "Epoch 00041: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0590 - acc: 0.9823 - val_loss: 0.6905 - val_acc: 0.8800\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9820\n",
      "Epoch 00042: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0615 - acc: 0.9820 - val_loss: 0.7184 - val_acc: 0.8784\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9827\n",
      "Epoch 00043: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0576 - acc: 0.9827 - val_loss: 0.6730 - val_acc: 0.8789\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9833\n",
      "Epoch 00044: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0551 - acc: 0.9833 - val_loss: 0.7120 - val_acc: 0.8810\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9827\n",
      "Epoch 00045: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0596 - acc: 0.9827 - val_loss: 0.7095 - val_acc: 0.8724\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9858\n",
      "Epoch 00046: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0487 - acc: 0.9858 - val_loss: 0.7123 - val_acc: 0.8784\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9837\n",
      "Epoch 00047: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0554 - acc: 0.9837 - val_loss: 0.7309 - val_acc: 0.8775\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9848\n",
      "Epoch 00048: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0520 - acc: 0.9848 - val_loss: 0.7459 - val_acc: 0.8768\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9839\n",
      "Epoch 00049: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0545 - acc: 0.9839 - val_loss: 0.7472 - val_acc: 0.8700\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9862\n",
      "Epoch 00050: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0470 - acc: 0.9862 - val_loss: 0.7417 - val_acc: 0.8786\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9875\n",
      "Epoch 00051: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0439 - acc: 0.9875 - val_loss: 0.7242 - val_acc: 0.8805\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9841\n",
      "Epoch 00052: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0527 - acc: 0.9841 - val_loss: 0.7201 - val_acc: 0.8775\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9864\n",
      "Epoch 00053: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0460 - acc: 0.9864 - val_loss: 0.7409 - val_acc: 0.8821\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9866\n",
      "Epoch 00054: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0477 - acc: 0.9866 - val_loss: 0.7482 - val_acc: 0.8849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9858\n",
      "Epoch 00055: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0487 - acc: 0.9858 - val_loss: 0.7225 - val_acc: 0.8803\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9867\n",
      "Epoch 00056: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0450 - acc: 0.9867 - val_loss: 0.7652 - val_acc: 0.8758\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9895\n",
      "Epoch 00057: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0381 - acc: 0.9895 - val_loss: 0.7834 - val_acc: 0.8765\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9882\n",
      "Epoch 00058: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0411 - acc: 0.9882 - val_loss: 0.7681 - val_acc: 0.8826\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9869\n",
      "Epoch 00059: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0468 - acc: 0.9869 - val_loss: 0.7229 - val_acc: 0.8833\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9874\n",
      "Epoch 00060: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0412 - acc: 0.9874 - val_loss: 0.8388 - val_acc: 0.8691\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9854\n",
      "Epoch 00061: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0557 - acc: 0.9854 - val_loss: 0.7872 - val_acc: 0.8703\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9890\n",
      "Epoch 00062: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0401 - acc: 0.9890 - val_loss: 0.7444 - val_acc: 0.8814\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9875\n",
      "Epoch 00063: val_loss did not improve from 0.46810\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0428 - acc: 0.9875 - val_loss: 0.7304 - val_acc: 0.8859\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 925us/sample - loss: 0.5719 - acc: 0.8482\n",
      "Loss: 0.571932884280184 Accuracy: 0.84818274\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0394 - acc: 0.3353\n",
      "Epoch 00001: val_loss improved from inf to 1.61896, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/001-1.6190.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 2.0394 - acc: 0.3353 - val_loss: 1.6190 - val_acc: 0.4673\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4022 - acc: 0.5460\n",
      "Epoch 00002: val_loss improved from 1.61896 to 1.18917, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/002-1.1892.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 1.4022 - acc: 0.5460 - val_loss: 1.1892 - val_acc: 0.6352\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1331 - acc: 0.6406\n",
      "Epoch 00003: val_loss improved from 1.18917 to 0.93734, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/003-0.9373.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 1.1329 - acc: 0.6406 - val_loss: 0.9373 - val_acc: 0.7135\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8919 - acc: 0.7272\n",
      "Epoch 00004: val_loss improved from 0.93734 to 0.83490, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/004-0.8349.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.8919 - acc: 0.7272 - val_loss: 0.8349 - val_acc: 0.7554\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7374 - acc: 0.7778\n",
      "Epoch 00005: val_loss improved from 0.83490 to 0.68845, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/005-0.6885.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.7375 - acc: 0.7778 - val_loss: 0.6885 - val_acc: 0.8062\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6221 - acc: 0.8135\n",
      "Epoch 00006: val_loss improved from 0.68845 to 0.57226, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/006-0.5723.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.6221 - acc: 0.8135 - val_loss: 0.5723 - val_acc: 0.8435\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5334 - acc: 0.8415\n",
      "Epoch 00007: val_loss improved from 0.57226 to 0.52618, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/007-0.5262.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.5333 - acc: 0.8415 - val_loss: 0.5262 - val_acc: 0.8591\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4639 - acc: 0.8592\n",
      "Epoch 00008: val_loss improved from 0.52618 to 0.48670, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/008-0.4867.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.4638 - acc: 0.8592 - val_loss: 0.4867 - val_acc: 0.8730\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4152 - acc: 0.8730\n",
      "Epoch 00009: val_loss improved from 0.48670 to 0.46575, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/009-0.4658.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.4152 - acc: 0.8730 - val_loss: 0.4658 - val_acc: 0.8661\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3696 - acc: 0.8869\n",
      "Epoch 00010: val_loss improved from 0.46575 to 0.46338, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/010-0.4634.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.3696 - acc: 0.8869 - val_loss: 0.4634 - val_acc: 0.8863\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3354 - acc: 0.8974\n",
      "Epoch 00011: val_loss improved from 0.46338 to 0.44060, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/011-0.4406.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.3355 - acc: 0.8974 - val_loss: 0.4406 - val_acc: 0.8796\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3099 - acc: 0.9055\n",
      "Epoch 00012: val_loss improved from 0.44060 to 0.40725, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/012-0.4073.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.3100 - acc: 0.9054 - val_loss: 0.4073 - val_acc: 0.8947\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2870 - acc: 0.9112\n",
      "Epoch 00013: val_loss did not improve from 0.40725\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2869 - acc: 0.9112 - val_loss: 0.4390 - val_acc: 0.8870\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2614 - acc: 0.9188\n",
      "Epoch 00014: val_loss did not improve from 0.40725\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.2613 - acc: 0.9188 - val_loss: 0.4404 - val_acc: 0.8824\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2335 - acc: 0.9267\n",
      "Epoch 00015: val_loss improved from 0.40725 to 0.39847, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_5_conv_checkpoint/015-0.3985.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2335 - acc: 0.9267 - val_loss: 0.3985 - val_acc: 0.9010\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2243 - acc: 0.9286\n",
      "Epoch 00016: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2243 - acc: 0.9286 - val_loss: 0.4444 - val_acc: 0.8861\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2033 - acc: 0.9342\n",
      "Epoch 00017: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2033 - acc: 0.9342 - val_loss: 0.4196 - val_acc: 0.8945\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9402\n",
      "Epoch 00018: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1853 - acc: 0.9402 - val_loss: 0.4015 - val_acc: 0.9026\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1774 - acc: 0.9426\n",
      "Epoch 00019: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1775 - acc: 0.9426 - val_loss: 0.4625 - val_acc: 0.8859\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9446\n",
      "Epoch 00020: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1713 - acc: 0.9446 - val_loss: 0.4031 - val_acc: 0.9031\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9489\n",
      "Epoch 00021: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1578 - acc: 0.9488 - val_loss: 0.4717 - val_acc: 0.8935\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9534\n",
      "Epoch 00022: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1437 - acc: 0.9534 - val_loss: 0.4471 - val_acc: 0.8973\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9543\n",
      "Epoch 00023: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1423 - acc: 0.9543 - val_loss: 0.4829 - val_acc: 0.9031\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9576\n",
      "Epoch 00024: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1303 - acc: 0.9576 - val_loss: 0.4297 - val_acc: 0.9010\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9631\n",
      "Epoch 00025: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1152 - acc: 0.9631 - val_loss: 0.5117 - val_acc: 0.8933\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9639\n",
      "Epoch 00026: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1128 - acc: 0.9639 - val_loss: 0.4397 - val_acc: 0.9012\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9655\n",
      "Epoch 00027: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1069 - acc: 0.9655 - val_loss: 0.4656 - val_acc: 0.9047\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9656\n",
      "Epoch 00028: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1060 - acc: 0.9656 - val_loss: 0.4602 - val_acc: 0.9061\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9668\n",
      "Epoch 00029: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1006 - acc: 0.9669 - val_loss: 0.4635 - val_acc: 0.9043\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9686\n",
      "Epoch 00030: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0972 - acc: 0.9685 - val_loss: 0.4668 - val_acc: 0.9052\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9689\n",
      "Epoch 00031: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0958 - acc: 0.9689 - val_loss: 0.4643 - val_acc: 0.9068\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9726\n",
      "Epoch 00032: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0851 - acc: 0.9726 - val_loss: 0.4514 - val_acc: 0.9045\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9721\n",
      "Epoch 00033: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0862 - acc: 0.9722 - val_loss: 0.4845 - val_acc: 0.9038\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9738\n",
      "Epoch 00034: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0813 - acc: 0.9738 - val_loss: 0.4840 - val_acc: 0.9064\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9759\n",
      "Epoch 00035: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0757 - acc: 0.9759 - val_loss: 0.5122 - val_acc: 0.9050\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9749\n",
      "Epoch 00036: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0781 - acc: 0.9749 - val_loss: 0.4862 - val_acc: 0.9119\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9778\n",
      "Epoch 00037: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0682 - acc: 0.9778 - val_loss: 0.5195 - val_acc: 0.9073\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9770\n",
      "Epoch 00038: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0724 - acc: 0.9770 - val_loss: 0.5174 - val_acc: 0.9036\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9768\n",
      "Epoch 00039: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0720 - acc: 0.9768 - val_loss: 0.4789 - val_acc: 0.9073\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9786\n",
      "Epoch 00040: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0664 - acc: 0.9786 - val_loss: 0.5248 - val_acc: 0.9071\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9779\n",
      "Epoch 00041: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0662 - acc: 0.9779 - val_loss: 0.5288 - val_acc: 0.9045\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9786\n",
      "Epoch 00042: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0658 - acc: 0.9786 - val_loss: 0.5159 - val_acc: 0.9089\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9818\n",
      "Epoch 00043: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0576 - acc: 0.9818 - val_loss: 0.5210 - val_acc: 0.9115\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9827\n",
      "Epoch 00044: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0566 - acc: 0.9827 - val_loss: 0.5295 - val_acc: 0.9096\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9807\n",
      "Epoch 00045: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0614 - acc: 0.9807 - val_loss: 0.5373 - val_acc: 0.9087\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9807\n",
      "Epoch 00046: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0592 - acc: 0.9807 - val_loss: 0.5399 - val_acc: 0.9024\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9823\n",
      "Epoch 00047: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0558 - acc: 0.9822 - val_loss: 0.5530 - val_acc: 0.9054\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9793\n",
      "Epoch 00048: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0684 - acc: 0.9793 - val_loss: 0.5274 - val_acc: 0.9119\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9833\n",
      "Epoch 00049: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0538 - acc: 0.9833 - val_loss: 0.5067 - val_acc: 0.9157\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9837\n",
      "Epoch 00050: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0513 - acc: 0.9837 - val_loss: 0.5320 - val_acc: 0.9068\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9822\n",
      "Epoch 00051: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0558 - acc: 0.9822 - val_loss: 0.5247 - val_acc: 0.9110\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9845\n",
      "Epoch 00052: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0479 - acc: 0.9845 - val_loss: 0.5451 - val_acc: 0.9094\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9857\n",
      "Epoch 00053: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0465 - acc: 0.9857 - val_loss: 0.5907 - val_acc: 0.9096\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9830\n",
      "Epoch 00054: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0525 - acc: 0.9830 - val_loss: 0.5419 - val_acc: 0.9103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9827\n",
      "Epoch 00055: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0515 - acc: 0.9827 - val_loss: 0.5489 - val_acc: 0.9061\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9855\n",
      "Epoch 00056: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0459 - acc: 0.9855 - val_loss: 0.5469 - val_acc: 0.9082\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9861\n",
      "Epoch 00057: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0444 - acc: 0.9861 - val_loss: 0.5507 - val_acc: 0.9133\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9841\n",
      "Epoch 00058: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0515 - acc: 0.9841 - val_loss: 0.5627 - val_acc: 0.9119\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9861\n",
      "Epoch 00059: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0457 - acc: 0.9861 - val_loss: 0.5697 - val_acc: 0.9036\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9855\n",
      "Epoch 00060: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0469 - acc: 0.9855 - val_loss: 0.6064 - val_acc: 0.9038\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9866\n",
      "Epoch 00061: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0443 - acc: 0.9866 - val_loss: 0.5302 - val_acc: 0.9133\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9881\n",
      "Epoch 00062: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0400 - acc: 0.9881 - val_loss: 0.5727 - val_acc: 0.9047\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9850\n",
      "Epoch 00063: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0483 - acc: 0.9850 - val_loss: 0.5304 - val_acc: 0.9043\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9878\n",
      "Epoch 00064: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0393 - acc: 0.9878 - val_loss: 0.5948 - val_acc: 0.9082\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9889\n",
      "Epoch 00065: val_loss did not improve from 0.39847\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0388 - acc: 0.9889 - val_loss: 0.5416 - val_acc: 0.9096\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl4VNX5wPHvmSWTPWRhJxBQZIewSoui1moRFa2KuC91qa3aWlsqtdXyq61brXWp1qLFrSpal4oVRduCaAvKIpuCspNAyJ6QdTLL+/vjzGSBJISQISF5P89zn8nc9Z1Jct57zzn3XCMiKKWUUofiaO8AlFJKHRs0YSillGoRTRhKKaVaRBOGUkqpFtGEoZRSqkU0YSillGoRTRhKKaVaRBOGUkqpFtGEoZRSqkVc7R1AW0pLS5OMjIz2DkMppY4Zq1evLhCR7i1Zt1MljIyMDFatWtXeYSil1DHDGLOrpetqlZRSSqkW0YShlFKqRTRhKKWUapFO1YbRGJ/PR3Z2NtXV1e0dyjEpOjqafv364Xa72zsUpVQ76/QJIzs7m4SEBDIyMjDGtHc4xxQRobCwkOzsbAYOHNje4Sil2lmnr5Kqrq4mNTVVk0UrGGNITU3VqzOlFNAFEgagyeII6HenlArrEgmjOSKC17sXv7+0vUNRSqkOLWIJwxiTboxZYoz50hjzhTHmx42sY4wxjxljthpj1htjxtVbdrUxZktoujqCcVJTkxuxhFFSUsKTTz7Zqm2nT59OSUlJi9efO3cuDz30UKuOpZRShxLJKww/8FMRGQ5MBm42xgw/YJ2zgMGh6UbgzwDGmBTg18CJwCTg18aY5EgFaowLEX9E9t1cwvD7mz/mokWL6NatWyTCUkqpwxaxhCEiOSKyJvRzGbAJ6HvAaucBL4i1AuhmjOkNfAf4UESKRKQY+BCYFqlYjXFGLGHMmTOHbdu2kZmZyezZs1m6dCknn3wyM2bMYPhwmz/PP/98xo8fz4gRI5g3b17tthkZGRQUFLBz506GDRvGDTfcwIgRIzjzzDOpqqpq9rhr165l8uTJjB49mu9+97sUFxcD8NhjjzF8+HBGjx7NJZdcAsBHH31EZmYmmZmZjB07lrKysoh8F0qpY9tR6VZrjMkAxgKfHrCoL5BV7312aF5T84/Ili23UV6+9qD5wWAVIDgcsYe9z/j4TAYPfqTJ5ffffz8bN25k7Vp73KVLl7JmzRo2btxY21V1/vz5pKSkUFVVxcSJE7nwwgtJTU09IPYtvPLKKzz99NNcfPHFvPHGG1xxxRVNHveqq67i8ccf55RTTuHuu+/m//7v/3jkkUe4//772bFjBx6Pp7a666GHHuKJJ55gypQplJeXEx0dfdjfg1Kq84t4o7cxJh54A7hNRPZHYP83GmNWGWNW5efnt3YviEibxtWcSZMmNbiv4bHHHmPMmDFMnjyZrKwstmzZctA2AwcOJDMzE4Dx48ezc+fOJvdfWlpKSUkJp5xyCgBXX301y5YtA2D06NFcfvnl/O1vf8PlsucLU6ZM4fbbb+exxx6jpKSkdr5SStUX0ZLBGOPGJouXROTNRlbZA6TXe98vNG8PcOoB85c2dgwRmQfMA5gwYUKzpX5TVwLV1bvx+QpJSBjb3OZtJi4urvbnpUuX8q9//Yvly5cTGxvLqaee2uh9Dx6Pp/Znp9N5yCqpprz77rssW7aMd955h9/97nds2LCBOXPmcPbZZ7No0SKmTJnC4sWLGTp0aKv2r5TqvCLZS8oAfwU2icjDTay2ELgq1FtqMlAqIjnAYuBMY0xyqLH7zNC8CMXqAgKIBNt83wkJCc22CZSWlpKcnExsbCybN29mxYoVR3zMpKQkkpOT+fjjjwF48cUXOeWUUwgGg2RlZXHaaafxwAMPUFpaSnl5Odu2bWPUqFHccccdTJw4kc2bNx9xDEqpzieSVxhTgCuBDcaYcMPBnUB/ABF5ClgETAe2ApXAtaFlRcaYe4CVoe1+IyJFkQrUJgwQCWBM2+bQ1NRUpkyZwsiRIznrrLM4++yzGyyfNm0aTz31FMOGDWPIkCFMnjy5TY77/PPPc9NNN1FZWcmgQYN49tlnCQQCXHHFFZSWliIi/OhHP6Jbt27cddddLFmyBIfDwYgRIzjrrLPaJAalVOdijmbdfaRNmDBBDnyA0qZNmxg2bFiz2/l8RVRXbyc2dgROZ0wkQzwmteQ7VEodm4wxq0VkQkvW7fJ3ekP9K4zIdK1VSqnOQBMGmjCUUqolNGGgCUMppVpCEwb2Tm/QhKGUUs3RhEE4YTg0YSilVDM0YYREcgBCpZTqDDRhhHSkhBEfH39Y85VS6mjQhBESyRFrlVKqM9CEEWKvMAJtvt85c+bwxBNP1L4PP+SovLyc008/nXHjxjFq1CjefvvtFu9TRJg9ezYjR45k1KhRvPrqqwDk5OQwdepUMjMzGTlyJB9//DGBQIBrrrmmdt0//vGPbf4ZlVJdQ9calvS222DtwcObA3iC1QTFD87DrPbJzIRHmh7efNasWdx2223cfPPNALz22mssXryY6Oho3nrrLRITEykoKGDy5MnMmDGjRc/QfvPNN1m7di3r1q2joKCAiRMnMnXqVF5++WW+853v8Mtf/pJAIEBlZSVr165lz549bNy4EeCwnuCnlFL1da2E0SwDCBL6qa2MHTuWvLw89u7dS35+PsnJyaSnp+Pz+bjzzjtZtmwZDoeDPXv2kJubS69evQ65z08++YRLL70Up9NJz549OeWUU1i5ciUTJ07ke9/7Hj6fj/PPP5/MzEwGDRrE9u3bufXWWzn77LM588wz2/DTKaW6kq6VMJq5EvDX5OL1ZhEXl4lxtO3XMnPmTF5//XX27dvHrFmzAHjppZfIz89n9erVuN1uMjIyGh3W/HBMnTqVZcuW8e6773LNNddw++23c9VVV7Fu3ToWL17MU089xWuvvcb8+fPb4mMppboYbcMIieTd3rNmzWLBggW8/vrrzJw5E7DDmvfo0QO3282SJUvYtWtXi/d38skn8+qrrxIIBMjPz2fZsmVMmjSJXbt20bNnT2644Qauv/561qxZQ0FBAcFgkAsvvJDf/va3rFmzps0/n1Kqa+haVxjNiGTCGDFiBGVlZfTt25fevXsDcPnll3PuuecyatQoJkyYcFgPLPrud7/L8uXLGTNmDMYYHnzwQXr16sXzzz/P73//e9xuN/Hx8bzwwgvs2bOHa6+9lmDQPuvjvvvua/PPp5TqGnR485BAoILKyk1ERx+P290tUiEek3R4c6U6Lx3evBV0AEKllGpexKqkjDHzgXOAPBEZ2cjy2cDl9eIYBnQPPW1vJ1AGBAB/S7PfkcWrCUMppZoTySuM54BpTS0Ukd+LSKaIZAK/AD464DGsp4WWRzxZWA5sh1pNGEop1ZiIJQwRWQa09DnclwKvRCqWljDGdKjxpJRSqqNp9zYMY0ws9krkjXqzBfjAGLPaGHPj0YtFE4ZSSjWlI3SrPRf47wHVUSeJyB5jTA/gQ2PM5tAVy0FCCeVGgP79+x9RIDoAoVJKNa3drzCASzigOkpE9oRe84C3gElNbSwi80RkgohM6N69+xEFEokBCEtKSnjyySdbte306dN17CelVIfRrgnDGJMEnAK8XW9enDEmIfwzcCaw8ejE0/ZVUs0lDL+/+WMtWrSIbt30nhClVMcQsYRhjHkFWA4MMcZkG2OuM8bcZIy5qd5q3wU+EJGKevN6Ap8YY9YBnwHvisj7kYqzYcw2YbTlzYxz5sxh27ZtZGZmMnv2bJYuXcrJJ5/MjBkzGD58OADnn38+48ePZ8SIEcybN69224yMDAoKCti5cyfDhg3jhhtuYMSIEZx55plUVVUddKx33nmHE088kbFjx/Ltb3+b3NxcAMrLy7n22msZNWoUo0eP5o03bHPR+++/z7hx4xgzZgynn356m31mpVTn1KXu9G5mdHMARGoIBr04nfG0dMzaQ4xuzs6dOznnnHNqhxdfunQpZ599Nhs3bmTgwIEAFBUVkZKSQlVVFRMnTuSjjz4iNTWVjIwMVq1aRXl5OccffzyrVq0iMzOTiy++mBkzZnDFFVc0OFZxcTHdunXDGMMzzzzDpk2b+MMf/sAdd9yB1+vlkVCgxcXF+P1+xo0bx7Jlyxg4cGBtDI3RO72V6rwO507vjtDo3YGEk0RbD3Le0KRJk2qTBcBjjz3GW2+9BUBWVhZbtmwhNTW1wTYDBw4kMzMTgPHjx7Nz586D9pudnc2sWbPIycmhpqam9hj/+te/WLBgQe16ycnJvPPOO0ydOrV2naaShVJKhXWphNHclQCAz1dBdfVWYmOH4XTGRSyOuLi6fS9dupR//etfLF++nNjYWE499dRGhzn3eDy1PzudzkarpG699VZuv/12ZsyYwdKlS5k7d25E4ldKdU0doZdUhxGJ4UESEhIoKytrcnlpaSnJycnExsayefNmVqxY0epjlZaW0rdvXwCef/752vlnnHFGg8fEFhcXM3nyZJYtW8aOHTsAWy2mlFLN0YRRTyQSRmpqKlOmTGHkyJHMnj37oOXTpk3D7/czbNgw5syZw+TJk1t9rLlz5zJz5kzGjx9PWlpa7fxf/epXFBcXM3LkSMaMGcOSJUvo3r078+bN44ILLmDMmDG1D3ZSSqmmdKlG70MJBv1UVKzF40knKqpnJEI8Jmmjt1Kdlw5v3krGOAEdsVYppRqjCSNMBGMMoONJKaVUYzRhiNibM/buBXQAQqWUaoomDGPA4YCamtBbTRhKKdUYTRgAbne9hKEj1iqlVGM0YQBERYHPB0RmxFqllOoMNGGATRg1NaGG7/avkoqPj2/X4yulVGM0YYBNGMEgBAKhm/eCepWhlFIH0IQBNmEA1NTUu9u7bRLGnDlzGgzLMXfuXB566CHKy8s5/fTTGTduHKNGjeLtt99uZi9WU8OgNzZMeVNDmiulVGt1qcEHb3v/Ntbua2R880AAKithbQzihGCwCocjDmMOnU8ze2XyyLSmRzWcNWsWt912GzfffDMAr732GosXLyY6Opq33nqLxMRECgoKmDx5MjNmzAjdC9K4+fPnNxgG/cILLyQYDHLDDTc0GKYc4J577iEpKYkNGzYAdvwopZQ6El0qYTTJEUoMItRddLXNkCljx44lLy+PvXv3kp+fT3JyMunp6fh8Pu68806WLVuGw+Fgz5495Obm0qtXryb31dgw6Pn5+Y0OU97YkOZKKXUkIpYwjDHzgXOAPBEZ2cjyU7GPZt0RmvWmiPwmtGwa8CjgBJ4RkfvbIqYmrwREYM0a6NWLQK8UKiu/IDp6EG532zwjYubMmbz++uvs27evdpC/l156ifz8fFavXo3b7SYjI6PRYc3DWjoMulJKRUok2zCeA6YdYp2PRSQzNIWThRN4AjgLGA5caowZHsE47c17oXsxIjFi7axZs1iwYAGvv/46M2fOBOxQ5D169MDtdrNkyRJ27drV7D6aGga9qWHKGxvSXCmljkTEEoaILANa85CFScBWEdkuIjXAAuC8Ng2uMaGutZEYgHDEiBGUlZXRt29fevfuDcDll1/OqlWrGDVqFC+88AJDhw5tdh9NDYPe1DDljQ1prpRSR6K92zC+YYxZB+wFfiYiXwB9gax662QDJ0Y8kqgoqKgINXS3/d3e4cbnsLS0NJYvX97ouuXl5QfN83g8vPfee42uf9ZZZ3HWWWc1mBcfH9/gIUpKKXWk2rNb7RpggIiMAR4H/tGanRhjbjTGrDLGrMrPz299NB3s5j2llOpo2i1hiMh+ESkP/bwIcBtj0oA9QHq9VfuF5jW1n3kiMkFEJnTv3r31AbndtvHb79eEoZRSjWi3hGGM6WVCNx0YYyaFYikEVgKDjTEDjTFRwCXAwiM5VoueKhi+ec/n0wEI6+lMT2RUSh2ZSHarfQU4FUgzxmQDvwbcACLyFHAR8ANjjB+oAi4RWzr5jTG3AIux3Wrnh9o2WiU6OprCwkJSU1ObvSmuwd3eHhfBoLe1h+w0RITCwkKio6PbOxSlVAfQ6Z/p7fP5yM7OPvQ9C4EAZGdDSgq+aB+BQDnR0f0jGO2xITo6mn79+uF2u9s7FKVUBBzOM73bu5dUxLnd7tq7oJsVDMK4cfDTn7Lz+7Hs3Hk3Y8Z4cTiiIh+kUkodA3TwwTCHA/r1g6ws3O40AHy+1txGopRSnZMmjPpqE0YqAD5fQTsHpJRSHYcmjPrS0yE7u/YKw+8vbOeAlFKq49CEUV8oYUS57Iix1dW72zkgpZTqODRh1JeeDjU1xJQnYYyHiooNh95GKaW6CE0Y9fXrB4Bj7z7i4oZTXr6+nQNSSqmOQxNGfemhEUmysoiLG01FhSYMpZQK04RRX72EER8/mpqaHGpqjmBAQ6WU6kQ0YdSXlgYeD2RnExc3GkDbMZRSKkQTRn3G1N6LER8/CtCEoZRSYZowDpSeDllZREX1xO3uoQ3fSikVognjQP362UEIgfh4bfhWSqkwTRgHSk+HPXsgGAz1lNqISKC9o1JKqXanCeNA6eng80FuLnFxowgGq6mq2tbeUSmlVLvThHGg0M17ZGcTH297Smk7hlJKRTBhGGPmG2PyjDEbm1h+uTFmvTFmgzHmf8aYMfWW7QzNX2uMWdXY9hFT716M2NjhgEPbMZRSisheYTwHTGtm+Q7gFBEZBdwDzDtg+WkiktnSJ0G1mXoJw+mMJjb2BL3CUEopIpgwRGQZ0OQTiETkfyJSHHq7AugXqVgOS0oKREfX9pTSIUKUUsrqKG0Y1wHv1XsvwAfGmNXGmBub29AYc6MxZpUxZlV+fhsM42FM7b0YYLvWVlfvwO8vO/J9K6XUMazdE4Yx5jRswrij3uyTRGQccBZwszFmalPbi8g8EZkgIhO6d+/eNkHVSxh1Q4Q02hSjlFJdRrsmDGPMaOAZ4DwRqX28nYjsCb3mAW8Bk45qYPVu3ouLCw8RotVSSqmurd0ShjGmP/AmcKWIfF1vfpwxJiH8M3AmcHRP78M37wUCREcPwOlM0IZvpVSX54rUjo0xrwCnAmnGmGzg14AbQESeAu4GUoEnjTEA/lCPqJ7AW6F5LuBlEXk/UnE2Kj0dAgHYtw/Tt2+o4VsHIVRKdW0RSxgicukhll8PXN/I/O3AmIO3OIrq3bxH377Ex48iN/cVRIRQIlNKqS6n3Ru9O6SBA+3rli2AbfgOBErxerPaMSillGpfmjAac8IJ9l6Mzz8H0CFClFIKTRiNc7lg9GhYuxaAuLiRgPaUUkp1bZowmpKZaa8wRHC5kvB4BmjDt1KqS9OE0ZSxY6G4GHbvBmy1lFZJKaW6Mk0YTRk71r6G2jHi4kZTWfkVgUB1OwallFLtRxNGU0aNAoejXsN3JhDQaimlVJelCaMpsbEwdGhtwkhIGA9AWdnRfTyHUkp1FC1KGMaYHxtjEo31V2PMGmPMmZEOrt2NHVubMKKjM3C5UigrW93OQSmlVPto6RXG90RkP3Zcp2TgSuD+iEXVUYwda+/2LijAGENCwnjKyzVhKKW6ppYmjPB4GNOBF0Xki3rzOq8DGr4TEsZTUbFRG76VUl1SSxPGamPMB9iEsTg0mmwwcmF1EJmZ9rW24Xs8In5t+FZKdUktTRjXAXOAiSJSiR119tqIRdVRpKRA//6NNHxrtZRSqutpacL4BvCViJQYY64AfgWURi6sDuSghu9kbcdQSnVJLU0YfwYqjTFjgJ8C24AXIhZVRzJ2LHz9NZSX1zZ86xWGUqoramnC8IuIAOcBfxKRJ4CEQ21kjJlvjMkzxjT6xLxQN93HjDFbjTHrjTHj6i272hizJTRd3cI4297YsSAC6+2wIAkJE6io2KAN30qpLqelCaPMGPMLbHfad40xDkJPzzuE54BpzSw/Cxgcmm7EXslgjEnBPqHvROzzvH9tjEluYaxt64CeUtrwrZTqqlqaMGYBXuz9GPuAfsDvD7WRiCwDippZ5TzgBbFWAN2MMb2B7wAfikiRiBQDH9J84omcfv0gNVUbvpVSXV6LEkYoSbwEJBljzgGqRaQt2jD6AvUfY5cdmtfU/KPPGG34VkopWvhMb2PMxdgriqXYG/YeN8bMFpHXIxhbixhjbsRWZ9G/f//IHGTsWHj0UfD5MG63NnyrLiUQAJ8P/P66VxE73FpMDDidh96HiN2upsZu42jiVLWqCvLzobwcgsGGk9sNHo99GGZ0NERF2fXLy+umigp7DK+37tXhgMRESEqyr4mJdluHw54PhmMpL4fSUti/376Wl9uYA4G6yeGAuDj72cOvgYA9bniqqrL7c7nsd+N02u18vrq4wrF5vVBdXffq8UC3bnVTYqKdXz+usrK6ffh89jUxEf72t7b5fTenRQkD+CX2How8AGNMd+BfwJEmjD1Aer33/ULz9gCnHjB/aWM7EJF5wDyACRMmyBHG07ixY+1v5csvYcwY4uPHk539MMGgF4fDE5FDqmOPiC0wyspsAREuKBwOW/BUVTWc6hcy4YLG5bKFWVSULSBFbCFRWgolJfbV57PruVx2HZerrvALT2ALmspKO1VV2T/hcAEWLsyMsbHVn/bvt4+CCU/l5c1/bo/HFpxud92xw3w+G0d1tS30wa4TLsC7dbPbFxRAXp79HroSj6cuCXo8NnEUF9vvrTFxcZCQYNet/3fSs+fRibelCcMRThYhhbTNSLcLgVuMMQuwDdylIpJjjFkM3FuvoftM4BdtcLzWqd/wPWYMCQnjEfFRXr6BxMQJ7RaWquPzwd69trA7sACsrrYFZvjV67UFsdQ7vQgEGp6Vhs/4DizkA4G6M97wmXdxsS3wCgvt9pHictkCNiqq4dm+z2fjCX+m8OeKibFTbKydoqJszOGz5vCVQjjphBNJQgJkZNg/++RkW7B7PHXruUPdXaqq6hJSZeXBn13EHjN8RRAdbbcNn8mHk6DXCyecAD16QPfudkpIaJhww4mt/tm412s/X3x83RQbW3f1ES5Ug0H7dxE+Qw8nXZGG31t8fMOrkPh4G284yTqd9nsLJ/vKSvvqdNqCPDzFxNT9TYW/52CwroCvX9A3dqUlYj9f+AQhOtrGlZBgv//21NLDvx8qxF8JvZ8FLDrURsaYV7BXCmnGmGxszyc3gIg8FdrHdGArUEno7nERKTLG3AOsDO3qNyLSXON5ZA0ebP8SP/8crrmmtuG7vHy1Jow25Pfb6ojcXPtP6fPVTV6v/QcqKqqb8vIgK8tOOTkNE8CRcrnsP2q40I2JqSvwwoWYw2HXO+44mDTJ9o1IS7P/2PWrUgIBu179fYUL8vj4hgVNINCwukHEJomkJLv8wDN41fkYU/c30rt3e0fTUIsShojMNsZcCEwJzZonIm+1YLtLD7FcgJubWDYfmN+S+CLO6YTRo+s1fA/E5UoOPRvj++0bWwdTv1omXKccPhOrrLSFfl6eTQq5ufbnffvslJ/fskLf4bCFaPfukJ4O3/mOfU1Pt2fE4eqa8FlzuOAPv3o8dWd24QLY4airHgjXbyulGmrxBY6IvAG8EcFYOraxY22rUjCIcTi6ZMN3RYU9m9+9G3btgp07615377bJoLy8ZYV+dLStd+3Z01Z/TJ4MvXrZqWfPujrx8OTx2GSQnGyrC7RAV+roazZhGGPKgMb+/Q32AiExIlF1RKeeCn/+M/zznzBjRqdp+Baxj/z48ks7bd9edzUQrqMuLLQJobCw4bZOpz2rHzDAfj0pKbY6JjzVr24J9ypJTLQJIT5eq1eUOtY0mzBE5JDDf3QZF1xgT4Xvuw/OPfeYa/j2+2HHDti06eCprKxuvXCjX/3G0t694cQT7cC94aqfjAzo27f9G+E6M6/fy37vflJjU3GY9rmk8gf9VPoq8Tg9RDmjMG2c5WsCNezZv4eCygIKqwopqCygoLIAj9PD6J6jGd1zNAmexouhoAQxmDaP6UAiQkFlAXvK9lDmLcPj8hDtisbjtK+94nvhcbX8pFFE2F68nbKaMoamDSXaFR3B6NuW/ru3lMsFs2fDzTfDsmUkTOp4Dd/l5XVXClu21FUd7d5tryICgbp1+/Sxjyy/5hoYPtxOw4bZdoHD5fV72V26m4xuGbidTY8YU1hZyL7yfZyQekKz69XnC/jI3p9NbkUuHqeHuKg44txxxEXFkRCVgNPR/E0A1f5q8ivyKawqpKiqiMLKQoqri6n2V+P1e+1rwEtQgsS6YxtMBoMv6MMX8NW+VvurqfZXU+WvotpfTU2ghlh3LPFR8SREJRAfFU+sOxaXw4XT4cTlcOFyuKgJ1FDmLWO/dz9lNWWUectwGEeDwscYw47iHXxd9DVbCrewq3QXQQniNE56xPWgd0Jvesf3pmdcT9Ji02qnlJgUqv3VtYVtQWUBxdXFBCWIwzgwxmAwuB1uEjwJJEQlkOhJJMGTgD/oZ1/5PnLLc9lXYV9LqkvY793Pfu9+qvxVtd+lwziIdccS44ohxh2D2+HG7XTXvnaL7sagboMYmDyQQcmDGNhtIMYYiquKKakuoaS6hMKqQnaW7GRb8Ta2FW0ja38WQWn+0TqDkgcxpucYnA4neRV5tVNRVREO4yDGFUO0K5oYdwwepwdBCEoQEan92R/0EwgG8Af9+IN+EjwJ9IjrUTulxaThC/qo8FVQUVNBha+C0upS9pTtYW/ZXmoCTXd/cxong1MHM6rHKEb2GMmI7iOIccfUHl9EKKsp4/Ocz1mds5o1OWso9ZbWbntC6gmM7jmaUT1G0TO+Jw7jwGmctb+74qpi8ivzya/IJ78yn6Kqotq/Q2/A/g0nRyez6sZVLfqfOhJG2rJrSTubMGGCrFoVwS+tqsrWv4wfjyxaxH//m0r37hcxZMi8yB2zCYWF8NlnsGIFrF4NGzfa5IDDD/0/xiTuo6drCIMShjAoPY4BA+D4421SGDrUXknUfixfFW9seoO/fv5XPs3+lFMyTuG8IecxY8gM+iT0qV3PH/SztWgrG/M2sjFvI1/kf8HGvI1sKdxCQAKkxaYxc/hMLht1Gd9M/yYO46DKV8U7X7/DSxteYtGWRfiDfqJd0YzuOZrxvcczrvc4EqISGhR2+ZX5ZO3PYle8U9BpAAAgAElEQVTJLvaW7UUarRWFKGcUg1MGM6z7MIal2ckb8PJl/pe1086SnU1uH+YwDgyGgASaXa++aFc0Ma4Y3E43lb5KymsOcbPCAWJcMQhCtb/hIJaJnkQGpwxmcOpgBqcMJi02jbyKPHLKcsgpt1O44GiqEEuOTiY5JhmHcSASKjwRfAFfbbKq/504jIMecT3oFd+LnnE9SY5JJjEqsTapxLnjqAnUUOmrrJ2q/FUNkmlNoIbCykJ2lOwgryKv0bjCusd257iU4zgu+TgGJQ8io1sG3WO7N0iC5TXlrMtdx9p9a1mXu44NuRswxtAjrgc943rSI64HqTGpBCRgE7iviip/Fd6At/b3GU6UDuOoTdwuhwuHcVDmLSOv0iae3PJcCqsKiXJG1Z6MxLnjSPQk0iehD30T+tI3sS/9EvuR6EnE6/fWFtRVvip2luxkQ94GNuRtYHvx9iY/d/iqKfx3nxSdxMa8jazPXc/63PXsKNnR5LYGQ2psKt1ju5Mam0qMKwaPy1N7lZMak8qjZz3a7Pfe5L6NWS0iLTrr1YRxuO69F375S/j8c9aZ2dTU5DJx4vrIHhObIP6ycC2vrHuNnJ3dKPz6eCg6HlNyHEOHGFInfUBF+j/Y4niH8kDDHsgDkgYwrPswMpIy6BXfq/ZMNdYdyxub3uDlDS9T6i3luOTj+NbAb/GfHf9hW/E2ACb1ncTglMF8kf8Fm/I34Q14AfsHfFzKcbVnVAOSBvDvHf9m4VcLqfJXkZ6YzqS+k/hg2weU1ZTRJ6EPl428jNE9R7Mud13tmdZ+7/4GsXaL7kZabBr9EvsxIGmAnboNoFd8L7x+b4MzwH3l+9hcsJlNBZvYXry99kw1yhnF0LShDO8+nGFpw+iT0IeUmBRSY1JJiUkhOSa59h8u2hWNy2EvtH0BH1X+Kip9lVTUVCDIQWfR9a8G6gtKsDZxVPoqG5zR+oI+opxRJHpsIRwfFV97TBHBF7RXLkEJkuRJalEVi4hQ4auwVTmVhcS4Y2qvNsL7bko41tLqUtxON6kxqYe8Ujsc5TXl7CzZyc6SnTiMg27R3RpMse7YNjtWR1NeU87XhV/jC/hqE5YxhhhXzCGvrMu8ZZR6SwkEAwQlSEDsa3J0MikxKW36O6pPE0YklZTYyvyzz2b3A+PZvn02J564g5iYjCPa7c6SneRV5HF8yvGkxKQQDMLatbDw3Rpe/vxNtiT/Cfr/F4IOcDS8hHc73PiCPrpFd+PcE87l/KHnMzhlMF8VflVboG7K30TW/iwKKgsabBvtiubCYRdy/bjrmTpgau1Z6Zf5X/L2V2/zj83/YF/5Pkb0GMHI7iMZ1dNedg9LG0aMO+agz1FeU87CrxbyysZXWLV3FWcdfxaXj7qcUzNOPegPPihBthdvpyZQ0+LCrilev5ctRVuIckYxKHlQq/ejVFejCSPS7rgDHnqIqrWL+bTwDI4//lH69fvRYe2iJlDDJ7s/YdGWRby75V02F2yuXeYJpBAsGIwvPwMGfAQJ+0iWQVw17GbuOudaXE4H24q3sbVoK1uLtlJaXcqZx53J1AFTD9k2UBOoIbc8l5zyHAorC/lG+jfoFt2tNd+CUqoT0IQRaTk5MHAgXHMNn33vY6KiepKZ+Z9DblZeU86iLYt4Y9MbvLflPcpqyohyRnFC1Kl4N05n68oMJHkrUX220G3QFgKJ2xjTZzg/PfkWph0/rd16yiilOq/DSRh63d4avXvb7kXPPkvPa25iR8kT+HyFuN2pB60alCCvffEar37xKu9vfZ9qfzU94npwcvIlVK49h08XfIuNpfEcdxzceQlMn26HmdDuqkqpjkaLpdaaPRuefppeC4rZcX6AwsJ36dXrqgarFFUVceVbV7JoyyL6JvTlhnE3MJwLefb/TmLRp06SkuCKi+Hqq+Gb39Qb2ZRSHZvWcbTWccfBBRcQ9dJ7RDn6UFDwjwaLV+9dzfh54/lw24c8Mf0JPrt0N2WvPcYPpp/C7l1OnnnG1mzNmwdTpmiyUEp1fJowjsSll2IKCkjfMYGiosUEAlWICM+seYYp86cQCAZYetUnVH70Q4YOcfDSS/Dzn8PXX8N119UNg6yUUscCrZI6EtOmQWws3T8Ksm1AJQWFi7nr00U8veZpzhh0Bg9942VuuTKNjz+Gc86Bhx+2I6UrpdSxSBPGkYiNhbPPxrNoGY4r47ll8R28vv1rfnHSL5hcdQ/fmuykuhpefBGuuKK9g1VKqSOjVVJH6qKLIDeX59cm8/r2r5nzzTupee9ezjvXSb9+sGaNJgulVOcQ0SsMY8w04FHACTwjIvcfsPyPwGmht7FADxHpFloWADaElu0WkRmRjLXVpk9n7redzN+fxbk93Pznrtl89in88Ifwhz/Y5z4opVRnELGEYYxxAk8AZwDZwEpjzEIR+TK8joj8pN76twJj6+2iSkQyIxVfW3lo/VP85qQAV22K5/M3/smmTQm88gpcckl7R6aUUm0rklVSk4CtIrJdRGqABcB5zax/KXXPDD8m/OmzPzH7w9lcFDeZnNde5YuNJ/HrX/+EWbM6z93zSikVFsmE0RfIqvc+OzTvIMaYAcBAoP74GtHGmFXGmBXGmPMjF+bhC0qQOz68g1vfu5VzBs+gZtm/+FCm86eTH+akkx6nouKL9g5RKaXaXEdp9L4EeF2kwQMJBoTGN7kMeMQYc1xjGxpjbgwlllX5+fkRD7TaX81lb1zGg/97kO+Pu4n4d99g4TtxPDZyHjdt+yMEoaDgzYjHoZRSR1skE8YeIL3e+36heY25hAOqo0RkT+h1O7CUhu0b9debJyITRGRC99Y8Lu4wFFYWcsaLZ/DqF6/ywLcfIOHjJ1nwsov77oNbfx6D2ZNDnz3jycn5K3IYD+NRSqljQSQTxkpgsDFmoDEmCpsUFh64kjFmKJAMLK83L9kY4wn9nAZMAb48cNujaXfpbr45/5t8tuczFly4gBmpP+ePDxuuvx7mzAHOPRfcbvqt6IvXu5vCwnfbM1yllGpzEUsYIuIHbgEWA5uA10TkC2PMb4wx9bvIXgIskIbjrA8DVhlj1gFLgPvr96462kSE7739PXLKcvj3Vf9m1shZ3HGHvW/v3ntDK3XrBmecQcyi9US5+7BnzxPtFa5SSkVERO/DEJFFwKID5t19wPu5jWz3P2BUJGM7HAs2LuDfO/7Nn876Eyf1P4mlS2HhQrjvPmhQCzZzJubaa8kouomvfU9RWfk1sbEntFfYSinVpjpKo3eHVVJdwu0f3M6EPhO4acJNBIPw05/ap7T++McHrDxjBrhc9FhiMMbF3r1/bpeYlVIqEjRhHMKv/vMr8iryeOrsp3A6nLz8sh3u4957GxltNiUFZszA9eLf6Z5wPjk5zxIIVLRL3Eop1dY0YTRj1d5VPLnySW6eeDPj+4ynqgruvBPGj4dLL21iox/+EAoKGLByKIFAKbm5x9S9iEop1SRNGE0IBAPc9M+b6Bnfk3tOuweARx6BrCx46CFwNPXNfetbMGQIsc//m7i4Uezd+wSd6bnpSqmuSxNGE/686s+szlnNI995hKToJPLybCP3jBlw6qnNbGgM/OAHmOXLGVB8LuXla9m/f3kzGyil1LFBE0YjCioL+OV/fskZg87g4hEXA/C730FlJTz4YAt2cPXVEBND2mt7cToTtYutUqpT0ITRiIVfLWS/dz/3f/t+jDFkZ8Nf/mLzwJAhLdhBt25w+eU4XnmNPrGXkJ//d2pqciMet1JKRZImjEa8t/U9+ib0ZWwvOxrJffdBIAB33XUYO/nBD6CykvQlaYj42b3795EJVimljhJNGAfwBXx8sO0Dph0/DWMMu3fD00/DdddBRsZh7GjcOJg8mahn3qBXz6vYs+dxqqt3RSpspVRHJGKfpDZ+PGRnt3c0R0wTxgGWZy9nv3c/0wdPB2zbhTG2O+1h++EP4auvGLRrGsY42LHj7kNvo5RqO7t2wfr17XPskhK44AL42c/szVu33HLk+1y7Fi67DPbuPfJ9tYImjAO8t+U9XA4X3x70bbZvh/nz4YYb7J3dh23mTEhNJeqZ1+nb90fk5r5Iefm6No9ZKdWIlSvtlf7EibBo0aHXb0tr1tirin/+E/74R3jgAXj7bXjrrdbvM5yAXnkFpk2z748yTRgHWLR1EVPSp5DoSeS3vwWns5VXF2Af6H3ddfCPf9A/eBkuVze2b5/TpvEqpRqxbBmcfjokJcGIEbagXbw4ssf0+2HrVnj8cfjmN6GmBj76CG67DX7yExgzxl5llJYevK2Irfv+4IPG9y1iy5KsLLj/fti82fbxr6qK7Gc6OA7pNNP48ePlSGSXZgtzkQc+eUC+/lrE6RS57bYj2qXIzp0icXEigwdL9vJfypIlSFHRv49wp0qpJr33nkhMjMjQoSLZ2SKFhSKZmSLR0SIfftg2xygtFXn3XZGf/1xk+nSRwYNFXC4RW7SLnHmmSH5+w20++0zEGJGbb244v6ZG5Lrr7HbGiDz++MHHe/xxu/z3v7fvFyyw655/vojff0QfBVglLSxj272Qb8vpSBPGM6ufEeYi6/etlyuvtH9zOTlHtEvrv/8VSUyU4ID+svq13rJy5XgJBgNtsGOljhG7dok884wtLJcujdxxXn9dxO22CSIvr25+QYHI6NE2afy73glbMGj/yZcvtwX6F1/Yk7y8PJGiIpGtW0VWrBD55z9FnnvOJohJk+zZJNhjjRkjctFFIr/4hcj8+SL/+59IoIn/7x//2Bb0//uffV9WJjJtmt3XnXeKnHee/flnP6vbx6pVIlFRIuec03C/jz1m173xRvs5WkkTRitd8OoF0u/hfrJ9e1AcDvs7azOrV4ukpoq/Vzf59DkkN3dBG+5cqXZWVWUL2vXrRT75RGTRIpGXXxa59VaRIUOk9szb7bavZ50l8vnnbXf8TZtsMnI4RL7xDZHi4oPXycsTGTnSnglefLHIuHEiCQl1sbVkcrtFTj5Z5K67bOKpqDi8OPfvF+nXz8axe7eNwekUefppu9zvt58DbIz79okMGiSSnm6T3oHuvNOu++tfH/ZXFnY4CcPY9TuHCRMmyKpVq1q1rS/gI+33acwaMYvJ+fO47jr48ksYNqwNA9y4Efn2t/HXFLDp0V6MuGwrTmd0Gx5AqUMQgfJyyMuD/HxIToYTTrBdAVuiutr+Y2zcaF83bbKv27dDMHjw+jExdiydM8+EM86AgQPhiSfszU3FxXYUz3vugeOOa/qY+/fDM8/YYw8ZYqfjjwe3G959F/70J/jwQ4iKgssvh8ceg/j4xveVlwcXXmh7GQ0ebKcTToBBg+x3U1Fhh3SoqACfD1JTIS2tburdu5Fhqg/TO+/Y9oeYGPu9//3vMH163XIRePhh27sqPt62UyxbZttFDiQC118Pn3wCq1c3/bmbYYxZLSITWrRySzNLayZgGvAVsBWY08jya4B8YG1our7esquBLaHp6pYc70iuMJbuWCrMRd788k353vdEUlKavqo8Il99Jf4+3aUmHsl+9sIIHEB1al9/LfLmmyKLF9sz+bVrRbZtO3SVxFNPiQwYIOLxHHzW3K+fyDXXiLz0kj2jLSoS2bjRHmP+fJG5c0VmzrRXCg5Hw7PtESPssrvvFvnrX0X+/ne73fLldh/V1Y3HU1xsq3BiYuwZ9kUXiSxb1vBzVFWJ/OEPIqmpB8dsjEhSkv25b1+R3/5WJDe3zb7miLvsMpFevURWrmx6nVdfte2fDz/c/L58PttO00p0hCopwAlsAwYBUcA6YPgB61wD/KmRbVOA7aHX5NDPyYc65pEkjJ9/8HNx/8YtpdWlMnSorS6MmJ07pfqEFAk6kIr7bjmi+kdVz8KFdXXDx5oNG2w1x7p1jS/3+0Xuv7+uSufA6YwzGq+yELHbgchJJ4nMni3y4IMizz5r6+X/8hdbWCcnN18VM2iQbWC96y6bFDZtso21R2rPHhtTt272OJmZNknNm2cTWbgBeeVKW9+/erWt6po71zYU//3vtsA81gQCIl7voddri+/4EDpKwvgGsLje+18AvzhgnaYSxqXAX+q9/wtw6aGOeSQJY9STo+S0506TggL7rdx7b6t31SL+4hwpnBonAhK49sqmz8RUy2zebAvTpCTbM+ZYUVRk6/nDjajGiFx1lW0PCNu2zRb2IHLhhbZx9pNPRN5/X+SNN0Tuu882ig4caK84woJBkV/9ym536aXNFz5+vy2Uf/97kYceEnnlFXvGv22bSGVl5D5/WHm5TV4jRtQlqcmTRZYsifyxu7iOkjAuAp6p9/7KA5NDKGHkAOuB14H00PyfAb+qt95dwM+aOM6NwCpgVf/+/Vv1hWWVZglzkQc/eVDeecd+Kx991KpdHZbS4v/JjiuNPeCUKbY6QB2+YND2NElIsFUc06d3/Ks2v9+eRael2WqeH/5QZMsWe7bt8dgEcPvtIk8+KRIfL5KYKPLCC01/rhUrRPr0EYmNtV0ug0GRn/zE/m1dd90Rd708aoJB24vqww87/u+wkziWEkYq4An9/H3gP3KYCaP+1NorjHmr5glzkY25G2XOHNud+nA7P7TW9u13yca7kGBMlD07/ulPRXbsODoHP1YsW2br2Jvq47xwof1T/sMfRB591P787LNHNcQm7dkjcsEFtv1g0CDbX3/oUNvrBUSmTm14VSBie89ce6292gCR006z3VIPJSfHnniA7foJIj/6UYQa41Rn0VESxiGrpA5Y3wmUhn4+qlVS313wXUl/OF2CwaBMnWr/146WQKBGVq4cL6ufSxL/zBm2asLhsIXMRx91/rOs+fNtl8LG6nMDAduYGW5oHTvW3jBVX1WVLYiHDbNVLoGALYSTkkSystomxmDQ1p/v3m0bVisrW/Z7WbDAtg3ExNhGzssvF7nkEttdcuZMW+3T3H42bLD7OJwC3+sVuekm+3394hed/+9HHbGOkjBcocbqgfUavUccsE7vej9/F1gR+jkF2BFq8E4O/ZxyqGO2JmF4/V5JuDdBvv/O98Xrtff1HPHd3YepvPxL+eijaFm79tsS2LlFZM4c200rXKedkGCrG4YMETnxRNtrorz86AZ5uL74wlazFBU1vc7ixVJbX52RYZNHuAFz3z7bkBuuf3/tNXvpd/rpDdt77r3XrvPBB3Xztm61VTPTpjUsMLOzRW64wRbgffrY7/LCC+0v/O677dn4FVeInH227cs/dKhIjx4N7+ANTy6X/R0df7zI1VeLvPiiyN699jiFhTYxgD3GV1+12dfaYm1yx6nqCg4nYUT0PgxjzHTgkdDVw3wR+Z0x5jehABcaY+4DZgB+oAj4gYhsDm37PSA8itPvROTZQx2vNfdh+IN+/rPjP/SK70X1rtGceKLtFn3RRYe1myOWk/MsX331PVJTz2XEiNdxVPvhtddg2zbbb76szL7u3AmffgopKfCjH8Gtt9qfO5LiYjvg27ZtdpC0f/7TDspVX2EhjBplHzZ13322L/7q1bZ//fXX2weol5TYcXmuu872V3/hBfsUq1mz4OWXbV/6IUNsH/8DB3V7/HH7/fz1r3YcoQcesPsMBGxffWPscNNZWXaqqLDjDqWk2HsTwlNqqn1NSbGx+nz2voD9++3vZO9eO15QYaE97ogRUFRk73GYOxfuuANcrqPytSvVGh3mPoyjPR3pnd4PP2xPCvfsOaLdtFp29hOyZAmyYcP5Egg006Nl+XKRGTNssHFxtqG0rKz5nX/8se2L/+ijIg88IPKb39ipuR5Ffr/twXPiiSJvv92y6o1AwDY6u1wit9xiY/z5zxuuEwzaM3u3W2TNmrp5//iHHb4B7Nn9+vUH7/+BB+zyH//YnsV7PLYnT2NxnHKKvTpLTrZXaldcIbJ9+8HrBoNH1igcCNjP8eCD9qpo6lTb/VOpYwAdoUqqPaYjTRgXXWRrRtpTVtbjoaRxQfNJQ8TWcV9+uS0Mjzuu8XsQCgtFrrxSmuxf37dv433/fT5b7w4iPXva14kTbTVSc4lj7ly77hNP2Pc/+IF9/9JLdes895ydd//9B28fCNhG7qaq3IJBW4UUjv+uu5qOZds2W230ne+07TAUSnUimjBaIRgU6d3blpHtLSvrEVmyBNm48aJDJw0R2ziekWEbh++8s64B+a237N2kLpctWLOy7M1d5eU2IaxbZxNGQoJNBGHV1SLf/a7U3pDi89m7ePv3t/NOPtmO1HngDVPhPslXXVWXVLxeu350tB1Ebft2e7ypU1t/Vh8I2F5Ew4cfui1Hewgp1SxNGK2wY4c0ODFub7t3/yF0pXGhBAItuCO0tNQWouHeRDNnSu2ds82dXWdl2Wogp9MmhYqKutEzH3204brV1fYL6tPHLu/TR+SOO+xdv1u22J5JmZkH3+iVm2u7kfbrZ2/GSkxseGNaa2kPIKWOmCaMVvjb3+y30ZFqLnbvfliWLEHWrZsmfn8Lbwz5xz9Eune37QP33NOyoQVKS+3wC+EhIIyxQ1E3xeu14xmde27dHcoJCbb6p7E2AhFbpx8TY9d98cWWfRalVMQdTsLQ0WpDbr7ZdsIpKTm4Q0972rv3ab7++vskJZ3MqFHv4HIlHnqjoiLbg2fAgJYfyOeDH/wAnn/efhGXXtqy7fbtg5degoUL4e677VPOmvLBB/b5yj/9actHR1VKRdTh9JLShBGSmQndu9tRkjua3NwFbN58JfHxYxk9+j3c7tTIHayiAuLiIrd/pVSHcjgJQ5/pje1Sv2EDTJnS3pE0rmfPSxgx4k3Ky9ezdu2pVFfvjtzBNFkopZqgCQN7H1ww2HETBkBa2rmMHv0u1dU7WblyNHl5r7Z3SEqpLkYTBvC//4HDASee2N6RNC85+XQmTFhLXNwwvvzyEjZtugq/f397h6WU6iI0YQD//a8dpSKxBe3J7S0m5jgyMz8mI2MuubkvsWpVJqWl/2vvsJRSXUCXTxiBAKxY0fjjcjsqh8NFRsavGTv2EwA+//wkvvzyCqqqtrdzZEqpzqzLJ4xg0PYkve669o7k8CUlfYMJE9aSnv5zCgre5LPPhvD11zfj9e5r79CUUp2QdqvtJLzevezadQ85Oc9gTBR9+95KevrtREX1aO/QlFIdmHar7YI8nj6ccMKfmThxE2lp55OV9SArVmSwZcuPqa7Oau/wlFKdgCaMTiY29niGD3+JSZM20aPHJezd+ySffnocmzdfT1XVtvYOTyl1DItowjDGTDPGfGWM2WqMmdPI8tuNMV8aY9YbY/5tjBlQb1nAGLM2NC2MZJydUWzsEIYOnc+JJ26ld+8byc39G599NlTbOJRSrRaxNgxjjBP4GjgDyAZWYp/L/WW9dU4DPhWRSmPMD4BTRWRWaFm5iMQfzjG7chvGoXi9OaE2jqcxJop+/W4jPX02bne39g5NKdWOOkobxiRgq4hsF5EaYAFwXv0VRGSJiFSG3q4A+kUwni7N4+nNCSc8GWrjOI/du+/l008HkZ39KMGgr73DU0odAyKZMPoC9Vtbs0PzmnId8F6999HGmFXGmBXGmPMjEWBXZNs4Xmb8+DUkJExg69bbWLVqDEVFi9s7NKVUB9chGr2NMVcAE4Df15s9IHSZdBnwiDHmuCa2vTGUWFbl5+cfhWg7h4SEsYwevZiRIxcSDNawfv00Nmw4l8rKr9s7NKVUB+WK4L73AOn13vcLzWvAGPNt4JfAKSLiDc8XkT2h1+3GmKXAWOCgbj4iMg+YB7YNow3j7/SMMaSlnUtKyplkZz/Grl338NlnQ/B4+hMfP5aEhLHEx48lMfEbREV1b+9wlVLtLJIJYyUw2BgzEJsoLsFeLdQyxowF/gJME5G8evOTgUoR8Rpj0oApwIMRjLVLczg89O8/m549ryQ390XKy9dQVvY5hYULAcEYN927X0y/freRmNiitjGlVCcUsYQhIn5jzC3AYsAJzBeRL4wxv8E+EnAhtgoqHvi7sU9g2y0iM4BhwF+MMUFstdn99XtXqcjweHrRv//s2vd+fzkVFevIy/s7+/b9lby8l0hMnEK/freRlnY+DkckzzeUUh2NDg2iWsTvLyUn51n27HmM6uodREX1pmfPK+jV6xri4oa3d3hKqVbSR7SqiBEJUFj4T3Jy5lNUtAgRPwkJE+nV62qSkk4iJuYEnM6Y9g5TKdVCh5MwtE5BHRZjnKSlnUda2nnU1OSRm/sy+/Y9x5Ytt4TXIDp6IHFxw4mNHUp09CCiowcSEzMQj2cATmd0u8avlGo9TRiq1aKiepCefhvp6bdRUbGZior1VFR8SWXlJiorN1FU9CH1Or4BEBMzmOTkM0lJ+Q7dup2Gy3VYN/MrpdqRJgzVJuLihhIXN7TBPJEgNTU5VFXtoLraTmVlK9m37zn27n0CY9wkJZ1ESspZpKaeTWzsMEKdH5RSHZC2YaijLhj0Ulr6X4qK3qeo6H0qKjYAEB2dQUrK2aSmTsfj6YfDEY3D4cHhiMbpjMfpjGvnyJXqfLTRWx1TqquzKCpaRGHhuxQX/4tgsKrR9eLiRtOt26mhaSpud+pRjlSpzkcThjpmBQJV7N+/Ar+/mGCwOjR58fnyKC39hNLS/9YmlPj4saEG+POJixut1VlKtYL2klLHLKczhuTk05pcHgzWUFa2ipKSpRQVvc/Onf/Hzp1ziY7OIC3tfOLjx+F0JuB0xuNyJeB0JhAV1UeHcVeqDWjCUMcUhyOKpKRvkpT0TQYMuJOamjwKC9+hoOAf7Nnz54N6ZYU5nUlERw8gOjqjtn3EGDcOhxtj3DidcXg8/fB40vF40omK6q13sit1AP2PUMe0qKge9O59Hb17X0cgUIHXm0MgUEYgUE4gUIbfvx+vNxuvdxfV1Tuprt5OaenHBIM1iPgQ8QGNVcs6cLvTcLtTcLlSQ6/JOJ1xBzXG24EaJ+JyJRztj6/UUaUJQwi3qgwAAAuJSURBVHUaTmccsbHHH/Z2IoF6iSUbrzcLrzeLmpo8/P4ifL4ivN4sysvXEQxWEgx6CQarQ8kmzEFc3EgSEycTFzcckUCDpORwxOLx9CEqqk/tq8uVpO0u6piiCUN1ecY4cbuTcbuTiY8f1eLtRIL4/cXs37+S/ftXsH//cvLyXiUQKG3R9g5HHNHR/WurwTye3gSD3torJL+/DGNcJCTYK5iEhPENeoaJCIFAGTU1eYj4McYBODDGgTFuoqJ64nBEHe7XoVSTNGEo1UrGOHC7U0lNnUZq6jSgLokY4643OQkGK/F6c6ip2YvXu5eamj14vdlUV2fh9e6momI9NTW5OBye2kZ7pzOBYLCSgoI3ao8ZHT0QlysFny8vlCgab7MJRUhUVO9QUupPVFRPbEIxQN1kjLNBsvF40omLG0lc3AhcrqQWfRf2qqsGpzMutK/m+XwllJQspaTk31RX7yI5+XRSU88lJmZQi46n2od2q1WqgxCRRquofL6S0DNKVlFWtpJAoBy3uydRUT2JiuqB290dY6KAICJBIEAw6MXr3YvXuxuvN4vq6t3U1ORi22vCE6H1g/VeA9Rv0/F4+hEbOwynMx5jokKdBKIQCVBTk0NNTQ5e7178/sLabRyOmNobLV2ubvXagFJwODzs37+csrLVQLC2qq6qaisAsbHDSU09l6Skb+B0JuFyJeJ0JuJyJRAIlFNTs6928vkK8Xj6h8YtG9aiNqRAoAqvdzfBoLfe53HjcHhwu9MwxnlYv7NAoAJjXDgcnsPariPR+zCUUq0iEqS6ejcVFRuprPyCioovqKz8imCwKtQmU0MwWIMx9uolKqp3bZuMwxFDMFgR6nBQEep0UPr/7d1bjF1VHcfx72/mzEzn0tIW2lpoQ4stIihtgXARNEiDqcQIDxhQJMSQ8FIjJCZK4y3ypC8iD0QhiIISuQna8CBCIRAeBAoUKK2lFVoYAp0KpTjM/czfh7VmOE4K3UyZnrM7v0+yM2evs8+e/zmzJ/+z1157/Rkefnv8WlC12svMmacwe/Zq5sxZzaxZZ9DU1Ep//yt5tNt69u17nIiRjx17W9ti2tuX0dTUkQclpKVa7WNgIA16GB7e/RF7aKatbdH4GVlb29F5Xx8McqhWe+nvf5m+vu3097/M0NCbAPlM7tj8usVIYnR0iNHRQSIGiajS3DyzJgHOolKZQ0vL/JrEfxTDw3trPvvN9PVtp61tEV1dK+jqWklX1wpaWuZO8q+7f04YZlZaIyP76Ovbnq/lpJFu1ep7NDd30dr6qbwsoFKZw8DArpzUtvD++1sYGNg5fsNnxCCjo4M0NbUxY8aS8SXNmtzO6OgwEWlgQrXan8+WXmNg4LV8Zvbmfrv8Wlrm0d5+PB0dx9PevoyIkZyQdjE4uIvBwW5SV1/reNKCppxI931EMhS1Z3eVymza25czONg9npjS71+Qh4WPdSU209o6n1WrHp/U590wN+5JWgPcQKq4d0tE/GLC823A7cCpwNvAJRGxMz+3DrgSqALfi4gHpzJWM2sMlcoRhUsBd3Qsp6NjOXDRlMQSMZrPrNLIuKamGYWv6+x/f5EHNrzH8PA7+VrUboaGdjM83EOlcgSdnZ+ns/NztLYuHO+iHBrqobf3eXp7N9HXty2Pvqsy1o1Yqcz6hN7xR5uyhKHUGXgjcD7QDTwtaf2EUqtXAnsjYpmkS4FfApdIOpFUA/wk4GjgYUnHR/qEzMwOCakp13CZAUw+UXywP9HcPIPm5hm0ts4HTjjgayDdbzR37vnMnXv+QcdwMA48nGHyTgd2RMQrETEE3AlcOGGbC4Hb8uN7gdVKKfVC4M6IGIyIV4EdeX9mZlYnU5kwjgFer1nvzm373SZSx94+4MiCrzUzs0NoKhPGISHpKkkbJW3cs2dPvcMxMztsTWXCeANYXLO+KLftdxtJFVIn4dsFXwtARNwcEadFxGnz5s37hEI3M7OJpjJhPA0sl7RU6a6iS4H1E7ZZD1yRH18MPBJpnO964FJJbZKWAsuBp6YwVjMzO4ApGyUVESOSvgs8SBpWe2tEvCTpOmBjRKwHfgf8UdIO4B1SUiFvdzewBRgB1nqElJlZffnGPTOzaezj3LhX+oveZmZ2aBxWZxiS9gC7Jvnyo4D/fILhHEpljh3KHX+ZYwfHX0+NEvuxEVFoxNBhlTAOhqSNRU/LGk2ZY4dyx1/m2MHx11MZY3eXlJmZFeKEYWZmhThhfODmegdwEMocO5Q7/jLHDo6/nkoXu69hmJlZIT7DMDOzQqZ9wpC0RtI2STskXVvveA5E0q2SeiRtrmmbK+khSdvzzzn1jPHDSFos6VFJWyS9JOnq3F6W+GdIekrS8zn+n+f2pZKezMfQXXkqnIYkqVnSc5IeyOtlin2npBclbZK0MbeV4tgBkDRb0r2S/iVpq6SzyhQ/TPOEUVPk6avAicA3c/GmRvYHYM2EtmuBDRGxHNiQ1xvRCPD9iDgROBNYmz/vssQ/CJwXESuAlcAaSWeSCn9dHxHLgL2kwmCN6mpga816mWIH+HJErKwZjlqWYwdS9dG/R8QJwArS36FM8aeSgdN1Ac4CHqxZXwesq3dcBeJeAmyuWd8GLMyPFwLb6h1jwffxN1JFxtLFD3QAzwJnkG6+quzvmGqkhTTr8wbgPOABUhHpUsSe49sJHDWhrRTHDmkm7lfJ143LFv/YMq3PMDh8CjUtiIixKvFvAQvqGUwRkpYAq4AnKVH8uUtnE9ADPAT8G3g3UgEwaOxj6NfAD4DRvH4k5YkdIIB/SHpG0lW5rSzHzlJgD/D73CV4i6ROyhM/MM27pA5Hkb6qNPTQN0ldwF+AayLivdrnGj3+iKhGxErSt/XTKVqUuc4kfQ3oiYhn6h3LQTgnIk4hdSGvlfSl2icb/NipAKcAv4mIVcD7TOh+avD4ASeMwoWaGtxuSQsB8s+eOsfzoSS1kJLFHRFxX24uTfxjIuJd4FFSN87sXAAMGvcYOhv4uqSdwJ2kbqkbKEfsAETEG/lnD3A/KWGX5djpBroj4sm8fi8pgZQlfsAJo0iRpzKoLUR1BenaQMORJFINlK0R8auap8oS/zxJs/PjdtL1l62kxHFx3qwh44+IdRGxKCKWkI7zRyLiMkoQO4CkTkkzxx4DXwE2U5JjJyLeAl6X9JnctJpU76cU8Y+r90WUei/ABcDLpL7oH9U7ngLx/hl4ExgmfWu5ktQXvQHYDjwMzK13nB8S+zmkU+4XgE15uaBE8Z8MPJfj3wz8NLcfR6oIuQO4B2ird6wHeB/nAg+UKfYc5/N5eWnsf7Usx06OdSWwMR8/fwXmlCn+iPCd3mZmVsx075IyM7OCnDDMzKwQJwwzMyvECcPMzApxwjAzs0KcMMwagKRzx2aQNWtUThhmZlaIE4bZxyDp27kmxiZJN+XJCHslXZ9rZGyQNC9vu1LSPyW9IOn+sVoHkpZJejjX1XhW0qfz7rtq6iXcke+MN2sYThhmBUn6LHAJcHakCQirwGVAJ7AxIk4CHgN+ll9yO/DDiDgZeLGm/Q7gxkh1Nb5AunMf0uy915BqsxxHmv/JrGFUDryJmWWrgVOBp/OX/3bSZHGjwF15mz8B90k6ApgdEY/l9tuAe/J8SMdExP0AETEAkPf3VER05/VNpLonT0z92zIrxgnDrDgBt0XEuv9rlH4yYbvJzrczWPO4iv8/rcG4S8qsuA3AxZLmw3g96WNJ/0djM75+C3giIvYBeyV9MbdfDjwWEf8FuiVdlPfRJqnjkL4Ls0nyNxizgiJii6Qfk6q+NZFmDF5LKoZzen6uh3SdA9J01b/NCeEV4Du5/XLgJknX5X184xC+DbNJ82y1ZgdJUm9EdNU7DrOp5i4pMzMrxGcYZmZWiM8wzMysECcMMzMrxAnDzMwKccIwM7NCnDDMzKwQJwwzMyvkf1o8nOr59T4KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 959us/sample - loss: 0.4523 - acc: 0.8760\n",
      "Loss: 0.45233589846520905 Accuracy: 0.87601244\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2381 - acc: 0.2551\n",
      "Epoch 00001: val_loss improved from inf to 1.55108, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/001-1.5511.hdf5\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 2.2381 - acc: 0.2551 - val_loss: 1.5511 - val_acc: 0.5013\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4388 - acc: 0.5272\n",
      "Epoch 00002: val_loss improved from 1.55108 to 1.14374, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/002-1.1437.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 1.4388 - acc: 0.5272 - val_loss: 1.1437 - val_acc: 0.6478\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1400 - acc: 0.6327\n",
      "Epoch 00003: val_loss improved from 1.14374 to 0.97556, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/003-0.9756.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 1.1400 - acc: 0.6327 - val_loss: 0.9756 - val_acc: 0.7142\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9129 - acc: 0.7172\n",
      "Epoch 00004: val_loss improved from 0.97556 to 0.71205, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/004-0.7121.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.9130 - acc: 0.7172 - val_loss: 0.7121 - val_acc: 0.7845\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7500 - acc: 0.7724\n",
      "Epoch 00005: val_loss improved from 0.71205 to 0.61818, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/005-0.6182.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.7500 - acc: 0.7724 - val_loss: 0.6182 - val_acc: 0.8225\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6269 - acc: 0.8097\n",
      "Epoch 00006: val_loss improved from 0.61818 to 0.55489, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/006-0.5549.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.6268 - acc: 0.8098 - val_loss: 0.5549 - val_acc: 0.8369\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5473 - acc: 0.8368\n",
      "Epoch 00007: val_loss improved from 0.55489 to 0.47934, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/007-0.4793.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.5473 - acc: 0.8369 - val_loss: 0.4793 - val_acc: 0.8640\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4802 - acc: 0.8561\n",
      "Epoch 00008: val_loss improved from 0.47934 to 0.40255, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/008-0.4026.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.4802 - acc: 0.8561 - val_loss: 0.4026 - val_acc: 0.8945\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4309 - acc: 0.8712\n",
      "Epoch 00009: val_loss did not improve from 0.40255\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.4308 - acc: 0.8712 - val_loss: 0.4153 - val_acc: 0.8772\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3851 - acc: 0.8833\n",
      "Epoch 00010: val_loss improved from 0.40255 to 0.38461, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/010-0.3846.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.3851 - acc: 0.8833 - val_loss: 0.3846 - val_acc: 0.8926\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3535 - acc: 0.8925\n",
      "Epoch 00011: val_loss improved from 0.38461 to 0.32746, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/011-0.3275.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.3535 - acc: 0.8925 - val_loss: 0.3275 - val_acc: 0.9096\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3266 - acc: 0.8998\n",
      "Epoch 00012: val_loss improved from 0.32746 to 0.31310, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/012-0.3131.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.3266 - acc: 0.8998 - val_loss: 0.3131 - val_acc: 0.9092\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3051 - acc: 0.9071\n",
      "Epoch 00013: val_loss did not improve from 0.31310\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.3051 - acc: 0.9071 - val_loss: 0.3287 - val_acc: 0.9096\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2793 - acc: 0.9132\n",
      "Epoch 00014: val_loss improved from 0.31310 to 0.28247, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/014-0.2825.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2793 - acc: 0.9132 - val_loss: 0.2825 - val_acc: 0.9220\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2600 - acc: 0.9182\n",
      "Epoch 00015: val_loss did not improve from 0.28247\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2599 - acc: 0.9182 - val_loss: 0.3085 - val_acc: 0.9140\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2415 - acc: 0.9235\n",
      "Epoch 00016: val_loss did not improve from 0.28247\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2415 - acc: 0.9235 - val_loss: 0.3130 - val_acc: 0.9152\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2296 - acc: 0.9285\n",
      "Epoch 00017: val_loss improved from 0.28247 to 0.27847, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/017-0.2785.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2296 - acc: 0.9285 - val_loss: 0.2785 - val_acc: 0.9248\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2166 - acc: 0.9322\n",
      "Epoch 00018: val_loss improved from 0.27847 to 0.26784, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/018-0.2678.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.2166 - acc: 0.9322 - val_loss: 0.2678 - val_acc: 0.9250\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2034 - acc: 0.9357\n",
      "Epoch 00019: val_loss did not improve from 0.26784\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.2034 - acc: 0.9357 - val_loss: 0.2795 - val_acc: 0.9222\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9408\n",
      "Epoch 00020: val_loss improved from 0.26784 to 0.25300, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/020-0.2530.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1853 - acc: 0.9408 - val_loss: 0.2530 - val_acc: 0.9278\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1763 - acc: 0.9438\n",
      "Epoch 00021: val_loss did not improve from 0.25300\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1762 - acc: 0.9438 - val_loss: 0.2760 - val_acc: 0.9285\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9453\n",
      "Epoch 00022: val_loss did not improve from 0.25300\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1664 - acc: 0.9453 - val_loss: 0.2921 - val_acc: 0.9213\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9491\n",
      "Epoch 00023: val_loss did not improve from 0.25300\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1546 - acc: 0.9491 - val_loss: 0.2944 - val_acc: 0.9236\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9497\n",
      "Epoch 00024: val_loss did not improve from 0.25300\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1549 - acc: 0.9497 - val_loss: 0.2651 - val_acc: 0.9327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9527\n",
      "Epoch 00025: val_loss did not improve from 0.25300\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1439 - acc: 0.9527 - val_loss: 0.2661 - val_acc: 0.9280\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9564\n",
      "Epoch 00026: val_loss improved from 0.25300 to 0.25080, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/026-0.2508.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1339 - acc: 0.9564 - val_loss: 0.2508 - val_acc: 0.9348\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9577\n",
      "Epoch 00027: val_loss did not improve from 0.25080\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1287 - acc: 0.9577 - val_loss: 0.2769 - val_acc: 0.9273\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9596\n",
      "Epoch 00028: val_loss did not improve from 0.25080\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.1236 - acc: 0.9596 - val_loss: 0.2736 - val_acc: 0.9294\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9596\n",
      "Epoch 00029: val_loss did not improve from 0.25080\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1216 - acc: 0.9596 - val_loss: 0.3026 - val_acc: 0.9238\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9616\n",
      "Epoch 00030: val_loss did not improve from 0.25080\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1140 - acc: 0.9616 - val_loss: 0.2957 - val_acc: 0.9297\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9640\n",
      "Epoch 00031: val_loss did not improve from 0.25080\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.1066 - acc: 0.9640 - val_loss: 0.2787 - val_acc: 0.9311\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9648\n",
      "Epoch 00032: val_loss did not improve from 0.25080\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.1029 - acc: 0.9648 - val_loss: 0.2895 - val_acc: 0.9334\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9659\n",
      "Epoch 00033: val_loss did not improve from 0.25080\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.1016 - acc: 0.9659 - val_loss: 0.2724 - val_acc: 0.9343\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9671\n",
      "Epoch 00034: val_loss did not improve from 0.25080\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0968 - acc: 0.9671 - val_loss: 0.2969 - val_acc: 0.9341\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9690\n",
      "Epoch 00035: val_loss did not improve from 0.25080\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0912 - acc: 0.9690 - val_loss: 0.3015 - val_acc: 0.9327\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9674\n",
      "Epoch 00036: val_loss improved from 0.25080 to 0.24618, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_6_conv_checkpoint/036-0.2462.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0971 - acc: 0.9675 - val_loss: 0.2462 - val_acc: 0.9387\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9729\n",
      "Epoch 00037: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0820 - acc: 0.9729 - val_loss: 0.2852 - val_acc: 0.9355\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9702\n",
      "Epoch 00038: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0875 - acc: 0.9702 - val_loss: 0.2834 - val_acc: 0.9378\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9722\n",
      "Epoch 00039: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0846 - acc: 0.9722 - val_loss: 0.2952 - val_acc: 0.9373\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9713\n",
      "Epoch 00040: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0834 - acc: 0.9713 - val_loss: 0.2986 - val_acc: 0.9294\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9731\n",
      "Epoch 00041: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0813 - acc: 0.9731 - val_loss: 0.2632 - val_acc: 0.9404\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9754\n",
      "Epoch 00042: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0736 - acc: 0.9754 - val_loss: 0.2899 - val_acc: 0.9331\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9730\n",
      "Epoch 00043: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0813 - acc: 0.9730 - val_loss: 0.2798 - val_acc: 0.9357\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9757\n",
      "Epoch 00044: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0717 - acc: 0.9757 - val_loss: 0.2981 - val_acc: 0.9364\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9756\n",
      "Epoch 00045: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0727 - acc: 0.9756 - val_loss: 0.2827 - val_acc: 0.9355\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9768\n",
      "Epoch 00046: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0705 - acc: 0.9768 - val_loss: 0.3062 - val_acc: 0.9376\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9779\n",
      "Epoch 00047: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0674 - acc: 0.9779 - val_loss: 0.2669 - val_acc: 0.9443\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9777\n",
      "Epoch 00048: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0679 - acc: 0.9777 - val_loss: 0.3122 - val_acc: 0.9355\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9802\n",
      "Epoch 00049: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0606 - acc: 0.9802 - val_loss: 0.3063 - val_acc: 0.9415\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9742\n",
      "Epoch 00050: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0771 - acc: 0.9742 - val_loss: 0.3090 - val_acc: 0.9359\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9808\n",
      "Epoch 00051: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0588 - acc: 0.9808 - val_loss: 0.3083 - val_acc: 0.9387\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9806\n",
      "Epoch 00052: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0585 - acc: 0.9806 - val_loss: 0.3159 - val_acc: 0.9304\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9801\n",
      "Epoch 00053: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0605 - acc: 0.9801 - val_loss: 0.2848 - val_acc: 0.9376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9813\n",
      "Epoch 00054: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0572 - acc: 0.9813 - val_loss: 0.2970 - val_acc: 0.9392\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9806\n",
      "Epoch 00055: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0594 - acc: 0.9806 - val_loss: 0.2804 - val_acc: 0.9427\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9821\n",
      "Epoch 00056: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0538 - acc: 0.9821 - val_loss: 0.3236 - val_acc: 0.9383\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9822\n",
      "Epoch 00057: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0548 - acc: 0.9822 - val_loss: 0.3126 - val_acc: 0.9429\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9811\n",
      "Epoch 00058: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0597 - acc: 0.9811 - val_loss: 0.3202 - val_acc: 0.9352\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9842\n",
      "Epoch 00059: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0484 - acc: 0.9842 - val_loss: 0.3369 - val_acc: 0.9383\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9832\n",
      "Epoch 00060: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0538 - acc: 0.9832 - val_loss: 0.3228 - val_acc: 0.9406\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9814\n",
      "Epoch 00061: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0565 - acc: 0.9814 - val_loss: 0.2993 - val_acc: 0.9399\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9826\n",
      "Epoch 00062: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0521 - acc: 0.9826 - val_loss: 0.3145 - val_acc: 0.9406\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9837\n",
      "Epoch 00063: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0473 - acc: 0.9838 - val_loss: 0.3034 - val_acc: 0.9422\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9847\n",
      "Epoch 00064: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0477 - acc: 0.9847 - val_loss: 0.2916 - val_acc: 0.9413\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9826\n",
      "Epoch 00065: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0540 - acc: 0.9826 - val_loss: 0.2827 - val_acc: 0.9422\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9856\n",
      "Epoch 00066: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0450 - acc: 0.9856 - val_loss: 0.3230 - val_acc: 0.9383\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9835\n",
      "Epoch 00067: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0491 - acc: 0.9835 - val_loss: 0.2968 - val_acc: 0.9399\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9848\n",
      "Epoch 00068: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0469 - acc: 0.9848 - val_loss: 0.3052 - val_acc: 0.9399\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9853\n",
      "Epoch 00069: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0456 - acc: 0.9853 - val_loss: 0.3372 - val_acc: 0.9366\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9859\n",
      "Epoch 00070: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0434 - acc: 0.9859 - val_loss: 0.3312 - val_acc: 0.9359\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9851\n",
      "Epoch 00071: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0447 - acc: 0.9851 - val_loss: 0.3098 - val_acc: 0.9397\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9826\n",
      "Epoch 00072: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0543 - acc: 0.9826 - val_loss: 0.3196 - val_acc: 0.9422\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9852\n",
      "Epoch 00073: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0441 - acc: 0.9852 - val_loss: 0.3270 - val_acc: 0.9378\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9871\n",
      "Epoch 00074: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0400 - acc: 0.9871 - val_loss: 0.3365 - val_acc: 0.9399\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9868\n",
      "Epoch 00075: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0415 - acc: 0.9868 - val_loss: 0.3050 - val_acc: 0.9462\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9870\n",
      "Epoch 00076: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0417 - acc: 0.9870 - val_loss: 0.3340 - val_acc: 0.9373\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9866\n",
      "Epoch 00077: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0425 - acc: 0.9866 - val_loss: 0.3419 - val_acc: 0.9427\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9867\n",
      "Epoch 00078: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0403 - acc: 0.9867 - val_loss: 0.3129 - val_acc: 0.9415\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9870\n",
      "Epoch 00079: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0389 - acc: 0.9870 - val_loss: 0.3166 - val_acc: 0.9427\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9864\n",
      "Epoch 00080: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0421 - acc: 0.9864 - val_loss: 0.2992 - val_acc: 0.9394\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9875\n",
      "Epoch 00081: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0383 - acc: 0.9875 - val_loss: 0.3146 - val_acc: 0.9406\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9867\n",
      "Epoch 00082: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0389 - acc: 0.9867 - val_loss: 0.3111 - val_acc: 0.9453\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9870\n",
      "Epoch 00083: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0408 - acc: 0.9870 - val_loss: 0.3407 - val_acc: 0.9411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9890\n",
      "Epoch 00084: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0341 - acc: 0.9890 - val_loss: 0.3150 - val_acc: 0.9427\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9868\n",
      "Epoch 00085: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0401 - acc: 0.9868 - val_loss: 0.3345 - val_acc: 0.9413\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9892\n",
      "Epoch 00086: val_loss did not improve from 0.24618\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0327 - acc: 0.9892 - val_loss: 0.3488 - val_acc: 0.9387\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 981us/sample - loss: 0.3056 - acc: 0.9225\n",
      "Loss: 0.3056400315598164 Accuracy: 0.92253375\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3085 - acc: 0.2393\n",
      "Epoch 00001: val_loss improved from inf to 1.65231, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/001-1.6523.hdf5\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 2.3086 - acc: 0.2393 - val_loss: 1.6523 - val_acc: 0.4929\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5534 - acc: 0.4916\n",
      "Epoch 00002: val_loss improved from 1.65231 to 1.17613, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/002-1.1761.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 1.5532 - acc: 0.4916 - val_loss: 1.1761 - val_acc: 0.6322\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2292 - acc: 0.5989\n",
      "Epoch 00003: val_loss improved from 1.17613 to 0.94740, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/003-0.9474.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 1.2292 - acc: 0.5989 - val_loss: 0.9474 - val_acc: 0.7035\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0153 - acc: 0.6785\n",
      "Epoch 00004: val_loss improved from 0.94740 to 0.75735, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/004-0.7574.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 1.0153 - acc: 0.6785 - val_loss: 0.7574 - val_acc: 0.7724\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8263 - acc: 0.7455\n",
      "Epoch 00005: val_loss improved from 0.75735 to 0.60548, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/005-0.6055.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.8263 - acc: 0.7455 - val_loss: 0.6055 - val_acc: 0.8269\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6815 - acc: 0.7931\n",
      "Epoch 00006: val_loss improved from 0.60548 to 0.49201, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/006-0.4920.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.6814 - acc: 0.7931 - val_loss: 0.4920 - val_acc: 0.8526\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5867 - acc: 0.8214\n",
      "Epoch 00007: val_loss improved from 0.49201 to 0.41600, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/007-0.4160.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.5867 - acc: 0.8214 - val_loss: 0.4160 - val_acc: 0.8847\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5033 - acc: 0.8468\n",
      "Epoch 00008: val_loss improved from 0.41600 to 0.36021, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/008-0.3602.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.5033 - acc: 0.8468 - val_loss: 0.3602 - val_acc: 0.9017\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4571 - acc: 0.8597\n",
      "Epoch 00009: val_loss improved from 0.36021 to 0.35417, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/009-0.3542.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.4571 - acc: 0.8597 - val_loss: 0.3542 - val_acc: 0.8980\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4055 - acc: 0.8758\n",
      "Epoch 00010: val_loss improved from 0.35417 to 0.30010, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/010-0.3001.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.4054 - acc: 0.8758 - val_loss: 0.3001 - val_acc: 0.9182\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3748 - acc: 0.8866\n",
      "Epoch 00011: val_loss did not improve from 0.30010\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.3749 - acc: 0.8866 - val_loss: 0.3039 - val_acc: 0.9175\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3470 - acc: 0.8939\n",
      "Epoch 00012: val_loss improved from 0.30010 to 0.27569, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/012-0.2757.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.3469 - acc: 0.8940 - val_loss: 0.2757 - val_acc: 0.9234\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3230 - acc: 0.9002\n",
      "Epoch 00013: val_loss improved from 0.27569 to 0.26417, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/013-0.2642.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.3231 - acc: 0.9002 - val_loss: 0.2642 - val_acc: 0.9294\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3082 - acc: 0.9053\n",
      "Epoch 00014: val_loss improved from 0.26417 to 0.24884, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/014-0.2488.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.3082 - acc: 0.9053 - val_loss: 0.2488 - val_acc: 0.9315\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2794 - acc: 0.9123\n",
      "Epoch 00015: val_loss improved from 0.24884 to 0.23617, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/015-0.2362.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2793 - acc: 0.9123 - val_loss: 0.2362 - val_acc: 0.9352\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9143\n",
      "Epoch 00016: val_loss did not improve from 0.23617\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2707 - acc: 0.9143 - val_loss: 0.2554 - val_acc: 0.9262\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2557 - acc: 0.9201\n",
      "Epoch 00017: val_loss improved from 0.23617 to 0.22014, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/017-0.2201.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2556 - acc: 0.9201 - val_loss: 0.2201 - val_acc: 0.9390\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2379 - acc: 0.9251\n",
      "Epoch 00018: val_loss improved from 0.22014 to 0.20941, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/018-0.2094.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2379 - acc: 0.9251 - val_loss: 0.2094 - val_acc: 0.9406\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2294 - acc: 0.9282\n",
      "Epoch 00019: val_loss did not improve from 0.20941\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2293 - acc: 0.9282 - val_loss: 0.2380 - val_acc: 0.9362\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2198 - acc: 0.9306\n",
      "Epoch 00020: val_loss did not improve from 0.20941\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2199 - acc: 0.9306 - val_loss: 0.2202 - val_acc: 0.9394\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2041 - acc: 0.9351\n",
      "Epoch 00021: val_loss did not improve from 0.20941\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2041 - acc: 0.9351 - val_loss: 0.2258 - val_acc: 0.9390\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9361\n",
      "Epoch 00022: val_loss improved from 0.20941 to 0.20904, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/022-0.2090.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.2021 - acc: 0.9361 - val_loss: 0.2090 - val_acc: 0.9427\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1883 - acc: 0.9386\n",
      "Epoch 00023: val_loss improved from 0.20904 to 0.20627, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/023-0.2063.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1883 - acc: 0.9386 - val_loss: 0.2063 - val_acc: 0.9418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9413\n",
      "Epoch 00024: val_loss improved from 0.20627 to 0.20354, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/024-0.2035.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1819 - acc: 0.9413 - val_loss: 0.2035 - val_acc: 0.9415\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1774 - acc: 0.9422\n",
      "Epoch 00025: val_loss did not improve from 0.20354\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1774 - acc: 0.9422 - val_loss: 0.2103 - val_acc: 0.9434\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1687 - acc: 0.9457\n",
      "Epoch 00026: val_loss improved from 0.20354 to 0.19926, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/026-0.1993.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1686 - acc: 0.9457 - val_loss: 0.1993 - val_acc: 0.9467\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9483\n",
      "Epoch 00027: val_loss did not improve from 0.19926\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1592 - acc: 0.9482 - val_loss: 0.2018 - val_acc: 0.9434\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1586 - acc: 0.9482\n",
      "Epoch 00028: val_loss improved from 0.19926 to 0.19676, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/028-0.1968.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1586 - acc: 0.9482 - val_loss: 0.1968 - val_acc: 0.9462\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9502\n",
      "Epoch 00029: val_loss improved from 0.19676 to 0.19503, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/029-0.1950.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1515 - acc: 0.9502 - val_loss: 0.1950 - val_acc: 0.9464\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9520\n",
      "Epoch 00030: val_loss improved from 0.19503 to 0.19343, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/030-0.1934.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1503 - acc: 0.9520 - val_loss: 0.1934 - val_acc: 0.9509\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9520\n",
      "Epoch 00031: val_loss did not improve from 0.19343\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1462 - acc: 0.9520 - val_loss: 0.2105 - val_acc: 0.9415\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9551\n",
      "Epoch 00032: val_loss did not improve from 0.19343\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1367 - acc: 0.9551 - val_loss: 0.2077 - val_acc: 0.9481\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9558\n",
      "Epoch 00033: val_loss did not improve from 0.19343\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1386 - acc: 0.9558 - val_loss: 0.1951 - val_acc: 0.9495\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9568\n",
      "Epoch 00034: val_loss did not improve from 0.19343\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1277 - acc: 0.9568 - val_loss: 0.1955 - val_acc: 0.9490\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9582\n",
      "Epoch 00035: val_loss improved from 0.19343 to 0.19173, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/035-0.1917.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1233 - acc: 0.9582 - val_loss: 0.1917 - val_acc: 0.9492\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9567\n",
      "Epoch 00036: val_loss improved from 0.19173 to 0.18272, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/036-0.1827.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1287 - acc: 0.9566 - val_loss: 0.1827 - val_acc: 0.9509\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9614\n",
      "Epoch 00037: val_loss did not improve from 0.18272\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.1171 - acc: 0.9614 - val_loss: 0.1914 - val_acc: 0.9499\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9601\n",
      "Epoch 00038: val_loss did not improve from 0.18272\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1218 - acc: 0.9601 - val_loss: 0.1896 - val_acc: 0.9467\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9621\n",
      "Epoch 00039: val_loss did not improve from 0.18272\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.1138 - acc: 0.9621 - val_loss: 0.1898 - val_acc: 0.9506\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9627\n",
      "Epoch 00040: val_loss improved from 0.18272 to 0.18144, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_7_conv_checkpoint/040-0.1814.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.1096 - acc: 0.9627 - val_loss: 0.1814 - val_acc: 0.9532\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9654\n",
      "Epoch 00041: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1021 - acc: 0.9654 - val_loss: 0.1905 - val_acc: 0.9532\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9639\n",
      "Epoch 00042: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.1086 - acc: 0.9639 - val_loss: 0.2263 - val_acc: 0.9490\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9655\n",
      "Epoch 00043: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.1015 - acc: 0.9655 - val_loss: 0.1850 - val_acc: 0.9553\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9658\n",
      "Epoch 00044: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.1025 - acc: 0.9658 - val_loss: 0.1968 - val_acc: 0.9515\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9670\n",
      "Epoch 00045: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.1009 - acc: 0.9670 - val_loss: 0.2330 - val_acc: 0.9439\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9684\n",
      "Epoch 00046: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0957 - acc: 0.9684 - val_loss: 0.2064 - val_acc: 0.9513\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9671\n",
      "Epoch 00047: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0997 - acc: 0.9671 - val_loss: 0.2081 - val_acc: 0.9515\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9694\n",
      "Epoch 00048: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0902 - acc: 0.9694 - val_loss: 0.2189 - val_acc: 0.9495\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9701\n",
      "Epoch 00049: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0901 - acc: 0.9701 - val_loss: 0.2097 - val_acc: 0.9464\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9694\n",
      "Epoch 00050: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0900 - acc: 0.9694 - val_loss: 0.1937 - val_acc: 0.9509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9711\n",
      "Epoch 00051: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0847 - acc: 0.9711 - val_loss: 0.1827 - val_acc: 0.9550\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9705\n",
      "Epoch 00052: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0887 - acc: 0.9705 - val_loss: 0.1848 - val_acc: 0.9539\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9704\n",
      "Epoch 00053: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0858 - acc: 0.9704 - val_loss: 0.1970 - val_acc: 0.9502\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9728\n",
      "Epoch 00054: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0802 - acc: 0.9728 - val_loss: 0.2014 - val_acc: 0.9532\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9740\n",
      "Epoch 00055: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0792 - acc: 0.9740 - val_loss: 0.2376 - val_acc: 0.9450\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9688\n",
      "Epoch 00056: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0926 - acc: 0.9688 - val_loss: 0.2025 - val_acc: 0.9504\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9752\n",
      "Epoch 00057: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0751 - acc: 0.9752 - val_loss: 0.1998 - val_acc: 0.9543\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9746\n",
      "Epoch 00058: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0757 - acc: 0.9746 - val_loss: 0.2117 - val_acc: 0.9525\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9748\n",
      "Epoch 00059: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0737 - acc: 0.9748 - val_loss: 0.1895 - val_acc: 0.9574\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9754\n",
      "Epoch 00060: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0745 - acc: 0.9754 - val_loss: 0.1961 - val_acc: 0.9520\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9748\n",
      "Epoch 00061: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0744 - acc: 0.9748 - val_loss: 0.1917 - val_acc: 0.9532\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9750\n",
      "Epoch 00062: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0729 - acc: 0.9749 - val_loss: 0.2118 - val_acc: 0.9543\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9762\n",
      "Epoch 00063: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0706 - acc: 0.9762 - val_loss: 0.1897 - val_acc: 0.9585\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9766\n",
      "Epoch 00064: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0694 - acc: 0.9766 - val_loss: 0.2192 - val_acc: 0.9534\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9776\n",
      "Epoch 00065: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0665 - acc: 0.9776 - val_loss: 0.1823 - val_acc: 0.9583\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9746\n",
      "Epoch 00066: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0751 - acc: 0.9746 - val_loss: 0.1905 - val_acc: 0.9546\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9771\n",
      "Epoch 00067: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0672 - acc: 0.9771 - val_loss: 0.1952 - val_acc: 0.9571\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9795\n",
      "Epoch 00068: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0623 - acc: 0.9795 - val_loss: 0.2172 - val_acc: 0.9539\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9791\n",
      "Epoch 00069: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0626 - acc: 0.9791 - val_loss: 0.2171 - val_acc: 0.9562\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9789\n",
      "Epoch 00070: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0640 - acc: 0.9789 - val_loss: 0.2199 - val_acc: 0.9539\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9785\n",
      "Epoch 00071: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0643 - acc: 0.9785 - val_loss: 0.2078 - val_acc: 0.9534\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9798\n",
      "Epoch 00072: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0599 - acc: 0.9798 - val_loss: 0.1965 - val_acc: 0.9569\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9804\n",
      "Epoch 00073: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0583 - acc: 0.9804 - val_loss: 0.2303 - val_acc: 0.9557\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9796\n",
      "Epoch 00074: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0625 - acc: 0.9796 - val_loss: 0.1912 - val_acc: 0.9576\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9793\n",
      "Epoch 00075: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0583 - acc: 0.9793 - val_loss: 0.2338 - val_acc: 0.9511\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9801\n",
      "Epoch 00076: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0573 - acc: 0.9801 - val_loss: 0.2298 - val_acc: 0.9541\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9810\n",
      "Epoch 00077: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0562 - acc: 0.9810 - val_loss: 0.2254 - val_acc: 0.9592\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9792\n",
      "Epoch 00078: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0620 - acc: 0.9792 - val_loss: 0.2111 - val_acc: 0.9536\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9796\n",
      "Epoch 00079: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0631 - acc: 0.9796 - val_loss: 0.2157 - val_acc: 0.9574\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9818\n",
      "Epoch 00080: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0521 - acc: 0.9818 - val_loss: 0.2358 - val_acc: 0.9497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9799\n",
      "Epoch 00081: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0589 - acc: 0.9799 - val_loss: 0.2053 - val_acc: 0.9599\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9822\n",
      "Epoch 00082: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0540 - acc: 0.9822 - val_loss: 0.2279 - val_acc: 0.9529\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9811\n",
      "Epoch 00083: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0543 - acc: 0.9811 - val_loss: 0.2301 - val_acc: 0.9536\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9804\n",
      "Epoch 00084: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0590 - acc: 0.9804 - val_loss: 0.2158 - val_acc: 0.9536\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9843\n",
      "Epoch 00085: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0461 - acc: 0.9843 - val_loss: 0.2353 - val_acc: 0.9546\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9832\n",
      "Epoch 00086: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0516 - acc: 0.9831 - val_loss: 0.2209 - val_acc: 0.9569\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9830\n",
      "Epoch 00087: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0518 - acc: 0.9830 - val_loss: 0.2237 - val_acc: 0.9564\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9833\n",
      "Epoch 00088: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0503 - acc: 0.9833 - val_loss: 0.2449 - val_acc: 0.9525\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9835\n",
      "Epoch 00089: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0491 - acc: 0.9835 - val_loss: 0.2461 - val_acc: 0.9557\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9821\n",
      "Epoch 00090: val_loss did not improve from 0.18144\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0528 - acc: 0.9821 - val_loss: 0.2211 - val_acc: 0.9571\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 991us/sample - loss: 0.2434 - acc: 0.9350\n",
      "Loss: 0.24343668199216836 Accuracy: 0.9349948\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4067 - acc: 0.2063\n",
      "Epoch 00001: val_loss improved from inf to 1.65650, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/001-1.6565.hdf5\n",
      "36805/36805 [==============================] - 176s 5ms/sample - loss: 2.4066 - acc: 0.2063 - val_loss: 1.6565 - val_acc: 0.4635\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5291 - acc: 0.5011\n",
      "Epoch 00002: val_loss improved from 1.65650 to 1.00675, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/002-1.0068.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 1.5291 - acc: 0.5011 - val_loss: 1.0068 - val_acc: 0.6879\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1177 - acc: 0.6393\n",
      "Epoch 00003: val_loss improved from 1.00675 to 0.76349, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/003-0.7635.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 1.1177 - acc: 0.6393 - val_loss: 0.7635 - val_acc: 0.7589\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8931 - acc: 0.7152\n",
      "Epoch 00004: val_loss improved from 0.76349 to 0.63492, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/004-0.6349.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.8931 - acc: 0.7152 - val_loss: 0.6349 - val_acc: 0.8111\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7388 - acc: 0.7681\n",
      "Epoch 00005: val_loss improved from 0.63492 to 0.46760, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/005-0.4676.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.7387 - acc: 0.7681 - val_loss: 0.4676 - val_acc: 0.8649\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6232 - acc: 0.8044\n",
      "Epoch 00006: val_loss improved from 0.46760 to 0.40833, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/006-0.4083.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.6232 - acc: 0.8044 - val_loss: 0.4083 - val_acc: 0.8768\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5502 - acc: 0.8279\n",
      "Epoch 00007: val_loss improved from 0.40833 to 0.36993, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/007-0.3699.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.5501 - acc: 0.8279 - val_loss: 0.3699 - val_acc: 0.8873\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4812 - acc: 0.8487\n",
      "Epoch 00008: val_loss improved from 0.36993 to 0.31066, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/008-0.3107.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.4812 - acc: 0.8488 - val_loss: 0.3107 - val_acc: 0.9054\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4441 - acc: 0.8630\n",
      "Epoch 00009: val_loss improved from 0.31066 to 0.28185, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/009-0.2818.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.4442 - acc: 0.8630 - val_loss: 0.2818 - val_acc: 0.9180\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4028 - acc: 0.8739\n",
      "Epoch 00010: val_loss improved from 0.28185 to 0.24147, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/010-0.2415.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.4029 - acc: 0.8739 - val_loss: 0.2415 - val_acc: 0.9315\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3700 - acc: 0.8835\n",
      "Epoch 00011: val_loss improved from 0.24147 to 0.23168, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/011-0.2317.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.3700 - acc: 0.8835 - val_loss: 0.2317 - val_acc: 0.9338\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3432 - acc: 0.8931\n",
      "Epoch 00012: val_loss improved from 0.23168 to 0.22543, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/012-0.2254.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.3432 - acc: 0.8931 - val_loss: 0.2254 - val_acc: 0.9334\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3203 - acc: 0.9011\n",
      "Epoch 00013: val_loss improved from 0.22543 to 0.22230, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/013-0.2223.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.3203 - acc: 0.9011 - val_loss: 0.2223 - val_acc: 0.9373\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2979 - acc: 0.9076\n",
      "Epoch 00014: val_loss improved from 0.22230 to 0.20324, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/014-0.2032.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2980 - acc: 0.9075 - val_loss: 0.2032 - val_acc: 0.9408\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2896 - acc: 0.9100\n",
      "Epoch 00015: val_loss improved from 0.20324 to 0.20172, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/015-0.2017.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2896 - acc: 0.9100 - val_loss: 0.2017 - val_acc: 0.9411\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2693 - acc: 0.9163\n",
      "Epoch 00016: val_loss did not improve from 0.20172\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2694 - acc: 0.9163 - val_loss: 0.2209 - val_acc: 0.9362\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2569 - acc: 0.9185\n",
      "Epoch 00017: val_loss improved from 0.20172 to 0.18529, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/017-0.1853.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2569 - acc: 0.9185 - val_loss: 0.1853 - val_acc: 0.9420\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2384 - acc: 0.9243\n",
      "Epoch 00018: val_loss did not improve from 0.18529\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2384 - acc: 0.9243 - val_loss: 0.1907 - val_acc: 0.9429\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2330 - acc: 0.9259\n",
      "Epoch 00019: val_loss did not improve from 0.18529\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2331 - acc: 0.9259 - val_loss: 0.1906 - val_acc: 0.9460\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2252 - acc: 0.9270\n",
      "Epoch 00020: val_loss improved from 0.18529 to 0.18486, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/020-0.1849.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2252 - acc: 0.9270 - val_loss: 0.1849 - val_acc: 0.9420\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9319\n",
      "Epoch 00021: val_loss improved from 0.18486 to 0.17784, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/021-0.1778.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2135 - acc: 0.9319 - val_loss: 0.1778 - val_acc: 0.9483\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2066 - acc: 0.9335\n",
      "Epoch 00022: val_loss improved from 0.17784 to 0.17660, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/022-0.1766.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.2066 - acc: 0.9335 - val_loss: 0.1766 - val_acc: 0.9492\n",
      "Epoch 23/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1991 - acc: 0.9369\n",
      "Epoch 00023: val_loss improved from 0.17660 to 0.15241, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/023-0.1524.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1991 - acc: 0.9369 - val_loss: 0.1524 - val_acc: 0.9499\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1927 - acc: 0.9389\n",
      "Epoch 00024: val_loss did not improve from 0.15241\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1927 - acc: 0.9389 - val_loss: 0.1561 - val_acc: 0.9527\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9396\n",
      "Epoch 00025: val_loss improved from 0.15241 to 0.14965, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/025-0.1497.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1860 - acc: 0.9396 - val_loss: 0.1497 - val_acc: 0.9527\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1788 - acc: 0.9417\n",
      "Epoch 00026: val_loss did not improve from 0.14965\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1788 - acc: 0.9417 - val_loss: 0.1562 - val_acc: 0.9532\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1673 - acc: 0.9457\n",
      "Epoch 00027: val_loss did not improve from 0.14965\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1673 - acc: 0.9457 - val_loss: 0.1627 - val_acc: 0.9541\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1650 - acc: 0.9475\n",
      "Epoch 00028: val_loss did not improve from 0.14965\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1650 - acc: 0.9475 - val_loss: 0.1545 - val_acc: 0.9562\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9474\n",
      "Epoch 00029: val_loss improved from 0.14965 to 0.14854, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/029-0.1485.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1622 - acc: 0.9474 - val_loss: 0.1485 - val_acc: 0.9571\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1544 - acc: 0.9498\n",
      "Epoch 00030: val_loss did not improve from 0.14854\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1544 - acc: 0.9498 - val_loss: 0.1583 - val_acc: 0.9548\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9508\n",
      "Epoch 00031: val_loss improved from 0.14854 to 0.14745, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/031-0.1474.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1547 - acc: 0.9508 - val_loss: 0.1474 - val_acc: 0.9564\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1495 - acc: 0.9510\n",
      "Epoch 00032: val_loss did not improve from 0.14745\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1495 - acc: 0.9510 - val_loss: 0.1625 - val_acc: 0.9529\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9515\n",
      "Epoch 00033: val_loss did not improve from 0.14745\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1499 - acc: 0.9516 - val_loss: 0.1535 - val_acc: 0.9560\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1423 - acc: 0.9534\n",
      "Epoch 00034: val_loss did not improve from 0.14745\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1423 - acc: 0.9534 - val_loss: 0.1710 - val_acc: 0.9576\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9538\n",
      "Epoch 00035: val_loss did not improve from 0.14745\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1405 - acc: 0.9538 - val_loss: 0.2006 - val_acc: 0.9481\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9567\n",
      "Epoch 00036: val_loss did not improve from 0.14745\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1335 - acc: 0.9567 - val_loss: 0.1497 - val_acc: 0.9576\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9592\n",
      "Epoch 00037: val_loss did not improve from 0.14745\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1240 - acc: 0.9592 - val_loss: 0.1824 - val_acc: 0.9536\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9583\n",
      "Epoch 00038: val_loss did not improve from 0.14745\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1267 - acc: 0.9583 - val_loss: 0.1611 - val_acc: 0.9562\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1268 - acc: 0.9577\n",
      "Epoch 00039: val_loss did not improve from 0.14745\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1267 - acc: 0.9577 - val_loss: 0.1571 - val_acc: 0.9574\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9608\n",
      "Epoch 00040: val_loss did not improve from 0.14745\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1194 - acc: 0.9608 - val_loss: 0.1567 - val_acc: 0.9588\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9618\n",
      "Epoch 00041: val_loss improved from 0.14745 to 0.14727, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/041-0.1473.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1161 - acc: 0.9618 - val_loss: 0.1473 - val_acc: 0.9578\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9629\n",
      "Epoch 00042: val_loss improved from 0.14727 to 0.14240, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/042-0.1424.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1108 - acc: 0.9629 - val_loss: 0.1424 - val_acc: 0.9613\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9639\n",
      "Epoch 00043: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1084 - acc: 0.9639 - val_loss: 0.1491 - val_acc: 0.9597\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9630\n",
      "Epoch 00044: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1127 - acc: 0.9630 - val_loss: 0.1643 - val_acc: 0.9557\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9630\n",
      "Epoch 00045: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1120 - acc: 0.9630 - val_loss: 0.1474 - val_acc: 0.9592\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9651\n",
      "Epoch 00046: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1028 - acc: 0.9651 - val_loss: 0.1542 - val_acc: 0.9581\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9650\n",
      "Epoch 00047: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1064 - acc: 0.9650 - val_loss: 0.1528 - val_acc: 0.9590\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9667\n",
      "Epoch 00048: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1009 - acc: 0.9667 - val_loss: 0.1496 - val_acc: 0.9602\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9671\n",
      "Epoch 00049: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0991 - acc: 0.9671 - val_loss: 0.1477 - val_acc: 0.9618\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9670\n",
      "Epoch 00050: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0997 - acc: 0.9670 - val_loss: 0.1551 - val_acc: 0.9569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9681\n",
      "Epoch 00051: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0965 - acc: 0.9681 - val_loss: 0.1849 - val_acc: 0.9504\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9680\n",
      "Epoch 00052: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0957 - acc: 0.9680 - val_loss: 0.1457 - val_acc: 0.9597\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9693\n",
      "Epoch 00053: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0913 - acc: 0.9693 - val_loss: 0.1688 - val_acc: 0.9564\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9697\n",
      "Epoch 00054: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0899 - acc: 0.9697 - val_loss: 0.1465 - val_acc: 0.9613\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9717\n",
      "Epoch 00055: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0840 - acc: 0.9717 - val_loss: 0.1470 - val_acc: 0.9606\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9697\n",
      "Epoch 00056: val_loss did not improve from 0.14240\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0901 - acc: 0.9697 - val_loss: 0.1500 - val_acc: 0.9627\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9720\n",
      "Epoch 00057: val_loss improved from 0.14240 to 0.13903, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/057-0.1390.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0852 - acc: 0.9720 - val_loss: 0.1390 - val_acc: 0.9618\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9723\n",
      "Epoch 00058: val_loss did not improve from 0.13903\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0818 - acc: 0.9723 - val_loss: 0.1446 - val_acc: 0.9630\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9722\n",
      "Epoch 00059: val_loss did not improve from 0.13903\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0805 - acc: 0.9722 - val_loss: 0.1469 - val_acc: 0.9613\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9741\n",
      "Epoch 00060: val_loss improved from 0.13903 to 0.13888, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_8_conv_checkpoint/060-0.1389.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0757 - acc: 0.9741 - val_loss: 0.1389 - val_acc: 0.9637\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9725\n",
      "Epoch 00061: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0825 - acc: 0.9725 - val_loss: 0.1532 - val_acc: 0.9632\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9752\n",
      "Epoch 00062: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0765 - acc: 0.9752 - val_loss: 0.1801 - val_acc: 0.9578\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9747\n",
      "Epoch 00063: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0765 - acc: 0.9747 - val_loss: 0.1463 - val_acc: 0.9632\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9754\n",
      "Epoch 00064: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0758 - acc: 0.9754 - val_loss: 0.1440 - val_acc: 0.9648\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9744\n",
      "Epoch 00065: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0756 - acc: 0.9744 - val_loss: 0.1573 - val_acc: 0.9618\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9744\n",
      "Epoch 00066: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0757 - acc: 0.9744 - val_loss: 0.1718 - val_acc: 0.9595\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9761\n",
      "Epoch 00067: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0727 - acc: 0.9761 - val_loss: 0.1493 - val_acc: 0.9641\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9769\n",
      "Epoch 00068: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0690 - acc: 0.9769 - val_loss: 0.1660 - val_acc: 0.9618\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9776\n",
      "Epoch 00069: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0693 - acc: 0.9776 - val_loss: 0.1592 - val_acc: 0.9611\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9770\n",
      "Epoch 00070: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0659 - acc: 0.9770 - val_loss: 0.1577 - val_acc: 0.9644\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9779\n",
      "Epoch 00071: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0664 - acc: 0.9779 - val_loss: 0.1798 - val_acc: 0.9581\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9765\n",
      "Epoch 00072: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0685 - acc: 0.9765 - val_loss: 0.1520 - val_acc: 0.9632\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9796\n",
      "Epoch 00073: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0615 - acc: 0.9796 - val_loss: 0.1628 - val_acc: 0.9618\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9789\n",
      "Epoch 00074: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0648 - acc: 0.9789 - val_loss: 0.1892 - val_acc: 0.9571\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9792\n",
      "Epoch 00075: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0632 - acc: 0.9792 - val_loss: 0.1543 - val_acc: 0.9646\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9779\n",
      "Epoch 00076: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0646 - acc: 0.9779 - val_loss: 0.1733 - val_acc: 0.9651\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9794\n",
      "Epoch 00077: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0595 - acc: 0.9794 - val_loss: 0.1730 - val_acc: 0.9613\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9786\n",
      "Epoch 00078: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0610 - acc: 0.9786 - val_loss: 0.1679 - val_acc: 0.9613\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9793\n",
      "Epoch 00079: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0612 - acc: 0.9793 - val_loss: 0.1494 - val_acc: 0.9641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9812\n",
      "Epoch 00080: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0548 - acc: 0.9812 - val_loss: 0.1485 - val_acc: 0.9672\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9796\n",
      "Epoch 00081: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0626 - acc: 0.9796 - val_loss: 0.1532 - val_acc: 0.9630\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9816\n",
      "Epoch 00082: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0538 - acc: 0.9816 - val_loss: 0.1462 - val_acc: 0.9695\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9827\n",
      "Epoch 00083: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0533 - acc: 0.9827 - val_loss: 0.1526 - val_acc: 0.9658\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9807\n",
      "Epoch 00084: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0553 - acc: 0.9807 - val_loss: 0.1755 - val_acc: 0.9630\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9815\n",
      "Epoch 00085: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0559 - acc: 0.9816 - val_loss: 0.1858 - val_acc: 0.9616\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9821\n",
      "Epoch 00086: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0566 - acc: 0.9821 - val_loss: 0.1625 - val_acc: 0.9632\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9821\n",
      "Epoch 00087: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0549 - acc: 0.9821 - val_loss: 0.1632 - val_acc: 0.9630\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9812\n",
      "Epoch 00088: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0518 - acc: 0.9812 - val_loss: 0.1887 - val_acc: 0.9630\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9805\n",
      "Epoch 00089: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0576 - acc: 0.9805 - val_loss: 0.1669 - val_acc: 0.9658\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9833\n",
      "Epoch 00090: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0484 - acc: 0.9833 - val_loss: 0.1698 - val_acc: 0.9669\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9840\n",
      "Epoch 00091: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0470 - acc: 0.9840 - val_loss: 0.1794 - val_acc: 0.9630\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9828\n",
      "Epoch 00092: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0498 - acc: 0.9828 - val_loss: 0.1724 - val_acc: 0.9637\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9819\n",
      "Epoch 00093: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0532 - acc: 0.9819 - val_loss: 0.1550 - val_acc: 0.9674\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9838\n",
      "Epoch 00094: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0480 - acc: 0.9838 - val_loss: 0.1518 - val_acc: 0.9660\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9841\n",
      "Epoch 00095: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0485 - acc: 0.9841 - val_loss: 0.1723 - val_acc: 0.9669\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9841\n",
      "Epoch 00096: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0466 - acc: 0.9841 - val_loss: 0.1711 - val_acc: 0.9653\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9850\n",
      "Epoch 00097: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0449 - acc: 0.9850 - val_loss: 0.1763 - val_acc: 0.9616\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9847\n",
      "Epoch 00098: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0469 - acc: 0.9847 - val_loss: 0.1761 - val_acc: 0.9655\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9849\n",
      "Epoch 00099: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0460 - acc: 0.9849 - val_loss: 0.1768 - val_acc: 0.9634\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9847\n",
      "Epoch 00100: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0474 - acc: 0.9847 - val_loss: 0.1594 - val_acc: 0.9627\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9846\n",
      "Epoch 00101: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0465 - acc: 0.9846 - val_loss: 0.1631 - val_acc: 0.9667\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9843\n",
      "Epoch 00102: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0480 - acc: 0.9843 - val_loss: 0.1718 - val_acc: 0.9658\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9843\n",
      "Epoch 00103: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0478 - acc: 0.9843 - val_loss: 0.1765 - val_acc: 0.9641\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9870\n",
      "Epoch 00104: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0400 - acc: 0.9870 - val_loss: 0.1787 - val_acc: 0.9655\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9851\n",
      "Epoch 00105: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0449 - acc: 0.9851 - val_loss: 0.2143 - val_acc: 0.9602\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9819\n",
      "Epoch 00106: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0572 - acc: 0.9819 - val_loss: 0.1850 - val_acc: 0.9625\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9877\n",
      "Epoch 00107: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0373 - acc: 0.9877 - val_loss: 0.1838 - val_acc: 0.9667\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9872\n",
      "Epoch 00108: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0382 - acc: 0.9872 - val_loss: 0.1631 - val_acc: 0.9686\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9857\n",
      "Epoch 00109: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0407 - acc: 0.9857 - val_loss: 0.1908 - val_acc: 0.9625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9874\n",
      "Epoch 00110: val_loss did not improve from 0.13888\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0399 - acc: 0.9874 - val_loss: 0.1734 - val_acc: 0.9634\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1881 - acc: 0.9489\n",
      "Loss: 0.188122254530759 Accuracy: 0.94890964\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0013 - acc: 0.3451\n",
      "Epoch 00001: val_loss improved from inf to 1.08700, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/001-1.0870.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 2.0013 - acc: 0.3451 - val_loss: 1.0870 - val_acc: 0.6688\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0736 - acc: 0.6582\n",
      "Epoch 00002: val_loss improved from 1.08700 to 0.68875, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/002-0.6888.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 1.0736 - acc: 0.6582 - val_loss: 0.6888 - val_acc: 0.7980\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7792 - acc: 0.7567\n",
      "Epoch 00003: val_loss improved from 0.68875 to 0.49025, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/003-0.4903.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.7791 - acc: 0.7567 - val_loss: 0.4903 - val_acc: 0.8549\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6117 - acc: 0.8095\n",
      "Epoch 00004: val_loss improved from 0.49025 to 0.38056, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/004-0.3806.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.6118 - acc: 0.8095 - val_loss: 0.3806 - val_acc: 0.8824\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5066 - acc: 0.8429\n",
      "Epoch 00005: val_loss improved from 0.38056 to 0.32456, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/005-0.3246.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.5065 - acc: 0.8430 - val_loss: 0.3246 - val_acc: 0.9024\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4364 - acc: 0.8644\n",
      "Epoch 00006: val_loss improved from 0.32456 to 0.27512, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/006-0.2751.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.4364 - acc: 0.8644 - val_loss: 0.2751 - val_acc: 0.9185\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3880 - acc: 0.8792\n",
      "Epoch 00007: val_loss did not improve from 0.27512\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.3880 - acc: 0.8792 - val_loss: 0.2899 - val_acc: 0.9117\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3523 - acc: 0.8902\n",
      "Epoch 00008: val_loss did not improve from 0.27512\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.3523 - acc: 0.8902 - val_loss: 0.3660 - val_acc: 0.8819\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3384 - acc: 0.8950\n",
      "Epoch 00009: val_loss improved from 0.27512 to 0.21830, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/009-0.2183.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.3384 - acc: 0.8950 - val_loss: 0.2183 - val_acc: 0.9327\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3029 - acc: 0.9048\n",
      "Epoch 00010: val_loss improved from 0.21830 to 0.20286, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/010-0.2029.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.3029 - acc: 0.9048 - val_loss: 0.2029 - val_acc: 0.9369\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2805 - acc: 0.9131\n",
      "Epoch 00011: val_loss did not improve from 0.20286\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.2805 - acc: 0.9131 - val_loss: 0.2365 - val_acc: 0.9264\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2664 - acc: 0.9182\n",
      "Epoch 00012: val_loss did not improve from 0.20286\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.2664 - acc: 0.9182 - val_loss: 0.2126 - val_acc: 0.9334\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2459 - acc: 0.9220\n",
      "Epoch 00013: val_loss did not improve from 0.20286\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.2459 - acc: 0.9220 - val_loss: 0.2229 - val_acc: 0.9299\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2391 - acc: 0.9257\n",
      "Epoch 00014: val_loss improved from 0.20286 to 0.20034, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/014-0.2003.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.2391 - acc: 0.9256 - val_loss: 0.2003 - val_acc: 0.9401\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2227 - acc: 0.9287\n",
      "Epoch 00015: val_loss improved from 0.20034 to 0.16697, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/015-0.1670.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.2227 - acc: 0.9287 - val_loss: 0.1670 - val_acc: 0.9464\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2112 - acc: 0.9324\n",
      "Epoch 00016: val_loss did not improve from 0.16697\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.2112 - acc: 0.9325 - val_loss: 0.1724 - val_acc: 0.9448\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1985 - acc: 0.9357\n",
      "Epoch 00017: val_loss did not improve from 0.16697\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.1985 - acc: 0.9357 - val_loss: 0.1740 - val_acc: 0.9446\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1866 - acc: 0.9405\n",
      "Epoch 00018: val_loss improved from 0.16697 to 0.16318, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/018-0.1632.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.1866 - acc: 0.9406 - val_loss: 0.1632 - val_acc: 0.9455\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1838 - acc: 0.9404\n",
      "Epoch 00019: val_loss improved from 0.16318 to 0.15501, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/019-0.1550.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.1838 - acc: 0.9404 - val_loss: 0.1550 - val_acc: 0.9525\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1708 - acc: 0.9450\n",
      "Epoch 00020: val_loss did not improve from 0.15501\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.1708 - acc: 0.9450 - val_loss: 0.1589 - val_acc: 0.9529\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1588 - acc: 0.9491\n",
      "Epoch 00021: val_loss did not improve from 0.15501\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1589 - acc: 0.9491 - val_loss: 0.1846 - val_acc: 0.9413\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1637 - acc: 0.9475\n",
      "Epoch 00022: val_loss improved from 0.15501 to 0.15246, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/022-0.1525.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.1637 - acc: 0.9475 - val_loss: 0.1525 - val_acc: 0.9543\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9526\n",
      "Epoch 00023: val_loss did not improve from 0.15246\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1474 - acc: 0.9526 - val_loss: 0.1535 - val_acc: 0.9529\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9525\n",
      "Epoch 00024: val_loss did not improve from 0.15246\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1447 - acc: 0.9525 - val_loss: 0.1735 - val_acc: 0.9504\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9538\n",
      "Epoch 00025: val_loss did not improve from 0.15246\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1413 - acc: 0.9538 - val_loss: 0.1558 - val_acc: 0.9562\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1327 - acc: 0.9565\n",
      "Epoch 00026: val_loss did not improve from 0.15246\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1327 - acc: 0.9564 - val_loss: 0.1547 - val_acc: 0.9567\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9578\n",
      "Epoch 00027: val_loss did not improve from 0.15246\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1279 - acc: 0.9578 - val_loss: 0.1649 - val_acc: 0.9520\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9589\n",
      "Epoch 00028: val_loss did not improve from 0.15246\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1237 - acc: 0.9589 - val_loss: 0.1609 - val_acc: 0.9546\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9604\n",
      "Epoch 00029: val_loss did not improve from 0.15246\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1203 - acc: 0.9604 - val_loss: 0.1693 - val_acc: 0.9567\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9630\n",
      "Epoch 00030: val_loss did not improve from 0.15246\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1139 - acc: 0.9630 - val_loss: 0.1655 - val_acc: 0.9534\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9647\n",
      "Epoch 00031: val_loss improved from 0.15246 to 0.15142, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/031-0.1514.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1075 - acc: 0.9647 - val_loss: 0.1514 - val_acc: 0.9555\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9642\n",
      "Epoch 00032: val_loss did not improve from 0.15142\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1090 - acc: 0.9642 - val_loss: 0.1641 - val_acc: 0.9569\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9679\n",
      "Epoch 00033: val_loss did not improve from 0.15142\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0981 - acc: 0.9679 - val_loss: 0.1597 - val_acc: 0.9571\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9675\n",
      "Epoch 00034: val_loss improved from 0.15142 to 0.14500, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/034-0.1450.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1004 - acc: 0.9675 - val_loss: 0.1450 - val_acc: 0.9604\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9673\n",
      "Epoch 00035: val_loss did not improve from 0.14500\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0982 - acc: 0.9673 - val_loss: 0.1482 - val_acc: 0.9613\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9678\n",
      "Epoch 00036: val_loss improved from 0.14500 to 0.13928, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_9_conv_checkpoint/036-0.1393.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0988 - acc: 0.9677 - val_loss: 0.1393 - val_acc: 0.9609\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9680\n",
      "Epoch 00037: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0962 - acc: 0.9680 - val_loss: 0.1594 - val_acc: 0.9560\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9723\n",
      "Epoch 00038: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0816 - acc: 0.9723 - val_loss: 0.1770 - val_acc: 0.9583\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9706\n",
      "Epoch 00039: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0911 - acc: 0.9706 - val_loss: 0.1638 - val_acc: 0.9567\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9717\n",
      "Epoch 00040: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0862 - acc: 0.9717 - val_loss: 0.1467 - val_acc: 0.9625\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9734\n",
      "Epoch 00041: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0793 - acc: 0.9734 - val_loss: 0.1664 - val_acc: 0.9588\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9729\n",
      "Epoch 00042: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0807 - acc: 0.9729 - val_loss: 0.1747 - val_acc: 0.9597\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9744\n",
      "Epoch 00043: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0799 - acc: 0.9744 - val_loss: 0.1880 - val_acc: 0.9564\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9752\n",
      "Epoch 00044: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0751 - acc: 0.9752 - val_loss: 0.1665 - val_acc: 0.9616\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9734\n",
      "Epoch 00045: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0784 - acc: 0.9734 - val_loss: 0.1741 - val_acc: 0.9576\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9767\n",
      "Epoch 00046: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0707 - acc: 0.9767 - val_loss: 0.1736 - val_acc: 0.9560\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9749\n",
      "Epoch 00047: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0736 - acc: 0.9749 - val_loss: 0.1616 - val_acc: 0.9585\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9761\n",
      "Epoch 00048: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0725 - acc: 0.9761 - val_loss: 0.1659 - val_acc: 0.9613\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9765\n",
      "Epoch 00049: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0704 - acc: 0.9765 - val_loss: 0.1760 - val_acc: 0.9574\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9780\n",
      "Epoch 00050: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0644 - acc: 0.9780 - val_loss: 0.1476 - val_acc: 0.9658\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9760\n",
      "Epoch 00051: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0725 - acc: 0.9759 - val_loss: 0.1553 - val_acc: 0.9599\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9752\n",
      "Epoch 00052: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0747 - acc: 0.9752 - val_loss: 0.1631 - val_acc: 0.9604\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9800\n",
      "Epoch 00053: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0597 - acc: 0.9800 - val_loss: 0.1671 - val_acc: 0.9620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9792\n",
      "Epoch 00054: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0631 - acc: 0.9792 - val_loss: 0.1671 - val_acc: 0.9620\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9798\n",
      "Epoch 00055: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0616 - acc: 0.9798 - val_loss: 0.1608 - val_acc: 0.9660\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9797\n",
      "Epoch 00056: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0596 - acc: 0.9797 - val_loss: 0.1697 - val_acc: 0.9653\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9807\n",
      "Epoch 00057: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0583 - acc: 0.9807 - val_loss: 0.1751 - val_acc: 0.9618\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9818\n",
      "Epoch 00058: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0549 - acc: 0.9818 - val_loss: 0.2086 - val_acc: 0.9571\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9783\n",
      "Epoch 00059: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0634 - acc: 0.9783 - val_loss: 0.1903 - val_acc: 0.9609\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9816\n",
      "Epoch 00060: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0519 - acc: 0.9816 - val_loss: 0.1583 - val_acc: 0.9648\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9805\n",
      "Epoch 00061: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0592 - acc: 0.9805 - val_loss: 0.1918 - val_acc: 0.9585\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9807\n",
      "Epoch 00062: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0564 - acc: 0.9807 - val_loss: 0.1514 - val_acc: 0.9644\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9840\n",
      "Epoch 00063: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0479 - acc: 0.9840 - val_loss: 0.1798 - val_acc: 0.9667\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9835\n",
      "Epoch 00064: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0521 - acc: 0.9835 - val_loss: 0.1901 - val_acc: 0.9630\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9846\n",
      "Epoch 00065: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0473 - acc: 0.9846 - val_loss: 0.1918 - val_acc: 0.9606\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9827\n",
      "Epoch 00066: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0525 - acc: 0.9827 - val_loss: 0.2009 - val_acc: 0.9592\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9833\n",
      "Epoch 00067: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0509 - acc: 0.9833 - val_loss: 0.1599 - val_acc: 0.9646\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9846\n",
      "Epoch 00068: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0471 - acc: 0.9846 - val_loss: 0.1946 - val_acc: 0.9602\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9837\n",
      "Epoch 00069: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0486 - acc: 0.9837 - val_loss: 0.1991 - val_acc: 0.9611\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9826\n",
      "Epoch 00070: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0516 - acc: 0.9826 - val_loss: 0.1728 - val_acc: 0.9618\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9854\n",
      "Epoch 00071: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0435 - acc: 0.9854 - val_loss: 0.2065 - val_acc: 0.9606\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9866\n",
      "Epoch 00072: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0414 - acc: 0.9866 - val_loss: 0.1853 - val_acc: 0.9639\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9853\n",
      "Epoch 00073: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0446 - acc: 0.9853 - val_loss: 0.2079 - val_acc: 0.9604\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9841\n",
      "Epoch 00074: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0485 - acc: 0.9841 - val_loss: 0.1950 - val_acc: 0.9618\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9859\n",
      "Epoch 00075: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0419 - acc: 0.9859 - val_loss: 0.1859 - val_acc: 0.9616\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9855\n",
      "Epoch 00076: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0433 - acc: 0.9855 - val_loss: 0.2099 - val_acc: 0.9602\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9848\n",
      "Epoch 00077: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0452 - acc: 0.9848 - val_loss: 0.1862 - val_acc: 0.9644\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9873\n",
      "Epoch 00078: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0368 - acc: 0.9873 - val_loss: 0.1819 - val_acc: 0.9599\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9860\n",
      "Epoch 00079: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0457 - acc: 0.9860 - val_loss: 0.1594 - val_acc: 0.9681\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9875\n",
      "Epoch 00080: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0383 - acc: 0.9875 - val_loss: 0.1843 - val_acc: 0.9658\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9874\n",
      "Epoch 00081: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0378 - acc: 0.9874 - val_loss: 0.1783 - val_acc: 0.9632\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9857\n",
      "Epoch 00082: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0422 - acc: 0.9857 - val_loss: 0.1955 - val_acc: 0.9616\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9878\n",
      "Epoch 00083: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0379 - acc: 0.9878 - val_loss: 0.1858 - val_acc: 0.9672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9868\n",
      "Epoch 00084: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0407 - acc: 0.9868 - val_loss: 0.1863 - val_acc: 0.9627\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9814\n",
      "Epoch 00085: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0571 - acc: 0.9814 - val_loss: 0.2047 - val_acc: 0.9599\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9869\n",
      "Epoch 00086: val_loss did not improve from 0.13928\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0390 - acc: 0.9869 - val_loss: 0.1830 - val_acc: 0.9665\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 997us/sample - loss: 0.1974 - acc: 0.9479\n",
      "Loss: 0.19740201153658013 Accuracy: 0.9478712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    base = '1D_CNN_custom_kernel_192_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_kernel_192_DO_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,368\n",
      "Trainable params: 16,396,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 448us/sample - loss: 1.5956 - acc: 0.5009\n",
      "Loss: 1.5955962598509505 Accuracy: 0.5009346\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,866,640\n",
      "Trainable params: 5,866,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 817us/sample - loss: 0.9282 - acc: 0.7259\n",
      "Loss: 0.9281952437953415 Accuracy: 0.7258567\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,421,968\n",
      "Trainable params: 2,421,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 930us/sample - loss: 0.7212 - acc: 0.7886\n",
      "Loss: 0.7212270665267794 Accuracy: 0.7885774\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 1,306,896\n",
      "Trainable params: 1,306,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 978us/sample - loss: 0.5719 - acc: 0.8482\n",
      "Loss: 0.571932884280184 Accuracy: 0.84818274\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,202,576\n",
      "Trainable params: 1,202,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.4523 - acc: 0.8760\n",
      "Loss: 0.45233589846520905 Accuracy: 0.87601244\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,030,672\n",
      "Trainable params: 1,030,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.3056 - acc: 0.9225\n",
      "Loss: 0.3056400315598164 Accuracy: 0.92253375\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 989,840\n",
      "Trainable params: 989,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2434 - acc: 0.9350\n",
      "Loss: 0.24343668199216836 Accuracy: 0.9349948\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 1,010,448\n",
      "Trainable params: 1,010,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1881 - acc: 0.9489\n",
      "Loss: 0.188122254530759 Accuracy: 0.94890964\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,102,864\n",
      "Trainable params: 1,102,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1974 - acc: 0.9479\n",
      "Loss: 0.19740201153658013 Accuracy: 0.9478712\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_kernel_192_DO'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_kernel_192_DO_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,368\n",
      "Trainable params: 16,396,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 498us/sample - loss: 3.7688 - acc: 0.4787\n",
      "Loss: 3.7687574623282205 Accuracy: 0.47871235\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,866,640\n",
      "Trainable params: 5,866,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 890us/sample - loss: 1.9315 - acc: 0.7286\n",
      "Loss: 1.9315179574898098 Accuracy: 0.7285566\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,421,968\n",
      "Trainable params: 2,421,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.4397 - acc: 0.7985\n",
      "Loss: 1.439711612159713 Accuracy: 0.7985462\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 1,306,896\n",
      "Trainable params: 1,306,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.9188 - acc: 0.8621\n",
      "Loss: 0.9188228291762086 Accuracy: 0.8620976\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,202,576\n",
      "Trainable params: 1,202,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.6197 - acc: 0.8908\n",
      "Loss: 0.6197051307617814 Accuracy: 0.89075804\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,030,672\n",
      "Trainable params: 1,030,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.4068 - acc: 0.9261\n",
      "Loss: 0.40677676644323246 Accuracy: 0.9260644\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 989,840\n",
      "Trainable params: 989,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2572 - acc: 0.9456\n",
      "Loss: 0.25723175980259017 Accuracy: 0.9455867\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 1,010,448\n",
      "Trainable params: 1,010,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2295 - acc: 0.9516\n",
      "Loss: 0.22947452924323586 Accuracy: 0.95160955\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,102,864\n",
      "Trainable params: 1,102,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2505 - acc: 0.9512\n",
      "Loss: 0.250489298407169 Accuracy: 0.95119417\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_kernel_192_DO'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
