{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_BN(conv_num=1):\n",
    "    init_channel = 128\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=init_channel, strides=1, \n",
    "                      padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=int(init_channel/(2**int((i+1)/3))), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 2048000)           8192000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                32768016  \n",
      "=================================================================\n",
      "Total params: 40,961,296\n",
      "Trainable params: 36,865,040\n",
      "Non-trainable params: 4,096,256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 682624)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 682624)            2730496   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                10922000  \n",
      "=================================================================\n",
      "Total params: 13,736,336\n",
      "Trainable params: 12,370,576\n",
      "Non-trainable params: 1,365,760\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 227456)            909824    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 4,715,536\n",
      "Trainable params: 4,259,856\n",
      "Non-trainable params: 455,680\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 965,456\n",
      "Trainable params: 888,784\n",
      "Non-trainable params: 76,672\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 12608)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 12608)             50432     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                201744    \n",
      "=================================================================\n",
      "Total params: 480,656\n",
      "Trainable params: 454,416\n",
      "Non-trainable params: 26,240\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 4160)              16640     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                66576     \n",
      "=================================================================\n",
      "Total params: 332,496\n",
      "Trainable params: 323,024\n",
      "Non-trainable params: 9,472\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 65, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 672)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 672)               2688      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                10768     \n",
      "=================================================================\n",
      "Total params: 273,136\n",
      "Trainable params: 270,576\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 65, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 32)            5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 21, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 224)               896       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                3600      \n",
      "=================================================================\n",
      "Total params: 269,456\n",
      "Trainable params: 267,728\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 65, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 32)            5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 21, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 32)             5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 7, 32)             128       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 32)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 271,536\n",
      "Trainable params: 270,064\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7750 - acc: 0.4847\n",
      "Epoch 00001: val_loss improved from inf to 1.55743, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_4_conv_checkpoint/001-1.5574.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 1.7750 - acc: 0.4847 - val_loss: 1.5574 - val_acc: 0.5183\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1033 - acc: 0.6813\n",
      "Epoch 00002: val_loss improved from 1.55743 to 1.25767, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_4_conv_checkpoint/002-1.2577.hdf5\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 1.1032 - acc: 0.6813 - val_loss: 1.2577 - val_acc: 0.6459\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7793 - acc: 0.7682\n",
      "Epoch 00003: val_loss did not improve from 1.25767\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.7797 - acc: 0.7682 - val_loss: 1.2782 - val_acc: 0.6462\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5645 - acc: 0.8340\n",
      "Epoch 00004: val_loss improved from 1.25767 to 1.20166, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_4_conv_checkpoint/004-1.2017.hdf5\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5645 - acc: 0.8340 - val_loss: 1.2017 - val_acc: 0.6825\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4023 - acc: 0.8835\n",
      "Epoch 00005: val_loss improved from 1.20166 to 1.15940, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_4_conv_checkpoint/005-1.1594.hdf5\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.4024 - acc: 0.8834 - val_loss: 1.1594 - val_acc: 0.6785\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2821 - acc: 0.9268\n",
      "Epoch 00006: val_loss improved from 1.15940 to 1.13707, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_4_conv_checkpoint/006-1.1371.hdf5\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.2821 - acc: 0.9268 - val_loss: 1.1371 - val_acc: 0.6997\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9470\n",
      "Epoch 00007: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 0.2127 - acc: 0.9470 - val_loss: 1.1856 - val_acc: 0.6916\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9627\n",
      "Epoch 00008: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 0.1693 - acc: 0.9627 - val_loss: 1.3078 - val_acc: 0.6739\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9702\n",
      "Epoch 00009: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.1381 - acc: 0.9702 - val_loss: 1.3545 - val_acc: 0.6758\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9777\n",
      "Epoch 00010: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.1196 - acc: 0.9777 - val_loss: 1.2981 - val_acc: 0.6932\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9809\n",
      "Epoch 00011: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.1005 - acc: 0.9809 - val_loss: 1.2879 - val_acc: 0.6949\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9831\n",
      "Epoch 00012: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0908 - acc: 0.9831 - val_loss: 1.4438 - val_acc: 0.6765\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9886\n",
      "Epoch 00013: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0721 - acc: 0.9886 - val_loss: 1.2973 - val_acc: 0.7039\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9885\n",
      "Epoch 00014: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0644 - acc: 0.9885 - val_loss: 1.4517 - val_acc: 0.6802\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9902\n",
      "Epoch 00015: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0602 - acc: 0.9902 - val_loss: 1.5108 - val_acc: 0.6718\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9844\n",
      "Epoch 00016: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0757 - acc: 0.9844 - val_loss: 1.5848 - val_acc: 0.6669\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9857\n",
      "Epoch 00017: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0707 - acc: 0.9857 - val_loss: 1.5060 - val_acc: 0.6811\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9916\n",
      "Epoch 00018: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0495 - acc: 0.9916 - val_loss: 1.5136 - val_acc: 0.6832\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9939\n",
      "Epoch 00019: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0420 - acc: 0.9939 - val_loss: 1.7917 - val_acc: 0.6462\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9863\n",
      "Epoch 00020: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0642 - acc: 0.9863 - val_loss: 1.5023 - val_acc: 0.7014\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9921\n",
      "Epoch 00021: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0452 - acc: 0.9921 - val_loss: 1.6250 - val_acc: 0.6692\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9920\n",
      "Epoch 00022: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0422 - acc: 0.9919 - val_loss: 1.7087 - val_acc: 0.6778\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9841\n",
      "Epoch 00023: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0688 - acc: 0.9841 - val_loss: 1.5132 - val_acc: 0.6986\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9919\n",
      "Epoch 00024: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0415 - acc: 0.9919 - val_loss: 1.6652 - val_acc: 0.6855\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9953\n",
      "Epoch 00025: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0307 - acc: 0.9953 - val_loss: 1.5342 - val_acc: 0.6969\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9932\n",
      "Epoch 00026: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0373 - acc: 0.9932 - val_loss: 1.7077 - val_acc: 0.6767\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9948\n",
      "Epoch 00027: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0330 - acc: 0.9948 - val_loss: 1.6507 - val_acc: 0.6883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9950\n",
      "Epoch 00028: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0299 - acc: 0.9950 - val_loss: 1.6397 - val_acc: 0.6962\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9951\n",
      "Epoch 00029: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0302 - acc: 0.9950 - val_loss: 1.7146 - val_acc: 0.6834\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9887\n",
      "Epoch 00030: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0493 - acc: 0.9886 - val_loss: 1.6646 - val_acc: 0.6853\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9937\n",
      "Epoch 00031: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0332 - acc: 0.9937 - val_loss: 1.7844 - val_acc: 0.6774\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9916\n",
      "Epoch 00032: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0393 - acc: 0.9916 - val_loss: 1.9027 - val_acc: 0.6748\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9955\n",
      "Epoch 00033: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0255 - acc: 0.9954 - val_loss: 1.6860 - val_acc: 0.7046\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9923\n",
      "Epoch 00034: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0350 - acc: 0.9923 - val_loss: 1.8225 - val_acc: 0.6862\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9957\n",
      "Epoch 00035: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0263 - acc: 0.9956 - val_loss: 2.0101 - val_acc: 0.6573\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9894\n",
      "Epoch 00036: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0452 - acc: 0.9894 - val_loss: 1.8267 - val_acc: 0.6783\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9938\n",
      "Epoch 00037: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0323 - acc: 0.9938 - val_loss: 1.8635 - val_acc: 0.6858\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9957\n",
      "Epoch 00038: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0281 - acc: 0.9957 - val_loss: 1.8079 - val_acc: 0.6853\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9957\n",
      "Epoch 00039: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0245 - acc: 0.9957 - val_loss: 1.8503 - val_acc: 0.6937\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9963\n",
      "Epoch 00040: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0223 - acc: 0.9963 - val_loss: 1.8919 - val_acc: 0.6874\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9950\n",
      "Epoch 00041: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0263 - acc: 0.9950 - val_loss: 2.0207 - val_acc: 0.6636\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9948\n",
      "Epoch 00042: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0292 - acc: 0.9948 - val_loss: 1.9551 - val_acc: 0.6727\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9918\n",
      "Epoch 00043: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0366 - acc: 0.9918 - val_loss: 2.1280 - val_acc: 0.6594\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9968\n",
      "Epoch 00044: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0204 - acc: 0.9968 - val_loss: 2.0578 - val_acc: 0.6653\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9926\n",
      "Epoch 00045: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0322 - acc: 0.9926 - val_loss: 1.8590 - val_acc: 0.6911\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9975\n",
      "Epoch 00046: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0192 - acc: 0.9974 - val_loss: 1.9427 - val_acc: 0.6848\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9944\n",
      "Epoch 00047: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0285 - acc: 0.9944 - val_loss: 2.0313 - val_acc: 0.6760\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9945\n",
      "Epoch 00048: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0260 - acc: 0.9945 - val_loss: 1.8641 - val_acc: 0.6939\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9952\n",
      "Epoch 00049: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0241 - acc: 0.9952 - val_loss: 1.9633 - val_acc: 0.6825\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9985\n",
      "Epoch 00050: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0137 - acc: 0.9984 - val_loss: 2.0013 - val_acc: 0.6837\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9934\n",
      "Epoch 00051: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0308 - acc: 0.9934 - val_loss: 2.0279 - val_acc: 0.6785\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9958\n",
      "Epoch 00052: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0238 - acc: 0.9958 - val_loss: 2.0544 - val_acc: 0.6760\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9934\n",
      "Epoch 00053: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0323 - acc: 0.9934 - val_loss: 1.9971 - val_acc: 0.6862\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9957\n",
      "Epoch 00054: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0228 - acc: 0.9956 - val_loss: 2.0759 - val_acc: 0.6704\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9965\n",
      "Epoch 00055: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0193 - acc: 0.9965 - val_loss: 1.9584 - val_acc: 0.6956\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9979\n",
      "Epoch 00056: val_loss did not improve from 1.13707\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0164 - acc: 0.9978 - val_loss: 2.2261 - val_acc: 0.6585\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.2746 - acc: 0.6557\n",
      "Loss: 1.274618286234815 Accuracy: 0.6556594\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6682 - acc: 0.4936\n",
      "Epoch 00001: val_loss improved from inf to 1.46961, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_5_conv_checkpoint/001-1.4696.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 1.6683 - acc: 0.4936 - val_loss: 1.4696 - val_acc: 0.5379\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0773 - acc: 0.6776\n",
      "Epoch 00002: val_loss improved from 1.46961 to 1.08583, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_5_conv_checkpoint/002-1.0858.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 1.0775 - acc: 0.6775 - val_loss: 1.0858 - val_acc: 0.6962\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8812 - acc: 0.7390\n",
      "Epoch 00003: val_loss improved from 1.08583 to 0.96050, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_5_conv_checkpoint/003-0.9605.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.8812 - acc: 0.7390 - val_loss: 0.9605 - val_acc: 0.7207\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7536 - acc: 0.7748\n",
      "Epoch 00004: val_loss did not improve from 0.96050\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.7540 - acc: 0.7747 - val_loss: 1.0296 - val_acc: 0.6988\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6637 - acc: 0.8009\n",
      "Epoch 00005: val_loss improved from 0.96050 to 0.88216, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_5_conv_checkpoint/005-0.8822.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.6637 - acc: 0.8009 - val_loss: 0.8822 - val_acc: 0.7463\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5819 - acc: 0.8277\n",
      "Epoch 00006: val_loss improved from 0.88216 to 0.87580, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_5_conv_checkpoint/006-0.8758.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.5818 - acc: 0.8278 - val_loss: 0.8758 - val_acc: 0.7515\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5082 - acc: 0.8493\n",
      "Epoch 00007: val_loss improved from 0.87580 to 0.83697, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_5_conv_checkpoint/007-0.8370.hdf5\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.5083 - acc: 0.8493 - val_loss: 0.8370 - val_acc: 0.7668\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4582 - acc: 0.8657\n",
      "Epoch 00008: val_loss did not improve from 0.83697\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.4582 - acc: 0.8657 - val_loss: 0.8747 - val_acc: 0.7480\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3943 - acc: 0.8846\n",
      "Epoch 00009: val_loss did not improve from 0.83697\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.3945 - acc: 0.8845 - val_loss: 0.8979 - val_acc: 0.7512\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3597 - acc: 0.8959\n",
      "Epoch 00010: val_loss did not improve from 0.83697\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.3599 - acc: 0.8958 - val_loss: 0.8641 - val_acc: 0.7610\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3062 - acc: 0.9147\n",
      "Epoch 00011: val_loss did not improve from 0.83697\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.3062 - acc: 0.9147 - val_loss: 0.8783 - val_acc: 0.7466\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2647 - acc: 0.9262\n",
      "Epoch 00012: val_loss did not improve from 0.83697\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.2647 - acc: 0.9262 - val_loss: 0.9030 - val_acc: 0.7505\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2358 - acc: 0.9390\n",
      "Epoch 00013: val_loss improved from 0.83697 to 0.81522, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_5_conv_checkpoint/013-0.8152.hdf5\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.2358 - acc: 0.9390 - val_loss: 0.8152 - val_acc: 0.7792\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2001 - acc: 0.9486\n",
      "Epoch 00014: val_loss did not improve from 0.81522\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.2002 - acc: 0.9485 - val_loss: 0.8789 - val_acc: 0.7608\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9552\n",
      "Epoch 00015: val_loss improved from 0.81522 to 0.80905, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_5_conv_checkpoint/015-0.8091.hdf5\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.1808 - acc: 0.9552 - val_loss: 0.8091 - val_acc: 0.7871\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9617\n",
      "Epoch 00016: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.1574 - acc: 0.9617 - val_loss: 0.8968 - val_acc: 0.7643\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1350 - acc: 0.9705\n",
      "Epoch 00017: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.1350 - acc: 0.9705 - val_loss: 0.8788 - val_acc: 0.7780\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9737\n",
      "Epoch 00018: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.1210 - acc: 0.9737 - val_loss: 0.9433 - val_acc: 0.7591\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9738\n",
      "Epoch 00019: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.1190 - acc: 0.9738 - val_loss: 0.9390 - val_acc: 0.7661\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9760\n",
      "Epoch 00020: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.1097 - acc: 0.9760 - val_loss: 0.9948 - val_acc: 0.7547\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9806\n",
      "Epoch 00021: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0946 - acc: 0.9806 - val_loss: 0.8722 - val_acc: 0.7803\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9813\n",
      "Epoch 00022: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0909 - acc: 0.9812 - val_loss: 0.9381 - val_acc: 0.7738\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9823\n",
      "Epoch 00023: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0888 - acc: 0.9822 - val_loss: 0.9073 - val_acc: 0.7857\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9868\n",
      "Epoch 00024: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0741 - acc: 0.9868 - val_loss: 0.9682 - val_acc: 0.7666\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9900\n",
      "Epoch 00025: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0612 - acc: 0.9900 - val_loss: 1.0104 - val_acc: 0.7675\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9892\n",
      "Epoch 00026: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0622 - acc: 0.9891 - val_loss: 1.1601 - val_acc: 0.7256\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9851\n",
      "Epoch 00027: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0732 - acc: 0.9850 - val_loss: 1.0534 - val_acc: 0.7563\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9844\n",
      "Epoch 00028: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0740 - acc: 0.9843 - val_loss: 0.9484 - val_acc: 0.7815\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9882\n",
      "Epoch 00029: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0613 - acc: 0.9882 - val_loss: 1.0993 - val_acc: 0.7480\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9884\n",
      "Epoch 00030: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0586 - acc: 0.9884 - val_loss: 0.9601 - val_acc: 0.7810\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9903\n",
      "Epoch 00031: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0554 - acc: 0.9902 - val_loss: 0.9704 - val_acc: 0.7768\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9905\n",
      "Epoch 00032: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0525 - acc: 0.9905 - val_loss: 0.9900 - val_acc: 0.7806\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9924\n",
      "Epoch 00033: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0463 - acc: 0.9924 - val_loss: 1.0026 - val_acc: 0.7752\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9938\n",
      "Epoch 00034: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0413 - acc: 0.9937 - val_loss: 1.2093 - val_acc: 0.7463\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9883\n",
      "Epoch 00035: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0565 - acc: 0.9883 - val_loss: 1.0009 - val_acc: 0.7831\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9928\n",
      "Epoch 00036: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0419 - acc: 0.9928 - val_loss: 1.0852 - val_acc: 0.7720\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9944\n",
      "Epoch 00037: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0371 - acc: 0.9943 - val_loss: 1.0841 - val_acc: 0.7694\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9923\n",
      "Epoch 00038: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0406 - acc: 0.9923 - val_loss: 1.0929 - val_acc: 0.7717\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9909\n",
      "Epoch 00039: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0447 - acc: 0.9909 - val_loss: 1.0243 - val_acc: 0.7820\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9939\n",
      "Epoch 00040: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0354 - acc: 0.9939 - val_loss: 1.0127 - val_acc: 0.7934\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9940\n",
      "Epoch 00041: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0348 - acc: 0.9940 - val_loss: 1.2212 - val_acc: 0.7480\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9965\n",
      "Epoch 00042: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0284 - acc: 0.9965 - val_loss: 1.1482 - val_acc: 0.7645\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9889\n",
      "Epoch 00043: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0521 - acc: 0.9889 - val_loss: 1.0251 - val_acc: 0.7827\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9936\n",
      "Epoch 00044: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0351 - acc: 0.9936 - val_loss: 1.0532 - val_acc: 0.7855\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9938\n",
      "Epoch 00045: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0364 - acc: 0.9937 - val_loss: 1.1295 - val_acc: 0.7689\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9914\n",
      "Epoch 00046: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0411 - acc: 0.9913 - val_loss: 1.0712 - val_acc: 0.7764\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9904\n",
      "Epoch 00047: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0434 - acc: 0.9904 - val_loss: 1.1230 - val_acc: 0.7699\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9974\n",
      "Epoch 00048: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0224 - acc: 0.9974 - val_loss: 1.1113 - val_acc: 0.7747\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9965\n",
      "Epoch 00049: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0250 - acc: 0.9964 - val_loss: 1.2050 - val_acc: 0.7657\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9910\n",
      "Epoch 00050: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0407 - acc: 0.9910 - val_loss: 1.1586 - val_acc: 0.7710\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9930\n",
      "Epoch 00051: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0364 - acc: 0.9930 - val_loss: 1.1259 - val_acc: 0.7731\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9980\n",
      "Epoch 00052: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0199 - acc: 0.9980 - val_loss: 1.1037 - val_acc: 0.7747\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9940\n",
      "Epoch 00053: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0323 - acc: 0.9939 - val_loss: 1.1388 - val_acc: 0.7636\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9907\n",
      "Epoch 00054: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0401 - acc: 0.9907 - val_loss: 1.0944 - val_acc: 0.7766\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9976\n",
      "Epoch 00055: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0210 - acc: 0.9976 - val_loss: 1.0670 - val_acc: 0.7878\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9977\n",
      "Epoch 00056: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0192 - acc: 0.9976 - val_loss: 1.3959 - val_acc: 0.7379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9929\n",
      "Epoch 00057: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0356 - acc: 0.9928 - val_loss: 1.1012 - val_acc: 0.7862\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9951\n",
      "Epoch 00058: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0274 - acc: 0.9951 - val_loss: 1.1639 - val_acc: 0.7759\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9980\n",
      "Epoch 00059: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0180 - acc: 0.9980 - val_loss: 1.1552 - val_acc: 0.7761\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9926\n",
      "Epoch 00060: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0363 - acc: 0.9926 - val_loss: 1.2683 - val_acc: 0.7524\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9977\n",
      "Epoch 00061: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0197 - acc: 0.9976 - val_loss: 1.6029 - val_acc: 0.7188\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9926\n",
      "Epoch 00062: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0336 - acc: 0.9926 - val_loss: 1.1211 - val_acc: 0.7855\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9974\n",
      "Epoch 00063: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0194 - acc: 0.9974 - val_loss: 1.1653 - val_acc: 0.7724\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9973\n",
      "Epoch 00064: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0201 - acc: 0.9972 - val_loss: 1.1810 - val_acc: 0.7785\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9919\n",
      "Epoch 00065: val_loss did not improve from 0.80905\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0364 - acc: 0.9919 - val_loss: 1.1661 - val_acc: 0.7696\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.9102 - acc: 0.7497\n",
      "Loss: 0.9101950282991118 Accuracy: 0.7497404\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8158 - acc: 0.4407\n",
      "Epoch 00001: val_loss improved from inf to 1.47512, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_6_conv_checkpoint/001-1.4751.hdf5\n",
      "36805/36805 [==============================] - 187s 5ms/sample - loss: 1.8157 - acc: 0.4408 - val_loss: 1.4751 - val_acc: 0.5334\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1394 - acc: 0.6574\n",
      "Epoch 00002: val_loss improved from 1.47512 to 1.12510, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_6_conv_checkpoint/002-1.1251.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 1.1394 - acc: 0.6574 - val_loss: 1.1251 - val_acc: 0.6490\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9354 - acc: 0.7262\n",
      "Epoch 00003: val_loss improved from 1.12510 to 0.89833, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_6_conv_checkpoint/003-0.8983.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.9354 - acc: 0.7262 - val_loss: 0.8983 - val_acc: 0.7340\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8088 - acc: 0.7641\n",
      "Epoch 00004: val_loss improved from 0.89833 to 0.84181, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_6_conv_checkpoint/004-0.8418.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.8089 - acc: 0.7641 - val_loss: 0.8418 - val_acc: 0.7666\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7178 - acc: 0.7909\n",
      "Epoch 00005: val_loss did not improve from 0.84181\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.7178 - acc: 0.7909 - val_loss: 0.9346 - val_acc: 0.7298\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6500 - acc: 0.8114\n",
      "Epoch 00006: val_loss improved from 0.84181 to 0.74284, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_6_conv_checkpoint/006-0.7428.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.6501 - acc: 0.8114 - val_loss: 0.7428 - val_acc: 0.7964\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5870 - acc: 0.8314\n",
      "Epoch 00007: val_loss improved from 0.74284 to 0.63300, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_6_conv_checkpoint/007-0.6330.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.5872 - acc: 0.8314 - val_loss: 0.6330 - val_acc: 0.8188\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5357 - acc: 0.8473\n",
      "Epoch 00008: val_loss improved from 0.63300 to 0.62720, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_6_conv_checkpoint/008-0.6272.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.5359 - acc: 0.8472 - val_loss: 0.6272 - val_acc: 0.8260\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4957 - acc: 0.8589\n",
      "Epoch 00009: val_loss improved from 0.62720 to 0.58637, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_6_conv_checkpoint/009-0.5864.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.4957 - acc: 0.8589 - val_loss: 0.5864 - val_acc: 0.8432\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8717\n",
      "Epoch 00010: val_loss did not improve from 0.58637\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.4507 - acc: 0.8716 - val_loss: 0.5958 - val_acc: 0.8346\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4180 - acc: 0.8807\n",
      "Epoch 00011: val_loss improved from 0.58637 to 0.54242, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_6_conv_checkpoint/011-0.5424.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.4181 - acc: 0.8806 - val_loss: 0.5424 - val_acc: 0.8544\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3892 - acc: 0.8891\n",
      "Epoch 00012: val_loss did not improve from 0.54242\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.3892 - acc: 0.8891 - val_loss: 0.5704 - val_acc: 0.8407\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3522 - acc: 0.8999\n",
      "Epoch 00013: val_loss did not improve from 0.54242\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.3522 - acc: 0.8999 - val_loss: 0.6201 - val_acc: 0.8272\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3331 - acc: 0.9049\n",
      "Epoch 00014: val_loss did not improve from 0.54242\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.3333 - acc: 0.9048 - val_loss: 0.5970 - val_acc: 0.8360\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3120 - acc: 0.9111\n",
      "Epoch 00015: val_loss improved from 0.54242 to 0.51361, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_6_conv_checkpoint/015-0.5136.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.3120 - acc: 0.9111 - val_loss: 0.5136 - val_acc: 0.8605\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2833 - acc: 0.9209\n",
      "Epoch 00016: val_loss did not improve from 0.51361\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.2834 - acc: 0.9209 - val_loss: 0.5291 - val_acc: 0.8570\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2683 - acc: 0.9248\n",
      "Epoch 00017: val_loss did not improve from 0.51361\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.2684 - acc: 0.9248 - val_loss: 0.5399 - val_acc: 0.8498\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2460 - acc: 0.9311\n",
      "Epoch 00018: val_loss did not improve from 0.51361\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.2461 - acc: 0.9310 - val_loss: 0.6139 - val_acc: 0.8395\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9356\n",
      "Epoch 00019: val_loss did not improve from 0.51361\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.2299 - acc: 0.9356 - val_loss: 0.5222 - val_acc: 0.8616\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2097 - acc: 0.9423\n",
      "Epoch 00020: val_loss did not improve from 0.51361\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.2099 - acc: 0.9423 - val_loss: 0.5929 - val_acc: 0.8435\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9454\n",
      "Epoch 00021: val_loss did not improve from 0.51361\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1994 - acc: 0.9454 - val_loss: 0.5184 - val_acc: 0.8703\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1783 - acc: 0.9529\n",
      "Epoch 00022: val_loss did not improve from 0.51361\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1784 - acc: 0.9529 - val_loss: 0.5142 - val_acc: 0.8619\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9548\n",
      "Epoch 00023: val_loss did not improve from 0.51361\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1704 - acc: 0.9548 - val_loss: 0.5232 - val_acc: 0.8607\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1709 - acc: 0.9529\n",
      "Epoch 00024: val_loss did not improve from 0.51361\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1709 - acc: 0.9529 - val_loss: 0.5236 - val_acc: 0.8682\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9610\n",
      "Epoch 00025: val_loss did not improve from 0.51361\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1490 - acc: 0.9609 - val_loss: 0.5208 - val_acc: 0.8595\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9658\n",
      "Epoch 00026: val_loss improved from 0.51361 to 0.49009, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_6_conv_checkpoint/026-0.4901.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1392 - acc: 0.9658 - val_loss: 0.4901 - val_acc: 0.8644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9668\n",
      "Epoch 00027: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1309 - acc: 0.9667 - val_loss: 0.6021 - val_acc: 0.8416\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9682\n",
      "Epoch 00028: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1269 - acc: 0.9682 - val_loss: 0.4935 - val_acc: 0.8710\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9730\n",
      "Epoch 00029: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1115 - acc: 0.9730 - val_loss: 0.5201 - val_acc: 0.8651\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9737\n",
      "Epoch 00030: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1095 - acc: 0.9736 - val_loss: 0.5561 - val_acc: 0.8693\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9747\n",
      "Epoch 00031: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1072 - acc: 0.9747 - val_loss: 0.5409 - val_acc: 0.8593\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9805\n",
      "Epoch 00032: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0891 - acc: 0.9805 - val_loss: 0.5147 - val_acc: 0.8721\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9805\n",
      "Epoch 00033: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0852 - acc: 0.9805 - val_loss: 0.6024 - val_acc: 0.8502\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9814\n",
      "Epoch 00034: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0839 - acc: 0.9814 - val_loss: 0.5288 - val_acc: 0.8672\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9763\n",
      "Epoch 00035: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0944 - acc: 0.9763 - val_loss: 0.5369 - val_acc: 0.8619\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9843\n",
      "Epoch 00036: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0761 - acc: 0.9843 - val_loss: 0.5502 - val_acc: 0.8656\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9849\n",
      "Epoch 00037: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0727 - acc: 0.9849 - val_loss: 0.5492 - val_acc: 0.8649\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9882\n",
      "Epoch 00038: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0624 - acc: 0.9882 - val_loss: 0.5994 - val_acc: 0.8651\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9796\n",
      "Epoch 00039: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0851 - acc: 0.9796 - val_loss: 0.4960 - val_acc: 0.8812\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9913\n",
      "Epoch 00040: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0525 - acc: 0.9913 - val_loss: 0.5192 - val_acc: 0.8763\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9882\n",
      "Epoch 00041: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0608 - acc: 0.9882 - val_loss: 0.6080 - val_acc: 0.8607\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9812\n",
      "Epoch 00042: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0785 - acc: 0.9812 - val_loss: 0.5363 - val_acc: 0.8686\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9904\n",
      "Epoch 00043: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0524 - acc: 0.9904 - val_loss: 0.6267 - val_acc: 0.8553\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9856\n",
      "Epoch 00044: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0634 - acc: 0.9856 - val_loss: 0.5540 - val_acc: 0.8726\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9890\n",
      "Epoch 00045: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0543 - acc: 0.9891 - val_loss: 0.5394 - val_acc: 0.8712\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9920\n",
      "Epoch 00046: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0447 - acc: 0.9920 - val_loss: 0.5197 - val_acc: 0.8805\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9910\n",
      "Epoch 00047: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0475 - acc: 0.9910 - val_loss: 0.5635 - val_acc: 0.8696\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9935\n",
      "Epoch 00048: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0408 - acc: 0.9935 - val_loss: 0.5844 - val_acc: 0.8705\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9860\n",
      "Epoch 00049: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0617 - acc: 0.9859 - val_loss: 0.5815 - val_acc: 0.8710\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9874\n",
      "Epoch 00050: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0567 - acc: 0.9874 - val_loss: 0.4977 - val_acc: 0.8812\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9945\n",
      "Epoch 00051: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0363 - acc: 0.9945 - val_loss: 0.5704 - val_acc: 0.8651\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9932\n",
      "Epoch 00052: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0397 - acc: 0.9932 - val_loss: 0.5503 - val_acc: 0.8737\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9906\n",
      "Epoch 00053: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0445 - acc: 0.9906 - val_loss: 0.5617 - val_acc: 0.8765\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9891\n",
      "Epoch 00054: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0499 - acc: 0.9891 - val_loss: 0.5291 - val_acc: 0.8845\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9942\n",
      "Epoch 00055: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0346 - acc: 0.9942 - val_loss: 0.5859 - val_acc: 0.8698\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9924\n",
      "Epoch 00056: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0395 - acc: 0.9923 - val_loss: 0.5945 - val_acc: 0.8663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9915\n",
      "Epoch 00057: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0432 - acc: 0.9915 - val_loss: 0.5382 - val_acc: 0.8849\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9953\n",
      "Epoch 00058: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0312 - acc: 0.9952 - val_loss: 0.6345 - val_acc: 0.8595\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9882\n",
      "Epoch 00059: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0519 - acc: 0.9882 - val_loss: 0.5474 - val_acc: 0.8807\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9933\n",
      "Epoch 00060: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0368 - acc: 0.9933 - val_loss: 0.6051 - val_acc: 0.8672\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9926\n",
      "Epoch 00061: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0382 - acc: 0.9926 - val_loss: 0.5289 - val_acc: 0.8838\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9947\n",
      "Epoch 00062: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0308 - acc: 0.9947 - val_loss: 0.5625 - val_acc: 0.8782\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9935\n",
      "Epoch 00063: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0342 - acc: 0.9935 - val_loss: 0.5660 - val_acc: 0.8782\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9961\n",
      "Epoch 00064: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0259 - acc: 0.9961 - val_loss: 0.5659 - val_acc: 0.8749\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9911\n",
      "Epoch 00065: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0407 - acc: 0.9911 - val_loss: 0.5828 - val_acc: 0.8751\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9912\n",
      "Epoch 00066: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0403 - acc: 0.9912 - val_loss: 0.5715 - val_acc: 0.8805\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9945\n",
      "Epoch 00067: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0299 - acc: 0.9945 - val_loss: 0.5889 - val_acc: 0.8728\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9935\n",
      "Epoch 00068: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0343 - acc: 0.9935 - val_loss: 0.5748 - val_acc: 0.8728\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9973\n",
      "Epoch 00069: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0209 - acc: 0.9973 - val_loss: 0.6066 - val_acc: 0.8749\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9936\n",
      "Epoch 00070: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0321 - acc: 0.9935 - val_loss: 0.6258 - val_acc: 0.8560\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9890\n",
      "Epoch 00071: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0473 - acc: 0.9890 - val_loss: 0.5931 - val_acc: 0.8737\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9972\n",
      "Epoch 00072: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0210 - acc: 0.9972 - val_loss: 0.5646 - val_acc: 0.8842\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9970\n",
      "Epoch 00073: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0218 - acc: 0.9969 - val_loss: 0.5898 - val_acc: 0.8751\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9925\n",
      "Epoch 00074: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0373 - acc: 0.9925 - val_loss: 0.5987 - val_acc: 0.8698\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9919\n",
      "Epoch 00075: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0354 - acc: 0.9918 - val_loss: 0.5860 - val_acc: 0.8740\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9920\n",
      "Epoch 00076: val_loss did not improve from 0.49009\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0334 - acc: 0.9919 - val_loss: 0.5896 - val_acc: 0.8754\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.5948 - acc: 0.8355\n",
      "Loss: 0.5948092682958268 Accuracy: 0.835514\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1630 - acc: 0.3370\n",
      "Epoch 00001: val_loss improved from inf to 1.80855, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/001-1.8086.hdf5\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 2.1629 - acc: 0.3371 - val_loss: 1.8086 - val_acc: 0.4405\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3498 - acc: 0.5889\n",
      "Epoch 00002: val_loss improved from 1.80855 to 1.16543, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/002-1.1654.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 1.3502 - acc: 0.5889 - val_loss: 1.1654 - val_acc: 0.6506\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0661 - acc: 0.6860\n",
      "Epoch 00003: val_loss improved from 1.16543 to 0.92304, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/003-0.9230.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 1.0663 - acc: 0.6859 - val_loss: 0.9230 - val_acc: 0.7300\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8943 - acc: 0.7414\n",
      "Epoch 00004: val_loss improved from 0.92304 to 0.85523, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/004-0.8552.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.8943 - acc: 0.7413 - val_loss: 0.8552 - val_acc: 0.7508\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7703 - acc: 0.7792\n",
      "Epoch 00005: val_loss improved from 0.85523 to 0.78928, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/005-0.7893.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.7704 - acc: 0.7791 - val_loss: 0.7893 - val_acc: 0.7780\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6771 - acc: 0.8065\n",
      "Epoch 00006: val_loss improved from 0.78928 to 0.72902, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/006-0.7290.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.6771 - acc: 0.8065 - val_loss: 0.7290 - val_acc: 0.7980\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6047 - acc: 0.8288\n",
      "Epoch 00007: val_loss improved from 0.72902 to 0.63747, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/007-0.6375.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.6049 - acc: 0.8287 - val_loss: 0.6375 - val_acc: 0.8134\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5503 - acc: 0.8445\n",
      "Epoch 00008: val_loss improved from 0.63747 to 0.55939, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/008-0.5594.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.5503 - acc: 0.8445 - val_loss: 0.5594 - val_acc: 0.8365\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5036 - acc: 0.8566\n",
      "Epoch 00009: val_loss improved from 0.55939 to 0.55767, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/009-0.5577.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.5036 - acc: 0.8566 - val_loss: 0.5577 - val_acc: 0.8414\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4619 - acc: 0.8704\n",
      "Epoch 00010: val_loss improved from 0.55767 to 0.47374, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/010-0.4737.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.4620 - acc: 0.8704 - val_loss: 0.4737 - val_acc: 0.8696\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4259 - acc: 0.8799\n",
      "Epoch 00011: val_loss improved from 0.47374 to 0.44384, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/011-0.4438.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.4259 - acc: 0.8799 - val_loss: 0.4438 - val_acc: 0.8744\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4003 - acc: 0.8866\n",
      "Epoch 00012: val_loss improved from 0.44384 to 0.44357, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/012-0.4436.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.4004 - acc: 0.8866 - val_loss: 0.4436 - val_acc: 0.8747\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3718 - acc: 0.8952\n",
      "Epoch 00013: val_loss did not improve from 0.44357\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.3719 - acc: 0.8952 - val_loss: 0.4634 - val_acc: 0.8707\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3488 - acc: 0.9013\n",
      "Epoch 00014: val_loss improved from 0.44357 to 0.44237, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/014-0.4424.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.3487 - acc: 0.9013 - val_loss: 0.4424 - val_acc: 0.8705\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3203 - acc: 0.9086\n",
      "Epoch 00015: val_loss improved from 0.44237 to 0.37890, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/015-0.3789.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.3203 - acc: 0.9086 - val_loss: 0.3789 - val_acc: 0.8912\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3048 - acc: 0.9120\n",
      "Epoch 00016: val_loss improved from 0.37890 to 0.35099, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/016-0.3510.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.3049 - acc: 0.9120 - val_loss: 0.3510 - val_acc: 0.8977\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2886 - acc: 0.9184\n",
      "Epoch 00017: val_loss did not improve from 0.35099\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.2887 - acc: 0.9184 - val_loss: 0.4561 - val_acc: 0.8719\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2752 - acc: 0.9220\n",
      "Epoch 00018: val_loss did not improve from 0.35099\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.2752 - acc: 0.9220 - val_loss: 0.3963 - val_acc: 0.8782\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2574 - acc: 0.9255\n",
      "Epoch 00019: val_loss did not improve from 0.35099\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.2574 - acc: 0.9255 - val_loss: 0.3816 - val_acc: 0.8910\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2421 - acc: 0.9318\n",
      "Epoch 00020: val_loss did not improve from 0.35099\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.2423 - acc: 0.9318 - val_loss: 0.3538 - val_acc: 0.8963\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2339 - acc: 0.9326\n",
      "Epoch 00021: val_loss improved from 0.35099 to 0.34174, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/021-0.3417.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.2339 - acc: 0.9326 - val_loss: 0.3417 - val_acc: 0.8996\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9392\n",
      "Epoch 00022: val_loss did not improve from 0.34174\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.2180 - acc: 0.9392 - val_loss: 0.3734 - val_acc: 0.8875\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9336\n",
      "Epoch 00023: val_loss improved from 0.34174 to 0.33539, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/023-0.3354.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.2283 - acc: 0.9336 - val_loss: 0.3354 - val_acc: 0.9082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1974 - acc: 0.9452\n",
      "Epoch 00024: val_loss improved from 0.33539 to 0.31129, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/024-0.3113.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.1975 - acc: 0.9452 - val_loss: 0.3113 - val_acc: 0.9115\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1901 - acc: 0.9473\n",
      "Epoch 00025: val_loss did not improve from 0.31129\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1900 - acc: 0.9473 - val_loss: 0.3422 - val_acc: 0.9045\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9519\n",
      "Epoch 00026: val_loss did not improve from 0.31129\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.1723 - acc: 0.9518 - val_loss: 0.3350 - val_acc: 0.9043\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9507\n",
      "Epoch 00027: val_loss did not improve from 0.31129\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1731 - acc: 0.9507 - val_loss: 0.3230 - val_acc: 0.9068\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1625 - acc: 0.9535\n",
      "Epoch 00028: val_loss did not improve from 0.31129\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1627 - acc: 0.9535 - val_loss: 0.3670 - val_acc: 0.8949\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1586 - acc: 0.9558\n",
      "Epoch 00029: val_loss did not improve from 0.31129\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.1587 - acc: 0.9558 - val_loss: 0.3778 - val_acc: 0.8905\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9596\n",
      "Epoch 00030: val_loss improved from 0.31129 to 0.30068, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/030-0.3007.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.1447 - acc: 0.9596 - val_loss: 0.3007 - val_acc: 0.9131\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9637\n",
      "Epoch 00031: val_loss did not improve from 0.30068\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1343 - acc: 0.9637 - val_loss: 0.3384 - val_acc: 0.9050\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9639\n",
      "Epoch 00032: val_loss did not improve from 0.30068\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1302 - acc: 0.9639 - val_loss: 0.3021 - val_acc: 0.9124\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9673\n",
      "Epoch 00033: val_loss did not improve from 0.30068\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1228 - acc: 0.9672 - val_loss: 0.3365 - val_acc: 0.9108\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9662\n",
      "Epoch 00034: val_loss did not improve from 0.30068\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1239 - acc: 0.9662 - val_loss: 0.3154 - val_acc: 0.9113\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9716\n",
      "Epoch 00035: val_loss did not improve from 0.30068\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1103 - acc: 0.9715 - val_loss: 0.3133 - val_acc: 0.9078\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9686\n",
      "Epoch 00036: val_loss did not improve from 0.30068\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.1122 - acc: 0.9685 - val_loss: 0.3345 - val_acc: 0.9012\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9693\n",
      "Epoch 00037: val_loss improved from 0.30068 to 0.29684, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/037-0.2968.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.1120 - acc: 0.9693 - val_loss: 0.2968 - val_acc: 0.9206\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9761\n",
      "Epoch 00038: val_loss did not improve from 0.29684\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0944 - acc: 0.9761 - val_loss: 0.3444 - val_acc: 0.9122\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9771\n",
      "Epoch 00039: val_loss did not improve from 0.29684\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0888 - acc: 0.9770 - val_loss: 0.3638 - val_acc: 0.8975\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9770\n",
      "Epoch 00040: val_loss did not improve from 0.29684\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0877 - acc: 0.9770 - val_loss: 0.3493 - val_acc: 0.9052\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9718\n",
      "Epoch 00041: val_loss did not improve from 0.29684\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1022 - acc: 0.9718 - val_loss: 0.3003 - val_acc: 0.9152\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9801\n",
      "Epoch 00042: val_loss did not improve from 0.29684\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0801 - acc: 0.9801 - val_loss: 0.3377 - val_acc: 0.9045\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9805\n",
      "Epoch 00043: val_loss improved from 0.29684 to 0.29590, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/043-0.2959.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0777 - acc: 0.9805 - val_loss: 0.2959 - val_acc: 0.9189\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9823\n",
      "Epoch 00044: val_loss did not improve from 0.29590\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0725 - acc: 0.9822 - val_loss: 0.4038 - val_acc: 0.8917\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9806\n",
      "Epoch 00045: val_loss did not improve from 0.29590\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0787 - acc: 0.9805 - val_loss: 0.3190 - val_acc: 0.9131\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9797\n",
      "Epoch 00046: val_loss improved from 0.29590 to 0.29281, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_7_conv_checkpoint/046-0.2928.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0783 - acc: 0.9797 - val_loss: 0.2928 - val_acc: 0.9194\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9867\n",
      "Epoch 00047: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0592 - acc: 0.9867 - val_loss: 0.4160 - val_acc: 0.8987\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9811\n",
      "Epoch 00048: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0717 - acc: 0.9811 - val_loss: 0.3055 - val_acc: 0.9217\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9830\n",
      "Epoch 00049: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0660 - acc: 0.9829 - val_loss: 0.3118 - val_acc: 0.9203\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9824\n",
      "Epoch 00050: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0674 - acc: 0.9824 - val_loss: 0.3206 - val_acc: 0.9143\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9887\n",
      "Epoch 00051: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0514 - acc: 0.9887 - val_loss: 0.3312 - val_acc: 0.9168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9859\n",
      "Epoch 00052: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0605 - acc: 0.9859 - val_loss: 0.3197 - val_acc: 0.9147\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9865\n",
      "Epoch 00053: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0572 - acc: 0.9865 - val_loss: 0.3474 - val_acc: 0.9092\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9836\n",
      "Epoch 00054: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0626 - acc: 0.9835 - val_loss: 0.2947 - val_acc: 0.9248\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9909\n",
      "Epoch 00055: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0436 - acc: 0.9909 - val_loss: 0.3173 - val_acc: 0.9213\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9923\n",
      "Epoch 00056: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0404 - acc: 0.9922 - val_loss: 0.3311 - val_acc: 0.9140\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9872\n",
      "Epoch 00057: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0538 - acc: 0.9872 - val_loss: 0.3472 - val_acc: 0.9117\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9914\n",
      "Epoch 00058: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0404 - acc: 0.9913 - val_loss: 0.3540 - val_acc: 0.9157\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9872\n",
      "Epoch 00059: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0507 - acc: 0.9871 - val_loss: 0.3339 - val_acc: 0.9147\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9858\n",
      "Epoch 00060: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0546 - acc: 0.9858 - val_loss: 0.3089 - val_acc: 0.9236\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9927\n",
      "Epoch 00061: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0357 - acc: 0.9927 - val_loss: 0.3082 - val_acc: 0.9227\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9942\n",
      "Epoch 00062: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0306 - acc: 0.9941 - val_loss: 0.3932 - val_acc: 0.9015\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9879\n",
      "Epoch 00063: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0495 - acc: 0.9879 - val_loss: 0.3624 - val_acc: 0.9040\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9914\n",
      "Epoch 00064: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0380 - acc: 0.9914 - val_loss: 0.3211 - val_acc: 0.9206\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9935\n",
      "Epoch 00065: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0326 - acc: 0.9935 - val_loss: 0.3130 - val_acc: 0.9241\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9948\n",
      "Epoch 00066: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0289 - acc: 0.9948 - val_loss: 0.4336 - val_acc: 0.8994\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9848\n",
      "Epoch 00067: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0577 - acc: 0.9847 - val_loss: 0.3431 - val_acc: 0.9138\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9892\n",
      "Epoch 00068: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0437 - acc: 0.9891 - val_loss: 0.3390 - val_acc: 0.9157\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9948\n",
      "Epoch 00069: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0276 - acc: 0.9948 - val_loss: 0.3110 - val_acc: 0.9266\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9906\n",
      "Epoch 00070: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0402 - acc: 0.9906 - val_loss: 0.3433 - val_acc: 0.9192\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9937\n",
      "Epoch 00071: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0291 - acc: 0.9937 - val_loss: 0.3074 - val_acc: 0.9248\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9893\n",
      "Epoch 00072: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0429 - acc: 0.9893 - val_loss: 0.3445 - val_acc: 0.9192\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9932\n",
      "Epoch 00073: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0307 - acc: 0.9931 - val_loss: 0.3499 - val_acc: 0.9152\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9927\n",
      "Epoch 00074: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0326 - acc: 0.9927 - val_loss: 0.3393 - val_acc: 0.9168\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9906\n",
      "Epoch 00075: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0373 - acc: 0.9905 - val_loss: 0.3436 - val_acc: 0.9201\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9945\n",
      "Epoch 00076: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0276 - acc: 0.9945 - val_loss: 0.3190 - val_acc: 0.9222\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9922\n",
      "Epoch 00077: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0325 - acc: 0.9922 - val_loss: 0.3259 - val_acc: 0.9201\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9968\n",
      "Epoch 00078: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0198 - acc: 0.9968 - val_loss: 0.3801 - val_acc: 0.9129\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9876\n",
      "Epoch 00079: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0466 - acc: 0.9876 - val_loss: 0.3518 - val_acc: 0.9168\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9971\n",
      "Epoch 00080: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0186 - acc: 0.9970 - val_loss: 0.3384 - val_acc: 0.9224\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9877\n",
      "Epoch 00081: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0448 - acc: 0.9877 - val_loss: 0.3296 - val_acc: 0.9229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9947\n",
      "Epoch 00082: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0266 - acc: 0.9946 - val_loss: 0.3890 - val_acc: 0.9096\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9890\n",
      "Epoch 00083: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0425 - acc: 0.9890 - val_loss: 0.3335 - val_acc: 0.9220\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9957\n",
      "Epoch 00084: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0219 - acc: 0.9957 - val_loss: 0.3303 - val_acc: 0.9215\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9956\n",
      "Epoch 00085: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0211 - acc: 0.9956 - val_loss: 0.3106 - val_acc: 0.9306\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9951\n",
      "Epoch 00086: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0247 - acc: 0.9951 - val_loss: 0.3704 - val_acc: 0.9164\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9916\n",
      "Epoch 00087: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0328 - acc: 0.9916 - val_loss: 0.3393 - val_acc: 0.9201\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9971\n",
      "Epoch 00088: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0168 - acc: 0.9971 - val_loss: 0.3264 - val_acc: 0.9206\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9968\n",
      "Epoch 00089: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0176 - acc: 0.9968 - val_loss: 0.4565 - val_acc: 0.8970\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9875\n",
      "Epoch 00090: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0435 - acc: 0.9874 - val_loss: 0.3245 - val_acc: 0.9224\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9905\n",
      "Epoch 00091: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0361 - acc: 0.9905 - val_loss: 0.3069 - val_acc: 0.9238\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9974\n",
      "Epoch 00092: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0152 - acc: 0.9974 - val_loss: 0.3431 - val_acc: 0.9217\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9922\n",
      "Epoch 00093: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0309 - acc: 0.9922 - val_loss: 0.3236 - val_acc: 0.9294\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9976\n",
      "Epoch 00094: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0148 - acc: 0.9976 - val_loss: 0.3661 - val_acc: 0.9217\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9942\n",
      "Epoch 00095: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0256 - acc: 0.9942 - val_loss: 0.3324 - val_acc: 0.9297\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9963\n",
      "Epoch 00096: val_loss did not improve from 0.29281\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0186 - acc: 0.9963 - val_loss: 0.3847 - val_acc: 0.9164\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.3492 - acc: 0.9007\n",
      "Loss: 0.3491537195747391 Accuracy: 0.9007269\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2038 - acc: 0.3223\n",
      "Epoch 00001: val_loss improved from inf to 1.89031, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/001-1.8903.hdf5\n",
      "36805/36805 [==============================] - 197s 5ms/sample - loss: 2.2037 - acc: 0.3223 - val_loss: 1.8903 - val_acc: 0.4172\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3443 - acc: 0.5985\n",
      "Epoch 00002: val_loss improved from 1.89031 to 1.12660, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/002-1.1266.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 1.3443 - acc: 0.5985 - val_loss: 1.1266 - val_acc: 0.6608\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9987 - acc: 0.7179\n",
      "Epoch 00003: val_loss improved from 1.12660 to 0.87488, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/003-0.8749.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.9986 - acc: 0.7179 - val_loss: 0.8749 - val_acc: 0.7510\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7879 - acc: 0.7815\n",
      "Epoch 00004: val_loss improved from 0.87488 to 0.82825, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/004-0.8282.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.7882 - acc: 0.7814 - val_loss: 0.8282 - val_acc: 0.7668\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6516 - acc: 0.8194\n",
      "Epoch 00005: val_loss improved from 0.82825 to 0.60760, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/005-0.6076.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.6517 - acc: 0.8194 - val_loss: 0.6076 - val_acc: 0.8241\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5526 - acc: 0.8499\n",
      "Epoch 00006: val_loss improved from 0.60760 to 0.51413, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/006-0.5141.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.5526 - acc: 0.8499 - val_loss: 0.5141 - val_acc: 0.8577\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4774 - acc: 0.8682\n",
      "Epoch 00007: val_loss improved from 0.51413 to 0.48232, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/007-0.4823.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.4774 - acc: 0.8682 - val_loss: 0.4823 - val_acc: 0.8640\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4242 - acc: 0.8832\n",
      "Epoch 00008: val_loss improved from 0.48232 to 0.41091, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/008-0.4109.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.4244 - acc: 0.8831 - val_loss: 0.4109 - val_acc: 0.8896\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3840 - acc: 0.8922\n",
      "Epoch 00009: val_loss improved from 0.41091 to 0.37034, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/009-0.3703.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.3840 - acc: 0.8922 - val_loss: 0.3703 - val_acc: 0.8998\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3439 - acc: 0.9046\n",
      "Epoch 00010: val_loss improved from 0.37034 to 0.33016, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/010-0.3302.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.3439 - acc: 0.9047 - val_loss: 0.3302 - val_acc: 0.9073\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3120 - acc: 0.9141\n",
      "Epoch 00011: val_loss did not improve from 0.33016\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.3124 - acc: 0.9141 - val_loss: 0.3519 - val_acc: 0.8966\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.9164\n",
      "Epoch 00012: val_loss did not improve from 0.33016\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.2981 - acc: 0.9164 - val_loss: 0.3376 - val_acc: 0.9078\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2690 - acc: 0.9240\n",
      "Epoch 00013: val_loss improved from 0.33016 to 0.31556, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/013-0.3156.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.2692 - acc: 0.9239 - val_loss: 0.3156 - val_acc: 0.9110\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2533 - acc: 0.9298\n",
      "Epoch 00014: val_loss improved from 0.31556 to 0.27053, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/014-0.2705.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.2533 - acc: 0.9298 - val_loss: 0.2705 - val_acc: 0.9255\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2312 - acc: 0.9371\n",
      "Epoch 00015: val_loss did not improve from 0.27053\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.2312 - acc: 0.9371 - val_loss: 0.3202 - val_acc: 0.9054\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2195 - acc: 0.9382\n",
      "Epoch 00016: val_loss did not improve from 0.27053\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.2195 - acc: 0.9382 - val_loss: 0.3009 - val_acc: 0.9154\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2068 - acc: 0.9421\n",
      "Epoch 00017: val_loss did not improve from 0.27053\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.2069 - acc: 0.9420 - val_loss: 0.2895 - val_acc: 0.9152\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2008 - acc: 0.9430\n",
      "Epoch 00018: val_loss improved from 0.27053 to 0.24368, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/018-0.2437.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.2007 - acc: 0.9430 - val_loss: 0.2437 - val_acc: 0.9248\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1785 - acc: 0.9506\n",
      "Epoch 00019: val_loss did not improve from 0.24368\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1786 - acc: 0.9506 - val_loss: 0.2626 - val_acc: 0.9210\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9505\n",
      "Epoch 00020: val_loss improved from 0.24368 to 0.23867, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/020-0.2387.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1762 - acc: 0.9505 - val_loss: 0.2387 - val_acc: 0.9313\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9572\n",
      "Epoch 00021: val_loss improved from 0.23867 to 0.23157, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/021-0.2316.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1583 - acc: 0.9572 - val_loss: 0.2316 - val_acc: 0.9306\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9601\n",
      "Epoch 00022: val_loss improved from 0.23157 to 0.21520, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/022-0.2152.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1464 - acc: 0.9601 - val_loss: 0.2152 - val_acc: 0.9385\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9594\n",
      "Epoch 00023: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1437 - acc: 0.9594 - val_loss: 0.2186 - val_acc: 0.9345\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9643\n",
      "Epoch 00024: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1332 - acc: 0.9643 - val_loss: 0.2203 - val_acc: 0.9345\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9657\n",
      "Epoch 00025: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1283 - acc: 0.9656 - val_loss: 0.2450 - val_acc: 0.9324\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9605\n",
      "Epoch 00026: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1390 - acc: 0.9605 - val_loss: 0.2233 - val_acc: 0.9387\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9700\n",
      "Epoch 00027: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1109 - acc: 0.9700 - val_loss: 0.2262 - val_acc: 0.9366\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9713\n",
      "Epoch 00028: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1054 - acc: 0.9713 - val_loss: 0.2229 - val_acc: 0.9352\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9738\n",
      "Epoch 00029: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0988 - acc: 0.9738 - val_loss: 0.2195 - val_acc: 0.9371\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9735\n",
      "Epoch 00030: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0959 - acc: 0.9735 - val_loss: 0.2274 - val_acc: 0.9352\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9727\n",
      "Epoch 00031: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0993 - acc: 0.9727 - val_loss: 0.2312 - val_acc: 0.9366\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9762\n",
      "Epoch 00032: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0899 - acc: 0.9762 - val_loss: 0.2189 - val_acc: 0.9385\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9785\n",
      "Epoch 00033: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0801 - acc: 0.9785 - val_loss: 0.2353 - val_acc: 0.9308\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9783\n",
      "Epoch 00034: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0814 - acc: 0.9782 - val_loss: 0.2518 - val_acc: 0.9294\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9787\n",
      "Epoch 00035: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0774 - acc: 0.9788 - val_loss: 0.2421 - val_acc: 0.9334\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9833\n",
      "Epoch 00036: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0660 - acc: 0.9833 - val_loss: 0.2364 - val_acc: 0.9380\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9835\n",
      "Epoch 00037: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0635 - acc: 0.9835 - val_loss: 0.2404 - val_acc: 0.9366\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9850\n",
      "Epoch 00038: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0589 - acc: 0.9850 - val_loss: 0.2431 - val_acc: 0.9341\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9829\n",
      "Epoch 00039: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0652 - acc: 0.9829 - val_loss: 0.2202 - val_acc: 0.9369\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9849\n",
      "Epoch 00040: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0568 - acc: 0.9849 - val_loss: 0.2447 - val_acc: 0.9345\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9881\n",
      "Epoch 00041: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0519 - acc: 0.9881 - val_loss: 0.2246 - val_acc: 0.9366\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9867\n",
      "Epoch 00042: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0524 - acc: 0.9866 - val_loss: 0.2642 - val_acc: 0.9276\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9872\n",
      "Epoch 00043: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0496 - acc: 0.9872 - val_loss: 0.2434 - val_acc: 0.9352\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9886\n",
      "Epoch 00044: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0475 - acc: 0.9886 - val_loss: 0.2427 - val_acc: 0.9315\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9911\n",
      "Epoch 00045: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0395 - acc: 0.9911 - val_loss: 0.2514 - val_acc: 0.9317\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9882\n",
      "Epoch 00046: val_loss did not improve from 0.21520\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0470 - acc: 0.9882 - val_loss: 0.2343 - val_acc: 0.9366\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9829\n",
      "Epoch 00047: val_loss improved from 0.21520 to 0.20910, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_8_conv_checkpoint/047-0.2091.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0618 - acc: 0.9829 - val_loss: 0.2091 - val_acc: 0.9415\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9911\n",
      "Epoch 00048: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0382 - acc: 0.9911 - val_loss: 0.2170 - val_acc: 0.9404\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9941\n",
      "Epoch 00049: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0299 - acc: 0.9941 - val_loss: 0.2445 - val_acc: 0.9369\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9882\n",
      "Epoch 00050: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0456 - acc: 0.9882 - val_loss: 0.2493 - val_acc: 0.9364\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9876\n",
      "Epoch 00051: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0473 - acc: 0.9876 - val_loss: 0.2161 - val_acc: 0.9399\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9878\n",
      "Epoch 00052: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0468 - acc: 0.9878 - val_loss: 0.2317 - val_acc: 0.9411\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9952\n",
      "Epoch 00053: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0261 - acc: 0.9952 - val_loss: 0.2322 - val_acc: 0.9429\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9946\n",
      "Epoch 00054: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0263 - acc: 0.9946 - val_loss: 0.2408 - val_acc: 0.9383\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9933\n",
      "Epoch 00055: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0305 - acc: 0.9933 - val_loss: 0.2256 - val_acc: 0.9446\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9952\n",
      "Epoch 00056: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0257 - acc: 0.9952 - val_loss: 0.2741 - val_acc: 0.9327\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9850\n",
      "Epoch 00057: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0515 - acc: 0.9850 - val_loss: 0.2231 - val_acc: 0.9436\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9964\n",
      "Epoch 00058: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0214 - acc: 0.9964 - val_loss: 0.2480 - val_acc: 0.9390\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9967\n",
      "Epoch 00059: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0201 - acc: 0.9967 - val_loss: 0.2399 - val_acc: 0.9378\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9933\n",
      "Epoch 00060: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0293 - acc: 0.9933 - val_loss: 0.2307 - val_acc: 0.9425\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9914\n",
      "Epoch 00061: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0330 - acc: 0.9914 - val_loss: 0.2241 - val_acc: 0.9432\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9959\n",
      "Epoch 00062: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0207 - acc: 0.9959 - val_loss: 0.2616 - val_acc: 0.9345\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9872\n",
      "Epoch 00063: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0453 - acc: 0.9872 - val_loss: 0.2330 - val_acc: 0.9432\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9896\n",
      "Epoch 00064: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0412 - acc: 0.9896 - val_loss: 0.2218 - val_acc: 0.9436\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9972\n",
      "Epoch 00065: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0175 - acc: 0.9972 - val_loss: 0.2315 - val_acc: 0.9427\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9963\n",
      "Epoch 00066: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0188 - acc: 0.9963 - val_loss: 0.2308 - val_acc: 0.9422\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9913\n",
      "Epoch 00067: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0338 - acc: 0.9913 - val_loss: 0.2397 - val_acc: 0.9401\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9949\n",
      "Epoch 00068: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0235 - acc: 0.9948 - val_loss: 0.2472 - val_acc: 0.9420\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9947\n",
      "Epoch 00069: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0236 - acc: 0.9947 - val_loss: 0.2436 - val_acc: 0.9404\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9976\n",
      "Epoch 00070: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0148 - acc: 0.9976 - val_loss: 0.2484 - val_acc: 0.9406\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9961\n",
      "Epoch 00071: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0188 - acc: 0.9961 - val_loss: 0.2747 - val_acc: 0.9380\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9970\n",
      "Epoch 00072: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0158 - acc: 0.9970 - val_loss: 0.2676 - val_acc: 0.9373\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9965\n",
      "Epoch 00073: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0168 - acc: 0.9965 - val_loss: 0.2634 - val_acc: 0.9383\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9904\n",
      "Epoch 00074: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0341 - acc: 0.9904 - val_loss: 0.3113 - val_acc: 0.9264\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9973\n",
      "Epoch 00075: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0154 - acc: 0.9973 - val_loss: 0.2794 - val_acc: 0.9362\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9943\n",
      "Epoch 00076: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0234 - acc: 0.9942 - val_loss: 0.2486 - val_acc: 0.9425\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9957\n",
      "Epoch 00077: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0184 - acc: 0.9957 - val_loss: 0.2427 - val_acc: 0.9432\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9976\n",
      "Epoch 00078: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0126 - acc: 0.9976 - val_loss: 0.2562 - val_acc: 0.9385\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9923\n",
      "Epoch 00079: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0298 - acc: 0.9923 - val_loss: 0.2830 - val_acc: 0.9378\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9979\n",
      "Epoch 00080: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0121 - acc: 0.9979 - val_loss: 0.2469 - val_acc: 0.9441\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9973\n",
      "Epoch 00081: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0129 - acc: 0.9973 - val_loss: 0.2499 - val_acc: 0.9404\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9966\n",
      "Epoch 00082: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0156 - acc: 0.9966 - val_loss: 0.2586 - val_acc: 0.9413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9970\n",
      "Epoch 00083: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0137 - acc: 0.9970 - val_loss: 0.2650 - val_acc: 0.9385\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9904\n",
      "Epoch 00084: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0330 - acc: 0.9904 - val_loss: 0.2543 - val_acc: 0.9392\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9929\n",
      "Epoch 00085: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0261 - acc: 0.9929 - val_loss: 0.2400 - val_acc: 0.9471\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9984\n",
      "Epoch 00086: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0094 - acc: 0.9984 - val_loss: 0.2662 - val_acc: 0.9425\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9961\n",
      "Epoch 00087: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0172 - acc: 0.9961 - val_loss: 0.2589 - val_acc: 0.9432\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9965\n",
      "Epoch 00088: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0157 - acc: 0.9965 - val_loss: 0.2495 - val_acc: 0.9408\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9982\n",
      "Epoch 00089: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0114 - acc: 0.9981 - val_loss: 0.3603 - val_acc: 0.9243\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9893\n",
      "Epoch 00090: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0374 - acc: 0.9893 - val_loss: 0.2575 - val_acc: 0.9418\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9985\n",
      "Epoch 00091: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0092 - acc: 0.9985 - val_loss: 0.2660 - val_acc: 0.9418\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9952\n",
      "Epoch 00092: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0195 - acc: 0.9952 - val_loss: 0.2720 - val_acc: 0.9343\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9934\n",
      "Epoch 00093: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0251 - acc: 0.9934 - val_loss: 0.2489 - val_acc: 0.9432\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9973\n",
      "Epoch 00094: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0124 - acc: 0.9973 - val_loss: 0.2702 - val_acc: 0.9371\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9985\n",
      "Epoch 00095: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0090 - acc: 0.9985 - val_loss: 0.2585 - val_acc: 0.9411\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9962\n",
      "Epoch 00096: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0157 - acc: 0.9962 - val_loss: 0.2847 - val_acc: 0.9350\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9889\n",
      "Epoch 00097: val_loss did not improve from 0.20910\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0373 - acc: 0.9889 - val_loss: 0.2470 - val_acc: 0.9432\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2729 - acc: 0.9240\n",
      "Loss: 0.27291673340158673 Accuracy: 0.92398757\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1069 - acc: 0.3512\n",
      "Epoch 00001: val_loss improved from inf to 1.70987, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/001-1.7099.hdf5\n",
      "36805/36805 [==============================] - 205s 6ms/sample - loss: 2.1069 - acc: 0.3512 - val_loss: 1.7099 - val_acc: 0.5171\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1623 - acc: 0.6621\n",
      "Epoch 00002: val_loss improved from 1.70987 to 1.03963, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/002-1.0396.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 1.1625 - acc: 0.6620 - val_loss: 1.0396 - val_acc: 0.7016\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8302 - acc: 0.7673\n",
      "Epoch 00003: val_loss improved from 1.03963 to 0.71613, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/003-0.7161.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.8301 - acc: 0.7674 - val_loss: 0.7161 - val_acc: 0.8046\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6572 - acc: 0.8165\n",
      "Epoch 00004: val_loss improved from 0.71613 to 0.58230, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/004-0.5823.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.6571 - acc: 0.8166 - val_loss: 0.5823 - val_acc: 0.8472\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5489 - acc: 0.8466\n",
      "Epoch 00005: val_loss improved from 0.58230 to 0.47497, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/005-0.4750.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.5489 - acc: 0.8466 - val_loss: 0.4750 - val_acc: 0.8686\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4691 - acc: 0.8712\n",
      "Epoch 00006: val_loss improved from 0.47497 to 0.42279, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/006-0.4228.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.4691 - acc: 0.8712 - val_loss: 0.4228 - val_acc: 0.8859\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4074 - acc: 0.8875\n",
      "Epoch 00007: val_loss improved from 0.42279 to 0.38895, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/007-0.3890.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.4073 - acc: 0.8875 - val_loss: 0.3890 - val_acc: 0.8880\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3656 - acc: 0.8972\n",
      "Epoch 00008: val_loss improved from 0.38895 to 0.32604, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/008-0.3260.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.3657 - acc: 0.8972 - val_loss: 0.3260 - val_acc: 0.9099\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3350 - acc: 0.9051\n",
      "Epoch 00009: val_loss improved from 0.32604 to 0.30532, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/009-0.3053.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.3352 - acc: 0.9050 - val_loss: 0.3053 - val_acc: 0.9131\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2997 - acc: 0.9161\n",
      "Epoch 00010: val_loss did not improve from 0.30532\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.2997 - acc: 0.9160 - val_loss: 0.3164 - val_acc: 0.9110\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2760 - acc: 0.9230\n",
      "Epoch 00011: val_loss improved from 0.30532 to 0.27834, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/011-0.2783.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.2761 - acc: 0.9229 - val_loss: 0.2783 - val_acc: 0.9194\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2530 - acc: 0.9292\n",
      "Epoch 00012: val_loss improved from 0.27834 to 0.25754, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/012-0.2575.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.2532 - acc: 0.9291 - val_loss: 0.2575 - val_acc: 0.9241\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2378 - acc: 0.9324\n",
      "Epoch 00013: val_loss did not improve from 0.25754\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.2377 - acc: 0.9324 - val_loss: 0.2581 - val_acc: 0.9220\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2205 - acc: 0.9374\n",
      "Epoch 00014: val_loss did not improve from 0.25754\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.2205 - acc: 0.9375 - val_loss: 0.2791 - val_acc: 0.9154\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2013 - acc: 0.9422\n",
      "Epoch 00015: val_loss improved from 0.25754 to 0.24911, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/015-0.2491.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.2013 - acc: 0.9422 - val_loss: 0.2491 - val_acc: 0.9248\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9443\n",
      "Epoch 00016: val_loss did not improve from 0.24911\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1923 - acc: 0.9443 - val_loss: 0.2715 - val_acc: 0.9182\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1794 - acc: 0.9487\n",
      "Epoch 00017: val_loss improved from 0.24911 to 0.22635, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/017-0.2264.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1794 - acc: 0.9487 - val_loss: 0.2264 - val_acc: 0.9273\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1648 - acc: 0.9533\n",
      "Epoch 00018: val_loss did not improve from 0.22635\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1649 - acc: 0.9533 - val_loss: 0.2301 - val_acc: 0.9273\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1603 - acc: 0.9546\n",
      "Epoch 00019: val_loss did not improve from 0.22635\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1604 - acc: 0.9546 - val_loss: 0.2342 - val_acc: 0.9292\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9567\n",
      "Epoch 00020: val_loss improved from 0.22635 to 0.21956, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/020-0.2196.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1501 - acc: 0.9567 - val_loss: 0.2196 - val_acc: 0.9334\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1391 - acc: 0.9609\n",
      "Epoch 00021: val_loss improved from 0.21956 to 0.21504, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/021-0.2150.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1391 - acc: 0.9609 - val_loss: 0.2150 - val_acc: 0.9336\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9630\n",
      "Epoch 00022: val_loss did not improve from 0.21504\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1295 - acc: 0.9630 - val_loss: 0.2247 - val_acc: 0.9334\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9665\n",
      "Epoch 00023: val_loss improved from 0.21504 to 0.20854, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/023-0.2085.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1219 - acc: 0.9665 - val_loss: 0.2085 - val_acc: 0.9378\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9672\n",
      "Epoch 00024: val_loss did not improve from 0.20854\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1166 - acc: 0.9672 - val_loss: 0.2293 - val_acc: 0.9329\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9705\n",
      "Epoch 00025: val_loss did not improve from 0.20854\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.1079 - acc: 0.9704 - val_loss: 0.2201 - val_acc: 0.9371\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9724\n",
      "Epoch 00026: val_loss improved from 0.20854 to 0.20058, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/026-0.2006.hdf5\n",
      "36805/36805 [==============================] - 187s 5ms/sample - loss: 0.1001 - acc: 0.9724 - val_loss: 0.2006 - val_acc: 0.9411\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9745\n",
      "Epoch 00027: val_loss did not improve from 0.20058\n",
      "36805/36805 [==============================] - 187s 5ms/sample - loss: 0.0927 - acc: 0.9745 - val_loss: 0.3036 - val_acc: 0.9047\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9753\n",
      "Epoch 00028: val_loss did not improve from 0.20058\n",
      "36805/36805 [==============================] - 187s 5ms/sample - loss: 0.0890 - acc: 0.9753 - val_loss: 0.2306 - val_acc: 0.9336\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9765\n",
      "Epoch 00029: val_loss did not improve from 0.20058\n",
      "36805/36805 [==============================] - 187s 5ms/sample - loss: 0.0839 - acc: 0.9765 - val_loss: 0.2148 - val_acc: 0.9341\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9766\n",
      "Epoch 00030: val_loss did not improve from 0.20058\n",
      "36805/36805 [==============================] - 187s 5ms/sample - loss: 0.0849 - acc: 0.9766 - val_loss: 0.2223 - val_acc: 0.9359\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9779\n",
      "Epoch 00031: val_loss did not improve from 0.20058\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0790 - acc: 0.9779 - val_loss: 0.2591 - val_acc: 0.9250\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9783\n",
      "Epoch 00032: val_loss improved from 0.20058 to 0.19657, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/032-0.1966.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0794 - acc: 0.9783 - val_loss: 0.1966 - val_acc: 0.9441\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9801\n",
      "Epoch 00033: val_loss did not improve from 0.19657\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0723 - acc: 0.9801 - val_loss: 0.2026 - val_acc: 0.9399\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9823\n",
      "Epoch 00034: val_loss did not improve from 0.19657\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0661 - acc: 0.9823 - val_loss: 0.2337 - val_acc: 0.9348\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9840\n",
      "Epoch 00035: val_loss did not improve from 0.19657\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0615 - acc: 0.9840 - val_loss: 0.2190 - val_acc: 0.9366\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9870\n",
      "Epoch 00036: val_loss did not improve from 0.19657\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0532 - acc: 0.9869 - val_loss: 0.2179 - val_acc: 0.9352\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9822\n",
      "Epoch 00037: val_loss did not improve from 0.19657\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0647 - acc: 0.9822 - val_loss: 0.2266 - val_acc: 0.9366\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9810\n",
      "Epoch 00038: val_loss did not improve from 0.19657\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0663 - acc: 0.9809 - val_loss: 0.2369 - val_acc: 0.9352\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9788\n",
      "Epoch 00039: val_loss improved from 0.19657 to 0.19614, saving model to model/checkpoint/1D_CNN_custom_4_ch_128_BN_9_conv_checkpoint/039-0.1961.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0740 - acc: 0.9788 - val_loss: 0.1961 - val_acc: 0.9422\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9883\n",
      "Epoch 00040: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 0.0477 - acc: 0.9882 - val_loss: 0.2346 - val_acc: 0.9327\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9798\n",
      "Epoch 00041: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0696 - acc: 0.9798 - val_loss: 0.2210 - val_acc: 0.9408\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9907\n",
      "Epoch 00042: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0393 - acc: 0.9906 - val_loss: 0.1978 - val_acc: 0.9418\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9862\n",
      "Epoch 00043: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0521 - acc: 0.9862 - val_loss: 0.2013 - val_acc: 0.9441\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9921\n",
      "Epoch 00044: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0355 - acc: 0.9921 - val_loss: 0.2230 - val_acc: 0.9364\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9859\n",
      "Epoch 00045: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0522 - acc: 0.9859 - val_loss: 0.2194 - val_acc: 0.9394\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9925\n",
      "Epoch 00046: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0330 - acc: 0.9925 - val_loss: 0.2094 - val_acc: 0.9413\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9903\n",
      "Epoch 00047: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0382 - acc: 0.9903 - val_loss: 0.2195 - val_acc: 0.9418\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9924\n",
      "Epoch 00048: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0319 - acc: 0.9924 - val_loss: 0.2206 - val_acc: 0.9401\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9888\n",
      "Epoch 00049: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0413 - acc: 0.9888 - val_loss: 0.2145 - val_acc: 0.9420\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9924\n",
      "Epoch 00050: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0302 - acc: 0.9924 - val_loss: 0.2513 - val_acc: 0.9317\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9923\n",
      "Epoch 00051: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0316 - acc: 0.9923 - val_loss: 0.2415 - val_acc: 0.9357\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9842\n",
      "Epoch 00052: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0536 - acc: 0.9841 - val_loss: 0.2252 - val_acc: 0.9397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9920\n",
      "Epoch 00053: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0321 - acc: 0.9920 - val_loss: 0.2385 - val_acc: 0.9364\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9954\n",
      "Epoch 00054: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0232 - acc: 0.9954 - val_loss: 0.2236 - val_acc: 0.9401\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9945\n",
      "Epoch 00055: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0252 - acc: 0.9945 - val_loss: 0.2426 - val_acc: 0.9336\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9901\n",
      "Epoch 00056: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0375 - acc: 0.9901 - val_loss: 0.2615 - val_acc: 0.9297\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9891\n",
      "Epoch 00057: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0397 - acc: 0.9891 - val_loss: 0.2203 - val_acc: 0.9394\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9959\n",
      "Epoch 00058: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0211 - acc: 0.9959 - val_loss: 0.2175 - val_acc: 0.9453\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9950\n",
      "Epoch 00059: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0236 - acc: 0.9950 - val_loss: 0.2727 - val_acc: 0.9331\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9918\n",
      "Epoch 00060: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0307 - acc: 0.9918 - val_loss: 0.2732 - val_acc: 0.9301\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9874\n",
      "Epoch 00061: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0429 - acc: 0.9873 - val_loss: 0.2640 - val_acc: 0.9359\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9886\n",
      "Epoch 00062: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0397 - acc: 0.9886 - val_loss: 0.2200 - val_acc: 0.9418\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9946\n",
      "Epoch 00063: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0224 - acc: 0.9946 - val_loss: 0.2159 - val_acc: 0.9462\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9968\n",
      "Epoch 00064: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0167 - acc: 0.9968 - val_loss: 0.2299 - val_acc: 0.9446\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9949\n",
      "Epoch 00065: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0215 - acc: 0.9949 - val_loss: 0.2255 - val_acc: 0.9434\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9964\n",
      "Epoch 00066: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0171 - acc: 0.9964 - val_loss: 0.2392 - val_acc: 0.9406\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9918\n",
      "Epoch 00067: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0289 - acc: 0.9917 - val_loss: 0.2825 - val_acc: 0.9264\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9937\n",
      "Epoch 00068: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0251 - acc: 0.9937 - val_loss: 0.2525 - val_acc: 0.9357\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9930\n",
      "Epoch 00069: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0258 - acc: 0.9930 - val_loss: 0.2530 - val_acc: 0.9373\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9937\n",
      "Epoch 00070: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0247 - acc: 0.9937 - val_loss: 0.2258 - val_acc: 0.9471\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9924\n",
      "Epoch 00071: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0278 - acc: 0.9923 - val_loss: 0.2203 - val_acc: 0.9469\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9941\n",
      "Epoch 00072: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0227 - acc: 0.9941 - val_loss: 0.2376 - val_acc: 0.9441\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9968\n",
      "Epoch 00073: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0146 - acc: 0.9968 - val_loss: 0.2266 - val_acc: 0.9481\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9982\n",
      "Epoch 00074: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0118 - acc: 0.9982 - val_loss: 0.2374 - val_acc: 0.9446\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9965\n",
      "Epoch 00075: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0159 - acc: 0.9965 - val_loss: 0.2678 - val_acc: 0.9413\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9896\n",
      "Epoch 00076: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0348 - acc: 0.9896 - val_loss: 0.2213 - val_acc: 0.9485\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9971\n",
      "Epoch 00077: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0144 - acc: 0.9971 - val_loss: 0.2379 - val_acc: 0.9406\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9977\n",
      "Epoch 00078: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0122 - acc: 0.9977 - val_loss: 0.2805 - val_acc: 0.9387\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9891\n",
      "Epoch 00079: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0360 - acc: 0.9891 - val_loss: 0.2331 - val_acc: 0.9453\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9918\n",
      "Epoch 00080: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0282 - acc: 0.9918 - val_loss: 0.2358 - val_acc: 0.9453\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9978\n",
      "Epoch 00081: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0116 - acc: 0.9978 - val_loss: 0.2264 - val_acc: 0.9443\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9945\n",
      "Epoch 00082: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0212 - acc: 0.9945 - val_loss: 0.2329 - val_acc: 0.9478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9950\n",
      "Epoch 00083: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0193 - acc: 0.9950 - val_loss: 0.2372 - val_acc: 0.9429\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9974\n",
      "Epoch 00084: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0136 - acc: 0.9974 - val_loss: 0.2248 - val_acc: 0.9490\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9955\n",
      "Epoch 00085: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0176 - acc: 0.9955 - val_loss: 0.2426 - val_acc: 0.9441\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9986\n",
      "Epoch 00086: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0092 - acc: 0.9986 - val_loss: 0.2418 - val_acc: 0.9439\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9979\n",
      "Epoch 00087: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0107 - acc: 0.9978 - val_loss: 0.2900 - val_acc: 0.9371\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9896\n",
      "Epoch 00088: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0329 - acc: 0.9896 - val_loss: 0.2423 - val_acc: 0.9460\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9969\n",
      "Epoch 00089: val_loss did not improve from 0.19614\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0129 - acc: 0.9969 - val_loss: 0.2480 - val_acc: 0.9411\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2554 - acc: 0.9259\n",
      "Loss: 0.25539070464678393 Accuracy: 0.9258567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 10):\n",
    "    base = '1D_CNN_custom_4_ch_128_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_4_ch_128_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 965,456\n",
      "Trainable params: 888,784\n",
      "Non-trainable params: 76,672\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 1.2746 - acc: 0.6557\n",
      "Loss: 1.274618286234815 Accuracy: 0.6556594\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 12608)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 12608)             50432     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                201744    \n",
      "=================================================================\n",
      "Total params: 480,656\n",
      "Trainable params: 454,416\n",
      "Non-trainable params: 26,240\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.9102 - acc: 0.7497\n",
      "Loss: 0.9101950282991118 Accuracy: 0.7497404\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 4160)              16640     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                66576     \n",
      "=================================================================\n",
      "Total params: 332,496\n",
      "Trainable params: 323,024\n",
      "Non-trainable params: 9,472\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.5948 - acc: 0.8355\n",
      "Loss: 0.5948092682958268 Accuracy: 0.835514\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 65, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 672)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 672)               2688      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                10768     \n",
      "=================================================================\n",
      "Total params: 273,136\n",
      "Trainable params: 270,576\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.3492 - acc: 0.9007\n",
      "Loss: 0.3491537195747391 Accuracy: 0.9007269\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 65, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 32)            5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 224)               896       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                3600      \n",
      "=================================================================\n",
      "Total params: 269,456\n",
      "Trainable params: 267,728\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2729 - acc: 0.9240\n",
      "Loss: 0.27291673340158673 Accuracy: 0.92398757\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 32)            5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 32)             5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 7, 32)             128       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 32)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 271,536\n",
      "Trainable params: 270,064\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2554 - acc: 0.9259\n",
      "Loss: 0.25539070464678393 Accuracy: 0.9258567\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_4_ch_128_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(4, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_4_ch_128_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 965,456\n",
      "Trainable params: 888,784\n",
      "Non-trainable params: 76,672\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 2.5882 - acc: 0.6069\n",
      "Loss: 2.5882132176917167 Accuracy: 0.6068536\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 12608)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 12608)             50432     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                201744    \n",
      "=================================================================\n",
      "Total params: 480,656\n",
      "Trainable params: 454,416\n",
      "Non-trainable params: 26,240\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 1.3450 - acc: 0.7383\n",
      "Loss: 1.3450261568602249 Accuracy: 0.7383177\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 4160)              16640     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                66576     \n",
      "=================================================================\n",
      "Total params: 332,496\n",
      "Trainable params: 323,024\n",
      "Non-trainable params: 9,472\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.7439 - acc: 0.8449\n",
      "Loss: 0.7438777809821433 Accuracy: 0.84485984\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 65, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 672)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 672)               2688      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                10768     \n",
      "=================================================================\n",
      "Total params: 273,136\n",
      "Trainable params: 270,576\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.4491 - acc: 0.8941\n",
      "Loss: 0.4490877017672807 Accuracy: 0.894081\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 65, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 32)            5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 224)               896       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                3600      \n",
      "=================================================================\n",
      "Total params: 269,456\n",
      "Trainable params: 267,728\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.3248 - acc: 0.9271\n",
      "Loss: 0.32484145322940305 Accuracy: 0.9271028\n",
      "\n",
      "1D_CNN_custom_4_ch_128_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 32)            5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 32)             5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 7, 32)             128       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 32)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 271,536\n",
      "Trainable params: 270,064\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.3160 - acc: 0.9248\n",
      "Loss: 0.31601402289306635 Accuracy: 0.9248183\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(4, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
