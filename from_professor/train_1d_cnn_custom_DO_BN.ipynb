{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.4772 - acc: 0.2365\n",
      "Epoch 00001: val_loss improved from inf to 2.25122, saving model to model/checkpoint/1D_CNN_custom_DO_BN_1_conv_checkpoint/001-2.2512.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 3.4771 - acc: 0.2365 - val_loss: 2.2512 - val_acc: 0.2970\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5221 - acc: 0.5434\n",
      "Epoch 00002: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.5220 - acc: 0.5434 - val_loss: 2.4866 - val_acc: 0.2954\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0686 - acc: 0.6806\n",
      "Epoch 00003: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.0687 - acc: 0.6806 - val_loss: 2.8945 - val_acc: 0.2970\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8001 - acc: 0.7653\n",
      "Epoch 00004: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.8001 - acc: 0.7653 - val_loss: 2.9820 - val_acc: 0.3058\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6336 - acc: 0.8170\n",
      "Epoch 00005: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.6336 - acc: 0.8170 - val_loss: 3.2328 - val_acc: 0.2907\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5026 - acc: 0.8577\n",
      "Epoch 00006: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.5027 - acc: 0.8577 - val_loss: 3.8758 - val_acc: 0.2846\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4077 - acc: 0.8890\n",
      "Epoch 00007: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.4078 - acc: 0.8890 - val_loss: 3.6131 - val_acc: 0.3063\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3661 - acc: 0.9002\n",
      "Epoch 00008: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.3661 - acc: 0.9002 - val_loss: 4.2940 - val_acc: 0.2816\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3292 - acc: 0.9115\n",
      "Epoch 00009: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.3292 - acc: 0.9115 - val_loss: 4.1613 - val_acc: 0.2863\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2719 - acc: 0.9293\n",
      "Epoch 00010: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2720 - acc: 0.9292 - val_loss: 4.1890 - val_acc: 0.3035\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2358 - acc: 0.9390\n",
      "Epoch 00011: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2358 - acc: 0.9390 - val_loss: 4.2606 - val_acc: 0.2930\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2193 - acc: 0.9453\n",
      "Epoch 00012: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2193 - acc: 0.9453 - val_loss: 5.5297 - val_acc: 0.2767\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1912 - acc: 0.9544\n",
      "Epoch 00013: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1912 - acc: 0.9544 - val_loss: 4.5161 - val_acc: 0.3035\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1812 - acc: 0.9556\n",
      "Epoch 00014: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1812 - acc: 0.9556 - val_loss: 5.5687 - val_acc: 0.2786\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1686 - acc: 0.9592\n",
      "Epoch 00015: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1686 - acc: 0.9591 - val_loss: 5.3352 - val_acc: 0.2821\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1629 - acc: 0.9606\n",
      "Epoch 00016: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1629 - acc: 0.9606 - val_loss: 5.2194 - val_acc: 0.2772\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9676\n",
      "Epoch 00017: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1393 - acc: 0.9676 - val_loss: 5.3938 - val_acc: 0.2912\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9709\n",
      "Epoch 00018: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1271 - acc: 0.9709 - val_loss: 5.3595 - val_acc: 0.3042\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9775\n",
      "Epoch 00019: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1071 - acc: 0.9775 - val_loss: 5.4416 - val_acc: 0.3075\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9730\n",
      "Epoch 00020: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1218 - acc: 0.9730 - val_loss: 6.4125 - val_acc: 0.2555\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9745\n",
      "Epoch 00021: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1153 - acc: 0.9745 - val_loss: 5.7091 - val_acc: 0.2900\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9749\n",
      "Epoch 00022: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1160 - acc: 0.9749 - val_loss: 5.4422 - val_acc: 0.3156\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9782\n",
      "Epoch 00023: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1031 - acc: 0.9782 - val_loss: 5.8874 - val_acc: 0.2842\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9774\n",
      "Epoch 00024: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1061 - acc: 0.9774 - val_loss: 6.1435 - val_acc: 0.2926\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9806\n",
      "Epoch 00025: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0944 - acc: 0.9806 - val_loss: 5.6681 - val_acc: 0.3096\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9823\n",
      "Epoch 00026: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0897 - acc: 0.9823 - val_loss: 6.3115 - val_acc: 0.2770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9830\n",
      "Epoch 00027: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0844 - acc: 0.9830 - val_loss: 6.3833 - val_acc: 0.2888\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9811\n",
      "Epoch 00028: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0904 - acc: 0.9811 - val_loss: 6.0583 - val_acc: 0.2914\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9817\n",
      "Epoch 00029: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0885 - acc: 0.9817 - val_loss: 6.4023 - val_acc: 0.2807\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9829\n",
      "Epoch 00030: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0842 - acc: 0.9829 - val_loss: 6.4904 - val_acc: 0.2779\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9842\n",
      "Epoch 00031: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0788 - acc: 0.9842 - val_loss: 6.4377 - val_acc: 0.2905\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9844\n",
      "Epoch 00032: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0793 - acc: 0.9844 - val_loss: 7.6643 - val_acc: 0.2639\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9848\n",
      "Epoch 00033: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0788 - acc: 0.9848 - val_loss: 5.8551 - val_acc: 0.3033\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9849\n",
      "Epoch 00034: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0793 - acc: 0.9849 - val_loss: 6.4717 - val_acc: 0.3040\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9833\n",
      "Epoch 00035: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0852 - acc: 0.9833 - val_loss: 6.5459 - val_acc: 0.2996\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9841\n",
      "Epoch 00036: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0789 - acc: 0.9841 - val_loss: 6.9047 - val_acc: 0.2872\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9836\n",
      "Epoch 00037: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0804 - acc: 0.9836 - val_loss: 6.6053 - val_acc: 0.2972\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9877\n",
      "Epoch 00038: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0656 - acc: 0.9877 - val_loss: 6.4144 - val_acc: 0.3096\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9881\n",
      "Epoch 00039: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0649 - acc: 0.9881 - val_loss: 6.9962 - val_acc: 0.2895\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9892\n",
      "Epoch 00040: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0632 - acc: 0.9892 - val_loss: 6.7737 - val_acc: 0.2879\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9886\n",
      "Epoch 00041: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0647 - acc: 0.9886 - val_loss: 6.4248 - val_acc: 0.2940\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9874\n",
      "Epoch 00042: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0692 - acc: 0.9874 - val_loss: 6.6103 - val_acc: 0.3019\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9879\n",
      "Epoch 00043: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0667 - acc: 0.9879 - val_loss: 7.4426 - val_acc: 0.2667\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9908\n",
      "Epoch 00044: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0558 - acc: 0.9908 - val_loss: 6.4292 - val_acc: 0.2998\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9896\n",
      "Epoch 00045: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0580 - acc: 0.9896 - val_loss: 7.9070 - val_acc: 0.2560\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9887\n",
      "Epoch 00046: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0635 - acc: 0.9887 - val_loss: 6.6075 - val_acc: 0.2949\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9901\n",
      "Epoch 00047: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0580 - acc: 0.9901 - val_loss: 6.9272 - val_acc: 0.2928\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9895\n",
      "Epoch 00048: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0625 - acc: 0.9895 - val_loss: 8.4199 - val_acc: 0.2679\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9886\n",
      "Epoch 00049: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0638 - acc: 0.9886 - val_loss: 7.9076 - val_acc: 0.2604\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9881\n",
      "Epoch 00050: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0650 - acc: 0.9881 - val_loss: 7.2303 - val_acc: 0.2721\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9908\n",
      "Epoch 00051: val_loss did not improve from 2.25122\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0536 - acc: 0.9908 - val_loss: 6.9269 - val_acc: 0.3035\n",
      "\n",
      "1D_CNN_custom_DO_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 400us/sample - loss: 2.3054 - acc: 0.2748\n",
      "Loss: 2.3053826310305334 Accuracy: 0.27476636\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.0391 - acc: 0.2667\n",
      "Epoch 00001: val_loss improved from inf to 3.23351, saving model to model/checkpoint/1D_CNN_custom_DO_BN_2_conv_checkpoint/001-3.2335.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 3.0392 - acc: 0.2667 - val_loss: 3.2335 - val_acc: 0.1917\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9317 - acc: 0.4469\n",
      "Epoch 00002: val_loss improved from 3.23351 to 2.73035, saving model to model/checkpoint/1D_CNN_custom_DO_BN_2_conv_checkpoint/002-2.7304.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 1.9316 - acc: 0.4469 - val_loss: 2.7304 - val_acc: 0.3063\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5411 - acc: 0.5454\n",
      "Epoch 00003: val_loss did not improve from 2.73035\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 1.5411 - acc: 0.5454 - val_loss: 2.7637 - val_acc: 0.3296\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1991 - acc: 0.6345\n",
      "Epoch 00004: val_loss did not improve from 2.73035\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 1.1990 - acc: 0.6345 - val_loss: 2.9907 - val_acc: 0.3678\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9440 - acc: 0.7090\n",
      "Epoch 00005: val_loss did not improve from 2.73035\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.9440 - acc: 0.7090 - val_loss: 2.7465 - val_acc: 0.3843\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7867 - acc: 0.7535\n",
      "Epoch 00006: val_loss improved from 2.73035 to 2.62487, saving model to model/checkpoint/1D_CNN_custom_DO_BN_2_conv_checkpoint/006-2.6249.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.7866 - acc: 0.7535 - val_loss: 2.6249 - val_acc: 0.3981\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6265 - acc: 0.8045\n",
      "Epoch 00007: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.6266 - acc: 0.8044 - val_loss: 3.1971 - val_acc: 0.3783\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5187 - acc: 0.8355\n",
      "Epoch 00008: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.5187 - acc: 0.8355 - val_loss: 3.1501 - val_acc: 0.3953\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4550 - acc: 0.8555\n",
      "Epoch 00009: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.4550 - acc: 0.8556 - val_loss: 4.8133 - val_acc: 0.2977\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3955 - acc: 0.8748\n",
      "Epoch 00010: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.3956 - acc: 0.8747 - val_loss: 3.4653 - val_acc: 0.4088\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3551 - acc: 0.8877\n",
      "Epoch 00011: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.3551 - acc: 0.8877 - val_loss: 4.3299 - val_acc: 0.3331\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3626 - acc: 0.8886\n",
      "Epoch 00012: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.3626 - acc: 0.8887 - val_loss: 3.5909 - val_acc: 0.4109\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2855 - acc: 0.9127\n",
      "Epoch 00013: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.2856 - acc: 0.9126 - val_loss: 4.6602 - val_acc: 0.3597\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3068 - acc: 0.9073\n",
      "Epoch 00014: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3067 - acc: 0.9073 - val_loss: 4.0279 - val_acc: 0.4009\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2659 - acc: 0.9189\n",
      "Epoch 00015: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.2659 - acc: 0.9189 - val_loss: 3.7507 - val_acc: 0.4237\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2297 - acc: 0.9314\n",
      "Epoch 00016: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.2297 - acc: 0.9314 - val_loss: 5.2290 - val_acc: 0.3622\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.9265\n",
      "Epoch 00017: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2470 - acc: 0.9265 - val_loss: 3.9289 - val_acc: 0.4239\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2076 - acc: 0.9380\n",
      "Epoch 00018: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.2076 - acc: 0.9380 - val_loss: 4.3731 - val_acc: 0.4048\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9400\n",
      "Epoch 00019: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1994 - acc: 0.9400 - val_loss: 5.1967 - val_acc: 0.3573\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9471\n",
      "Epoch 00020: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1793 - acc: 0.9471 - val_loss: 4.4378 - val_acc: 0.3916\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1925 - acc: 0.9448\n",
      "Epoch 00021: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1925 - acc: 0.9448 - val_loss: 4.6989 - val_acc: 0.3790\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9506\n",
      "Epoch 00022: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1713 - acc: 0.9506 - val_loss: 5.4570 - val_acc: 0.3736\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1858 - acc: 0.9490\n",
      "Epoch 00023: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1858 - acc: 0.9490 - val_loss: 4.6225 - val_acc: 0.3974\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1575 - acc: 0.9555\n",
      "Epoch 00024: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1575 - acc: 0.9554 - val_loss: 5.6844 - val_acc: 0.3461\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1404 - acc: 0.9604\n",
      "Epoch 00025: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1404 - acc: 0.9604 - val_loss: 4.4642 - val_acc: 0.4072\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9619\n",
      "Epoch 00026: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1351 - acc: 0.9619 - val_loss: 4.5996 - val_acc: 0.3951\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9618\n",
      "Epoch 00027: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1402 - acc: 0.9618 - val_loss: 4.9691 - val_acc: 0.4202\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9641\n",
      "Epoch 00028: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1311 - acc: 0.9641 - val_loss: 5.2948 - val_acc: 0.3604\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9599\n",
      "Epoch 00029: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1521 - acc: 0.9599 - val_loss: 4.8738 - val_acc: 0.3897\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9633\n",
      "Epoch 00030: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1290 - acc: 0.9633 - val_loss: 4.8039 - val_acc: 0.4177\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9686\n",
      "Epoch 00031: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1142 - acc: 0.9686 - val_loss: 5.1377 - val_acc: 0.3897\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9713\n",
      "Epoch 00032: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1073 - acc: 0.9713 - val_loss: 4.9481 - val_acc: 0.3941\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9698\n",
      "Epoch 00033: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1104 - acc: 0.9698 - val_loss: 4.6254 - val_acc: 0.4095\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9732\n",
      "Epoch 00034: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0997 - acc: 0.9732 - val_loss: 4.5092 - val_acc: 0.4319\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9714\n",
      "Epoch 00035: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1060 - acc: 0.9713 - val_loss: 5.9858 - val_acc: 0.3459\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9733\n",
      "Epoch 00036: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1010 - acc: 0.9733 - val_loss: 4.4670 - val_acc: 0.4421\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9724\n",
      "Epoch 00037: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1067 - acc: 0.9724 - val_loss: 5.7748 - val_acc: 0.3827\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9730\n",
      "Epoch 00038: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1018 - acc: 0.9730 - val_loss: 5.1375 - val_acc: 0.3708\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9785\n",
      "Epoch 00039: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0814 - acc: 0.9785 - val_loss: 4.6493 - val_acc: 0.4295\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9795\n",
      "Epoch 00040: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0802 - acc: 0.9795 - val_loss: 4.9030 - val_acc: 0.4139\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9781\n",
      "Epoch 00041: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0852 - acc: 0.9781 - val_loss: 4.5578 - val_acc: 0.4391\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9796\n",
      "Epoch 00042: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0805 - acc: 0.9796 - val_loss: 4.6939 - val_acc: 0.4444\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9760\n",
      "Epoch 00043: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0924 - acc: 0.9760 - val_loss: 4.6798 - val_acc: 0.4379\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9813\n",
      "Epoch 00044: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0725 - acc: 0.9813 - val_loss: 4.5992 - val_acc: 0.4416\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9800\n",
      "Epoch 00045: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0819 - acc: 0.9800 - val_loss: 4.6183 - val_acc: 0.4316\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9805\n",
      "Epoch 00046: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0771 - acc: 0.9805 - val_loss: 5.0309 - val_acc: 0.4200\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9831\n",
      "Epoch 00047: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0678 - acc: 0.9831 - val_loss: 4.5256 - val_acc: 0.4410\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9815\n",
      "Epoch 00048: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0713 - acc: 0.9815 - val_loss: 4.4446 - val_acc: 0.4486\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9840\n",
      "Epoch 00049: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0637 - acc: 0.9840 - val_loss: 4.6964 - val_acc: 0.4349\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9820\n",
      "Epoch 00050: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0702 - acc: 0.9820 - val_loss: 4.6197 - val_acc: 0.4456\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9841\n",
      "Epoch 00051: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0673 - acc: 0.9841 - val_loss: 4.6401 - val_acc: 0.4430\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9840\n",
      "Epoch 00052: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0624 - acc: 0.9840 - val_loss: 4.8315 - val_acc: 0.4384\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9854\n",
      "Epoch 00053: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0602 - acc: 0.9854 - val_loss: 5.0991 - val_acc: 0.4018\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9850\n",
      "Epoch 00054: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0637 - acc: 0.9850 - val_loss: 4.8631 - val_acc: 0.4200\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9852\n",
      "Epoch 00055: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0616 - acc: 0.9852 - val_loss: 4.5410 - val_acc: 0.4305\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9874\n",
      "Epoch 00056: val_loss did not improve from 2.62487\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0540 - acc: 0.9874 - val_loss: 5.0634 - val_acc: 0.4023\n",
      "\n",
      "1D_CNN_custom_DO_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 670us/sample - loss: 2.7925 - acc: 0.3780\n",
      "Loss: 2.7925413291154744 Accuracy: 0.37798545\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3626 - acc: 0.3399\n",
      "Epoch 00001: val_loss improved from inf to 2.18262, saving model to model/checkpoint/1D_CNN_custom_DO_BN_3_conv_checkpoint/001-2.1826.hdf5\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 2.3625 - acc: 0.3399 - val_loss: 2.1826 - val_acc: 0.3333\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5660 - acc: 0.5230\n",
      "Epoch 00002: val_loss improved from 2.18262 to 1.49349, saving model to model/checkpoint/1D_CNN_custom_DO_BN_3_conv_checkpoint/002-1.4935.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.5660 - acc: 0.5229 - val_loss: 1.4935 - val_acc: 0.5271\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2747 - acc: 0.6110\n",
      "Epoch 00003: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.2748 - acc: 0.6110 - val_loss: 1.5583 - val_acc: 0.5334\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0559 - acc: 0.6691\n",
      "Epoch 00004: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.0558 - acc: 0.6691 - val_loss: 1.5584 - val_acc: 0.5460\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8777 - acc: 0.7218\n",
      "Epoch 00005: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.8776 - acc: 0.7219 - val_loss: 1.5868 - val_acc: 0.5574\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7576 - acc: 0.7558\n",
      "Epoch 00006: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.7576 - acc: 0.7558 - val_loss: 1.5822 - val_acc: 0.5686\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6583 - acc: 0.7875\n",
      "Epoch 00007: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.6584 - acc: 0.7874 - val_loss: 1.6301 - val_acc: 0.5763\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5767 - acc: 0.8149\n",
      "Epoch 00008: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.5767 - acc: 0.8148 - val_loss: 1.9746 - val_acc: 0.5311\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5032 - acc: 0.8355\n",
      "Epoch 00009: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.5032 - acc: 0.8354 - val_loss: 1.5610 - val_acc: 0.6061\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4225 - acc: 0.8636\n",
      "Epoch 00010: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.4228 - acc: 0.8636 - val_loss: 1.7027 - val_acc: 0.5945\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3929 - acc: 0.8727\n",
      "Epoch 00011: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3930 - acc: 0.8727 - val_loss: 1.7635 - val_acc: 0.5856\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3572 - acc: 0.8830\n",
      "Epoch 00012: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3572 - acc: 0.8830 - val_loss: 1.9291 - val_acc: 0.5744\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.8934\n",
      "Epoch 00013: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3257 - acc: 0.8934 - val_loss: 2.0020 - val_acc: 0.5432\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3115 - acc: 0.8998\n",
      "Epoch 00014: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3115 - acc: 0.8999 - val_loss: 2.0166 - val_acc: 0.5744\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2671 - acc: 0.9140\n",
      "Epoch 00015: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2671 - acc: 0.9140 - val_loss: 1.7406 - val_acc: 0.6103\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2540 - acc: 0.9179\n",
      "Epoch 00016: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2540 - acc: 0.9179 - val_loss: 2.0445 - val_acc: 0.5807\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2348 - acc: 0.9272\n",
      "Epoch 00017: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2348 - acc: 0.9272 - val_loss: 2.0492 - val_acc: 0.5863\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2203 - acc: 0.9304\n",
      "Epoch 00018: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2204 - acc: 0.9304 - val_loss: 1.9773 - val_acc: 0.5835\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9329\n",
      "Epoch 00019: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2107 - acc: 0.9329 - val_loss: 1.9840 - val_acc: 0.5933\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9317\n",
      "Epoch 00020: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2110 - acc: 0.9316 - val_loss: 2.1328 - val_acc: 0.5912\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1983 - acc: 0.9374\n",
      "Epoch 00021: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1982 - acc: 0.9375 - val_loss: 2.1397 - val_acc: 0.5793\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9460\n",
      "Epoch 00022: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1700 - acc: 0.9460 - val_loss: 2.1209 - val_acc: 0.5949\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9430\n",
      "Epoch 00023: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1811 - acc: 0.9430 - val_loss: 1.9485 - val_acc: 0.6243\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1633 - acc: 0.9482\n",
      "Epoch 00024: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1632 - acc: 0.9482 - val_loss: 2.0535 - val_acc: 0.6096\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9502\n",
      "Epoch 00025: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1595 - acc: 0.9502 - val_loss: 2.1668 - val_acc: 0.5933\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1601 - acc: 0.9498\n",
      "Epoch 00026: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1600 - acc: 0.9498 - val_loss: 2.3194 - val_acc: 0.5872\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9524\n",
      "Epoch 00027: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1508 - acc: 0.9523 - val_loss: 2.5046 - val_acc: 0.5553\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1519 - acc: 0.9530\n",
      "Epoch 00028: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1519 - acc: 0.9530 - val_loss: 1.9888 - val_acc: 0.6357\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9564\n",
      "Epoch 00029: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1414 - acc: 0.9564 - val_loss: 2.2097 - val_acc: 0.5970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9593\n",
      "Epoch 00030: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1355 - acc: 0.9593 - val_loss: 2.4701 - val_acc: 0.5604\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9604\n",
      "Epoch 00031: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1265 - acc: 0.9604 - val_loss: 2.2247 - val_acc: 0.6094\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9634\n",
      "Epoch 00032: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1181 - acc: 0.9634 - val_loss: 2.3409 - val_acc: 0.6075\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9615\n",
      "Epoch 00033: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1254 - acc: 0.9614 - val_loss: 2.5312 - val_acc: 0.5756\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9583\n",
      "Epoch 00034: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1370 - acc: 0.9583 - val_loss: 2.1517 - val_acc: 0.6175\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9629\n",
      "Epoch 00035: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1209 - acc: 0.9629 - val_loss: 3.0358 - val_acc: 0.5283\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9660\n",
      "Epoch 00036: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1086 - acc: 0.9660 - val_loss: 2.6108 - val_acc: 0.5865\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9654\n",
      "Epoch 00037: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1172 - acc: 0.9654 - val_loss: 2.2581 - val_acc: 0.6129\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9700\n",
      "Epoch 00038: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1003 - acc: 0.9700 - val_loss: 2.2347 - val_acc: 0.6117\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9700\n",
      "Epoch 00039: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0998 - acc: 0.9700 - val_loss: 2.2567 - val_acc: 0.6096\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9696\n",
      "Epoch 00040: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1009 - acc: 0.9697 - val_loss: 2.3851 - val_acc: 0.6094\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9694\n",
      "Epoch 00041: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0990 - acc: 0.9694 - val_loss: 2.4329 - val_acc: 0.6129\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9729\n",
      "Epoch 00042: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0915 - acc: 0.9729 - val_loss: 2.4435 - val_acc: 0.6040\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9721\n",
      "Epoch 00043: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0959 - acc: 0.9721 - val_loss: 2.2098 - val_acc: 0.6315\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9717\n",
      "Epoch 00044: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0966 - acc: 0.9717 - val_loss: 2.1383 - val_acc: 0.6387\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9736\n",
      "Epoch 00045: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0897 - acc: 0.9736 - val_loss: 2.4423 - val_acc: 0.6157\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9737\n",
      "Epoch 00046: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0872 - acc: 0.9737 - val_loss: 2.4012 - val_acc: 0.6217\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9739\n",
      "Epoch 00047: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0866 - acc: 0.9739 - val_loss: 2.1016 - val_acc: 0.6427\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9758\n",
      "Epoch 00048: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0832 - acc: 0.9758 - val_loss: 2.6120 - val_acc: 0.5872\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9724\n",
      "Epoch 00049: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0921 - acc: 0.9724 - val_loss: 2.5248 - val_acc: 0.6105\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9766\n",
      "Epoch 00050: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0789 - acc: 0.9766 - val_loss: 2.2527 - val_acc: 0.6389\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9766\n",
      "Epoch 00051: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0791 - acc: 0.9766 - val_loss: 2.2022 - val_acc: 0.6345\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9757\n",
      "Epoch 00052: val_loss did not improve from 1.49349\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0825 - acc: 0.9757 - val_loss: 2.4661 - val_acc: 0.6115\n",
      "\n",
      "1D_CNN_custom_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 786us/sample - loss: 1.5907 - acc: 0.5034\n",
      "Loss: 1.590732184525962 Accuracy: 0.5034268\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2488 - acc: 0.3430\n",
      "Epoch 00001: val_loss improved from inf to 1.63984, saving model to model/checkpoint/1D_CNN_custom_DO_BN_4_conv_checkpoint/001-1.6398.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.2490 - acc: 0.3430 - val_loss: 1.6398 - val_acc: 0.4680\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4705 - acc: 0.5458\n",
      "Epoch 00002: val_loss improved from 1.63984 to 1.14578, saving model to model/checkpoint/1D_CNN_custom_DO_BN_4_conv_checkpoint/002-1.1458.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.4705 - acc: 0.5458 - val_loss: 1.1458 - val_acc: 0.6504\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2422 - acc: 0.6204\n",
      "Epoch 00003: val_loss did not improve from 1.14578\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.2421 - acc: 0.6204 - val_loss: 1.2395 - val_acc: 0.6327\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0873 - acc: 0.6659\n",
      "Epoch 00004: val_loss improved from 1.14578 to 1.04592, saving model to model/checkpoint/1D_CNN_custom_DO_BN_4_conv_checkpoint/004-1.0459.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.0873 - acc: 0.6659 - val_loss: 1.0459 - val_acc: 0.6909\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9737 - acc: 0.6986\n",
      "Epoch 00005: val_loss improved from 1.04592 to 1.01447, saving model to model/checkpoint/1D_CNN_custom_DO_BN_4_conv_checkpoint/005-1.0145.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.9737 - acc: 0.6986 - val_loss: 1.0145 - val_acc: 0.6874\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8784 - acc: 0.7274\n",
      "Epoch 00006: val_loss improved from 1.01447 to 0.94894, saving model to model/checkpoint/1D_CNN_custom_DO_BN_4_conv_checkpoint/006-0.9489.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.8787 - acc: 0.7274 - val_loss: 0.9489 - val_acc: 0.7268\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8046 - acc: 0.7509\n",
      "Epoch 00007: val_loss improved from 0.94894 to 0.93403, saving model to model/checkpoint/1D_CNN_custom_DO_BN_4_conv_checkpoint/007-0.9340.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.8046 - acc: 0.7509 - val_loss: 0.9340 - val_acc: 0.7244\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7375 - acc: 0.7685\n",
      "Epoch 00008: val_loss did not improve from 0.93403\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.7375 - acc: 0.7685 - val_loss: 1.1545 - val_acc: 0.6664\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6880 - acc: 0.7866\n",
      "Epoch 00009: val_loss did not improve from 0.93403\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6880 - acc: 0.7866 - val_loss: 1.0303 - val_acc: 0.7011\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6355 - acc: 0.8014\n",
      "Epoch 00010: val_loss did not improve from 0.93403\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6354 - acc: 0.8014 - val_loss: 0.9606 - val_acc: 0.7282\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5861 - acc: 0.8157\n",
      "Epoch 00011: val_loss did not improve from 0.93403\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5861 - acc: 0.8157 - val_loss: 0.9369 - val_acc: 0.7291\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5410 - acc: 0.8301\n",
      "Epoch 00012: val_loss improved from 0.93403 to 0.92154, saving model to model/checkpoint/1D_CNN_custom_DO_BN_4_conv_checkpoint/012-0.9215.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5410 - acc: 0.8302 - val_loss: 0.9215 - val_acc: 0.7475\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5166 - acc: 0.8337\n",
      "Epoch 00013: val_loss did not improve from 0.92154\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5167 - acc: 0.8336 - val_loss: 1.0251 - val_acc: 0.7163\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4782 - acc: 0.8465\n",
      "Epoch 00014: val_loss improved from 0.92154 to 0.89287, saving model to model/checkpoint/1D_CNN_custom_DO_BN_4_conv_checkpoint/014-0.8929.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4781 - acc: 0.8465 - val_loss: 0.8929 - val_acc: 0.7577\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4483 - acc: 0.8577\n",
      "Epoch 00015: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4483 - acc: 0.8577 - val_loss: 0.9899 - val_acc: 0.7314\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4202 - acc: 0.8637\n",
      "Epoch 00016: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4206 - acc: 0.8637 - val_loss: 0.9569 - val_acc: 0.7370\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4006 - acc: 0.8707\n",
      "Epoch 00017: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4005 - acc: 0.8707 - val_loss: 0.9177 - val_acc: 0.7549\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3703 - acc: 0.8808\n",
      "Epoch 00018: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3703 - acc: 0.8808 - val_loss: 1.1321 - val_acc: 0.7021\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3516 - acc: 0.8867\n",
      "Epoch 00019: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3516 - acc: 0.8866 - val_loss: 0.9212 - val_acc: 0.7603\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3373 - acc: 0.8924\n",
      "Epoch 00020: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3373 - acc: 0.8924 - val_loss: 1.0336 - val_acc: 0.7296\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3163 - acc: 0.8977\n",
      "Epoch 00021: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3164 - acc: 0.8976 - val_loss: 1.0417 - val_acc: 0.7354\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3115 - acc: 0.8979\n",
      "Epoch 00022: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3114 - acc: 0.8979 - val_loss: 0.9537 - val_acc: 0.7531\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2879 - acc: 0.9065\n",
      "Epoch 00023: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2879 - acc: 0.9065 - val_loss: 1.1916 - val_acc: 0.7147\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2843 - acc: 0.9088\n",
      "Epoch 00024: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2843 - acc: 0.9088 - val_loss: 1.0116 - val_acc: 0.7470\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2693 - acc: 0.9117\n",
      "Epoch 00025: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2693 - acc: 0.9117 - val_loss: 1.0229 - val_acc: 0.7428\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2563 - acc: 0.9174\n",
      "Epoch 00026: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2563 - acc: 0.9174 - val_loss: 1.0831 - val_acc: 0.7361\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2424 - acc: 0.9220\n",
      "Epoch 00027: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2423 - acc: 0.9220 - val_loss: 1.1770 - val_acc: 0.7074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2433 - acc: 0.9206\n",
      "Epoch 00028: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2436 - acc: 0.9206 - val_loss: 1.1683 - val_acc: 0.7160\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2368 - acc: 0.9230\n",
      "Epoch 00029: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2368 - acc: 0.9230 - val_loss: 1.0290 - val_acc: 0.7503\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2216 - acc: 0.9277\n",
      "Epoch 00030: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2216 - acc: 0.9277 - val_loss: 1.0450 - val_acc: 0.7431\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2147 - acc: 0.9292\n",
      "Epoch 00031: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2147 - acc: 0.9292 - val_loss: 1.0450 - val_acc: 0.7473\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2066 - acc: 0.9335\n",
      "Epoch 00032: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2066 - acc: 0.9334 - val_loss: 0.9746 - val_acc: 0.7692\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2043 - acc: 0.9345\n",
      "Epoch 00033: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2044 - acc: 0.9344 - val_loss: 1.1120 - val_acc: 0.7389\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9388\n",
      "Epoch 00034: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1932 - acc: 0.9388 - val_loss: 0.9929 - val_acc: 0.7636\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1921 - acc: 0.9378\n",
      "Epoch 00035: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1921 - acc: 0.9378 - val_loss: 1.0184 - val_acc: 0.7608\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1813 - acc: 0.9424\n",
      "Epoch 00036: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1812 - acc: 0.9424 - val_loss: 1.0738 - val_acc: 0.7566\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9430\n",
      "Epoch 00037: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1770 - acc: 0.9430 - val_loss: 1.1762 - val_acc: 0.7389\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1684 - acc: 0.9443\n",
      "Epoch 00038: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1684 - acc: 0.9443 - val_loss: 1.2912 - val_acc: 0.7221\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1734 - acc: 0.9441\n",
      "Epoch 00039: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1734 - acc: 0.9441 - val_loss: 1.1807 - val_acc: 0.7349\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9439\n",
      "Epoch 00040: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1736 - acc: 0.9438 - val_loss: 1.0134 - val_acc: 0.7612\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9453\n",
      "Epoch 00041: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1691 - acc: 0.9453 - val_loss: 1.0016 - val_acc: 0.7703\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1563 - acc: 0.9503\n",
      "Epoch 00042: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1564 - acc: 0.9503 - val_loss: 1.0653 - val_acc: 0.7556\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9502\n",
      "Epoch 00043: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1526 - acc: 0.9502 - val_loss: 1.1771 - val_acc: 0.7421\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9529\n",
      "Epoch 00044: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1501 - acc: 0.9529 - val_loss: 1.1133 - val_acc: 0.7549\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9538\n",
      "Epoch 00045: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1463 - acc: 0.9538 - val_loss: 1.1064 - val_acc: 0.7543\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9525\n",
      "Epoch 00046: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1499 - acc: 0.9525 - val_loss: 1.0141 - val_acc: 0.7761\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9547\n",
      "Epoch 00047: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1443 - acc: 0.9547 - val_loss: 1.1931 - val_acc: 0.7426\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9562\n",
      "Epoch 00048: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1378 - acc: 0.9561 - val_loss: 1.1173 - val_acc: 0.7522\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9563\n",
      "Epoch 00049: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1400 - acc: 0.9563 - val_loss: 1.0700 - val_acc: 0.7659\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9572\n",
      "Epoch 00050: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1337 - acc: 0.9572 - val_loss: 1.0337 - val_acc: 0.7729\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9564\n",
      "Epoch 00051: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1346 - acc: 0.9564 - val_loss: 1.0843 - val_acc: 0.7675\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9618\n",
      "Epoch 00052: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1234 - acc: 0.9619 - val_loss: 1.1235 - val_acc: 0.7629\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9621\n",
      "Epoch 00053: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1229 - acc: 0.9621 - val_loss: 1.1972 - val_acc: 0.7445\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9614\n",
      "Epoch 00054: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1216 - acc: 0.9614 - val_loss: 1.1328 - val_acc: 0.7629\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9628\n",
      "Epoch 00055: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1181 - acc: 0.9628 - val_loss: 1.0321 - val_acc: 0.7771\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9621\n",
      "Epoch 00056: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1217 - acc: 0.9621 - val_loss: 1.1979 - val_acc: 0.7400\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9613\n",
      "Epoch 00057: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1200 - acc: 0.9613 - val_loss: 1.1381 - val_acc: 0.7587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9610\n",
      "Epoch 00058: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1251 - acc: 0.9610 - val_loss: 1.0253 - val_acc: 0.7810\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9641\n",
      "Epoch 00059: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1140 - acc: 0.9641 - val_loss: 1.0571 - val_acc: 0.7666\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9665\n",
      "Epoch 00060: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1097 - acc: 0.9665 - val_loss: 1.0871 - val_acc: 0.7717\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9651\n",
      "Epoch 00061: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1107 - acc: 0.9651 - val_loss: 1.3050 - val_acc: 0.7368\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9658\n",
      "Epoch 00062: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1100 - acc: 0.9657 - val_loss: 1.0819 - val_acc: 0.7736\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9660\n",
      "Epoch 00063: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1109 - acc: 0.9659 - val_loss: 1.1764 - val_acc: 0.7654\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9637\n",
      "Epoch 00064: val_loss did not improve from 0.89287\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1153 - acc: 0.9637 - val_loss: 1.1358 - val_acc: 0.7659\n",
      "\n",
      "1D_CNN_custom_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 837us/sample - loss: 0.9833 - acc: 0.7188\n",
      "Loss: 0.983314494131015 Accuracy: 0.7187954\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0785 - acc: 0.3723\n",
      "Epoch 00001: val_loss improved from inf to 1.67620, saving model to model/checkpoint/1D_CNN_custom_DO_BN_5_conv_checkpoint/001-1.6762.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 2.0786 - acc: 0.3723 - val_loss: 1.6762 - val_acc: 0.4333\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3496 - acc: 0.5750\n",
      "Epoch 00002: val_loss improved from 1.67620 to 1.18110, saving model to model/checkpoint/1D_CNN_custom_DO_BN_5_conv_checkpoint/002-1.1811.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.3497 - acc: 0.5749 - val_loss: 1.1811 - val_acc: 0.6219\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1207 - acc: 0.6523\n",
      "Epoch 00003: val_loss improved from 1.18110 to 0.92828, saving model to model/checkpoint/1D_CNN_custom_DO_BN_5_conv_checkpoint/003-0.9283.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.1207 - acc: 0.6522 - val_loss: 0.9283 - val_acc: 0.7207\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9700 - acc: 0.7001\n",
      "Epoch 00004: val_loss improved from 0.92828 to 0.87540, saving model to model/checkpoint/1D_CNN_custom_DO_BN_5_conv_checkpoint/004-0.8754.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.9701 - acc: 0.7001 - val_loss: 0.8754 - val_acc: 0.7445\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8844 - acc: 0.7279\n",
      "Epoch 00005: val_loss improved from 0.87540 to 0.80187, saving model to model/checkpoint/1D_CNN_custom_DO_BN_5_conv_checkpoint/005-0.8019.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8844 - acc: 0.7279 - val_loss: 0.8019 - val_acc: 0.7636\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7987 - acc: 0.7539\n",
      "Epoch 00006: val_loss did not improve from 0.80187\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.7987 - acc: 0.7539 - val_loss: 0.8334 - val_acc: 0.7594\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7400 - acc: 0.7733\n",
      "Epoch 00007: val_loss improved from 0.80187 to 0.78383, saving model to model/checkpoint/1D_CNN_custom_DO_BN_5_conv_checkpoint/007-0.7838.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.7403 - acc: 0.7732 - val_loss: 0.7838 - val_acc: 0.7796\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7014 - acc: 0.7854\n",
      "Epoch 00008: val_loss improved from 0.78383 to 0.73785, saving model to model/checkpoint/1D_CNN_custom_DO_BN_5_conv_checkpoint/008-0.7378.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7015 - acc: 0.7853 - val_loss: 0.7378 - val_acc: 0.7925\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6449 - acc: 0.8018\n",
      "Epoch 00009: val_loss did not improve from 0.73785\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6449 - acc: 0.8018 - val_loss: 0.7907 - val_acc: 0.7664\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.8162\n",
      "Epoch 00010: val_loss did not improve from 0.73785\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6018 - acc: 0.8161 - val_loss: 0.7863 - val_acc: 0.7796\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5724 - acc: 0.8245\n",
      "Epoch 00011: val_loss improved from 0.73785 to 0.68695, saving model to model/checkpoint/1D_CNN_custom_DO_BN_5_conv_checkpoint/011-0.6870.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5724 - acc: 0.8245 - val_loss: 0.6870 - val_acc: 0.8034\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5427 - acc: 0.8327\n",
      "Epoch 00012: val_loss did not improve from 0.68695\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5426 - acc: 0.8327 - val_loss: 0.6917 - val_acc: 0.8092\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5077 - acc: 0.8439\n",
      "Epoch 00013: val_loss did not improve from 0.68695\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5077 - acc: 0.8439 - val_loss: 0.7471 - val_acc: 0.7873\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4890 - acc: 0.8479\n",
      "Epoch 00014: val_loss did not improve from 0.68695\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4890 - acc: 0.8478 - val_loss: 0.7409 - val_acc: 0.7906\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4453 - acc: 0.8610\n",
      "Epoch 00015: val_loss did not improve from 0.68695\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4453 - acc: 0.8610 - val_loss: 0.7246 - val_acc: 0.8008\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4421 - acc: 0.8625\n",
      "Epoch 00016: val_loss did not improve from 0.68695\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4421 - acc: 0.8625 - val_loss: 0.7381 - val_acc: 0.7971\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4093 - acc: 0.8726\n",
      "Epoch 00017: val_loss improved from 0.68695 to 0.66189, saving model to model/checkpoint/1D_CNN_custom_DO_BN_5_conv_checkpoint/017-0.6619.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4092 - acc: 0.8726 - val_loss: 0.6619 - val_acc: 0.8143\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3898 - acc: 0.8756\n",
      "Epoch 00018: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3898 - acc: 0.8756 - val_loss: 0.7429 - val_acc: 0.7945\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3753 - acc: 0.8804\n",
      "Epoch 00019: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3753 - acc: 0.8804 - val_loss: 0.6977 - val_acc: 0.8085\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3545 - acc: 0.8860\n",
      "Epoch 00020: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3545 - acc: 0.8860 - val_loss: 0.7048 - val_acc: 0.8116\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3385 - acc: 0.8945\n",
      "Epoch 00021: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3385 - acc: 0.8945 - val_loss: 0.6880 - val_acc: 0.8155\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3330 - acc: 0.8939\n",
      "Epoch 00022: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3331 - acc: 0.8939 - val_loss: 0.7216 - val_acc: 0.8015\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3168 - acc: 0.9002\n",
      "Epoch 00023: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3167 - acc: 0.9003 - val_loss: 0.7403 - val_acc: 0.7957\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3004 - acc: 0.9045\n",
      "Epoch 00024: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3004 - acc: 0.9045 - val_loss: 0.8209 - val_acc: 0.7922\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2850 - acc: 0.9095\n",
      "Epoch 00025: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2850 - acc: 0.9094 - val_loss: 0.6691 - val_acc: 0.8267\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2825 - acc: 0.9092\n",
      "Epoch 00026: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2825 - acc: 0.9093 - val_loss: 0.6985 - val_acc: 0.8167\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2646 - acc: 0.9135\n",
      "Epoch 00027: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2647 - acc: 0.9135 - val_loss: 0.7487 - val_acc: 0.8120\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2657 - acc: 0.9156\n",
      "Epoch 00028: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2658 - acc: 0.9156 - val_loss: 0.8417 - val_acc: 0.7885\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2465 - acc: 0.9208\n",
      "Epoch 00029: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2466 - acc: 0.9207 - val_loss: 0.7170 - val_acc: 0.8141\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2448 - acc: 0.9202\n",
      "Epoch 00030: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2448 - acc: 0.9203 - val_loss: 0.7107 - val_acc: 0.8220\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2310 - acc: 0.9249\n",
      "Epoch 00031: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2310 - acc: 0.9249 - val_loss: 0.6755 - val_acc: 0.8369\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9296\n",
      "Epoch 00032: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2196 - acc: 0.9296 - val_loss: 0.7627 - val_acc: 0.8174\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2150 - acc: 0.9295\n",
      "Epoch 00033: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2150 - acc: 0.9295 - val_loss: 0.7059 - val_acc: 0.8265\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9296\n",
      "Epoch 00034: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2133 - acc: 0.9295 - val_loss: 0.7340 - val_acc: 0.8130\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2057 - acc: 0.9334\n",
      "Epoch 00035: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2057 - acc: 0.9334 - val_loss: 0.7288 - val_acc: 0.8234\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2016 - acc: 0.9345\n",
      "Epoch 00036: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2016 - acc: 0.9345 - val_loss: 0.9152 - val_acc: 0.7871\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9345\n",
      "Epoch 00037: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1994 - acc: 0.9345 - val_loss: 0.7042 - val_acc: 0.8321\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1785 - acc: 0.9425\n",
      "Epoch 00038: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1785 - acc: 0.9425 - val_loss: 0.8016 - val_acc: 0.8074\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1813 - acc: 0.9419\n",
      "Epoch 00039: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1814 - acc: 0.9419 - val_loss: 0.7166 - val_acc: 0.8351\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1812 - acc: 0.9405\n",
      "Epoch 00040: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1813 - acc: 0.9405 - val_loss: 0.7859 - val_acc: 0.8095\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1788 - acc: 0.9436\n",
      "Epoch 00041: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1789 - acc: 0.9435 - val_loss: 0.8096 - val_acc: 0.8134\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1640 - acc: 0.9469\n",
      "Epoch 00042: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1641 - acc: 0.9469 - val_loss: 0.8075 - val_acc: 0.8050\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1651 - acc: 0.9471\n",
      "Epoch 00043: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1652 - acc: 0.9471 - val_loss: 0.7313 - val_acc: 0.8244\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9459\n",
      "Epoch 00044: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1656 - acc: 0.9459 - val_loss: 0.8095 - val_acc: 0.8211\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9479\n",
      "Epoch 00045: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1598 - acc: 0.9479 - val_loss: 0.7509 - val_acc: 0.8204\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1529 - acc: 0.9501\n",
      "Epoch 00046: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1529 - acc: 0.9501 - val_loss: 0.8390 - val_acc: 0.8148\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9525\n",
      "Epoch 00047: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1457 - acc: 0.9525 - val_loss: 0.7923 - val_acc: 0.8181\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9529\n",
      "Epoch 00048: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1463 - acc: 0.9529 - val_loss: 0.7918 - val_acc: 0.8157\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9550\n",
      "Epoch 00049: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1403 - acc: 0.9550 - val_loss: 0.8270 - val_acc: 0.8146\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9548\n",
      "Epoch 00050: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1416 - acc: 0.9548 - val_loss: 0.7086 - val_acc: 0.8325\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9583\n",
      "Epoch 00051: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1318 - acc: 0.9583 - val_loss: 0.7769 - val_acc: 0.8267\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9568\n",
      "Epoch 00052: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1325 - acc: 0.9567 - val_loss: 0.7144 - val_acc: 0.8381\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9555\n",
      "Epoch 00053: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1368 - acc: 0.9555 - val_loss: 0.8022 - val_acc: 0.8223\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1268 - acc: 0.9582\n",
      "Epoch 00054: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1269 - acc: 0.9581 - val_loss: 0.7512 - val_acc: 0.8337\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9573\n",
      "Epoch 00055: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1316 - acc: 0.9573 - val_loss: 0.7439 - val_acc: 0.8407\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9595\n",
      "Epoch 00056: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1242 - acc: 0.9595 - val_loss: 0.7291 - val_acc: 0.8404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9624\n",
      "Epoch 00057: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1160 - acc: 0.9624 - val_loss: 0.8223 - val_acc: 0.8260\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9627\n",
      "Epoch 00058: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1177 - acc: 0.9627 - val_loss: 0.8716 - val_acc: 0.8118\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9604\n",
      "Epoch 00059: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1219 - acc: 0.9604 - val_loss: 0.7415 - val_acc: 0.8374\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9636\n",
      "Epoch 00060: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1130 - acc: 0.9636 - val_loss: 0.7492 - val_acc: 0.8251\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9665\n",
      "Epoch 00061: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1075 - acc: 0.9665 - val_loss: 0.7776 - val_acc: 0.8346\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9656\n",
      "Epoch 00062: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1077 - acc: 0.9656 - val_loss: 0.8099 - val_acc: 0.8237\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9627\n",
      "Epoch 00063: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1110 - acc: 0.9627 - val_loss: 0.7698 - val_acc: 0.8272\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9635\n",
      "Epoch 00064: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1105 - acc: 0.9635 - val_loss: 0.8887 - val_acc: 0.8120\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9654\n",
      "Epoch 00065: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1062 - acc: 0.9654 - val_loss: 0.9905 - val_acc: 0.7929\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9676\n",
      "Epoch 00066: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1009 - acc: 0.9676 - val_loss: 0.7775 - val_acc: 0.8341\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9693\n",
      "Epoch 00067: val_loss did not improve from 0.66189\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1002 - acc: 0.9693 - val_loss: 0.7237 - val_acc: 0.8453\n",
      "\n",
      "1D_CNN_custom_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 872us/sample - loss: 0.7455 - acc: 0.7836\n",
      "Loss: 0.7454629350426536 Accuracy: 0.78359294\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1587 - acc: 0.3429\n",
      "Epoch 00001: val_loss improved from inf to 1.46450, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/001-1.4645.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 2.1587 - acc: 0.3429 - val_loss: 1.4645 - val_acc: 0.5483\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3337 - acc: 0.5802\n",
      "Epoch 00002: val_loss improved from 1.46450 to 1.00688, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/002-1.0069.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.3339 - acc: 0.5802 - val_loss: 1.0069 - val_acc: 0.6900\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0697 - acc: 0.6687\n",
      "Epoch 00003: val_loss improved from 1.00688 to 0.83978, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/003-0.8398.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.0697 - acc: 0.6686 - val_loss: 0.8398 - val_acc: 0.7540\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9180 - acc: 0.7173\n",
      "Epoch 00004: val_loss improved from 0.83978 to 0.75571, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/004-0.7557.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.9181 - acc: 0.7173 - val_loss: 0.7557 - val_acc: 0.7782\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8157 - acc: 0.7518\n",
      "Epoch 00005: val_loss improved from 0.75571 to 0.73399, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/005-0.7340.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.8156 - acc: 0.7518 - val_loss: 0.7340 - val_acc: 0.7897\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7401 - acc: 0.7772\n",
      "Epoch 00006: val_loss improved from 0.73399 to 0.71719, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/006-0.7172.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.7401 - acc: 0.7772 - val_loss: 0.7172 - val_acc: 0.7962\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6768 - acc: 0.7945\n",
      "Epoch 00007: val_loss improved from 0.71719 to 0.61184, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/007-0.6118.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.6767 - acc: 0.7945 - val_loss: 0.6118 - val_acc: 0.8213\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6216 - acc: 0.8151\n",
      "Epoch 00008: val_loss improved from 0.61184 to 0.57951, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/008-0.5795.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6216 - acc: 0.8151 - val_loss: 0.5795 - val_acc: 0.8355\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5780 - acc: 0.8273\n",
      "Epoch 00009: val_loss did not improve from 0.57951\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5780 - acc: 0.8273 - val_loss: 0.5857 - val_acc: 0.8300\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5385 - acc: 0.8402\n",
      "Epoch 00010: val_loss did not improve from 0.57951\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5385 - acc: 0.8402 - val_loss: 0.6701 - val_acc: 0.7950\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5047 - acc: 0.8499\n",
      "Epoch 00011: val_loss improved from 0.57951 to 0.57550, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/011-0.5755.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5050 - acc: 0.8499 - val_loss: 0.5755 - val_acc: 0.8423\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4777 - acc: 0.8556\n",
      "Epoch 00012: val_loss improved from 0.57550 to 0.49130, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/012-0.4913.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4778 - acc: 0.8555 - val_loss: 0.4913 - val_acc: 0.8556\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4543 - acc: 0.8634\n",
      "Epoch 00013: val_loss improved from 0.49130 to 0.47786, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/013-0.4779.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4544 - acc: 0.8634 - val_loss: 0.4779 - val_acc: 0.8663\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4300 - acc: 0.8712\n",
      "Epoch 00014: val_loss did not improve from 0.47786\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4299 - acc: 0.8713 - val_loss: 0.5000 - val_acc: 0.8612\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4004 - acc: 0.8774\n",
      "Epoch 00015: val_loss improved from 0.47786 to 0.45841, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/015-0.4584.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4004 - acc: 0.8774 - val_loss: 0.4584 - val_acc: 0.8770\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3866 - acc: 0.8832\n",
      "Epoch 00016: val_loss improved from 0.45841 to 0.44561, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/016-0.4456.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3867 - acc: 0.8831 - val_loss: 0.4456 - val_acc: 0.8826\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3720 - acc: 0.8872\n",
      "Epoch 00017: val_loss did not improve from 0.44561\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3720 - acc: 0.8872 - val_loss: 0.4879 - val_acc: 0.8679\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3581 - acc: 0.8911\n",
      "Epoch 00018: val_loss did not improve from 0.44561\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3581 - acc: 0.8911 - val_loss: 0.4599 - val_acc: 0.8789\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3344 - acc: 0.8980\n",
      "Epoch 00019: val_loss improved from 0.44561 to 0.42807, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/019-0.4281.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3345 - acc: 0.8979 - val_loss: 0.4281 - val_acc: 0.8782\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3243 - acc: 0.9018\n",
      "Epoch 00020: val_loss improved from 0.42807 to 0.41858, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/020-0.4186.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3244 - acc: 0.9018 - val_loss: 0.4186 - val_acc: 0.8866\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3131 - acc: 0.9047\n",
      "Epoch 00021: val_loss did not improve from 0.41858\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3131 - acc: 0.9047 - val_loss: 0.4439 - val_acc: 0.8796\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3006 - acc: 0.9070\n",
      "Epoch 00022: val_loss did not improve from 0.41858\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3006 - acc: 0.9070 - val_loss: 0.4193 - val_acc: 0.8814\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2891 - acc: 0.9101\n",
      "Epoch 00023: val_loss improved from 0.41858 to 0.39987, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/023-0.3999.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2891 - acc: 0.9101 - val_loss: 0.3999 - val_acc: 0.8898\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.9127\n",
      "Epoch 00024: val_loss did not improve from 0.39987\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2801 - acc: 0.9127 - val_loss: 0.4185 - val_acc: 0.8824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2674 - acc: 0.9188\n",
      "Epoch 00025: val_loss improved from 0.39987 to 0.38563, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/025-0.3856.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2674 - acc: 0.9188 - val_loss: 0.3856 - val_acc: 0.8963\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2622 - acc: 0.9192\n",
      "Epoch 00026: val_loss did not improve from 0.38563\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2624 - acc: 0.9191 - val_loss: 0.4459 - val_acc: 0.8817\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2539 - acc: 0.9221\n",
      "Epoch 00027: val_loss did not improve from 0.38563\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2539 - acc: 0.9221 - val_loss: 0.5135 - val_acc: 0.8609\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2393 - acc: 0.9246\n",
      "Epoch 00028: val_loss did not improve from 0.38563\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2392 - acc: 0.9247 - val_loss: 0.3951 - val_acc: 0.8894\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2290 - acc: 0.9283\n",
      "Epoch 00029: val_loss did not improve from 0.38563\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2291 - acc: 0.9283 - val_loss: 0.4469 - val_acc: 0.8828\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2260 - acc: 0.9295\n",
      "Epoch 00030: val_loss did not improve from 0.38563\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2260 - acc: 0.9295 - val_loss: 0.4146 - val_acc: 0.8896\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2164 - acc: 0.9328\n",
      "Epoch 00031: val_loss did not improve from 0.38563\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2164 - acc: 0.9328 - val_loss: 0.4148 - val_acc: 0.8910\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9328\n",
      "Epoch 00032: val_loss did not improve from 0.38563\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2108 - acc: 0.9328 - val_loss: 0.4162 - val_acc: 0.8896\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9365\n",
      "Epoch 00033: val_loss did not improve from 0.38563\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2018 - acc: 0.9365 - val_loss: 0.4066 - val_acc: 0.8915\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1988 - acc: 0.9385\n",
      "Epoch 00034: val_loss did not improve from 0.38563\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1988 - acc: 0.9385 - val_loss: 0.3928 - val_acc: 0.8975\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9375\n",
      "Epoch 00035: val_loss did not improve from 0.38563\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1995 - acc: 0.9375 - val_loss: 0.3866 - val_acc: 0.8963\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1955 - acc: 0.9383\n",
      "Epoch 00036: val_loss improved from 0.38563 to 0.37863, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/036-0.3786.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1955 - acc: 0.9382 - val_loss: 0.3786 - val_acc: 0.9001\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1803 - acc: 0.9442\n",
      "Epoch 00037: val_loss did not improve from 0.37863\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1803 - acc: 0.9441 - val_loss: 0.3881 - val_acc: 0.8956\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1785 - acc: 0.9425\n",
      "Epoch 00038: val_loss did not improve from 0.37863\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1788 - acc: 0.9424 - val_loss: 0.4069 - val_acc: 0.8931\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1784 - acc: 0.9418\n",
      "Epoch 00039: val_loss improved from 0.37863 to 0.35795, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/039-0.3580.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1785 - acc: 0.9418 - val_loss: 0.3580 - val_acc: 0.9078\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1707 - acc: 0.9458\n",
      "Epoch 00040: val_loss did not improve from 0.35795\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1708 - acc: 0.9457 - val_loss: 0.3854 - val_acc: 0.8975\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1639 - acc: 0.9496\n",
      "Epoch 00041: val_loss did not improve from 0.35795\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1639 - acc: 0.9496 - val_loss: 0.3997 - val_acc: 0.8980\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9500\n",
      "Epoch 00042: val_loss did not improve from 0.35795\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1569 - acc: 0.9500 - val_loss: 0.3990 - val_acc: 0.8968\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9498\n",
      "Epoch 00043: val_loss did not improve from 0.35795\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1558 - acc: 0.9498 - val_loss: 0.3990 - val_acc: 0.8942\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9507\n",
      "Epoch 00044: val_loss did not improve from 0.35795\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1503 - acc: 0.9507 - val_loss: 0.3946 - val_acc: 0.8996\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1470 - acc: 0.9518\n",
      "Epoch 00045: val_loss did not improve from 0.35795\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1470 - acc: 0.9518 - val_loss: 0.3864 - val_acc: 0.9036\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1429 - acc: 0.9535\n",
      "Epoch 00046: val_loss did not improve from 0.35795\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1430 - acc: 0.9534 - val_loss: 0.3684 - val_acc: 0.9061\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9527\n",
      "Epoch 00047: val_loss did not improve from 0.35795\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1496 - acc: 0.9527 - val_loss: 0.4541 - val_acc: 0.8866\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9556\n",
      "Epoch 00048: val_loss improved from 0.35795 to 0.34677, saving model to model/checkpoint/1D_CNN_custom_DO_BN_6_conv_checkpoint/048-0.3468.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1368 - acc: 0.9556 - val_loss: 0.3468 - val_acc: 0.9119\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9548\n",
      "Epoch 00049: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1367 - acc: 0.9548 - val_loss: 0.4946 - val_acc: 0.8796\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9595\n",
      "Epoch 00050: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1281 - acc: 0.9595 - val_loss: 0.4075 - val_acc: 0.8994\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9594\n",
      "Epoch 00051: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1277 - acc: 0.9594 - val_loss: 0.3973 - val_acc: 0.9026\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9590\n",
      "Epoch 00052: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1269 - acc: 0.9590 - val_loss: 0.3869 - val_acc: 0.9050\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9601\n",
      "Epoch 00053: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1256 - acc: 0.9601 - val_loss: 0.3927 - val_acc: 0.8994\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9618\n",
      "Epoch 00054: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1196 - acc: 0.9618 - val_loss: 0.4218 - val_acc: 0.8970\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9610\n",
      "Epoch 00055: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1223 - acc: 0.9610 - val_loss: 0.4084 - val_acc: 0.9031\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9619\n",
      "Epoch 00056: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1160 - acc: 0.9619 - val_loss: 0.3827 - val_acc: 0.9115\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9642\n",
      "Epoch 00057: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1068 - acc: 0.9642 - val_loss: 0.4064 - val_acc: 0.9036\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9629\n",
      "Epoch 00058: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1147 - acc: 0.9629 - val_loss: 0.3794 - val_acc: 0.9047\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9661\n",
      "Epoch 00059: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1044 - acc: 0.9661 - val_loss: 0.4043 - val_acc: 0.9036\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9664\n",
      "Epoch 00060: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1062 - acc: 0.9664 - val_loss: 0.4152 - val_acc: 0.8998\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9668\n",
      "Epoch 00061: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1034 - acc: 0.9668 - val_loss: 0.4072 - val_acc: 0.9085\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9675\n",
      "Epoch 00062: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1019 - acc: 0.9675 - val_loss: 0.4180 - val_acc: 0.8984\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9683\n",
      "Epoch 00063: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1008 - acc: 0.9682 - val_loss: 0.4298 - val_acc: 0.8959\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9644\n",
      "Epoch 00064: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1092 - acc: 0.9644 - val_loss: 0.3704 - val_acc: 0.9129\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9676\n",
      "Epoch 00065: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0984 - acc: 0.9676 - val_loss: 0.3998 - val_acc: 0.9040\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9690\n",
      "Epoch 00066: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0937 - acc: 0.9690 - val_loss: 0.4032 - val_acc: 0.9057\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9698\n",
      "Epoch 00067: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0949 - acc: 0.9698 - val_loss: 0.4390 - val_acc: 0.8956\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9700\n",
      "Epoch 00068: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0947 - acc: 0.9700 - val_loss: 0.4316 - val_acc: 0.8987\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9713\n",
      "Epoch 00069: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0877 - acc: 0.9713 - val_loss: 0.5296 - val_acc: 0.8807\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9718\n",
      "Epoch 00070: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0877 - acc: 0.9718 - val_loss: 0.4652 - val_acc: 0.8975\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9685\n",
      "Epoch 00071: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0982 - acc: 0.9684 - val_loss: 0.3834 - val_acc: 0.9096\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9733\n",
      "Epoch 00072: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0828 - acc: 0.9733 - val_loss: 0.3937 - val_acc: 0.9052\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9740\n",
      "Epoch 00073: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0814 - acc: 0.9740 - val_loss: 0.4328 - val_acc: 0.9022\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9722\n",
      "Epoch 00074: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0848 - acc: 0.9722 - val_loss: 0.4144 - val_acc: 0.9087\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9738\n",
      "Epoch 00075: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0834 - acc: 0.9738 - val_loss: 0.4465 - val_acc: 0.8996\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9740\n",
      "Epoch 00076: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0803 - acc: 0.9741 - val_loss: 0.3955 - val_acc: 0.9119\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9763\n",
      "Epoch 00077: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0756 - acc: 0.9763 - val_loss: 0.4189 - val_acc: 0.9012\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9696\n",
      "Epoch 00078: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0917 - acc: 0.9696 - val_loss: 0.4352 - val_acc: 0.9050\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9754\n",
      "Epoch 00079: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0753 - acc: 0.9754 - val_loss: 0.4312 - val_acc: 0.9003\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9777\n",
      "Epoch 00080: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0713 - acc: 0.9777 - val_loss: 0.4353 - val_acc: 0.9024\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9750\n",
      "Epoch 00081: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0760 - acc: 0.9750 - val_loss: 0.4228 - val_acc: 0.9038\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9771\n",
      "Epoch 00082: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0726 - acc: 0.9771 - val_loss: 0.4822 - val_acc: 0.8954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9764\n",
      "Epoch 00083: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0744 - acc: 0.9764 - val_loss: 0.4426 - val_acc: 0.9087\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9772\n",
      "Epoch 00084: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0723 - acc: 0.9771 - val_loss: 0.4679 - val_acc: 0.9005\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9743\n",
      "Epoch 00085: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0818 - acc: 0.9742 - val_loss: 0.5013 - val_acc: 0.8896\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9750\n",
      "Epoch 00086: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0796 - acc: 0.9750 - val_loss: 0.3833 - val_acc: 0.9150\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9791\n",
      "Epoch 00087: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0663 - acc: 0.9791 - val_loss: 0.4243 - val_acc: 0.9038\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9808\n",
      "Epoch 00088: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0613 - acc: 0.9808 - val_loss: 0.4211 - val_acc: 0.9096\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9788\n",
      "Epoch 00089: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0664 - acc: 0.9788 - val_loss: 0.4870 - val_acc: 0.8947\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9770\n",
      "Epoch 00090: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0731 - acc: 0.9770 - val_loss: 0.4002 - val_acc: 0.9136\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9802\n",
      "Epoch 00091: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0629 - acc: 0.9802 - val_loss: 0.4739 - val_acc: 0.8970\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9783\n",
      "Epoch 00092: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0666 - acc: 0.9783 - val_loss: 0.4340 - val_acc: 0.9050\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9759\n",
      "Epoch 00093: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0752 - acc: 0.9759 - val_loss: 0.4828 - val_acc: 0.8956\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9800\n",
      "Epoch 00094: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0615 - acc: 0.9800 - val_loss: 0.5393 - val_acc: 0.8966\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9801\n",
      "Epoch 00095: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0641 - acc: 0.9801 - val_loss: 0.4316 - val_acc: 0.9131\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9828\n",
      "Epoch 00096: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0558 - acc: 0.9828 - val_loss: 0.4216 - val_acc: 0.9057\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9817\n",
      "Epoch 00097: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0589 - acc: 0.9816 - val_loss: 0.4335 - val_acc: 0.9119\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9773\n",
      "Epoch 00098: val_loss did not improve from 0.34677\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0697 - acc: 0.9773 - val_loss: 0.4316 - val_acc: 0.9119\n",
      "\n",
      "1D_CNN_custom_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 912us/sample - loss: 0.4158 - acc: 0.8831\n",
      "Loss: 0.41578495934497284 Accuracy: 0.88307375\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3357 - acc: 0.2920\n",
      "Epoch 00001: val_loss improved from inf to 1.55680, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/001-1.5568.hdf5\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 2.3356 - acc: 0.2921 - val_loss: 1.5568 - val_acc: 0.5106\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3698 - acc: 0.5600\n",
      "Epoch 00002: val_loss improved from 1.55680 to 0.94665, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/002-0.9467.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.3697 - acc: 0.5600 - val_loss: 0.9467 - val_acc: 0.7249\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0339 - acc: 0.6760\n",
      "Epoch 00003: val_loss improved from 0.94665 to 0.76509, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/003-0.7651.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.0339 - acc: 0.6759 - val_loss: 0.7651 - val_acc: 0.7836\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8408 - acc: 0.7417\n",
      "Epoch 00004: val_loss improved from 0.76509 to 0.66365, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/004-0.6637.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.8408 - acc: 0.7417 - val_loss: 0.6637 - val_acc: 0.8092\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7218 - acc: 0.7815\n",
      "Epoch 00005: val_loss improved from 0.66365 to 0.53206, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/005-0.5321.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.7220 - acc: 0.7814 - val_loss: 0.5321 - val_acc: 0.8495\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6231 - acc: 0.8134\n",
      "Epoch 00006: val_loss improved from 0.53206 to 0.46684, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/006-0.4668.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6230 - acc: 0.8134 - val_loss: 0.4668 - val_acc: 0.8684\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5532 - acc: 0.8325\n",
      "Epoch 00007: val_loss improved from 0.46684 to 0.43960, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/007-0.4396.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5533 - acc: 0.8324 - val_loss: 0.4396 - val_acc: 0.8798\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4949 - acc: 0.8524\n",
      "Epoch 00008: val_loss improved from 0.43960 to 0.41841, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/008-0.4184.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4948 - acc: 0.8525 - val_loss: 0.4184 - val_acc: 0.8898\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4508 - acc: 0.8650\n",
      "Epoch 00009: val_loss improved from 0.41841 to 0.36370, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/009-0.3637.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4508 - acc: 0.8649 - val_loss: 0.3637 - val_acc: 0.9019\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4183 - acc: 0.8716\n",
      "Epoch 00010: val_loss improved from 0.36370 to 0.35207, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/010-0.3521.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4188 - acc: 0.8715 - val_loss: 0.3521 - val_acc: 0.8963\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3844 - acc: 0.8850\n",
      "Epoch 00011: val_loss did not improve from 0.35207\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3846 - acc: 0.8849 - val_loss: 0.3559 - val_acc: 0.9038\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3628 - acc: 0.8912\n",
      "Epoch 00012: val_loss improved from 0.35207 to 0.32939, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/012-0.3294.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3629 - acc: 0.8912 - val_loss: 0.3294 - val_acc: 0.9103\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3383 - acc: 0.8979\n",
      "Epoch 00013: val_loss did not improve from 0.32939\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3384 - acc: 0.8979 - val_loss: 0.3309 - val_acc: 0.9078\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.9035\n",
      "Epoch 00014: val_loss did not improve from 0.32939\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3157 - acc: 0.9035 - val_loss: 0.3340 - val_acc: 0.9099\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2993 - acc: 0.9090\n",
      "Epoch 00015: val_loss improved from 0.32939 to 0.27673, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/015-0.2767.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2993 - acc: 0.9091 - val_loss: 0.2767 - val_acc: 0.9255\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2835 - acc: 0.9133\n",
      "Epoch 00016: val_loss did not improve from 0.27673\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2836 - acc: 0.9133 - val_loss: 0.3225 - val_acc: 0.9078\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2704 - acc: 0.9175\n",
      "Epoch 00017: val_loss did not improve from 0.27673\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2704 - acc: 0.9175 - val_loss: 0.3178 - val_acc: 0.9126\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2502 - acc: 0.9224\n",
      "Epoch 00018: val_loss improved from 0.27673 to 0.26117, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/018-0.2612.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2505 - acc: 0.9223 - val_loss: 0.2612 - val_acc: 0.9241\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2451 - acc: 0.9244\n",
      "Epoch 00019: val_loss did not improve from 0.26117\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2451 - acc: 0.9244 - val_loss: 0.2666 - val_acc: 0.9245\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2271 - acc: 0.9299\n",
      "Epoch 00020: val_loss improved from 0.26117 to 0.25079, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/020-0.2508.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2274 - acc: 0.9298 - val_loss: 0.2508 - val_acc: 0.9304\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2287 - acc: 0.9290\n",
      "Epoch 00021: val_loss improved from 0.25079 to 0.21772, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/021-0.2177.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2288 - acc: 0.9290 - val_loss: 0.2177 - val_acc: 0.9376\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9355\n",
      "Epoch 00022: val_loss did not improve from 0.21772\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2103 - acc: 0.9354 - val_loss: 0.2573 - val_acc: 0.9322\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9372\n",
      "Epoch 00023: val_loss did not improve from 0.21772\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2039 - acc: 0.9372 - val_loss: 0.2372 - val_acc: 0.9306\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9395\n",
      "Epoch 00024: val_loss did not improve from 0.21772\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1928 - acc: 0.9395 - val_loss: 0.2672 - val_acc: 0.9287\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9403\n",
      "Epoch 00025: val_loss did not improve from 0.21772\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1932 - acc: 0.9403 - val_loss: 0.2264 - val_acc: 0.9359\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1769 - acc: 0.9451\n",
      "Epoch 00026: val_loss did not improve from 0.21772\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1769 - acc: 0.9451 - val_loss: 0.2306 - val_acc: 0.9387\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9446\n",
      "Epoch 00027: val_loss did not improve from 0.21772\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1724 - acc: 0.9446 - val_loss: 0.2301 - val_acc: 0.9387\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1711 - acc: 0.9470\n",
      "Epoch 00028: val_loss did not improve from 0.21772\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1711 - acc: 0.9470 - val_loss: 0.2365 - val_acc: 0.9362\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9518\n",
      "Epoch 00029: val_loss did not improve from 0.21772\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1568 - acc: 0.9518 - val_loss: 0.2436 - val_acc: 0.9322\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1531 - acc: 0.9515\n",
      "Epoch 00030: val_loss did not improve from 0.21772\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1531 - acc: 0.9515 - val_loss: 0.2483 - val_acc: 0.9324\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9529\n",
      "Epoch 00031: val_loss did not improve from 0.21772\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1488 - acc: 0.9528 - val_loss: 0.2651 - val_acc: 0.9292\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9525\n",
      "Epoch 00032: val_loss did not improve from 0.21772\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1494 - acc: 0.9525 - val_loss: 0.2258 - val_acc: 0.9397\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9556\n",
      "Epoch 00033: val_loss improved from 0.21772 to 0.21281, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/033-0.2128.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1397 - acc: 0.9556 - val_loss: 0.2128 - val_acc: 0.9425\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9579\n",
      "Epoch 00034: val_loss did not improve from 0.21281\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1329 - acc: 0.9579 - val_loss: 0.2349 - val_acc: 0.9352\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9595\n",
      "Epoch 00035: val_loss did not improve from 0.21281\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1293 - acc: 0.9595 - val_loss: 0.2276 - val_acc: 0.9345\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9609\n",
      "Epoch 00036: val_loss did not improve from 0.21281\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1240 - acc: 0.9609 - val_loss: 0.2229 - val_acc: 0.9362\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9601\n",
      "Epoch 00037: val_loss did not improve from 0.21281\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1259 - acc: 0.9601 - val_loss: 0.2395 - val_acc: 0.9320\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9605\n",
      "Epoch 00038: val_loss did not improve from 0.21281\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1214 - acc: 0.9605 - val_loss: 0.2163 - val_acc: 0.9401\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9638\n",
      "Epoch 00039: val_loss improved from 0.21281 to 0.20590, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/039-0.2059.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1108 - acc: 0.9638 - val_loss: 0.2059 - val_acc: 0.9469\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9651\n",
      "Epoch 00040: val_loss did not improve from 0.20590\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1113 - acc: 0.9651 - val_loss: 0.2428 - val_acc: 0.9408\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9640\n",
      "Epoch 00041: val_loss improved from 0.20590 to 0.19902, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/041-0.1990.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1154 - acc: 0.9640 - val_loss: 0.1990 - val_acc: 0.9495\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9670\n",
      "Epoch 00042: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1040 - acc: 0.9670 - val_loss: 0.2203 - val_acc: 0.9415\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9680\n",
      "Epoch 00043: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1015 - acc: 0.9680 - val_loss: 0.2423 - val_acc: 0.9425\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9695\n",
      "Epoch 00044: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0962 - acc: 0.9695 - val_loss: 0.2279 - val_acc: 0.9366\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9693\n",
      "Epoch 00045: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0957 - acc: 0.9693 - val_loss: 0.2110 - val_acc: 0.9464\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9692\n",
      "Epoch 00046: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0978 - acc: 0.9692 - val_loss: 0.2341 - val_acc: 0.9455\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9709\n",
      "Epoch 00047: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0896 - acc: 0.9709 - val_loss: 0.2450 - val_acc: 0.9387\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9731\n",
      "Epoch 00048: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0863 - acc: 0.9731 - val_loss: 0.2328 - val_acc: 0.9425\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9728\n",
      "Epoch 00049: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0843 - acc: 0.9728 - val_loss: 0.2409 - val_acc: 0.9371\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9740\n",
      "Epoch 00050: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0838 - acc: 0.9740 - val_loss: 0.2468 - val_acc: 0.9401\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9718\n",
      "Epoch 00051: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0881 - acc: 0.9717 - val_loss: 0.2099 - val_acc: 0.9432\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9746\n",
      "Epoch 00052: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0789 - acc: 0.9746 - val_loss: 0.2083 - val_acc: 0.9427\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9737\n",
      "Epoch 00053: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0815 - acc: 0.9737 - val_loss: 0.2301 - val_acc: 0.9457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9763\n",
      "Epoch 00054: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0737 - acc: 0.9763 - val_loss: 0.2408 - val_acc: 0.9441\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9784\n",
      "Epoch 00055: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0701 - acc: 0.9783 - val_loss: 0.2620 - val_acc: 0.9352\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9747\n",
      "Epoch 00056: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0776 - acc: 0.9747 - val_loss: 0.2092 - val_acc: 0.9511\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9782\n",
      "Epoch 00057: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0688 - acc: 0.9782 - val_loss: 0.2403 - val_acc: 0.9394\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9786\n",
      "Epoch 00058: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0657 - acc: 0.9786 - val_loss: 0.2392 - val_acc: 0.9404\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9749\n",
      "Epoch 00059: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0773 - acc: 0.9749 - val_loss: 0.2410 - val_acc: 0.9446\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9803\n",
      "Epoch 00060: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0635 - acc: 0.9803 - val_loss: 0.2023 - val_acc: 0.9511\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9778\n",
      "Epoch 00061: val_loss did not improve from 0.19902\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0696 - acc: 0.9778 - val_loss: 0.2804 - val_acc: 0.9383\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9819\n",
      "Epoch 00062: val_loss improved from 0.19902 to 0.19894, saving model to model/checkpoint/1D_CNN_custom_DO_BN_7_conv_checkpoint/062-0.1989.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0600 - acc: 0.9819 - val_loss: 0.1989 - val_acc: 0.9506\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9820\n",
      "Epoch 00063: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0582 - acc: 0.9820 - val_loss: 0.2321 - val_acc: 0.9504\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9785\n",
      "Epoch 00064: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0684 - acc: 0.9785 - val_loss: 0.2063 - val_acc: 0.9564\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9821\n",
      "Epoch 00065: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0568 - acc: 0.9820 - val_loss: 0.2452 - val_acc: 0.9404\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9797\n",
      "Epoch 00066: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0652 - acc: 0.9797 - val_loss: 0.2382 - val_acc: 0.9439\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9844\n",
      "Epoch 00067: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0504 - acc: 0.9844 - val_loss: 0.2114 - val_acc: 0.9478\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9831\n",
      "Epoch 00068: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0545 - acc: 0.9830 - val_loss: 0.2758 - val_acc: 0.9366\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9805\n",
      "Epoch 00069: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0613 - acc: 0.9805 - val_loss: 0.2181 - val_acc: 0.9488\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9831\n",
      "Epoch 00070: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0514 - acc: 0.9831 - val_loss: 0.2615 - val_acc: 0.9383\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9846\n",
      "Epoch 00071: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0495 - acc: 0.9846 - val_loss: 0.2238 - val_acc: 0.9464\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9847\n",
      "Epoch 00072: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0492 - acc: 0.9847 - val_loss: 0.2578 - val_acc: 0.9411\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9845\n",
      "Epoch 00073: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0496 - acc: 0.9844 - val_loss: 0.2736 - val_acc: 0.9385\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9832\n",
      "Epoch 00074: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0530 - acc: 0.9832 - val_loss: 0.2089 - val_acc: 0.9504\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9865\n",
      "Epoch 00075: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0443 - acc: 0.9864 - val_loss: 0.2339 - val_acc: 0.9462\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9833\n",
      "Epoch 00076: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0542 - acc: 0.9833 - val_loss: 0.2339 - val_acc: 0.9460\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9849\n",
      "Epoch 00077: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0465 - acc: 0.9849 - val_loss: 0.2161 - val_acc: 0.9536\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9879\n",
      "Epoch 00078: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0403 - acc: 0.9879 - val_loss: 0.2441 - val_acc: 0.9495\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9859\n",
      "Epoch 00079: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0442 - acc: 0.9859 - val_loss: 0.2655 - val_acc: 0.9350\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9856\n",
      "Epoch 00080: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0459 - acc: 0.9856 - val_loss: 0.2717 - val_acc: 0.9397\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9878\n",
      "Epoch 00081: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0395 - acc: 0.9878 - val_loss: 0.2709 - val_acc: 0.9362\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9871\n",
      "Epoch 00082: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0403 - acc: 0.9871 - val_loss: 0.2596 - val_acc: 0.9413\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9878\n",
      "Epoch 00083: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0389 - acc: 0.9878 - val_loss: 0.2313 - val_acc: 0.9481\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9875\n",
      "Epoch 00084: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0410 - acc: 0.9875 - val_loss: 0.2418 - val_acc: 0.9464\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9874\n",
      "Epoch 00085: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0401 - acc: 0.9874 - val_loss: 0.2833 - val_acc: 0.9331\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9899\n",
      "Epoch 00086: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0346 - acc: 0.9899 - val_loss: 0.2538 - val_acc: 0.9429\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9827\n",
      "Epoch 00087: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0554 - acc: 0.9826 - val_loss: 0.2808 - val_acc: 0.9376\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9852\n",
      "Epoch 00088: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0460 - acc: 0.9852 - val_loss: 0.2335 - val_acc: 0.9509\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9895\n",
      "Epoch 00089: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0344 - acc: 0.9895 - val_loss: 0.2271 - val_acc: 0.9506\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9895\n",
      "Epoch 00090: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0325 - acc: 0.9895 - val_loss: 0.2321 - val_acc: 0.9476\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9887\n",
      "Epoch 00091: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0372 - acc: 0.9887 - val_loss: 0.2665 - val_acc: 0.9404\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9877\n",
      "Epoch 00092: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0389 - acc: 0.9877 - val_loss: 0.2270 - val_acc: 0.9497\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9889\n",
      "Epoch 00093: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0344 - acc: 0.9889 - val_loss: 0.2126 - val_acc: 0.9529\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9905\n",
      "Epoch 00094: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0315 - acc: 0.9904 - val_loss: 0.2789 - val_acc: 0.9434\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9863\n",
      "Epoch 00095: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0428 - acc: 0.9863 - val_loss: 0.2454 - val_acc: 0.9481\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9912\n",
      "Epoch 00096: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0287 - acc: 0.9911 - val_loss: 0.2912 - val_acc: 0.9441\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9885\n",
      "Epoch 00097: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0366 - acc: 0.9885 - val_loss: 0.3106 - val_acc: 0.9329\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9881\n",
      "Epoch 00098: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0378 - acc: 0.9881 - val_loss: 0.2289 - val_acc: 0.9481\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9902\n",
      "Epoch 00099: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0303 - acc: 0.9902 - val_loss: 0.2611 - val_acc: 0.9481\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9906\n",
      "Epoch 00100: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0297 - acc: 0.9906 - val_loss: 0.2543 - val_acc: 0.9457\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9914\n",
      "Epoch 00101: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0291 - acc: 0.9914 - val_loss: 0.2434 - val_acc: 0.9467\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9908\n",
      "Epoch 00102: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0291 - acc: 0.9908 - val_loss: 0.2858 - val_acc: 0.9369\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9875\n",
      "Epoch 00103: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0392 - acc: 0.9875 - val_loss: 0.2759 - val_acc: 0.9390\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9899\n",
      "Epoch 00104: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0322 - acc: 0.9899 - val_loss: 0.2918 - val_acc: 0.9385\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9870\n",
      "Epoch 00105: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0412 - acc: 0.9869 - val_loss: 0.2304 - val_acc: 0.9513\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9902\n",
      "Epoch 00106: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0315 - acc: 0.9902 - val_loss: 0.2954 - val_acc: 0.9434\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9919\n",
      "Epoch 00107: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0271 - acc: 0.9919 - val_loss: 0.2390 - val_acc: 0.9488\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9912\n",
      "Epoch 00108: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0298 - acc: 0.9913 - val_loss: 0.2088 - val_acc: 0.9571\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9905\n",
      "Epoch 00109: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0291 - acc: 0.9905 - val_loss: 0.2484 - val_acc: 0.9495\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9905\n",
      "Epoch 00110: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0299 - acc: 0.9905 - val_loss: 0.2317 - val_acc: 0.9509\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9909\n",
      "Epoch 00111: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0281 - acc: 0.9909 - val_loss: 0.2781 - val_acc: 0.9413\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9928\n",
      "Epoch 00112: val_loss did not improve from 0.19894\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0240 - acc: 0.9928 - val_loss: 0.2397 - val_acc: 0.9504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 979us/sample - loss: 0.2449 - acc: 0.9304\n",
      "Loss: 0.24487037120207075 Accuracy: 0.93042576\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2699 - acc: 0.3200\n",
      "Epoch 00001: val_loss improved from inf to 1.48008, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/001-1.4801.hdf5\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 2.2698 - acc: 0.3201 - val_loss: 1.4801 - val_acc: 0.5525\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2113 - acc: 0.6161\n",
      "Epoch 00002: val_loss improved from 1.48008 to 0.66948, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/002-0.6695.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.2113 - acc: 0.6161 - val_loss: 0.6695 - val_acc: 0.8134\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8480 - acc: 0.7397\n",
      "Epoch 00003: val_loss improved from 0.66948 to 0.53499, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/003-0.5350.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.8482 - acc: 0.7396 - val_loss: 0.5350 - val_acc: 0.8477\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6517 - acc: 0.8007\n",
      "Epoch 00004: val_loss improved from 0.53499 to 0.51960, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/004-0.5196.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6521 - acc: 0.8006 - val_loss: 0.5196 - val_acc: 0.8474\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5306 - acc: 0.8394\n",
      "Epoch 00005: val_loss improved from 0.51960 to 0.34653, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/005-0.3465.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.5307 - acc: 0.8393 - val_loss: 0.3465 - val_acc: 0.9008\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4463 - acc: 0.8651\n",
      "Epoch 00006: val_loss improved from 0.34653 to 0.30614, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/006-0.3061.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4465 - acc: 0.8650 - val_loss: 0.3061 - val_acc: 0.9185\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3893 - acc: 0.8817\n",
      "Epoch 00007: val_loss improved from 0.30614 to 0.28297, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/007-0.2830.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3894 - acc: 0.8817 - val_loss: 0.2830 - val_acc: 0.9196\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3422 - acc: 0.8958\n",
      "Epoch 00008: val_loss improved from 0.28297 to 0.24817, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/008-0.2482.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3421 - acc: 0.8958 - val_loss: 0.2482 - val_acc: 0.9276\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3029 - acc: 0.9072\n",
      "Epoch 00009: val_loss did not improve from 0.24817\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3030 - acc: 0.9072 - val_loss: 0.2525 - val_acc: 0.9255\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2730 - acc: 0.9167\n",
      "Epoch 00010: val_loss improved from 0.24817 to 0.22441, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/010-0.2244.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2731 - acc: 0.9166 - val_loss: 0.2244 - val_acc: 0.9308\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2573 - acc: 0.9211\n",
      "Epoch 00011: val_loss improved from 0.22441 to 0.18505, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/011-0.1851.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2574 - acc: 0.9210 - val_loss: 0.1851 - val_acc: 0.9439\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2331 - acc: 0.9267\n",
      "Epoch 00012: val_loss did not improve from 0.18505\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2331 - acc: 0.9266 - val_loss: 0.2030 - val_acc: 0.9385\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9346\n",
      "Epoch 00013: val_loss improved from 0.18505 to 0.17745, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/013-0.1775.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2135 - acc: 0.9346 - val_loss: 0.1775 - val_acc: 0.9483\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2014 - acc: 0.9372\n",
      "Epoch 00014: val_loss improved from 0.17745 to 0.16720, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/014-0.1672.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2014 - acc: 0.9372 - val_loss: 0.1672 - val_acc: 0.9509\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9427\n",
      "Epoch 00015: val_loss did not improve from 0.16720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1853 - acc: 0.9428 - val_loss: 0.1877 - val_acc: 0.9478\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9457\n",
      "Epoch 00016: val_loss improved from 0.16720 to 0.15901, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/016-0.1590.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1762 - acc: 0.9457 - val_loss: 0.1590 - val_acc: 0.9518\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9477\n",
      "Epoch 00017: val_loss did not improve from 0.15901\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1681 - acc: 0.9477 - val_loss: 0.2136 - val_acc: 0.9392\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1561 - acc: 0.9518\n",
      "Epoch 00018: val_loss did not improve from 0.15901\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1561 - acc: 0.9518 - val_loss: 0.1625 - val_acc: 0.9499\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9520\n",
      "Epoch 00019: val_loss improved from 0.15901 to 0.14149, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/019-0.1415.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1498 - acc: 0.9519 - val_loss: 0.1415 - val_acc: 0.9583\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9551\n",
      "Epoch 00020: val_loss did not improve from 0.14149\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1422 - acc: 0.9551 - val_loss: 0.1599 - val_acc: 0.9527\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9588\n",
      "Epoch 00021: val_loss did not improve from 0.14149\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1315 - acc: 0.9588 - val_loss: 0.1917 - val_acc: 0.9450\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9599\n",
      "Epoch 00022: val_loss did not improve from 0.14149\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1244 - acc: 0.9598 - val_loss: 0.1696 - val_acc: 0.9492\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9632\n",
      "Epoch 00023: val_loss did not improve from 0.14149\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1186 - acc: 0.9632 - val_loss: 0.1498 - val_acc: 0.9564\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9649\n",
      "Epoch 00024: val_loss did not improve from 0.14149\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1099 - acc: 0.9650 - val_loss: 0.1457 - val_acc: 0.9595\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9658\n",
      "Epoch 00025: val_loss did not improve from 0.14149\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1068 - acc: 0.9658 - val_loss: 0.1699 - val_acc: 0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9676\n",
      "Epoch 00026: val_loss did not improve from 0.14149\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1006 - acc: 0.9676 - val_loss: 0.1490 - val_acc: 0.9590\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9692\n",
      "Epoch 00027: val_loss did not improve from 0.14149\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0969 - acc: 0.9692 - val_loss: 0.1441 - val_acc: 0.9599\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9721\n",
      "Epoch 00028: val_loss did not improve from 0.14149\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0902 - acc: 0.9720 - val_loss: 0.2033 - val_acc: 0.9406\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9680\n",
      "Epoch 00029: val_loss did not improve from 0.14149\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0971 - acc: 0.9679 - val_loss: 0.1628 - val_acc: 0.9522\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9741\n",
      "Epoch 00030: val_loss improved from 0.14149 to 0.13321, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/030-0.1332.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0854 - acc: 0.9741 - val_loss: 0.1332 - val_acc: 0.9627\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9751\n",
      "Epoch 00031: val_loss did not improve from 0.13321\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0828 - acc: 0.9751 - val_loss: 0.1948 - val_acc: 0.9485\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9745\n",
      "Epoch 00032: val_loss did not improve from 0.13321\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0800 - acc: 0.9745 - val_loss: 0.2082 - val_acc: 0.9518\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9771\n",
      "Epoch 00033: val_loss improved from 0.13321 to 0.13313, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/033-0.1331.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0732 - acc: 0.9771 - val_loss: 0.1331 - val_acc: 0.9620\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9783\n",
      "Epoch 00034: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0697 - acc: 0.9782 - val_loss: 0.2504 - val_acc: 0.9394\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9756\n",
      "Epoch 00035: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0793 - acc: 0.9756 - val_loss: 0.1346 - val_acc: 0.9634\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9799\n",
      "Epoch 00036: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0644 - acc: 0.9799 - val_loss: 0.1590 - val_acc: 0.9569\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9776\n",
      "Epoch 00037: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0692 - acc: 0.9775 - val_loss: 0.1524 - val_acc: 0.9585\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9761\n",
      "Epoch 00038: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0759 - acc: 0.9761 - val_loss: 0.1359 - val_acc: 0.9620\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9826\n",
      "Epoch 00039: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0558 - acc: 0.9826 - val_loss: 0.1446 - val_acc: 0.9604\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9842\n",
      "Epoch 00040: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0542 - acc: 0.9842 - val_loss: 0.2133 - val_acc: 0.9492\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9821\n",
      "Epoch 00041: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0566 - acc: 0.9821 - val_loss: 0.2171 - val_acc: 0.9415\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9824\n",
      "Epoch 00042: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0542 - acc: 0.9824 - val_loss: 0.1628 - val_acc: 0.9585\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9849\n",
      "Epoch 00043: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0494 - acc: 0.9849 - val_loss: 0.1581 - val_acc: 0.9620\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9843\n",
      "Epoch 00044: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0522 - acc: 0.9843 - val_loss: 0.1335 - val_acc: 0.9644\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9831\n",
      "Epoch 00045: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0526 - acc: 0.9831 - val_loss: 0.1480 - val_acc: 0.9620\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9872\n",
      "Epoch 00046: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0429 - acc: 0.9871 - val_loss: 0.1546 - val_acc: 0.9620\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9843\n",
      "Epoch 00047: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0501 - acc: 0.9843 - val_loss: 0.2378 - val_acc: 0.9441\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9858\n",
      "Epoch 00048: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0474 - acc: 0.9858 - val_loss: 0.1722 - val_acc: 0.9543\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9873\n",
      "Epoch 00049: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0406 - acc: 0.9873 - val_loss: 0.2235 - val_acc: 0.9453\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9878\n",
      "Epoch 00050: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0395 - acc: 0.9878 - val_loss: 0.1568 - val_acc: 0.9602\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9866\n",
      "Epoch 00051: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0432 - acc: 0.9866 - val_loss: 0.1731 - val_acc: 0.9534\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9888\n",
      "Epoch 00052: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0360 - acc: 0.9888 - val_loss: 0.1885 - val_acc: 0.9532\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9850\n",
      "Epoch 00053: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0482 - acc: 0.9850 - val_loss: 0.1708 - val_acc: 0.9599\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9896\n",
      "Epoch 00054: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0339 - acc: 0.9896 - val_loss: 0.1427 - val_acc: 0.9651\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9905\n",
      "Epoch 00055: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0316 - acc: 0.9905 - val_loss: 0.1481 - val_acc: 0.9630\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9901\n",
      "Epoch 00056: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0310 - acc: 0.9901 - val_loss: 0.2149 - val_acc: 0.9502\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9904\n",
      "Epoch 00057: val_loss did not improve from 0.13313\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0314 - acc: 0.9904 - val_loss: 0.1750 - val_acc: 0.9595\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9843\n",
      "Epoch 00058: val_loss improved from 0.13313 to 0.13158, saving model to model/checkpoint/1D_CNN_custom_DO_BN_8_conv_checkpoint/058-0.1316.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0482 - acc: 0.9843 - val_loss: 0.1316 - val_acc: 0.9637\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9923\n",
      "Epoch 00059: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0263 - acc: 0.9923 - val_loss: 0.1899 - val_acc: 0.9592\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9908\n",
      "Epoch 00060: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0300 - acc: 0.9908 - val_loss: 0.1542 - val_acc: 0.9630\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9908\n",
      "Epoch 00061: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0294 - acc: 0.9908 - val_loss: 0.1640 - val_acc: 0.9564\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9897\n",
      "Epoch 00062: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0345 - acc: 0.9896 - val_loss: 0.1545 - val_acc: 0.9602\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9902\n",
      "Epoch 00063: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0317 - acc: 0.9901 - val_loss: 0.1782 - val_acc: 0.9602\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9929\n",
      "Epoch 00064: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0243 - acc: 0.9928 - val_loss: 0.1753 - val_acc: 0.9590\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9878\n",
      "Epoch 00065: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0390 - acc: 0.9878 - val_loss: 0.1752 - val_acc: 0.9576\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9936\n",
      "Epoch 00066: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0228 - acc: 0.9936 - val_loss: 0.1684 - val_acc: 0.9592\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9932\n",
      "Epoch 00067: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0232 - acc: 0.9931 - val_loss: 0.1614 - val_acc: 0.9578\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9893\n",
      "Epoch 00068: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0333 - acc: 0.9893 - val_loss: 0.1439 - val_acc: 0.9667\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9939\n",
      "Epoch 00069: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0214 - acc: 0.9939 - val_loss: 0.1757 - val_acc: 0.9560\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9911\n",
      "Epoch 00070: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0293 - acc: 0.9911 - val_loss: 0.1515 - val_acc: 0.9655\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9933\n",
      "Epoch 00071: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0220 - acc: 0.9933 - val_loss: 0.1362 - val_acc: 0.9660\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9931\n",
      "Epoch 00072: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0221 - acc: 0.9931 - val_loss: 0.1898 - val_acc: 0.9560\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9934\n",
      "Epoch 00073: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0216 - acc: 0.9934 - val_loss: 0.1773 - val_acc: 0.9602\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9929\n",
      "Epoch 00074: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0251 - acc: 0.9929 - val_loss: 0.1927 - val_acc: 0.9539\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9934\n",
      "Epoch 00075: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0218 - acc: 0.9934 - val_loss: 0.1533 - val_acc: 0.9630\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9942\n",
      "Epoch 00076: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0195 - acc: 0.9942 - val_loss: 0.2207 - val_acc: 0.9525\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9946\n",
      "Epoch 00077: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0197 - acc: 0.9946 - val_loss: 0.1709 - val_acc: 0.9602\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9940\n",
      "Epoch 00078: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0189 - acc: 0.9940 - val_loss: 0.2002 - val_acc: 0.9550\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9937\n",
      "Epoch 00079: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0214 - acc: 0.9937 - val_loss: 0.1692 - val_acc: 0.9611\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9937\n",
      "Epoch 00080: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0197 - acc: 0.9937 - val_loss: 0.1642 - val_acc: 0.9616\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9926\n",
      "Epoch 00081: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0235 - acc: 0.9926 - val_loss: 0.1804 - val_acc: 0.9611\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9933\n",
      "Epoch 00082: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0207 - acc: 0.9933 - val_loss: 0.1953 - val_acc: 0.9588\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9954\n",
      "Epoch 00083: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0149 - acc: 0.9954 - val_loss: 0.1705 - val_acc: 0.9616\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9943\n",
      "Epoch 00084: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0180 - acc: 0.9943 - val_loss: 0.1626 - val_acc: 0.9620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9957\n",
      "Epoch 00085: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0150 - acc: 0.9957 - val_loss: 0.1810 - val_acc: 0.9620\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9931\n",
      "Epoch 00086: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0220 - acc: 0.9931 - val_loss: 0.1921 - val_acc: 0.9595\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9946\n",
      "Epoch 00087: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0183 - acc: 0.9946 - val_loss: 0.2062 - val_acc: 0.9550\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9934\n",
      "Epoch 00088: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0213 - acc: 0.9934 - val_loss: 0.2227 - val_acc: 0.9539\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9960\n",
      "Epoch 00089: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0138 - acc: 0.9960 - val_loss: 0.2034 - val_acc: 0.9569\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9945\n",
      "Epoch 00090: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0186 - acc: 0.9945 - val_loss: 0.1463 - val_acc: 0.9648\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9944\n",
      "Epoch 00091: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0184 - acc: 0.9944 - val_loss: 0.1758 - val_acc: 0.9595\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9939\n",
      "Epoch 00092: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0195 - acc: 0.9938 - val_loss: 0.1439 - val_acc: 0.9658\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9933\n",
      "Epoch 00093: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0220 - acc: 0.9933 - val_loss: 0.1720 - val_acc: 0.9602\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9930\n",
      "Epoch 00094: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0222 - acc: 0.9930 - val_loss: 0.1577 - val_acc: 0.9653\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9968\n",
      "Epoch 00095: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0119 - acc: 0.9968 - val_loss: 0.1456 - val_acc: 0.9672\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9958\n",
      "Epoch 00096: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0139 - acc: 0.9958 - val_loss: 0.1891 - val_acc: 0.9592\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9952\n",
      "Epoch 00097: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0155 - acc: 0.9952 - val_loss: 0.1847 - val_acc: 0.9609\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9957\n",
      "Epoch 00098: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0156 - acc: 0.9957 - val_loss: 0.1759 - val_acc: 0.9609\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9952\n",
      "Epoch 00099: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0159 - acc: 0.9952 - val_loss: 0.1958 - val_acc: 0.9618\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9955\n",
      "Epoch 00100: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0143 - acc: 0.9955 - val_loss: 0.1969 - val_acc: 0.9576\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9951\n",
      "Epoch 00101: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0145 - acc: 0.9950 - val_loss: 0.1546 - val_acc: 0.9637\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9940\n",
      "Epoch 00102: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0203 - acc: 0.9940 - val_loss: 0.1587 - val_acc: 0.9632\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9964\n",
      "Epoch 00103: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0119 - acc: 0.9964 - val_loss: 0.2280 - val_acc: 0.9485\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9955\n",
      "Epoch 00104: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0142 - acc: 0.9954 - val_loss: 0.1862 - val_acc: 0.9585\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9942\n",
      "Epoch 00105: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0202 - acc: 0.9942 - val_loss: 0.1555 - val_acc: 0.9674\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9971\n",
      "Epoch 00106: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0094 - acc: 0.9971 - val_loss: 0.1545 - val_acc: 0.9667\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9966\n",
      "Epoch 00107: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0117 - acc: 0.9966 - val_loss: 0.1632 - val_acc: 0.9653\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9957\n",
      "Epoch 00108: val_loss did not improve from 0.13158\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0143 - acc: 0.9957 - val_loss: 0.2230 - val_acc: 0.9599\n",
      "\n",
      "1D_CNN_custom_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XecVNXZwPHfmV62d2SBpUmHRYoYBDWKoibYgmjsJhrzGo3xDW+ILZpqmonGGEOMRk2CDY01ihgIFlC6dOmwC9v7zuxOO+8fZ2cLW1jKsMA8389nPrtz63PvzD3PPefee0ZprRFCCCEALD0dgBBCiOOHJAUhhBDNJCkIIYRoJklBCCFEM0kKQgghmklSEEII0UySghBCiGaSFIQQQjSTpCCEEKKZracDOFQZGRk6Ly+vp8MQQogTysqVK8u01pkHm+6ESwp5eXmsWLGip8MQQogTilJqd3emk+YjIYQQzSQpCCGEaCZJQQghRLMT7ppCR4LBIAUFBTQ0NPR0KCcsl8tFbm4udru9p0MRQvSgkyIpFBQUkJiYSF5eHkqpng7nhKO1pry8nIKCAvr379/T4QghetBJ0XzU0NBAenq6JITDpJQiPT1dalpCiJMjKQCSEI6Q7D8hBJxESeFgwmE/jY2FRCLBng5FCCGOW3GTFCIRP4HAfrQ++kmhqqqKJ5544rDmveiii6iqqur29A8++CC/+c1vDmtdQghxMHGTFFo2VR/1JXeVFEKhUJfzvvPOO6SkpBz1mIQQ4nDETVJQymyq1pGjvuw5c+awfft28vPzmT17NosXL2bKlCnMmDGD4cOHA3DppZcybtw4RowYwdy5c5vnzcvLo6ysjF27djFs2DBuueUWRowYwfnnn4/f7+9yvWvWrGHSpEmMHj2ayy67jMrKSgAee+wxhg8fzujRo7nqqqsA+O9//0t+fj75+fmMHTuW2trao74fhBAnvpPiltTWtm69i7q6Ne2Gax0mEvFhsXhQynpIy0xIyGfw4N93Ov7hhx9m/fr1rFlj1rt48WJWrVrF+vXrm2/xfPrpp0lLS8Pv9zNhwgSuuOIK0tPTD4h9K/PmzeMvf/kLV155JfPnz+faa6/tdL3XX389f/jDHzjrrLN44IEHeOihh/j973/Pww8/zM6dO3E6nc1NU7/5zW/44x//yOTJk6mrq8Plch3SPhBCxIc4qilE/zv6zUcdmThxYpt7/h977DHGjBnDpEmT2Lt3L1u3bm03T//+/cnPzwdg3Lhx7Nq1q9PlV1dXU1VVxVlnnQXADTfcwJIlSwAYPXo011xzDX//+9+x2Uzenzx5MnfffTePPfYYVVVVzcOFEKK1k65k6OyMPhz24/NtwOUagN2eFvM4vF5v8/+LFy9m4cKFLF26FI/Hw9lnn93hMwFOp7P5f6vVetDmo868/fbbLFmyhDfffJOf/exnrFu3jjlz5nDxxRfzzjvvMHnyZN577z2GDh16WMsXQpy84qamANGqwtGvKSQmJnbZRl9dXU1qaioej4fNmzezbNmyI15ncnIyqampfPjhhwA8//zznHXWWUQiEfbu3cs555zDL3/5S6qrq6mrq2P79u2MGjWKH/zgB0yYMIHNmzcfcQxCiJPPSVdT6EwsLzSnp6czefJkRo4cyYUXXsjFF1/cZvz06dN58sknGTZsGEOGDGHSpElHZb3PPvsst912Gz6fjwEDBvDMM88QDoe59tprqa6uRmvNnXfeSUpKCvfffz+LFi3CYrEwYsQILrzwwqMSgxDi5KK0PjZt7EfL+PHj9YE/srNp0yaGDRvW5XyRSJD6+rU4nX1xOLJiGeIJqzv7UQhxYlJKrdRajz/YdHHTfBStKcDRrykIIcTJIm6SQvSawolWMxJCiGMp7pKC1BSEEKJzcZMUTC+glphcaBZCiJNF3CQFw8KxenhNCCFORHGVFExtQWoKQgjRmbhKCsdT81FCQsIhDRdCiGMhrpKCqSlI85EQQnQmrpJCrGoKc+bM4Y9//GPz++gP4dTV1XHuuedy2mmnMWrUKF5//fVuL1NrzezZsxk5ciSjRo3ixRdfBGD//v1MnTqV/Px8Ro4cyYcffkg4HObGG29snvZ3v/vdUd9GIUR8OPm6ubjrLljTvutsAFfYZ7pLtbgPbZn5+fD7zrvOnjVrFnfddRe33347AC+99BLvvfceLpeL1157jaSkJMrKypg0aRIzZszo1u8hv/rqq6xZs4a1a9dSVlbGhAkTmDp1Kv/85z+54IILuPfeewmHw/h8PtasWUNhYSHr168HOKRfchNCiNZOvqTQFQWxaD4aO3YsJSUl7Nu3j9LSUlJTU+nTpw/BYJB77rmHJUuWYLFYKCwspLi4mJycnIMu86OPPuLqq6/GarWSnZ3NWWedxfLly5kwYQI333wzwWCQSy+9lPz8fAYMGMCOHTu44447uPjiizn//POP+jYKIeJDzJKCUqoP8ByQjSmJ52qtHz1gGgU8ClwE+IAbtdarjmjFXZzRN/q2onUIr/fo9+8zc+ZMXnnlFYqKipg1axYA//jHPygtLWXlypXY7Xby8vI67DL7UEydOpUlS5bw9ttvc+ONN3L33Xdz/fXXs3btWt577z2efPJJXnrpJZ5++umjsVlCiDgTy2sKIeB/tdbDgUnA7Uqp4QdMcyEwuOl1K/CnGMYT01tSZ82axQsvvMArr7zCzJkzAdNldlZWFna7nUWLFrF79+5uL2/KlCm8+OKLhMNhSktLWbJkCRMnTmT37t1kZ2dzyy238M1vfpNVq1ZRVlZGJBLhiiuu4Kc//SmrVh1ZXhVCxK+Y1RS01vuB/U3/1yqlNgG9gY2tJrsEeE6bDomWKaVSlFK9muaNgdjdkjpixAhqa2vp3bs3vXr1AuCaa67hq1/9KqNGjWL8+PGH9KM2l112GUuXLmXMmDEopfjVr35FTk4Ozz77LL/+9a+x2+0kJCTw3HPPUVhYyE033UQkYrbtF7/4RUy2UQhx8jsmXWcrpfKAJcBIrXVNq+FvAQ9rrT9qev8B8AOt9YqOlgOH33U2gN+/k3C4loSE0YezGSc96TpbiJPXcdN1tlIqAZgP3NU6IRziMm5VSq1QSq0oLS09glgsyBPNQgjRuZgmBaWUHZMQ/qG1frWDSQqBPq3e5zYNa0NrPVdrPV5rPT4zM/MIIrJI19lCCNGFmCWFpjuL/gps0lo/0slkbwDXK2MSUB276wnS95EQQhxMLJ9TmAxcB6xTSkWfJrsH6AugtX4SeAdzO+o2zC2pN8UwHqK9pGqtu/UAmRBCxJtY3n30ES2/bNPZNBq4PVYxtBcNR3OQ0IQQIi7FVd9H0d9pPl56ShVCiONNXCWFWP0kZ1VVFU888cRhzXvRRRdJX0VCiONGnCWF6OYe3TuQukoKoVCoy3nfeecdUlJSjmo8QghxuOIqKcSq+WjOnDls376d/Px8Zs+ezeLFi5kyZQozZsxg+HDTs8ell17KuHHjGDFiBHPnzm2eNy8vj7KyMnbt2sWwYcO45ZZbGDFiBOeffz5+v7/dut58801OP/10xo4dy3nnnUdxcTEAdXV13HTTTYwaNYrRo0czf/58AN59911OO+00xowZw7nnnntUt1sIcfI56XpJ7aLnbLROJBIZgsXi4FBuPjpIz9k8/PDDrF+/njVNK168eDGrVq1i/fr19O/fH4Cnn36atLQ0/H4/EyZM4IorriA9Pb3NcrZu3cq8efP4y1/+wpVXXsn8+fO59tpr20xz5plnsmzZMpRSPPXUU/zqV7/it7/9LT/5yU9ITk5m3bp1AFRWVlJaWsott9zCkiVL6N+/PxUVFd3faCFEXDrpkkLXjt0dRxMnTmxOCACPPfYYr732GgB79+5l69at7ZJC//79yc/PB2DcuHHs2rWr3XILCgqYNWsW+/fvJxAINK9j4cKFvPDCC83Tpaam8uabbzJ16tTmadLS0o7qNgohTj4nXVLo6ow+FPLj92/B7R6CzZYY0zi8Xm/z/4sXL2bhwoUsXboUj8fD2Wef3WEX2k6ns/l/q9XaYfPRHXfcwd13382MGTNYvHgxDz74YEziF0LEp7i6phCru48SExOpra3tdHx1dTWpqal4PB42b97MsmXLDntd1dXV9O7dG4Bnn322efi0adPa/CRoZWUlkyZNYsmSJezcuRNAmo+EEAcVV0khVhea09PTmTx5MiNHjmT27Nntxk+fPp1QKMSwYcOYM2cOkyZNOux1Pfjgg8ycOZNx48aRkZHRPPy+++6jsrKSkSNHMmbMGBYtWkRmZiZz587l8ssvZ8yYMc0//iOEEJ05Jl1nH01H0nV2OOzH59uAyzUAu13a1w8kXWcLcfI6brrOPp5EawrSKZ4QQnQsrpJC9JrCiVY7EkKIYyXOkoLUFIQQoitxlRSkQzwhhOhaXCWFtl1nCyGEOFBcJQXzwzry62tCCNGZuEoKxvHxO80JCQk9HYIQQrQTd0lBfqdZCCE6F3dJIRY1hTlz5rTpYuLBBx/kN7/5DXV1dZx77rmcdtppjBo1itdff/2gy+qsi+2OusDurLtsIYQ4XCddh3h3vXsXa4o66TsbCIfrUcqKxeLq9jLzc/L5/fTOe9qbNWsWd911F7ffbn5u+qWXXuK9997D5XLx2muvkZSURFlZGZMmTWLGjBlNtZWOddTFdiQS6bAL7I66yxZCiCNx0iWF7jm6NYWxY8dSUlLCvn37KC0tJTU1lT59+hAMBrnnnntYsmQJFouFwsJCiouLycnJ6XRZHXWxXVpa2mEX2B11ly2EEEfipEsKXZ3RA9TXb0IpGx7P4KO63pkzZ/LKK69QVFTU3PHcP/7xD0pLS1m5ciV2u528vLwOu8yO6m4X20IIEStxd00hVheaZ82axQsvvMArr7zCzJkzAdPNdVZWFna7nUWLFrF79+4ul9FZF9uddYHdUXfZQghxJOIuKZgLzUc/KYwYMYLa2lp69+5Nr169ALjmmmtYsWIFo0aN4rnnnmPo0KFdLqOzLrY76wK7o+6yhRDiSMRV19kAPt9WtA7i9Q6PRXgnNOk6W4iTl3Sd3QnT/5E8pyCEEB2Ju6QA6rh4olkIIY5HJ01S6G5BLzWFjkmiFELASZIUXC4X5eXl3SzYjo++j44nWmvKy8txubr/QJ8Q4uR0UjynkJubS0FBAaWlpQedNhisJByuxeXadAwiO3G4XC5yc3N7OgwhRA87KZKC3W5vftr3YHbuvJ/du39Ofn6oy+4mhBAiHp0UzUeHwvR5FEHrUE+HIoQQx504TQoQiUj3EUIIcaC4SwpKOQGIRBp7OBIhhDj+xF1SkJqCEEJ0LmZJQSn1tFKqRCm1vpPxZyulqpVSa5peD8QqltYkKQghROdieffR34DHgee6mOZDrfVXYhhDO5IUhBCiczGrKWitlwAVsVr+4ZKkIIQQnevpawpnKKXWKqX+rZQacSxWKElBCCE615NJYRXQT2s9BvgD8K/OJlRK3aqUWqGUWtGdp5Y79MUX8NvfYq0OAJIUhBCiIz2WFLTWNVrruqb/3wHsSqmMTqadq7Uer7Uen5mZeXgrXLcOvv99rEU1TcuUW1KFEOJAPZYUlFI5qqmfCaXUxKZYymO2Qo8HAEtDGJCaghBCdCRmdx8ppeYBZwMZSqkC4EeAHUBr/STwNeDbSqkQ4Aeu0rHsvrQ5KUTALUlBCCE6ErOkoLW++iDjH8fcsnpstK4pSFIQQogO9fTdR8eO1wuAxW86wpOkIIQQ7cVPUmiqKShJCkII0an4SwoNQUCSghBCdCR+kkJT85Gq9wMWSQpCCNGB+EkKbjcAyu/HYnFK19lCCNGB+EkKFgu4XODzYbG4pKYghBAdiJ+kAOa6giQFIYToVHwlBa8X6uslKQghRCfiKylITUEIIbokSUEIIUQzSQpCCCGaxVdSkGsKQgjRpfhKCs01BXlOQQghOhKnSUFqCkII0RFJCkIIIZrFV1KQawpCCNGl+EoKUlMQQoguxV9SCAaxhO2SFIQQogPxlxQAa8AqSUEIITrQraSglPquUipJGX9VSq1SSp0f6+COuqbfVLA1WtE6gNaRHg5ICCGOL92tKdysta4BzgdSgeuAh2MWVaw01RRsAfM3GKzoyWiEEOK4092koJr+XgQ8r7Xe0GrYiaMpKThCiQAEg8U9GY0QQhx3upsUViqlFmCSwntKqUTgxGt7aUoK9oBpRgoEJCkIIURrtm5O9w0gH9ihtfYppdKAm2IXVow0XVOwB13gkKQghBAH6m5N4Qxgi9a6Sil1LXAfUB27sGIkWlMIugAIBkt6MhohhDjudDcp/AnwKaXGAP8LbAeei1lUsRK9JbXRglI2qSkIIcQBupsUQlprDVwCPK61/iOQGLuwYqSp+Uj5/NjtWZIUhBDiAN29plCrlPoh5lbUKUopC2CPXVgx0lRTwOfD4ciWpCCEEAfobk1hFtCIeV6hCMgFfh2zqGLlgKQgt6QKIURb3UoKTYngH0CyUuorQIPW+sS7puB2m7/19djtUlMQQogDdbebiyuBz4CZwJXAp0qpr8UysJiwWExiaNV8ZC6VCCGEgO5fU7gXmKC1LgFQSmUCC4FXYhVYzDR1n+1wDEDrAKFQNXZ7Sk9HJYQQx4XuXlOwRBNCk/JDmPf40pwUsgHp6kIIIVrrbk3hXaXUe8C8pvezgHdiE1KMeTzN1xTAPNXs8Qzp4aCEEOL40K2koLWerZS6ApjcNGiu1vq12IUVQ15vm5qCXGwWQogW3a0poLWeD8zv7vRKqaeBrwAlWuuRHYxXwKOYTvZ8wI1a61XdXf5hO6D5SJKCEEK06PK6gFKqVilV08GrVilVc5Bl/w2Y3sX4C4HBTa9bMV1pxF5TUrDb0wGLXFMQQohWuqwpaK0PuysLrfUSpVReF5NcAjzX1H3GMqVUilKql9Z6/+Gus1s8Hti/H6Ws2O0ZUlMQ4jihNdTXg9UKLhcoBeEw+HwQDEJyshnXlWAQKirMdImJ4HCY5RwKnw8KCsy6nU4Ti91uXjYbRCIQCpm/VqsZFo010vSDAtFpHQ5zJzyYcZWVUFVlxrlc5uV2m+nBjC8uNvvBZjMvu93E4XRCUlJzbz0x0+3moxjoDext9b6gaVi7pKCUuhVTm6Bv375HttamawpA07MK0lPq8Uxr8PshEDAHeUeFgt8PZWXmQI0ejK0Ptv37YdcuKCmBtDTIyjLL8vnMwVdX1/K3ocEsJxw2y/F4zMFYV2cO2Pp6yM6Gfv3MAbprF2zdCkVF0NhoXuGwiTMaayRitqN/f8jPh0GDYM0aWLIEPv/cLN/rNfFGCzCr1bx3u02hEgqZAq+qCkpLTSy9e8OQIebvtm1mWbt3m2XYbJCQAH36QN++Zv7t283LYjH7ID3dxFtZCTU1JkaLxcwfiZjt0LqlcFLKxBAKmc+jsdH8jRaQrQtJm61lH1hatUdEHxWKbmswaJZRU2O2LdLqV1ocDjOu9bxpac33ilBXZ6b3eMzyGhrMMlpr/TlE90v0O9I6TovFvKqqoLz8SL+1bTkc5jOur2+7fa1F93s43PWyZs+GX/3q6MZ3oJ5MCt2mtZ4LzAUYP378kT1t1tR8BEhXF92gddszLa1NwVNSYg7ChgYz3m43B1dlpSmgy8vNbvb7zTzp6ZCRYf7fuRN27DAFQnq6OdCjZ0AOB2zZAitWwPr1UF3d9kBKTDQfodZmuM/X/HH2qMREk4iiZ4bhsHkpZd5rbZLTgfOMHWsK14oKs6+iQiHzPrr/ooVtSgpkZprCvqAAFi0y06SkwOjRcH7TL6eHw2bf7d0Ln31m5h80CM4+28RUUmI+J5fLLCspycTZunCPFubRbYlE2p4BO53mb7RgjSaTaOJoPV/0OxQKme9MdFvtdrOMxESzDUlJZnq/3+wXt9skN5vNfKdKS824hATzUsq8r68325KZab5n4TDU1prEEX0+NXqGH02w4XDLe63N+8REk/Bzc01c0e94MNiyXa2TXettjA7XumUdgUDLMhISzPc9NdXMEx0e/ZwjEZOss7PNtOFwy3obG820+fkx+wo368mkUAj0afU+t2lYbEVPMwC7PRu/f3vMV9lTwmFzEBUWmgOqpsYcKNEDrrHRHDQ1NS3j6upMYVJSYl6BgDnTzMszX861a6E6XARBDzQmdbJmDc5aaEzCbjcHbiAAOKshdSeWimH0PcWJy2UKw4oKcxBhbYSEYpx2G6OHJDLzSi+ZGZbmZoDo2aTP13Jm5XZDekYYW2oRDZZSaoIV1AQr0UEX1sZ0rMFUcjJt9M6F3CwvVn8OJSVmW71ec/C1/utytRRyoZBZV/SATk010xQVwZ49UF4Zwpa1nYaEzfh0GSmuFFLdqQzLGEavxF7t9kppZQMLl+9mzY59jBuSzUVnDCDB5aIh1EBBTQENoQaGpA/Bbu1+X5PRJom0tPbNJFprNpZuZOGOhditdi4deimnJJ4CwM7Knby/432qGqoIR8JYlIUp/aZweu/TsVq6bqPZXbUbj91DpjfzoPFpralprCEYCRKKhACwKitWixWv3YvT5myeNhQJUeGvoDHUSFiHCUdaTputFivp7nQSHAmobrQHaa3ZVrGNlftX0iuhFyOyRpDmTmNH5Q5W719NcX0xQzOGMjJrJF67ly3lW9hctpl9tfuoaaxheWMN/VP6M7XfVPJz8rFarGitaQw3NveCENZhGkONNIYbsVvsZHgymmOrbaxlXck6ahtrsVls2K12xp8yHo/d0y7OTWWbeH/7+2ws3Ui1xcYuqx2n1UmCIwGvw8spiacwLnM4p6afisvmOui2H6meTApvAN9RSr0AnA5Ux/x6ArSrKfTUNYVgOEiZr4y6QB2Z3kySnckopahuqGZ39W6SnEnkpeQB5syjpAQ2bKvh06IPWV35HzbWfIpX55ASGImrehQUnEHpjlMoKmo6+2jQ1Kq9hHsthdxlkL4VEorAWwL1WVA4AYryIWk/ttzVkLkBnVMHtkZsES+jq+/hEte3cNis7NkDm4p2UJn7Ms4p88G+HJfFy/Tsm5jV/04yHL0pqt9PQf121vje5sPSf7Gvfg/fmXAHv5z2MG6bh39vWsRNb11DiX8/Voud1KyRZHozSW2sJStQS3FdMaW+UsD0vLgcWGOxc/7A87l65NXMGDKDRGfLJa6t5Vv58ZIf8+auxeyv3U+4uJN6twXzqGVTk8BVI6/i59N/Tv/U/viCPhZsX0BBQxXnDTiP3KRcqhuqmbtyLn9a8SdsFhsTe09kXK9xpPhTsDRYaAg1sLpoNcv3LWdd8TqC64PtV6ksXDT4Ir459ptoNO9sfYf3d7zPrqpdLRMVA0sgxZVCVUNLm4fT6mR09mgyvZnsrd7L3pq91Afqm8fbrXY8dg9umxuP3YPX4cVlc+EL+qhtrKUx3GiG270U1xezr3Zf87zfeec7TMqdRFVDFZvKNnW4u7K8WUzuM5lSXyk7K3fiD/kZnT2a03JOozHcyHvb32NbxTaTRPpO4ZIhl1DVUMVHez9i1f5VZHuzGZoxlFMST2FL+RbWFK2hwl/RyVEAXruXNHca/pCfcl85mq4bAhxWB9nebAakDmBg6kB6JfbCbXPjtrupD9RTVFdEYW0hnxZ+SlFdUbt5A+FAJ0tuYVEWEhwJ1DTWNMdotVipC9QR0Z3/CrHH7iEvJY9AOMC2im3txqe70/n2+G9zy7hb2FCygde3vM7bW9+moKYAgExPJhpNIBygIdTQLlaLsnDPmffwky//5KDbcCRUrPr+UUrNA84GMjCHwI9o6m5ba/1k0y2pj2PuUPIBN2mtVxxsuePHj9crVhx0ss797Gdw330QCLBn/+/YseMHnHlmLTZbwuEvswPFdcX8c90/CUVCDM8czqC0QazYt4I3v3iTD3Z+QJmvrM30duXEop000nJTV0LZWbg3f4Oq6gjBwS/DwAVgDULICfvGgacM0raBxXxRXf7+pEWG0eAooNa6k6ClFgCHctPPO4Qsbw7ZCVmUNBSwtnQFtYEaFIohGUMYnT2aFGcKTpuTtcVrWbJ7Cfk5+Xx95Nd5bfNrLC1YCsCEUyZw6dBL+aL8C+atn9fui+uyuTh/4Pmku9N5Zs0zDM0YyvSB03n000c5Nf1U5pw5hy1lW1i5fyXVjdUkOhJJdCaS5ckiNymXXom9CEfC1AZqKagp4NVNr7K3Zi8Oq4Pxp4znzD5nUuGv4Jk1z+C0Obl82OX0S+5H78TeZCdkk+5OJ8WVQkOogQp/BZUNlc1nnBtKN/DYp48R1mGm9J3CJ3s/wR9qabMZljGMgpoCagO1nJN3DsmuZJYXLqewtm0FNtmZzPhTxjOu1zhGZI1gaMZQsrxZVDdUU+Gv4P0d7/PMmmeaC6VERyLTBk4jPzuf/qn96ZXQi6K6InZU7qC4vpichBz6JPXBZrGxumi12TcN1fRJ7kOfpD4kOU2NTGtTYPhDfnxBH76gj/pgPQ2hBrx2L4nORBxWB/6gn/pgPQmOBM7tfy7TBkzDF/Qxf9N8Xt/yOimuFC4efDEXDrqQ3KRcbBYb9cF63tv2Hq9veZ0V+1bQO6k3/VP647A6WFu8ls+LP8eiLJyTdw7nDzyfMl8Zr256lQ2lG7AoC2OyxzDhlAmU+cvYXLaZwppCTk0/lfycfE5NPxWn1YnNYs5BwzpMKBKiPlBPhb+Ccn85bpubLG8WGZ4M3HY3NosNi7KgMGfewUiQCn8FZb4yCmsL2VG5g+0V2ympL2mTSNLcaeQk5JCfk8/UvlOZ2HsiJfUlbCzdSGFtIUMzhnJar9PISchhS9kW1pWswxf0MSR9CMMyh5GblIvX7kUpRUFNAR/u/pBlBctQSpkzd7sXizLtakopXDYXTquThlADu6p2sbNqJzaLjfycfMZkjyHdk04oEqK6oZq/rv4rb2x5ozler93LBYMuYPrA6UwbOK35JDAqFAlRF6hjT/UeNpZuZGPpRs7IPYMLB1948AKoA0qplVrr8Qed7kTrEO6Ik8Lvfgd33w1VVRT5/8XmzTdy+unbcLsHHtJiwpEwxfXFJDoSSXAkEAgH2FqxlQ0lG5i/aT7/2vwvgpH2Z5FenU1SyXTCZQNpKM8/dUnFAAAgAElEQVSgttKLdpWZs3hbA67GvqSqftizt1PW96/4XOaMI83SjykZVzA15yuMTD4Dl81FRgakZPopaFzPx3s/4qO9H7GtYht9kvrQP6U/QzKGMCl3EmOyx7RrkojoCLurdpPpzSTB0TYhaq15eePL/O+C/6WgpoCRWSO5bvR1zBoxi34p/ZqnK6or4vm1zxPWYXol9KJ3Um8m5U5qXt7CHQu58V83UlhbyA1jbuDxix5vt66DiegIS/cu5Y0tb/DR3o9YXrgcgNvG38Y9U+4hJyHnkJZXWFPIA4se4OO9H3PegPO4bOhlZHmzWLB9AQt2LCDTk8ndZ9zNab1Oa56ntL4Uf8hPREewKAu5SbnNBUNnguEgC3csxG13M7nP5ENqEjoehSIhtNbttmN31W5S3anNietY01oTjATxBX24be42zVHHoy/Kv2D+xvnk5+RzTv9zjklzUJQkhc78+c9w221QWEi583PWrbuQsWM/Jjn5Sx1OHtERFu5YSHFdMb6gj3J/OZ/s/YSP9nxEdaP5meroGU1YmzPSJFsak9w30L/iVgq/yGZt4UYK/FvRJcNQ+yeQP8ZC377molhODgwbBiNGwKmntvTuDeYLv7RgKXaLaY/sTlvq0eQL+iiqK2JA6oDDXkZVQxUbSzfypT4d799D5Q/6aQw3kuKSTgyFOBTdTQonxN1HR1XrH9pJ7Pqp5gXbF/CDhT9gTdGaNsOHpA9h1ohZjMkZgy/oY3thFVu2KPatHcbWT4ZTUzyMBWFn8x0fE0dO5qYRk5k0CSZPNndYdIdS6qgVpofDY/ccUUIA02Z+NLfBbTftx0KI2Ii/pBB98qOLri7CkTAzX57Ja5tfIy8lj+cve55JuZPw2D0kOBJIciZRXAzPPw///CesXm3mGzsWfngTnHmmSQb9+rU8lCKEECeC+EsKrWoKdru5pe7AZxXmrpzLa5tf40dn/YgfnvnDNu2Uq1fDo4/CvHnmNssJE8xlipkzzUNEQghxIovfpFBfj8Vix2ZLb1NTKK4r5ocf/JAv9/8yPzrrR83t+CtXwgMPwDvvmMrGLbfAd74DQ4f2xEYIIURsxG9SaH5WIatNUvi/hf+HL+jjjxf9EaUUpaXw7W/D/Pnm4aWf/Qz+53/M05dCCHGyib+k0OqaAoDVnsWOyt14K3eyrmQdz619jnvOvIehGUNZvhyuuMI8Ffzgg/C973X/IrEQQpyI4i8ptGo+qgvU8c2PN7CmvAz+Y+6y6Zfcj3un3svf/mbuXM3JgY8/htNO63yRQghxsojbpOCvr2LGvBmsqyjn1v6KSSP/DMrGeQPO453XPdx0E5x7LrzwgulgSwgh4kH8JQWvl4AVZlb9hcUVW3j83NsZHnqccYMnkJiYz4oVcP318KUvwVtvmQ7ShBAiXnT9rP7JyOXiT+Ph7chm/nTxn7hh7G0A+HwbKSyESy4x3de+9pokBCFE/Im/moLFwvpTrGRHnHxr/LeIRAIoZaOubgM33GC6Z/7kE5MYhBAi3sRfUgB2pVrIC5tumC0WB273YN56K4GPP4a5c2HUqB4OUAghekj8NR8Bu5I1eYGW/nMcjpH8/vczGTIEbrqpBwMTQogeFnc1hYiOsDshxBWVLRcMFiy4ml27BvHSSwFsNkcPRieEED0r7moK+2v3E7RCXp3Jhw0N8Nhj5zN06KdMn97xr1EJIUS8iLukEP1JxLwas+lPPgmFhV5uvXUOPt/GHoxMCCF6Xtwlhd3VuwHIa/pZ3Hnz4PTTI4wd+yH19Rt6MDIhhOh5cZcUojWFfuVhqqpgxQq44AILbvcgqSkIIeJeXCaFrJALd62fxYshEoHzzgOvd4TUFIQQcS8uk0JeJBF8Pj74wHSFdPrp4PUOx+/fRiTS2NMhCiFEj4nPpEAK+HwsXAhTp4LDAR7PCCCCz7elp0MUQogeE1dJIaIj7K7eTZ41ncK6ZDZvNk1HYGoKAPX1cl1BCBG/4urhtaK6IgLhAHmJffhPZBBguscGcLtPBSz4fHJdQQgRv+IqKTQ/ozByCi+QREZiA6NHmyebrVYXbvcg6urW9WCEQgjRs+Kq+aj5dtSx5/CBOo8vZ63H0moPJCdPprp6CVqHeyZAIYToYXGZFBrLBlCoe3Ou760241NTzyMUqqS2dlUPRCeEED0v7pJCljeLpUvMT3Keu/95KC1tHp+aai4wVFYu7JH4hBCip8VdUshLyWPLFkhwhxnADvjoo+bxDkc2Xu9oKivf78EohRCi58RlUigogD79LCiXC5YsaTNNauo0qqs/Jhz29VCUQgjRc+ImKUR0hD3Ve8hLNkkht4+CM85olxTS0qahdYDq6g97KFIhhOg5cZMUiuuKaQw30i+ln0kKuZjHmdesgerq5umSk6eglIOKCmlCEkLEn7hJCtE7j3IT8ti/vykpTJliesT75JPm6axWD8nJk+VisxAiLsVdUvAG89C6KSlMmgQ2WwfXFc6jvn4tgUDxsQ9UCCF6UEyTglJqulJqi1Jqm1JqTgfjb1RKlSql1jS9vhmrWGYMmcHqb63GVmO6t8jNBbxeGD8eXn4Zli1rnjY1dRoAlZUfxCocIYQ4LsUsKSilrMAfgQuB4cDVSqnhHUz6otY6v+n1VKzi8Tq85OfkU7zPAUCfPk0j5syBigpz0fmcc2DdOhITT8Nuz6Cs7LVYhSOEEMelWNYUJgLbtNY7tNYB4AXgkhiur1sKCszf3NymAZdcAnv2wG9/C59/DnfeiVJWsrOvpazsdQKBsh6LVQghjrVYJoXewN5W7wuahh3oCqXU50qpV5RSfToYf1QVFJgf1klJaTUwIQHuvhuuvBJWrwatycn5BloHKS7+e6xDEkKI40ZPX2h+E8jTWo8G3gee7WgipdStSqkVSqkVpa26pTgc0dtRlepgZH6+uT11924SEkaSmDiBoqK/orU+onUKIcSJIpZJoRBofeaf2zSsmda6XGsd/f3Lp4BxHS1Iaz1Xaz1eaz0+MzPziIJqfkahI2PHmr9r1gDQq9c3qK9fT23t8iNapxBCnChimRSWA4OVUv2VUg7gKuCN1hMopXq1ejsD2BTDeICDJIWRI8FiaU4KWVlXYbG42b//r7EOSwghjgsxSwpa6xDwHeA9TGH/ktZ6g1Lqx0qpGU2T3amU2qCUWgvcCdwYq3gAwmHYt6+LpODxwJAh5roCYLMlk5k5k5KSeYTD9bEMTQghjgsxvaagtX5Ha32q1nqg1vpnTcMe0Fq/0fT/D7XWI7TWY7TW52itN8cynuJikxj6dHU5Oz+/uaYApgkpHK6lqOj5WIYmhBDHhZ6+0HxM7W26F6rTmgKYpLBnj3l2AdMXUnLymeza9SNCoZrYBymEED0orpJCu2cUOpKfb/6uXQuAUoqBA39HMFjC7t0/j22AQgjRwyQpHGjMGPO3VRNSUtJ4srOvp6Dgd/j9O2MXoBBC9LC4SwpOJ6SndzFRdjb06tUmKQAMGPBzlLKxY8f/xTZIIYToQXGXFDp9cK21/PzmO5CinM7e9O37A0pLX6GiYkHsghRCiB4Ul0nhoMaOhU2boKGhzeA+fWbj8Qxl8+abCQYrYxOkEEL0oLhLCl3ejhqVnw+hEGzc2Gaw1epm6NDnCQSK2Lr1jtgEKYQQPShukkIkAoWF3awpRO9AOuC6ApiLznl591NS8g9KSl4+ukEKIUQPi5ukUFICwWA3k8LAgZCWBk8+2a4JCaBv33tITJzAF1/cht+/66jHKoQQPSVukkK3bkeNsljgL3+B5cvh9tvhgF5SLRY7w4b9A4iwfv1XCYVqj3q8QgjREyQpdObyy+H+++Hpp+GJJ9qN9ngGM3z4S9TXb2LTpmvQOnz0ghVCiB4SN0lh0CC47z4YMOAQZnrwQfjqV+Guu2DevHaj09KmMWjQ7ykvf5MdO+bI7y4IIU54tp4O4FgZOdK8DonFAn//O1x4IXz96/Duu/CHP0BSUvMkvXvfjs+3kb17f4PWYQYO/A1KxU2uFUKcZKT0OpikJPjvf+FHPzIJYuxY2LatebRSisGDH6d37zspKPgdmzffSCQS7MGAhRDi8ElS6A6bzTQlLVkCNTVw3nktFykApSwMGvR78vJ+QnHx86xZczaVlR9Ic5IQ4oQjSeFQTJ5smpAqKmDaNIj+XnQggAqFyMu7j6FDn6WhYSdr157HqlVnUFX1Yc/GLIQQh0CSwqEaNw7eegt27TJNSXl54HabR6WXLiUn53pOP30Hgwf/iUBgP2vWnM2uXT+J37uT/v1vOOccCAR6OhIhRDdIUjgcU6fC66/D8OEwZQrcey8kJMCXvwwvv4zV6qJ379uYMGE9WVlXsWvXA6xdewGNjft6OvJj76mnYPFiWLq0pyNpsXAhXHWVeZpRCNGGJIXDdf75sGABPP88/PjHptA77TS48kp49FEAbLZEhg37O6ee+hdqaj7ms8+GsHfvI/FzIToUgg8+MP+/+27PxtLaQw/Biy+aGwdaW7Dg+EpeJ4Jt26CxsWdjCIVg/nz45JOejaM7duww5cSCw+hp+cEHj833U2t9Qr3GjRunj1t+v9aXXaY1aP3qq21G1ddv1WvXXqgXLUJ/9tlIvW/f0zoYrDn4Mp94Quv582MU8FEUiWi9fbv5G/XRR2ZfuFxa5+cf/rJ37NB65kytTztN64wMrUeM0Lqu7vCWtWmTiclq1XrgQK2DQTN840atHQ6ts7O19vkOP9bW7r5b67lzj86yjkc7d2ptt2s9Y0bbz/1YCQa1fvZZ8zmafge0vuoqrQsKjn0s3XXrrSbO1FSz/7rrk0/MfA8+eNirBlbobpSxPV7IH+rruE4KWpvEMHGi1h6P1mvWmGHLlml9xRU68s9/6pKS1/SyZafqRYvQ//2vR2/ceL2urV3X8bKWLWspVLduPXbbEPXOO1rffLPZps5UV2v9xz9qPXKkifWvf20Zd//9WlssWv/gB2bcvn2HF8cVV5j9edFFWl9/vVnWPfcc3rK+/32tbTat//xns5y//U3rcFjrKVO0drvNsMceO7xlt/bf/5plKaX1m28e+fKOR7fd1lIYz5vXMrykROs//KH7iftQE0plpda//a3W/fubdefnm5OwH/1Ia6dTa6/XfHePlVBI6y++0HrtWq0//dQcEx3Zt8+ceHz1q1onJ5uTnK6OrahIROszzzQnLLW1hx2mJIWetG+f1r17a923r9azZpndbLOZv9/9ro40Nuqqqo/15s236iVLEvSiRejN71yg6198REfCYbOMUEjrceO0zsnROilJ63PPPfjB89ZbWn/ta+Zs+EjV1Wndq5eJ+eabO153ZaXZTjBf8IEDzVl8dNqJE7U+4wyTHKMF8KHatMkUrPfe2zLsuuvMwbVly6Etq7FR68xMU5uLRExhMmiQqY1FE9qUKWabGhraz79zp9ZPPtm95DZtmtZZWWa/JCaamsiB9u3T+qGHtK7pRo3xWNm7V+s5c0wtL/o5Ll9uamo33GC+l1prXVhoPoNvfMN8zhkZJhns2KH14MFmf555ZucFpNZa79ql9V13mf1zzjld79dAQOt339X6pptMoR9d/quvmqQetX27+Q7263d0anzBoNaPP671I49o/frrWm/Y0HZ9S5aY9UWTI5jjvqys/bJmzzYnSdu2af3GG2bab3zj4Mf166+baZ944og2RZJCT1uxwpx5ut3mjLm8XOvvfrfly7xggdaBgA7U79dls8/RIYf5QhXO9OpN62/U1b/+ppn2n//U+k9/Mv8/80zn63vllZbE43KZL3HrL++h+vGPzbIuv9z8ffzx9tPce68Z9+675ov9t7+Z9++/bw4KpUx1NxIxye2qqw49jhtvNPuwpKRl2P79JlFecMGhnWW+8oqJ7+23zftXXzXvLRatzz7bLGvBAjPsySdb5tuwwSQiq9WM83i0fuCBzgvzaA3vV7/Ses8ekxwGD9a6oqLtdDNnmummTTMJqyt+v9YPP2xqXY88ovXf/671iy+a12uvtW+668ynn2q9e3fH4yIRs0+jhduQIaawhpaC+PvfN9N+73tmf2zfrvX69aYZado08zmnpJhkZ7NpPX58+wJy8+aW/WmzaX3ppWafZmVp/cEH7bf7F78wSQdMArnxRq1Xrux8G//zHzPtz37WMqy+3tQeDjwmIpGuj5Pod7z1KzNT669/XetrrmlJAk88Yb5fzz5rkuX06W2XW1GhdUJC22PgnnvM/LNnd/7ZBYNaDxum9amnmsR4BCQpHA82b25/9vOPf5gvNpiDp6k9NHzJV3TtTeYALDvTpgNJ6Mox6E+XDdFbt9ytQ5PyTTtkcXH79cybZw6wL33JnD1/9atm+ZMna72uk6apFSvM+Iceal8gFRWZL/Bll5kv9le+Yg7e//637TRer6kJRTU0mAP7K1/R+oUXTAxLl5pxN9ygdVpay5lmd+zebdZ7xx3tx/3ud7r57L67Z9rTp5taQDSGcFjr0aNNk8MXX5hhkYjWp5+udV6e1qtWtRTcHo8pCD/+WOsrrzTDcnJMAjjQxRdrnZ7eUtX/6KP2be8ff2yWcdZZ5u/VV5t4wmGtP/tM60WLWj6XTZu0HjPGTGe3ty+koq/0dFOoP/CASXyVlW3j+tvfTAJMStL6pZfaxx1Nmj//udZPP21OXvLytP7lL80Z/3e+Y8b/+tcmUV93Xcu8Dz1kxuXmmiShtWk2czrNWft112n905+awtRiMfN/73smaWpt5hk61Iw75xzTFPTnP5v1g2k6fO217jW3aG2+u16vOf7KykyNFdrWdiortT7vPJNw7ruv/bG6YIE5sbn5ZrOMTz81J2bXXmu+5zabqVUd2EwWPYl76KGWYT/7mRm2enXLsHBY6//5HzP8ttvaJ6dwWOtHHzXjj8J1RUkKx7P6eq3/9S/zBZ00yXzZox55REeU0hGrVe9773t67drpevFim/70GXTYrnSgT4qumH+/rq//QkfKykz122LReurUlsIxetaelma+uLNnt5ylRiLmi2a3m8IBTPU3WnhrrfW3v23mizbPVFWZs8bk5JbEcMcdJhFFC9OoBx4wB9JZZ5kkFj0A580z61q2zCSUSy81BfKNN5payN697ffTnXeaODo6sw0GzfzRAjEnR+v//d/2CS4cNoXq00+buO6/v+34PXtMIdzam2+2LDcx0ZzRlZa2nWbZMq0HDDC1sldeaRm+apWZ76c/bTt99OB+5BHzGUyaZJrn6upMDQBM01VOTsu6ExJMgvV4TMH11ltm3ooK89ls2GBen31mCtBvfEPrUaPM9yF6dh+t0Tz1lNn+L3/ZrBvM5xwt0GprTYE+ZkzLxfeO9vm55+rmayWtm8QaG821mAM/x8WLTcGbm9uSXGfP7vjkprbWFLJjx5rlg/mMFy7sOJ6ubNtmvuOXXmrOtB0Ok5DAnOFv3WqG2+0mPqXM/7Nmaf3vf5vtyMw0x0Z9ffvlh8OdN09FIiZxKGXWec45ZrsvvLDjaefMMXGde645rmbPNnFEa0eTJx+VC/mSFE5k//63aRZo0thYqvfu/YPe8pfhur63KTBKpqADiUpHLOjaq0/X9SVr2i+ntFTrb36zpZBJSzNt6GBqE2VlpgCMHrBZWaZgslq1vv32tsvavdskBqfTHPx2u7mT4kD79rWczc6c2TI82px0ySWm4HO7tT7/fHPggTlob7/d3DnyxRemOu52m8TZmcpKrV9+2ZzZfu1rZjkTJ5q26t27TZJISWmbODprOmktEjEF5r33dtw2HFVSYgpYpcyZ8AUXmAM5Odkk0gOXedllJsl9//u6zUX5SETr//s/E+uVV2r9/POmHflb3zJnyhdeaNrwu6umxjShRGs5aWnm7/TppiALBEzBAybeH//Y7HswNZiulJebmwpuuqn78UTV1nb/QmllpUl2h1KzPFB0G5OSTM1L65YzdpvN7O/o8K1bzUlIdF/ZbKYg7+haUHfU1Zlk0KuXqaVce61JVJ359a+1PuUUcyLldpv/r7vONEd1dV3mEEhSOEmF66p0w1036IhF6bozTtFrn++rFy2i6VbX0XrHjgd0efkCHQy2KpSWLzft29/+tmnaeOyxtmce1dXmDPbmm02TwbhxHZ/JlZaaQjd63aKzW/+iba1PPdV2+Omnm+FDh7Y0a0Ui5qz3llvMgRg9QwSTwLo6kA70yiumAEhMNInNajWF7DPPmPV1dgZ8JHw+czaYkGAuKl97bedntpWVLc0ho0cfWYHXXZ9+apLv1Ve3v3j+ySfm+xDd3zff3L1lRpu5jnfV1ebMe80BJ0yPPGK+ix0V+A0N5nt05ZUnxq3gh6C7SUGZaU8c48eP1ytWrOjpMHpeba15ilopGhr2Ulb2KqWlr1Bd/TGgAYXHMwSvdzRe7yiSkiaSnHwmVqvnyNZbX29+jW7cOLjjjo6n2bgRvvMd84BYZmbL8H//2zzdfP/9JvYD7dxpnoDOzTWdDg4aBEodWnzbt8OcOdCvH9x5J/Tte2jzHy6tuxfr8uVwzTVmO6dOjX1c3fH55/Dqq/Dd70Jqak9HI2JEKbVSaz3+oNNJUji5hELV1NR8Rk3NMmprV1Jfv46Ghh0AKOUgOflMvN5ROBw5OBw5eL3D8HpHY7W6ezhyIUQsdTcpxM2P7MQLmy2ZtLRppKVNax4WCtVSU/MJFRXvU1X1AUVFTxMOt/5daSsezxBcrv44nbm43f1JSDiNxMTxWK2J1Nevp7b2M5Syk5FxGXZ7yrHfMCHEMSE1hTgVDtfT2LiP+vr11NWtoq7ucxob99DQsJdQqLx5OqWcaN3Y5n16+ldISZmC3Z7R9MrC4cjCbs/CYrH3xOYIIQ5CagqiS1arF49nMB7PYDIzL2szLhispLZ2JbW1ywkGy0lMHEdS0kSCwUqKi/9OSck8ysrmd7BUhcczlMTEiSQmjsPl6ofT2RutQ5SX/5uKireJRIL07n072dnXYbW6AAiH/dTVraW2dgU+3yYyMy8nNfXcY7AXhBAHkpqCOGRaRwiFKgkGywgESgkGSwkEigkECqmrW0NNzXKCweID5lIkJU0iEmmgrm41dns2CQmj8Pm20ti4B3Nx3Fz30DpAVtbXGTToERyO7GO+fUKcjKSmIGJGKQt2ezp2ezoez5B247XWBALFNDYW0NhYgNYBUlLOweHIRGtNVdUiCgp+RyBQTHLymXg8g/F6x5CYOB67PZ09ex5mz56HKSt7HZerD1ZrAkrZmxJROZFIALs9Dbs9HYfjFDyeU3G7B6OUlUCghGCwlEikAa1DgIXk5DNIS7sIhyOTcNhHbe0KGhp2Ny0jE5er3yEnn3C4gUBgH273gEOaT2tNY2MhTucpKCU914vjj9QUxHHJ59tCQcGjBIPlhMO1TYkgFZstHYvFQTBYQShUTkPDXvz+bW2ue1gsXqxWD0pZiUQaCYUqAYXbPQi/fwfQ/lfwnM4+JCZOxO3uj8XixmJxEgxW0Ni4h0CgCLd7EElJX8Ll6k9Z2auUlMwjFKoiMfF0+vT5HhkZlx/0ekpl5X/YufM+amqWkpJyLkOH/hWXq1+X82gdARSqk9tdA4FiqqqWkJZ2PjZb8sF2q4hjx8UtqUqp6cCjgBV4Smv98AHjncBzwDigHJiltd7V1TIlKYgDaR2msbEAUNjtmW1ur9VaU1e3mvLyN6mtXYXXO5KkpEl4PKcSClURDJbh831Bbe1yamo+IxDYRyTSAGgsFjdOZ18cjix8vk0Eg2UAWCwuMjIuJyFhNPv3P4Xfvw2LxY3dnoHNlobVmoDFYkcpe3N8oVAFdXVrcDpzycycxf79fwagX7/7UMpBY+NegsEKlLJhsdgJBivx+Tbj929B6xB2eyZ2exZe70iSkyfj8QylpOSfFBU9j9aN2Gwp5ObeRe/ed2K1JqB1CL//C8rK/kVZ2ZtYLHaysr5OVtZVKGWhuvojamo+w+nsTVLSl/B6R2KxdNxwYG5KKETrIA7HKdhsKZ0mqe6KRAJN+9h5RMsR3dfjSUEpZQW+AKYBBcBy4Gqt9cZW0/wPMFprfZtS6irgMq31rK6WK0lBxJp5sjOIUvbmwk9rjd+/Db//C5KTz2w+K9c6Qnn521RVLWquvYTDPrQOorX5hT2lbE23815Cr17fwmp10dCwm82bb6aq6j8AzUlF6whaB7FaE/B4huLxDMVicRIIlBAI7KeubhWBQFHTPC6ys28gI+MS9u+fS1nZvzrYGkVS0hlEIj7q6tZgzs+iNSULEGmK0dlUQEev7ZiYtQ4QClW1WaLF4sJuz8JuT8NmS0Mp2wHzOVBKEQxWNu2POqzWBKzWJLQO0di4t2kbNFZrEg5HFm73oKYHLYcTiTQSCBQRDFZgt6ficOSglJ3a2pXU1HxKILAfp7M3TmcfLBYHgUARgUAJdnsmycmTm65d+fH5vqChYWdTM6L5HCORBiIRP+FwHcFgOcFgGeFwXdN+0LhcA8jIuJSMjMtwOLIJhaoIhaoIh2sJh+sIh+ubtxU0WofROoxS1qZtTMBicTZ9jmEaGnZRX78On28TLtcAUlO/THLymYAmGKxo+kw/p65uDeFwHenpXyEz83Icjqym71eYYLCCYLCMYLAUh6MXHs/gw/hWHx9J4QzgQa31BU3vfwigtf5Fq2nea5pmqTLfrCIgU3cRlCQFcbLQOoLfv71V4Xrws2+tdVNB8zlJSV/C4Wh5Yry2djXl5W8DpnB2OHJIT7+w+XpJXd3nlJS8hNXqJjn5LJKSJtDYuJ+amk+oq1tNJBJslQRDTe9tOJ25OJ25Tdds9tPYuI9gsIxQqIJgsAKtQ+3mgzA2Wyp2ewZWq5dwuJ5QqAalLDidfXG5+qCUrSnZFeP3b6G+fiNaB5q3x2pNbPM8jdWaQGLiBFyufjQ27qOxcW9T7SUHuz2LxsY91NaupnXzoMPRq6mQ1piaiQuLxY3V6mm+pdpqTduy884AAAfESURBVGy+vlNbu5Lq6o9oKfiPnNWahMczFL//i3YJNsrp7IdSNhoatgMWnM4+Tcmous10ffr8HwMH/vKw4jgeLjT3Bva2el8AnN7ZNFrrkFKqGkgHymIYlxDHBaUsh3zWp5TC7e6P292/3bjExLEkJo7tdN6EhNEkJIxuM8ztzsPtziM7++uHFEcsRCJBGhp2YLF4cTiysFgcRCJBgsESwmEfbvcATANE58Lheurq1mC1JuJ2Dzqsbl0CgRIqKv5NJNKAzZaC1ZqMzZbYVAvwtInB/G9qX6YmUUckEmgarpprNEoptA433Z33KRaLC5stDYcjE49nOHZ7Klpr6uvXUVr6Mg0Nu7DZUpsTq3llHnYt4VCcEHcfKaVuBW4F6Hus+rIRQhxTFou93d1sFosdp7N3t5dhtXpJTp58RHE4HFnk5NxwRMvoiFJWEhPHkZg4rpPxqsPEfazF8p64QqBPq/e5TcM6nKap+SgZc8G5Da31XK31eK31+MzWHawJIYQ4qmKZFJYDg5VS/ZVSDuAq4I0DpnkDiKbkrwH/6ep6ghBCiNiKWfNR0zWC7wDvYRrdntZab1BK/RjTr/cbwF+B55VS24AKTOIQQgjRQ2J6TUFr/Q7wzgHDHmj1fwMwM5YxCCGE6D55zl4IIUQzSQpCCCGaSVIQQgjRTJKCEEKIZidcL6lKqVJg92HOnsHJ/7S0bOPJQbbx5HA8bWM/rfVBH/Q64ZLCkVBKrehO3x8nMtnGk4Ns48nhRNxGaT4SQgjRTJKCEEKIZvGWFOb2dADHgGzjyUG28eRwwm1jXF1TEEII0bV4qykIIYToQtwkBaXUdKXUFqXUNqXUnJ6O52hQSvVRSi1SSm1USm1QSn23aXiaUup9pdTWpr+pPR3rkVBKWZVSq5VSbzW976+U+rTps3yxqRfeE5pSKkWp/2/vzmLtGsMwjv8fMVZFEYQ21BSUaJU0NabBhSK4MI8R4kZiCDGFCIkLiZhCkJgqmhqqhisRJcWFmqeoC0GotOqiaoqpHhfft7fttEePnvbss9d+fsnJOWvtlZXvy7vPfvf+1l7vq7mSPpW0SNJBTYqjpMvqc/RjSXMkbdqEOEp6SNIySR937Ftt3FTcVef7oaSp3Rv54PoiKdR+0fcAM4FJwOmSJnV3VOvEn8DlticB04GL6ryuBubb3gOYX7d72SXAoo7tW4Dbbe8OLAfO78qo1q07gRds7wVMpsy3EXGUNB64GDjQ9r6Uqsmn0Yw4PgIcPWDfYHGbCexRfy4E7h2hMf4vfZEUgGnAZ7Y/d2kC+zhwQpfHNGy2l9h+t/79I+WFZDxlbrPqYbOAE7szwuGTNAE4Fnigbgs4AphbD+np+QFI2hI4nFJKHtu/2/6eBsWRUpF5s9pMawywhAbE0farlLL/nQaL2wnAoy7eAMZJ2mFkRjp0/ZIUVtcveug9/nqApInA/sBCYHvbS+pDS4HtuzSsdeEO4Ergr7q9DfC97T/rdhNiuQvwHfBwXSZ7QNLmNCSOtr8BbgW+oiSDFcA7NC+OLYPFrSdeh/olKTSapLHA08Cltn/ofKx2suvJr5hJOg5YZvudbo9lPdsQmArca3t/4GcGLBX1eBy3orxL3gXYEdicVZdcGqkX49YvSWEo/aJ7kqSNKAlhtu15dfe3rY+l9feybo1vmA4Bjpf0JWXJ7wjK2vu4ugwBzYjlYmCx7YV1ey4lSTQljkcBX9j+zvYfwDxKbJsWx5bB4tYTr0P9khSG0i+659T19QeBRbZv63ios/f1ucBzIz22dcH2NbYn2J5IidnLts8EXqH09IYenl+L7aXA15L2rLuOBD6hIXGkLBtNlzSmPmdb82tUHDsMFrfngXPqt5CmAys6lplGjb65eU3SMZT16Va/6Ju7PKRhk3Qo8BrwEf+suV9Lua7wJLATpaLsKbYHXgzrKZJmAFfYPk7SrpRPDlsD7wFn2f6tm+MbLklTKBfTNwY+B86jvGlrRBwl3QicSvnG3HvABZT19J6Oo6Q5wAxKNdRvgRuAZ1lN3GpCvJuydPYLcJ7tt7sx7v/SN0khIiLWrF+WjyIiYgiSFCIioi1JISIi2pIUIiKiLUkhIiLakhQiRpCkGa1qrxGjUZJCRES0JSlErIaksyS9Kel9SffXng4/Sbq99gWYL2nbeuwUSW/UGvnPdNTP313SS5I+kPSupN3q6cd29E6YXW9qihgVkhQiBpC0N+Xu20NsTwFWAmdSCrm9bXsfYAHl7lWAR4GrbO9Hubu8tX82cI/tycDBlAqhUKrZXkrp7bErpQ5QxKiw4ZoPieg7RwIHAG/VN/GbUYqa/QU8UY95DJhXeyGMs72g7p8FPCVpC2C87WcAbP8KUM/3pu3Fdft9YCLw+vqfVsSaJSlErErALNvX/GundP2A49a2RkxnfZ+V5P8wRpEsH0Wsaj5wkqTtoN1zd2fK/0urqucZwOu2VwDLJR1W958NLKid8BZLOrGeYxNJY0Z0FhFrIe9QIgaw/Ymk64AXJW0A/AFcRGl+M60+toxy3QFKeeT76ot+q8IplARxv6Sb6jlOHsFpRKyVVEmNGCJJP9ke2+1xRKxPWT6KiIi2fFKIiIi2fFKIiIi2JIWIiGhLUoiIiLYkhYiIaEtSiIiItiSFiIho+xvWzqg6nr3r4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 986us/sample - loss: 0.1814 - acc: 0.9479\n",
      "Loss: 0.1813921118083556 Accuracy: 0.9478712\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8341 - acc: 0.4573\n",
      "Epoch 00001: val_loss improved from inf to 0.89645, saving model to model/checkpoint/1D_CNN_custom_DO_BN_9_conv_checkpoint/001-0.8965.hdf5\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 1.8339 - acc: 0.4573 - val_loss: 0.8965 - val_acc: 0.7508\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7684 - acc: 0.7600\n",
      "Epoch 00002: val_loss improved from 0.89645 to 0.58270, saving model to model/checkpoint/1D_CNN_custom_DO_BN_9_conv_checkpoint/002-0.5827.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.7685 - acc: 0.7600 - val_loss: 0.5827 - val_acc: 0.8185\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5246 - acc: 0.8356\n",
      "Epoch 00003: val_loss improved from 0.58270 to 0.35525, saving model to model/checkpoint/1D_CNN_custom_DO_BN_9_conv_checkpoint/003-0.3553.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.5247 - acc: 0.8356 - val_loss: 0.3553 - val_acc: 0.8908\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4065 - acc: 0.8720\n",
      "Epoch 00004: val_loss improved from 0.35525 to 0.26153, saving model to model/checkpoint/1D_CNN_custom_DO_BN_9_conv_checkpoint/004-0.2615.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.4066 - acc: 0.8719 - val_loss: 0.2615 - val_acc: 0.9283\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3391 - acc: 0.8951\n",
      "Epoch 00005: val_loss did not improve from 0.26153\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3391 - acc: 0.8952 - val_loss: 0.3052 - val_acc: 0.9075\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2869 - acc: 0.9111\n",
      "Epoch 00006: val_loss improved from 0.26153 to 0.20524, saving model to model/checkpoint/1D_CNN_custom_DO_BN_9_conv_checkpoint/006-0.2052.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2870 - acc: 0.9111 - val_loss: 0.2052 - val_acc: 0.9392\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2483 - acc: 0.9220\n",
      "Epoch 00007: val_loss improved from 0.20524 to 0.17755, saving model to model/checkpoint/1D_CNN_custom_DO_BN_9_conv_checkpoint/007-0.1775.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2483 - acc: 0.9220 - val_loss: 0.1775 - val_acc: 0.9497\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9318\n",
      "Epoch 00008: val_loss did not improve from 0.17755\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2189 - acc: 0.9318 - val_loss: 0.2230 - val_acc: 0.9355\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1912 - acc: 0.9410\n",
      "Epoch 00009: val_loss did not improve from 0.17755\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1915 - acc: 0.9410 - val_loss: 0.1865 - val_acc: 0.9481\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1881 - acc: 0.9401\n",
      "Epoch 00010: val_loss did not improve from 0.17755\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1882 - acc: 0.9400 - val_loss: 0.2233 - val_acc: 0.9352\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9480\n",
      "Epoch 00011: val_loss improved from 0.17755 to 0.16055, saving model to model/checkpoint/1D_CNN_custom_DO_BN_9_conv_checkpoint/011-0.1605.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1622 - acc: 0.9480 - val_loss: 0.1605 - val_acc: 0.9518\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9543\n",
      "Epoch 00012: val_loss improved from 0.16055 to 0.13951, saving model to model/checkpoint/1D_CNN_custom_DO_BN_9_conv_checkpoint/012-0.1395.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1450 - acc: 0.9544 - val_loss: 0.1395 - val_acc: 0.9620\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9583\n",
      "Epoch 00013: val_loss did not improve from 0.13951\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1345 - acc: 0.9583 - val_loss: 0.1542 - val_acc: 0.9522\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9614\n",
      "Epoch 00014: val_loss improved from 0.13951 to 0.13305, saving model to model/checkpoint/1D_CNN_custom_DO_BN_9_conv_checkpoint/014-0.1331.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1238 - acc: 0.9614 - val_loss: 0.1331 - val_acc: 0.9651\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9653\n",
      "Epoch 00015: val_loss did not improve from 0.13305\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1127 - acc: 0.9653 - val_loss: 0.1597 - val_acc: 0.9525\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9677\n",
      "Epoch 00016: val_loss did not improve from 0.13305\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1028 - acc: 0.9677 - val_loss: 0.1650 - val_acc: 0.9541\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9700\n",
      "Epoch 00017: val_loss did not improve from 0.13305\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0952 - acc: 0.9699 - val_loss: 0.1477 - val_acc: 0.9585\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9667\n",
      "Epoch 00018: val_loss did not improve from 0.13305\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1040 - acc: 0.9667 - val_loss: 0.1333 - val_acc: 0.9625\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9742\n",
      "Epoch 00019: val_loss did not improve from 0.13305\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0819 - acc: 0.9741 - val_loss: 0.1352 - val_acc: 0.9620\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9749\n",
      "Epoch 00020: val_loss did not improve from 0.13305\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0809 - acc: 0.9748 - val_loss: 0.1498 - val_acc: 0.9588\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9768\n",
      "Epoch 00021: val_loss improved from 0.13305 to 0.11981, saving model to model/checkpoint/1D_CNN_custom_DO_BN_9_conv_checkpoint/021-0.1198.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0723 - acc: 0.9768 - val_loss: 0.1198 - val_acc: 0.9644\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9798\n",
      "Epoch 00022: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0645 - acc: 0.9798 - val_loss: 0.1317 - val_acc: 0.9627\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9804\n",
      "Epoch 00023: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0638 - acc: 0.9804 - val_loss: 0.1397 - val_acc: 0.9613\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9810\n",
      "Epoch 00024: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0616 - acc: 0.9810 - val_loss: 0.1532 - val_acc: 0.9564\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9837\n",
      "Epoch 00025: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0536 - acc: 0.9837 - val_loss: 0.1564 - val_acc: 0.9583\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9818\n",
      "Epoch 00026: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0606 - acc: 0.9818 - val_loss: 0.1390 - val_acc: 0.9597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9853\n",
      "Epoch 00027: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0473 - acc: 0.9853 - val_loss: 0.1522 - val_acc: 0.9555\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9872\n",
      "Epoch 00028: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0425 - acc: 0.9872 - val_loss: 0.1389 - val_acc: 0.9639\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9875\n",
      "Epoch 00029: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0415 - acc: 0.9875 - val_loss: 0.1412 - val_acc: 0.9630\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9867\n",
      "Epoch 00030: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0424 - acc: 0.9867 - val_loss: 0.1374 - val_acc: 0.9641\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9885\n",
      "Epoch 00031: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0379 - acc: 0.9885 - val_loss: 0.1762 - val_acc: 0.9567\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9890\n",
      "Epoch 00032: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0382 - acc: 0.9891 - val_loss: 0.1517 - val_acc: 0.9583\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9900\n",
      "Epoch 00033: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0335 - acc: 0.9900 - val_loss: 0.1639 - val_acc: 0.9550\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9893\n",
      "Epoch 00034: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0356 - acc: 0.9893 - val_loss: 0.1680 - val_acc: 0.9574\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9907\n",
      "Epoch 00035: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0304 - acc: 0.9907 - val_loss: 0.1496 - val_acc: 0.9613\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9921\n",
      "Epoch 00036: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0281 - acc: 0.9921 - val_loss: 0.1633 - val_acc: 0.9590\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9899\n",
      "Epoch 00037: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0315 - acc: 0.9899 - val_loss: 0.1907 - val_acc: 0.9557\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9924\n",
      "Epoch 00038: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0268 - acc: 0.9924 - val_loss: 0.1569 - val_acc: 0.9604\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9926\n",
      "Epoch 00039: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0248 - acc: 0.9926 - val_loss: 0.1441 - val_acc: 0.9667\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9921\n",
      "Epoch 00040: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0266 - acc: 0.9921 - val_loss: 0.1278 - val_acc: 0.9667\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9926\n",
      "Epoch 00041: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0251 - acc: 0.9926 - val_loss: 0.1655 - val_acc: 0.9597\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9938\n",
      "Epoch 00042: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0217 - acc: 0.9938 - val_loss: 0.1425 - val_acc: 0.9639\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9947\n",
      "Epoch 00043: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0192 - acc: 0.9947 - val_loss: 0.1975 - val_acc: 0.9581\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9928\n",
      "Epoch 00044: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0228 - acc: 0.9928 - val_loss: 0.1476 - val_acc: 0.9632\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9931\n",
      "Epoch 00045: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0221 - acc: 0.9931 - val_loss: 0.1424 - val_acc: 0.9639\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9948\n",
      "Epoch 00046: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0185 - acc: 0.9948 - val_loss: 0.1653 - val_acc: 0.9588\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9933\n",
      "Epoch 00047: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0224 - acc: 0.9933 - val_loss: 0.1601 - val_acc: 0.9637\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9940\n",
      "Epoch 00048: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0194 - acc: 0.9940 - val_loss: 0.1708 - val_acc: 0.9611\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9937\n",
      "Epoch 00049: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0222 - acc: 0.9937 - val_loss: 0.1427 - val_acc: 0.9641\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9951\n",
      "Epoch 00050: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0166 - acc: 0.9951 - val_loss: 0.1745 - val_acc: 0.9588\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9950\n",
      "Epoch 00051: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0165 - acc: 0.9950 - val_loss: 0.1608 - val_acc: 0.9595\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9944\n",
      "Epoch 00052: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0195 - acc: 0.9943 - val_loss: 0.1571 - val_acc: 0.9613\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9927\n",
      "Epoch 00053: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0239 - acc: 0.9927 - val_loss: 0.1365 - val_acc: 0.9683\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9923\n",
      "Epoch 00054: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0254 - acc: 0.9923 - val_loss: 0.1753 - val_acc: 0.9578\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9977\n",
      "Epoch 00055: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0098 - acc: 0.9977 - val_loss: 0.1367 - val_acc: 0.9669\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9958\n",
      "Epoch 00056: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0143 - acc: 0.9958 - val_loss: 0.2036 - val_acc: 0.9562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9961\n",
      "Epoch 00057: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0135 - acc: 0.9961 - val_loss: 0.1628 - val_acc: 0.9623\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9951\n",
      "Epoch 00058: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0155 - acc: 0.9951 - val_loss: 0.1742 - val_acc: 0.9609\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9960\n",
      "Epoch 00059: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0129 - acc: 0.9960 - val_loss: 0.1680 - val_acc: 0.9655\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9925\n",
      "Epoch 00060: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0233 - acc: 0.9925 - val_loss: 0.1414 - val_acc: 0.9648\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9924\n",
      "Epoch 00061: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0265 - acc: 0.9924 - val_loss: 0.1609 - val_acc: 0.9690\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9944\n",
      "Epoch 00062: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0199 - acc: 0.9944 - val_loss: 0.1415 - val_acc: 0.9660\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9973\n",
      "Epoch 00063: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0096 - acc: 0.9973 - val_loss: 0.1558 - val_acc: 0.9637\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9969\n",
      "Epoch 00064: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0108 - acc: 0.9969 - val_loss: 0.1645 - val_acc: 0.9639\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9966\n",
      "Epoch 00065: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0118 - acc: 0.9966 - val_loss: 0.1553 - val_acc: 0.9658\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9956\n",
      "Epoch 00066: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0149 - acc: 0.9956 - val_loss: 0.1354 - val_acc: 0.9683\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9979\n",
      "Epoch 00067: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0074 - acc: 0.9979 - val_loss: 0.1553 - val_acc: 0.9662\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9964\n",
      "Epoch 00068: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0124 - acc: 0.9964 - val_loss: 0.1594 - val_acc: 0.9637\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9963\n",
      "Epoch 00069: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0118 - acc: 0.9963 - val_loss: 0.2283 - val_acc: 0.9539\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9962\n",
      "Epoch 00070: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0130 - acc: 0.9962 - val_loss: 0.1428 - val_acc: 0.9669\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9974\n",
      "Epoch 00071: val_loss did not improve from 0.11981\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0098 - acc: 0.9974 - val_loss: 0.1782 - val_acc: 0.9597\n",
      "\n",
      "1D_CNN_custom_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1748 - acc: 0.9466\n",
      "Loss: 0.17480578318215048 Accuracy: 0.9466251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 559us/sample - loss: 2.3054 - acc: 0.2748\n",
      "Loss: 2.3053826310305334 Accuracy: 0.27476636\n",
      "\n",
      "1D_CNN_custom_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 871us/sample - loss: 2.7925 - acc: 0.3780\n",
      "Loss: 2.7925413291154744 Accuracy: 0.37798545\n",
      "\n",
      "1D_CNN_custom_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 962us/sample - loss: 1.5907 - acc: 0.5034\n",
      "Loss: 1.590732184525962 Accuracy: 0.5034268\n",
      "\n",
      "1D_CNN_custom_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 995us/sample - loss: 0.9833 - acc: 0.7188\n",
      "Loss: 0.983314494131015 Accuracy: 0.7187954\n",
      "\n",
      "1D_CNN_custom_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.7455 - acc: 0.7836\n",
      "Loss: 0.7454629350426536 Accuracy: 0.78359294\n",
      "\n",
      "1D_CNN_custom_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4158 - acc: 0.8831\n",
      "Loss: 0.41578495934497284 Accuracy: 0.88307375\n",
      "\n",
      "1D_CNN_custom_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2449 - acc: 0.9304\n",
      "Loss: 0.24487037120207075 Accuracy: 0.93042576\n",
      "\n",
      "1D_CNN_custom_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1814 - acc: 0.9479\n",
      "Loss: 0.1813921118083556 Accuracy: 0.9478712\n",
      "\n",
      "1D_CNN_custom_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1748 - acc: 0.9466\n",
      "Loss: 0.17480578318215048 Accuracy: 0.9466251\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 732us/sample - loss: 7.2961 - acc: 0.2831\n",
      "Loss: 7.296111360789583 Accuracy: 0.28307372\n",
      "\n",
      "1D_CNN_custom_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 5.5077 - acc: 0.3614\n",
      "Loss: 5.507693571663101 Accuracy: 0.3613707\n",
      "\n",
      "1D_CNN_custom_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.7513 - acc: 0.5726\n",
      "Loss: 2.751322233491226 Accuracy: 0.57258564\n",
      "\n",
      "1D_CNN_custom_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.2914 - acc: 0.7333\n",
      "Loss: 1.2914326360292523 Accuracy: 0.73333335\n",
      "\n",
      "1D_CNN_custom_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.8377 - acc: 0.8073\n",
      "Loss: 0.8377053605928352 Accuracy: 0.807269\n",
      "\n",
      "1D_CNN_custom_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4885 - acc: 0.8818\n",
      "Loss: 0.4884930573086625 Accuracy: 0.8818276\n",
      "\n",
      "1D_CNN_custom_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2894 - acc: 0.9302\n",
      "Loss: 0.28940941195621667 Accuracy: 0.93021804\n",
      "\n",
      "1D_CNN_custom_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2658 - acc: 0.9458\n",
      "Loss: 0.2657522783880649 Accuracy: 0.9457944\n",
      "\n",
      "1D_CNN_custom_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2345 - acc: 0.9470\n",
      "Loss: 0.23451349686827366 Accuracy: 0.9470405\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
