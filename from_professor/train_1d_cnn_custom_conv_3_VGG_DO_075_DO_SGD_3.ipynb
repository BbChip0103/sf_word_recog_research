{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_DO_075_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                      activation='relu', input_shape=input_shape)) \n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                  activation='relu')) \n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))         \n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.75))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,498,320\n",
      "Trainable params: 5,498,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_075_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7511 - acc: 0.0767\n",
      "Epoch 00001: val_loss improved from inf to 2.73078, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/001-2.7308.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 2.7511 - acc: 0.0767 - val_loss: 2.7308 - val_acc: 0.0785\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7290 - acc: 0.0791\n",
      "Epoch 00002: val_loss improved from 2.73078 to 2.72060, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/002-2.7206.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7289 - acc: 0.0791 - val_loss: 2.7206 - val_acc: 0.0785\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7253 - acc: 0.0800\n",
      "Epoch 00003: val_loss improved from 2.72060 to 2.71949, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/003-2.7195.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7254 - acc: 0.0800 - val_loss: 2.7195 - val_acc: 0.0820\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7244 - acc: 0.0785\n",
      "Epoch 00004: val_loss improved from 2.71949 to 2.71912, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/004-2.7191.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7244 - acc: 0.0786 - val_loss: 2.7191 - val_acc: 0.0820\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7230 - acc: 0.0792\n",
      "Epoch 00005: val_loss improved from 2.71912 to 2.71864, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/005-2.7186.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7230 - acc: 0.0792 - val_loss: 2.7186 - val_acc: 0.0820\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7232 - acc: 0.0805\n",
      "Epoch 00006: val_loss improved from 2.71864 to 2.71839, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/006-2.7184.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7233 - acc: 0.0805 - val_loss: 2.7184 - val_acc: 0.0892\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7213 - acc: 0.0819\n",
      "Epoch 00007: val_loss improved from 2.71839 to 2.71732, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/007-2.7173.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7213 - acc: 0.0819 - val_loss: 2.7173 - val_acc: 0.0820\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7196 - acc: 0.0832\n",
      "Epoch 00008: val_loss improved from 2.71732 to 2.71474, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/008-2.7147.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7196 - acc: 0.0832 - val_loss: 2.7147 - val_acc: 0.0901\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7165 - acc: 0.0892\n",
      "Epoch 00009: val_loss improved from 2.71474 to 2.70823, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/009-2.7082.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7165 - acc: 0.0892 - val_loss: 2.7082 - val_acc: 0.1258\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7044 - acc: 0.1075\n",
      "Epoch 00010: val_loss improved from 2.70823 to 2.68331, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/010-2.6833.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7044 - acc: 0.1075 - val_loss: 2.6833 - val_acc: 0.1624\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6709 - acc: 0.1308\n",
      "Epoch 00011: val_loss improved from 2.68331 to 2.60883, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/011-2.6088.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.6709 - acc: 0.1307 - val_loss: 2.6088 - val_acc: 0.1854\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6151 - acc: 0.1539\n",
      "Epoch 00012: val_loss improved from 2.60883 to 2.51602, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/012-2.5160.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.6150 - acc: 0.1539 - val_loss: 2.5160 - val_acc: 0.1898\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5505 - acc: 0.1734\n",
      "Epoch 00013: val_loss improved from 2.51602 to 2.49631, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/013-2.4963.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.5505 - acc: 0.1734 - val_loss: 2.4963 - val_acc: 0.1901\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4983 - acc: 0.1800\n",
      "Epoch 00014: val_loss improved from 2.49631 to 2.41027, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/014-2.4103.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.4983 - acc: 0.1800 - val_loss: 2.4103 - val_acc: 0.2183\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4404 - acc: 0.1977\n",
      "Epoch 00015: val_loss did not improve from 2.41027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.4404 - acc: 0.1977 - val_loss: 3.1474 - val_acc: 0.1053\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3138 - acc: 0.2442\n",
      "Epoch 00016: val_loss improved from 2.41027 to 2.05243, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/016-2.0524.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.3139 - acc: 0.2442 - val_loss: 2.0524 - val_acc: 0.3557\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0545 - acc: 0.3298\n",
      "Epoch 00017: val_loss improved from 2.05243 to 1.85984, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/017-1.8598.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.0545 - acc: 0.3298 - val_loss: 1.8598 - val_acc: 0.3797\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7846 - acc: 0.4116\n",
      "Epoch 00018: val_loss improved from 1.85984 to 1.43933, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/018-1.4393.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.7845 - acc: 0.4115 - val_loss: 1.4393 - val_acc: 0.5318\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5357 - acc: 0.4971\n",
      "Epoch 00019: val_loss improved from 1.43933 to 1.21024, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/019-1.2102.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.5358 - acc: 0.4971 - val_loss: 1.2102 - val_acc: 0.6320\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3454 - acc: 0.5564\n",
      "Epoch 00020: val_loss improved from 1.21024 to 1.09670, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/020-1.0967.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.3452 - acc: 0.5564 - val_loss: 1.0967 - val_acc: 0.6592\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1969 - acc: 0.6045\n",
      "Epoch 00021: val_loss improved from 1.09670 to 0.91507, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/021-0.9151.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.1968 - acc: 0.6046 - val_loss: 0.9151 - val_acc: 0.7074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0875 - acc: 0.6437\n",
      "Epoch 00022: val_loss did not improve from 0.91507\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.0875 - acc: 0.6437 - val_loss: 1.0796 - val_acc: 0.6662\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9872 - acc: 0.6765\n",
      "Epoch 00023: val_loss did not improve from 0.91507\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9872 - acc: 0.6765 - val_loss: 1.5621 - val_acc: 0.5551\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9151 - acc: 0.7011\n",
      "Epoch 00024: val_loss improved from 0.91507 to 0.65783, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/024-0.6578.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9152 - acc: 0.7011 - val_loss: 0.6578 - val_acc: 0.7969\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8289 - acc: 0.7303\n",
      "Epoch 00025: val_loss did not improve from 0.65783\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8290 - acc: 0.7303 - val_loss: 0.9388 - val_acc: 0.7023\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7646 - acc: 0.7520\n",
      "Epoch 00026: val_loss improved from 0.65783 to 0.50200, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/026-0.5020.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7646 - acc: 0.7520 - val_loss: 0.5020 - val_acc: 0.8432\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7054 - acc: 0.7711\n",
      "Epoch 00027: val_loss improved from 0.50200 to 0.41576, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/027-0.4158.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7054 - acc: 0.7711 - val_loss: 0.4158 - val_acc: 0.8807\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6500 - acc: 0.7950\n",
      "Epoch 00028: val_loss did not improve from 0.41576\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6501 - acc: 0.7950 - val_loss: 0.5943 - val_acc: 0.8118\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6047 - acc: 0.8082\n",
      "Epoch 00029: val_loss improved from 0.41576 to 0.37801, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/029-0.3780.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6047 - acc: 0.8082 - val_loss: 0.3780 - val_acc: 0.8882\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5679 - acc: 0.8188\n",
      "Epoch 00030: val_loss improved from 0.37801 to 0.36974, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/030-0.3697.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5678 - acc: 0.8188 - val_loss: 0.3697 - val_acc: 0.8912\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5304 - acc: 0.8318\n",
      "Epoch 00031: val_loss improved from 0.36974 to 0.35268, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/031-0.3527.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5304 - acc: 0.8318 - val_loss: 0.3527 - val_acc: 0.8849\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5039 - acc: 0.8417\n",
      "Epoch 00032: val_loss improved from 0.35268 to 0.29775, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/032-0.2977.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5039 - acc: 0.8418 - val_loss: 0.2977 - val_acc: 0.9071\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4720 - acc: 0.8533\n",
      "Epoch 00033: val_loss improved from 0.29775 to 0.24710, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/033-0.2471.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4720 - acc: 0.8533 - val_loss: 0.2471 - val_acc: 0.9271\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4531 - acc: 0.8563\n",
      "Epoch 00034: val_loss improved from 0.24710 to 0.24287, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/034-0.2429.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4530 - acc: 0.8564 - val_loss: 0.2429 - val_acc: 0.9250\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4282 - acc: 0.8644\n",
      "Epoch 00035: val_loss did not improve from 0.24287\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4282 - acc: 0.8644 - val_loss: 0.2444 - val_acc: 0.9294\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4131 - acc: 0.8711\n",
      "Epoch 00036: val_loss did not improve from 0.24287\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4131 - acc: 0.8712 - val_loss: 0.3337 - val_acc: 0.8963\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3972 - acc: 0.8764\n",
      "Epoch 00037: val_loss improved from 0.24287 to 0.21306, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/037-0.2131.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3972 - acc: 0.8764 - val_loss: 0.2131 - val_acc: 0.9392\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3865 - acc: 0.8799\n",
      "Epoch 00038: val_loss did not improve from 0.21306\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3866 - acc: 0.8799 - val_loss: 0.2473 - val_acc: 0.9280\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3641 - acc: 0.8862\n",
      "Epoch 00039: val_loss improved from 0.21306 to 0.18659, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/039-0.1866.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3641 - acc: 0.8862 - val_loss: 0.1866 - val_acc: 0.9441\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3478 - acc: 0.8910\n",
      "Epoch 00040: val_loss did not improve from 0.18659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3477 - acc: 0.8910 - val_loss: 0.1921 - val_acc: 0.9450\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3346 - acc: 0.8958\n",
      "Epoch 00041: val_loss improved from 0.18659 to 0.16855, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/041-0.1686.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3346 - acc: 0.8958 - val_loss: 0.1686 - val_acc: 0.9509\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3259 - acc: 0.9004\n",
      "Epoch 00042: val_loss did not improve from 0.16855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3260 - acc: 0.9003 - val_loss: 0.1883 - val_acc: 0.9450\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3218 - acc: 0.9008\n",
      "Epoch 00043: val_loss did not improve from 0.16855\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3218 - acc: 0.9008 - val_loss: 0.1791 - val_acc: 0.9488\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3049 - acc: 0.9049\n",
      "Epoch 00044: val_loss did not improve from 0.16855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3049 - acc: 0.9049 - val_loss: 0.2497 - val_acc: 0.9208\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2925 - acc: 0.9092\n",
      "Epoch 00045: val_loss did not improve from 0.16855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2925 - acc: 0.9092 - val_loss: 0.1732 - val_acc: 0.9448\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2828 - acc: 0.9112\n",
      "Epoch 00046: val_loss did not improve from 0.16855\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2828 - acc: 0.9112 - val_loss: 0.1809 - val_acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2803 - acc: 0.9126\n",
      "Epoch 00047: val_loss did not improve from 0.16855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2804 - acc: 0.9126 - val_loss: 0.2588 - val_acc: 0.9264\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2718 - acc: 0.9152\n",
      "Epoch 00048: val_loss improved from 0.16855 to 0.15526, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/048-0.1553.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2719 - acc: 0.9151 - val_loss: 0.1553 - val_acc: 0.9513\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2597 - acc: 0.9190\n",
      "Epoch 00049: val_loss improved from 0.15526 to 0.14968, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/049-0.1497.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2597 - acc: 0.9191 - val_loss: 0.1497 - val_acc: 0.9548\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2539 - acc: 0.9210\n",
      "Epoch 00050: val_loss did not improve from 0.14968\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2539 - acc: 0.9210 - val_loss: 0.1504 - val_acc: 0.9574\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2438 - acc: 0.9236\n",
      "Epoch 00051: val_loss did not improve from 0.14968\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2438 - acc: 0.9236 - val_loss: 0.1581 - val_acc: 0.9560\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2371 - acc: 0.9256\n",
      "Epoch 00052: val_loss did not improve from 0.14968\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2371 - acc: 0.9256 - val_loss: 0.1584 - val_acc: 0.9511\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2341 - acc: 0.9248\n",
      "Epoch 00053: val_loss did not improve from 0.14968\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2340 - acc: 0.9248 - val_loss: 0.1554 - val_acc: 0.9557\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2312 - acc: 0.9282\n",
      "Epoch 00054: val_loss improved from 0.14968 to 0.14048, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/054-0.1405.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2312 - acc: 0.9282 - val_loss: 0.1405 - val_acc: 0.9602\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9307\n",
      "Epoch 00055: val_loss improved from 0.14048 to 0.13218, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/055-0.1322.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2189 - acc: 0.9307 - val_loss: 0.1322 - val_acc: 0.9627\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2134 - acc: 0.9335\n",
      "Epoch 00056: val_loss did not improve from 0.13218\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2135 - acc: 0.9335 - val_loss: 0.1789 - val_acc: 0.9474\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2123 - acc: 0.9333\n",
      "Epoch 00057: val_loss did not improve from 0.13218\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2125 - acc: 0.9333 - val_loss: 0.1558 - val_acc: 0.9555\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2137 - acc: 0.9332\n",
      "Epoch 00058: val_loss did not improve from 0.13218\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2137 - acc: 0.9332 - val_loss: 0.1339 - val_acc: 0.9630\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2050 - acc: 0.9352\n",
      "Epoch 00059: val_loss did not improve from 0.13218\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2050 - acc: 0.9352 - val_loss: 0.1359 - val_acc: 0.9609\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9373\n",
      "Epoch 00060: val_loss improved from 0.13218 to 0.12593, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/060-0.1259.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1980 - acc: 0.9373 - val_loss: 0.1259 - val_acc: 0.9641\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1916 - acc: 0.9385\n",
      "Epoch 00061: val_loss improved from 0.12593 to 0.11707, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/061-0.1171.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1916 - acc: 0.9385 - val_loss: 0.1171 - val_acc: 0.9665\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1844 - acc: 0.9421\n",
      "Epoch 00062: val_loss did not improve from 0.11707\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1843 - acc: 0.9422 - val_loss: 0.1248 - val_acc: 0.9639\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9405\n",
      "Epoch 00063: val_loss did not improve from 0.11707\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1854 - acc: 0.9405 - val_loss: 0.1222 - val_acc: 0.9639\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9417\n",
      "Epoch 00064: val_loss did not improve from 0.11707\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1842 - acc: 0.9417 - val_loss: 0.1331 - val_acc: 0.9634\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9441\n",
      "Epoch 00065: val_loss did not improve from 0.11707\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1793 - acc: 0.9441 - val_loss: 0.1239 - val_acc: 0.9646\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9442\n",
      "Epoch 00066: val_loss did not improve from 0.11707\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1763 - acc: 0.9442 - val_loss: 0.1218 - val_acc: 0.9632\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1776 - acc: 0.9434\n",
      "Epoch 00067: val_loss did not improve from 0.11707\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1776 - acc: 0.9434 - val_loss: 0.1453 - val_acc: 0.9576\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9450\n",
      "Epoch 00068: val_loss improved from 0.11707 to 0.11700, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/068-0.1170.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1690 - acc: 0.9450 - val_loss: 0.1170 - val_acc: 0.9672\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9452\n",
      "Epoch 00069: val_loss did not improve from 0.11700\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1679 - acc: 0.9452 - val_loss: 0.1259 - val_acc: 0.9634\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1643 - acc: 0.9485\n",
      "Epoch 00070: val_loss improved from 0.11700 to 0.11108, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/070-0.1111.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1643 - acc: 0.9485 - val_loss: 0.1111 - val_acc: 0.9655\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9493\n",
      "Epoch 00071: val_loss did not improve from 0.11108\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1598 - acc: 0.9493 - val_loss: 0.1284 - val_acc: 0.9630\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9491\n",
      "Epoch 00072: val_loss did not improve from 0.11108\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1583 - acc: 0.9491 - val_loss: 0.1158 - val_acc: 0.9644\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9507\n",
      "Epoch 00073: val_loss did not improve from 0.11108\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1557 - acc: 0.9507 - val_loss: 0.1658 - val_acc: 0.9518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1611 - acc: 0.9477\n",
      "Epoch 00074: val_loss did not improve from 0.11108\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1612 - acc: 0.9477 - val_loss: 0.1423 - val_acc: 0.9567\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1618 - acc: 0.9484\n",
      "Epoch 00075: val_loss did not improve from 0.11108\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1618 - acc: 0.9484 - val_loss: 0.1188 - val_acc: 0.9644\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9523\n",
      "Epoch 00076: val_loss did not improve from 0.11108\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1492 - acc: 0.9523 - val_loss: 0.1139 - val_acc: 0.9641\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9534\n",
      "Epoch 00077: val_loss improved from 0.11108 to 0.11000, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/077-0.1100.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1435 - acc: 0.9534 - val_loss: 0.1100 - val_acc: 0.9702\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9522\n",
      "Epoch 00078: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1461 - acc: 0.9522 - val_loss: 0.1130 - val_acc: 0.9676\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9552\n",
      "Epoch 00079: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1405 - acc: 0.9552 - val_loss: 0.1128 - val_acc: 0.9665\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9558\n",
      "Epoch 00080: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1394 - acc: 0.9558 - val_loss: 0.1148 - val_acc: 0.9669\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9564\n",
      "Epoch 00081: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1352 - acc: 0.9564 - val_loss: 0.1152 - val_acc: 0.9660\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9577\n",
      "Epoch 00082: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1306 - acc: 0.9578 - val_loss: 0.1236 - val_acc: 0.9632\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9583\n",
      "Epoch 00083: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1309 - acc: 0.9583 - val_loss: 0.1351 - val_acc: 0.9660\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9570\n",
      "Epoch 00084: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1298 - acc: 0.9570 - val_loss: 0.1165 - val_acc: 0.9655\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9578\n",
      "Epoch 00085: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1302 - acc: 0.9578 - val_loss: 0.1171 - val_acc: 0.9658\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9586\n",
      "Epoch 00086: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1274 - acc: 0.9586 - val_loss: 0.1289 - val_acc: 0.9625\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9596\n",
      "Epoch 00087: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1232 - acc: 0.9596 - val_loss: 0.1133 - val_acc: 0.9679\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9606\n",
      "Epoch 00088: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1206 - acc: 0.9606 - val_loss: 0.1114 - val_acc: 0.9686\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9615\n",
      "Epoch 00089: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1198 - acc: 0.9615 - val_loss: 0.1221 - val_acc: 0.9644\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9603\n",
      "Epoch 00090: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1218 - acc: 0.9603 - val_loss: 0.1133 - val_acc: 0.9669\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9615\n",
      "Epoch 00091: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1195 - acc: 0.9615 - val_loss: 0.1149 - val_acc: 0.9686\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9623\n",
      "Epoch 00092: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1164 - acc: 0.9623 - val_loss: 0.1144 - val_acc: 0.9693\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9633\n",
      "Epoch 00093: val_loss did not improve from 0.11000\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1118 - acc: 0.9633 - val_loss: 0.1127 - val_acc: 0.9690\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9627\n",
      "Epoch 00094: val_loss improved from 0.11000 to 0.10915, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/094-0.1091.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1139 - acc: 0.9627 - val_loss: 0.1091 - val_acc: 0.9686\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9644\n",
      "Epoch 00095: val_loss did not improve from 0.10915\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1117 - acc: 0.9644 - val_loss: 0.1141 - val_acc: 0.9695\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9656\n",
      "Epoch 00096: val_loss did not improve from 0.10915\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1041 - acc: 0.9656 - val_loss: 0.1201 - val_acc: 0.9669\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9624\n",
      "Epoch 00097: val_loss did not improve from 0.10915\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1118 - acc: 0.9624 - val_loss: 0.1121 - val_acc: 0.9716\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9658\n",
      "Epoch 00098: val_loss improved from 0.10915 to 0.10869, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/098-0.1087.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1064 - acc: 0.9658 - val_loss: 0.1087 - val_acc: 0.9711\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9648\n",
      "Epoch 00099: val_loss did not improve from 0.10869\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1092 - acc: 0.9648 - val_loss: 0.1293 - val_acc: 0.9674\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9651\n",
      "Epoch 00100: val_loss did not improve from 0.10869\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1040 - acc: 0.9651 - val_loss: 0.1621 - val_acc: 0.9597\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9636\n",
      "Epoch 00101: val_loss did not improve from 0.10869\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1080 - acc: 0.9636 - val_loss: 0.1197 - val_acc: 0.9688\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9667\n",
      "Epoch 00102: val_loss improved from 0.10869 to 0.10350, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/102-0.1035.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1028 - acc: 0.9667 - val_loss: 0.1035 - val_acc: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9674\n",
      "Epoch 00103: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0991 - acc: 0.9675 - val_loss: 0.1217 - val_acc: 0.9681\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9683\n",
      "Epoch 00104: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0970 - acc: 0.9683 - val_loss: 0.1317 - val_acc: 0.9653\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9698\n",
      "Epoch 00105: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0956 - acc: 0.9698 - val_loss: 0.1205 - val_acc: 0.9690\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9679\n",
      "Epoch 00106: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0969 - acc: 0.9679 - val_loss: 0.1187 - val_acc: 0.9697\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9692\n",
      "Epoch 00107: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0931 - acc: 0.9692 - val_loss: 0.1227 - val_acc: 0.9690\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9694\n",
      "Epoch 00108: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0939 - acc: 0.9694 - val_loss: 0.1247 - val_acc: 0.9676\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0903 - acc: 0.9708\n",
      "Epoch 00109: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0904 - acc: 0.9707 - val_loss: 0.1266 - val_acc: 0.9634\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9689\n",
      "Epoch 00110: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0951 - acc: 0.9689 - val_loss: 0.1120 - val_acc: 0.9672\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9692\n",
      "Epoch 00111: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0927 - acc: 0.9692 - val_loss: 0.1125 - val_acc: 0.9690\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9715\n",
      "Epoch 00112: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0880 - acc: 0.9716 - val_loss: 0.1250 - val_acc: 0.9667\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.9717\n",
      "Epoch 00113: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0879 - acc: 0.9717 - val_loss: 0.1197 - val_acc: 0.9690\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9713\n",
      "Epoch 00114: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0871 - acc: 0.9713 - val_loss: 0.1282 - val_acc: 0.9653\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9723\n",
      "Epoch 00115: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0862 - acc: 0.9723 - val_loss: 0.1204 - val_acc: 0.9660\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9718\n",
      "Epoch 00116: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0841 - acc: 0.9718 - val_loss: 0.1150 - val_acc: 0.9695\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9723\n",
      "Epoch 00117: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0843 - acc: 0.9723 - val_loss: 0.1124 - val_acc: 0.9700\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9721\n",
      "Epoch 00118: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0851 - acc: 0.9721 - val_loss: 0.1170 - val_acc: 0.9681\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9727\n",
      "Epoch 00119: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0827 - acc: 0.9727 - val_loss: 0.1173 - val_acc: 0.9688\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9730\n",
      "Epoch 00120: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0799 - acc: 0.9730 - val_loss: 0.1214 - val_acc: 0.9660\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9730\n",
      "Epoch 00121: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0812 - acc: 0.9730 - val_loss: 0.1197 - val_acc: 0.9688\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9728\n",
      "Epoch 00122: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0807 - acc: 0.9728 - val_loss: 0.1317 - val_acc: 0.9662\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9741\n",
      "Epoch 00123: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0776 - acc: 0.9741 - val_loss: 0.1658 - val_acc: 0.9553\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9703\n",
      "Epoch 00124: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0898 - acc: 0.9703 - val_loss: 0.1239 - val_acc: 0.9695\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9756\n",
      "Epoch 00125: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0750 - acc: 0.9756 - val_loss: 0.1203 - val_acc: 0.9693\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9746\n",
      "Epoch 00126: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0791 - acc: 0.9747 - val_loss: 0.1133 - val_acc: 0.9706\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9749\n",
      "Epoch 00127: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0744 - acc: 0.9749 - val_loss: 0.1203 - val_acc: 0.9679\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9753\n",
      "Epoch 00128: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0749 - acc: 0.9753 - val_loss: 0.1111 - val_acc: 0.9695\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9760\n",
      "Epoch 00129: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0711 - acc: 0.9760 - val_loss: 0.1196 - val_acc: 0.9697\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9765\n",
      "Epoch 00130: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0724 - acc: 0.9766 - val_loss: 0.1221 - val_acc: 0.9686\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9782\n",
      "Epoch 00131: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0677 - acc: 0.9782 - val_loss: 0.1213 - val_acc: 0.9702\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9763\n",
      "Epoch 00132: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0701 - acc: 0.9763 - val_loss: 0.1231 - val_acc: 0.9679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9770\n",
      "Epoch 00133: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0697 - acc: 0.9770 - val_loss: 0.1151 - val_acc: 0.9683\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9771\n",
      "Epoch 00134: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0681 - acc: 0.9771 - val_loss: 0.1287 - val_acc: 0.9697\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9770\n",
      "Epoch 00135: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0700 - acc: 0.9770 - val_loss: 0.1262 - val_acc: 0.9700\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9783\n",
      "Epoch 00136: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0648 - acc: 0.9783 - val_loss: 0.1127 - val_acc: 0.9702\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9784\n",
      "Epoch 00137: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0667 - acc: 0.9784 - val_loss: 0.1175 - val_acc: 0.9697\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9787\n",
      "Epoch 00138: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0658 - acc: 0.9788 - val_loss: 0.1311 - val_acc: 0.9679\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9781\n",
      "Epoch 00139: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0657 - acc: 0.9781 - val_loss: 0.1270 - val_acc: 0.9702\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9781\n",
      "Epoch 00140: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0670 - acc: 0.9781 - val_loss: 0.1220 - val_acc: 0.9693\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9780\n",
      "Epoch 00141: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0650 - acc: 0.9780 - val_loss: 0.1366 - val_acc: 0.9683\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9788\n",
      "Epoch 00142: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0629 - acc: 0.9788 - val_loss: 0.1182 - val_acc: 0.9688\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9793\n",
      "Epoch 00143: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0629 - acc: 0.9794 - val_loss: 0.1264 - val_acc: 0.9690\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9795\n",
      "Epoch 00144: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0611 - acc: 0.9795 - val_loss: 0.1233 - val_acc: 0.9688\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9792\n",
      "Epoch 00145: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0634 - acc: 0.9792 - val_loss: 0.1265 - val_acc: 0.9686\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9800\n",
      "Epoch 00146: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0605 - acc: 0.9800 - val_loss: 0.1288 - val_acc: 0.9686\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9801\n",
      "Epoch 00147: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0603 - acc: 0.9801 - val_loss: 0.1186 - val_acc: 0.9693\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9790\n",
      "Epoch 00148: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0626 - acc: 0.9791 - val_loss: 0.1129 - val_acc: 0.9713\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9811\n",
      "Epoch 00149: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0591 - acc: 0.9811 - val_loss: 0.1132 - val_acc: 0.9697\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9813\n",
      "Epoch 00150: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0580 - acc: 0.9813 - val_loss: 0.1139 - val_acc: 0.9700\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9800\n",
      "Epoch 00151: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0584 - acc: 0.9800 - val_loss: 0.1268 - val_acc: 0.9716\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9811\n",
      "Epoch 00152: val_loss did not improve from 0.10350\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0579 - acc: 0.9811 - val_loss: 0.1282 - val_acc: 0.9693\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 987us/sample - loss: 0.1351 - acc: 0.9603\n",
      "Loss: 0.1350821490982704 Accuracy: 0.9603323\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7443 - acc: 0.0802\n",
      "Epoch 00001: val_loss improved from inf to 2.72510, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/001-2.7251.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 2.7444 - acc: 0.0802 - val_loss: 2.7251 - val_acc: 0.0785\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7276 - acc: 0.0796\n",
      "Epoch 00002: val_loss improved from 2.72510 to 2.72038, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/002-2.7204.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7276 - acc: 0.0796 - val_loss: 2.7204 - val_acc: 0.0785\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7260 - acc: 0.0785\n",
      "Epoch 00003: val_loss improved from 2.72038 to 2.72023, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/003-2.7202.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7260 - acc: 0.0785 - val_loss: 2.7202 - val_acc: 0.0820\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7244 - acc: 0.0810\n",
      "Epoch 00004: val_loss improved from 2.72023 to 2.71929, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/004-2.7193.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7244 - acc: 0.0810 - val_loss: 2.7193 - val_acc: 0.0785\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7236 - acc: 0.0790\n",
      "Epoch 00005: val_loss improved from 2.71929 to 2.71885, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/005-2.7189.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7236 - acc: 0.0790 - val_loss: 2.7189 - val_acc: 0.1048\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7236 - acc: 0.0803\n",
      "Epoch 00006: val_loss did not improve from 2.71885\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7236 - acc: 0.0803 - val_loss: 2.7190 - val_acc: 0.0820\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7236 - acc: 0.0793\n",
      "Epoch 00007: val_loss improved from 2.71885 to 2.71882, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/007-2.7188.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7236 - acc: 0.0793 - val_loss: 2.7188 - val_acc: 0.0820\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7228 - acc: 0.0789\n",
      "Epoch 00008: val_loss improved from 2.71882 to 2.71850, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/008-2.7185.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7228 - acc: 0.0790 - val_loss: 2.7185 - val_acc: 0.0820\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7215 - acc: 0.0810\n",
      "Epoch 00009: val_loss improved from 2.71850 to 2.71763, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/009-2.7176.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7215 - acc: 0.0809 - val_loss: 2.7176 - val_acc: 0.0822\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7206 - acc: 0.0848\n",
      "Epoch 00010: val_loss improved from 2.71763 to 2.71637, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/010-2.7164.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7207 - acc: 0.0848 - val_loss: 2.7164 - val_acc: 0.0946\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7190 - acc: 0.0883\n",
      "Epoch 00011: val_loss improved from 2.71637 to 2.71277, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/011-2.7128.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7189 - acc: 0.0882 - val_loss: 2.7128 - val_acc: 0.0881\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7126 - acc: 0.1026\n",
      "Epoch 00012: val_loss improved from 2.71277 to 2.70011, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/012-2.7001.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7126 - acc: 0.1027 - val_loss: 2.7001 - val_acc: 0.1421\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6870 - acc: 0.1310\n",
      "Epoch 00013: val_loss improved from 2.70011 to 2.63340, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/013-2.6334.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.6870 - acc: 0.1310 - val_loss: 2.6334 - val_acc: 0.1607\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6044 - acc: 0.1598\n",
      "Epoch 00014: val_loss improved from 2.63340 to 2.53142, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/014-2.5314.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.6043 - acc: 0.1599 - val_loss: 2.5314 - val_acc: 0.1787\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4927 - acc: 0.1885\n",
      "Epoch 00015: val_loss improved from 2.53142 to 2.32900, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/015-2.3290.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.4927 - acc: 0.1885 - val_loss: 2.3290 - val_acc: 0.2697\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2656 - acc: 0.2634\n",
      "Epoch 00016: val_loss improved from 2.32900 to 2.30396, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/016-2.3040.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.2657 - acc: 0.2634 - val_loss: 2.3040 - val_acc: 0.2371\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9579 - acc: 0.3607\n",
      "Epoch 00017: val_loss improved from 2.30396 to 1.69205, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/017-1.6920.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.9577 - acc: 0.3608 - val_loss: 1.6920 - val_acc: 0.4514\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5792 - acc: 0.4796\n",
      "Epoch 00018: val_loss improved from 1.69205 to 1.27592, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/018-1.2759.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.5792 - acc: 0.4796 - val_loss: 1.2759 - val_acc: 0.5851\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3392 - acc: 0.5601\n",
      "Epoch 00019: val_loss improved from 1.27592 to 1.20402, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/019-1.2040.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.3394 - acc: 0.5601 - val_loss: 1.2040 - val_acc: 0.6268\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1670 - acc: 0.6187\n",
      "Epoch 00020: val_loss did not improve from 1.20402\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.1671 - acc: 0.6187 - val_loss: 1.2934 - val_acc: 0.6073\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0290 - acc: 0.6686\n",
      "Epoch 00021: val_loss improved from 1.20402 to 1.04118, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/021-1.0412.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.0291 - acc: 0.6686 - val_loss: 1.0412 - val_acc: 0.6564\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9309 - acc: 0.7005\n",
      "Epoch 00022: val_loss improved from 1.04118 to 0.66901, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/022-0.6690.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9308 - acc: 0.7006 - val_loss: 0.6690 - val_acc: 0.7852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8459 - acc: 0.7263\n",
      "Epoch 00023: val_loss did not improve from 0.66901\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8459 - acc: 0.7263 - val_loss: 0.7362 - val_acc: 0.7575\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7797 - acc: 0.7515\n",
      "Epoch 00024: val_loss did not improve from 0.66901\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7796 - acc: 0.7516 - val_loss: 0.8358 - val_acc: 0.7277\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7343 - acc: 0.7638\n",
      "Epoch 00025: val_loss improved from 0.66901 to 0.59435, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/025-0.5944.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7342 - acc: 0.7639 - val_loss: 0.5944 - val_acc: 0.8029\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6808 - acc: 0.7828\n",
      "Epoch 00026: val_loss improved from 0.59435 to 0.56382, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/026-0.5638.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6808 - acc: 0.7828 - val_loss: 0.5638 - val_acc: 0.8139\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6370 - acc: 0.7977\n",
      "Epoch 00027: val_loss improved from 0.56382 to 0.47603, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/027-0.4760.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6369 - acc: 0.7978 - val_loss: 0.4760 - val_acc: 0.8451\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5872 - acc: 0.8152\n",
      "Epoch 00028: val_loss did not improve from 0.47603\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5872 - acc: 0.8152 - val_loss: 0.4882 - val_acc: 0.8386\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5371 - acc: 0.8301\n",
      "Epoch 00029: val_loss did not improve from 0.47603\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5371 - acc: 0.8301 - val_loss: 0.8914 - val_acc: 0.7202\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5021 - acc: 0.8439\n",
      "Epoch 00030: val_loss improved from 0.47603 to 0.40917, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/030-0.4092.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5020 - acc: 0.8440 - val_loss: 0.4092 - val_acc: 0.8728\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4548 - acc: 0.8576\n",
      "Epoch 00031: val_loss did not improve from 0.40917\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4547 - acc: 0.8575 - val_loss: 1.0280 - val_acc: 0.7119\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4146 - acc: 0.8713\n",
      "Epoch 00032: val_loss did not improve from 0.40917\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4147 - acc: 0.8713 - val_loss: 0.5834 - val_acc: 0.8153\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3801 - acc: 0.8818\n",
      "Epoch 00033: val_loss improved from 0.40917 to 0.30044, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/033-0.3004.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3801 - acc: 0.8818 - val_loss: 0.3004 - val_acc: 0.9038\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3426 - acc: 0.8924\n",
      "Epoch 00034: val_loss improved from 0.30044 to 0.25374, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/034-0.2537.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3425 - acc: 0.8924 - val_loss: 0.2537 - val_acc: 0.9227\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3201 - acc: 0.9009\n",
      "Epoch 00035: val_loss did not improve from 0.25374\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3201 - acc: 0.9009 - val_loss: 0.2688 - val_acc: 0.9166\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2993 - acc: 0.9068\n",
      "Epoch 00036: val_loss improved from 0.25374 to 0.21113, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/036-0.2111.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2993 - acc: 0.9068 - val_loss: 0.2111 - val_acc: 0.9352\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2734 - acc: 0.9153\n",
      "Epoch 00037: val_loss improved from 0.21113 to 0.19889, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/037-0.1989.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2734 - acc: 0.9153 - val_loss: 0.1989 - val_acc: 0.9394\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2583 - acc: 0.9206\n",
      "Epoch 00038: val_loss improved from 0.19889 to 0.19800, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/038-0.1980.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2583 - acc: 0.9206 - val_loss: 0.1980 - val_acc: 0.9408\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2453 - acc: 0.9238\n",
      "Epoch 00039: val_loss improved from 0.19800 to 0.18122, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/039-0.1812.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2453 - acc: 0.9238 - val_loss: 0.1812 - val_acc: 0.9469\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2327 - acc: 0.9276\n",
      "Epoch 00040: val_loss did not improve from 0.18122\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2327 - acc: 0.9276 - val_loss: 0.2478 - val_acc: 0.9245\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2178 - acc: 0.9319\n",
      "Epoch 00041: val_loss did not improve from 0.18122\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2177 - acc: 0.9319 - val_loss: 0.1846 - val_acc: 0.9439\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2085 - acc: 0.9348\n",
      "Epoch 00042: val_loss did not improve from 0.18122\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2085 - acc: 0.9348 - val_loss: 0.1945 - val_acc: 0.9441\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1944 - acc: 0.9384\n",
      "Epoch 00043: val_loss improved from 0.18122 to 0.17586, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/043-0.1759.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1944 - acc: 0.9384 - val_loss: 0.1759 - val_acc: 0.9488\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9419\n",
      "Epoch 00044: val_loss did not improve from 0.17586\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1842 - acc: 0.9419 - val_loss: 0.1778 - val_acc: 0.9460\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1783 - acc: 0.9448\n",
      "Epoch 00045: val_loss improved from 0.17586 to 0.16112, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/045-0.1611.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1783 - acc: 0.9448 - val_loss: 0.1611 - val_acc: 0.9509\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1695 - acc: 0.9463\n",
      "Epoch 00046: val_loss improved from 0.16112 to 0.15749, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/046-0.1575.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1695 - acc: 0.9463 - val_loss: 0.1575 - val_acc: 0.9511\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9484\n",
      "Epoch 00047: val_loss improved from 0.15749 to 0.15030, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/047-0.1503.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1620 - acc: 0.9484 - val_loss: 0.1503 - val_acc: 0.9518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1571 - acc: 0.9514\n",
      "Epoch 00048: val_loss improved from 0.15030 to 0.13541, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/048-0.1354.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1571 - acc: 0.9514 - val_loss: 0.1354 - val_acc: 0.9585\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1523 - acc: 0.9513\n",
      "Epoch 00049: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1523 - acc: 0.9513 - val_loss: 0.1474 - val_acc: 0.9569\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9529\n",
      "Epoch 00050: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1454 - acc: 0.9529 - val_loss: 0.1511 - val_acc: 0.9555\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9539\n",
      "Epoch 00051: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1421 - acc: 0.9539 - val_loss: 0.1484 - val_acc: 0.9536\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9552\n",
      "Epoch 00052: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1373 - acc: 0.9551 - val_loss: 0.1785 - val_acc: 0.9467\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9560\n",
      "Epoch 00053: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1341 - acc: 0.9560 - val_loss: 0.1721 - val_acc: 0.9550\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9591\n",
      "Epoch 00054: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1275 - acc: 0.9591 - val_loss: 0.1723 - val_acc: 0.9518\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9611\n",
      "Epoch 00055: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1221 - acc: 0.9611 - val_loss: 0.1370 - val_acc: 0.9602\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9603\n",
      "Epoch 00056: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1199 - acc: 0.9603 - val_loss: 0.1439 - val_acc: 0.9571\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9637\n",
      "Epoch 00057: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1113 - acc: 0.9637 - val_loss: 0.1746 - val_acc: 0.9539\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9641\n",
      "Epoch 00058: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1102 - acc: 0.9641 - val_loss: 0.1601 - val_acc: 0.9532\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9660\n",
      "Epoch 00059: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1059 - acc: 0.9660 - val_loss: 0.1544 - val_acc: 0.9585\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9662\n",
      "Epoch 00060: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1037 - acc: 0.9662 - val_loss: 0.1574 - val_acc: 0.9569\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9667\n",
      "Epoch 00061: val_loss did not improve from 0.13541\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1013 - acc: 0.9667 - val_loss: 0.1705 - val_acc: 0.9555\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9682\n",
      "Epoch 00062: val_loss improved from 0.13541 to 0.13412, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/062-0.1341.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0962 - acc: 0.9681 - val_loss: 0.1341 - val_acc: 0.9590\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9691\n",
      "Epoch 00063: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0934 - acc: 0.9691 - val_loss: 0.1677 - val_acc: 0.9560\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9707\n",
      "Epoch 00064: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0908 - acc: 0.9707 - val_loss: 0.1615 - val_acc: 0.9592\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9713\n",
      "Epoch 00065: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0889 - acc: 0.9713 - val_loss: 0.1512 - val_acc: 0.9599\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9699\n",
      "Epoch 00066: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0882 - acc: 0.9699 - val_loss: 0.1620 - val_acc: 0.9564\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9718\n",
      "Epoch 00067: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0842 - acc: 0.9718 - val_loss: 0.1670 - val_acc: 0.9550\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9733\n",
      "Epoch 00068: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0819 - acc: 0.9733 - val_loss: 0.1460 - val_acc: 0.9618\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9727\n",
      "Epoch 00069: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0811 - acc: 0.9727 - val_loss: 0.1576 - val_acc: 0.9574\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9739\n",
      "Epoch 00070: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0770 - acc: 0.9739 - val_loss: 0.1641 - val_acc: 0.9583\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9723\n",
      "Epoch 00071: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0831 - acc: 0.9723 - val_loss: 0.1577 - val_acc: 0.9595\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9752\n",
      "Epoch 00072: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0737 - acc: 0.9751 - val_loss: 0.1429 - val_acc: 0.9613\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9753\n",
      "Epoch 00073: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0746 - acc: 0.9753 - val_loss: 0.1437 - val_acc: 0.9613\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9764\n",
      "Epoch 00074: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0733 - acc: 0.9764 - val_loss: 0.1424 - val_acc: 0.9634\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9767\n",
      "Epoch 00075: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0713 - acc: 0.9767 - val_loss: 0.1687 - val_acc: 0.9578\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9779\n",
      "Epoch 00076: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0666 - acc: 0.9779 - val_loss: 0.1618 - val_acc: 0.9620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9785\n",
      "Epoch 00077: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0659 - acc: 0.9785 - val_loss: 0.1495 - val_acc: 0.9599\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9781\n",
      "Epoch 00078: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0652 - acc: 0.9781 - val_loss: 0.1668 - val_acc: 0.9623\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9785\n",
      "Epoch 00079: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0624 - acc: 0.9785 - val_loss: 0.1485 - val_acc: 0.9634\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9786\n",
      "Epoch 00080: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0635 - acc: 0.9786 - val_loss: 0.1755 - val_acc: 0.9616\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9799\n",
      "Epoch 00081: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0585 - acc: 0.9799 - val_loss: 0.1809 - val_acc: 0.9576\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9788\n",
      "Epoch 00082: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0635 - acc: 0.9788 - val_loss: 0.1909 - val_acc: 0.9602\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9794\n",
      "Epoch 00083: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0619 - acc: 0.9794 - val_loss: 0.1723 - val_acc: 0.9606\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9806\n",
      "Epoch 00084: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0582 - acc: 0.9806 - val_loss: 0.1628 - val_acc: 0.9630\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9816\n",
      "Epoch 00085: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0578 - acc: 0.9816 - val_loss: 0.1920 - val_acc: 0.9548\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9831\n",
      "Epoch 00086: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0521 - acc: 0.9831 - val_loss: 0.1799 - val_acc: 0.9625\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9829\n",
      "Epoch 00087: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0522 - acc: 0.9829 - val_loss: 0.1769 - val_acc: 0.9646\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9829\n",
      "Epoch 00088: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0521 - acc: 0.9829 - val_loss: 0.1953 - val_acc: 0.9604\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9810\n",
      "Epoch 00089: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0553 - acc: 0.9810 - val_loss: 0.1743 - val_acc: 0.9599\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9829\n",
      "Epoch 00090: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0504 - acc: 0.9829 - val_loss: 0.1882 - val_acc: 0.9637\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9841\n",
      "Epoch 00091: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0477 - acc: 0.9841 - val_loss: 0.1864 - val_acc: 0.9564\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9818\n",
      "Epoch 00092: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0558 - acc: 0.9818 - val_loss: 0.1816 - val_acc: 0.9634\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9845\n",
      "Epoch 00093: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0475 - acc: 0.9845 - val_loss: 0.1882 - val_acc: 0.9618\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9841\n",
      "Epoch 00094: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0471 - acc: 0.9841 - val_loss: 0.1860 - val_acc: 0.9616\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9845\n",
      "Epoch 00095: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0473 - acc: 0.9845 - val_loss: 0.1812 - val_acc: 0.9571\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9834\n",
      "Epoch 00096: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0503 - acc: 0.9834 - val_loss: 0.1728 - val_acc: 0.9658\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9848\n",
      "Epoch 00097: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0459 - acc: 0.9847 - val_loss: 0.2073 - val_acc: 0.9522\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9833\n",
      "Epoch 00098: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0528 - acc: 0.9833 - val_loss: 0.1557 - val_acc: 0.9646\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9867\n",
      "Epoch 00099: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0397 - acc: 0.9867 - val_loss: 0.1889 - val_acc: 0.9644\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9856\n",
      "Epoch 00100: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0424 - acc: 0.9856 - val_loss: 0.1724 - val_acc: 0.9641\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9848\n",
      "Epoch 00101: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0448 - acc: 0.9848 - val_loss: 0.1746 - val_acc: 0.9644\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9868\n",
      "Epoch 00102: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0400 - acc: 0.9868 - val_loss: 0.2637 - val_acc: 0.9474\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9839\n",
      "Epoch 00103: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0498 - acc: 0.9839 - val_loss: 0.1679 - val_acc: 0.9627\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9872\n",
      "Epoch 00104: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0386 - acc: 0.9872 - val_loss: 0.1782 - val_acc: 0.9639\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9873\n",
      "Epoch 00105: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0388 - acc: 0.9873 - val_loss: 0.1725 - val_acc: 0.9667\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9876\n",
      "Epoch 00106: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0378 - acc: 0.9876 - val_loss: 0.1776 - val_acc: 0.9618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9877\n",
      "Epoch 00107: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0372 - acc: 0.9877 - val_loss: 0.1875 - val_acc: 0.9639\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9883\n",
      "Epoch 00108: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0351 - acc: 0.9883 - val_loss: 0.2037 - val_acc: 0.9597\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9890\n",
      "Epoch 00109: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0362 - acc: 0.9890 - val_loss: 0.1666 - val_acc: 0.9667\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9886\n",
      "Epoch 00110: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0345 - acc: 0.9886 - val_loss: 0.2270 - val_acc: 0.9641\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9875\n",
      "Epoch 00111: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0387 - acc: 0.9875 - val_loss: 0.2213 - val_acc: 0.9616\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9877\n",
      "Epoch 00112: val_loss did not improve from 0.13412\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0375 - acc: 0.9877 - val_loss: 0.1820 - val_acc: 0.9644\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2045 - acc: 0.9421\n",
      "Loss: 0.2044540225886977 Accuracy: 0.94205606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD'\n",
    "\n",
    "for i in range(8, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_075_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=SGD(lr=0.001, momentum=0.9, decay=1e-6, nesterov=True),\n",
    "                  metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "    \n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 881us/sample - loss: 1.2714 - acc: 0.6195\n",
      "Loss: 1.2713904990833 Accuracy: 0.61952233\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 925us/sample - loss: 0.7915 - acc: 0.7801\n",
      "Loss: 0.7915258266225164 Accuracy: 0.7800623\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 988us/sample - loss: 0.5926 - acc: 0.8594\n",
      "Loss: 0.592554632711262 Accuracy: 0.8593977\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_114 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 983us/sample - loss: 2.7130 - acc: 0.0781\n",
      "Loss: 2.7129934609493365 Accuracy: 0.078089304\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_126 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 992us/sample - loss: 0.2081 - acc: 0.9475\n",
      "Loss: 0.2080932543262441 Accuracy: 0.9474559\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1351 - acc: 0.9603\n",
      "Loss: 0.1350821490982704 Accuracy: 0.9603323\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_106 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2045 - acc: 0.9421\n",
      "Loss: 0.2044540225886977 Accuracy: 0.94205606\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 937us/sample - loss: 1.5248 - acc: 0.6839\n",
      "Loss: 1.5247803859869145 Accuracy: 0.68390447\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 985us/sample - loss: 0.9413 - acc: 0.8004\n",
      "Loss: 0.9412812744902673 Accuracy: 0.8004154\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.6436 - acc: 0.8619\n",
      "Loss: 0.6436304615913027 Accuracy: 0.8618899\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_114 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 2.7131 - acc: 0.0800\n",
      "Loss: 2.713131129382679 Accuracy: 0.07995846\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_126 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2238 - acc: 0.9456\n",
      "Loss: 0.22379237889792858 Accuracy: 0.9455867\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1520 - acc: 0.9616\n",
      "Loss: 0.15201902663252276 Accuracy: 0.9615784\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_106 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2466 - acc: 0.9520\n",
      "Loss: 0.24663095375579064 Accuracy: 0.95202494\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_conv_3_VGG_DO_075_DO'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
