{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, \\\n",
    "                                    Flatten, Conv1D, MaxPooling1D, Dropout, \\\n",
    "                                    Concatenate, GlobalMaxPool1D, GlobalAvgPool1D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(conv_num=1):\n",
    "    filter_size = 64\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    layer_outputs = []\n",
    "    for i in range(conv_num):\n",
    "        x = Conv1D (kernel_size=5, filters=filter_size*(2**(i//4)), \n",
    "                          strides=1, padding='same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling1D(pool_size=3, strides=3)(x)\n",
    "        layer_outputs.append(x)    \n",
    "    \n",
    "    x = Concatenate()([GlobalAvgPool1D()(output) for output in layer_outputs[-3:]])\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 16000, 64)    384         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16000, 64)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 5333, 64)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 5333, 64)     20544       max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5333, 64)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1777, 64)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1777, 64)     20544       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1777, 64)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 592, 64)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 64)           0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 192)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 192)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           3088        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 44,560\n",
      "Trainable params: 44,560\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 16000, 64)    384         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16000, 64)    0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 5333, 64)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 5333, 64)     20544       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 5333, 64)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1777, 64)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1777, 64)     20544       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1777, 64)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 592, 64)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 592, 64)      20544       max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 592, 64)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 197, 64)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 64)           0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 64)           0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 64)           0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192)          0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 192)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           3088        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 65,104\n",
      "Trainable params: 65,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 16000, 64)    384         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16000, 64)    0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 5333, 64)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 5333, 64)     20544       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5333, 64)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1777, 64)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1777, 64)     20544       max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1777, 64)     0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 592, 64)      0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 592, 64)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 197, 64)      0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 197, 128)     0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 65, 128)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 64)           0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 64)           0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 128)          0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           global_average_pooling1d_6[0][0] \n",
      "                                                                 global_average_pooling1d_7[0][0] \n",
      "                                                                 global_average_pooling1d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           4112        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 107,216\n",
      "Trainable params: 107,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 16000, 64)    384         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16000, 64)    0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 5333, 64)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5333, 64)     0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1777, 64)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1777, 64)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 592, 64)      0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 592, 64)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 197, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 197, 128)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 65, 128)      0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 65, 128)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 21, 128)      0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 64)           0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 128)          0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 128)          0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 320)          0           global_average_pooling1d_9[0][0] \n",
      "                                                                 global_average_pooling1d_10[0][0]\n",
      "                                                                 global_average_pooling1d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 320)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           5136        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 190,288\n",
      "Trainable params: 190,288\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 16000, 64)    384         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16000, 64)    0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 5333, 64)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 5333, 64)     0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1777, 64)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1777, 64)     0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 592, 64)      0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 592, 64)      0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 197, 64)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 197, 128)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 65, 128)      0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 65, 128)      0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 21, 128)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 21, 128)      82048       max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 21, 128)      0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 7, 128)       0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 128)          0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 128)          0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 128)          0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 384)          0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_average_pooling1d_13[0][0]\n",
      "                                                                 global_average_pooling1d_14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 384)          0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           6160        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 273,360\n",
      "Trainable params: 273,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 16000, 64)    384         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16000, 64)    0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 5333, 64)     0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 5333, 64)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1777, 64)     0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1777, 64)     0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 592, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 592, 64)      0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 197, 64)      0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 197, 128)     0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 65, 128)      0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 65, 128)      0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 21, 128)      0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 21, 128)      82048       max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 21, 128)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 7, 128)       0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 7, 128)       82048       max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 128)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 2, 128)       0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 128)          0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 128)          0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 128)          0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 384)          0           global_average_pooling1d_15[0][0]\n",
      "                                                                 global_average_pooling1d_16[0][0]\n",
      "                                                                 global_average_pooling1d_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 384)          0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           6160        dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 355,408\n",
      "Trainable params: 355,408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 9):\n",
    "    model = build_cnn(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.7205 - acc: 0.1019\n",
      "Epoch 00001: val_loss improved from inf to 2.65501, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/001-2.6550.hdf5\n",
      "36805/36805 [==============================] - 32s 863us/sample - loss: 2.7205 - acc: 0.1019 - val_loss: 2.6550 - val_acc: 0.1628\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5928 - acc: 0.1740\n",
      "Epoch 00002: val_loss improved from 2.65501 to 2.44915, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/002-2.4492.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 2.5928 - acc: 0.1740 - val_loss: 2.4492 - val_acc: 0.2485\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4121 - acc: 0.2174\n",
      "Epoch 00003: val_loss improved from 2.44915 to 2.24447, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/003-2.2445.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 2.4122 - acc: 0.2174 - val_loss: 2.2445 - val_acc: 0.3138\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2832 - acc: 0.2482\n",
      "Epoch 00004: val_loss improved from 2.24447 to 2.11690, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/004-2.1169.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 2.2831 - acc: 0.2483 - val_loss: 2.1169 - val_acc: 0.3364\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1919 - acc: 0.2743\n",
      "Epoch 00005: val_loss improved from 2.11690 to 2.02944, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/005-2.0294.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 2.1919 - acc: 0.2743 - val_loss: 2.0294 - val_acc: 0.3760\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1295 - acc: 0.2946\n",
      "Epoch 00006: val_loss improved from 2.02944 to 1.96776, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/006-1.9678.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 2.1295 - acc: 0.2946 - val_loss: 1.9678 - val_acc: 0.3816\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0726 - acc: 0.3154\n",
      "Epoch 00007: val_loss improved from 1.96776 to 1.90527, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/007-1.9053.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 2.0726 - acc: 0.3154 - val_loss: 1.9053 - val_acc: 0.4191\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0279 - acc: 0.3308\n",
      "Epoch 00008: val_loss improved from 1.90527 to 1.85262, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/008-1.8526.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 2.0279 - acc: 0.3308 - val_loss: 1.8526 - val_acc: 0.4391\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9838 - acc: 0.3483\n",
      "Epoch 00009: val_loss improved from 1.85262 to 1.81059, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/009-1.8106.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.9839 - acc: 0.3482 - val_loss: 1.8106 - val_acc: 0.4486\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9375 - acc: 0.3588\n",
      "Epoch 00010: val_loss improved from 1.81059 to 1.76543, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/010-1.7654.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.9375 - acc: 0.3588 - val_loss: 1.7654 - val_acc: 0.4703\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9130 - acc: 0.3711\n",
      "Epoch 00011: val_loss improved from 1.76543 to 1.73592, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/011-1.7359.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.9129 - acc: 0.3712 - val_loss: 1.7359 - val_acc: 0.4810\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8721 - acc: 0.3871\n",
      "Epoch 00012: val_loss improved from 1.73592 to 1.69652, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/012-1.6965.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.8720 - acc: 0.3871 - val_loss: 1.6965 - val_acc: 0.4931\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8429 - acc: 0.3944\n",
      "Epoch 00013: val_loss improved from 1.69652 to 1.66643, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/013-1.6664.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.8429 - acc: 0.3944 - val_loss: 1.6664 - val_acc: 0.5013\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8183 - acc: 0.4070\n",
      "Epoch 00014: val_loss improved from 1.66643 to 1.64937, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/014-1.6494.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.8184 - acc: 0.4070 - val_loss: 1.6494 - val_acc: 0.5111\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7942 - acc: 0.4174\n",
      "Epoch 00015: val_loss improved from 1.64937 to 1.62108, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/015-1.6211.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.7942 - acc: 0.4174 - val_loss: 1.6211 - val_acc: 0.5201\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7656 - acc: 0.4273\n",
      "Epoch 00016: val_loss improved from 1.62108 to 1.58545, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/016-1.5854.hdf5\n",
      "36805/36805 [==============================] - 29s 802us/sample - loss: 1.7656 - acc: 0.4273 - val_loss: 1.5854 - val_acc: 0.5339\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7444 - acc: 0.4374\n",
      "Epoch 00017: val_loss improved from 1.58545 to 1.56320, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/017-1.5632.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.7444 - acc: 0.4374 - val_loss: 1.5632 - val_acc: 0.5397\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7230 - acc: 0.4429\n",
      "Epoch 00018: val_loss improved from 1.56320 to 1.54176, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/018-1.5418.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.7230 - acc: 0.4429 - val_loss: 1.5418 - val_acc: 0.5495\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7073 - acc: 0.4499\n",
      "Epoch 00019: val_loss improved from 1.54176 to 1.52164, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/019-1.5216.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.7073 - acc: 0.4499 - val_loss: 1.5216 - val_acc: 0.5572\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6875 - acc: 0.4599\n",
      "Epoch 00020: val_loss improved from 1.52164 to 1.49891, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/020-1.4989.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.6875 - acc: 0.4599 - val_loss: 1.4989 - val_acc: 0.5604\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6685 - acc: 0.4675\n",
      "Epoch 00021: val_loss improved from 1.49891 to 1.48174, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/021-1.4817.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.6684 - acc: 0.4676 - val_loss: 1.4817 - val_acc: 0.5639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6501 - acc: 0.4703\n",
      "Epoch 00022: val_loss improved from 1.48174 to 1.46256, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/022-1.4626.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.6505 - acc: 0.4703 - val_loss: 1.4626 - val_acc: 0.5705\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6317 - acc: 0.4779\n",
      "Epoch 00023: val_loss improved from 1.46256 to 1.45174, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/023-1.4517.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.6316 - acc: 0.4780 - val_loss: 1.4517 - val_acc: 0.5747\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6258 - acc: 0.4830\n",
      "Epoch 00024: val_loss improved from 1.45174 to 1.43599, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/024-1.4360.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.6257 - acc: 0.4831 - val_loss: 1.4360 - val_acc: 0.5807\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6113 - acc: 0.4839\n",
      "Epoch 00025: val_loss improved from 1.43599 to 1.41942, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/025-1.4194.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.6113 - acc: 0.4839 - val_loss: 1.4194 - val_acc: 0.5800\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5959 - acc: 0.4908\n",
      "Epoch 00026: val_loss improved from 1.41942 to 1.40502, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/026-1.4050.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.5960 - acc: 0.4907 - val_loss: 1.4050 - val_acc: 0.5854\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5786 - acc: 0.4975- ETA: 1s - loss: 1.57\n",
      "Epoch 00027: val_loss improved from 1.40502 to 1.39581, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/027-1.3958.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.5787 - acc: 0.4975 - val_loss: 1.3958 - val_acc: 0.5847\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5617 - acc: 0.5047\n",
      "Epoch 00028: val_loss improved from 1.39581 to 1.37917, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/028-1.3792.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.5617 - acc: 0.5047 - val_loss: 1.3792 - val_acc: 0.5917\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5544 - acc: 0.5076\n",
      "Epoch 00029: val_loss improved from 1.37917 to 1.36468, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/029-1.3647.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.5545 - acc: 0.5075 - val_loss: 1.3647 - val_acc: 0.5975\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5437 - acc: 0.5121\n",
      "Epoch 00030: val_loss improved from 1.36468 to 1.35132, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/030-1.3513.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.5437 - acc: 0.5121 - val_loss: 1.3513 - val_acc: 0.6024\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5322 - acc: 0.5160\n",
      "Epoch 00031: val_loss improved from 1.35132 to 1.34340, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/031-1.3434.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.5322 - acc: 0.5160 - val_loss: 1.3434 - val_acc: 0.6098\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5197 - acc: 0.5172\n",
      "Epoch 00032: val_loss improved from 1.34340 to 1.32346, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/032-1.3235.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.5196 - acc: 0.5172 - val_loss: 1.3235 - val_acc: 0.6138\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5104 - acc: 0.5226\n",
      "Epoch 00033: val_loss improved from 1.32346 to 1.31837, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/033-1.3184.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.5103 - acc: 0.5226 - val_loss: 1.3184 - val_acc: 0.6115\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4940 - acc: 0.5295\n",
      "Epoch 00034: val_loss improved from 1.31837 to 1.30169, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/034-1.3017.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.4940 - acc: 0.5294 - val_loss: 1.3017 - val_acc: 0.6143\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4924 - acc: 0.5297\n",
      "Epoch 00035: val_loss improved from 1.30169 to 1.28483, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/035-1.2848.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.4925 - acc: 0.5297 - val_loss: 1.2848 - val_acc: 0.6264\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4784 - acc: 0.5363\n",
      "Epoch 00036: val_loss improved from 1.28483 to 1.27558, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/036-1.2756.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.4783 - acc: 0.5364 - val_loss: 1.2756 - val_acc: 0.6273\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4677 - acc: 0.5384\n",
      "Epoch 00037: val_loss improved from 1.27558 to 1.26673, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/037-1.2667.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.4683 - acc: 0.5384 - val_loss: 1.2667 - val_acc: 0.6261\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4585 - acc: 0.5418\n",
      "Epoch 00038: val_loss improved from 1.26673 to 1.25644, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/038-1.2564.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.4585 - acc: 0.5419 - val_loss: 1.2564 - val_acc: 0.6364\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4433 - acc: 0.5451\n",
      "Epoch 00039: val_loss improved from 1.25644 to 1.25103, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/039-1.2510.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.4433 - acc: 0.5451 - val_loss: 1.2510 - val_acc: 0.6352\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4364 - acc: 0.5464\n",
      "Epoch 00040: val_loss improved from 1.25103 to 1.23426, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/040-1.2343.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.4365 - acc: 0.5464 - val_loss: 1.2343 - val_acc: 0.6382\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4259 - acc: 0.5518\n",
      "Epoch 00041: val_loss improved from 1.23426 to 1.22734, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/041-1.2273.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.4259 - acc: 0.5518 - val_loss: 1.2273 - val_acc: 0.6434\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4225 - acc: 0.5532\n",
      "Epoch 00042: val_loss improved from 1.22734 to 1.21173, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/042-1.2117.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.4225 - acc: 0.5532 - val_loss: 1.2117 - val_acc: 0.6487\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4127 - acc: 0.5588\n",
      "Epoch 00043: val_loss improved from 1.21173 to 1.20955, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/043-1.2095.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.4127 - acc: 0.5588 - val_loss: 1.2095 - val_acc: 0.6487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4028 - acc: 0.5624\n",
      "Epoch 00044: val_loss improved from 1.20955 to 1.19913, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/044-1.1991.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.4034 - acc: 0.5625 - val_loss: 1.1991 - val_acc: 0.6497\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3980 - acc: 0.5613\n",
      "Epoch 00045: val_loss improved from 1.19913 to 1.18828, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/045-1.1883.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.3980 - acc: 0.5613 - val_loss: 1.1883 - val_acc: 0.6539\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3895 - acc: 0.5640\n",
      "Epoch 00046: val_loss improved from 1.18828 to 1.18162, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/046-1.1816.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.3896 - acc: 0.5640 - val_loss: 1.1816 - val_acc: 0.6608\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3790 - acc: 0.5682\n",
      "Epoch 00047: val_loss improved from 1.18162 to 1.17389, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/047-1.1739.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.3790 - acc: 0.5682 - val_loss: 1.1739 - val_acc: 0.6606\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3737 - acc: 0.5698\n",
      "Epoch 00048: val_loss improved from 1.17389 to 1.16249, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/048-1.1625.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.3737 - acc: 0.5698 - val_loss: 1.1625 - val_acc: 0.6627\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3685 - acc: 0.5779\n",
      "Epoch 00049: val_loss improved from 1.16249 to 1.16152, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/049-1.1615.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.3685 - acc: 0.5779 - val_loss: 1.1615 - val_acc: 0.6667\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3526 - acc: 0.5806\n",
      "Epoch 00050: val_loss improved from 1.16152 to 1.15378, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/050-1.1538.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.3526 - acc: 0.5806 - val_loss: 1.1538 - val_acc: 0.6639\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3477 - acc: 0.5813\n",
      "Epoch 00051: val_loss improved from 1.15378 to 1.13883, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/051-1.1388.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.3477 - acc: 0.5813 - val_loss: 1.1388 - val_acc: 0.6713\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3438 - acc: 0.5814\n",
      "Epoch 00052: val_loss improved from 1.13883 to 1.13630, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/052-1.1363.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.3438 - acc: 0.5814 - val_loss: 1.1363 - val_acc: 0.6709\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3360 - acc: 0.5838\n",
      "Epoch 00053: val_loss improved from 1.13630 to 1.12584, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/053-1.1258.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.3358 - acc: 0.5839 - val_loss: 1.1258 - val_acc: 0.6725\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3354 - acc: 0.5865\n",
      "Epoch 00054: val_loss did not improve from 1.12584\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.3354 - acc: 0.5865 - val_loss: 1.1267 - val_acc: 0.6746\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3269 - acc: 0.5895\n",
      "Epoch 00055: val_loss improved from 1.12584 to 1.12190, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/055-1.1219.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.3269 - acc: 0.5895 - val_loss: 1.1219 - val_acc: 0.6746\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3237 - acc: 0.5890\n",
      "Epoch 00056: val_loss improved from 1.12190 to 1.10909, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/056-1.1091.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.3236 - acc: 0.5891 - val_loss: 1.1091 - val_acc: 0.6785\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3175 - acc: 0.5904\n",
      "Epoch 00057: val_loss improved from 1.10909 to 1.09944, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/057-1.0994.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.3174 - acc: 0.5904 - val_loss: 1.0994 - val_acc: 0.6867\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3120 - acc: 0.5952\n",
      "Epoch 00058: val_loss improved from 1.09944 to 1.09364, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/058-1.0936.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.3120 - acc: 0.5952 - val_loss: 1.0936 - val_acc: 0.6851\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2983 - acc: 0.5965\n",
      "Epoch 00059: val_loss did not improve from 1.09364\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.2983 - acc: 0.5965 - val_loss: 1.0938 - val_acc: 0.6827\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2978 - acc: 0.5951\n",
      "Epoch 00060: val_loss improved from 1.09364 to 1.08469, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/060-1.0847.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.2979 - acc: 0.5950 - val_loss: 1.0847 - val_acc: 0.6890\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2913 - acc: 0.5987\n",
      "Epoch 00061: val_loss improved from 1.08469 to 1.07773, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/061-1.0777.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.2914 - acc: 0.5987 - val_loss: 1.0777 - val_acc: 0.6911\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2942 - acc: 0.5989\n",
      "Epoch 00062: val_loss improved from 1.07773 to 1.07680, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/062-1.0768.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.2942 - acc: 0.5989 - val_loss: 1.0768 - val_acc: 0.6897\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2804 - acc: 0.6012\n",
      "Epoch 00063: val_loss improved from 1.07680 to 1.06638, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/063-1.0664.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.2804 - acc: 0.6012 - val_loss: 1.0664 - val_acc: 0.6935\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2766 - acc: 0.6063\n",
      "Epoch 00064: val_loss improved from 1.06638 to 1.06451, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/064-1.0645.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.2767 - acc: 0.6062 - val_loss: 1.0645 - val_acc: 0.6993\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2750 - acc: 0.6023\n",
      "Epoch 00065: val_loss improved from 1.06451 to 1.05678, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/065-1.0568.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.2751 - acc: 0.6023 - val_loss: 1.0568 - val_acc: 0.6967\n",
      "Epoch 66/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2696 - acc: 0.6074\n",
      "Epoch 00066: val_loss did not improve from 1.05678\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.2695 - acc: 0.6074 - val_loss: 1.0585 - val_acc: 0.6956\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2660 - acc: 0.6099\n",
      "Epoch 00067: val_loss improved from 1.05678 to 1.04511, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/067-1.0451.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.2661 - acc: 0.6099 - val_loss: 1.0451 - val_acc: 0.7021\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2565 - acc: 0.6113\n",
      "Epoch 00068: val_loss improved from 1.04511 to 1.04268, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/068-1.0427.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.2564 - acc: 0.6114 - val_loss: 1.0427 - val_acc: 0.7056\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2481 - acc: 0.6111\n",
      "Epoch 00069: val_loss improved from 1.04268 to 1.04258, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/069-1.0426.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.2480 - acc: 0.6112 - val_loss: 1.0426 - val_acc: 0.7049\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2495 - acc: 0.6152\n",
      "Epoch 00070: val_loss improved from 1.04258 to 1.03115, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/070-1.0312.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.2494 - acc: 0.6152 - val_loss: 1.0312 - val_acc: 0.6990\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2450 - acc: 0.6152\n",
      "Epoch 00071: val_loss improved from 1.03115 to 1.03108, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/071-1.0311.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.2450 - acc: 0.6152 - val_loss: 1.0311 - val_acc: 0.7070\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2436 - acc: 0.6157\n",
      "Epoch 00072: val_loss improved from 1.03108 to 1.02598, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/072-1.0260.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.2437 - acc: 0.6156 - val_loss: 1.0260 - val_acc: 0.7070\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2430 - acc: 0.6207\n",
      "Epoch 00073: val_loss improved from 1.02598 to 1.02047, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/073-1.0205.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.2431 - acc: 0.6206 - val_loss: 1.0205 - val_acc: 0.7065\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2325 - acc: 0.6204\n",
      "Epoch 00074: val_loss improved from 1.02047 to 1.01578, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/074-1.0158.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.2325 - acc: 0.6204 - val_loss: 1.0158 - val_acc: 0.7102\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2313 - acc: 0.6205\n",
      "Epoch 00075: val_loss improved from 1.01578 to 1.01387, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/075-1.0139.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.2312 - acc: 0.6205 - val_loss: 1.0139 - val_acc: 0.7107\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2293 - acc: 0.6233\n",
      "Epoch 00076: val_loss improved from 1.01387 to 1.01031, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/076-1.0103.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.2293 - acc: 0.6233 - val_loss: 1.0103 - val_acc: 0.7121\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2214 - acc: 0.6222\n",
      "Epoch 00077: val_loss improved from 1.01031 to 0.99603, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/077-0.9960.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.2213 - acc: 0.6222 - val_loss: 0.9960 - val_acc: 0.7179\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2188 - acc: 0.6231\n",
      "Epoch 00078: val_loss did not improve from 0.99603\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.2188 - acc: 0.6231 - val_loss: 1.0022 - val_acc: 0.7163\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2159 - acc: 0.6285\n",
      "Epoch 00079: val_loss improved from 0.99603 to 0.99184, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/079-0.9918.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.2158 - acc: 0.6286 - val_loss: 0.9918 - val_acc: 0.7198\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2112 - acc: 0.6274\n",
      "Epoch 00080: val_loss did not improve from 0.99184\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.2112 - acc: 0.6274 - val_loss: 0.9928 - val_acc: 0.7135\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2073 - acc: 0.6294- ETA: 0s - loss: 1.2067\n",
      "Epoch 00081: val_loss improved from 0.99184 to 0.99079, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/081-0.9908.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.2074 - acc: 0.6293 - val_loss: 0.9908 - val_acc: 0.7170\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2083 - acc: 0.6280\n",
      "Epoch 00082: val_loss improved from 0.99079 to 0.98498, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/082-0.9850.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.2084 - acc: 0.6280 - val_loss: 0.9850 - val_acc: 0.7261\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2028 - acc: 0.6301\n",
      "Epoch 00083: val_loss improved from 0.98498 to 0.97973, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/083-0.9797.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.2027 - acc: 0.6301 - val_loss: 0.9797 - val_acc: 0.7165\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1997 - acc: 0.6313\n",
      "Epoch 00084: val_loss did not improve from 0.97973\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.1997 - acc: 0.6313 - val_loss: 0.9851 - val_acc: 0.7158\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1924 - acc: 0.6340\n",
      "Epoch 00085: val_loss improved from 0.97973 to 0.97477, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/085-0.9748.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.1924 - acc: 0.6340 - val_loss: 0.9748 - val_acc: 0.7240\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1885 - acc: 0.6337\n",
      "Epoch 00086: val_loss improved from 0.97477 to 0.96399, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/086-0.9640.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.1885 - acc: 0.6337 - val_loss: 0.9640 - val_acc: 0.7258\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1877 - acc: 0.6382\n",
      "Epoch 00087: val_loss did not improve from 0.96399\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.1877 - acc: 0.6382 - val_loss: 0.9690 - val_acc: 0.7249\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1895 - acc: 0.6339\n",
      "Epoch 00088: val_loss improved from 0.96399 to 0.96313, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/088-0.9631.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.1894 - acc: 0.6340 - val_loss: 0.9631 - val_acc: 0.7275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1846 - acc: 0.6371\n",
      "Epoch 00089: val_loss did not improve from 0.96313\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.1845 - acc: 0.6371 - val_loss: 0.9657 - val_acc: 0.7261\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1802 - acc: 0.6398\n",
      "Epoch 00090: val_loss did not improve from 0.96313\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.1802 - acc: 0.6397 - val_loss: 0.9635 - val_acc: 0.7263\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1764 - acc: 0.6387\n",
      "Epoch 00091: val_loss improved from 0.96313 to 0.95634, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/091-0.9563.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.1764 - acc: 0.6387 - val_loss: 0.9563 - val_acc: 0.7300\n",
      "Epoch 92/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1734 - acc: 0.6396\n",
      "Epoch 00092: val_loss improved from 0.95634 to 0.95516, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/092-0.9552.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.1737 - acc: 0.6396 - val_loss: 0.9552 - val_acc: 0.7247\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1706 - acc: 0.6413\n",
      "Epoch 00093: val_loss improved from 0.95516 to 0.94701, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/093-0.9470.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.1706 - acc: 0.6413 - val_loss: 0.9470 - val_acc: 0.7319\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1625 - acc: 0.6429\n",
      "Epoch 00094: val_loss improved from 0.94701 to 0.94591, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/094-0.9459.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.1625 - acc: 0.6428 - val_loss: 0.9459 - val_acc: 0.7321\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1676 - acc: 0.6445\n",
      "Epoch 00095: val_loss improved from 0.94591 to 0.94373, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/095-0.9437.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.1675 - acc: 0.6445 - val_loss: 0.9437 - val_acc: 0.7340\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1622 - acc: 0.6433\n",
      "Epoch 00096: val_loss improved from 0.94373 to 0.93941, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/096-0.9394.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.1622 - acc: 0.6433 - val_loss: 0.9394 - val_acc: 0.7338\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1610 - acc: 0.6465\n",
      "Epoch 00097: val_loss improved from 0.93941 to 0.93390, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/097-0.9339.hdf5\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 1.1610 - acc: 0.6466 - val_loss: 0.9339 - val_acc: 0.7342\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1543 - acc: 0.6461\n",
      "Epoch 00098: val_loss improved from 0.93390 to 0.93007, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/098-0.9301.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.1542 - acc: 0.6462 - val_loss: 0.9301 - val_acc: 0.7379\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1508 - acc: 0.6451\n",
      "Epoch 00099: val_loss did not improve from 0.93007\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.1508 - acc: 0.6451 - val_loss: 0.9367 - val_acc: 0.7356\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1535 - acc: 0.6468\n",
      "Epoch 00100: val_loss did not improve from 0.93007\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.1534 - acc: 0.6468 - val_loss: 0.9313 - val_acc: 0.7363\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1451 - acc: 0.6510\n",
      "Epoch 00101: val_loss improved from 0.93007 to 0.92498, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/101-0.9250.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.1451 - acc: 0.6510 - val_loss: 0.9250 - val_acc: 0.7363\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1452 - acc: 0.6509\n",
      "Epoch 00102: val_loss improved from 0.92498 to 0.92220, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/102-0.9222.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.1452 - acc: 0.6508 - val_loss: 0.9222 - val_acc: 0.7386\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1456 - acc: 0.6488\n",
      "Epoch 00103: val_loss improved from 0.92220 to 0.91821, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/103-0.9182.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.1456 - acc: 0.6488 - val_loss: 0.9182 - val_acc: 0.7384\n",
      "Epoch 104/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1476 - acc: 0.6483\n",
      "Epoch 00104: val_loss did not improve from 0.91821\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.1480 - acc: 0.6483 - val_loss: 0.9206 - val_acc: 0.7421\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1418 - acc: 0.6553\n",
      "Epoch 00105: val_loss did not improve from 0.91821\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.1417 - acc: 0.6553 - val_loss: 0.9197 - val_acc: 0.7393\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1377 - acc: 0.6555\n",
      "Epoch 00106: val_loss improved from 0.91821 to 0.91546, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/106-0.9155.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.1378 - acc: 0.6555 - val_loss: 0.9155 - val_acc: 0.7405\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1338 - acc: 0.6545\n",
      "Epoch 00107: val_loss improved from 0.91546 to 0.91005, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/107-0.9100.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.1337 - acc: 0.6544 - val_loss: 0.9100 - val_acc: 0.7461\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1304 - acc: 0.6532\n",
      "Epoch 00108: val_loss improved from 0.91005 to 0.90943, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/108-0.9094.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.1304 - acc: 0.6531 - val_loss: 0.9094 - val_acc: 0.7438\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1351 - acc: 0.6528\n",
      "Epoch 00109: val_loss did not improve from 0.90943\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.1352 - acc: 0.6528 - val_loss: 0.9125 - val_acc: 0.7386\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1329 - acc: 0.6536\n",
      "Epoch 00110: val_loss did not improve from 0.90943\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.1329 - acc: 0.6536 - val_loss: 0.9097 - val_acc: 0.7445\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1291 - acc: 0.6539\n",
      "Epoch 00111: val_loss improved from 0.90943 to 0.90158, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/111-0.9016.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.1291 - acc: 0.6539 - val_loss: 0.9016 - val_acc: 0.7489\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1313 - acc: 0.6539\n",
      "Epoch 00112: val_loss did not improve from 0.90158\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.1313 - acc: 0.6539 - val_loss: 0.9157 - val_acc: 0.7445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1255 - acc: 0.6562\n",
      "Epoch 00113: val_loss did not improve from 0.90158\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.1255 - acc: 0.6562 - val_loss: 0.9081 - val_acc: 0.7452\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1230 - acc: 0.6582\n",
      "Epoch 00114: val_loss improved from 0.90158 to 0.89648, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/114-0.8965.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.1229 - acc: 0.6582 - val_loss: 0.8965 - val_acc: 0.7468\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1170 - acc: 0.6608\n",
      "Epoch 00115: val_loss did not improve from 0.89648\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.1170 - acc: 0.6608 - val_loss: 0.8968 - val_acc: 0.7498\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1206 - acc: 0.6617\n",
      "Epoch 00116: val_loss improved from 0.89648 to 0.88964, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/116-0.8896.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.1206 - acc: 0.6616 - val_loss: 0.8896 - val_acc: 0.7508\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1205 - acc: 0.6602\n",
      "Epoch 00117: val_loss improved from 0.88964 to 0.88636, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/117-0.8864.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.1205 - acc: 0.6602 - val_loss: 0.8864 - val_acc: 0.7559\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1144 - acc: 0.6630\n",
      "Epoch 00118: val_loss improved from 0.88636 to 0.88587, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/118-0.8859.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.1143 - acc: 0.6630 - val_loss: 0.8859 - val_acc: 0.7487\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1077 - acc: 0.6646- ETA: 2s - loss:  - ETA: 0s - loss: 1.1065 - ac\n",
      "Epoch 00119: val_loss did not improve from 0.88587\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.1076 - acc: 0.6646 - val_loss: 0.8876 - val_acc: 0.7536\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1109 - acc: 0.6617\n",
      "Epoch 00120: val_loss did not improve from 0.88587\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.1110 - acc: 0.6616 - val_loss: 0.8877 - val_acc: 0.7529\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1072 - acc: 0.6613\n",
      "Epoch 00121: val_loss improved from 0.88587 to 0.87920, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/121-0.8792.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.1075 - acc: 0.6612 - val_loss: 0.8792 - val_acc: 0.7512\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1008 - acc: 0.6652\n",
      "Epoch 00122: val_loss did not improve from 0.87920\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.1008 - acc: 0.6652 - val_loss: 0.8815 - val_acc: 0.7498\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1043 - acc: 0.6635\n",
      "Epoch 00123: val_loss did not improve from 0.87920\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.1042 - acc: 0.6635 - val_loss: 0.8817 - val_acc: 0.7503\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1023 - acc: 0.6624\n",
      "Epoch 00124: val_loss improved from 0.87920 to 0.87496, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/124-0.8750.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.1023 - acc: 0.6624 - val_loss: 0.8750 - val_acc: 0.7591\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0998 - acc: 0.6642\n",
      "Epoch 00125: val_loss improved from 0.87496 to 0.87145, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/125-0.8715.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.0998 - acc: 0.6643 - val_loss: 0.8715 - val_acc: 0.7543\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1003 - acc: 0.6650\n",
      "Epoch 00126: val_loss did not improve from 0.87145\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.1003 - acc: 0.6650 - val_loss: 0.8717 - val_acc: 0.7556\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0938 - acc: 0.6662\n",
      "Epoch 00127: val_loss improved from 0.87145 to 0.86636, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/127-0.8664.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0939 - acc: 0.6662 - val_loss: 0.8664 - val_acc: 0.7554\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0953 - acc: 0.6670\n",
      "Epoch 00128: val_loss did not improve from 0.86636\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.0953 - acc: 0.6669 - val_loss: 0.8748 - val_acc: 0.7559\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0937 - acc: 0.6668\n",
      "Epoch 00129: val_loss did not improve from 0.86636\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0937 - acc: 0.6668 - val_loss: 0.8707 - val_acc: 0.7561\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0961 - acc: 0.6683\n",
      "Epoch 00130: val_loss did not improve from 0.86636\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0959 - acc: 0.6684 - val_loss: 0.8717 - val_acc: 0.7584\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0912 - acc: 0.6692- ETA: 0s - loss: 1.0920 - acc: 0.6\n",
      "Epoch 00131: val_loss improved from 0.86636 to 0.86306, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/131-0.8631.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0912 - acc: 0.6692 - val_loss: 0.8631 - val_acc: 0.7570\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0917 - acc: 0.6709\n",
      "Epoch 00132: val_loss improved from 0.86306 to 0.86121, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/132-0.8612.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.0916 - acc: 0.6709 - val_loss: 0.8612 - val_acc: 0.7603\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0828 - acc: 0.6679\n",
      "Epoch 00133: val_loss improved from 0.86121 to 0.85826, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/133-0.8583.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0827 - acc: 0.6679 - val_loss: 0.8583 - val_acc: 0.7580\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0813 - acc: 0.6733\n",
      "Epoch 00134: val_loss improved from 0.85826 to 0.85492, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/134-0.8549.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.0813 - acc: 0.6733 - val_loss: 0.8549 - val_acc: 0.7622\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0886 - acc: 0.6732\n",
      "Epoch 00135: val_loss did not improve from 0.85492\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0886 - acc: 0.6732 - val_loss: 0.8559 - val_acc: 0.7612\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0821 - acc: 0.6713\n",
      "Epoch 00136: val_loss improved from 0.85492 to 0.85392, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/136-0.8539.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.0821 - acc: 0.6713 - val_loss: 0.8539 - val_acc: 0.7587\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0769 - acc: 0.6745\n",
      "Epoch 00137: val_loss did not improve from 0.85392\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0769 - acc: 0.6745 - val_loss: 0.8547 - val_acc: 0.7610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0767 - acc: 0.6710\n",
      "Epoch 00138: val_loss improved from 0.85392 to 0.85314, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/138-0.8531.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0767 - acc: 0.6710 - val_loss: 0.8531 - val_acc: 0.7603\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0783 - acc: 0.6720\n",
      "Epoch 00139: val_loss did not improve from 0.85314\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.0784 - acc: 0.6719 - val_loss: 0.8561 - val_acc: 0.7568\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0786 - acc: 0.6722\n",
      "Epoch 00140: val_loss improved from 0.85314 to 0.84700, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/140-0.8470.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0786 - acc: 0.6722 - val_loss: 0.8470 - val_acc: 0.7631\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0769 - acc: 0.6726\n",
      "Epoch 00141: val_loss improved from 0.84700 to 0.84664, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/141-0.8466.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0769 - acc: 0.6727 - val_loss: 0.8466 - val_acc: 0.7624\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0802 - acc: 0.6761\n",
      "Epoch 00142: val_loss did not improve from 0.84664\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.0801 - acc: 0.6761 - val_loss: 0.8476 - val_acc: 0.7622\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0693 - acc: 0.6768\n",
      "Epoch 00143: val_loss improved from 0.84664 to 0.84247, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/143-0.8425.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.0694 - acc: 0.6768 - val_loss: 0.8425 - val_acc: 0.7657\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0717 - acc: 0.6709\n",
      "Epoch 00144: val_loss improved from 0.84247 to 0.84247, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/144-0.8425.hdf5\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 1.0717 - acc: 0.6709 - val_loss: 0.8425 - val_acc: 0.7678\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0708 - acc: 0.6770\n",
      "Epoch 00145: val_loss improved from 0.84247 to 0.84038, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/145-0.8404.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.0707 - acc: 0.6770 - val_loss: 0.8404 - val_acc: 0.7671\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0681 - acc: 0.6755\n",
      "Epoch 00146: val_loss did not improve from 0.84038\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0682 - acc: 0.6755 - val_loss: 0.8465 - val_acc: 0.7629\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0695 - acc: 0.6730\n",
      "Epoch 00147: val_loss improved from 0.84038 to 0.83913, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/147-0.8391.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.0695 - acc: 0.6730 - val_loss: 0.8391 - val_acc: 0.7680\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0627 - acc: 0.6763\n",
      "Epoch 00148: val_loss did not improve from 0.83913\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0628 - acc: 0.6762 - val_loss: 0.8469 - val_acc: 0.7617\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0668 - acc: 0.6760\n",
      "Epoch 00149: val_loss improved from 0.83913 to 0.83579, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/149-0.8358.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.0668 - acc: 0.6760 - val_loss: 0.8358 - val_acc: 0.7680\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0555 - acc: 0.6801\n",
      "Epoch 00150: val_loss did not improve from 0.83579\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.0555 - acc: 0.6801 - val_loss: 0.8391 - val_acc: 0.7636\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0631 - acc: 0.6746\n",
      "Epoch 00151: val_loss improved from 0.83579 to 0.83222, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/151-0.8322.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.0633 - acc: 0.6746 - val_loss: 0.8322 - val_acc: 0.7692\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0624 - acc: 0.6784\n",
      "Epoch 00152: val_loss did not improve from 0.83222\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0624 - acc: 0.6784 - val_loss: 0.8418 - val_acc: 0.7650\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0577 - acc: 0.6777\n",
      "Epoch 00153: val_loss did not improve from 0.83222\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.0577 - acc: 0.6777 - val_loss: 0.8328 - val_acc: 0.7729\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0591 - acc: 0.6774\n",
      "Epoch 00154: val_loss improved from 0.83222 to 0.83132, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/154-0.8313.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0590 - acc: 0.6774 - val_loss: 0.8313 - val_acc: 0.7699\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0510 - acc: 0.6790\n",
      "Epoch 00155: val_loss improved from 0.83132 to 0.82330, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/155-0.8233.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.0510 - acc: 0.6789 - val_loss: 0.8233 - val_acc: 0.7706\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0584 - acc: 0.6810\n",
      "Epoch 00156: val_loss did not improve from 0.82330\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.0585 - acc: 0.6810 - val_loss: 0.8323 - val_acc: 0.7701\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0535 - acc: 0.6808\n",
      "Epoch 00157: val_loss did not improve from 0.82330\n",
      "36805/36805 [==============================] - 29s 802us/sample - loss: 1.0535 - acc: 0.6809 - val_loss: 0.8331 - val_acc: 0.7687\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0527 - acc: 0.6793\n",
      "Epoch 00158: val_loss improved from 0.82330 to 0.82292, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/158-0.8229.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0527 - acc: 0.6792 - val_loss: 0.8229 - val_acc: 0.7736\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0492 - acc: 0.6811\n",
      "Epoch 00159: val_loss improved from 0.82292 to 0.81975, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/159-0.8197.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.0493 - acc: 0.6811 - val_loss: 0.8197 - val_acc: 0.7694\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0499 - acc: 0.6821\n",
      "Epoch 00160: val_loss did not improve from 0.81975\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.0498 - acc: 0.6822 - val_loss: 0.8230 - val_acc: 0.7727\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0510 - acc: 0.6837\n",
      "Epoch 00161: val_loss improved from 0.81975 to 0.81938, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/161-0.8194.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0510 - acc: 0.6837 - val_loss: 0.8194 - val_acc: 0.7713\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0448 - acc: 0.6845\n",
      "Epoch 00162: val_loss improved from 0.81938 to 0.81553, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/162-0.8155.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0448 - acc: 0.6845 - val_loss: 0.8155 - val_acc: 0.7727\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0454 - acc: 0.6827\n",
      "Epoch 00163: val_loss did not improve from 0.81553\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0454 - acc: 0.6827 - val_loss: 0.8208 - val_acc: 0.7706\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0450 - acc: 0.6852\n",
      "Epoch 00164: val_loss did not improve from 0.81553\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0450 - acc: 0.6852 - val_loss: 0.8164 - val_acc: 0.7717\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0446 - acc: 0.6836\n",
      "Epoch 00165: val_loss did not improve from 0.81553\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.0446 - acc: 0.6836 - val_loss: 0.8232 - val_acc: 0.7685\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0382 - acc: 0.6839\n",
      "Epoch 00166: val_loss did not improve from 0.81553\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0381 - acc: 0.6839 - val_loss: 0.8228 - val_acc: 0.7685\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0373 - acc: 0.6852\n",
      "Epoch 00167: val_loss improved from 0.81553 to 0.81148, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/167-0.8115.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0373 - acc: 0.6852 - val_loss: 0.8115 - val_acc: 0.7750\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0392 - acc: 0.6848\n",
      "Epoch 00168: val_loss improved from 0.81148 to 0.80937, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/168-0.8094.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.0392 - acc: 0.6848 - val_loss: 0.8094 - val_acc: 0.7752\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0434 - acc: 0.6817\n",
      "Epoch 00169: val_loss improved from 0.80937 to 0.80850, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/169-0.8085.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.0435 - acc: 0.6817 - val_loss: 0.8085 - val_acc: 0.7717\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0391 - acc: 0.6870\n",
      "Epoch 00170: val_loss did not improve from 0.80850\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.0390 - acc: 0.6870 - val_loss: 0.8130 - val_acc: 0.7736\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0445 - acc: 0.6859\n",
      "Epoch 00171: val_loss did not improve from 0.80850\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0445 - acc: 0.6859 - val_loss: 0.8094 - val_acc: 0.7720\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0373 - acc: 0.6884\n",
      "Epoch 00172: val_loss improved from 0.80850 to 0.80677, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/172-0.8068.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0372 - acc: 0.6884 - val_loss: 0.8068 - val_acc: 0.7750\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0393 - acc: 0.6829\n",
      "Epoch 00173: val_loss did not improve from 0.80677\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0393 - acc: 0.6830 - val_loss: 0.8071 - val_acc: 0.7754\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0318 - acc: 0.6888\n",
      "Epoch 00174: val_loss did not improve from 0.80677\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0318 - acc: 0.6887 - val_loss: 0.8110 - val_acc: 0.7729\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0323 - acc: 0.6888\n",
      "Epoch 00175: val_loss did not improve from 0.80677\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0324 - acc: 0.6888 - val_loss: 0.8118 - val_acc: 0.7775\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0331 - acc: 0.6861\n",
      "Epoch 00176: val_loss improved from 0.80677 to 0.79985, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/176-0.7999.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.0331 - acc: 0.6861 - val_loss: 0.7999 - val_acc: 0.7782\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0353 - acc: 0.6893\n",
      "Epoch 00177: val_loss did not improve from 0.79985\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0353 - acc: 0.6893 - val_loss: 0.8022 - val_acc: 0.7789\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0291 - acc: 0.6894\n",
      "Epoch 00178: val_loss did not improve from 0.79985\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0291 - acc: 0.6894 - val_loss: 0.8031 - val_acc: 0.7734\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0327 - acc: 0.6882\n",
      "Epoch 00179: val_loss did not improve from 0.79985\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.0326 - acc: 0.6882 - val_loss: 0.8062 - val_acc: 0.7747\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0337 - acc: 0.6852\n",
      "Epoch 00180: val_loss did not improve from 0.79985\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0337 - acc: 0.6852 - val_loss: 0.8053 - val_acc: 0.7778\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0301 - acc: 0.6871\n",
      "Epoch 00181: val_loss improved from 0.79985 to 0.79828, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/181-0.7983.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0301 - acc: 0.6871 - val_loss: 0.7983 - val_acc: 0.7778\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0243 - acc: 0.6888\n",
      "Epoch 00182: val_loss improved from 0.79828 to 0.79706, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/182-0.7971.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0243 - acc: 0.6888 - val_loss: 0.7971 - val_acc: 0.7764\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0250 - acc: 0.6890\n",
      "Epoch 00183: val_loss did not improve from 0.79706\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0249 - acc: 0.6890 - val_loss: 0.7974 - val_acc: 0.7773\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0242 - acc: 0.6912\n",
      "Epoch 00184: val_loss improved from 0.79706 to 0.79193, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/184-0.7919.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0242 - acc: 0.6912 - val_loss: 0.7919 - val_acc: 0.7806\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0213 - acc: 0.6910\n",
      "Epoch 00185: val_loss did not improve from 0.79193\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0213 - acc: 0.6910 - val_loss: 0.7980 - val_acc: 0.7789\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0199 - acc: 0.6899\n",
      "Epoch 00186: val_loss did not improve from 0.79193\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0199 - acc: 0.6899 - val_loss: 0.7962 - val_acc: 0.7764\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0201 - acc: 0.6912\n",
      "Epoch 00187: val_loss did not improve from 0.79193\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0200 - acc: 0.6912 - val_loss: 0.7941 - val_acc: 0.7831\n",
      "Epoch 188/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0222 - acc: 0.6915\n",
      "Epoch 00188: val_loss improved from 0.79193 to 0.78929, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/188-0.7893.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.0223 - acc: 0.6915 - val_loss: 0.7893 - val_acc: 0.7857\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0165 - acc: 0.6941\n",
      "Epoch 00189: val_loss did not improve from 0.78929\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0166 - acc: 0.6941 - val_loss: 0.7966 - val_acc: 0.7794\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0194 - acc: 0.6893\n",
      "Epoch 00190: val_loss did not improve from 0.78929\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0193 - acc: 0.6893 - val_loss: 0.8026 - val_acc: 0.7780\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0217 - acc: 0.6905\n",
      "Epoch 00191: val_loss improved from 0.78929 to 0.78799, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/191-0.7880.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0216 - acc: 0.6906 - val_loss: 0.7880 - val_acc: 0.7822\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0133 - acc: 0.6949\n",
      "Epoch 00192: val_loss did not improve from 0.78799\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0134 - acc: 0.6949 - val_loss: 0.7895 - val_acc: 0.7834\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0199 - acc: 0.6907\n",
      "Epoch 00193: val_loss improved from 0.78799 to 0.78592, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/193-0.7859.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0199 - acc: 0.6907 - val_loss: 0.7859 - val_acc: 0.7848\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0203 - acc: 0.6923\n",
      "Epoch 00194: val_loss did not improve from 0.78592\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0202 - acc: 0.6923 - val_loss: 0.7926 - val_acc: 0.7785\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0155 - acc: 0.6914\n",
      "Epoch 00195: val_loss improved from 0.78592 to 0.78419, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/195-0.7842.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0155 - acc: 0.6913 - val_loss: 0.7842 - val_acc: 0.7824\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0149 - acc: 0.6921\n",
      "Epoch 00196: val_loss did not improve from 0.78419\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0150 - acc: 0.6922 - val_loss: 0.7844 - val_acc: 0.7771\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0186 - acc: 0.6913\n",
      "Epoch 00197: val_loss did not improve from 0.78419\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0187 - acc: 0.6913 - val_loss: 0.7979 - val_acc: 0.7768\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0131 - acc: 0.6929\n",
      "Epoch 00198: val_loss did not improve from 0.78419\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0131 - acc: 0.6929 - val_loss: 0.7844 - val_acc: 0.7803\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0183 - acc: 0.6927\n",
      "Epoch 00199: val_loss did not improve from 0.78419\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0183 - acc: 0.6927 - val_loss: 0.7856 - val_acc: 0.7831\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0116 - acc: 0.6965\n",
      "Epoch 00200: val_loss improved from 0.78419 to 0.78415, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/200-0.7841.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.0117 - acc: 0.6965 - val_loss: 0.7841 - val_acc: 0.7778\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0145 - acc: 0.6910\n",
      "Epoch 00201: val_loss improved from 0.78415 to 0.77829, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/201-0.7783.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0145 - acc: 0.6910 - val_loss: 0.7783 - val_acc: 0.7848\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0127 - acc: 0.6939\n",
      "Epoch 00202: val_loss did not improve from 0.77829\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0128 - acc: 0.6939 - val_loss: 0.7835 - val_acc: 0.7775\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0103 - acc: 0.6963\n",
      "Epoch 00203: val_loss did not improve from 0.77829\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0103 - acc: 0.6963 - val_loss: 0.7828 - val_acc: 0.7855\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0071 - acc: 0.6953\n",
      "Epoch 00204: val_loss improved from 0.77829 to 0.77490, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/204-0.7749.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0070 - acc: 0.6953 - val_loss: 0.7749 - val_acc: 0.7876\n",
      "Epoch 205/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0124 - acc: 0.6950\n",
      "Epoch 00205: val_loss did not improve from 0.77490\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.0118 - acc: 0.6952 - val_loss: 0.7775 - val_acc: 0.7824\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0038 - acc: 0.6967\n",
      "Epoch 00206: val_loss did not improve from 0.77490\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0039 - acc: 0.6966 - val_loss: 0.7771 - val_acc: 0.7852\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0018 - acc: 0.6984\n",
      "Epoch 00207: val_loss did not improve from 0.77490\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.0018 - acc: 0.6984 - val_loss: 0.7830 - val_acc: 0.7850\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0074 - acc: 0.6963\n",
      "Epoch 00208: val_loss did not improve from 0.77490\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0073 - acc: 0.6963 - val_loss: 0.7793 - val_acc: 0.7838\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0092 - acc: 0.6950\n",
      "Epoch 00209: val_loss did not improve from 0.77490\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.0091 - acc: 0.6950 - val_loss: 0.7808 - val_acc: 0.7857\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0008 - acc: 0.6969\n",
      "Epoch 00210: val_loss improved from 0.77490 to 0.77000, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/210-0.7700.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.0009 - acc: 0.6969 - val_loss: 0.7700 - val_acc: 0.7885\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0059 - acc: 0.6965\n",
      "Epoch 00211: val_loss did not improve from 0.77000\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0059 - acc: 0.6965 - val_loss: 0.7745 - val_acc: 0.7869\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0007 - acc: 0.6991\n",
      "Epoch 00212: val_loss did not improve from 0.77000\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0008 - acc: 0.6991 - val_loss: 0.7759 - val_acc: 0.7864\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0071 - acc: 0.6938\n",
      "Epoch 00213: val_loss did not improve from 0.77000\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0071 - acc: 0.6937 - val_loss: 0.7700 - val_acc: 0.7862\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9990 - acc: 0.6959\n",
      "Epoch 00214: val_loss did not improve from 0.77000\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9991 - acc: 0.6958 - val_loss: 0.7721 - val_acc: 0.7904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9992 - acc: 0.6990\n",
      "Epoch 00215: val_loss did not improve from 0.77000\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9993 - acc: 0.6990 - val_loss: 0.7719 - val_acc: 0.7892\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0008 - acc: 0.6999\n",
      "Epoch 00216: val_loss did not improve from 0.77000\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0007 - acc: 0.6999 - val_loss: 0.7755 - val_acc: 0.7850\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9997 - acc: 0.7008\n",
      "Epoch 00217: val_loss improved from 0.77000 to 0.76795, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/217-0.7680.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9997 - acc: 0.7008 - val_loss: 0.7680 - val_acc: 0.7904\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9988 - acc: 0.6964\n",
      "Epoch 00218: val_loss did not improve from 0.76795\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9988 - acc: 0.6964 - val_loss: 0.7701 - val_acc: 0.7876\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9990 - acc: 0.7007- ETA: 2s - lo\n",
      "Epoch 00219: val_loss improved from 0.76795 to 0.76727, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/219-0.7673.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9991 - acc: 0.7006 - val_loss: 0.7673 - val_acc: 0.7880\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9958 - acc: 0.6991\n",
      "Epoch 00220: val_loss did not improve from 0.76727\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9957 - acc: 0.6992 - val_loss: 0.7678 - val_acc: 0.7890\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9922 - acc: 0.6988\n",
      "Epoch 00221: val_loss improved from 0.76727 to 0.76347, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/221-0.7635.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9921 - acc: 0.6989 - val_loss: 0.7635 - val_acc: 0.7952\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9903 - acc: 0.7012\n",
      "Epoch 00222: val_loss improved from 0.76347 to 0.76334, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/222-0.7633.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9904 - acc: 0.7012 - val_loss: 0.7633 - val_acc: 0.7918\n",
      "Epoch 223/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9918 - acc: 0.7007\n",
      "Epoch 00223: val_loss improved from 0.76334 to 0.75931, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/223-0.7593.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9917 - acc: 0.7007 - val_loss: 0.7593 - val_acc: 0.7901\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9948 - acc: 0.7023\n",
      "Epoch 00224: val_loss did not improve from 0.75931\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9948 - acc: 0.7023 - val_loss: 0.7631 - val_acc: 0.7850\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9903 - acc: 0.7011\n",
      "Epoch 00225: val_loss did not improve from 0.75931\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9904 - acc: 0.7011 - val_loss: 0.7646 - val_acc: 0.7866\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9885 - acc: 0.7014\n",
      "Epoch 00226: val_loss did not improve from 0.75931\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9885 - acc: 0.7014 - val_loss: 0.7710 - val_acc: 0.7869\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9910 - acc: 0.7014\n",
      "Epoch 00227: val_loss did not improve from 0.75931\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.9909 - acc: 0.7014 - val_loss: 0.7665 - val_acc: 0.7843\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9990 - acc: 0.6976\n",
      "Epoch 00228: val_loss did not improve from 0.75931\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9989 - acc: 0.6975 - val_loss: 0.7653 - val_acc: 0.7871\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9894 - acc: 0.6989\n",
      "Epoch 00229: val_loss did not improve from 0.75931\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9893 - acc: 0.6989 - val_loss: 0.7619 - val_acc: 0.7897\n",
      "Epoch 230/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9830 - acc: 0.7055\n",
      "Epoch 00230: val_loss did not improve from 0.75931\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9828 - acc: 0.7057 - val_loss: 0.7606 - val_acc: 0.7904\n",
      "Epoch 231/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9850 - acc: 0.7047\n",
      "Epoch 00231: val_loss did not improve from 0.75931\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9853 - acc: 0.7047 - val_loss: 0.7638 - val_acc: 0.7906\n",
      "Epoch 232/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9967 - acc: 0.6978\n",
      "Epoch 00232: val_loss did not improve from 0.75931\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9969 - acc: 0.6978 - val_loss: 0.7614 - val_acc: 0.7894\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9809 - acc: 0.7048\n",
      "Epoch 00233: val_loss did not improve from 0.75931\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9808 - acc: 0.7048 - val_loss: 0.7694 - val_acc: 0.7829\n",
      "Epoch 234/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9881 - acc: 0.7030\n",
      "Epoch 00234: val_loss improved from 0.75931 to 0.75860, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/234-0.7586.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9881 - acc: 0.7030 - val_loss: 0.7586 - val_acc: 0.7887\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9770 - acc: 0.7035\n",
      "Epoch 00235: val_loss did not improve from 0.75860\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9771 - acc: 0.7034 - val_loss: 0.7623 - val_acc: 0.7894\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9848 - acc: 0.7043\n",
      "Epoch 00236: val_loss improved from 0.75860 to 0.75508, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/236-0.7551.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9849 - acc: 0.7042 - val_loss: 0.7551 - val_acc: 0.7915\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9860 - acc: 0.6992\n",
      "Epoch 00237: val_loss did not improve from 0.75508\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9860 - acc: 0.6992 - val_loss: 0.7608 - val_acc: 0.7906\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9850 - acc: 0.7045\n",
      "Epoch 00238: val_loss did not improve from 0.75508\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9850 - acc: 0.7046 - val_loss: 0.7567 - val_acc: 0.7927\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9855 - acc: 0.7040\n",
      "Epoch 00239: val_loss improved from 0.75508 to 0.75376, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/239-0.7538.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9855 - acc: 0.7040 - val_loss: 0.7538 - val_acc: 0.7936\n",
      "Epoch 240/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9851 - acc: 0.7048\n",
      "Epoch 00240: val_loss did not improve from 0.75376\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9851 - acc: 0.7048 - val_loss: 0.7549 - val_acc: 0.7897\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9822 - acc: 0.7043\n",
      "Epoch 00241: val_loss did not improve from 0.75376\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9822 - acc: 0.7043 - val_loss: 0.7584 - val_acc: 0.7894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9846 - acc: 0.7041\n",
      "Epoch 00242: val_loss improved from 0.75376 to 0.75078, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/242-0.7508.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9845 - acc: 0.7042 - val_loss: 0.7508 - val_acc: 0.7959\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9779 - acc: 0.7053\n",
      "Epoch 00243: val_loss improved from 0.75078 to 0.74973, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/243-0.7497.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9778 - acc: 0.7053 - val_loss: 0.7497 - val_acc: 0.7927\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9742 - acc: 0.7051\n",
      "Epoch 00244: val_loss improved from 0.74973 to 0.74493, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/244-0.7449.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9743 - acc: 0.7051 - val_loss: 0.7449 - val_acc: 0.7948\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9743 - acc: 0.7060\n",
      "Epoch 00245: val_loss did not improve from 0.74493\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9743 - acc: 0.7060 - val_loss: 0.7598 - val_acc: 0.7885\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9786 - acc: 0.7055\n",
      "Epoch 00246: val_loss did not improve from 0.74493\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9786 - acc: 0.7055 - val_loss: 0.7501 - val_acc: 0.7932\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9786 - acc: 0.7065\n",
      "Epoch 00247: val_loss did not improve from 0.74493\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9786 - acc: 0.7065 - val_loss: 0.7526 - val_acc: 0.7920\n",
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9692 - acc: 0.7079\n",
      "Epoch 00248: val_loss improved from 0.74493 to 0.74131, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/248-0.7413.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9692 - acc: 0.7079 - val_loss: 0.7413 - val_acc: 0.7959\n",
      "Epoch 249/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9686 - acc: 0.7097\n",
      "Epoch 00249: val_loss did not improve from 0.74131\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9686 - acc: 0.7097 - val_loss: 0.7553 - val_acc: 0.7915\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9773 - acc: 0.7047\n",
      "Epoch 00250: val_loss did not improve from 0.74131\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9773 - acc: 0.7047 - val_loss: 0.7550 - val_acc: 0.7857\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9720 - acc: 0.7088\n",
      "Epoch 00251: val_loss did not improve from 0.74131\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9720 - acc: 0.7088 - val_loss: 0.7477 - val_acc: 0.7925\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9769 - acc: 0.7065\n",
      "Epoch 00252: val_loss did not improve from 0.74131\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9769 - acc: 0.7064 - val_loss: 0.7511 - val_acc: 0.7929\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9751 - acc: 0.7034\n",
      "Epoch 00253: val_loss did not improve from 0.74131\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9751 - acc: 0.7034 - val_loss: 0.7487 - val_acc: 0.7959\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9821 - acc: 0.7054\n",
      "Epoch 00254: val_loss did not improve from 0.74131\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9821 - acc: 0.7054 - val_loss: 0.7459 - val_acc: 0.7929\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9759 - acc: 0.7060\n",
      "Epoch 00255: val_loss did not improve from 0.74131\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9759 - acc: 0.7060 - val_loss: 0.7436 - val_acc: 0.7957\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9650 - acc: 0.7077\n",
      "Epoch 00256: val_loss improved from 0.74131 to 0.73616, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/256-0.7362.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.9650 - acc: 0.7078 - val_loss: 0.7362 - val_acc: 0.8032\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9691 - acc: 0.7075\n",
      "Epoch 00257: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9692 - acc: 0.7075 - val_loss: 0.7464 - val_acc: 0.7911\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9727 - acc: 0.7064\n",
      "Epoch 00258: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9727 - acc: 0.7064 - val_loss: 0.7392 - val_acc: 0.7980\n",
      "Epoch 259/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9692 - acc: 0.7076\n",
      "Epoch 00259: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9692 - acc: 0.7076 - val_loss: 0.7406 - val_acc: 0.7976\n",
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9668 - acc: 0.7103\n",
      "Epoch 00260: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9668 - acc: 0.7103 - val_loss: 0.7436 - val_acc: 0.7971\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9718 - acc: 0.7060\n",
      "Epoch 00261: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9718 - acc: 0.7060 - val_loss: 0.7464 - val_acc: 0.7955\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9662 - acc: 0.7087\n",
      "Epoch 00262: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9662 - acc: 0.7087 - val_loss: 0.7439 - val_acc: 0.7980\n",
      "Epoch 263/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9674 - acc: 0.7055\n",
      "Epoch 00263: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9673 - acc: 0.7055 - val_loss: 0.7443 - val_acc: 0.7997\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9723 - acc: 0.7058\n",
      "Epoch 00264: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9723 - acc: 0.7058 - val_loss: 0.7399 - val_acc: 0.7973\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9665 - acc: 0.7090\n",
      "Epoch 00265: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9665 - acc: 0.7090 - val_loss: 0.7380 - val_acc: 0.7983\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9719 - acc: 0.7085\n",
      "Epoch 00266: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9720 - acc: 0.7085 - val_loss: 0.7410 - val_acc: 0.7990\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9633 - acc: 0.7076\n",
      "Epoch 00267: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9632 - acc: 0.7076 - val_loss: 0.7410 - val_acc: 0.7969\n",
      "Epoch 268/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9686 - acc: 0.7101\n",
      "Epoch 00268: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.9691 - acc: 0.7101 - val_loss: 0.7409 - val_acc: 0.7941\n",
      "Epoch 269/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9646 - acc: 0.7101\n",
      "Epoch 00269: val_loss did not improve from 0.73616\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9646 - acc: 0.7101 - val_loss: 0.7396 - val_acc: 0.7966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9676 - acc: 0.7088\n",
      "Epoch 00270: val_loss improved from 0.73616 to 0.73413, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/270-0.7341.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9676 - acc: 0.7088 - val_loss: 0.7341 - val_acc: 0.8018\n",
      "Epoch 271/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9600 - acc: 0.7109\n",
      "Epoch 00271: val_loss did not improve from 0.73413\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9602 - acc: 0.7109 - val_loss: 0.7380 - val_acc: 0.8013\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9704 - acc: 0.7083\n",
      "Epoch 00272: val_loss did not improve from 0.73413\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9704 - acc: 0.7084 - val_loss: 0.7374 - val_acc: 0.8015\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9675 - acc: 0.7085\n",
      "Epoch 00273: val_loss did not improve from 0.73413\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9674 - acc: 0.7085 - val_loss: 0.7377 - val_acc: 0.7939\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9643 - acc: 0.7086\n",
      "Epoch 00274: val_loss did not improve from 0.73413\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9642 - acc: 0.7086 - val_loss: 0.7376 - val_acc: 0.7959\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9646 - acc: 0.7066\n",
      "Epoch 00275: val_loss improved from 0.73413 to 0.73292, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/275-0.7329.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9645 - acc: 0.7066 - val_loss: 0.7329 - val_acc: 0.7966\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9635 - acc: 0.7090\n",
      "Epoch 00276: val_loss did not improve from 0.73292\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9635 - acc: 0.7090 - val_loss: 0.7355 - val_acc: 0.7997\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9629 - acc: 0.7092\n",
      "Epoch 00277: val_loss did not improve from 0.73292\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9628 - acc: 0.7093 - val_loss: 0.7335 - val_acc: 0.8001\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9562 - acc: 0.7120\n",
      "Epoch 00278: val_loss did not improve from 0.73292\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9561 - acc: 0.7120 - val_loss: 0.7456 - val_acc: 0.7929\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9672 - acc: 0.7092\n",
      "Epoch 00279: val_loss did not improve from 0.73292\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9672 - acc: 0.7092 - val_loss: 0.7343 - val_acc: 0.7964\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9585 - acc: 0.7120\n",
      "Epoch 00280: val_loss improved from 0.73292 to 0.72456, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/280-0.7246.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9588 - acc: 0.7120 - val_loss: 0.7246 - val_acc: 0.8015\n",
      "Epoch 281/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9603 - acc: 0.7105\n",
      "Epoch 00281: val_loss did not improve from 0.72456\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9602 - acc: 0.7105 - val_loss: 0.7314 - val_acc: 0.8039\n",
      "Epoch 282/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9555 - acc: 0.7119\n",
      "Epoch 00282: val_loss did not improve from 0.72456\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9554 - acc: 0.7119 - val_loss: 0.7265 - val_acc: 0.8006\n",
      "Epoch 283/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9557 - acc: 0.7118\n",
      "Epoch 00283: val_loss did not improve from 0.72456\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9556 - acc: 0.7118 - val_loss: 0.7280 - val_acc: 0.8046\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9583 - acc: 0.7106\n",
      "Epoch 00284: val_loss did not improve from 0.72456\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9583 - acc: 0.7106 - val_loss: 0.7313 - val_acc: 0.7992\n",
      "Epoch 285/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9517 - acc: 0.7116\n",
      "Epoch 00285: val_loss did not improve from 0.72456\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9517 - acc: 0.7116 - val_loss: 0.7298 - val_acc: 0.7997\n",
      "Epoch 286/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9501 - acc: 0.7150\n",
      "Epoch 00286: val_loss improved from 0.72456 to 0.72327, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/286-0.7233.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9502 - acc: 0.7150 - val_loss: 0.7233 - val_acc: 0.8088\n",
      "Epoch 287/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9643 - acc: 0.7104\n",
      "Epoch 00287: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9643 - acc: 0.7104 - val_loss: 0.7300 - val_acc: 0.8015\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9573 - acc: 0.7121\n",
      "Epoch 00288: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9573 - acc: 0.7121 - val_loss: 0.7361 - val_acc: 0.7955\n",
      "Epoch 289/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9509 - acc: 0.7132\n",
      "Epoch 00289: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9508 - acc: 0.7132 - val_loss: 0.7252 - val_acc: 0.7992\n",
      "Epoch 290/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9537 - acc: 0.7114\n",
      "Epoch 00290: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9536 - acc: 0.7114 - val_loss: 0.7239 - val_acc: 0.8039\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9569 - acc: 0.7166\n",
      "Epoch 00291: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9568 - acc: 0.7166 - val_loss: 0.7268 - val_acc: 0.8018\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9596 - acc: 0.7129\n",
      "Epoch 00292: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9600 - acc: 0.7128 - val_loss: 0.7290 - val_acc: 0.7987\n",
      "Epoch 293/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9599 - acc: 0.7109\n",
      "Epoch 00293: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9599 - acc: 0.7110 - val_loss: 0.7240 - val_acc: 0.7994\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9489 - acc: 0.7146\n",
      "Epoch 00294: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9488 - acc: 0.7147 - val_loss: 0.7269 - val_acc: 0.8006\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9497 - acc: 0.7134\n",
      "Epoch 00295: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9498 - acc: 0.7134 - val_loss: 0.7246 - val_acc: 0.8032\n",
      "Epoch 296/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9511 - acc: 0.7128\n",
      "Epoch 00296: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9510 - acc: 0.7129 - val_loss: 0.7286 - val_acc: 0.8008\n",
      "Epoch 297/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9573 - acc: 0.7120\n",
      "Epoch 00297: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9573 - acc: 0.7120 - val_loss: 0.7248 - val_acc: 0.8011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9518 - acc: 0.7129\n",
      "Epoch 00298: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9519 - acc: 0.7128 - val_loss: 0.7265 - val_acc: 0.8008\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9509 - acc: 0.7138\n",
      "Epoch 00299: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9508 - acc: 0.7138 - val_loss: 0.7255 - val_acc: 0.8032\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9471 - acc: 0.7144\n",
      "Epoch 00300: val_loss did not improve from 0.72327\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9471 - acc: 0.7144 - val_loss: 0.7276 - val_acc: 0.8013\n",
      "Epoch 301/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9585 - acc: 0.7117\n",
      "Epoch 00301: val_loss improved from 0.72327 to 0.72210, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/301-0.7221.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9584 - acc: 0.7118 - val_loss: 0.7221 - val_acc: 0.8034\n",
      "Epoch 302/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9529 - acc: 0.7137\n",
      "Epoch 00302: val_loss did not improve from 0.72210\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9531 - acc: 0.7137 - val_loss: 0.7374 - val_acc: 0.7962\n",
      "Epoch 303/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9439 - acc: 0.7164\n",
      "Epoch 00303: val_loss improved from 0.72210 to 0.71582, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/303-0.7158.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9438 - acc: 0.7164 - val_loss: 0.7158 - val_acc: 0.8050\n",
      "Epoch 304/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9522 - acc: 0.7135\n",
      "Epoch 00304: val_loss did not improve from 0.71582\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9522 - acc: 0.7134 - val_loss: 0.7227 - val_acc: 0.8029\n",
      "Epoch 305/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9459 - acc: 0.7149\n",
      "Epoch 00305: val_loss did not improve from 0.71582\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9458 - acc: 0.7150 - val_loss: 0.7239 - val_acc: 0.8029\n",
      "Epoch 306/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9529 - acc: 0.7123\n",
      "Epoch 00306: val_loss did not improve from 0.71582\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9529 - acc: 0.7123 - val_loss: 0.7259 - val_acc: 0.8015\n",
      "Epoch 307/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9425 - acc: 0.7152\n",
      "Epoch 00307: val_loss did not improve from 0.71582\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9429 - acc: 0.7152 - val_loss: 0.7183 - val_acc: 0.8032\n",
      "Epoch 308/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9461 - acc: 0.7158\n",
      "Epoch 00308: val_loss improved from 0.71582 to 0.71558, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/308-0.7156.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9461 - acc: 0.7158 - val_loss: 0.7156 - val_acc: 0.8043\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9483 - acc: 0.7144\n",
      "Epoch 00309: val_loss did not improve from 0.71558\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.9483 - acc: 0.7144 - val_loss: 0.7190 - val_acc: 0.8011\n",
      "Epoch 310/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9436 - acc: 0.7162\n",
      "Epoch 00310: val_loss improved from 0.71558 to 0.71271, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/310-0.7127.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9435 - acc: 0.7162 - val_loss: 0.7127 - val_acc: 0.8046\n",
      "Epoch 311/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9477 - acc: 0.7174\n",
      "Epoch 00311: val_loss did not improve from 0.71271\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9477 - acc: 0.7174 - val_loss: 0.7205 - val_acc: 0.8029\n",
      "Epoch 312/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9498 - acc: 0.7155\n",
      "Epoch 00312: val_loss did not improve from 0.71271\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9498 - acc: 0.7155 - val_loss: 0.7151 - val_acc: 0.8050\n",
      "Epoch 313/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9505 - acc: 0.7157\n",
      "Epoch 00313: val_loss improved from 0.71271 to 0.71186, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/313-0.7119.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.9513 - acc: 0.7154 - val_loss: 0.7119 - val_acc: 0.8050\n",
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9472 - acc: 0.7143\n",
      "Epoch 00314: val_loss did not improve from 0.71186\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9472 - acc: 0.7144 - val_loss: 0.7161 - val_acc: 0.8032\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9436 - acc: 0.7168\n",
      "Epoch 00315: val_loss did not improve from 0.71186\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.9437 - acc: 0.7168 - val_loss: 0.7212 - val_acc: 0.8020\n",
      "Epoch 316/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9437 - acc: 0.7173\n",
      "Epoch 00316: val_loss did not improve from 0.71186\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.9437 - acc: 0.7173 - val_loss: 0.7190 - val_acc: 0.8039\n",
      "Epoch 317/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9435 - acc: 0.7144\n",
      "Epoch 00317: val_loss did not improve from 0.71186\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.9435 - acc: 0.7144 - val_loss: 0.7161 - val_acc: 0.8043\n",
      "Epoch 318/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9368 - acc: 0.7184\n",
      "Epoch 00318: val_loss improved from 0.71186 to 0.71058, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/318-0.7106.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.9368 - acc: 0.7184 - val_loss: 0.7106 - val_acc: 0.8074\n",
      "Epoch 319/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9470 - acc: 0.7153\n",
      "Epoch 00319: val_loss did not improve from 0.71058\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9470 - acc: 0.7153 - val_loss: 0.7144 - val_acc: 0.8053\n",
      "Epoch 320/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9404 - acc: 0.7200\n",
      "Epoch 00320: val_loss did not improve from 0.71058\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9404 - acc: 0.7200 - val_loss: 0.7125 - val_acc: 0.8062\n",
      "Epoch 321/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9441 - acc: 0.7150\n",
      "Epoch 00321: val_loss improved from 0.71058 to 0.70882, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/321-0.7088.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9441 - acc: 0.7150 - val_loss: 0.7088 - val_acc: 0.8064\n",
      "Epoch 322/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9419 - acc: 0.7158\n",
      "Epoch 00322: val_loss did not improve from 0.70882\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9419 - acc: 0.7158 - val_loss: 0.7143 - val_acc: 0.8039\n",
      "Epoch 323/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9375 - acc: 0.7197\n",
      "Epoch 00323: val_loss did not improve from 0.70882\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9375 - acc: 0.7198 - val_loss: 0.7135 - val_acc: 0.8025\n",
      "Epoch 324/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9372 - acc: 0.7150\n",
      "Epoch 00324: val_loss improved from 0.70882 to 0.70656, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/324-0.7066.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.9372 - acc: 0.7150 - val_loss: 0.7066 - val_acc: 0.8064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9328 - acc: 0.7217\n",
      "Epoch 00325: val_loss did not improve from 0.70656\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9328 - acc: 0.7216 - val_loss: 0.7136 - val_acc: 0.8069\n",
      "Epoch 326/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9412 - acc: 0.7189\n",
      "Epoch 00326: val_loss did not improve from 0.70656\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9412 - acc: 0.7189 - val_loss: 0.7145 - val_acc: 0.8050\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9409 - acc: 0.7171\n",
      "Epoch 00327: val_loss did not improve from 0.70656\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9413 - acc: 0.7170 - val_loss: 0.7140 - val_acc: 0.8060\n",
      "Epoch 328/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9328 - acc: 0.7192\n",
      "Epoch 00328: val_loss improved from 0.70656 to 0.70569, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/328-0.7057.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9327 - acc: 0.7192 - val_loss: 0.7057 - val_acc: 0.8078\n",
      "Epoch 329/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9353 - acc: 0.7188\n",
      "Epoch 00329: val_loss did not improve from 0.70569\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9352 - acc: 0.7188 - val_loss: 0.7192 - val_acc: 0.8022\n",
      "Epoch 330/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9389 - acc: 0.7182\n",
      "Epoch 00330: val_loss did not improve from 0.70569\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9385 - acc: 0.7183 - val_loss: 0.7087 - val_acc: 0.8064\n",
      "Epoch 331/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9336 - acc: 0.7189\n",
      "Epoch 00331: val_loss did not improve from 0.70569\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9335 - acc: 0.7189 - val_loss: 0.7272 - val_acc: 0.7976\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9410 - acc: 0.7168\n",
      "Epoch 00332: val_loss did not improve from 0.70569\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9410 - acc: 0.7168 - val_loss: 0.7118 - val_acc: 0.8064\n",
      "Epoch 333/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9332 - acc: 0.7206\n",
      "Epoch 00333: val_loss improved from 0.70569 to 0.70221, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/333-0.7022.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9332 - acc: 0.7206 - val_loss: 0.7022 - val_acc: 0.8092\n",
      "Epoch 334/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9361 - acc: 0.7192\n",
      "Epoch 00334: val_loss did not improve from 0.70221\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9361 - acc: 0.7192 - val_loss: 0.7117 - val_acc: 0.8090\n",
      "Epoch 335/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9323 - acc: 0.7230\n",
      "Epoch 00335: val_loss did not improve from 0.70221\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.9323 - acc: 0.7230 - val_loss: 0.7038 - val_acc: 0.8099\n",
      "Epoch 336/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9335 - acc: 0.7210\n",
      "Epoch 00336: val_loss improved from 0.70221 to 0.70167, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/336-0.7017.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9334 - acc: 0.7210 - val_loss: 0.7017 - val_acc: 0.8067\n",
      "Epoch 337/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9312 - acc: 0.7183\n",
      "Epoch 00337: val_loss improved from 0.70167 to 0.69771, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/337-0.6977.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.9312 - acc: 0.7183 - val_loss: 0.6977 - val_acc: 0.8090\n",
      "Epoch 338/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9266 - acc: 0.7205\n",
      "Epoch 00338: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9267 - acc: 0.7204 - val_loss: 0.7051 - val_acc: 0.8071\n",
      "Epoch 339/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9350 - acc: 0.7210\n",
      "Epoch 00339: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9350 - acc: 0.7210 - val_loss: 0.7132 - val_acc: 0.8062\n",
      "Epoch 340/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9300 - acc: 0.7223\n",
      "Epoch 00340: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9300 - acc: 0.7222 - val_loss: 0.7060 - val_acc: 0.8106\n",
      "Epoch 341/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9326 - acc: 0.7211\n",
      "Epoch 00341: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9326 - acc: 0.7211 - val_loss: 0.7028 - val_acc: 0.8085\n",
      "Epoch 342/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9343 - acc: 0.7194\n",
      "Epoch 00342: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9345 - acc: 0.7194 - val_loss: 0.7104 - val_acc: 0.8046\n",
      "Epoch 343/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9341 - acc: 0.7190\n",
      "Epoch 00343: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9341 - acc: 0.7190 - val_loss: 0.7049 - val_acc: 0.8125\n",
      "Epoch 344/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9327 - acc: 0.7212\n",
      "Epoch 00344: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9328 - acc: 0.7213 - val_loss: 0.7008 - val_acc: 0.8085\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9275 - acc: 0.7206\n",
      "Epoch 00345: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9275 - acc: 0.7206 - val_loss: 0.7039 - val_acc: 0.8050\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9264 - acc: 0.7212\n",
      "Epoch 00346: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9263 - acc: 0.7212 - val_loss: 0.7069 - val_acc: 0.8069\n",
      "Epoch 347/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9293 - acc: 0.7187\n",
      "Epoch 00347: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9295 - acc: 0.7187 - val_loss: 0.6986 - val_acc: 0.8097\n",
      "Epoch 348/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9243 - acc: 0.7232\n",
      "Epoch 00348: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9240 - acc: 0.7232 - val_loss: 0.6984 - val_acc: 0.8074\n",
      "Epoch 349/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9236 - acc: 0.7224\n",
      "Epoch 00349: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9238 - acc: 0.7223 - val_loss: 0.6995 - val_acc: 0.8078\n",
      "Epoch 350/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9252 - acc: 0.7219\n",
      "Epoch 00350: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9252 - acc: 0.7219 - val_loss: 0.6998 - val_acc: 0.8102\n",
      "Epoch 351/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9301 - acc: 0.7219\n",
      "Epoch 00351: val_loss did not improve from 0.69771\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9301 - acc: 0.7219 - val_loss: 0.7050 - val_acc: 0.8067\n",
      "Epoch 352/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9293 - acc: 0.7199\n",
      "Epoch 00352: val_loss improved from 0.69771 to 0.69232, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/352-0.6923.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9292 - acc: 0.7199 - val_loss: 0.6923 - val_acc: 0.8134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9305 - acc: 0.7186\n",
      "Epoch 00353: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9305 - acc: 0.7186 - val_loss: 0.6982 - val_acc: 0.8085\n",
      "Epoch 354/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9307 - acc: 0.7190\n",
      "Epoch 00354: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9306 - acc: 0.7190 - val_loss: 0.6964 - val_acc: 0.8125\n",
      "Epoch 355/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9263 - acc: 0.7222\n",
      "Epoch 00355: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9263 - acc: 0.7222 - val_loss: 0.6994 - val_acc: 0.8099\n",
      "Epoch 356/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9273 - acc: 0.7210\n",
      "Epoch 00356: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9272 - acc: 0.7210 - val_loss: 0.7011 - val_acc: 0.8106\n",
      "Epoch 357/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9286 - acc: 0.7204\n",
      "Epoch 00357: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.9284 - acc: 0.7205 - val_loss: 0.6953 - val_acc: 0.8106\n",
      "Epoch 358/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9241 - acc: 0.7201\n",
      "Epoch 00358: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9241 - acc: 0.7201 - val_loss: 0.7036 - val_acc: 0.8062\n",
      "Epoch 359/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9228 - acc: 0.7229\n",
      "Epoch 00359: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9229 - acc: 0.7228 - val_loss: 0.6933 - val_acc: 0.8139\n",
      "Epoch 360/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9221 - acc: 0.7217\n",
      "Epoch 00360: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.9220 - acc: 0.7217 - val_loss: 0.6954 - val_acc: 0.8097\n",
      "Epoch 361/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9246 - acc: 0.7202\n",
      "Epoch 00361: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9246 - acc: 0.7203 - val_loss: 0.6970 - val_acc: 0.8106\n",
      "Epoch 362/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9229 - acc: 0.7237\n",
      "Epoch 00362: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9229 - acc: 0.7237 - val_loss: 0.6946 - val_acc: 0.8074\n",
      "Epoch 363/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9185 - acc: 0.7225\n",
      "Epoch 00363: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9182 - acc: 0.7226 - val_loss: 0.7001 - val_acc: 0.8102\n",
      "Epoch 364/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9200 - acc: 0.7232\n",
      "Epoch 00364: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9201 - acc: 0.7232 - val_loss: 0.7025 - val_acc: 0.8111\n",
      "Epoch 365/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9155 - acc: 0.7256\n",
      "Epoch 00365: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.9154 - acc: 0.7257 - val_loss: 0.6970 - val_acc: 0.8104\n",
      "Epoch 366/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9209 - acc: 0.7220\n",
      "Epoch 00366: val_loss did not improve from 0.69232\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9209 - acc: 0.7220 - val_loss: 0.6962 - val_acc: 0.8113\n",
      "Epoch 367/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9221 - acc: 0.7257\n",
      "Epoch 00367: val_loss improved from 0.69232 to 0.69035, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/367-0.6904.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9221 - acc: 0.7257 - val_loss: 0.6904 - val_acc: 0.8106\n",
      "Epoch 368/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9240 - acc: 0.7251\n",
      "Epoch 00368: val_loss did not improve from 0.69035\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9240 - acc: 0.7250 - val_loss: 0.6915 - val_acc: 0.8125\n",
      "Epoch 369/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9215 - acc: 0.7232\n",
      "Epoch 00369: val_loss did not improve from 0.69035\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9216 - acc: 0.7231 - val_loss: 0.6933 - val_acc: 0.8106\n",
      "Epoch 370/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9178 - acc: 0.7247\n",
      "Epoch 00370: val_loss did not improve from 0.69035\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9178 - acc: 0.7247 - val_loss: 0.6929 - val_acc: 0.8090\n",
      "Epoch 371/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9191 - acc: 0.7251\n",
      "Epoch 00371: val_loss did not improve from 0.69035\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9191 - acc: 0.7251 - val_loss: 0.6927 - val_acc: 0.8099\n",
      "Epoch 372/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9163 - acc: 0.7232\n",
      "Epoch 00372: val_loss improved from 0.69035 to 0.68972, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/372-0.6897.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9164 - acc: 0.7232 - val_loss: 0.6897 - val_acc: 0.8120\n",
      "Epoch 373/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9193 - acc: 0.7250\n",
      "Epoch 00373: val_loss did not improve from 0.68972\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9192 - acc: 0.7250 - val_loss: 0.6904 - val_acc: 0.8109\n",
      "Epoch 374/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9149 - acc: 0.7246\n",
      "Epoch 00374: val_loss improved from 0.68972 to 0.68855, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/374-0.6886.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9149 - acc: 0.7247 - val_loss: 0.6886 - val_acc: 0.8139\n",
      "Epoch 375/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9116 - acc: 0.7265\n",
      "Epoch 00375: val_loss did not improve from 0.68855\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.9118 - acc: 0.7265 - val_loss: 0.6972 - val_acc: 0.8074\n",
      "Epoch 376/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9171 - acc: 0.7242\n",
      "Epoch 00376: val_loss did not improve from 0.68855\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9171 - acc: 0.7242 - val_loss: 0.6978 - val_acc: 0.8125\n",
      "Epoch 377/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9171 - acc: 0.7249\n",
      "Epoch 00377: val_loss did not improve from 0.68855\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9170 - acc: 0.7250 - val_loss: 0.6886 - val_acc: 0.8139\n",
      "Epoch 378/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9167 - acc: 0.7246\n",
      "Epoch 00378: val_loss did not improve from 0.68855\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9167 - acc: 0.7246 - val_loss: 0.6974 - val_acc: 0.8097\n",
      "Epoch 379/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9209 - acc: 0.7229\n",
      "Epoch 00379: val_loss improved from 0.68855 to 0.68715, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/379-0.6871.hdf5\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9209 - acc: 0.7229 - val_loss: 0.6871 - val_acc: 0.8137\n",
      "Epoch 380/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9180 - acc: 0.7234\n",
      "Epoch 00380: val_loss did not improve from 0.68715\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9179 - acc: 0.7235 - val_loss: 0.6919 - val_acc: 0.8139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9139 - acc: 0.7249\n",
      "Epoch 00381: val_loss did not improve from 0.68715\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9138 - acc: 0.7249 - val_loss: 0.6904 - val_acc: 0.8139\n",
      "Epoch 382/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9148 - acc: 0.7242\n",
      "Epoch 00382: val_loss improved from 0.68715 to 0.68453, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/382-0.6845.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9148 - acc: 0.7241 - val_loss: 0.6845 - val_acc: 0.8148\n",
      "Epoch 383/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9159 - acc: 0.7254\n",
      "Epoch 00383: val_loss did not improve from 0.68453\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9158 - acc: 0.7254 - val_loss: 0.6933 - val_acc: 0.8113\n",
      "Epoch 384/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9096 - acc: 0.7281\n",
      "Epoch 00384: val_loss did not improve from 0.68453\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9096 - acc: 0.7281 - val_loss: 0.6903 - val_acc: 0.8137\n",
      "Epoch 385/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9104 - acc: 0.7273\n",
      "Epoch 00385: val_loss did not improve from 0.68453\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9104 - acc: 0.7272 - val_loss: 0.6890 - val_acc: 0.8137\n",
      "Epoch 386/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9183 - acc: 0.7227\n",
      "Epoch 00386: val_loss did not improve from 0.68453\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.9183 - acc: 0.7226 - val_loss: 0.6891 - val_acc: 0.8132\n",
      "Epoch 387/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9168 - acc: 0.7227\n",
      "Epoch 00387: val_loss did not improve from 0.68453\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9168 - acc: 0.7227 - val_loss: 0.6851 - val_acc: 0.8150\n",
      "Epoch 388/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9156 - acc: 0.7236\n",
      "Epoch 00388: val_loss did not improve from 0.68453\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9156 - acc: 0.7236 - val_loss: 0.6883 - val_acc: 0.8143\n",
      "Epoch 389/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9158 - acc: 0.7253\n",
      "Epoch 00389: val_loss did not improve from 0.68453\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9157 - acc: 0.7253 - val_loss: 0.6884 - val_acc: 0.8113\n",
      "Epoch 390/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9145 - acc: 0.7242\n",
      "Epoch 00390: val_loss improved from 0.68453 to 0.68387, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/390-0.6839.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9146 - acc: 0.7242 - val_loss: 0.6839 - val_acc: 0.8157\n",
      "Epoch 391/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9225 - acc: 0.7226\n",
      "Epoch 00391: val_loss did not improve from 0.68387\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9224 - acc: 0.7226 - val_loss: 0.6884 - val_acc: 0.8148\n",
      "Epoch 392/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9184 - acc: 0.7268\n",
      "Epoch 00392: val_loss did not improve from 0.68387\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9184 - acc: 0.7269 - val_loss: 0.6938 - val_acc: 0.8116\n",
      "Epoch 393/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9089 - acc: 0.7265\n",
      "Epoch 00393: val_loss did not improve from 0.68387\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9088 - acc: 0.7266 - val_loss: 0.6855 - val_acc: 0.8143\n",
      "Epoch 394/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9119 - acc: 0.7255\n",
      "Epoch 00394: val_loss did not improve from 0.68387\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9118 - acc: 0.7255 - val_loss: 0.6861 - val_acc: 0.8176\n",
      "Epoch 395/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9027 - acc: 0.7287\n",
      "Epoch 00395: val_loss improved from 0.68387 to 0.68268, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/395-0.6827.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9027 - acc: 0.7288 - val_loss: 0.6827 - val_acc: 0.8164\n",
      "Epoch 396/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9024 - acc: 0.7282\n",
      "Epoch 00396: val_loss did not improve from 0.68268\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9024 - acc: 0.7282 - val_loss: 0.6854 - val_acc: 0.8137\n",
      "Epoch 397/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9135 - acc: 0.7274\n",
      "Epoch 00397: val_loss did not improve from 0.68268\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.9135 - acc: 0.7274 - val_loss: 0.6862 - val_acc: 0.8125\n",
      "Epoch 398/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9138 - acc: 0.7254\n",
      "Epoch 00398: val_loss did not improve from 0.68268\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.9138 - acc: 0.7254 - val_loss: 0.6901 - val_acc: 0.8125\n",
      "Epoch 399/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9122 - acc: 0.7280\n",
      "Epoch 00399: val_loss improved from 0.68268 to 0.68222, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/399-0.6822.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9122 - acc: 0.7280 - val_loss: 0.6822 - val_acc: 0.8171\n",
      "Epoch 400/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9061 - acc: 0.7281\n",
      "Epoch 00400: val_loss did not improve from 0.68222\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.9062 - acc: 0.7281 - val_loss: 0.6852 - val_acc: 0.8132\n",
      "Epoch 401/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9075 - acc: 0.7269\n",
      "Epoch 00401: val_loss improved from 0.68222 to 0.68043, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/401-0.6804.hdf5\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.9076 - acc: 0.7269 - val_loss: 0.6804 - val_acc: 0.8190\n",
      "Epoch 402/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9125 - acc: 0.7248- ETA: \n",
      "Epoch 00402: val_loss did not improve from 0.68043\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.9124 - acc: 0.7248 - val_loss: 0.6848 - val_acc: 0.8139\n",
      "Epoch 403/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9075 - acc: 0.7286\n",
      "Epoch 00403: val_loss did not improve from 0.68043\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9074 - acc: 0.7285 - val_loss: 0.6975 - val_acc: 0.8111\n",
      "Epoch 404/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9018 - acc: 0.7289\n",
      "Epoch 00404: val_loss improved from 0.68043 to 0.68023, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/404-0.6802.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9017 - acc: 0.7289 - val_loss: 0.6802 - val_acc: 0.8150\n",
      "Epoch 405/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9084 - acc: 0.7284\n",
      "Epoch 00405: val_loss did not improve from 0.68023\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9084 - acc: 0.7284 - val_loss: 0.6821 - val_acc: 0.8132\n",
      "Epoch 406/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9045 - acc: 0.7295\n",
      "Epoch 00406: val_loss did not improve from 0.68023\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9045 - acc: 0.7295 - val_loss: 0.6820 - val_acc: 0.8148\n",
      "Epoch 407/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9064 - acc: 0.7283\n",
      "Epoch 00407: val_loss did not improve from 0.68023\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9064 - acc: 0.7282 - val_loss: 0.6832 - val_acc: 0.8155\n",
      "Epoch 408/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9016 - acc: 0.7283\n",
      "Epoch 00408: val_loss improved from 0.68023 to 0.67500, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/408-0.6750.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.9016 - acc: 0.7283 - val_loss: 0.6750 - val_acc: 0.8148\n",
      "Epoch 409/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9020 - acc: 0.7276\n",
      "Epoch 00409: val_loss improved from 0.67500 to 0.67378, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/409-0.6738.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9019 - acc: 0.7277 - val_loss: 0.6738 - val_acc: 0.8160\n",
      "Epoch 410/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8997 - acc: 0.7280\n",
      "Epoch 00410: val_loss did not improve from 0.67378\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.8998 - acc: 0.7280 - val_loss: 0.6901 - val_acc: 0.8155\n",
      "Epoch 411/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9007 - acc: 0.7296\n",
      "Epoch 00411: val_loss did not improve from 0.67378\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9007 - acc: 0.7296 - val_loss: 0.6808 - val_acc: 0.8134\n",
      "Epoch 412/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9034 - acc: 0.7284\n",
      "Epoch 00412: val_loss did not improve from 0.67378\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9034 - acc: 0.7285 - val_loss: 0.6797 - val_acc: 0.8181\n",
      "Epoch 413/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8987 - acc: 0.7298\n",
      "Epoch 00413: val_loss did not improve from 0.67378\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8987 - acc: 0.7299 - val_loss: 0.6790 - val_acc: 0.8171\n",
      "Epoch 414/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9064 - acc: 0.7281\n",
      "Epoch 00414: val_loss did not improve from 0.67378\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9064 - acc: 0.7281 - val_loss: 0.6820 - val_acc: 0.8174\n",
      "Epoch 415/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8994 - acc: 0.7314\n",
      "Epoch 00415: val_loss did not improve from 0.67378\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.8994 - acc: 0.7314 - val_loss: 0.6799 - val_acc: 0.8190\n",
      "Epoch 416/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8975 - acc: 0.7281\n",
      "Epoch 00416: val_loss did not improve from 0.67378\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.8975 - acc: 0.7281 - val_loss: 0.6783 - val_acc: 0.8202\n",
      "Epoch 417/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8988 - acc: 0.7291\n",
      "Epoch 00417: val_loss did not improve from 0.67378\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.8987 - acc: 0.7292 - val_loss: 0.6804 - val_acc: 0.8132\n",
      "Epoch 418/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9049 - acc: 0.7297\n",
      "Epoch 00418: val_loss did not improve from 0.67378\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9049 - acc: 0.7297 - val_loss: 0.6937 - val_acc: 0.8113\n",
      "Epoch 419/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9006 - acc: 0.7301\n",
      "Epoch 00419: val_loss improved from 0.67378 to 0.67228, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/419-0.6723.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9006 - acc: 0.7301 - val_loss: 0.6723 - val_acc: 0.8204\n",
      "Epoch 420/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8962 - acc: 0.7293\n",
      "Epoch 00420: val_loss did not improve from 0.67228\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.8962 - acc: 0.7293 - val_loss: 0.6828 - val_acc: 0.8162\n",
      "Epoch 421/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9041 - acc: 0.7289\n",
      "Epoch 00421: val_loss did not improve from 0.67228\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9040 - acc: 0.7289 - val_loss: 0.6817 - val_acc: 0.8218\n",
      "Epoch 422/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9018 - acc: 0.7298\n",
      "Epoch 00422: val_loss did not improve from 0.67228\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9018 - acc: 0.7298 - val_loss: 0.6804 - val_acc: 0.8160\n",
      "Epoch 423/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9025 - acc: 0.7283\n",
      "Epoch 00423: val_loss did not improve from 0.67228\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9024 - acc: 0.7284 - val_loss: 0.6793 - val_acc: 0.8162\n",
      "Epoch 424/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8984 - acc: 0.7293\n",
      "Epoch 00424: val_loss did not improve from 0.67228\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.8984 - acc: 0.7293 - val_loss: 0.6744 - val_acc: 0.8167\n",
      "Epoch 425/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8954 - acc: 0.7315\n",
      "Epoch 00425: val_loss improved from 0.67228 to 0.67088, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/425-0.6709.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8954 - acc: 0.7316 - val_loss: 0.6709 - val_acc: 0.8192\n",
      "Epoch 426/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8974 - acc: 0.7294- ETA:\n",
      "Epoch 00426: val_loss did not improve from 0.67088\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.8975 - acc: 0.7294 - val_loss: 0.6767 - val_acc: 0.8206\n",
      "Epoch 427/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8935 - acc: 0.7342\n",
      "Epoch 00427: val_loss improved from 0.67088 to 0.66908, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/427-0.6691.hdf5\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.8934 - acc: 0.7342 - val_loss: 0.6691 - val_acc: 0.8211\n",
      "Epoch 428/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8948 - acc: 0.7302\n",
      "Epoch 00428: val_loss did not improve from 0.66908\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8948 - acc: 0.7301 - val_loss: 0.6759 - val_acc: 0.8174\n",
      "Epoch 429/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8884 - acc: 0.7342\n",
      "Epoch 00429: val_loss did not improve from 0.66908\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8884 - acc: 0.7342 - val_loss: 0.6781 - val_acc: 0.8185\n",
      "Epoch 430/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8953 - acc: 0.7311\n",
      "Epoch 00430: val_loss did not improve from 0.66908\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8952 - acc: 0.7312 - val_loss: 0.6771 - val_acc: 0.8218\n",
      "Epoch 431/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8951 - acc: 0.7312\n",
      "Epoch 00431: val_loss did not improve from 0.66908\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.8950 - acc: 0.7312 - val_loss: 0.6695 - val_acc: 0.8174\n",
      "Epoch 432/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8987 - acc: 0.7310\n",
      "Epoch 00432: val_loss did not improve from 0.66908\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8988 - acc: 0.7310 - val_loss: 0.6760 - val_acc: 0.8181\n",
      "Epoch 433/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8937 - acc: 0.7313\n",
      "Epoch 00433: val_loss did not improve from 0.66908\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.8938 - acc: 0.7313 - val_loss: 0.6703 - val_acc: 0.8195\n",
      "Epoch 434/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8932 - acc: 0.7307\n",
      "Epoch 00434: val_loss improved from 0.66908 to 0.66862, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/434-0.6686.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.8931 - acc: 0.7307 - val_loss: 0.6686 - val_acc: 0.8218\n",
      "Epoch 435/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8958 - acc: 0.7326\n",
      "Epoch 00435: val_loss did not improve from 0.66862\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.8958 - acc: 0.7326 - val_loss: 0.6754 - val_acc: 0.8174\n",
      "Epoch 436/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8991 - acc: 0.7317\n",
      "Epoch 00436: val_loss did not improve from 0.66862\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.8990 - acc: 0.7317 - val_loss: 0.6862 - val_acc: 0.8123\n",
      "Epoch 437/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8907 - acc: 0.7299\n",
      "Epoch 00437: val_loss did not improve from 0.66862\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8906 - acc: 0.7299 - val_loss: 0.6746 - val_acc: 0.8199\n",
      "Epoch 438/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8986 - acc: 0.7313\n",
      "Epoch 00438: val_loss did not improve from 0.66862\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.8986 - acc: 0.7313 - val_loss: 0.6732 - val_acc: 0.8192\n",
      "Epoch 439/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8973 - acc: 0.7312\n",
      "Epoch 00439: val_loss improved from 0.66862 to 0.66706, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/439-0.6671.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.8972 - acc: 0.7313 - val_loss: 0.6671 - val_acc: 0.8225\n",
      "Epoch 440/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8955 - acc: 0.7349\n",
      "Epoch 00440: val_loss did not improve from 0.66706\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8953 - acc: 0.7349 - val_loss: 0.6738 - val_acc: 0.8195\n",
      "Epoch 441/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8948 - acc: 0.7318\n",
      "Epoch 00441: val_loss did not improve from 0.66706\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.8948 - acc: 0.7318 - val_loss: 0.6751 - val_acc: 0.8211\n",
      "Epoch 442/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8918 - acc: 0.7311\n",
      "Epoch 00442: val_loss did not improve from 0.66706\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.8917 - acc: 0.7312 - val_loss: 0.6840 - val_acc: 0.8169\n",
      "Epoch 443/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8920 - acc: 0.7321\n",
      "Epoch 00443: val_loss did not improve from 0.66706\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.8920 - acc: 0.7322 - val_loss: 0.6723 - val_acc: 0.8227\n",
      "Epoch 444/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8920 - acc: 0.7340\n",
      "Epoch 00444: val_loss did not improve from 0.66706\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8920 - acc: 0.7339 - val_loss: 0.6758 - val_acc: 0.8183\n",
      "Epoch 445/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8955 - acc: 0.7303\n",
      "Epoch 00445: val_loss did not improve from 0.66706\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8956 - acc: 0.7303 - val_loss: 0.6730 - val_acc: 0.8160\n",
      "Epoch 446/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8899 - acc: 0.7328\n",
      "Epoch 00446: val_loss did not improve from 0.66706\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.8899 - acc: 0.7328 - val_loss: 0.6777 - val_acc: 0.8157\n",
      "Epoch 447/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8894 - acc: 0.7318\n",
      "Epoch 00447: val_loss did not improve from 0.66706\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.8895 - acc: 0.7318 - val_loss: 0.6700 - val_acc: 0.8230\n",
      "Epoch 448/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8891 - acc: 0.7344\n",
      "Epoch 00448: val_loss did not improve from 0.66706\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.8890 - acc: 0.7344 - val_loss: 0.6755 - val_acc: 0.8169\n",
      "Epoch 449/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8872 - acc: 0.7319\n",
      "Epoch 00449: val_loss did not improve from 0.66706\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.8873 - acc: 0.7319 - val_loss: 0.6722 - val_acc: 0.8195\n",
      "Epoch 450/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8902 - acc: 0.7349\n",
      "Epoch 00450: val_loss did not improve from 0.66706\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.8902 - acc: 0.7348 - val_loss: 0.6723 - val_acc: 0.8155\n",
      "Epoch 451/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8881 - acc: 0.7316\n",
      "Epoch 00451: val_loss improved from 0.66706 to 0.66439, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/451-0.6644.hdf5\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.8881 - acc: 0.7317 - val_loss: 0.6644 - val_acc: 0.8248\n",
      "Epoch 452/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8827 - acc: 0.7343\n",
      "Epoch 00452: val_loss improved from 0.66439 to 0.66331, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/452-0.6633.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8827 - acc: 0.7343 - val_loss: 0.6633 - val_acc: 0.8216\n",
      "Epoch 453/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8827 - acc: 0.7322\n",
      "Epoch 00453: val_loss did not improve from 0.66331\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8827 - acc: 0.7322 - val_loss: 0.6656 - val_acc: 0.8220\n",
      "Epoch 454/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8923 - acc: 0.7339\n",
      "Epoch 00454: val_loss did not improve from 0.66331\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8923 - acc: 0.7339 - val_loss: 0.7004 - val_acc: 0.8057\n",
      "Epoch 455/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8866 - acc: 0.7327\n",
      "Epoch 00455: val_loss did not improve from 0.66331\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8866 - acc: 0.7327 - val_loss: 0.6667 - val_acc: 0.8218\n",
      "Epoch 456/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8870 - acc: 0.7329\n",
      "Epoch 00456: val_loss did not improve from 0.66331\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8870 - acc: 0.7328 - val_loss: 0.6635 - val_acc: 0.8206\n",
      "Epoch 457/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8842 - acc: 0.7358\n",
      "Epoch 00457: val_loss did not improve from 0.66331\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.8842 - acc: 0.7357 - val_loss: 0.6649 - val_acc: 0.8213\n",
      "Epoch 458/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8823 - acc: 0.7332\n",
      "Epoch 00458: val_loss did not improve from 0.66331\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8823 - acc: 0.7332 - val_loss: 0.6698 - val_acc: 0.8197\n",
      "Epoch 459/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8878 - acc: 0.7345\n",
      "Epoch 00459: val_loss did not improve from 0.66331\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8878 - acc: 0.7345 - val_loss: 0.6647 - val_acc: 0.8216\n",
      "Epoch 460/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8879 - acc: 0.7348\n",
      "Epoch 00460: val_loss did not improve from 0.66331\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.8881 - acc: 0.7348 - val_loss: 0.6684 - val_acc: 0.8206\n",
      "Epoch 461/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8872 - acc: 0.7313\n",
      "Epoch 00461: val_loss did not improve from 0.66331\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.8872 - acc: 0.7313 - val_loss: 0.6682 - val_acc: 0.8206\n",
      "Epoch 462/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8907 - acc: 0.7329\n",
      "Epoch 00462: val_loss improved from 0.66331 to 0.66319, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/462-0.6632.hdf5\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8908 - acc: 0.7328 - val_loss: 0.6632 - val_acc: 0.8239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8854 - acc: 0.7339\n",
      "Epoch 00463: val_loss did not improve from 0.66319\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.8854 - acc: 0.7338 - val_loss: 0.6671 - val_acc: 0.8230\n",
      "Epoch 464/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8818 - acc: 0.7349\n",
      "Epoch 00464: val_loss improved from 0.66319 to 0.66157, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/464-0.6616.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.8820 - acc: 0.7348 - val_loss: 0.6616 - val_acc: 0.8251\n",
      "Epoch 465/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8854 - acc: 0.7349\n",
      "Epoch 00465: val_loss did not improve from 0.66157\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8853 - acc: 0.7349 - val_loss: 0.6689 - val_acc: 0.8202\n",
      "Epoch 466/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8876 - acc: 0.7328\n",
      "Epoch 00466: val_loss did not improve from 0.66157\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.8870 - acc: 0.7330 - val_loss: 0.6629 - val_acc: 0.8239\n",
      "Epoch 467/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8839 - acc: 0.7371\n",
      "Epoch 00467: val_loss did not improve from 0.66157\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8840 - acc: 0.7371 - val_loss: 0.6636 - val_acc: 0.8232\n",
      "Epoch 468/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8867 - acc: 0.7343\n",
      "Epoch 00468: val_loss did not improve from 0.66157\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.8867 - acc: 0.7343 - val_loss: 0.6619 - val_acc: 0.8244\n",
      "Epoch 469/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8911 - acc: 0.7343\n",
      "Epoch 00469: val_loss did not improve from 0.66157\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8911 - acc: 0.7343 - val_loss: 0.6645 - val_acc: 0.8237\n",
      "Epoch 470/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8873 - acc: 0.7367\n",
      "Epoch 00470: val_loss did not improve from 0.66157\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.8873 - acc: 0.7367 - val_loss: 0.6675 - val_acc: 0.8192\n",
      "Epoch 471/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8858 - acc: 0.7356\n",
      "Epoch 00471: val_loss did not improve from 0.66157\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.8859 - acc: 0.7356 - val_loss: 0.6625 - val_acc: 0.8253\n",
      "Epoch 472/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8844 - acc: 0.7357\n",
      "Epoch 00472: val_loss improved from 0.66157 to 0.66143, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/472-0.6614.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8848 - acc: 0.7356 - val_loss: 0.6614 - val_acc: 0.8265\n",
      "Epoch 473/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8816 - acc: 0.7334\n",
      "Epoch 00473: val_loss did not improve from 0.66143\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.8816 - acc: 0.7334 - val_loss: 0.6670 - val_acc: 0.8195\n",
      "Epoch 474/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8755 - acc: 0.7330\n",
      "Epoch 00474: val_loss did not improve from 0.66143\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8757 - acc: 0.7329 - val_loss: 0.6660 - val_acc: 0.8220\n",
      "Epoch 475/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8872 - acc: 0.7349\n",
      "Epoch 00475: val_loss improved from 0.66143 to 0.65653, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/475-0.6565.hdf5\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.8874 - acc: 0.7349 - val_loss: 0.6565 - val_acc: 0.8258\n",
      "Epoch 476/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8859 - acc: 0.7348\n",
      "Epoch 00476: val_loss did not improve from 0.65653\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.8858 - acc: 0.7348 - val_loss: 0.6636 - val_acc: 0.8246\n",
      "Epoch 477/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8766 - acc: 0.7342\n",
      "Epoch 00477: val_loss did not improve from 0.65653\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8768 - acc: 0.7341 - val_loss: 0.6674 - val_acc: 0.8230\n",
      "Epoch 478/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8821 - acc: 0.7355\n",
      "Epoch 00478: val_loss did not improve from 0.65653\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.8823 - acc: 0.7354 - val_loss: 0.6620 - val_acc: 0.8237\n",
      "Epoch 479/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8782 - acc: 0.7348\n",
      "Epoch 00479: val_loss did not improve from 0.65653\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.8781 - acc: 0.7348 - val_loss: 0.6614 - val_acc: 0.8239\n",
      "Epoch 480/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8764 - acc: 0.7355\n",
      "Epoch 00480: val_loss did not improve from 0.65653\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.8764 - acc: 0.7355 - val_loss: 0.6621 - val_acc: 0.8211\n",
      "Epoch 481/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8797 - acc: 0.7362\n",
      "Epoch 00481: val_loss did not improve from 0.65653\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.8797 - acc: 0.7362 - val_loss: 0.6604 - val_acc: 0.8234\n",
      "Epoch 482/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8755 - acc: 0.7381\n",
      "Epoch 00482: val_loss did not improve from 0.65653\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8754 - acc: 0.7381 - val_loss: 0.6749 - val_acc: 0.8174\n",
      "Epoch 483/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8788 - acc: 0.7363\n",
      "Epoch 00483: val_loss did not improve from 0.65653\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.8787 - acc: 0.7364 - val_loss: 0.6633 - val_acc: 0.8216\n",
      "Epoch 484/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8819 - acc: 0.7362\n",
      "Epoch 00484: val_loss did not improve from 0.65653\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.8819 - acc: 0.7362 - val_loss: 0.6613 - val_acc: 0.8265\n",
      "Epoch 485/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8711 - acc: 0.7356\n",
      "Epoch 00485: val_loss improved from 0.65653 to 0.65545, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/485-0.6555.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8711 - acc: 0.7356 - val_loss: 0.6555 - val_acc: 0.8253\n",
      "Epoch 486/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8836 - acc: 0.7364\n",
      "Epoch 00486: val_loss did not improve from 0.65545\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.8837 - acc: 0.7364 - val_loss: 0.6710 - val_acc: 0.8181\n",
      "Epoch 487/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8802 - acc: 0.7339\n",
      "Epoch 00487: val_loss did not improve from 0.65545\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8802 - acc: 0.7338 - val_loss: 0.6665 - val_acc: 0.8213\n",
      "Epoch 488/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8816 - acc: 0.7354\n",
      "Epoch 00488: val_loss did not improve from 0.65545\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.8812 - acc: 0.7355 - val_loss: 0.6558 - val_acc: 0.8274\n",
      "Epoch 489/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8817 - acc: 0.7343\n",
      "Epoch 00489: val_loss did not improve from 0.65545\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.8816 - acc: 0.7343 - val_loss: 0.6653 - val_acc: 0.8204\n",
      "Epoch 490/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8811 - acc: 0.7356\n",
      "Epoch 00490: val_loss improved from 0.65545 to 0.65278, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/490-0.6528.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.8810 - acc: 0.7356 - val_loss: 0.6528 - val_acc: 0.8241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8805 - acc: 0.7360\n",
      "Epoch 00491: val_loss did not improve from 0.65278\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.8805 - acc: 0.7360 - val_loss: 0.6619 - val_acc: 0.8213\n",
      "Epoch 492/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8815 - acc: 0.7354\n",
      "Epoch 00492: val_loss did not improve from 0.65278\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.8816 - acc: 0.7354 - val_loss: 0.6646 - val_acc: 0.8192\n",
      "Epoch 493/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8799 - acc: 0.7340\n",
      "Epoch 00493: val_loss improved from 0.65278 to 0.65259, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_3_conv_checkpoint/493-0.6526.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.8798 - acc: 0.7340 - val_loss: 0.6526 - val_acc: 0.8258\n",
      "Epoch 494/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8775 - acc: 0.7349\n",
      "Epoch 00494: val_loss did not improve from 0.65259\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.8775 - acc: 0.7348 - val_loss: 0.6574 - val_acc: 0.8227\n",
      "Epoch 495/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8760 - acc: 0.7378\n",
      "Epoch 00495: val_loss did not improve from 0.65259\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.8759 - acc: 0.7378 - val_loss: 0.6595 - val_acc: 0.8234\n",
      "Epoch 496/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8737 - acc: 0.7374\n",
      "Epoch 00496: val_loss did not improve from 0.65259\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.8737 - acc: 0.7374 - val_loss: 0.6556 - val_acc: 0.8262\n",
      "Epoch 497/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8804 - acc: 0.7362\n",
      "Epoch 00497: val_loss did not improve from 0.65259\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.8806 - acc: 0.7362 - val_loss: 0.6629 - val_acc: 0.8241\n",
      "Epoch 498/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8773 - acc: 0.7369\n",
      "Epoch 00498: val_loss did not improve from 0.65259\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.8773 - acc: 0.7369 - val_loss: 0.6581 - val_acc: 0.8246\n",
      "Epoch 499/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8733 - acc: 0.7377\n",
      "Epoch 00499: val_loss did not improve from 0.65259\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.8733 - acc: 0.7376 - val_loss: 0.6579 - val_acc: 0.8225\n",
      "Epoch 500/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8807 - acc: 0.7367\n",
      "Epoch 00500: val_loss did not improve from 0.65259\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.8806 - acc: 0.7367 - val_loss: 0.6634 - val_acc: 0.8192\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 364us/sample - loss: 0.7133 - acc: 0.7884\n",
      "Loss: 0.7133490382944189 Accuracy: 0.78836966\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6791 - acc: 0.1231\n",
      "Epoch 00001: val_loss improved from inf to 2.48872, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/001-2.4887.hdf5\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 2.6791 - acc: 0.1231 - val_loss: 2.4887 - val_acc: 0.2360\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.3530 - acc: 0.2358\n",
      "Epoch 00002: val_loss improved from 2.48872 to 2.11616, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/002-2.1162.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 2.3528 - acc: 0.2358 - val_loss: 2.1162 - val_acc: 0.3515\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1403 - acc: 0.2907\n",
      "Epoch 00003: val_loss improved from 2.11616 to 1.94023, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/003-1.9402.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 2.1402 - acc: 0.2907 - val_loss: 1.9402 - val_acc: 0.3944\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0213 - acc: 0.3239\n",
      "Epoch 00004: val_loss improved from 1.94023 to 1.82797, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/004-1.8280.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 2.0213 - acc: 0.3239 - val_loss: 1.8280 - val_acc: 0.4365\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.9461 - acc: 0.3496\n",
      "Epoch 00005: val_loss improved from 1.82797 to 1.75917, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/005-1.7592.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 1.9459 - acc: 0.3495 - val_loss: 1.7592 - val_acc: 0.4461\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.8756 - acc: 0.3734\n",
      "Epoch 00006: val_loss improved from 1.75917 to 1.68480, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/006-1.6848.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 1.8751 - acc: 0.3737 - val_loss: 1.6848 - val_acc: 0.4778\n",
      "Epoch 7/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.8230 - acc: 0.3905\n",
      "Epoch 00007: val_loss improved from 1.68480 to 1.63424, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/007-1.6342.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 1.8235 - acc: 0.3905 - val_loss: 1.6342 - val_acc: 0.4976\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7712 - acc: 0.4096\n",
      "Epoch 00008: val_loss improved from 1.63424 to 1.58313, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/008-1.5831.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 1.7713 - acc: 0.4096 - val_loss: 1.5831 - val_acc: 0.5199\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7215 - acc: 0.4312\n",
      "Epoch 00009: val_loss improved from 1.58313 to 1.53021, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/009-1.5302.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 1.7215 - acc: 0.4312 - val_loss: 1.5302 - val_acc: 0.5423\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6831 - acc: 0.4433\n",
      "Epoch 00010: val_loss improved from 1.53021 to 1.48984, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/010-1.4898.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 1.6833 - acc: 0.4433 - val_loss: 1.4898 - val_acc: 0.5639\n",
      "Epoch 11/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6447 - acc: 0.4599\n",
      "Epoch 00011: val_loss improved from 1.48984 to 1.43994, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/011-1.4399.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 1.6452 - acc: 0.4599 - val_loss: 1.4399 - val_acc: 0.5749\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6067 - acc: 0.4746\n",
      "Epoch 00012: val_loss improved from 1.43994 to 1.40753, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/012-1.4075.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 1.6066 - acc: 0.4748 - val_loss: 1.4075 - val_acc: 0.5809\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5750 - acc: 0.4862\n",
      "Epoch 00013: val_loss improved from 1.40753 to 1.36431, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/013-1.3643.hdf5\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 1.5752 - acc: 0.4862 - val_loss: 1.3643 - val_acc: 0.5919\n",
      "Epoch 14/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5523 - acc: 0.4926\n",
      "Epoch 00014: val_loss improved from 1.36431 to 1.35050, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/014-1.3505.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 1.5527 - acc: 0.4923 - val_loss: 1.3505 - val_acc: 0.5954\n",
      "Epoch 15/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5192 - acc: 0.5029\n",
      "Epoch 00015: val_loss improved from 1.35050 to 1.31135, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/015-1.3113.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 1.5189 - acc: 0.5031 - val_loss: 1.3113 - val_acc: 0.6096\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4995 - acc: 0.5133\n",
      "Epoch 00016: val_loss improved from 1.31135 to 1.29815, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/016-1.2982.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.4995 - acc: 0.5132 - val_loss: 1.2982 - val_acc: 0.6117\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4701 - acc: 0.5222\n",
      "Epoch 00017: val_loss improved from 1.29815 to 1.27304, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/017-1.2730.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 1.4702 - acc: 0.5221 - val_loss: 1.2730 - val_acc: 0.6173\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4466 - acc: 0.5329\n",
      "Epoch 00018: val_loss improved from 1.27304 to 1.25006, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/018-1.2501.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 1.4464 - acc: 0.5329 - val_loss: 1.2501 - val_acc: 0.6222\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4282 - acc: 0.5410\n",
      "Epoch 00019: val_loss improved from 1.25006 to 1.22611, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/019-1.2261.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 1.4282 - acc: 0.5410 - val_loss: 1.2261 - val_acc: 0.6317\n",
      "Epoch 20/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4130 - acc: 0.5470\n",
      "Epoch 00020: val_loss improved from 1.22611 to 1.20486, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/020-1.2049.hdf5\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 1.4128 - acc: 0.5471 - val_loss: 1.2049 - val_acc: 0.6450\n",
      "Epoch 21/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3923 - acc: 0.5541\n",
      "Epoch 00021: val_loss improved from 1.20486 to 1.19728, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/021-1.1973.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.3921 - acc: 0.5541 - val_loss: 1.1973 - val_acc: 0.6399\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3733 - acc: 0.5644\n",
      "Epoch 00022: val_loss improved from 1.19728 to 1.17378, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/022-1.1738.hdf5\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 1.3730 - acc: 0.5645 - val_loss: 1.1738 - val_acc: 0.6534\n",
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3564 - acc: 0.5676\n",
      "Epoch 00023: val_loss improved from 1.17378 to 1.14696, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/023-1.1470.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 1.3568 - acc: 0.5676 - val_loss: 1.1470 - val_acc: 0.6627\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3415 - acc: 0.5745\n",
      "Epoch 00024: val_loss improved from 1.14696 to 1.13450, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/024-1.1345.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 1.3411 - acc: 0.5747 - val_loss: 1.1345 - val_acc: 0.6639\n",
      "Epoch 25/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3207 - acc: 0.5806\n",
      "Epoch 00025: val_loss improved from 1.13450 to 1.12456, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/025-1.1246.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 1.3208 - acc: 0.5804 - val_loss: 1.1246 - val_acc: 0.6678\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3080 - acc: 0.5876\n",
      "Epoch 00026: val_loss improved from 1.12456 to 1.10610, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/026-1.1061.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 1.3081 - acc: 0.5873 - val_loss: 1.1061 - val_acc: 0.6734\n",
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2893 - acc: 0.5921\n",
      "Epoch 00027: val_loss did not improve from 1.10610\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.2892 - acc: 0.5921 - val_loss: 1.1218 - val_acc: 0.6681\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2832 - acc: 0.5973\n",
      "Epoch 00028: val_loss improved from 1.10610 to 1.08392, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/028-1.0839.hdf5\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 1.2831 - acc: 0.5973 - val_loss: 1.0839 - val_acc: 0.6792\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2733 - acc: 0.6012\n",
      "Epoch 00029: val_loss improved from 1.08392 to 1.07838, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/029-1.0784.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.2736 - acc: 0.6012 - val_loss: 1.0784 - val_acc: 0.6797\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2547 - acc: 0.6089\n",
      "Epoch 00030: val_loss improved from 1.07838 to 1.05635, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/030-1.0564.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.2546 - acc: 0.6088 - val_loss: 1.0564 - val_acc: 0.6865\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2504 - acc: 0.6097\n",
      "Epoch 00031: val_loss improved from 1.05635 to 1.04918, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/031-1.0492.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.2504 - acc: 0.6097 - val_loss: 1.0492 - val_acc: 0.6883\n",
      "Epoch 32/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2431 - acc: 0.6119\n",
      "Epoch 00032: val_loss improved from 1.04918 to 1.03221, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/032-1.0322.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.2429 - acc: 0.6120 - val_loss: 1.0322 - val_acc: 0.6916\n",
      "Epoch 33/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2254 - acc: 0.6186\n",
      "Epoch 00033: val_loss improved from 1.03221 to 1.02548, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/033-1.0255.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.2254 - acc: 0.6187 - val_loss: 1.0255 - val_acc: 0.6932\n",
      "Epoch 34/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2136 - acc: 0.6185\n",
      "Epoch 00034: val_loss improved from 1.02548 to 1.01264, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/034-1.0126.hdf5\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 1.2132 - acc: 0.6187 - val_loss: 1.0126 - val_acc: 0.6965\n",
      "Epoch 35/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2055 - acc: 0.6241\n",
      "Epoch 00035: val_loss improved from 1.01264 to 0.99735, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/035-0.9974.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.2055 - acc: 0.6243 - val_loss: 0.9974 - val_acc: 0.7072\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1932 - acc: 0.6281\n",
      "Epoch 00036: val_loss did not improve from 0.99735\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.1931 - acc: 0.6281 - val_loss: 1.0004 - val_acc: 0.7044\n",
      "Epoch 37/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1778 - acc: 0.6285\n",
      "Epoch 00037: val_loss improved from 0.99735 to 0.97562, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/037-0.9756.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.1779 - acc: 0.6285 - val_loss: 0.9756 - val_acc: 0.7126\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1718 - acc: 0.6328\n",
      "Epoch 00038: val_loss did not improve from 0.97562\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.1724 - acc: 0.6327 - val_loss: 0.9800 - val_acc: 0.7065\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1628 - acc: 0.6361\n",
      "Epoch 00039: val_loss improved from 0.97562 to 0.96707, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/039-0.9671.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.1628 - acc: 0.6361 - val_loss: 0.9671 - val_acc: 0.7081\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1624 - acc: 0.6370\n",
      "Epoch 00040: val_loss did not improve from 0.96707\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.1629 - acc: 0.6369 - val_loss: 0.9950 - val_acc: 0.7007\n",
      "Epoch 41/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1506 - acc: 0.6408\n",
      "Epoch 00041: val_loss improved from 0.96707 to 0.95873, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/041-0.9587.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.1505 - acc: 0.6408 - val_loss: 0.9587 - val_acc: 0.7130\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1393 - acc: 0.6455\n",
      "Epoch 00042: val_loss improved from 0.95873 to 0.94183, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/042-0.9418.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.1397 - acc: 0.6454 - val_loss: 0.9418 - val_acc: 0.7216\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1266 - acc: 0.6490\n",
      "Epoch 00043: val_loss improved from 0.94183 to 0.94102, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/043-0.9410.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.1270 - acc: 0.6487 - val_loss: 0.9410 - val_acc: 0.7154\n",
      "Epoch 44/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1273 - acc: 0.6526\n",
      "Epoch 00044: val_loss improved from 0.94102 to 0.92067, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/044-0.9207.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.1273 - acc: 0.6526 - val_loss: 0.9207 - val_acc: 0.7300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1166 - acc: 0.6517\n",
      "Epoch 00045: val_loss improved from 0.92067 to 0.91858, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/045-0.9186.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.1165 - acc: 0.6517 - val_loss: 0.9186 - val_acc: 0.7261\n",
      "Epoch 46/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1088 - acc: 0.6569\n",
      "Epoch 00046: val_loss improved from 0.91858 to 0.91354, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/046-0.9135.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.1084 - acc: 0.6570 - val_loss: 0.9135 - val_acc: 0.7268\n",
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1017 - acc: 0.6580\n",
      "Epoch 00047: val_loss improved from 0.91354 to 0.90042, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/047-0.9004.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.1021 - acc: 0.6578 - val_loss: 0.9004 - val_acc: 0.7324\n",
      "Epoch 48/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0994 - acc: 0.6602\n",
      "Epoch 00048: val_loss improved from 0.90042 to 0.89292, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/048-0.8929.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0990 - acc: 0.6603 - val_loss: 0.8929 - val_acc: 0.7365\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0907 - acc: 0.6629\n",
      "Epoch 00049: val_loss improved from 0.89292 to 0.88679, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/049-0.8868.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0906 - acc: 0.6629 - val_loss: 0.8868 - val_acc: 0.7347\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0841 - acc: 0.6635\n",
      "Epoch 00050: val_loss improved from 0.88679 to 0.88134, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/050-0.8813.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0841 - acc: 0.6635 - val_loss: 0.8813 - val_acc: 0.7414\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0792 - acc: 0.6684\n",
      "Epoch 00051: val_loss improved from 0.88134 to 0.87649, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/051-0.8765.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.0792 - acc: 0.6684 - val_loss: 0.8765 - val_acc: 0.7414\n",
      "Epoch 52/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0691 - acc: 0.6705\n",
      "Epoch 00052: val_loss improved from 0.87649 to 0.87566, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/052-0.8757.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.0690 - acc: 0.6706 - val_loss: 0.8757 - val_acc: 0.7428\n",
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0697 - acc: 0.6704\n",
      "Epoch 00053: val_loss improved from 0.87566 to 0.87268, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/053-0.8727.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0697 - acc: 0.6703 - val_loss: 0.8727 - val_acc: 0.7424\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0569 - acc: 0.6728\n",
      "Epoch 00054: val_loss did not improve from 0.87268\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 1.0569 - acc: 0.6728 - val_loss: 0.8878 - val_acc: 0.7354\n",
      "Epoch 55/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0591 - acc: 0.6731\n",
      "Epoch 00055: val_loss improved from 0.87268 to 0.85996, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/055-0.8600.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0590 - acc: 0.6731 - val_loss: 0.8600 - val_acc: 0.7477\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0500 - acc: 0.6774\n",
      "Epoch 00056: val_loss improved from 0.85996 to 0.84900, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/056-0.8490.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.0500 - acc: 0.6774 - val_loss: 0.8490 - val_acc: 0.7480\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0398 - acc: 0.6803\n",
      "Epoch 00057: val_loss did not improve from 0.84900\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 1.0397 - acc: 0.6803 - val_loss: 0.8549 - val_acc: 0.7468\n",
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0308 - acc: 0.6827\n",
      "Epoch 00058: val_loss improved from 0.84900 to 0.84145, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/058-0.8415.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.0305 - acc: 0.6828 - val_loss: 0.8415 - val_acc: 0.7512\n",
      "Epoch 59/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0344 - acc: 0.6798\n",
      "Epoch 00059: val_loss improved from 0.84145 to 0.83713, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/059-0.8371.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0337 - acc: 0.6800 - val_loss: 0.8371 - val_acc: 0.7545\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0306 - acc: 0.6844\n",
      "Epoch 00060: val_loss did not improve from 0.83713\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 1.0300 - acc: 0.6846 - val_loss: 0.8468 - val_acc: 0.7473\n",
      "Epoch 61/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0196 - acc: 0.6845\n",
      "Epoch 00061: val_loss improved from 0.83713 to 0.82752, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/061-0.8275.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 1.0197 - acc: 0.6845 - val_loss: 0.8275 - val_acc: 0.7547\n",
      "Epoch 62/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0190 - acc: 0.6882\n",
      "Epoch 00062: val_loss did not improve from 0.82752\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.0193 - acc: 0.6881 - val_loss: 0.8340 - val_acc: 0.7584\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0141 - acc: 0.6913\n",
      "Epoch 00063: val_loss improved from 0.82752 to 0.81386, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/063-0.8139.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 1.0143 - acc: 0.6913 - val_loss: 0.8139 - val_acc: 0.7626\n",
      "Epoch 64/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0096 - acc: 0.6913\n",
      "Epoch 00064: val_loss did not improve from 0.81386\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 1.0095 - acc: 0.6913 - val_loss: 0.8143 - val_acc: 0.7596\n",
      "Epoch 65/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0086 - acc: 0.6915\n",
      "Epoch 00065: val_loss improved from 0.81386 to 0.80918, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/065-0.8092.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 1.0083 - acc: 0.6914 - val_loss: 0.8092 - val_acc: 0.7577\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0060 - acc: 0.6890\n",
      "Epoch 00066: val_loss did not improve from 0.80918\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0059 - acc: 0.6892 - val_loss: 0.8115 - val_acc: 0.7631\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9942 - acc: 0.6973\n",
      "Epoch 00067: val_loss did not improve from 0.80918\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.9943 - acc: 0.6973 - val_loss: 0.8111 - val_acc: 0.7601\n",
      "Epoch 68/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9946 - acc: 0.6956\n",
      "Epoch 00068: val_loss improved from 0.80918 to 0.80562, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/068-0.8056.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.9948 - acc: 0.6954 - val_loss: 0.8056 - val_acc: 0.7605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9878 - acc: 0.6985\n",
      "Epoch 00069: val_loss improved from 0.80562 to 0.78799, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/069-0.7880.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.9873 - acc: 0.6985 - val_loss: 0.7880 - val_acc: 0.7703\n",
      "Epoch 70/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9830 - acc: 0.6995\n",
      "Epoch 00070: val_loss did not improve from 0.78799\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9831 - acc: 0.6996 - val_loss: 0.7897 - val_acc: 0.7673\n",
      "Epoch 71/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9778 - acc: 0.7009\n",
      "Epoch 00071: val_loss improved from 0.78799 to 0.78393, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/071-0.7839.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.9782 - acc: 0.7007 - val_loss: 0.7839 - val_acc: 0.7745\n",
      "Epoch 72/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9763 - acc: 0.7011\n",
      "Epoch 00072: val_loss did not improve from 0.78393\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.9762 - acc: 0.7011 - val_loss: 0.7862 - val_acc: 0.7729\n",
      "Epoch 73/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9761 - acc: 0.7039\n",
      "Epoch 00073: val_loss improved from 0.78393 to 0.76864, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/073-0.7686.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.9762 - acc: 0.7037 - val_loss: 0.7686 - val_acc: 0.7815\n",
      "Epoch 74/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9732 - acc: 0.7074\n",
      "Epoch 00074: val_loss did not improve from 0.76864\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9734 - acc: 0.7073 - val_loss: 0.7751 - val_acc: 0.7766\n",
      "Epoch 75/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9635 - acc: 0.7063\n",
      "Epoch 00075: val_loss did not improve from 0.76864\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9632 - acc: 0.7065 - val_loss: 0.7749 - val_acc: 0.7773\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9650 - acc: 0.7031\n",
      "Epoch 00076: val_loss did not improve from 0.76864\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.9650 - acc: 0.7031 - val_loss: 0.7708 - val_acc: 0.7806\n",
      "Epoch 77/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9628 - acc: 0.7082\n",
      "Epoch 00077: val_loss did not improve from 0.76864\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.9631 - acc: 0.7083 - val_loss: 0.7701 - val_acc: 0.7773\n",
      "Epoch 78/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9608 - acc: 0.7061\n",
      "Epoch 00078: val_loss improved from 0.76864 to 0.76086, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/078-0.7609.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.9606 - acc: 0.7062 - val_loss: 0.7609 - val_acc: 0.7820\n",
      "Epoch 79/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9506 - acc: 0.7083\n",
      "Epoch 00079: val_loss did not improve from 0.76086\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.9504 - acc: 0.7083 - val_loss: 0.7642 - val_acc: 0.7759\n",
      "Epoch 80/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9506 - acc: 0.7119- ETA: 1s - loss: 0.9518\n",
      "Epoch 00080: val_loss improved from 0.76086 to 0.74997, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/080-0.7500.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9505 - acc: 0.7119 - val_loss: 0.7500 - val_acc: 0.7827\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9398 - acc: 0.7161\n",
      "Epoch 00081: val_loss did not improve from 0.74997\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.9399 - acc: 0.7160 - val_loss: 0.7545 - val_acc: 0.7855\n",
      "Epoch 82/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9442 - acc: 0.7142\n",
      "Epoch 00082: val_loss did not improve from 0.74997\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.9442 - acc: 0.7142 - val_loss: 0.7531 - val_acc: 0.7869\n",
      "Epoch 83/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9449 - acc: 0.7158\n",
      "Epoch 00083: val_loss did not improve from 0.74997\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.9445 - acc: 0.7159 - val_loss: 0.7560 - val_acc: 0.7813\n",
      "Epoch 84/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9348 - acc: 0.7208\n",
      "Epoch 00084: val_loss did not improve from 0.74997\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.9346 - acc: 0.7208 - val_loss: 0.7502 - val_acc: 0.7850\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9357 - acc: 0.7144\n",
      "Epoch 00085: val_loss improved from 0.74997 to 0.73868, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/085-0.7387.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.9357 - acc: 0.7144 - val_loss: 0.7387 - val_acc: 0.7883\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9235 - acc: 0.7205\n",
      "Epoch 00086: val_loss improved from 0.73868 to 0.73412, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/086-0.7341.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.9234 - acc: 0.7206 - val_loss: 0.7341 - val_acc: 0.7908\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9295 - acc: 0.7198\n",
      "Epoch 00087: val_loss did not improve from 0.73412\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9295 - acc: 0.7198 - val_loss: 0.7424 - val_acc: 0.7892\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9197 - acc: 0.7211\n",
      "Epoch 00088: val_loss improved from 0.73412 to 0.72370, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/088-0.7237.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.9196 - acc: 0.7211 - val_loss: 0.7237 - val_acc: 0.8013\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9179 - acc: 0.7224\n",
      "Epoch 00089: val_loss did not improve from 0.72370\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.9180 - acc: 0.7224 - val_loss: 0.7334 - val_acc: 0.7911\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9237 - acc: 0.7235\n",
      "Epoch 00090: val_loss did not improve from 0.72370\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.9237 - acc: 0.7235 - val_loss: 0.7258 - val_acc: 0.7936\n",
      "Epoch 91/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9220 - acc: 0.7214\n",
      "Epoch 00091: val_loss did not improve from 0.72370\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.9222 - acc: 0.7213 - val_loss: 0.7306 - val_acc: 0.7966\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9130 - acc: 0.7238\n",
      "Epoch 00092: val_loss did not improve from 0.72370\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.9129 - acc: 0.7239 - val_loss: 0.7245 - val_acc: 0.7918\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9092 - acc: 0.7251\n",
      "Epoch 00093: val_loss did not improve from 0.72370\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.9092 - acc: 0.7251 - val_loss: 0.7247 - val_acc: 0.7936\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9100 - acc: 0.7261\n",
      "Epoch 00094: val_loss improved from 0.72370 to 0.72029, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/094-0.7203.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.9100 - acc: 0.7261 - val_loss: 0.7203 - val_acc: 0.7978\n",
      "Epoch 95/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9048 - acc: 0.7268\n",
      "Epoch 00095: val_loss did not improve from 0.72029\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.9048 - acc: 0.7268 - val_loss: 0.7215 - val_acc: 0.7959\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8968 - acc: 0.7290\n",
      "Epoch 00096: val_loss improved from 0.72029 to 0.71180, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/096-0.7118.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.8969 - acc: 0.7290 - val_loss: 0.7118 - val_acc: 0.7976\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9014 - acc: 0.7255\n",
      "Epoch 00097: val_loss did not improve from 0.71180\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9013 - acc: 0.7255 - val_loss: 0.7127 - val_acc: 0.7994\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8930 - acc: 0.7289\n",
      "Epoch 00098: val_loss improved from 0.71180 to 0.70659, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/098-0.7066.hdf5\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.8930 - acc: 0.7289 - val_loss: 0.7066 - val_acc: 0.7987\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8936 - acc: 0.7308\n",
      "Epoch 00099: val_loss did not improve from 0.70659\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.8939 - acc: 0.7307 - val_loss: 0.7085 - val_acc: 0.8029\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8976 - acc: 0.7304\n",
      "Epoch 00100: val_loss improved from 0.70659 to 0.69804, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/100-0.6980.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.8975 - acc: 0.7304 - val_loss: 0.6980 - val_acc: 0.8064\n",
      "Epoch 101/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8878 - acc: 0.7314\n",
      "Epoch 00101: val_loss did not improve from 0.69804\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.8876 - acc: 0.7314 - val_loss: 0.7041 - val_acc: 0.8018\n",
      "Epoch 102/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8881 - acc: 0.7335\n",
      "Epoch 00102: val_loss did not improve from 0.69804\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.8879 - acc: 0.7335 - val_loss: 0.7029 - val_acc: 0.8032\n",
      "Epoch 103/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8813 - acc: 0.7356\n",
      "Epoch 00103: val_loss improved from 0.69804 to 0.69295, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/103-0.6929.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.8816 - acc: 0.7356 - val_loss: 0.6929 - val_acc: 0.8067\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8809 - acc: 0.7342\n",
      "Epoch 00104: val_loss improved from 0.69295 to 0.68761, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/104-0.6876.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.8809 - acc: 0.7342 - val_loss: 0.6876 - val_acc: 0.8116\n",
      "Epoch 105/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8749 - acc: 0.7362\n",
      "Epoch 00105: val_loss improved from 0.68761 to 0.68340, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/105-0.6834.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.8745 - acc: 0.7364 - val_loss: 0.6834 - val_acc: 0.8111\n",
      "Epoch 106/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8812 - acc: 0.7350- ETA: 2s - l\n",
      "Epoch 00106: val_loss did not improve from 0.68340\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.8809 - acc: 0.7351 - val_loss: 0.6912 - val_acc: 0.8041\n",
      "Epoch 107/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8730 - acc: 0.7378\n",
      "Epoch 00107: val_loss did not improve from 0.68340\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.8731 - acc: 0.7378 - val_loss: 0.6861 - val_acc: 0.8111\n",
      "Epoch 108/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8726 - acc: 0.7404\n",
      "Epoch 00108: val_loss improved from 0.68340 to 0.67630, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/108-0.6763.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.8720 - acc: 0.7405 - val_loss: 0.6763 - val_acc: 0.8095\n",
      "Epoch 109/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8652 - acc: 0.7398\n",
      "Epoch 00109: val_loss did not improve from 0.67630\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.8657 - acc: 0.7397 - val_loss: 0.6792 - val_acc: 0.8181\n",
      "Epoch 110/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8627 - acc: 0.7409\n",
      "Epoch 00110: val_loss did not improve from 0.67630\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.8627 - acc: 0.7408 - val_loss: 0.6859 - val_acc: 0.8125\n",
      "Epoch 111/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8614 - acc: 0.7396\n",
      "Epoch 00111: val_loss did not improve from 0.67630\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.8608 - acc: 0.7399 - val_loss: 0.6769 - val_acc: 0.8120\n",
      "Epoch 112/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8606 - acc: 0.7404\n",
      "Epoch 00112: val_loss improved from 0.67630 to 0.66667, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/112-0.6667.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.8602 - acc: 0.7405 - val_loss: 0.6667 - val_acc: 0.8176\n",
      "Epoch 113/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8581 - acc: 0.7429\n",
      "Epoch 00113: val_loss did not improve from 0.66667\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.8582 - acc: 0.7428 - val_loss: 0.6860 - val_acc: 0.8083\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8565 - acc: 0.7423\n",
      "Epoch 00114: val_loss did not improve from 0.66667\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.8565 - acc: 0.7423 - val_loss: 0.6811 - val_acc: 0.8160\n",
      "Epoch 115/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8540 - acc: 0.7438\n",
      "Epoch 00115: val_loss did not improve from 0.66667\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.8540 - acc: 0.7437 - val_loss: 0.6698 - val_acc: 0.8185\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8506 - acc: 0.7456\n",
      "Epoch 00116: val_loss did not improve from 0.66667\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.8507 - acc: 0.7456 - val_loss: 0.6726 - val_acc: 0.8157\n",
      "Epoch 117/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8511 - acc: 0.7444\n",
      "Epoch 00117: val_loss improved from 0.66667 to 0.66238, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/117-0.6624.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.8510 - acc: 0.7445 - val_loss: 0.6624 - val_acc: 0.8192\n",
      "Epoch 118/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8541 - acc: 0.7431\n",
      "Epoch 00118: val_loss did not improve from 0.66238\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.8539 - acc: 0.7432 - val_loss: 0.6668 - val_acc: 0.8176\n",
      "Epoch 119/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8465 - acc: 0.7476\n",
      "Epoch 00119: val_loss did not improve from 0.66238\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.8466 - acc: 0.7475 - val_loss: 0.6698 - val_acc: 0.8164\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8431 - acc: 0.7480\n",
      "Epoch 00120: val_loss did not improve from 0.66238\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.8431 - acc: 0.7480 - val_loss: 0.6744 - val_acc: 0.8178\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8391 - acc: 0.7482\n",
      "Epoch 00121: val_loss did not improve from 0.66238\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.8398 - acc: 0.7481 - val_loss: 0.6675 - val_acc: 0.8155\n",
      "Epoch 122/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8445 - acc: 0.7468\n",
      "Epoch 00122: val_loss did not improve from 0.66238\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.8450 - acc: 0.7467 - val_loss: 0.6752 - val_acc: 0.8143\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8335 - acc: 0.7490\n",
      "Epoch 00123: val_loss improved from 0.66238 to 0.65415, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/123-0.6541.hdf5\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.8335 - acc: 0.7490 - val_loss: 0.6541 - val_acc: 0.8265\n",
      "Epoch 124/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8415 - acc: 0.7487\n",
      "Epoch 00124: val_loss did not improve from 0.65415\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.8412 - acc: 0.7487 - val_loss: 0.6618 - val_acc: 0.8146\n",
      "Epoch 125/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8393 - acc: 0.7495\n",
      "Epoch 00125: val_loss did not improve from 0.65415\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.8394 - acc: 0.7494 - val_loss: 0.6606 - val_acc: 0.8213\n",
      "Epoch 126/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8381 - acc: 0.7500\n",
      "Epoch 00126: val_loss did not improve from 0.65415\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.8388 - acc: 0.7497 - val_loss: 0.6637 - val_acc: 0.8167\n",
      "Epoch 127/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8353 - acc: 0.7496\n",
      "Epoch 00127: val_loss improved from 0.65415 to 0.65328, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/127-0.6533.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.8351 - acc: 0.7497 - val_loss: 0.6533 - val_acc: 0.8204\n",
      "Epoch 128/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8256 - acc: 0.7540\n",
      "Epoch 00128: val_loss improved from 0.65328 to 0.64865, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/128-0.6487.hdf5\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.8254 - acc: 0.7541 - val_loss: 0.6487 - val_acc: 0.8234\n",
      "Epoch 129/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8265 - acc: 0.7533\n",
      "Epoch 00129: val_loss improved from 0.64865 to 0.64763, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/129-0.6476.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.8268 - acc: 0.7532 - val_loss: 0.6476 - val_acc: 0.8183\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8221 - acc: 0.7566\n",
      "Epoch 00130: val_loss improved from 0.64763 to 0.64049, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/130-0.6405.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.8220 - acc: 0.7566 - val_loss: 0.6405 - val_acc: 0.8248\n",
      "Epoch 131/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8187 - acc: 0.7556\n",
      "Epoch 00131: val_loss improved from 0.64049 to 0.63937, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/131-0.6394.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.8186 - acc: 0.7556 - val_loss: 0.6394 - val_acc: 0.8239\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8229 - acc: 0.7542\n",
      "Epoch 00132: val_loss did not improve from 0.63937\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.8229 - acc: 0.7542 - val_loss: 0.6410 - val_acc: 0.8218\n",
      "Epoch 133/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8182 - acc: 0.7556\n",
      "Epoch 00133: val_loss improved from 0.63937 to 0.63901, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/133-0.6390.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.8182 - acc: 0.7556 - val_loss: 0.6390 - val_acc: 0.8295\n",
      "Epoch 134/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8194 - acc: 0.7551\n",
      "Epoch 00134: val_loss improved from 0.63901 to 0.63638, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/134-0.6364.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.8195 - acc: 0.7551 - val_loss: 0.6364 - val_acc: 0.8262\n",
      "Epoch 135/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8145 - acc: 0.7573\n",
      "Epoch 00135: val_loss did not improve from 0.63638\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.8146 - acc: 0.7572 - val_loss: 0.6367 - val_acc: 0.8293\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8175 - acc: 0.7551\n",
      "Epoch 00136: val_loss did not improve from 0.63638\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.8174 - acc: 0.7551 - val_loss: 0.6418 - val_acc: 0.8267\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8100 - acc: 0.7573\n",
      "Epoch 00137: val_loss improved from 0.63638 to 0.62777, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/137-0.6278.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.8100 - acc: 0.7573 - val_loss: 0.6278 - val_acc: 0.8346\n",
      "Epoch 138/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8122 - acc: 0.7579\n",
      "Epoch 00138: val_loss did not improve from 0.62777\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.8123 - acc: 0.7578 - val_loss: 0.6299 - val_acc: 0.8269\n",
      "Epoch 139/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8115 - acc: 0.7604\n",
      "Epoch 00139: val_loss did not improve from 0.62777\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.8120 - acc: 0.7602 - val_loss: 0.6424 - val_acc: 0.8265\n",
      "Epoch 140/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8054 - acc: 0.7603\n",
      "Epoch 00140: val_loss did not improve from 0.62777\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.8053 - acc: 0.7604 - val_loss: 0.6426 - val_acc: 0.8295\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8080 - acc: 0.7606\n",
      "Epoch 00141: val_loss did not improve from 0.62777\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.8079 - acc: 0.7606 - val_loss: 0.6335 - val_acc: 0.8300\n",
      "Epoch 142/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8134 - acc: 0.7560\n",
      "Epoch 00142: val_loss improved from 0.62777 to 0.62602, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/142-0.6260.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.8137 - acc: 0.7559 - val_loss: 0.6260 - val_acc: 0.8297\n",
      "Epoch 143/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8031 - acc: 0.7626\n",
      "Epoch 00143: val_loss improved from 0.62602 to 0.62157, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/143-0.6216.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.8032 - acc: 0.7627 - val_loss: 0.6216 - val_acc: 0.8334\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7971 - acc: 0.7628\n",
      "Epoch 00144: val_loss did not improve from 0.62157\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7970 - acc: 0.7628 - val_loss: 0.6290 - val_acc: 0.8297\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8021 - acc: 0.7609\n",
      "Epoch 00145: val_loss improved from 0.62157 to 0.61898, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/145-0.6190.hdf5\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 0.8020 - acc: 0.7609 - val_loss: 0.6190 - val_acc: 0.8358\n",
      "Epoch 146/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8007 - acc: 0.7629\n",
      "Epoch 00146: val_loss improved from 0.61898 to 0.61761, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/146-0.6176.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.8006 - acc: 0.7629 - val_loss: 0.6176 - val_acc: 0.8353\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7981 - acc: 0.7620\n",
      "Epoch 00147: val_loss improved from 0.61761 to 0.61581, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/147-0.6158.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.7981 - acc: 0.7620 - val_loss: 0.6158 - val_acc: 0.8358\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7960 - acc: 0.7621\n",
      "Epoch 00148: val_loss did not improve from 0.61581\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.7961 - acc: 0.7621 - val_loss: 0.6229 - val_acc: 0.8318\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7964 - acc: 0.7635\n",
      "Epoch 00149: val_loss improved from 0.61581 to 0.61132, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/149-0.6113.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7964 - acc: 0.7635 - val_loss: 0.6113 - val_acc: 0.8367\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7946 - acc: 0.7628\n",
      "Epoch 00150: val_loss did not improve from 0.61132\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.7945 - acc: 0.7628 - val_loss: 0.6220 - val_acc: 0.8341\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7927 - acc: 0.7644\n",
      "Epoch 00151: val_loss did not improve from 0.61132\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.7927 - acc: 0.7644 - val_loss: 0.6173 - val_acc: 0.8351\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7919 - acc: 0.7687\n",
      "Epoch 00152: val_loss did not improve from 0.61132\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.7919 - acc: 0.7686 - val_loss: 0.6231 - val_acc: 0.8311\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7888 - acc: 0.7635\n",
      "Epoch 00153: val_loss improved from 0.61132 to 0.61106, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/153-0.6111.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.7887 - acc: 0.7635 - val_loss: 0.6111 - val_acc: 0.8334\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7838 - acc: 0.7660\n",
      "Epoch 00154: val_loss did not improve from 0.61106\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.7838 - acc: 0.7660 - val_loss: 0.6144 - val_acc: 0.8316\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7814 - acc: 0.7668\n",
      "Epoch 00155: val_loss improved from 0.61106 to 0.60796, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/155-0.6080.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.7815 - acc: 0.7668 - val_loss: 0.6080 - val_acc: 0.8376\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7882 - acc: 0.7670\n",
      "Epoch 00156: val_loss did not improve from 0.60796\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.7881 - acc: 0.7670 - val_loss: 0.6139 - val_acc: 0.8367\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7865 - acc: 0.7683\n",
      "Epoch 00157: val_loss improved from 0.60796 to 0.60552, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/157-0.6055.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.7865 - acc: 0.7683 - val_loss: 0.6055 - val_acc: 0.8372\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7874 - acc: 0.7674\n",
      "Epoch 00158: val_loss did not improve from 0.60552\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.7874 - acc: 0.7675 - val_loss: 0.6125 - val_acc: 0.8309\n",
      "Epoch 159/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7840 - acc: 0.7658\n",
      "Epoch 00159: val_loss did not improve from 0.60552\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.7841 - acc: 0.7657 - val_loss: 0.6113 - val_acc: 0.8353\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7772 - acc: 0.7688\n",
      "Epoch 00160: val_loss did not improve from 0.60552\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7772 - acc: 0.7688 - val_loss: 0.6160 - val_acc: 0.8339\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7798 - acc: 0.7688\n",
      "Epoch 00161: val_loss improved from 0.60552 to 0.59734, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/161-0.5973.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.7798 - acc: 0.7688 - val_loss: 0.5973 - val_acc: 0.8416\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7800 - acc: 0.7670\n",
      "Epoch 00162: val_loss did not improve from 0.59734\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.7800 - acc: 0.7670 - val_loss: 0.5974 - val_acc: 0.8397\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7715 - acc: 0.7706\n",
      "Epoch 00163: val_loss improved from 0.59734 to 0.59709, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/163-0.5971.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.7714 - acc: 0.7706 - val_loss: 0.5971 - val_acc: 0.8362\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7666 - acc: 0.7738\n",
      "Epoch 00164: val_loss improved from 0.59709 to 0.59432, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/164-0.5943.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.7666 - acc: 0.7738 - val_loss: 0.5943 - val_acc: 0.8416\n",
      "Epoch 165/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7701 - acc: 0.7726\n",
      "Epoch 00165: val_loss did not improve from 0.59432\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.7700 - acc: 0.7727 - val_loss: 0.5968 - val_acc: 0.8411\n",
      "Epoch 166/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7707 - acc: 0.7702\n",
      "Epoch 00166: val_loss improved from 0.59432 to 0.59195, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/166-0.5919.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.7703 - acc: 0.7703 - val_loss: 0.5919 - val_acc: 0.8395\n",
      "Epoch 167/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7641 - acc: 0.7722\n",
      "Epoch 00167: val_loss did not improve from 0.59195\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.7636 - acc: 0.7724 - val_loss: 0.5923 - val_acc: 0.8414\n",
      "Epoch 168/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7646 - acc: 0.7717\n",
      "Epoch 00168: val_loss did not improve from 0.59195\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.7646 - acc: 0.7717 - val_loss: 0.6169 - val_acc: 0.8334\n",
      "Epoch 169/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7663 - acc: 0.7713\n",
      "Epoch 00169: val_loss did not improve from 0.59195\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.7663 - acc: 0.7713 - val_loss: 0.5931 - val_acc: 0.8425\n",
      "Epoch 170/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7660 - acc: 0.7739\n",
      "Epoch 00170: val_loss did not improve from 0.59195\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.7658 - acc: 0.7739 - val_loss: 0.5962 - val_acc: 0.8393\n",
      "Epoch 171/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7699 - acc: 0.7730\n",
      "Epoch 00171: val_loss improved from 0.59195 to 0.58933, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/171-0.5893.hdf5\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.7698 - acc: 0.7730 - val_loss: 0.5893 - val_acc: 0.8449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7605 - acc: 0.7759\n",
      "Epoch 00172: val_loss did not improve from 0.58933\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.7608 - acc: 0.7758 - val_loss: 0.6047 - val_acc: 0.8409\n",
      "Epoch 173/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7666 - acc: 0.7743\n",
      "Epoch 00173: val_loss did not improve from 0.58933\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.7670 - acc: 0.7742 - val_loss: 0.5917 - val_acc: 0.8430\n",
      "Epoch 174/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7596 - acc: 0.7745\n",
      "Epoch 00174: val_loss improved from 0.58933 to 0.58737, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/174-0.5874.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.7602 - acc: 0.7743 - val_loss: 0.5874 - val_acc: 0.8409\n",
      "Epoch 175/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7564 - acc: 0.7770\n",
      "Epoch 00175: val_loss improved from 0.58737 to 0.58269, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/175-0.5827.hdf5\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.7561 - acc: 0.7771 - val_loss: 0.5827 - val_acc: 0.8465\n",
      "Epoch 176/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7550 - acc: 0.7748\n",
      "Epoch 00176: val_loss did not improve from 0.58269\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.7550 - acc: 0.7748 - val_loss: 0.6337 - val_acc: 0.8286\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7554 - acc: 0.7754\n",
      "Epoch 00177: val_loss did not improve from 0.58269\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.7554 - acc: 0.7753 - val_loss: 0.5938 - val_acc: 0.8404\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7541 - acc: 0.7753\n",
      "Epoch 00178: val_loss did not improve from 0.58269\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.7541 - acc: 0.7753 - val_loss: 0.5855 - val_acc: 0.8425\n",
      "Epoch 179/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7509 - acc: 0.7770\n",
      "Epoch 00179: val_loss did not improve from 0.58269\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7510 - acc: 0.7770 - val_loss: 0.5924 - val_acc: 0.8428\n",
      "Epoch 180/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7555 - acc: 0.7769\n",
      "Epoch 00180: val_loss did not improve from 0.58269\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.7557 - acc: 0.7769 - val_loss: 0.5939 - val_acc: 0.8402\n",
      "Epoch 181/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7524 - acc: 0.7781\n",
      "Epoch 00181: val_loss did not improve from 0.58269\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.7522 - acc: 0.7781 - val_loss: 0.5835 - val_acc: 0.8446\n",
      "Epoch 182/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7443 - acc: 0.7782\n",
      "Epoch 00182: val_loss did not improve from 0.58269\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.7453 - acc: 0.7779 - val_loss: 0.5859 - val_acc: 0.8439\n",
      "Epoch 183/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7547 - acc: 0.7769\n",
      "Epoch 00183: val_loss did not improve from 0.58269\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.7546 - acc: 0.7769 - val_loss: 0.5849 - val_acc: 0.8432\n",
      "Epoch 184/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7459 - acc: 0.7770\n",
      "Epoch 00184: val_loss did not improve from 0.58269\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.7462 - acc: 0.7768 - val_loss: 0.5846 - val_acc: 0.8421\n",
      "Epoch 185/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7477 - acc: 0.7767\n",
      "Epoch 00185: val_loss improved from 0.58269 to 0.57082, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/185-0.5708.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.7475 - acc: 0.7767 - val_loss: 0.5708 - val_acc: 0.8479\n",
      "Epoch 186/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7486 - acc: 0.7774\n",
      "Epoch 00186: val_loss did not improve from 0.57082\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.7488 - acc: 0.7774 - val_loss: 0.5727 - val_acc: 0.8465\n",
      "Epoch 187/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7468 - acc: 0.7772\n",
      "Epoch 00187: val_loss did not improve from 0.57082\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.7469 - acc: 0.7771 - val_loss: 0.5765 - val_acc: 0.8474\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7425 - acc: 0.7809\n",
      "Epoch 00188: val_loss did not improve from 0.57082\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.7425 - acc: 0.7809 - val_loss: 0.5761 - val_acc: 0.8470\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7395 - acc: 0.7789\n",
      "Epoch 00189: val_loss did not improve from 0.57082\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.7395 - acc: 0.7790 - val_loss: 0.5949 - val_acc: 0.8386\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7439 - acc: 0.7814\n",
      "Epoch 00190: val_loss did not improve from 0.57082\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.7439 - acc: 0.7814 - val_loss: 0.5853 - val_acc: 0.8411\n",
      "Epoch 191/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7416 - acc: 0.7794\n",
      "Epoch 00191: val_loss did not improve from 0.57082\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.7413 - acc: 0.7795 - val_loss: 0.5751 - val_acc: 0.8463\n",
      "Epoch 192/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7399 - acc: 0.7809\n",
      "Epoch 00192: val_loss improved from 0.57082 to 0.56879, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/192-0.5688.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.7401 - acc: 0.7806 - val_loss: 0.5688 - val_acc: 0.8479\n",
      "Epoch 193/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7360 - acc: 0.7818\n",
      "Epoch 00193: val_loss improved from 0.56879 to 0.56790, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/193-0.5679.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.7368 - acc: 0.7817 - val_loss: 0.5679 - val_acc: 0.8477\n",
      "Epoch 194/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7423 - acc: 0.7798\n",
      "Epoch 00194: val_loss did not improve from 0.56790\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.7421 - acc: 0.7798 - val_loss: 0.5731 - val_acc: 0.8472\n",
      "Epoch 195/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7364 - acc: 0.7813\n",
      "Epoch 00195: val_loss improved from 0.56790 to 0.56789, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/195-0.5679.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.7372 - acc: 0.7813 - val_loss: 0.5679 - val_acc: 0.8488\n",
      "Epoch 196/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7344 - acc: 0.7848\n",
      "Epoch 00196: val_loss improved from 0.56789 to 0.56618, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/196-0.5662.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.7347 - acc: 0.7847 - val_loss: 0.5662 - val_acc: 0.8474\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7373 - acc: 0.7814\n",
      "Epoch 00197: val_loss did not improve from 0.56618\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.7373 - acc: 0.7814 - val_loss: 0.5662 - val_acc: 0.8507\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7305 - acc: 0.7842\n",
      "Epoch 00198: val_loss improved from 0.56618 to 0.56475, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/198-0.5648.hdf5\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.7304 - acc: 0.7842 - val_loss: 0.5648 - val_acc: 0.8486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7353 - acc: 0.7845\n",
      "Epoch 00199: val_loss improved from 0.56475 to 0.56397, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/199-0.5640.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.7354 - acc: 0.7845 - val_loss: 0.5640 - val_acc: 0.8474\n",
      "Epoch 200/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7287 - acc: 0.7830\n",
      "Epoch 00200: val_loss did not improve from 0.56397\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.7286 - acc: 0.7831 - val_loss: 0.5664 - val_acc: 0.8505\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7287 - acc: 0.7835\n",
      "Epoch 00201: val_loss did not improve from 0.56397\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.7287 - acc: 0.7835 - val_loss: 0.5643 - val_acc: 0.8491\n",
      "Epoch 202/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7295 - acc: 0.7831\n",
      "Epoch 00202: val_loss did not improve from 0.56397\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.7291 - acc: 0.7833 - val_loss: 0.5695 - val_acc: 0.8493\n",
      "Epoch 203/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7280 - acc: 0.7818\n",
      "Epoch 00203: val_loss improved from 0.56397 to 0.56276, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/203-0.5628.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7280 - acc: 0.7818 - val_loss: 0.5628 - val_acc: 0.8509\n",
      "Epoch 204/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7304 - acc: 0.7838\n",
      "Epoch 00204: val_loss improved from 0.56276 to 0.55297, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/204-0.5530.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.7301 - acc: 0.7838 - val_loss: 0.5530 - val_acc: 0.8498\n",
      "Epoch 205/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7188 - acc: 0.7876\n",
      "Epoch 00205: val_loss did not improve from 0.55297\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.7185 - acc: 0.7876 - val_loss: 0.5631 - val_acc: 0.8488\n",
      "Epoch 206/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7213 - acc: 0.7861\n",
      "Epoch 00206: val_loss did not improve from 0.55297\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.7215 - acc: 0.7861 - val_loss: 0.5541 - val_acc: 0.8509\n",
      "Epoch 207/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7201 - acc: 0.7871\n",
      "Epoch 00207: val_loss improved from 0.55297 to 0.55121, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/207-0.5512.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.7200 - acc: 0.7873 - val_loss: 0.5512 - val_acc: 0.8528\n",
      "Epoch 208/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7267 - acc: 0.7860\n",
      "Epoch 00208: val_loss did not improve from 0.55121\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.7265 - acc: 0.7860 - val_loss: 0.5595 - val_acc: 0.8486\n",
      "Epoch 209/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7221 - acc: 0.7875\n",
      "Epoch 00209: val_loss did not improve from 0.55121\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.7223 - acc: 0.7874 - val_loss: 0.5666 - val_acc: 0.8479\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7253 - acc: 0.7877\n",
      "Epoch 00210: val_loss did not improve from 0.55121\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.7252 - acc: 0.7877 - val_loss: 0.5572 - val_acc: 0.8519\n",
      "Epoch 211/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7171 - acc: 0.7861\n",
      "Epoch 00211: val_loss did not improve from 0.55121\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.7171 - acc: 0.7861 - val_loss: 0.5562 - val_acc: 0.8528\n",
      "Epoch 212/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7168 - acc: 0.7867\n",
      "Epoch 00212: val_loss improved from 0.55121 to 0.55037, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/212-0.5504.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.7169 - acc: 0.7867 - val_loss: 0.5504 - val_acc: 0.8556\n",
      "Epoch 213/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7162 - acc: 0.7870\n",
      "Epoch 00213: val_loss improved from 0.55037 to 0.54796, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/213-0.5480.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.7163 - acc: 0.7870 - val_loss: 0.5480 - val_acc: 0.8539\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7188 - acc: 0.7884\n",
      "Epoch 00214: val_loss did not improve from 0.54796\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.7188 - acc: 0.7883 - val_loss: 0.5623 - val_acc: 0.8467\n",
      "Epoch 215/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7122 - acc: 0.7896\n",
      "Epoch 00215: val_loss improved from 0.54796 to 0.54506, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/215-0.5451.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.7127 - acc: 0.7895 - val_loss: 0.5451 - val_acc: 0.8579\n",
      "Epoch 216/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7135 - acc: 0.7899\n",
      "Epoch 00216: val_loss did not improve from 0.54506\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.7138 - acc: 0.7897 - val_loss: 0.5597 - val_acc: 0.8474\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7120 - acc: 0.7891\n",
      "Epoch 00217: val_loss did not improve from 0.54506\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.7120 - acc: 0.7892 - val_loss: 0.5475 - val_acc: 0.8549\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7139 - acc: 0.7899\n",
      "Epoch 00218: val_loss did not improve from 0.54506\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.7138 - acc: 0.7900 - val_loss: 0.5478 - val_acc: 0.8532\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7144 - acc: 0.7881\n",
      "Epoch 00219: val_loss did not improve from 0.54506\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.7144 - acc: 0.7881 - val_loss: 0.5519 - val_acc: 0.8516\n",
      "Epoch 220/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7059 - acc: 0.7919\n",
      "Epoch 00220: val_loss did not improve from 0.54506\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.7060 - acc: 0.7919 - val_loss: 0.5706 - val_acc: 0.8439\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7138 - acc: 0.7895\n",
      "Epoch 00221: val_loss improved from 0.54506 to 0.54490, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/221-0.5449.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.7138 - acc: 0.7895 - val_loss: 0.5449 - val_acc: 0.8551\n",
      "Epoch 222/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7079 - acc: 0.7904\n",
      "Epoch 00222: val_loss improved from 0.54490 to 0.54155, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/222-0.5416.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.7082 - acc: 0.7904 - val_loss: 0.5416 - val_acc: 0.8553\n",
      "Epoch 223/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7098 - acc: 0.7894- ETA: 2\n",
      "Epoch 00223: val_loss did not improve from 0.54155\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.7101 - acc: 0.7892 - val_loss: 0.5441 - val_acc: 0.8567\n",
      "Epoch 224/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7101 - acc: 0.7902\n",
      "Epoch 00224: val_loss did not improve from 0.54155\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.7100 - acc: 0.7902 - val_loss: 0.5448 - val_acc: 0.8558\n",
      "Epoch 225/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7098 - acc: 0.7907\n",
      "Epoch 00225: val_loss did not improve from 0.54155\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.7098 - acc: 0.7907 - val_loss: 0.5452 - val_acc: 0.8549\n",
      "Epoch 226/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7048 - acc: 0.7918\n",
      "Epoch 00226: val_loss did not improve from 0.54155\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.7050 - acc: 0.7918 - val_loss: 0.5549 - val_acc: 0.8532\n",
      "Epoch 227/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7021 - acc: 0.7921\n",
      "Epoch 00227: val_loss improved from 0.54155 to 0.53861, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/227-0.5386.hdf5\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.7019 - acc: 0.7921 - val_loss: 0.5386 - val_acc: 0.8577\n",
      "Epoch 228/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7061 - acc: 0.7908\n",
      "Epoch 00228: val_loss did not improve from 0.53861\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.7061 - acc: 0.7907 - val_loss: 0.5436 - val_acc: 0.8523\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7050 - acc: 0.7918\n",
      "Epoch 00229: val_loss did not improve from 0.53861\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.7050 - acc: 0.7919 - val_loss: 0.5407 - val_acc: 0.8546\n",
      "Epoch 230/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7037 - acc: 0.7928\n",
      "Epoch 00230: val_loss did not improve from 0.53861\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.7036 - acc: 0.7928 - val_loss: 0.5429 - val_acc: 0.8516\n",
      "Epoch 231/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7040 - acc: 0.7913\n",
      "Epoch 00231: val_loss improved from 0.53861 to 0.52998, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/231-0.5300.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.7039 - acc: 0.7913 - val_loss: 0.5300 - val_acc: 0.8581\n",
      "Epoch 232/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6975 - acc: 0.7930\n",
      "Epoch 00232: val_loss did not improve from 0.52998\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6980 - acc: 0.7930 - val_loss: 0.5409 - val_acc: 0.8558\n",
      "Epoch 233/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6987 - acc: 0.7921\n",
      "Epoch 00233: val_loss did not improve from 0.52998\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6985 - acc: 0.7921 - val_loss: 0.5358 - val_acc: 0.8626\n",
      "Epoch 234/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6939 - acc: 0.7958\n",
      "Epoch 00234: val_loss did not improve from 0.52998\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6941 - acc: 0.7955 - val_loss: 0.5375 - val_acc: 0.8570\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6954 - acc: 0.7957\n",
      "Epoch 00235: val_loss did not improve from 0.52998\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6956 - acc: 0.7956 - val_loss: 0.5362 - val_acc: 0.8556\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6938 - acc: 0.7960\n",
      "Epoch 00236: val_loss did not improve from 0.52998\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.6938 - acc: 0.7960 - val_loss: 0.5320 - val_acc: 0.8574\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6965 - acc: 0.7940\n",
      "Epoch 00237: val_loss did not improve from 0.52998\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.6965 - acc: 0.7940 - val_loss: 0.5351 - val_acc: 0.8584\n",
      "Epoch 238/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6920 - acc: 0.7950\n",
      "Epoch 00238: val_loss improved from 0.52998 to 0.52924, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/238-0.5292.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6922 - acc: 0.7950 - val_loss: 0.5292 - val_acc: 0.8581\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6915 - acc: 0.7959\n",
      "Epoch 00239: val_loss improved from 0.52924 to 0.52519, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/239-0.5252.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6915 - acc: 0.7959 - val_loss: 0.5252 - val_acc: 0.8605\n",
      "Epoch 240/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6871 - acc: 0.7976- ETA: 1s - loss: \n",
      "Epoch 00240: val_loss did not improve from 0.52519\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6872 - acc: 0.7976 - val_loss: 0.5360 - val_acc: 0.8553\n",
      "Epoch 241/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6961 - acc: 0.7943\n",
      "Epoch 00241: val_loss did not improve from 0.52519\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6962 - acc: 0.7942 - val_loss: 0.5389 - val_acc: 0.8556\n",
      "Epoch 242/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6940 - acc: 0.7954\n",
      "Epoch 00242: val_loss did not improve from 0.52519\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6936 - acc: 0.7955 - val_loss: 0.5269 - val_acc: 0.8619\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6927 - acc: 0.7963\n",
      "Epoch 00243: val_loss improved from 0.52519 to 0.52111, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/243-0.5211.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6927 - acc: 0.7963 - val_loss: 0.5211 - val_acc: 0.8628\n",
      "Epoch 244/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6909 - acc: 0.7964\n",
      "Epoch 00244: val_loss did not improve from 0.52111\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.6904 - acc: 0.7965 - val_loss: 0.5317 - val_acc: 0.8593\n",
      "Epoch 245/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6848 - acc: 0.7981\n",
      "Epoch 00245: val_loss did not improve from 0.52111\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6850 - acc: 0.7979 - val_loss: 0.5271 - val_acc: 0.8612\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6896 - acc: 0.7966\n",
      "Epoch 00246: val_loss did not improve from 0.52111\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6896 - acc: 0.7966 - val_loss: 0.5259 - val_acc: 0.8621\n",
      "Epoch 247/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6876 - acc: 0.7967\n",
      "Epoch 00247: val_loss did not improve from 0.52111\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6876 - acc: 0.7968 - val_loss: 0.5213 - val_acc: 0.8609\n",
      "Epoch 248/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6809 - acc: 0.7966\n",
      "Epoch 00248: val_loss did not improve from 0.52111\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6806 - acc: 0.7968 - val_loss: 0.5284 - val_acc: 0.8579\n",
      "Epoch 249/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6802 - acc: 0.7974\n",
      "Epoch 00249: val_loss did not improve from 0.52111\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6801 - acc: 0.7974 - val_loss: 0.5292 - val_acc: 0.8591\n",
      "Epoch 250/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6776 - acc: 0.7974\n",
      "Epoch 00250: val_loss did not improve from 0.52111\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6773 - acc: 0.7974 - val_loss: 0.5260 - val_acc: 0.8602\n",
      "Epoch 251/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6805 - acc: 0.7993\n",
      "Epoch 00251: val_loss did not improve from 0.52111\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6807 - acc: 0.7991 - val_loss: 0.5259 - val_acc: 0.8595\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6820 - acc: 0.7976\n",
      "Epoch 00252: val_loss did not improve from 0.52111\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6819 - acc: 0.7976 - val_loss: 0.5242 - val_acc: 0.8584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6751 - acc: 0.7990\n",
      "Epoch 00253: val_loss improved from 0.52111 to 0.51793, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/253-0.5179.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6751 - acc: 0.7990 - val_loss: 0.5179 - val_acc: 0.8630\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6815 - acc: 0.7986\n",
      "Epoch 00254: val_loss improved from 0.51793 to 0.51521, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/254-0.5152.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6815 - acc: 0.7986 - val_loss: 0.5152 - val_acc: 0.8654\n",
      "Epoch 255/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6710 - acc: 0.8019\n",
      "Epoch 00255: val_loss did not improve from 0.51521\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.6713 - acc: 0.8016 - val_loss: 0.5281 - val_acc: 0.8595\n",
      "Epoch 256/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6731 - acc: 0.8008\n",
      "Epoch 00256: val_loss did not improve from 0.51521\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6729 - acc: 0.8010 - val_loss: 0.5200 - val_acc: 0.8619\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6732 - acc: 0.8018\n",
      "Epoch 00257: val_loss did not improve from 0.51521\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6733 - acc: 0.8018 - val_loss: 0.5198 - val_acc: 0.8628\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6706 - acc: 0.8010\n",
      "Epoch 00258: val_loss improved from 0.51521 to 0.51204, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/258-0.5120.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6705 - acc: 0.8010 - val_loss: 0.5120 - val_acc: 0.8649\n",
      "Epoch 259/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6799 - acc: 0.8004\n",
      "Epoch 00259: val_loss did not improve from 0.51204\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6797 - acc: 0.8004 - val_loss: 0.5342 - val_acc: 0.8558\n",
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6764 - acc: 0.8007\n",
      "Epoch 00260: val_loss did not improve from 0.51204\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6763 - acc: 0.8007 - val_loss: 0.5187 - val_acc: 0.8623\n",
      "Epoch 261/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6749 - acc: 0.8000\n",
      "Epoch 00261: val_loss improved from 0.51204 to 0.51126, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/261-0.5113.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6749 - acc: 0.7999 - val_loss: 0.5113 - val_acc: 0.8670\n",
      "Epoch 262/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6723 - acc: 0.8008\n",
      "Epoch 00262: val_loss did not improve from 0.51126\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6717 - acc: 0.8010 - val_loss: 0.5126 - val_acc: 0.8623\n",
      "Epoch 263/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6716 - acc: 0.8033\n",
      "Epoch 00263: val_loss did not improve from 0.51126\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6715 - acc: 0.8033 - val_loss: 0.5276 - val_acc: 0.8565\n",
      "Epoch 264/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6733 - acc: 0.8015\n",
      "Epoch 00264: val_loss improved from 0.51126 to 0.50592, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/264-0.5059.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6736 - acc: 0.8015 - val_loss: 0.5059 - val_acc: 0.8679\n",
      "Epoch 265/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6699 - acc: 0.8033\n",
      "Epoch 00265: val_loss did not improve from 0.50592\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6704 - acc: 0.8033 - val_loss: 0.5146 - val_acc: 0.8640\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6631 - acc: 0.8032\n",
      "Epoch 00266: val_loss did not improve from 0.50592\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6630 - acc: 0.8033 - val_loss: 0.5174 - val_acc: 0.8621\n",
      "Epoch 267/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6692 - acc: 0.8031\n",
      "Epoch 00267: val_loss did not improve from 0.50592\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6692 - acc: 0.8031 - val_loss: 0.5161 - val_acc: 0.8605\n",
      "Epoch 268/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6652 - acc: 0.8035\n",
      "Epoch 00268: val_loss did not improve from 0.50592\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6657 - acc: 0.8033 - val_loss: 0.5105 - val_acc: 0.8626\n",
      "Epoch 269/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6593 - acc: 0.8029\n",
      "Epoch 00269: val_loss improved from 0.50592 to 0.50217, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/269-0.5022.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6594 - acc: 0.8031 - val_loss: 0.5022 - val_acc: 0.8698\n",
      "Epoch 270/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6670 - acc: 0.8018\n",
      "Epoch 00270: val_loss did not improve from 0.50217\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6669 - acc: 0.8017 - val_loss: 0.5107 - val_acc: 0.8658\n",
      "Epoch 271/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6628 - acc: 0.8043\n",
      "Epoch 00271: val_loss did not improve from 0.50217\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6630 - acc: 0.8041 - val_loss: 0.5186 - val_acc: 0.8607\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6602 - acc: 0.8064\n",
      "Epoch 00272: val_loss did not improve from 0.50217\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6602 - acc: 0.8064 - val_loss: 0.5090 - val_acc: 0.8626\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6591 - acc: 0.8060\n",
      "Epoch 00273: val_loss did not improve from 0.50217\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.6591 - acc: 0.8060 - val_loss: 0.5036 - val_acc: 0.8682\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6584 - acc: 0.8048\n",
      "Epoch 00274: val_loss did not improve from 0.50217\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6585 - acc: 0.8048 - val_loss: 0.5175 - val_acc: 0.8635\n",
      "Epoch 275/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6587 - acc: 0.8060\n",
      "Epoch 00275: val_loss did not improve from 0.50217\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6584 - acc: 0.8060 - val_loss: 0.5133 - val_acc: 0.8642\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6630 - acc: 0.8028\n",
      "Epoch 00276: val_loss did not improve from 0.50217\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6629 - acc: 0.8028 - val_loss: 0.5107 - val_acc: 0.8651\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6586 - acc: 0.8043\n",
      "Epoch 00277: val_loss did not improve from 0.50217\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.6586 - acc: 0.8043 - val_loss: 0.5045 - val_acc: 0.8651\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6541 - acc: 0.8060\n",
      "Epoch 00278: val_loss did not improve from 0.50217\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6541 - acc: 0.8060 - val_loss: 0.5080 - val_acc: 0.8661\n",
      "Epoch 279/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6564 - acc: 0.8032\n",
      "Epoch 00279: val_loss improved from 0.50217 to 0.49845, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/279-0.4984.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6565 - acc: 0.8032 - val_loss: 0.4984 - val_acc: 0.8665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6522 - acc: 0.8064\n",
      "Epoch 00280: val_loss did not improve from 0.49845\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6522 - acc: 0.8064 - val_loss: 0.4998 - val_acc: 0.8700\n",
      "Epoch 281/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6617 - acc: 0.8034\n",
      "Epoch 00281: val_loss did not improve from 0.49845\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6617 - acc: 0.8034 - val_loss: 0.5014 - val_acc: 0.8651\n",
      "Epoch 282/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6559 - acc: 0.8058\n",
      "Epoch 00282: val_loss did not improve from 0.49845\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6560 - acc: 0.8058 - val_loss: 0.5124 - val_acc: 0.8642\n",
      "Epoch 283/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6562 - acc: 0.8074\n",
      "Epoch 00283: val_loss did not improve from 0.49845\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6563 - acc: 0.8073 - val_loss: 0.5051 - val_acc: 0.8663\n",
      "Epoch 284/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6545 - acc: 0.8084\n",
      "Epoch 00284: val_loss did not improve from 0.49845\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6543 - acc: 0.8084 - val_loss: 0.5118 - val_acc: 0.8637\n",
      "Epoch 285/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6517 - acc: 0.8092\n",
      "Epoch 00285: val_loss improved from 0.49845 to 0.49461, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/285-0.4946.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6516 - acc: 0.8092 - val_loss: 0.4946 - val_acc: 0.8668\n",
      "Epoch 286/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6505 - acc: 0.8101\n",
      "Epoch 00286: val_loss improved from 0.49461 to 0.49332, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/286-0.4933.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6503 - acc: 0.8101 - val_loss: 0.4933 - val_acc: 0.8684\n",
      "Epoch 287/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6512 - acc: 0.8062\n",
      "Epoch 00287: val_loss did not improve from 0.49332\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6514 - acc: 0.8062 - val_loss: 0.4988 - val_acc: 0.8672\n",
      "Epoch 288/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6505 - acc: 0.8073- E\n",
      "Epoch 00288: val_loss did not improve from 0.49332\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6507 - acc: 0.8073 - val_loss: 0.5032 - val_acc: 0.8689\n",
      "Epoch 289/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6491 - acc: 0.8090\n",
      "Epoch 00289: val_loss did not improve from 0.49332\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6494 - acc: 0.8090 - val_loss: 0.4970 - val_acc: 0.8665\n",
      "Epoch 290/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6497 - acc: 0.8083- ET\n",
      "Epoch 00290: val_loss did not improve from 0.49332\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6501 - acc: 0.8082 - val_loss: 0.4968 - val_acc: 0.8700\n",
      "Epoch 291/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6533 - acc: 0.8067\n",
      "Epoch 00291: val_loss did not improve from 0.49332\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6539 - acc: 0.8066 - val_loss: 0.4979 - val_acc: 0.8700\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6522 - acc: 0.8066\n",
      "Epoch 00292: val_loss did not improve from 0.49332\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6522 - acc: 0.8066 - val_loss: 0.4983 - val_acc: 0.8689\n",
      "Epoch 293/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6362 - acc: 0.8101\n",
      "Epoch 00293: val_loss did not improve from 0.49332\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6369 - acc: 0.8101 - val_loss: 0.5007 - val_acc: 0.8684\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6492 - acc: 0.8077\n",
      "Epoch 00294: val_loss improved from 0.49332 to 0.49322, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/294-0.4932.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6492 - acc: 0.8077 - val_loss: 0.4932 - val_acc: 0.8696\n",
      "Epoch 295/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.8078\n",
      "Epoch 00295: val_loss improved from 0.49322 to 0.49284, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/295-0.4928.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6464 - acc: 0.8077 - val_loss: 0.4928 - val_acc: 0.8698\n",
      "Epoch 296/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6444 - acc: 0.8113\n",
      "Epoch 00296: val_loss did not improve from 0.49284\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6443 - acc: 0.8114 - val_loss: 0.4962 - val_acc: 0.8710\n",
      "Epoch 297/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6461 - acc: 0.8099\n",
      "Epoch 00297: val_loss did not improve from 0.49284\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6461 - acc: 0.8099 - val_loss: 0.4937 - val_acc: 0.8691\n",
      "Epoch 298/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6437 - acc: 0.8105\n",
      "Epoch 00298: val_loss did not improve from 0.49284\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.6437 - acc: 0.8105 - val_loss: 0.4938 - val_acc: 0.8714\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6461 - acc: 0.8090\n",
      "Epoch 00299: val_loss did not improve from 0.49284\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6460 - acc: 0.8091 - val_loss: 0.4983 - val_acc: 0.8658\n",
      "Epoch 300/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6375 - acc: 0.8113\n",
      "Epoch 00300: val_loss did not improve from 0.49284\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6376 - acc: 0.8112 - val_loss: 0.4948 - val_acc: 0.8668\n",
      "Epoch 301/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6377 - acc: 0.8134\n",
      "Epoch 00301: val_loss improved from 0.49284 to 0.48352, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/301-0.4835.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6373 - acc: 0.8135 - val_loss: 0.4835 - val_acc: 0.8714\n",
      "Epoch 302/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6382 - acc: 0.8107\n",
      "Epoch 00302: val_loss did not improve from 0.48352\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6381 - acc: 0.8106 - val_loss: 0.4964 - val_acc: 0.8703\n",
      "Epoch 303/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6340 - acc: 0.8132\n",
      "Epoch 00303: val_loss did not improve from 0.48352\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6341 - acc: 0.8131 - val_loss: 0.4864 - val_acc: 0.8719\n",
      "Epoch 304/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6360 - acc: 0.8111\n",
      "Epoch 00304: val_loss improved from 0.48352 to 0.48144, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/304-0.4814.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6360 - acc: 0.8111 - val_loss: 0.4814 - val_acc: 0.8705\n",
      "Epoch 305/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6372 - acc: 0.8113\n",
      "Epoch 00305: val_loss did not improve from 0.48144\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6369 - acc: 0.8114 - val_loss: 0.4898 - val_acc: 0.8682\n",
      "Epoch 306/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6415 - acc: 0.8112\n",
      "Epoch 00306: val_loss did not improve from 0.48144\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6413 - acc: 0.8112 - val_loss: 0.4885 - val_acc: 0.8689\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6367 - acc: 0.8111\n",
      "Epoch 00307: val_loss did not improve from 0.48144\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6374 - acc: 0.8111 - val_loss: 0.4833 - val_acc: 0.8742\n",
      "Epoch 308/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6366 - acc: 0.8122\n",
      "Epoch 00308: val_loss did not improve from 0.48144\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6365 - acc: 0.8124 - val_loss: 0.4826 - val_acc: 0.8747\n",
      "Epoch 309/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6351 - acc: 0.8125- ETA: 0s - loss: 0.6352 - acc: 0.8\n",
      "Epoch 00309: val_loss improved from 0.48144 to 0.47662, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/309-0.4766.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6349 - acc: 0.8125 - val_loss: 0.4766 - val_acc: 0.8740\n",
      "Epoch 310/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6286 - acc: 0.8148\n",
      "Epoch 00310: val_loss did not improve from 0.47662\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6286 - acc: 0.8148 - val_loss: 0.4785 - val_acc: 0.8756\n",
      "Epoch 311/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6393 - acc: 0.8098\n",
      "Epoch 00311: val_loss did not improve from 0.47662\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.6390 - acc: 0.8099 - val_loss: 0.4853 - val_acc: 0.8712\n",
      "Epoch 312/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6310 - acc: 0.8139\n",
      "Epoch 00312: val_loss did not improve from 0.47662\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6310 - acc: 0.8139 - val_loss: 0.4878 - val_acc: 0.8705\n",
      "Epoch 313/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6290 - acc: 0.8130\n",
      "Epoch 00313: val_loss did not improve from 0.47662\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6290 - acc: 0.8129 - val_loss: 0.4859 - val_acc: 0.8700\n",
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6353 - acc: 0.8124\n",
      "Epoch 00314: val_loss did not improve from 0.47662\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.6353 - acc: 0.8124 - val_loss: 0.4823 - val_acc: 0.8712\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6329 - acc: 0.8143\n",
      "Epoch 00315: val_loss did not improve from 0.47662\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.6329 - acc: 0.8143 - val_loss: 0.4841 - val_acc: 0.8754\n",
      "Epoch 316/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6305 - acc: 0.8161\n",
      "Epoch 00316: val_loss did not improve from 0.47662\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6305 - acc: 0.8160 - val_loss: 0.4980 - val_acc: 0.8719\n",
      "Epoch 317/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6269 - acc: 0.8148\n",
      "Epoch 00317: val_loss did not improve from 0.47662\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6272 - acc: 0.8148 - val_loss: 0.4784 - val_acc: 0.8735\n",
      "Epoch 318/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6252 - acc: 0.8168\n",
      "Epoch 00318: val_loss improved from 0.47662 to 0.47129, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/318-0.4713.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6252 - acc: 0.8168 - val_loss: 0.4713 - val_acc: 0.8777\n",
      "Epoch 319/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6295 - acc: 0.8146\n",
      "Epoch 00319: val_loss did not improve from 0.47129\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6295 - acc: 0.8146 - val_loss: 0.4816 - val_acc: 0.8714\n",
      "Epoch 320/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6266 - acc: 0.8161\n",
      "Epoch 00320: val_loss did not improve from 0.47129\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6268 - acc: 0.8161 - val_loss: 0.4831 - val_acc: 0.8733\n",
      "Epoch 321/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6310 - acc: 0.8159\n",
      "Epoch 00321: val_loss did not improve from 0.47129\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6309 - acc: 0.8159 - val_loss: 0.4901 - val_acc: 0.8719\n",
      "Epoch 322/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6255 - acc: 0.8154\n",
      "Epoch 00322: val_loss did not improve from 0.47129\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6255 - acc: 0.8154 - val_loss: 0.4719 - val_acc: 0.8758\n",
      "Epoch 323/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6239 - acc: 0.8132\n",
      "Epoch 00323: val_loss did not improve from 0.47129\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6236 - acc: 0.8133 - val_loss: 0.4752 - val_acc: 0.8747\n",
      "Epoch 324/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6201 - acc: 0.8169\n",
      "Epoch 00324: val_loss did not improve from 0.47129\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6201 - acc: 0.8169 - val_loss: 0.4722 - val_acc: 0.8751\n",
      "Epoch 325/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6259 - acc: 0.8138\n",
      "Epoch 00325: val_loss improved from 0.47129 to 0.46727, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/325-0.4673.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6260 - acc: 0.8138 - val_loss: 0.4673 - val_acc: 0.8763\n",
      "Epoch 326/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6204 - acc: 0.8173\n",
      "Epoch 00326: val_loss did not improve from 0.46727\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6209 - acc: 0.8172 - val_loss: 0.4743 - val_acc: 0.8737\n",
      "Epoch 327/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6224 - acc: 0.8169\n",
      "Epoch 00327: val_loss did not improve from 0.46727\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6224 - acc: 0.8170 - val_loss: 0.4708 - val_acc: 0.8719\n",
      "Epoch 328/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6221 - acc: 0.8160\n",
      "Epoch 00328: val_loss did not improve from 0.46727\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6221 - acc: 0.8160 - val_loss: 0.4698 - val_acc: 0.8772\n",
      "Epoch 329/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6234 - acc: 0.8146\n",
      "Epoch 00329: val_loss did not improve from 0.46727\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6229 - acc: 0.8148 - val_loss: 0.4755 - val_acc: 0.8717\n",
      "Epoch 330/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6213 - acc: 0.8181\n",
      "Epoch 00330: val_loss did not improve from 0.46727\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6207 - acc: 0.8183 - val_loss: 0.4734 - val_acc: 0.8765\n",
      "Epoch 331/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6210 - acc: 0.8173\n",
      "Epoch 00331: val_loss did not improve from 0.46727\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6217 - acc: 0.8172 - val_loss: 0.4706 - val_acc: 0.8777\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6168 - acc: 0.8188\n",
      "Epoch 00332: val_loss did not improve from 0.46727\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6167 - acc: 0.8189 - val_loss: 0.4839 - val_acc: 0.8733\n",
      "Epoch 333/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6229 - acc: 0.8140\n",
      "Epoch 00333: val_loss improved from 0.46727 to 0.46178, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/333-0.4618.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.6231 - acc: 0.8139 - val_loss: 0.4618 - val_acc: 0.8772\n",
      "Epoch 334/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6223 - acc: 0.8142\n",
      "Epoch 00334: val_loss did not improve from 0.46178\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6222 - acc: 0.8141 - val_loss: 0.4777 - val_acc: 0.8763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6158 - acc: 0.8162\n",
      "Epoch 00335: val_loss did not improve from 0.46178\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6158 - acc: 0.8162 - val_loss: 0.4755 - val_acc: 0.8758\n",
      "Epoch 336/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6157 - acc: 0.8207- ETA: 0s - loss: 0.6130 - \n",
      "Epoch 00336: val_loss did not improve from 0.46178\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6157 - acc: 0.8206 - val_loss: 0.4726 - val_acc: 0.8768\n",
      "Epoch 337/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6120 - acc: 0.8176\n",
      "Epoch 00337: val_loss did not improve from 0.46178\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.6120 - acc: 0.8176 - val_loss: 0.4667 - val_acc: 0.8754\n",
      "Epoch 338/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6149 - acc: 0.8207\n",
      "Epoch 00338: val_loss did not improve from 0.46178\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.6149 - acc: 0.8207 - val_loss: 0.4734 - val_acc: 0.8791\n",
      "Epoch 339/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6145 - acc: 0.8200\n",
      "Epoch 00339: val_loss did not improve from 0.46178\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6146 - acc: 0.8201 - val_loss: 0.4685 - val_acc: 0.8754\n",
      "Epoch 340/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6126 - acc: 0.8201\n",
      "Epoch 00340: val_loss did not improve from 0.46178\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6127 - acc: 0.8200 - val_loss: 0.4739 - val_acc: 0.8789\n",
      "Epoch 341/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6116 - acc: 0.8186\n",
      "Epoch 00341: val_loss improved from 0.46178 to 0.45901, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/341-0.4590.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6116 - acc: 0.8185 - val_loss: 0.4590 - val_acc: 0.8789\n",
      "Epoch 342/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6120 - acc: 0.8180\n",
      "Epoch 00342: val_loss did not improve from 0.45901\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6119 - acc: 0.8180 - val_loss: 0.4716 - val_acc: 0.8758\n",
      "Epoch 343/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6077 - acc: 0.8207\n",
      "Epoch 00343: val_loss did not improve from 0.45901\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6072 - acc: 0.8208 - val_loss: 0.4651 - val_acc: 0.8807\n",
      "Epoch 344/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6121 - acc: 0.8180\n",
      "Epoch 00344: val_loss did not improve from 0.45901\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6120 - acc: 0.8180 - val_loss: 0.4674 - val_acc: 0.8765\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6092 - acc: 0.8205\n",
      "Epoch 00345: val_loss did not improve from 0.45901\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6092 - acc: 0.8205 - val_loss: 0.4652 - val_acc: 0.8782\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6089 - acc: 0.8198\n",
      "Epoch 00346: val_loss did not improve from 0.45901\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6089 - acc: 0.8199 - val_loss: 0.4657 - val_acc: 0.8772\n",
      "Epoch 347/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6055 - acc: 0.8196\n",
      "Epoch 00347: val_loss did not improve from 0.45901\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6056 - acc: 0.8196 - val_loss: 0.4617 - val_acc: 0.8777\n",
      "Epoch 348/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.8202\n",
      "Epoch 00348: val_loss improved from 0.45901 to 0.45681, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/348-0.4568.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6113 - acc: 0.8202 - val_loss: 0.4568 - val_acc: 0.8791\n",
      "Epoch 349/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6099 - acc: 0.8190\n",
      "Epoch 00349: val_loss did not improve from 0.45681\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6099 - acc: 0.8190 - val_loss: 0.4593 - val_acc: 0.8789\n",
      "Epoch 350/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6068 - acc: 0.8222\n",
      "Epoch 00350: val_loss did not improve from 0.45681\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6068 - acc: 0.8222 - val_loss: 0.4582 - val_acc: 0.8817\n",
      "Epoch 351/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6056 - acc: 0.8204\n",
      "Epoch 00351: val_loss did not improve from 0.45681\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6053 - acc: 0.8206 - val_loss: 0.4576 - val_acc: 0.8775\n",
      "Epoch 352/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.8222\n",
      "Epoch 00352: val_loss did not improve from 0.45681\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6020 - acc: 0.8223 - val_loss: 0.4639 - val_acc: 0.8775\n",
      "Epoch 353/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6033 - acc: 0.8205\n",
      "Epoch 00353: val_loss did not improve from 0.45681\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6034 - acc: 0.8205 - val_loss: 0.4606 - val_acc: 0.8807\n",
      "Epoch 354/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6041 - acc: 0.8207\n",
      "Epoch 00354: val_loss did not improve from 0.45681\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6041 - acc: 0.8206 - val_loss: 0.4718 - val_acc: 0.8749\n",
      "Epoch 355/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6012 - acc: 0.8224\n",
      "Epoch 00355: val_loss improved from 0.45681 to 0.45446, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/355-0.4545.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.6013 - acc: 0.8224 - val_loss: 0.4545 - val_acc: 0.8784\n",
      "Epoch 356/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6025 - acc: 0.8221\n",
      "Epoch 00356: val_loss did not improve from 0.45446\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6025 - acc: 0.8220 - val_loss: 0.4643 - val_acc: 0.8765\n",
      "Epoch 357/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6025 - acc: 0.8221\n",
      "Epoch 00357: val_loss did not improve from 0.45446\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.6024 - acc: 0.8221 - val_loss: 0.4684 - val_acc: 0.8800\n",
      "Epoch 358/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5996 - acc: 0.8226\n",
      "Epoch 00358: val_loss did not improve from 0.45446\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.5992 - acc: 0.8228 - val_loss: 0.4554 - val_acc: 0.8805\n",
      "Epoch 359/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.8194\n",
      "Epoch 00359: val_loss did not improve from 0.45446\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6024 - acc: 0.8194 - val_loss: 0.4593 - val_acc: 0.8775\n",
      "Epoch 360/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5927 - acc: 0.8249\n",
      "Epoch 00360: val_loss did not improve from 0.45446\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5937 - acc: 0.8248 - val_loss: 0.4565 - val_acc: 0.8807\n",
      "Epoch 361/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5972 - acc: 0.8232\n",
      "Epoch 00361: val_loss improved from 0.45446 to 0.44945, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/361-0.4495.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.5972 - acc: 0.8231 - val_loss: 0.4495 - val_acc: 0.8828\n",
      "Epoch 362/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5960 - acc: 0.8246\n",
      "Epoch 00362: val_loss did not improve from 0.44945\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5967 - acc: 0.8244 - val_loss: 0.4592 - val_acc: 0.8796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5944 - acc: 0.8249\n",
      "Epoch 00363: val_loss did not improve from 0.44945\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.5943 - acc: 0.8250 - val_loss: 0.4502 - val_acc: 0.8824\n",
      "Epoch 364/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5929 - acc: 0.8245\n",
      "Epoch 00364: val_loss did not improve from 0.44945\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5928 - acc: 0.8246 - val_loss: 0.4616 - val_acc: 0.8796\n",
      "Epoch 365/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5979 - acc: 0.8244\n",
      "Epoch 00365: val_loss did not improve from 0.44945\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5981 - acc: 0.8244 - val_loss: 0.4499 - val_acc: 0.8831\n",
      "Epoch 366/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5936 - acc: 0.8254\n",
      "Epoch 00366: val_loss did not improve from 0.44945\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5936 - acc: 0.8254 - val_loss: 0.4542 - val_acc: 0.8814\n",
      "Epoch 367/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5960 - acc: 0.8248\n",
      "Epoch 00367: val_loss did not improve from 0.44945\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5960 - acc: 0.8248 - val_loss: 0.4616 - val_acc: 0.8791\n",
      "Epoch 368/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6003 - acc: 0.8230\n",
      "Epoch 00368: val_loss did not improve from 0.44945\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6001 - acc: 0.8230 - val_loss: 0.4563 - val_acc: 0.8810\n",
      "Epoch 369/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5956 - acc: 0.8232\n",
      "Epoch 00369: val_loss improved from 0.44945 to 0.44871, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/369-0.4487.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.5960 - acc: 0.8231 - val_loss: 0.4487 - val_acc: 0.8847\n",
      "Epoch 370/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5992 - acc: 0.8229\n",
      "Epoch 00370: val_loss did not improve from 0.44871\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5991 - acc: 0.8229 - val_loss: 0.4506 - val_acc: 0.8817\n",
      "Epoch 371/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5908 - acc: 0.8259\n",
      "Epoch 00371: val_loss did not improve from 0.44871\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5907 - acc: 0.8259 - val_loss: 0.4537 - val_acc: 0.8812\n",
      "Epoch 372/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5950 - acc: 0.8241\n",
      "Epoch 00372: val_loss did not improve from 0.44871\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5951 - acc: 0.8241 - val_loss: 0.4620 - val_acc: 0.8772\n",
      "Epoch 373/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5888 - acc: 0.8273\n",
      "Epoch 00373: val_loss did not improve from 0.44871\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.5894 - acc: 0.8271 - val_loss: 0.4563 - val_acc: 0.8812\n",
      "Epoch 374/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5903 - acc: 0.8256\n",
      "Epoch 00374: val_loss improved from 0.44871 to 0.44461, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/374-0.4446.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.5904 - acc: 0.8256 - val_loss: 0.4446 - val_acc: 0.8849\n",
      "Epoch 375/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5915 - acc: 0.8236\n",
      "Epoch 00375: val_loss improved from 0.44461 to 0.44451, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/375-0.4445.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5919 - acc: 0.8234 - val_loss: 0.4445 - val_acc: 0.8838\n",
      "Epoch 376/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5865 - acc: 0.8282\n",
      "Epoch 00376: val_loss did not improve from 0.44451\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5864 - acc: 0.8283 - val_loss: 0.4529 - val_acc: 0.8800\n",
      "Epoch 377/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5877 - acc: 0.8250\n",
      "Epoch 00377: val_loss did not improve from 0.44451\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.5878 - acc: 0.8250 - val_loss: 0.4520 - val_acc: 0.8812\n",
      "Epoch 378/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5912 - acc: 0.8249\n",
      "Epoch 00378: val_loss did not improve from 0.44451\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.5912 - acc: 0.8249 - val_loss: 0.4467 - val_acc: 0.8803\n",
      "Epoch 379/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5846 - acc: 0.8269\n",
      "Epoch 00379: val_loss did not improve from 0.44451\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5851 - acc: 0.8268 - val_loss: 0.4629 - val_acc: 0.8784\n",
      "Epoch 380/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5887 - acc: 0.8266\n",
      "Epoch 00380: val_loss did not improve from 0.44451\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.5886 - acc: 0.8267 - val_loss: 0.4453 - val_acc: 0.8833\n",
      "Epoch 381/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5878 - acc: 0.8277\n",
      "Epoch 00381: val_loss improved from 0.44451 to 0.44194, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/381-0.4419.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.5881 - acc: 0.8276 - val_loss: 0.4419 - val_acc: 0.8838\n",
      "Epoch 382/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5882 - acc: 0.8242\n",
      "Epoch 00382: val_loss did not improve from 0.44194\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5881 - acc: 0.8242 - val_loss: 0.4440 - val_acc: 0.8856\n",
      "Epoch 383/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5904 - acc: 0.8242\n",
      "Epoch 00383: val_loss did not improve from 0.44194\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5903 - acc: 0.8242 - val_loss: 0.4468 - val_acc: 0.8835\n",
      "Epoch 384/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5772 - acc: 0.8305\n",
      "Epoch 00384: val_loss did not improve from 0.44194\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5779 - acc: 0.8303 - val_loss: 0.4490 - val_acc: 0.8800\n",
      "Epoch 385/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5843 - acc: 0.8276\n",
      "Epoch 00385: val_loss did not improve from 0.44194\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5844 - acc: 0.8276 - val_loss: 0.4437 - val_acc: 0.8849\n",
      "Epoch 386/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5837 - acc: 0.8255\n",
      "Epoch 00386: val_loss improved from 0.44194 to 0.43969, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/386-0.4397.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5836 - acc: 0.8255 - val_loss: 0.4397 - val_acc: 0.8840\n",
      "Epoch 387/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5820 - acc: 0.8287\n",
      "Epoch 00387: val_loss did not improve from 0.43969\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5819 - acc: 0.8288 - val_loss: 0.4432 - val_acc: 0.8863\n",
      "Epoch 388/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5828 - acc: 0.8261- ETA: 1s - loss: 0.5823 - a\n",
      "Epoch 00388: val_loss did not improve from 0.43969\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5826 - acc: 0.8261 - val_loss: 0.4441 - val_acc: 0.8798\n",
      "Epoch 389/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5822 - acc: 0.8277\n",
      "Epoch 00389: val_loss did not improve from 0.43969\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5823 - acc: 0.8277 - val_loss: 0.4452 - val_acc: 0.8838\n",
      "Epoch 390/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5835 - acc: 0.8276\n",
      "Epoch 00390: val_loss did not improve from 0.43969\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5833 - acc: 0.8276 - val_loss: 0.4611 - val_acc: 0.8812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5834 - acc: 0.8287\n",
      "Epoch 00391: val_loss improved from 0.43969 to 0.43915, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/391-0.4391.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5834 - acc: 0.8287 - val_loss: 0.4391 - val_acc: 0.8845\n",
      "Epoch 392/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5821 - acc: 0.8267\n",
      "Epoch 00392: val_loss did not improve from 0.43915\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5821 - acc: 0.8267 - val_loss: 0.4481 - val_acc: 0.8852\n",
      "Epoch 393/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5831 - acc: 0.8275\n",
      "Epoch 00393: val_loss improved from 0.43915 to 0.43818, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/393-0.4382.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.5831 - acc: 0.8274 - val_loss: 0.4382 - val_acc: 0.8856\n",
      "Epoch 394/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5756 - acc: 0.8325\n",
      "Epoch 00394: val_loss did not improve from 0.43818\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.5755 - acc: 0.8325 - val_loss: 0.4448 - val_acc: 0.8812\n",
      "Epoch 395/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5735 - acc: 0.8319\n",
      "Epoch 00395: val_loss did not improve from 0.43818\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5733 - acc: 0.8319 - val_loss: 0.4436 - val_acc: 0.8842\n",
      "Epoch 396/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5775 - acc: 0.8289\n",
      "Epoch 00396: val_loss did not improve from 0.43818\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5775 - acc: 0.8289 - val_loss: 0.4439 - val_acc: 0.8838\n",
      "Epoch 397/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5748 - acc: 0.8285\n",
      "Epoch 00397: val_loss improved from 0.43818 to 0.43629, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/397-0.4363.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.5746 - acc: 0.8286 - val_loss: 0.4363 - val_acc: 0.8875\n",
      "Epoch 398/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5803 - acc: 0.8279\n",
      "Epoch 00398: val_loss did not improve from 0.43629\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5801 - acc: 0.8280 - val_loss: 0.4486 - val_acc: 0.8847\n",
      "Epoch 399/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5696 - acc: 0.8302\n",
      "Epoch 00399: val_loss did not improve from 0.43629\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5697 - acc: 0.8302 - val_loss: 0.4437 - val_acc: 0.8866\n",
      "Epoch 400/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5721 - acc: 0.8307\n",
      "Epoch 00400: val_loss did not improve from 0.43629\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5727 - acc: 0.8305 - val_loss: 0.4386 - val_acc: 0.8859\n",
      "Epoch 401/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5728 - acc: 0.8298\n",
      "Epoch 00401: val_loss did not improve from 0.43629\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5724 - acc: 0.8300 - val_loss: 0.4372 - val_acc: 0.8859\n",
      "Epoch 402/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5785 - acc: 0.8275\n",
      "Epoch 00402: val_loss improved from 0.43629 to 0.42938, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/402-0.4294.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5786 - acc: 0.8275 - val_loss: 0.4294 - val_acc: 0.8868\n",
      "Epoch 403/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5824 - acc: 0.8293\n",
      "Epoch 00403: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5822 - acc: 0.8294 - val_loss: 0.4380 - val_acc: 0.8833\n",
      "Epoch 404/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5780 - acc: 0.8273\n",
      "Epoch 00404: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5783 - acc: 0.8272 - val_loss: 0.4348 - val_acc: 0.8852\n",
      "Epoch 405/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5765 - acc: 0.8310\n",
      "Epoch 00405: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5764 - acc: 0.8310 - val_loss: 0.4427 - val_acc: 0.8849\n",
      "Epoch 406/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.8289\n",
      "Epoch 00406: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5700 - acc: 0.8290 - val_loss: 0.4378 - val_acc: 0.8875\n",
      "Epoch 407/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5675 - acc: 0.8311\n",
      "Epoch 00407: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5679 - acc: 0.8311 - val_loss: 0.4321 - val_acc: 0.8856\n",
      "Epoch 408/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5744 - acc: 0.8286\n",
      "Epoch 00408: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5743 - acc: 0.8287 - val_loss: 0.4349 - val_acc: 0.8842\n",
      "Epoch 409/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5678 - acc: 0.8313\n",
      "Epoch 00409: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5677 - acc: 0.8313 - val_loss: 0.4443 - val_acc: 0.8842\n",
      "Epoch 410/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5716 - acc: 0.8286\n",
      "Epoch 00410: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5713 - acc: 0.8288 - val_loss: 0.4452 - val_acc: 0.8856\n",
      "Epoch 411/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5681 - acc: 0.8320\n",
      "Epoch 00411: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5680 - acc: 0.8321 - val_loss: 0.4418 - val_acc: 0.8859\n",
      "Epoch 412/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5680 - acc: 0.8305\n",
      "Epoch 00412: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.5679 - acc: 0.8305 - val_loss: 0.4353 - val_acc: 0.8861\n",
      "Epoch 413/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.8333\n",
      "Epoch 00413: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.5702 - acc: 0.8333 - val_loss: 0.4354 - val_acc: 0.8863\n",
      "Epoch 414/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5661 - acc: 0.8316\n",
      "Epoch 00414: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5663 - acc: 0.8314 - val_loss: 0.4388 - val_acc: 0.8852\n",
      "Epoch 415/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5666 - acc: 0.8308\n",
      "Epoch 00415: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5665 - acc: 0.8308 - val_loss: 0.4438 - val_acc: 0.8863\n",
      "Epoch 416/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5655 - acc: 0.8312\n",
      "Epoch 00416: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.5656 - acc: 0.8312 - val_loss: 0.4319 - val_acc: 0.8882\n",
      "Epoch 417/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5629 - acc: 0.8340\n",
      "Epoch 00417: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.5629 - acc: 0.8340 - val_loss: 0.4344 - val_acc: 0.8847\n",
      "Epoch 418/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5722 - acc: 0.8300\n",
      "Epoch 00418: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5723 - acc: 0.8300 - val_loss: 0.4377 - val_acc: 0.8856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5664 - acc: 0.8326\n",
      "Epoch 00419: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5665 - acc: 0.8325 - val_loss: 0.4295 - val_acc: 0.8877\n",
      "Epoch 420/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5672 - acc: 0.8317\n",
      "Epoch 00420: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5672 - acc: 0.8317 - val_loss: 0.4365 - val_acc: 0.8873\n",
      "Epoch 421/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.8328\n",
      "Epoch 00421: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5651 - acc: 0.8327 - val_loss: 0.4364 - val_acc: 0.8891\n",
      "Epoch 422/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5631 - acc: 0.8328\n",
      "Epoch 00422: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5644 - acc: 0.8326 - val_loss: 0.4485 - val_acc: 0.8833\n",
      "Epoch 423/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5613 - acc: 0.8336\n",
      "Epoch 00423: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5614 - acc: 0.8336 - val_loss: 0.4428 - val_acc: 0.8791\n",
      "Epoch 424/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5609 - acc: 0.8349\n",
      "Epoch 00424: val_loss did not improve from 0.42938\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5611 - acc: 0.8348 - val_loss: 0.4318 - val_acc: 0.8873\n",
      "Epoch 425/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5617 - acc: 0.8360\n",
      "Epoch 00425: val_loss improved from 0.42938 to 0.42404, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/425-0.4240.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.5615 - acc: 0.8360 - val_loss: 0.4240 - val_acc: 0.8887\n",
      "Epoch 426/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5653 - acc: 0.8314\n",
      "Epoch 00426: val_loss did not improve from 0.42404\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.5653 - acc: 0.8314 - val_loss: 0.4367 - val_acc: 0.8849\n",
      "Epoch 427/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5607 - acc: 0.8340\n",
      "Epoch 00427: val_loss did not improve from 0.42404\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5606 - acc: 0.8339 - val_loss: 0.4406 - val_acc: 0.8856\n",
      "Epoch 428/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5605 - acc: 0.8357\n",
      "Epoch 00428: val_loss did not improve from 0.42404\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5603 - acc: 0.8358 - val_loss: 0.4361 - val_acc: 0.8842\n",
      "Epoch 429/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5584 - acc: 0.8328\n",
      "Epoch 00429: val_loss did not improve from 0.42404\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5582 - acc: 0.8329 - val_loss: 0.4293 - val_acc: 0.8882\n",
      "Epoch 430/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5600 - acc: 0.8322\n",
      "Epoch 00430: val_loss did not improve from 0.42404\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5604 - acc: 0.8321 - val_loss: 0.4275 - val_acc: 0.8870\n",
      "Epoch 431/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5604 - acc: 0.8335\n",
      "Epoch 00431: val_loss did not improve from 0.42404\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5601 - acc: 0.8336 - val_loss: 0.4334 - val_acc: 0.8877\n",
      "Epoch 432/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5624 - acc: 0.8340\n",
      "Epoch 00432: val_loss did not improve from 0.42404\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5624 - acc: 0.8340 - val_loss: 0.4350 - val_acc: 0.8896\n",
      "Epoch 433/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5629 - acc: 0.8346\n",
      "Epoch 00433: val_loss did not improve from 0.42404\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.5629 - acc: 0.8346 - val_loss: 0.4283 - val_acc: 0.8877\n",
      "Epoch 434/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5586 - acc: 0.8342\n",
      "Epoch 00434: val_loss did not improve from 0.42404\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.5586 - acc: 0.8342 - val_loss: 0.4305 - val_acc: 0.8852\n",
      "Epoch 435/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5617 - acc: 0.8335\n",
      "Epoch 00435: val_loss did not improve from 0.42404\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.5617 - acc: 0.8336 - val_loss: 0.4356 - val_acc: 0.8835\n",
      "Epoch 436/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5518 - acc: 0.8338\n",
      "Epoch 00436: val_loss did not improve from 0.42404\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5517 - acc: 0.8337 - val_loss: 0.4261 - val_acc: 0.8875\n",
      "Epoch 437/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5584 - acc: 0.8343\n",
      "Epoch 00437: val_loss did not improve from 0.42404\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5584 - acc: 0.8343 - val_loss: 0.4574 - val_acc: 0.8812\n",
      "Epoch 438/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5620 - acc: 0.8316\n",
      "Epoch 00438: val_loss improved from 0.42404 to 0.42362, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/438-0.4236.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.5622 - acc: 0.8316 - val_loss: 0.4236 - val_acc: 0.8891\n",
      "Epoch 439/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5543 - acc: 0.8352\n",
      "Epoch 00439: val_loss did not improve from 0.42362\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5542 - acc: 0.8352 - val_loss: 0.4312 - val_acc: 0.8859\n",
      "Epoch 440/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5561 - acc: 0.8348\n",
      "Epoch 00440: val_loss did not improve from 0.42362\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5561 - acc: 0.8348 - val_loss: 0.4313 - val_acc: 0.8887\n",
      "Epoch 441/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5560 - acc: 0.8365\n",
      "Epoch 00441: val_loss did not improve from 0.42362\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5557 - acc: 0.8366 - val_loss: 0.4344 - val_acc: 0.8849\n",
      "Epoch 442/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5513 - acc: 0.8360\n",
      "Epoch 00442: val_loss did not improve from 0.42362\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5517 - acc: 0.8359 - val_loss: 0.4462 - val_acc: 0.8826\n",
      "Epoch 443/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5556 - acc: 0.8350\n",
      "Epoch 00443: val_loss did not improve from 0.42362\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5555 - acc: 0.8350 - val_loss: 0.4277 - val_acc: 0.8894\n",
      "Epoch 444/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5562 - acc: 0.8339\n",
      "Epoch 00444: val_loss did not improve from 0.42362\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5562 - acc: 0.8338 - val_loss: 0.4274 - val_acc: 0.8891\n",
      "Epoch 445/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5555 - acc: 0.8354\n",
      "Epoch 00445: val_loss improved from 0.42362 to 0.42337, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/445-0.4234.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.5552 - acc: 0.8355 - val_loss: 0.4234 - val_acc: 0.8880\n",
      "Epoch 446/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5510 - acc: 0.8369\n",
      "Epoch 00446: val_loss did not improve from 0.42337\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5510 - acc: 0.8369 - val_loss: 0.4314 - val_acc: 0.8901\n",
      "Epoch 447/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5494 - acc: 0.8366\n",
      "Epoch 00447: val_loss did not improve from 0.42337\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5493 - acc: 0.8367 - val_loss: 0.4311 - val_acc: 0.8880\n",
      "Epoch 448/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5439 - acc: 0.8364\n",
      "Epoch 00448: val_loss did not improve from 0.42337\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5440 - acc: 0.8363 - val_loss: 0.4261 - val_acc: 0.8905\n",
      "Epoch 449/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5504 - acc: 0.8372\n",
      "Epoch 00449: val_loss did not improve from 0.42337\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5504 - acc: 0.8371 - val_loss: 0.4246 - val_acc: 0.8905\n",
      "Epoch 450/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5517 - acc: 0.8351\n",
      "Epoch 00450: val_loss did not improve from 0.42337\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5520 - acc: 0.8351 - val_loss: 0.4302 - val_acc: 0.8889\n",
      "Epoch 451/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5526 - acc: 0.8345\n",
      "Epoch 00451: val_loss did not improve from 0.42337\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5528 - acc: 0.8346 - val_loss: 0.4242 - val_acc: 0.8887\n",
      "Epoch 452/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5524 - acc: 0.8364\n",
      "Epoch 00452: val_loss did not improve from 0.42337\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5524 - acc: 0.8364 - val_loss: 0.4319 - val_acc: 0.8861\n",
      "Epoch 453/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5516 - acc: 0.8360\n",
      "Epoch 00453: val_loss did not improve from 0.42337\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.5516 - acc: 0.8361 - val_loss: 0.4267 - val_acc: 0.8889\n",
      "Epoch 454/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5441 - acc: 0.8374\n",
      "Epoch 00454: val_loss improved from 0.42337 to 0.41974, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/454-0.4197.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.5442 - acc: 0.8374 - val_loss: 0.4197 - val_acc: 0.8915\n",
      "Epoch 455/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5520 - acc: 0.8351\n",
      "Epoch 00455: val_loss did not improve from 0.41974\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5517 - acc: 0.8352 - val_loss: 0.4273 - val_acc: 0.8870\n",
      "Epoch 456/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5506 - acc: 0.8380\n",
      "Epoch 00456: val_loss did not improve from 0.41974\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5505 - acc: 0.8381 - val_loss: 0.4301 - val_acc: 0.8852\n",
      "Epoch 457/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5467 - acc: 0.8361\n",
      "Epoch 00457: val_loss did not improve from 0.41974\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.5466 - acc: 0.8361 - val_loss: 0.4241 - val_acc: 0.8891\n",
      "Epoch 458/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5444 - acc: 0.8362\n",
      "Epoch 00458: val_loss did not improve from 0.41974\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.5445 - acc: 0.8362 - val_loss: 0.4231 - val_acc: 0.8882\n",
      "Epoch 459/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5476 - acc: 0.8392\n",
      "Epoch 00459: val_loss did not improve from 0.41974\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5476 - acc: 0.8392 - val_loss: 0.4295 - val_acc: 0.8873\n",
      "Epoch 460/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5487 - acc: 0.8386\n",
      "Epoch 00460: val_loss did not improve from 0.41974\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5489 - acc: 0.8386 - val_loss: 0.4222 - val_acc: 0.8884\n",
      "Epoch 461/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5452 - acc: 0.8392\n",
      "Epoch 00461: val_loss did not improve from 0.41974\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5452 - acc: 0.8391 - val_loss: 0.4257 - val_acc: 0.8859\n",
      "Epoch 462/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5440 - acc: 0.8380\n",
      "Epoch 00462: val_loss did not improve from 0.41974\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.5443 - acc: 0.8380 - val_loss: 0.4271 - val_acc: 0.8884\n",
      "Epoch 463/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5448 - acc: 0.8382\n",
      "Epoch 00463: val_loss did not improve from 0.41974\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5446 - acc: 0.8383 - val_loss: 0.4210 - val_acc: 0.8866\n",
      "Epoch 464/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5420 - acc: 0.8399\n",
      "Epoch 00464: val_loss did not improve from 0.41974\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5419 - acc: 0.8399 - val_loss: 0.4228 - val_acc: 0.8901\n",
      "Epoch 465/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5445 - acc: 0.8389\n",
      "Epoch 00465: val_loss improved from 0.41974 to 0.41635, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/465-0.4164.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5444 - acc: 0.8389 - val_loss: 0.4164 - val_acc: 0.8912\n",
      "Epoch 466/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5447 - acc: 0.8375\n",
      "Epoch 00466: val_loss did not improve from 0.41635\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5450 - acc: 0.8375 - val_loss: 0.4268 - val_acc: 0.8877\n",
      "Epoch 467/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5452 - acc: 0.8390\n",
      "Epoch 00467: val_loss did not improve from 0.41635\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5450 - acc: 0.8391 - val_loss: 0.4233 - val_acc: 0.8910\n",
      "Epoch 468/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5369 - acc: 0.8406\n",
      "Epoch 00468: val_loss did not improve from 0.41635\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5365 - acc: 0.8406 - val_loss: 0.4246 - val_acc: 0.8826\n",
      "Epoch 469/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5391 - acc: 0.8397\n",
      "Epoch 00469: val_loss did not improve from 0.41635\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5389 - acc: 0.8398 - val_loss: 0.4188 - val_acc: 0.8908\n",
      "Epoch 470/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5442 - acc: 0.8373\n",
      "Epoch 00470: val_loss did not improve from 0.41635\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5439 - acc: 0.8374 - val_loss: 0.4183 - val_acc: 0.8896\n",
      "Epoch 471/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5432 - acc: 0.8364\n",
      "Epoch 00471: val_loss did not improve from 0.41635\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5429 - acc: 0.8365 - val_loss: 0.4233 - val_acc: 0.8896\n",
      "Epoch 472/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5394 - acc: 0.8399\n",
      "Epoch 00472: val_loss did not improve from 0.41635\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5392 - acc: 0.8400 - val_loss: 0.4195 - val_acc: 0.8931\n",
      "Epoch 473/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5410 - acc: 0.8391\n",
      "Epoch 00473: val_loss did not improve from 0.41635\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5412 - acc: 0.8389 - val_loss: 0.4276 - val_acc: 0.8919\n",
      "Epoch 474/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5376 - acc: 0.8420\n",
      "Epoch 00474: val_loss did not improve from 0.41635\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.5377 - acc: 0.8420 - val_loss: 0.4312 - val_acc: 0.8891\n",
      "Epoch 475/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5375 - acc: 0.8389\n",
      "Epoch 00475: val_loss did not improve from 0.41635\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.5380 - acc: 0.8387 - val_loss: 0.4260 - val_acc: 0.8877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5373 - acc: 0.8406\n",
      "Epoch 00476: val_loss did not improve from 0.41635\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.5372 - acc: 0.8406 - val_loss: 0.4171 - val_acc: 0.8935\n",
      "Epoch 477/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5387 - acc: 0.8395- ETA: 1s - lo\n",
      "Epoch 00477: val_loss improved from 0.41635 to 0.41368, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/477-0.4137.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.5387 - acc: 0.8395 - val_loss: 0.4137 - val_acc: 0.8915\n",
      "Epoch 478/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5418 - acc: 0.8392\n",
      "Epoch 00478: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5418 - acc: 0.8392 - val_loss: 0.4189 - val_acc: 0.8919\n",
      "Epoch 479/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5382 - acc: 0.8394\n",
      "Epoch 00479: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5381 - acc: 0.8394 - val_loss: 0.4186 - val_acc: 0.8903\n",
      "Epoch 480/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5387 - acc: 0.8383\n",
      "Epoch 00480: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5388 - acc: 0.8383 - val_loss: 0.4170 - val_acc: 0.8889\n",
      "Epoch 481/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5399 - acc: 0.8394\n",
      "Epoch 00481: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5401 - acc: 0.8393 - val_loss: 0.4189 - val_acc: 0.8912\n",
      "Epoch 482/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5330 - acc: 0.8407\n",
      "Epoch 00482: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5329 - acc: 0.8406 - val_loss: 0.4159 - val_acc: 0.8891\n",
      "Epoch 483/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5328 - acc: 0.8414\n",
      "Epoch 00483: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5328 - acc: 0.8414 - val_loss: 0.4260 - val_acc: 0.8891\n",
      "Epoch 484/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5427 - acc: 0.8380\n",
      "Epoch 00484: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5425 - acc: 0.8380 - val_loss: 0.4214 - val_acc: 0.8889\n",
      "Epoch 485/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5342 - acc: 0.8397\n",
      "Epoch 00485: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5342 - acc: 0.8397 - val_loss: 0.4184 - val_acc: 0.8908\n",
      "Epoch 486/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5364 - acc: 0.8401\n",
      "Epoch 00486: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5360 - acc: 0.8403 - val_loss: 0.4155 - val_acc: 0.8912\n",
      "Epoch 487/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5308 - acc: 0.8396\n",
      "Epoch 00487: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5311 - acc: 0.8397 - val_loss: 0.4147 - val_acc: 0.8924\n",
      "Epoch 488/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5310 - acc: 0.8402\n",
      "Epoch 00488: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5310 - acc: 0.8402 - val_loss: 0.4137 - val_acc: 0.8931\n",
      "Epoch 489/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5402 - acc: 0.8407\n",
      "Epoch 00489: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5404 - acc: 0.8405 - val_loss: 0.4193 - val_acc: 0.8896\n",
      "Epoch 490/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5300 - acc: 0.8426\n",
      "Epoch 00490: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5301 - acc: 0.8426 - val_loss: 0.4140 - val_acc: 0.8919\n",
      "Epoch 491/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5348 - acc: 0.8394\n",
      "Epoch 00491: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5348 - acc: 0.8394 - val_loss: 0.4173 - val_acc: 0.8935\n",
      "Epoch 492/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5360 - acc: 0.8418\n",
      "Epoch 00492: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.5360 - acc: 0.8418 - val_loss: 0.4160 - val_acc: 0.8891\n",
      "Epoch 493/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5307 - acc: 0.8428\n",
      "Epoch 00493: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.5309 - acc: 0.8427 - val_loss: 0.4156 - val_acc: 0.8917\n",
      "Epoch 494/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5318 - acc: 0.8409\n",
      "Epoch 00494: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5318 - acc: 0.8409 - val_loss: 0.4175 - val_acc: 0.8908\n",
      "Epoch 495/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5270 - acc: 0.8427\n",
      "Epoch 00495: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5270 - acc: 0.8427 - val_loss: 0.4141 - val_acc: 0.8912\n",
      "Epoch 496/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5304 - acc: 0.8413\n",
      "Epoch 00496: val_loss did not improve from 0.41368\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.5304 - acc: 0.8413 - val_loss: 0.4159 - val_acc: 0.8903\n",
      "Epoch 497/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5247 - acc: 0.8448\n",
      "Epoch 00497: val_loss improved from 0.41368 to 0.41067, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_4_conv_checkpoint/497-0.4107.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.5247 - acc: 0.8449 - val_loss: 0.4107 - val_acc: 0.8915\n",
      "Epoch 498/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5290 - acc: 0.8417\n",
      "Epoch 00498: val_loss did not improve from 0.41067\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5290 - acc: 0.8417 - val_loss: 0.4207 - val_acc: 0.8854\n",
      "Epoch 499/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5343 - acc: 0.8406- ETA: 0s - loss: 0.5346 - acc: 0.840\n",
      "Epoch 00499: val_loss did not improve from 0.41067\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5341 - acc: 0.8407 - val_loss: 0.4159 - val_acc: 0.8905\n",
      "Epoch 500/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5282 - acc: 0.8434\n",
      "Epoch 00500: val_loss did not improve from 0.41067\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5279 - acc: 0.8435 - val_loss: 0.4138 - val_acc: 0.8915\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 372us/sample - loss: 0.4625 - acc: 0.8704\n",
      "Loss: 0.4625137715696174 Accuracy: 0.87040496\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5690 - acc: 0.1601\n",
      "Epoch 00001: val_loss improved from inf to 2.14749, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/001-2.1475.hdf5\n",
      "36805/36805 [==============================] - 32s 874us/sample - loss: 2.5690 - acc: 0.1601 - val_loss: 2.1475 - val_acc: 0.3247\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1290 - acc: 0.2914\n",
      "Epoch 00002: val_loss improved from 2.14749 to 1.86509, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/002-1.8651.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 2.1290 - acc: 0.2913 - val_loss: 1.8651 - val_acc: 0.4428\n",
      "Epoch 3/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.9455 - acc: 0.3495\n",
      "Epoch 00003: val_loss improved from 1.86509 to 1.69249, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/003-1.6925.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 1.9451 - acc: 0.3497 - val_loss: 1.6925 - val_acc: 0.4826\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8075 - acc: 0.3999\n",
      "Epoch 00004: val_loss improved from 1.69249 to 1.58242, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/004-1.5824.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 1.8075 - acc: 0.3999 - val_loss: 1.5824 - val_acc: 0.5164\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7025 - acc: 0.4361\n",
      "Epoch 00005: val_loss improved from 1.58242 to 1.47531, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/005-1.4753.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.7023 - acc: 0.4362 - val_loss: 1.4753 - val_acc: 0.5521\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6187 - acc: 0.4636\n",
      "Epoch 00006: val_loss improved from 1.47531 to 1.39772, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/006-1.3977.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.6187 - acc: 0.4636 - val_loss: 1.3977 - val_acc: 0.5747\n",
      "Epoch 7/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5412 - acc: 0.4955\n",
      "Epoch 00007: val_loss improved from 1.39772 to 1.32165, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/007-1.3216.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.5413 - acc: 0.4956 - val_loss: 1.3216 - val_acc: 0.6154\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4784 - acc: 0.5206\n",
      "Epoch 00008: val_loss improved from 1.32165 to 1.25578, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/008-1.2558.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.4782 - acc: 0.5206 - val_loss: 1.2558 - val_acc: 0.6317\n",
      "Epoch 9/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4209 - acc: 0.5403\n",
      "Epoch 00009: val_loss improved from 1.25578 to 1.20568, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/009-1.2057.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 1.4208 - acc: 0.5404 - val_loss: 1.2057 - val_acc: 0.6471\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3741 - acc: 0.5617\n",
      "Epoch 00010: val_loss improved from 1.20568 to 1.16507, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/010-1.1651.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.3738 - acc: 0.5617 - val_loss: 1.1651 - val_acc: 0.6539\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3194 - acc: 0.5819\n",
      "Epoch 00011: val_loss improved from 1.16507 to 1.11186, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/011-1.1119.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.3193 - acc: 0.5820 - val_loss: 1.1119 - val_acc: 0.6671\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2783 - acc: 0.5983\n",
      "Epoch 00012: val_loss improved from 1.11186 to 1.07478, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/012-1.0748.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.2782 - acc: 0.5983 - val_loss: 1.0748 - val_acc: 0.6853\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2291 - acc: 0.6171\n",
      "Epoch 00013: val_loss improved from 1.07478 to 1.03739, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/013-1.0374.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 1.2292 - acc: 0.6171 - val_loss: 1.0374 - val_acc: 0.6879\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1883 - acc: 0.6308\n",
      "Epoch 00014: val_loss did not improve from 1.03739\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 1.1884 - acc: 0.6308 - val_loss: 1.0684 - val_acc: 0.6844\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1574 - acc: 0.6418\n",
      "Epoch 00015: val_loss improved from 1.03739 to 0.95186, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/015-0.9519.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.1574 - acc: 0.6419 - val_loss: 0.9519 - val_acc: 0.7205\n",
      "Epoch 16/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1099 - acc: 0.6592\n",
      "Epoch 00016: val_loss improved from 0.95186 to 0.91684, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/016-0.9168.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 1.1099 - acc: 0.6592 - val_loss: 0.9168 - val_acc: 0.7303\n",
      "Epoch 17/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0812 - acc: 0.6698\n",
      "Epoch 00017: val_loss improved from 0.91684 to 0.89327, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/017-0.8933.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.0814 - acc: 0.6697 - val_loss: 0.8933 - val_acc: 0.7419\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0489 - acc: 0.6792\n",
      "Epoch 00018: val_loss improved from 0.89327 to 0.85131, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/018-0.8513.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.0492 - acc: 0.6791 - val_loss: 0.8513 - val_acc: 0.7561\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0167 - acc: 0.6910\n",
      "Epoch 00019: val_loss improved from 0.85131 to 0.84585, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/019-0.8459.hdf5\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 1.0167 - acc: 0.6910 - val_loss: 0.8459 - val_acc: 0.7594\n",
      "Epoch 20/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9941 - acc: 0.6971\n",
      "Epoch 00020: val_loss improved from 0.84585 to 0.79740, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/020-0.7974.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.9938 - acc: 0.6972 - val_loss: 0.7974 - val_acc: 0.7678\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9669 - acc: 0.7081\n",
      "Epoch 00021: val_loss improved from 0.79740 to 0.77892, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/021-0.7789.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.9670 - acc: 0.7081 - val_loss: 0.7789 - val_acc: 0.7736\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9481 - acc: 0.7168\n",
      "Epoch 00022: val_loss improved from 0.77892 to 0.74484, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/022-0.7448.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.9480 - acc: 0.7169 - val_loss: 0.7448 - val_acc: 0.7873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9275 - acc: 0.7221\n",
      "Epoch 00023: val_loss improved from 0.74484 to 0.72684, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/023-0.7268.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.9275 - acc: 0.7222 - val_loss: 0.7268 - val_acc: 0.7897\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9008 - acc: 0.7277\n",
      "Epoch 00024: val_loss improved from 0.72684 to 0.71215, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/024-0.7122.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.9011 - acc: 0.7277 - val_loss: 0.7122 - val_acc: 0.7992\n",
      "Epoch 25/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8813 - acc: 0.7390\n",
      "Epoch 00025: val_loss did not improve from 0.71215\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.8810 - acc: 0.7391 - val_loss: 0.7215 - val_acc: 0.7887\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8502 - acc: 0.7478\n",
      "Epoch 00026: val_loss improved from 0.71215 to 0.70383, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/026-0.7038.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8502 - acc: 0.7478 - val_loss: 0.7038 - val_acc: 0.8095\n",
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8446 - acc: 0.7498\n",
      "Epoch 00027: val_loss improved from 0.70383 to 0.65798, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/027-0.6580.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.8447 - acc: 0.7498 - val_loss: 0.6580 - val_acc: 0.8106\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8250 - acc: 0.7551\n",
      "Epoch 00028: val_loss improved from 0.65798 to 0.65086, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/028-0.6509.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.8248 - acc: 0.7551 - val_loss: 0.6509 - val_acc: 0.8141\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8089 - acc: 0.7628\n",
      "Epoch 00029: val_loss improved from 0.65086 to 0.63262, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/029-0.6326.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.8089 - acc: 0.7627 - val_loss: 0.6326 - val_acc: 0.8286\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7938 - acc: 0.7660\n",
      "Epoch 00030: val_loss improved from 0.63262 to 0.61453, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/030-0.6145.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.7938 - acc: 0.7660 - val_loss: 0.6145 - val_acc: 0.8311\n",
      "Epoch 31/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7725 - acc: 0.7704\n",
      "Epoch 00031: val_loss improved from 0.61453 to 0.60190, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/031-0.6019.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.7722 - acc: 0.7705 - val_loss: 0.6019 - val_acc: 0.8293\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7632 - acc: 0.7771\n",
      "Epoch 00032: val_loss improved from 0.60190 to 0.58242, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/032-0.5824.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.7632 - acc: 0.7771 - val_loss: 0.5824 - val_acc: 0.8386\n",
      "Epoch 33/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7506 - acc: 0.7770\n",
      "Epoch 00033: val_loss improved from 0.58242 to 0.57489, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/033-0.5749.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.7507 - acc: 0.7769 - val_loss: 0.5749 - val_acc: 0.8446\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7381 - acc: 0.7842\n",
      "Epoch 00034: val_loss improved from 0.57489 to 0.57398, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/034-0.5740.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.7383 - acc: 0.7842 - val_loss: 0.5740 - val_acc: 0.8409\n",
      "Epoch 35/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7237 - acc: 0.7887\n",
      "Epoch 00035: val_loss improved from 0.57398 to 0.54924, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/035-0.5492.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.7236 - acc: 0.7886 - val_loss: 0.5492 - val_acc: 0.8530\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7157 - acc: 0.7921\n",
      "Epoch 00036: val_loss did not improve from 0.54924\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.7160 - acc: 0.7921 - val_loss: 0.5547 - val_acc: 0.8446\n",
      "Epoch 37/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7029 - acc: 0.7940\n",
      "Epoch 00037: val_loss improved from 0.54924 to 0.54711, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/037-0.5471.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.7028 - acc: 0.7940 - val_loss: 0.5471 - val_acc: 0.8523\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6904 - acc: 0.7998\n",
      "Epoch 00038: val_loss improved from 0.54711 to 0.54076, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/038-0.5408.hdf5\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.6905 - acc: 0.7997 - val_loss: 0.5408 - val_acc: 0.8477\n",
      "Epoch 39/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6824 - acc: 0.8018\n",
      "Epoch 00039: val_loss improved from 0.54076 to 0.53141, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/039-0.5314.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.6821 - acc: 0.8019 - val_loss: 0.5314 - val_acc: 0.8486\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6734 - acc: 0.8034\n",
      "Epoch 00040: val_loss improved from 0.53141 to 0.51258, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/040-0.5126.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.6733 - acc: 0.8034 - val_loss: 0.5126 - val_acc: 0.8628\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6609 - acc: 0.8089\n",
      "Epoch 00041: val_loss improved from 0.51258 to 0.51048, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/041-0.5105.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.6608 - acc: 0.8089 - val_loss: 0.5105 - val_acc: 0.8600\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6524 - acc: 0.8102\n",
      "Epoch 00042: val_loss improved from 0.51048 to 0.50232, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/042-0.5023.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.6525 - acc: 0.8102 - val_loss: 0.5023 - val_acc: 0.8698\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6475 - acc: 0.8110\n",
      "Epoch 00043: val_loss improved from 0.50232 to 0.48747, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/043-0.4875.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.6473 - acc: 0.8109 - val_loss: 0.4875 - val_acc: 0.8742\n",
      "Epoch 44/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6382 - acc: 0.8139\n",
      "Epoch 00044: val_loss improved from 0.48747 to 0.47423, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/044-0.4742.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.6382 - acc: 0.8140 - val_loss: 0.4742 - val_acc: 0.8742\n",
      "Epoch 45/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6283 - acc: 0.8179\n",
      "Epoch 00045: val_loss did not improve from 0.47423\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.6286 - acc: 0.8178 - val_loss: 0.4894 - val_acc: 0.8717\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6265 - acc: 0.8186\n",
      "Epoch 00046: val_loss improved from 0.47423 to 0.46037, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/046-0.4604.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.6265 - acc: 0.8185 - val_loss: 0.4604 - val_acc: 0.8845\n",
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6192 - acc: 0.8210\n",
      "Epoch 00047: val_loss did not improve from 0.46037\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.6196 - acc: 0.8209 - val_loss: 0.4619 - val_acc: 0.8819\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6070 - acc: 0.8249\n",
      "Epoch 00048: val_loss improved from 0.46037 to 0.44953, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/048-0.4495.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.6070 - acc: 0.8249 - val_loss: 0.4495 - val_acc: 0.8868\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6003 - acc: 0.8249\n",
      "Epoch 00049: val_loss improved from 0.44953 to 0.44807, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/049-0.4481.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.5999 - acc: 0.8250 - val_loss: 0.4481 - val_acc: 0.8870\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5977 - acc: 0.8265\n",
      "Epoch 00050: val_loss did not improve from 0.44807\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.5983 - acc: 0.8264 - val_loss: 0.4551 - val_acc: 0.8814\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5874 - acc: 0.8290\n",
      "Epoch 00051: val_loss improved from 0.44807 to 0.43590, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/051-0.4359.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.5873 - acc: 0.8290 - val_loss: 0.4359 - val_acc: 0.8875\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5838 - acc: 0.8327\n",
      "Epoch 00052: val_loss improved from 0.43590 to 0.42529, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/052-0.4253.hdf5\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.5838 - acc: 0.8327 - val_loss: 0.4253 - val_acc: 0.8928\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5738 - acc: 0.8343\n",
      "Epoch 00053: val_loss improved from 0.42529 to 0.42144, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/053-0.4214.hdf5\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.5739 - acc: 0.8343 - val_loss: 0.4214 - val_acc: 0.8933\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5685 - acc: 0.8355\n",
      "Epoch 00054: val_loss improved from 0.42144 to 0.41659, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/054-0.4166.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.5686 - acc: 0.8355 - val_loss: 0.4166 - val_acc: 0.8961\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5642 - acc: 0.8374\n",
      "Epoch 00055: val_loss did not improve from 0.41659\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.5642 - acc: 0.8373 - val_loss: 0.4327 - val_acc: 0.8833\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5596 - acc: 0.8382\n",
      "Epoch 00056: val_loss improved from 0.41659 to 0.40730, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/056-0.4073.hdf5\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.5596 - acc: 0.8382 - val_loss: 0.4073 - val_acc: 0.8917\n",
      "Epoch 57/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5526 - acc: 0.8404\n",
      "Epoch 00057: val_loss did not improve from 0.40730\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.5525 - acc: 0.8403 - val_loss: 0.4136 - val_acc: 0.8945\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5440 - acc: 0.8421\n",
      "Epoch 00058: val_loss improved from 0.40730 to 0.39183, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/058-0.3918.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.5441 - acc: 0.8421 - val_loss: 0.3918 - val_acc: 0.8980\n",
      "Epoch 59/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5457 - acc: 0.8443\n",
      "Epoch 00059: val_loss did not improve from 0.39183\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.5459 - acc: 0.8443 - val_loss: 0.4102 - val_acc: 0.8938\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5351 - acc: 0.8451\n",
      "Epoch 00060: val_loss did not improve from 0.39183\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.5352 - acc: 0.8450 - val_loss: 0.4002 - val_acc: 0.8975\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5304 - acc: 0.8462\n",
      "Epoch 00061: val_loss improved from 0.39183 to 0.38513, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/061-0.3851.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.5303 - acc: 0.8462 - val_loss: 0.3851 - val_acc: 0.8952\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5226 - acc: 0.8519\n",
      "Epoch 00062: val_loss improved from 0.38513 to 0.38417, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/062-0.3842.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.5225 - acc: 0.8519 - val_loss: 0.3842 - val_acc: 0.8982\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5210 - acc: 0.8495\n",
      "Epoch 00063: val_loss did not improve from 0.38417\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.5210 - acc: 0.8495 - val_loss: 0.3866 - val_acc: 0.8973\n",
      "Epoch 64/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5231 - acc: 0.8505\n",
      "Epoch 00064: val_loss did not improve from 0.38417\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.5235 - acc: 0.8505 - val_loss: 0.3900 - val_acc: 0.9005\n",
      "Epoch 65/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5110 - acc: 0.8524\n",
      "Epoch 00065: val_loss improved from 0.38417 to 0.37659, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/065-0.3766.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.5110 - acc: 0.8523 - val_loss: 0.3766 - val_acc: 0.9017\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5062 - acc: 0.8519\n",
      "Epoch 00066: val_loss did not improve from 0.37659\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.5062 - acc: 0.8519 - val_loss: 0.3829 - val_acc: 0.8984\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4989 - acc: 0.8563\n",
      "Epoch 00067: val_loss improved from 0.37659 to 0.36691, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/067-0.3669.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.4988 - acc: 0.8563 - val_loss: 0.3669 - val_acc: 0.9045\n",
      "Epoch 68/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4975 - acc: 0.8557\n",
      "Epoch 00068: val_loss did not improve from 0.36691\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.4973 - acc: 0.8558 - val_loss: 0.3742 - val_acc: 0.9038\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4918 - acc: 0.8573\n",
      "Epoch 00069: val_loss did not improve from 0.36691\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.4919 - acc: 0.8573 - val_loss: 0.3713 - val_acc: 0.8984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4916 - acc: 0.8581\n",
      "Epoch 00070: val_loss did not improve from 0.36691\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.4916 - acc: 0.8581 - val_loss: 0.3739 - val_acc: 0.9038\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4879 - acc: 0.8592\n",
      "Epoch 00071: val_loss improved from 0.36691 to 0.35997, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/071-0.3600.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.4879 - acc: 0.8592 - val_loss: 0.3600 - val_acc: 0.9047\n",
      "Epoch 72/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4780 - acc: 0.8635\n",
      "Epoch 00072: val_loss improved from 0.35997 to 0.35175, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/072-0.3517.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.4782 - acc: 0.8634 - val_loss: 0.3517 - val_acc: 0.9066\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4800 - acc: 0.8605\n",
      "Epoch 00073: val_loss improved from 0.35175 to 0.35032, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/073-0.3503.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.4801 - acc: 0.8605 - val_loss: 0.3503 - val_acc: 0.9096\n",
      "Epoch 74/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4821 - acc: 0.8608\n",
      "Epoch 00074: val_loss improved from 0.35032 to 0.34995, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/074-0.3499.hdf5\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.4821 - acc: 0.8609 - val_loss: 0.3499 - val_acc: 0.9089\n",
      "Epoch 75/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4734 - acc: 0.8653\n",
      "Epoch 00075: val_loss improved from 0.34995 to 0.34603, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/075-0.3460.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.4733 - acc: 0.8653 - val_loss: 0.3460 - val_acc: 0.9103\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4661 - acc: 0.8638\n",
      "Epoch 00076: val_loss did not improve from 0.34603\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.4663 - acc: 0.8637 - val_loss: 0.3556 - val_acc: 0.9024\n",
      "Epoch 77/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4576 - acc: 0.8679\n",
      "Epoch 00077: val_loss improved from 0.34603 to 0.34221, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/077-0.3422.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.4572 - acc: 0.8680 - val_loss: 0.3422 - val_acc: 0.9080\n",
      "Epoch 78/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4626 - acc: 0.8664- ETA: 1s - \n",
      "Epoch 00078: val_loss did not improve from 0.34221\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.4624 - acc: 0.8664 - val_loss: 0.3638 - val_acc: 0.9064\n",
      "Epoch 79/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.8671\n",
      "Epoch 00079: val_loss did not improve from 0.34221\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.4582 - acc: 0.8671 - val_loss: 0.3456 - val_acc: 0.9124\n",
      "Epoch 80/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4499 - acc: 0.8699\n",
      "Epoch 00080: val_loss did not improve from 0.34221\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.4498 - acc: 0.8699 - val_loss: 0.3474 - val_acc: 0.9103\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4511 - acc: 0.8699\n",
      "Epoch 00081: val_loss improved from 0.34221 to 0.33318, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/081-0.3332.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.4511 - acc: 0.8699 - val_loss: 0.3332 - val_acc: 0.9124\n",
      "Epoch 82/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.8701\n",
      "Epoch 00082: val_loss did not improve from 0.33318\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.4499 - acc: 0.8702 - val_loss: 0.3437 - val_acc: 0.9122\n",
      "Epoch 83/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4402 - acc: 0.8726\n",
      "Epoch 00083: val_loss improved from 0.33318 to 0.33150, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/083-0.3315.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.4400 - acc: 0.8726 - val_loss: 0.3315 - val_acc: 0.9115\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4403 - acc: 0.8731\n",
      "Epoch 00084: val_loss improved from 0.33150 to 0.32843, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/084-0.3284.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.4403 - acc: 0.8731 - val_loss: 0.3284 - val_acc: 0.9126\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4318 - acc: 0.8754\n",
      "Epoch 00085: val_loss did not improve from 0.32843\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.4318 - acc: 0.8754 - val_loss: 0.3343 - val_acc: 0.9133\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4279 - acc: 0.8758\n",
      "Epoch 00086: val_loss did not improve from 0.32843\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.4279 - acc: 0.8759 - val_loss: 0.3338 - val_acc: 0.9136\n",
      "Epoch 87/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4323 - acc: 0.8734\n",
      "Epoch 00087: val_loss improved from 0.32843 to 0.32728, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/087-0.3273.hdf5\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.4326 - acc: 0.8734 - val_loss: 0.3273 - val_acc: 0.9173\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4312 - acc: 0.8743\n",
      "Epoch 00088: val_loss improved from 0.32728 to 0.31421, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/088-0.3142.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.4312 - acc: 0.8743 - val_loss: 0.3142 - val_acc: 0.9171\n",
      "Epoch 89/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4239 - acc: 0.8762- ETA: 0s - loss: 0.4232 - acc: \n",
      "Epoch 00089: val_loss did not improve from 0.31421\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.4236 - acc: 0.8763 - val_loss: 0.3187 - val_acc: 0.9147\n",
      "Epoch 90/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4227 - acc: 0.8758\n",
      "Epoch 00090: val_loss did not improve from 0.31421\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.4225 - acc: 0.8759 - val_loss: 0.3148 - val_acc: 0.9201\n",
      "Epoch 91/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4189 - acc: 0.8783\n",
      "Epoch 00091: val_loss did not improve from 0.31421\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.4185 - acc: 0.8784 - val_loss: 0.3188 - val_acc: 0.9182\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4128 - acc: 0.8790\n",
      "Epoch 00092: val_loss improved from 0.31421 to 0.30531, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/092-0.3053.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.4128 - acc: 0.8791 - val_loss: 0.3053 - val_acc: 0.9224\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4150 - acc: 0.8783\n",
      "Epoch 00093: val_loss did not improve from 0.30531\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.4150 - acc: 0.8783 - val_loss: 0.3196 - val_acc: 0.9192\n",
      "Epoch 94/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4065 - acc: 0.8823\n",
      "Epoch 00094: val_loss improved from 0.30531 to 0.30205, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/094-0.3021.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.4063 - acc: 0.8824 - val_loss: 0.3021 - val_acc: 0.9227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4089 - acc: 0.8796\n",
      "Epoch 00095: val_loss improved from 0.30205 to 0.29921, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/095-0.2992.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.4089 - acc: 0.8796 - val_loss: 0.2992 - val_acc: 0.9224\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4067 - acc: 0.8815\n",
      "Epoch 00096: val_loss did not improve from 0.29921\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.4066 - acc: 0.8815 - val_loss: 0.3017 - val_acc: 0.9231\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4107 - acc: 0.8796\n",
      "Epoch 00097: val_loss did not improve from 0.29921\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.4106 - acc: 0.8796 - val_loss: 0.3038 - val_acc: 0.9196\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4034 - acc: 0.8804\n",
      "Epoch 00098: val_loss did not improve from 0.29921\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.4033 - acc: 0.8804 - val_loss: 0.3176 - val_acc: 0.9203\n",
      "Epoch 99/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3966 - acc: 0.8856\n",
      "Epoch 00099: val_loss improved from 0.29921 to 0.29654, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/099-0.2965.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3967 - acc: 0.8856 - val_loss: 0.2965 - val_acc: 0.9222\n",
      "Epoch 100/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3978 - acc: 0.8850\n",
      "Epoch 00100: val_loss did not improve from 0.29654\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3977 - acc: 0.8850 - val_loss: 0.3017 - val_acc: 0.9236\n",
      "Epoch 101/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3916 - acc: 0.8859\n",
      "Epoch 00101: val_loss improved from 0.29654 to 0.28930, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/101-0.2893.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3919 - acc: 0.8858 - val_loss: 0.2893 - val_acc: 0.9252\n",
      "Epoch 102/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3902 - acc: 0.8874\n",
      "Epoch 00102: val_loss did not improve from 0.28930\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.3904 - acc: 0.8874 - val_loss: 0.2941 - val_acc: 0.9245\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3928 - acc: 0.8836\n",
      "Epoch 00103: val_loss did not improve from 0.28930\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3928 - acc: 0.8836 - val_loss: 0.2943 - val_acc: 0.9250\n",
      "Epoch 104/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3880 - acc: 0.8853\n",
      "Epoch 00104: val_loss did not improve from 0.28930\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3878 - acc: 0.8855 - val_loss: 0.3040 - val_acc: 0.9231\n",
      "Epoch 105/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3877 - acc: 0.8876\n",
      "Epoch 00105: val_loss did not improve from 0.28930\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3876 - acc: 0.8877 - val_loss: 0.2920 - val_acc: 0.9255\n",
      "Epoch 106/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3769 - acc: 0.8900\n",
      "Epoch 00106: val_loss improved from 0.28930 to 0.28868, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/106-0.2887.hdf5\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.3767 - acc: 0.8901 - val_loss: 0.2887 - val_acc: 0.9271\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3860 - acc: 0.8863\n",
      "Epoch 00107: val_loss did not improve from 0.28868\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3860 - acc: 0.8863 - val_loss: 0.2921 - val_acc: 0.9241\n",
      "Epoch 108/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3797 - acc: 0.8878\n",
      "Epoch 00108: val_loss improved from 0.28868 to 0.28319, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/108-0.2832.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.3796 - acc: 0.8878 - val_loss: 0.2832 - val_acc: 0.9266\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3739 - acc: 0.8915\n",
      "Epoch 00109: val_loss did not improve from 0.28319\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3738 - acc: 0.8915 - val_loss: 0.2996 - val_acc: 0.9201\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3745 - acc: 0.8892\n",
      "Epoch 00110: val_loss did not improve from 0.28319\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3745 - acc: 0.8893 - val_loss: 0.2922 - val_acc: 0.9255\n",
      "Epoch 111/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3774 - acc: 0.8894\n",
      "Epoch 00111: val_loss improved from 0.28319 to 0.28272, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/111-0.2827.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3779 - acc: 0.8893 - val_loss: 0.2827 - val_acc: 0.9259\n",
      "Epoch 112/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3685 - acc: 0.8904\n",
      "Epoch 00112: val_loss improved from 0.28272 to 0.28061, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/112-0.2806.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3684 - acc: 0.8904 - val_loss: 0.2806 - val_acc: 0.9273\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3664 - acc: 0.8917\n",
      "Epoch 00113: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3665 - acc: 0.8917 - val_loss: 0.2839 - val_acc: 0.9292\n",
      "Epoch 114/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3661 - acc: 0.8914\n",
      "Epoch 00114: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3660 - acc: 0.8915 - val_loss: 0.2869 - val_acc: 0.9229\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3688 - acc: 0.8932\n",
      "Epoch 00115: val_loss improved from 0.28061 to 0.27564, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/115-0.2756.hdf5\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.3687 - acc: 0.8932 - val_loss: 0.2756 - val_acc: 0.9259\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3660 - acc: 0.8922\n",
      "Epoch 00116: val_loss did not improve from 0.27564\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3659 - acc: 0.8922 - val_loss: 0.2766 - val_acc: 0.9238\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3597 - acc: 0.8933\n",
      "Epoch 00117: val_loss did not improve from 0.27564\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3597 - acc: 0.8934 - val_loss: 0.2844 - val_acc: 0.9278\n",
      "Epoch 118/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3541 - acc: 0.8968\n",
      "Epoch 00118: val_loss did not improve from 0.27564\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3541 - acc: 0.8967 - val_loss: 0.2800 - val_acc: 0.9245\n",
      "Epoch 119/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3590 - acc: 0.8940\n",
      "Epoch 00119: val_loss improved from 0.27564 to 0.27318, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/119-0.2732.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3589 - acc: 0.8941 - val_loss: 0.2732 - val_acc: 0.9292\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3551 - acc: 0.8956\n",
      "Epoch 00120: val_loss did not improve from 0.27318\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3551 - acc: 0.8956 - val_loss: 0.2736 - val_acc: 0.9283\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3513 - acc: 0.8964\n",
      "Epoch 00121: val_loss did not improve from 0.27318\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3513 - acc: 0.8964 - val_loss: 0.2848 - val_acc: 0.9278\n",
      "Epoch 122/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3544 - acc: 0.8947\n",
      "Epoch 00122: val_loss improved from 0.27318 to 0.26653, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/122-0.2665.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3544 - acc: 0.8947 - val_loss: 0.2665 - val_acc: 0.9313\n",
      "Epoch 123/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3526 - acc: 0.8945\n",
      "Epoch 00123: val_loss did not improve from 0.26653\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.3525 - acc: 0.8946 - val_loss: 0.2759 - val_acc: 0.9292\n",
      "Epoch 124/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3543 - acc: 0.8953\n",
      "Epoch 00124: val_loss did not improve from 0.26653\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3543 - acc: 0.8952 - val_loss: 0.2774 - val_acc: 0.9299\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3509 - acc: 0.8974\n",
      "Epoch 00125: val_loss did not improve from 0.26653\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3509 - acc: 0.8974 - val_loss: 0.2706 - val_acc: 0.9290\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3435 - acc: 0.8971\n",
      "Epoch 00126: val_loss did not improve from 0.26653\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.3434 - acc: 0.8971 - val_loss: 0.2698 - val_acc: 0.9313\n",
      "Epoch 127/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3407 - acc: 0.8987\n",
      "Epoch 00127: val_loss improved from 0.26653 to 0.26652, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/127-0.2665.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.3410 - acc: 0.8986 - val_loss: 0.2665 - val_acc: 0.9308\n",
      "Epoch 128/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3415 - acc: 0.9006\n",
      "Epoch 00128: val_loss did not improve from 0.26652\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3420 - acc: 0.9006 - val_loss: 0.2747 - val_acc: 0.9276\n",
      "Epoch 129/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3356 - acc: 0.9005\n",
      "Epoch 00129: val_loss did not improve from 0.26652\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3353 - acc: 0.9006 - val_loss: 0.2694 - val_acc: 0.9290\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3387 - acc: 0.9002- \n",
      "Epoch 00130: val_loss improved from 0.26652 to 0.26494, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/130-0.2649.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3387 - acc: 0.9002 - val_loss: 0.2649 - val_acc: 0.9304\n",
      "Epoch 131/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3348 - acc: 0.9007\n",
      "Epoch 00131: val_loss did not improve from 0.26494\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3347 - acc: 0.9007 - val_loss: 0.2923 - val_acc: 0.9248\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3328 - acc: 0.8989\n",
      "Epoch 00132: val_loss did not improve from 0.26494\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.3329 - acc: 0.8988 - val_loss: 0.2687 - val_acc: 0.9308\n",
      "Epoch 133/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3292 - acc: 0.9014\n",
      "Epoch 00133: val_loss did not improve from 0.26494\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3290 - acc: 0.9015 - val_loss: 0.2654 - val_acc: 0.9341\n",
      "Epoch 134/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3374 - acc: 0.8991\n",
      "Epoch 00134: val_loss improved from 0.26494 to 0.26311, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/134-0.2631.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.3370 - acc: 0.8993 - val_loss: 0.2631 - val_acc: 0.9320\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3308 - acc: 0.9032\n",
      "Epoch 00135: val_loss improved from 0.26311 to 0.26090, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/135-0.2609.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3308 - acc: 0.9032 - val_loss: 0.2609 - val_acc: 0.9341\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3355 - acc: 0.8998\n",
      "Epoch 00136: val_loss improved from 0.26090 to 0.25897, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/136-0.2590.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3355 - acc: 0.8998 - val_loss: 0.2590 - val_acc: 0.9306\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3279 - acc: 0.9018\n",
      "Epoch 00137: val_loss did not improve from 0.25897\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3278 - acc: 0.9019 - val_loss: 0.2600 - val_acc: 0.9315\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3220 - acc: 0.9036\n",
      "Epoch 00138: val_loss did not improve from 0.25897\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3220 - acc: 0.9036 - val_loss: 0.2700 - val_acc: 0.9271\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3231 - acc: 0.9017\n",
      "Epoch 00139: val_loss improved from 0.25897 to 0.25354, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/139-0.2535.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3231 - acc: 0.9018 - val_loss: 0.2535 - val_acc: 0.9324\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3248 - acc: 0.9036\n",
      "Epoch 00140: val_loss did not improve from 0.25354\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3248 - acc: 0.9036 - val_loss: 0.2631 - val_acc: 0.9317\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3233 - acc: 0.9042\n",
      "Epoch 00141: val_loss did not improve from 0.25354\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3234 - acc: 0.9042 - val_loss: 0.2602 - val_acc: 0.9311\n",
      "Epoch 142/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3245 - acc: 0.9020\n",
      "Epoch 00142: val_loss did not improve from 0.25354\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3244 - acc: 0.9020 - val_loss: 0.2642 - val_acc: 0.9315\n",
      "Epoch 143/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3171 - acc: 0.9046\n",
      "Epoch 00143: val_loss did not improve from 0.25354\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3170 - acc: 0.9047 - val_loss: 0.2961 - val_acc: 0.9215\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3240 - acc: 0.9036\n",
      "Epoch 00144: val_loss did not improve from 0.25354\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3240 - acc: 0.9036 - val_loss: 0.2616 - val_acc: 0.9297\n",
      "Epoch 145/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3145 - acc: 0.9065\n",
      "Epoch 00145: val_loss did not improve from 0.25354\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3142 - acc: 0.9065 - val_loss: 0.2559 - val_acc: 0.9338\n",
      "Epoch 146/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3129 - acc: 0.9057\n",
      "Epoch 00146: val_loss improved from 0.25354 to 0.25247, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/146-0.2525.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3128 - acc: 0.9057 - val_loss: 0.2525 - val_acc: 0.9371\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3222 - acc: 0.9036\n",
      "Epoch 00147: val_loss did not improve from 0.25247\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.3223 - acc: 0.9035 - val_loss: 0.2643 - val_acc: 0.9306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3139 - acc: 0.9041\n",
      "Epoch 00148: val_loss improved from 0.25247 to 0.25189, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/148-0.2519.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3139 - acc: 0.9041 - val_loss: 0.2519 - val_acc: 0.9317\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.9081\n",
      "Epoch 00149: val_loss did not improve from 0.25189\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3055 - acc: 0.9081 - val_loss: 0.2536 - val_acc: 0.9345\n",
      "Epoch 150/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3111 - acc: 0.9071\n",
      "Epoch 00150: val_loss did not improve from 0.25189\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3110 - acc: 0.9072 - val_loss: 0.2635 - val_acc: 0.9308\n",
      "Epoch 151/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3108 - acc: 0.9062\n",
      "Epoch 00151: val_loss did not improve from 0.25189\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3109 - acc: 0.9061 - val_loss: 0.2553 - val_acc: 0.9352\n",
      "Epoch 152/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3073 - acc: 0.9083\n",
      "Epoch 00152: val_loss did not improve from 0.25189\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3074 - acc: 0.9082 - val_loss: 0.2625 - val_acc: 0.9311\n",
      "Epoch 153/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3095 - acc: 0.9083\n",
      "Epoch 00153: val_loss did not improve from 0.25189\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.3097 - acc: 0.9082 - val_loss: 0.2558 - val_acc: 0.9341\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3077 - acc: 0.9077\n",
      "Epoch 00154: val_loss improved from 0.25189 to 0.25036, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/154-0.2504.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3077 - acc: 0.9077 - val_loss: 0.2504 - val_acc: 0.9345\n",
      "Epoch 155/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3088 - acc: 0.9065\n",
      "Epoch 00155: val_loss did not improve from 0.25036\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.3086 - acc: 0.9067 - val_loss: 0.2584 - val_acc: 0.9331\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2983 - acc: 0.9099\n",
      "Epoch 00156: val_loss did not improve from 0.25036\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2982 - acc: 0.9098 - val_loss: 0.2581 - val_acc: 0.9327\n",
      "Epoch 157/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3009 - acc: 0.9100\n",
      "Epoch 00157: val_loss improved from 0.25036 to 0.25015, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/157-0.2502.hdf5\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.3009 - acc: 0.9100 - val_loss: 0.2502 - val_acc: 0.9338\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2971 - acc: 0.9118\n",
      "Epoch 00158: val_loss improved from 0.25015 to 0.24810, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/158-0.2481.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2972 - acc: 0.9118 - val_loss: 0.2481 - val_acc: 0.9364\n",
      "Epoch 159/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2985 - acc: 0.9093\n",
      "Epoch 00159: val_loss did not improve from 0.24810\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2985 - acc: 0.9093 - val_loss: 0.2556 - val_acc: 0.9357\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3037 - acc: 0.9089\n",
      "Epoch 00160: val_loss did not improve from 0.24810\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3037 - acc: 0.9089 - val_loss: 0.2485 - val_acc: 0.9357\n",
      "Epoch 161/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2977 - acc: 0.9090\n",
      "Epoch 00161: val_loss did not improve from 0.24810\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2978 - acc: 0.9090 - val_loss: 0.2612 - val_acc: 0.9308\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3001 - acc: 0.9093\n",
      "Epoch 00162: val_loss improved from 0.24810 to 0.24678, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/162-0.2468.hdf5\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.3002 - acc: 0.9093 - val_loss: 0.2468 - val_acc: 0.9366\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2928 - acc: 0.9117\n",
      "Epoch 00163: val_loss did not improve from 0.24678\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2928 - acc: 0.9117 - val_loss: 0.2478 - val_acc: 0.9336\n",
      "Epoch 164/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2914 - acc: 0.9125\n",
      "Epoch 00164: val_loss did not improve from 0.24678\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.2913 - acc: 0.9125 - val_loss: 0.2469 - val_acc: 0.9373\n",
      "Epoch 165/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2952 - acc: 0.9118\n",
      "Epoch 00165: val_loss did not improve from 0.24678\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2953 - acc: 0.9118 - val_loss: 0.2469 - val_acc: 0.9369\n",
      "Epoch 166/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2909 - acc: 0.9116\n",
      "Epoch 00166: val_loss did not improve from 0.24678\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2907 - acc: 0.9117 - val_loss: 0.2477 - val_acc: 0.9376\n",
      "Epoch 167/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2934 - acc: 0.9113\n",
      "Epoch 00167: val_loss did not improve from 0.24678\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2932 - acc: 0.9114 - val_loss: 0.2469 - val_acc: 0.9320\n",
      "Epoch 168/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2887 - acc: 0.9134\n",
      "Epoch 00168: val_loss did not improve from 0.24678\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2890 - acc: 0.9133 - val_loss: 0.2624 - val_acc: 0.9338\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2902 - acc: 0.9129\n",
      "Epoch 00169: val_loss did not improve from 0.24678\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.2901 - acc: 0.9129 - val_loss: 0.2476 - val_acc: 0.9362\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2893 - acc: 0.9126\n",
      "Epoch 00170: val_loss did not improve from 0.24678\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2892 - acc: 0.9125 - val_loss: 0.2494 - val_acc: 0.9359\n",
      "Epoch 171/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2879 - acc: 0.9135\n",
      "Epoch 00171: val_loss improved from 0.24678 to 0.24169, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/171-0.2417.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2881 - acc: 0.9134 - val_loss: 0.2417 - val_acc: 0.9376\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2818 - acc: 0.9150\n",
      "Epoch 00172: val_loss improved from 0.24169 to 0.24083, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/172-0.2408.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2817 - acc: 0.9150 - val_loss: 0.2408 - val_acc: 0.9392\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2854 - acc: 0.9148\n",
      "Epoch 00173: val_loss did not improve from 0.24083\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2854 - acc: 0.9148 - val_loss: 0.2458 - val_acc: 0.9362\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2802 - acc: 0.9150\n",
      "Epoch 00174: val_loss did not improve from 0.24083\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2802 - acc: 0.9150 - val_loss: 0.2487 - val_acc: 0.9338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2790 - acc: 0.9152\n",
      "Epoch 00175: val_loss did not improve from 0.24083\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2792 - acc: 0.9151 - val_loss: 0.2431 - val_acc: 0.9373\n",
      "Epoch 176/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2814 - acc: 0.9141\n",
      "Epoch 00176: val_loss did not improve from 0.24083\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.2815 - acc: 0.9140 - val_loss: 0.2416 - val_acc: 0.9364\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2795 - acc: 0.9148\n",
      "Epoch 00177: val_loss did not improve from 0.24083\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2795 - acc: 0.9148 - val_loss: 0.2443 - val_acc: 0.9378\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2742 - acc: 0.9176\n",
      "Epoch 00178: val_loss did not improve from 0.24083\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 0.2742 - acc: 0.9176 - val_loss: 0.2501 - val_acc: 0.9311\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2779 - acc: 0.9149\n",
      "Epoch 00179: val_loss did not improve from 0.24083\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.2779 - acc: 0.9149 - val_loss: 0.2464 - val_acc: 0.9348\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2816 - acc: 0.9150\n",
      "Epoch 00180: val_loss did not improve from 0.24083\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2816 - acc: 0.9150 - val_loss: 0.2566 - val_acc: 0.9338\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2717 - acc: 0.9162\n",
      "Epoch 00181: val_loss did not improve from 0.24083\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2717 - acc: 0.9162 - val_loss: 0.2507 - val_acc: 0.9313\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2737 - acc: 0.9165\n",
      "Epoch 00182: val_loss did not improve from 0.24083\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.2736 - acc: 0.9166 - val_loss: 0.2417 - val_acc: 0.9373\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2731 - acc: 0.9173\n",
      "Epoch 00183: val_loss improved from 0.24083 to 0.23666, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/183-0.2367.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2731 - acc: 0.9173 - val_loss: 0.2367 - val_acc: 0.9385\n",
      "Epoch 184/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2680 - acc: 0.9188\n",
      "Epoch 00184: val_loss did not improve from 0.23666\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2681 - acc: 0.9187 - val_loss: 0.2588 - val_acc: 0.9362\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2730 - acc: 0.9171\n",
      "Epoch 00185: val_loss did not improve from 0.23666\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2729 - acc: 0.9171 - val_loss: 0.2452 - val_acc: 0.9369\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2726 - acc: 0.9176\n",
      "Epoch 00186: val_loss did not improve from 0.23666\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.2726 - acc: 0.9176 - val_loss: 0.2395 - val_acc: 0.9362\n",
      "Epoch 187/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2708 - acc: 0.9185\n",
      "Epoch 00187: val_loss did not improve from 0.23666\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2709 - acc: 0.9185 - val_loss: 0.2488 - val_acc: 0.9373\n",
      "Epoch 188/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2675 - acc: 0.9207\n",
      "Epoch 00188: val_loss did not improve from 0.23666\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2677 - acc: 0.9206 - val_loss: 0.2397 - val_acc: 0.9362\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2665 - acc: 0.9188\n",
      "Epoch 00189: val_loss did not improve from 0.23666\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.2665 - acc: 0.9188 - val_loss: 0.2464 - val_acc: 0.9371\n",
      "Epoch 190/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2647 - acc: 0.9205\n",
      "Epoch 00190: val_loss did not improve from 0.23666\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2647 - acc: 0.9204 - val_loss: 0.2369 - val_acc: 0.9373\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2694 - acc: 0.9177\n",
      "Epoch 00191: val_loss improved from 0.23666 to 0.23647, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/191-0.2365.hdf5\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.2694 - acc: 0.9176 - val_loss: 0.2365 - val_acc: 0.9397\n",
      "Epoch 192/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2644 - acc: 0.9197\n",
      "Epoch 00192: val_loss did not improve from 0.23647\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2642 - acc: 0.9197 - val_loss: 0.2422 - val_acc: 0.9373\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2611 - acc: 0.9212\n",
      "Epoch 00193: val_loss did not improve from 0.23647\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.2611 - acc: 0.9212 - val_loss: 0.2435 - val_acc: 0.9390\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2584 - acc: 0.9212\n",
      "Epoch 00194: val_loss did not improve from 0.23647\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2584 - acc: 0.9212 - val_loss: 0.2385 - val_acc: 0.9413\n",
      "Epoch 195/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2636 - acc: 0.9205\n",
      "Epoch 00195: val_loss did not improve from 0.23647\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2634 - acc: 0.9206 - val_loss: 0.2439 - val_acc: 0.9385\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2593 - acc: 0.9224\n",
      "Epoch 00196: val_loss improved from 0.23647 to 0.23495, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/196-0.2349.hdf5\n",
      "36805/36805 [==============================] - 31s 829us/sample - loss: 0.2593 - acc: 0.9225 - val_loss: 0.2349 - val_acc: 0.9392\n",
      "Epoch 197/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2582 - acc: 0.9204\n",
      "Epoch 00197: val_loss did not improve from 0.23495\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2581 - acc: 0.9204 - val_loss: 0.2388 - val_acc: 0.9401\n",
      "Epoch 198/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2594 - acc: 0.9191\n",
      "Epoch 00198: val_loss did not improve from 0.23495\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2592 - acc: 0.9191 - val_loss: 0.2365 - val_acc: 0.9385\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2582 - acc: 0.9210\n",
      "Epoch 00199: val_loss did not improve from 0.23495\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.2582 - acc: 0.9210 - val_loss: 0.2382 - val_acc: 0.9369\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2582 - acc: 0.9225\n",
      "Epoch 00200: val_loss improved from 0.23495 to 0.23324, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/200-0.2332.hdf5\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2582 - acc: 0.9225 - val_loss: 0.2332 - val_acc: 0.9390\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2583 - acc: 0.9208\n",
      "Epoch 00201: val_loss improved from 0.23324 to 0.23080, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/201-0.2308.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2583 - acc: 0.9208 - val_loss: 0.2308 - val_acc: 0.9399\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2540 - acc: 0.9215\n",
      "Epoch 00202: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2540 - acc: 0.9215 - val_loss: 0.2443 - val_acc: 0.9387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.9214\n",
      "Epoch 00203: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2560 - acc: 0.9214 - val_loss: 0.2378 - val_acc: 0.9385\n",
      "Epoch 204/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2544 - acc: 0.9234\n",
      "Epoch 00204: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2543 - acc: 0.9234 - val_loss: 0.2346 - val_acc: 0.9392\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2525 - acc: 0.9220\n",
      "Epoch 00205: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2525 - acc: 0.9220 - val_loss: 0.2410 - val_acc: 0.9369\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2493 - acc: 0.9238\n",
      "Epoch 00206: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2498 - acc: 0.9238 - val_loss: 0.2454 - val_acc: 0.9345\n",
      "Epoch 207/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2511 - acc: 0.9232\n",
      "Epoch 00207: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2513 - acc: 0.9230 - val_loss: 0.2460 - val_acc: 0.9371\n",
      "Epoch 208/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2513 - acc: 0.9229\n",
      "Epoch 00208: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2512 - acc: 0.9229 - val_loss: 0.2349 - val_acc: 0.9387\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2508 - acc: 0.9224\n",
      "Epoch 00209: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2508 - acc: 0.9225 - val_loss: 0.2309 - val_acc: 0.9401\n",
      "Epoch 210/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2496 - acc: 0.9235\n",
      "Epoch 00210: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2495 - acc: 0.9235 - val_loss: 0.2486 - val_acc: 0.9336\n",
      "Epoch 211/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2469 - acc: 0.9248\n",
      "Epoch 00211: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2467 - acc: 0.9248 - val_loss: 0.2373 - val_acc: 0.9387\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2543 - acc: 0.9222\n",
      "Epoch 00212: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2543 - acc: 0.9222 - val_loss: 0.2402 - val_acc: 0.9394\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2433 - acc: 0.9248\n",
      "Epoch 00213: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2433 - acc: 0.9248 - val_loss: 0.2412 - val_acc: 0.9369\n",
      "Epoch 214/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2482 - acc: 0.9242\n",
      "Epoch 00214: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2481 - acc: 0.9242 - val_loss: 0.2363 - val_acc: 0.9406\n",
      "Epoch 215/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2414 - acc: 0.9262\n",
      "Epoch 00215: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.2416 - acc: 0.9262 - val_loss: 0.2409 - val_acc: 0.9397\n",
      "Epoch 216/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2535 - acc: 0.9237\n",
      "Epoch 00216: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2535 - acc: 0.9237 - val_loss: 0.2324 - val_acc: 0.9411\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2425 - acc: 0.9247\n",
      "Epoch 00217: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2425 - acc: 0.9247 - val_loss: 0.2377 - val_acc: 0.9380\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2445 - acc: 0.9247\n",
      "Epoch 00218: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2445 - acc: 0.9247 - val_loss: 0.2404 - val_acc: 0.9357\n",
      "Epoch 219/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2471 - acc: 0.9231\n",
      "Epoch 00219: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2472 - acc: 0.9230 - val_loss: 0.2415 - val_acc: 0.9366\n",
      "Epoch 220/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9287\n",
      "Epoch 00220: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2362 - acc: 0.9287 - val_loss: 0.2326 - val_acc: 0.9408\n",
      "Epoch 221/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2403 - acc: 0.9257\n",
      "Epoch 00221: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2400 - acc: 0.9259 - val_loss: 0.2355 - val_acc: 0.9397\n",
      "Epoch 222/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2376 - acc: 0.9263\n",
      "Epoch 00222: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.2379 - acc: 0.9262 - val_loss: 0.2393 - val_acc: 0.9392\n",
      "Epoch 223/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2419 - acc: 0.9254\n",
      "Epoch 00223: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2420 - acc: 0.9254 - val_loss: 0.2456 - val_acc: 0.9369\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2406 - acc: 0.9270\n",
      "Epoch 00224: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2407 - acc: 0.9270 - val_loss: 0.2459 - val_acc: 0.9401\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2403 - acc: 0.9258\n",
      "Epoch 00225: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2403 - acc: 0.9258 - val_loss: 0.2335 - val_acc: 0.9387\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2337 - acc: 0.9290- ETA: 1s - lo\n",
      "Epoch 00226: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2337 - acc: 0.9291 - val_loss: 0.2387 - val_acc: 0.9385\n",
      "Epoch 227/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9258\n",
      "Epoch 00227: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2363 - acc: 0.9258 - val_loss: 0.2351 - val_acc: 0.9371\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2314 - acc: 0.9281\n",
      "Epoch 00228: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.2314 - acc: 0.9281 - val_loss: 0.2449 - val_acc: 0.9387\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2332 - acc: 0.9285\n",
      "Epoch 00229: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.2332 - acc: 0.9284 - val_loss: 0.2363 - val_acc: 0.9399\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2302 - acc: 0.9290\n",
      "Epoch 00230: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2303 - acc: 0.9290 - val_loss: 0.2354 - val_acc: 0.9401\n",
      "Epoch 231/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2298 - acc: 0.9291\n",
      "Epoch 00231: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 31s 833us/sample - loss: 0.2301 - acc: 0.9290 - val_loss: 0.2365 - val_acc: 0.9425\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2285 - acc: 0.9295\n",
      "Epoch 00232: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 31s 830us/sample - loss: 0.2285 - acc: 0.9295 - val_loss: 0.2407 - val_acc: 0.9378\n",
      "Epoch 233/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2278 - acc: 0.9294\n",
      "Epoch 00233: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 31s 829us/sample - loss: 0.2277 - acc: 0.9293 - val_loss: 0.2458 - val_acc: 0.9392\n",
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2255 - acc: 0.9313\n",
      "Epoch 00234: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2257 - acc: 0.9312 - val_loss: 0.2392 - val_acc: 0.9376\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2300 - acc: 0.9294\n",
      "Epoch 00235: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2300 - acc: 0.9294 - val_loss: 0.2415 - val_acc: 0.9399\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2272 - acc: 0.9292\n",
      "Epoch 00236: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.2272 - acc: 0.9292 - val_loss: 0.2405 - val_acc: 0.9387\n",
      "Epoch 237/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2312 - acc: 0.9291\n",
      "Epoch 00237: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2312 - acc: 0.9291 - val_loss: 0.2376 - val_acc: 0.9401\n",
      "Epoch 238/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2303 - acc: 0.9304\n",
      "Epoch 00238: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.2305 - acc: 0.9303 - val_loss: 0.2444 - val_acc: 0.9366\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9300\n",
      "Epoch 00239: val_loss did not improve from 0.23080\n",
      "36805/36805 [==============================] - 31s 830us/sample - loss: 0.2249 - acc: 0.9300 - val_loss: 0.2312 - val_acc: 0.9399\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2314 - acc: 0.9282\n",
      "Epoch 00240: val_loss improved from 0.23080 to 0.22910, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/240-0.2291.hdf5\n",
      "36805/36805 [==============================] - 31s 830us/sample - loss: 0.2314 - acc: 0.9282 - val_loss: 0.2291 - val_acc: 0.9401\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9304\n",
      "Epoch 00241: val_loss did not improve from 0.22910\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2257 - acc: 0.9303 - val_loss: 0.2345 - val_acc: 0.9394\n",
      "Epoch 242/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2217 - acc: 0.9318\n",
      "Epoch 00242: val_loss did not improve from 0.22910\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2217 - acc: 0.9319 - val_loss: 0.2318 - val_acc: 0.9418\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2244 - acc: 0.9304\n",
      "Epoch 00243: val_loss did not improve from 0.22910\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.2244 - acc: 0.9304 - val_loss: 0.2357 - val_acc: 0.9371\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2248 - acc: 0.9307\n",
      "Epoch 00244: val_loss did not improve from 0.22910\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2248 - acc: 0.9307 - val_loss: 0.2403 - val_acc: 0.9364\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2168 - acc: 0.9329\n",
      "Epoch 00245: val_loss did not improve from 0.22910\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.2169 - acc: 0.9329 - val_loss: 0.2434 - val_acc: 0.9401\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2242 - acc: 0.9315\n",
      "Epoch 00246: val_loss did not improve from 0.22910\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2242 - acc: 0.9315 - val_loss: 0.2415 - val_acc: 0.9383\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2178 - acc: 0.9330\n",
      "Epoch 00247: val_loss did not improve from 0.22910\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 0.2178 - acc: 0.9330 - val_loss: 0.2388 - val_acc: 0.9369\n",
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2193 - acc: 0.9318\n",
      "Epoch 00248: val_loss did not improve from 0.22910\n",
      "36805/36805 [==============================] - 31s 835us/sample - loss: 0.2193 - acc: 0.9318 - val_loss: 0.2367 - val_acc: 0.9397\n",
      "Epoch 249/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2201 - acc: 0.9316\n",
      "Epoch 00249: val_loss did not improve from 0.22910\n",
      "36805/36805 [==============================] - 31s 829us/sample - loss: 0.2201 - acc: 0.9316 - val_loss: 0.2303 - val_acc: 0.9413\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9313\n",
      "Epoch 00250: val_loss did not improve from 0.22910\n",
      "36805/36805 [==============================] - 31s 835us/sample - loss: 0.2200 - acc: 0.9313 - val_loss: 0.2309 - val_acc: 0.9369\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2235 - acc: 0.9308\n",
      "Epoch 00251: val_loss improved from 0.22910 to 0.22823, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_5_conv_checkpoint/251-0.2282.hdf5\n",
      "36805/36805 [==============================] - 31s 831us/sample - loss: 0.2235 - acc: 0.9309 - val_loss: 0.2282 - val_acc: 0.9415\n",
      "Epoch 252/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9344\n",
      "Epoch 00252: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.2139 - acc: 0.9344 - val_loss: 0.2492 - val_acc: 0.9401\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2168 - acc: 0.9326\n",
      "Epoch 00253: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.2168 - acc: 0.9326 - val_loss: 0.2283 - val_acc: 0.9394\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2166 - acc: 0.9331\n",
      "Epoch 00254: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2166 - acc: 0.9331 - val_loss: 0.2337 - val_acc: 0.9408\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2138 - acc: 0.9331\n",
      "Epoch 00255: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 31s 833us/sample - loss: 0.2138 - acc: 0.9331 - val_loss: 0.2286 - val_acc: 0.9415\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9333\n",
      "Epoch 00256: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 31s 833us/sample - loss: 0.2108 - acc: 0.9333 - val_loss: 0.2323 - val_acc: 0.9406\n",
      "Epoch 257/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2175 - acc: 0.9318\n",
      "Epoch 00257: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 31s 831us/sample - loss: 0.2174 - acc: 0.9318 - val_loss: 0.2346 - val_acc: 0.9408\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2166 - acc: 0.9318\n",
      "Epoch 00258: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.2166 - acc: 0.9318 - val_loss: 0.2373 - val_acc: 0.9406\n",
      "Epoch 259/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9334\n",
      "Epoch 00259: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.2137 - acc: 0.9334 - val_loss: 0.2408 - val_acc: 0.9413\n",
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2104 - acc: 0.9348\n",
      "Epoch 00260: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2104 - acc: 0.9348 - val_loss: 0.2356 - val_acc: 0.9436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2111 - acc: 0.9347\n",
      "Epoch 00261: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.2110 - acc: 0.9347 - val_loss: 0.2372 - val_acc: 0.9390\n",
      "Epoch 262/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2155 - acc: 0.9327\n",
      "Epoch 00262: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.2156 - acc: 0.9326 - val_loss: 0.2553 - val_acc: 0.9373\n",
      "Epoch 263/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2092 - acc: 0.9353\n",
      "Epoch 00263: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.2093 - acc: 0.9353 - val_loss: 0.2342 - val_acc: 0.9413\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2118 - acc: 0.9343\n",
      "Epoch 00264: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2118 - acc: 0.9343 - val_loss: 0.2349 - val_acc: 0.9406\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9365\n",
      "Epoch 00265: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 0.2036 - acc: 0.9366 - val_loss: 0.2335 - val_acc: 0.9404\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9338\n",
      "Epoch 00266: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 0.2106 - acc: 0.9338 - val_loss: 0.2307 - val_acc: 0.9415\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9340\n",
      "Epoch 00267: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2090 - acc: 0.9341 - val_loss: 0.2352 - val_acc: 0.9413\n",
      "Epoch 268/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2117 - acc: 0.9332\n",
      "Epoch 00268: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.2116 - acc: 0.9332 - val_loss: 0.2286 - val_acc: 0.9418\n",
      "Epoch 269/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2079 - acc: 0.9338\n",
      "Epoch 00269: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 0.2079 - acc: 0.9338 - val_loss: 0.2439 - val_acc: 0.9387\n",
      "Epoch 270/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9359\n",
      "Epoch 00270: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.2056 - acc: 0.9359 - val_loss: 0.2307 - val_acc: 0.9401\n",
      "Epoch 271/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9346\n",
      "Epoch 00271: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2078 - acc: 0.9347 - val_loss: 0.2341 - val_acc: 0.9411\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2033 - acc: 0.9370\n",
      "Epoch 00272: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.2034 - acc: 0.9370 - val_loss: 0.2424 - val_acc: 0.9383\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2007 - acc: 0.9371\n",
      "Epoch 00273: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2007 - acc: 0.9371 - val_loss: 0.2362 - val_acc: 0.9385\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2035 - acc: 0.9369\n",
      "Epoch 00274: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 0.2034 - acc: 0.9369 - val_loss: 0.2352 - val_acc: 0.9406\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9365\n",
      "Epoch 00275: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2032 - acc: 0.9365 - val_loss: 0.2320 - val_acc: 0.9413\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2050 - acc: 0.9349\n",
      "Epoch 00276: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 0.2050 - acc: 0.9349 - val_loss: 0.2424 - val_acc: 0.9411\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9373\n",
      "Epoch 00277: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2021 - acc: 0.9373 - val_loss: 0.2338 - val_acc: 0.9406\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9379\n",
      "Epoch 00278: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.1986 - acc: 0.9379 - val_loss: 0.2456 - val_acc: 0.9366\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2027 - acc: 0.9363\n",
      "Epoch 00279: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.2027 - acc: 0.9363 - val_loss: 0.2380 - val_acc: 0.9401\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2042 - acc: 0.9360\n",
      "Epoch 00280: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 0.2042 - acc: 0.9359 - val_loss: 0.2533 - val_acc: 0.9376\n",
      "Epoch 281/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9380\n",
      "Epoch 00281: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.2006 - acc: 0.9380 - val_loss: 0.2411 - val_acc: 0.9415\n",
      "Epoch 282/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1959 - acc: 0.9388\n",
      "Epoch 00282: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.1959 - acc: 0.9388 - val_loss: 0.2422 - val_acc: 0.9397\n",
      "Epoch 283/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1959 - acc: 0.9383\n",
      "Epoch 00283: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 0.1958 - acc: 0.9383 - val_loss: 0.2372 - val_acc: 0.9371\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9370\n",
      "Epoch 00284: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 829us/sample - loss: 0.1981 - acc: 0.9370 - val_loss: 0.2358 - val_acc: 0.9411\n",
      "Epoch 285/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1979 - acc: 0.9382\n",
      "Epoch 00285: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.1979 - acc: 0.9382 - val_loss: 0.2455 - val_acc: 0.9373\n",
      "Epoch 286/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1974 - acc: 0.9386\n",
      "Epoch 00286: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.1973 - acc: 0.9387 - val_loss: 0.2331 - val_acc: 0.9425\n",
      "Epoch 287/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9377\n",
      "Epoch 00287: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.1967 - acc: 0.9378 - val_loss: 0.2368 - val_acc: 0.9387\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9380\n",
      "Epoch 00288: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.1964 - acc: 0.9380 - val_loss: 0.2496 - val_acc: 0.9418\n",
      "Epoch 289/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9370\n",
      "Epoch 00289: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.1935 - acc: 0.9370 - val_loss: 0.2381 - val_acc: 0.9401\n",
      "Epoch 290/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1936 - acc: 0.9379\n",
      "Epoch 00290: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 0.1936 - acc: 0.9379 - val_loss: 0.2401 - val_acc: 0.9390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1930 - acc: 0.9400\n",
      "Epoch 00291: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.1929 - acc: 0.9400 - val_loss: 0.2385 - val_acc: 0.9418\n",
      "Epoch 292/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1925 - acc: 0.9394\n",
      "Epoch 00292: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.1924 - acc: 0.9394 - val_loss: 0.2388 - val_acc: 0.9411\n",
      "Epoch 293/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1952 - acc: 0.9392\n",
      "Epoch 00293: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.1952 - acc: 0.9392 - val_loss: 0.2300 - val_acc: 0.9397\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1964 - acc: 0.9374\n",
      "Epoch 00294: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 0.1964 - acc: 0.9374 - val_loss: 0.2319 - val_acc: 0.9359\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1933 - acc: 0.9394\n",
      "Epoch 00295: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.1933 - acc: 0.9394 - val_loss: 0.2340 - val_acc: 0.9390\n",
      "Epoch 296/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9380\n",
      "Epoch 00296: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.1920 - acc: 0.9380 - val_loss: 0.2368 - val_acc: 0.9415\n",
      "Epoch 297/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9401\n",
      "Epoch 00297: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 826us/sample - loss: 0.1886 - acc: 0.9400 - val_loss: 0.2350 - val_acc: 0.9408\n",
      "Epoch 298/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9391\n",
      "Epoch 00298: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.1932 - acc: 0.9391 - val_loss: 0.2351 - val_acc: 0.9406\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1888 - acc: 0.9403\n",
      "Epoch 00299: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 31s 829us/sample - loss: 0.1887 - acc: 0.9403 - val_loss: 0.2330 - val_acc: 0.9415\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1921 - acc: 0.9395\n",
      "Epoch 00300: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 827us/sample - loss: 0.1920 - acc: 0.9395 - val_loss: 0.2565 - val_acc: 0.9390\n",
      "Epoch 301/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1914 - acc: 0.9403\n",
      "Epoch 00301: val_loss did not improve from 0.22823\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.1912 - acc: 0.9404 - val_loss: 0.2385 - val_acc: 0.9427\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 400us/sample - loss: 0.2658 - acc: 0.9234\n",
      "Loss: 0.26581726950648416 Accuracy: 0.92336446\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4745 - acc: 0.1821\n",
      "Epoch 00001: val_loss improved from inf to 1.94580, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/001-1.9458.hdf5\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 2.4745 - acc: 0.1821 - val_loss: 1.9458 - val_acc: 0.3839\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9186 - acc: 0.3598\n",
      "Epoch 00002: val_loss improved from 1.94580 to 1.61298, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/002-1.6130.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 1.9185 - acc: 0.3598 - val_loss: 1.6130 - val_acc: 0.5080\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6763 - acc: 0.4497\n",
      "Epoch 00003: val_loss improved from 1.61298 to 1.38553, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/003-1.3855.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 1.6763 - acc: 0.4497 - val_loss: 1.3855 - val_acc: 0.5905\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4817 - acc: 0.5169\n",
      "Epoch 00004: val_loss improved from 1.38553 to 1.21117, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/004-1.2112.hdf5\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 1.4819 - acc: 0.5169 - val_loss: 1.2112 - val_acc: 0.6508\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3342 - acc: 0.5741\n",
      "Epoch 00005: val_loss improved from 1.21117 to 1.04205, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/005-1.0421.hdf5\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 1.3341 - acc: 0.5741 - val_loss: 1.0421 - val_acc: 0.7009\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1988 - acc: 0.6204\n",
      "Epoch 00006: val_loss improved from 1.04205 to 0.95181, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/006-0.9518.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 1.1987 - acc: 0.6204 - val_loss: 0.9518 - val_acc: 0.7133\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0951 - acc: 0.6596\n",
      "Epoch 00007: val_loss improved from 0.95181 to 0.84670, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/007-0.8467.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 1.0950 - acc: 0.6596 - val_loss: 0.8467 - val_acc: 0.7463\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9973 - acc: 0.6936\n",
      "Epoch 00008: val_loss improved from 0.84670 to 0.74982, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/008-0.7498.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.9973 - acc: 0.6936 - val_loss: 0.7498 - val_acc: 0.7945\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9240 - acc: 0.7177\n",
      "Epoch 00009: val_loss improved from 0.74982 to 0.69256, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/009-0.6926.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.9239 - acc: 0.7177 - val_loss: 0.6926 - val_acc: 0.8015\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8649 - acc: 0.7410\n",
      "Epoch 00010: val_loss improved from 0.69256 to 0.64216, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/010-0.6422.hdf5\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.8649 - acc: 0.7410 - val_loss: 0.6422 - val_acc: 0.8178\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8047 - acc: 0.7577\n",
      "Epoch 00011: val_loss improved from 0.64216 to 0.57879, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/011-0.5788.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.8046 - acc: 0.7578 - val_loss: 0.5788 - val_acc: 0.8395\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7556 - acc: 0.7710\n",
      "Epoch 00012: val_loss improved from 0.57879 to 0.53038, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/012-0.5304.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.7556 - acc: 0.7710 - val_loss: 0.5304 - val_acc: 0.8595\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7163 - acc: 0.7854\n",
      "Epoch 00013: val_loss did not improve from 0.53038\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.7167 - acc: 0.7853 - val_loss: 0.5486 - val_acc: 0.8404\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6881 - acc: 0.7936\n",
      "Epoch 00014: val_loss improved from 0.53038 to 0.51385, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/014-0.5139.hdf5\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.6881 - acc: 0.7936 - val_loss: 0.5139 - val_acc: 0.8584\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6614 - acc: 0.8031\n",
      "Epoch 00015: val_loss improved from 0.51385 to 0.45212, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/015-0.4521.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.6614 - acc: 0.8031 - val_loss: 0.4521 - val_acc: 0.8812\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6267 - acc: 0.8142\n",
      "Epoch 00016: val_loss improved from 0.45212 to 0.42278, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/016-0.4228.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.6267 - acc: 0.8142 - val_loss: 0.4228 - val_acc: 0.8889\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5980 - acc: 0.8236\n",
      "Epoch 00017: val_loss did not improve from 0.42278\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.5980 - acc: 0.8236 - val_loss: 0.4261 - val_acc: 0.8812\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5842 - acc: 0.8252\n",
      "Epoch 00018: val_loss improved from 0.42278 to 0.39235, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/018-0.3923.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.5842 - acc: 0.8252 - val_loss: 0.3923 - val_acc: 0.8991\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5577 - acc: 0.8348\n",
      "Epoch 00019: val_loss improved from 0.39235 to 0.37554, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/019-0.3755.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.5576 - acc: 0.8348 - val_loss: 0.3755 - val_acc: 0.9024\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5415 - acc: 0.8379\n",
      "Epoch 00020: val_loss improved from 0.37554 to 0.37302, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/020-0.3730.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.5415 - acc: 0.8379 - val_loss: 0.3730 - val_acc: 0.9005\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5282 - acc: 0.8456\n",
      "Epoch 00021: val_loss improved from 0.37302 to 0.36110, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/021-0.3611.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.5282 - acc: 0.8456 - val_loss: 0.3611 - val_acc: 0.9073\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5097 - acc: 0.8491\n",
      "Epoch 00022: val_loss improved from 0.36110 to 0.35534, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/022-0.3553.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.5097 - acc: 0.8490 - val_loss: 0.3553 - val_acc: 0.9052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4913 - acc: 0.8535\n",
      "Epoch 00023: val_loss improved from 0.35534 to 0.34179, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/023-0.3418.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.4913 - acc: 0.8535 - val_loss: 0.3418 - val_acc: 0.9033\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4796 - acc: 0.8562\n",
      "Epoch 00024: val_loss improved from 0.34179 to 0.32387, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/024-0.3239.hdf5\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.4796 - acc: 0.8562 - val_loss: 0.3239 - val_acc: 0.9143\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4688 - acc: 0.8607\n",
      "Epoch 00025: val_loss did not improve from 0.32387\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.4688 - acc: 0.8607 - val_loss: 0.3415 - val_acc: 0.9061\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4573 - acc: 0.8651\n",
      "Epoch 00026: val_loss improved from 0.32387 to 0.31164, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/026-0.3116.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.4573 - acc: 0.8650 - val_loss: 0.3116 - val_acc: 0.9168\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4451 - acc: 0.8663\n",
      "Epoch 00027: val_loss improved from 0.31164 to 0.29241, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/027-0.2924.hdf5\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.4450 - acc: 0.8663 - val_loss: 0.2924 - val_acc: 0.9229\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.8702\n",
      "Epoch 00028: val_loss improved from 0.29241 to 0.28522, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/028-0.2852.hdf5\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.4319 - acc: 0.8702 - val_loss: 0.2852 - val_acc: 0.9252\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4219 - acc: 0.8749\n",
      "Epoch 00029: val_loss improved from 0.28522 to 0.27802, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/029-0.2780.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.4218 - acc: 0.8750 - val_loss: 0.2780 - val_acc: 0.9245\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4160 - acc: 0.8760\n",
      "Epoch 00030: val_loss improved from 0.27802 to 0.27695, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/030-0.2770.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.4159 - acc: 0.8760 - val_loss: 0.2770 - val_acc: 0.9252\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4083 - acc: 0.8786\n",
      "Epoch 00031: val_loss did not improve from 0.27695\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.4083 - acc: 0.8786 - val_loss: 0.2858 - val_acc: 0.9206\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3962 - acc: 0.8821\n",
      "Epoch 00032: val_loss improved from 0.27695 to 0.25830, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/032-0.2583.hdf5\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.3962 - acc: 0.8822 - val_loss: 0.2583 - val_acc: 0.9311\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3895 - acc: 0.8832\n",
      "Epoch 00033: val_loss did not improve from 0.25830\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.3895 - acc: 0.8831 - val_loss: 0.2709 - val_acc: 0.9222\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3797 - acc: 0.8851\n",
      "Epoch 00034: val_loss improved from 0.25830 to 0.24926, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/034-0.2493.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3796 - acc: 0.8851 - val_loss: 0.2493 - val_acc: 0.9311\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3713 - acc: 0.8870\n",
      "Epoch 00035: val_loss did not improve from 0.24926\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.3713 - acc: 0.8870 - val_loss: 0.2582 - val_acc: 0.9313\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3635 - acc: 0.8894\n",
      "Epoch 00036: val_loss improved from 0.24926 to 0.24121, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/036-0.2412.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3635 - acc: 0.8894 - val_loss: 0.2412 - val_acc: 0.9336\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3597 - acc: 0.8932\n",
      "Epoch 00037: val_loss improved from 0.24121 to 0.23591, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/037-0.2359.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3597 - acc: 0.8932 - val_loss: 0.2359 - val_acc: 0.9366\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3472 - acc: 0.8945\n",
      "Epoch 00038: val_loss improved from 0.23591 to 0.23388, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/038-0.2339.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3472 - acc: 0.8945 - val_loss: 0.2339 - val_acc: 0.9364\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3496 - acc: 0.8951\n",
      "Epoch 00039: val_loss did not improve from 0.23388\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.3497 - acc: 0.8950 - val_loss: 0.2375 - val_acc: 0.9345\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3428 - acc: 0.8961\n",
      "Epoch 00040: val_loss did not improve from 0.23388\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.3429 - acc: 0.8961 - val_loss: 0.2442 - val_acc: 0.9308\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3365 - acc: 0.8977\n",
      "Epoch 00041: val_loss improved from 0.23388 to 0.23071, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/041-0.2307.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3365 - acc: 0.8977 - val_loss: 0.2307 - val_acc: 0.9387\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3272 - acc: 0.9014\n",
      "Epoch 00042: val_loss improved from 0.23071 to 0.22483, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/042-0.2248.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.3272 - acc: 0.9014 - val_loss: 0.2248 - val_acc: 0.9369\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3257 - acc: 0.9012\n",
      "Epoch 00043: val_loss improved from 0.22483 to 0.22312, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/043-0.2231.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3257 - acc: 0.9012 - val_loss: 0.2231 - val_acc: 0.9364\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3172 - acc: 0.9042\n",
      "Epoch 00044: val_loss did not improve from 0.22312\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.3171 - acc: 0.9042 - val_loss: 0.2335 - val_acc: 0.9315\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3164 - acc: 0.9033\n",
      "Epoch 00045: val_loss improved from 0.22312 to 0.21984, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/045-0.2198.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.3163 - acc: 0.9033 - val_loss: 0.2198 - val_acc: 0.9404\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3058 - acc: 0.9076\n",
      "Epoch 00046: val_loss improved from 0.21984 to 0.21408, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/046-0.2141.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.3058 - acc: 0.9076 - val_loss: 0.2141 - val_acc: 0.9394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3078 - acc: 0.9073\n",
      "Epoch 00047: val_loss improved from 0.21408 to 0.20102, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/047-0.2010.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3078 - acc: 0.9073 - val_loss: 0.2010 - val_acc: 0.9441\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2948 - acc: 0.9089\n",
      "Epoch 00048: val_loss did not improve from 0.20102\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.2949 - acc: 0.9089 - val_loss: 0.2276 - val_acc: 0.9355\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2954 - acc: 0.9109\n",
      "Epoch 00049: val_loss did not improve from 0.20102\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.2953 - acc: 0.9109 - val_loss: 0.2025 - val_acc: 0.9450\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2886 - acc: 0.9136\n",
      "Epoch 00050: val_loss did not improve from 0.20102\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.2886 - acc: 0.9137 - val_loss: 0.2117 - val_acc: 0.9401\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2834 - acc: 0.9142\n",
      "Epoch 00051: val_loss improved from 0.20102 to 0.19644, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/051-0.1964.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.2833 - acc: 0.9142 - val_loss: 0.1964 - val_acc: 0.9450\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2795 - acc: 0.9136\n",
      "Epoch 00052: val_loss improved from 0.19644 to 0.19591, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/052-0.1959.hdf5\n",
      "36805/36805 [==============================] - 31s 851us/sample - loss: 0.2795 - acc: 0.9136 - val_loss: 0.1959 - val_acc: 0.9448\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2776 - acc: 0.9157\n",
      "Epoch 00053: val_loss did not improve from 0.19591\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.2776 - acc: 0.9157 - val_loss: 0.2016 - val_acc: 0.9432\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2816 - acc: 0.9152\n",
      "Epoch 00054: val_loss did not improve from 0.19591\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.2816 - acc: 0.9152 - val_loss: 0.2267 - val_acc: 0.9366\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2713 - acc: 0.9183\n",
      "Epoch 00055: val_loss improved from 0.19591 to 0.18735, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/055-0.1874.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2712 - acc: 0.9183 - val_loss: 0.1874 - val_acc: 0.9467\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2679 - acc: 0.9193\n",
      "Epoch 00056: val_loss did not improve from 0.18735\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.2680 - acc: 0.9193 - val_loss: 0.1940 - val_acc: 0.9460\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2621 - acc: 0.9199\n",
      "Epoch 00057: val_loss improved from 0.18735 to 0.17520, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/057-0.1752.hdf5\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.2621 - acc: 0.9199 - val_loss: 0.1752 - val_acc: 0.9529\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2564 - acc: 0.9221\n",
      "Epoch 00058: val_loss did not improve from 0.17520\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2565 - acc: 0.9220 - val_loss: 0.1963 - val_acc: 0.9425\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2574 - acc: 0.9231\n",
      "Epoch 00059: val_loss did not improve from 0.17520\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2574 - acc: 0.9231 - val_loss: 0.1855 - val_acc: 0.9504\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2510 - acc: 0.9219\n",
      "Epoch 00060: val_loss did not improve from 0.17520\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.2510 - acc: 0.9219 - val_loss: 0.1790 - val_acc: 0.9495\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2504 - acc: 0.9241\n",
      "Epoch 00061: val_loss did not improve from 0.17520\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2504 - acc: 0.9241 - val_loss: 0.1789 - val_acc: 0.9488\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2490 - acc: 0.9236\n",
      "Epoch 00062: val_loss improved from 0.17520 to 0.17498, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/062-0.1750.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2490 - acc: 0.9236 - val_loss: 0.1750 - val_acc: 0.9499\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2447 - acc: 0.9249\n",
      "Epoch 00063: val_loss did not improve from 0.17498\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.2447 - acc: 0.9249 - val_loss: 0.1781 - val_acc: 0.9506\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2422 - acc: 0.9254\n",
      "Epoch 00064: val_loss improved from 0.17498 to 0.17080, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/064-0.1708.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2422 - acc: 0.9254 - val_loss: 0.1708 - val_acc: 0.9532\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2331 - acc: 0.9291\n",
      "Epoch 00065: val_loss did not improve from 0.17080\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.2331 - acc: 0.9291 - val_loss: 0.2087 - val_acc: 0.9383\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2377 - acc: 0.9266\n",
      "Epoch 00066: val_loss improved from 0.17080 to 0.17055, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/066-0.1705.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.2377 - acc: 0.9266 - val_loss: 0.1705 - val_acc: 0.9527\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2304 - acc: 0.9282\n",
      "Epoch 00067: val_loss did not improve from 0.17055\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.2304 - acc: 0.9282 - val_loss: 0.1707 - val_acc: 0.9483\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2271 - acc: 0.9292\n",
      "Epoch 00068: val_loss did not improve from 0.17055\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.2271 - acc: 0.9292 - val_loss: 0.1800 - val_acc: 0.9520\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2276 - acc: 0.9308\n",
      "Epoch 00069: val_loss did not improve from 0.17055\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2276 - acc: 0.9308 - val_loss: 0.1746 - val_acc: 0.9499\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2254 - acc: 0.9309\n",
      "Epoch 00070: val_loss improved from 0.17055 to 0.16792, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/070-0.1679.hdf5\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.2253 - acc: 0.9309 - val_loss: 0.1679 - val_acc: 0.9527\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2159 - acc: 0.9334\n",
      "Epoch 00071: val_loss did not improve from 0.16792\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.2159 - acc: 0.9334 - val_loss: 0.1857 - val_acc: 0.9495\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2192 - acc: 0.9314\n",
      "Epoch 00072: val_loss improved from 0.16792 to 0.16349, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/072-0.1635.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2192 - acc: 0.9314 - val_loss: 0.1635 - val_acc: 0.9546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2159 - acc: 0.9316\n",
      "Epoch 00073: val_loss did not improve from 0.16349\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2159 - acc: 0.9316 - val_loss: 0.1786 - val_acc: 0.9446\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2179 - acc: 0.9316\n",
      "Epoch 00074: val_loss did not improve from 0.16349\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.2179 - acc: 0.9316 - val_loss: 0.1704 - val_acc: 0.9536\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9333\n",
      "Epoch 00075: val_loss did not improve from 0.16349\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.2140 - acc: 0.9333 - val_loss: 0.1664 - val_acc: 0.9539\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2113 - acc: 0.9351\n",
      "Epoch 00076: val_loss improved from 0.16349 to 0.15766, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/076-0.1577.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.2112 - acc: 0.9351 - val_loss: 0.1577 - val_acc: 0.9560\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2076 - acc: 0.9351\n",
      "Epoch 00077: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.2076 - acc: 0.9351 - val_loss: 0.1731 - val_acc: 0.9509\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9377\n",
      "Epoch 00078: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.2044 - acc: 0.9378 - val_loss: 0.1652 - val_acc: 0.9532\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2029 - acc: 0.9364\n",
      "Epoch 00079: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.2029 - acc: 0.9364 - val_loss: 0.1580 - val_acc: 0.9576\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9376\n",
      "Epoch 00080: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.1980 - acc: 0.9376 - val_loss: 0.1633 - val_acc: 0.9546\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1983 - acc: 0.9379\n",
      "Epoch 00081: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1984 - acc: 0.9379 - val_loss: 0.1632 - val_acc: 0.9546\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1979 - acc: 0.9388\n",
      "Epoch 00082: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1980 - acc: 0.9388 - val_loss: 0.1694 - val_acc: 0.9536\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1964 - acc: 0.9381\n",
      "Epoch 00083: val_loss improved from 0.15766 to 0.15620, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/083-0.1562.hdf5\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.1964 - acc: 0.9381 - val_loss: 0.1562 - val_acc: 0.9576\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9404\n",
      "Epoch 00084: val_loss did not improve from 0.15620\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1926 - acc: 0.9404 - val_loss: 0.1649 - val_acc: 0.9562\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1901 - acc: 0.9411\n",
      "Epoch 00085: val_loss improved from 0.15620 to 0.15316, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/085-0.1532.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1901 - acc: 0.9411 - val_loss: 0.1532 - val_acc: 0.9588\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1864 - acc: 0.9416\n",
      "Epoch 00086: val_loss did not improve from 0.15316\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1864 - acc: 0.9416 - val_loss: 0.1613 - val_acc: 0.9583\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1891 - acc: 0.9414\n",
      "Epoch 00087: val_loss did not improve from 0.15316\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1891 - acc: 0.9414 - val_loss: 0.1613 - val_acc: 0.9578\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9427\n",
      "Epoch 00088: val_loss did not improve from 0.15316\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1828 - acc: 0.9427 - val_loss: 0.1551 - val_acc: 0.9585\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9413\n",
      "Epoch 00089: val_loss did not improve from 0.15316\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1828 - acc: 0.9413 - val_loss: 0.1699 - val_acc: 0.9541\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1824 - acc: 0.9424\n",
      "Epoch 00090: val_loss improved from 0.15316 to 0.15214, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/090-0.1521.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.1825 - acc: 0.9423 - val_loss: 0.1521 - val_acc: 0.9574\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9413\n",
      "Epoch 00091: val_loss did not improve from 0.15214\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1846 - acc: 0.9413 - val_loss: 0.1565 - val_acc: 0.9562\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1761 - acc: 0.9444\n",
      "Epoch 00092: val_loss improved from 0.15214 to 0.15035, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/092-0.1504.hdf5\n",
      "36805/36805 [==============================] - 31s 853us/sample - loss: 0.1761 - acc: 0.9444 - val_loss: 0.1504 - val_acc: 0.9606\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1796 - acc: 0.9435\n",
      "Epoch 00093: val_loss improved from 0.15035 to 0.14961, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/093-0.1496.hdf5\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.1796 - acc: 0.9435 - val_loss: 0.1496 - val_acc: 0.9581\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9437\n",
      "Epoch 00094: val_loss did not improve from 0.14961\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1811 - acc: 0.9437 - val_loss: 0.1511 - val_acc: 0.9583\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9453\n",
      "Epoch 00095: val_loss did not improve from 0.14961\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1762 - acc: 0.9453 - val_loss: 0.1592 - val_acc: 0.9571\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9455\n",
      "Epoch 00096: val_loss did not improve from 0.14961\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1715 - acc: 0.9455 - val_loss: 0.1716 - val_acc: 0.9532\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9457\n",
      "Epoch 00097: val_loss did not improve from 0.14961\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1679 - acc: 0.9457 - val_loss: 0.1544 - val_acc: 0.9567\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1709 - acc: 0.9450\n",
      "Epoch 00098: val_loss did not improve from 0.14961\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1709 - acc: 0.9450 - val_loss: 0.1646 - val_acc: 0.9543\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9477\n",
      "Epoch 00099: val_loss did not improve from 0.14961\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1656 - acc: 0.9477 - val_loss: 0.1565 - val_acc: 0.9576\n",
      "Epoch 100/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1671 - acc: 0.9471\n",
      "Epoch 00100: val_loss did not improve from 0.14961\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1671 - acc: 0.9471 - val_loss: 0.1621 - val_acc: 0.9550\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9474\n",
      "Epoch 00101: val_loss did not improve from 0.14961\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1654 - acc: 0.9474 - val_loss: 0.1598 - val_acc: 0.9578\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9476\n",
      "Epoch 00102: val_loss did not improve from 0.14961\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1643 - acc: 0.9476 - val_loss: 0.1635 - val_acc: 0.9567\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9490\n",
      "Epoch 00103: val_loss did not improve from 0.14961\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1602 - acc: 0.9490 - val_loss: 0.1570 - val_acc: 0.9576\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1652 - acc: 0.9481\n",
      "Epoch 00104: val_loss improved from 0.14961 to 0.14787, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/104-0.1479.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1652 - acc: 0.9481 - val_loss: 0.1479 - val_acc: 0.9606\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9490\n",
      "Epoch 00105: val_loss improved from 0.14787 to 0.14684, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/105-0.1468.hdf5\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1596 - acc: 0.9490 - val_loss: 0.1468 - val_acc: 0.9597\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9490\n",
      "Epoch 00106: val_loss did not improve from 0.14684\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1604 - acc: 0.9490 - val_loss: 0.1521 - val_acc: 0.9581\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1584 - acc: 0.9493\n",
      "Epoch 00107: val_loss did not improve from 0.14684\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1584 - acc: 0.9494 - val_loss: 0.1494 - val_acc: 0.9562\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9501\n",
      "Epoch 00108: val_loss did not improve from 0.14684\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1574 - acc: 0.9501 - val_loss: 0.1589 - val_acc: 0.9590\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1573 - acc: 0.9495\n",
      "Epoch 00109: val_loss did not improve from 0.14684\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1573 - acc: 0.9495 - val_loss: 0.1486 - val_acc: 0.9599\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9520\n",
      "Epoch 00110: val_loss did not improve from 0.14684\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1495 - acc: 0.9520 - val_loss: 0.1474 - val_acc: 0.9585\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9513\n",
      "Epoch 00111: val_loss did not improve from 0.14684\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1512 - acc: 0.9513 - val_loss: 0.1487 - val_acc: 0.9597\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1528 - acc: 0.9520\n",
      "Epoch 00112: val_loss did not improve from 0.14684\n",
      "36805/36805 [==============================] - 31s 840us/sample - loss: 0.1528 - acc: 0.9520 - val_loss: 0.1549 - val_acc: 0.9592\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9522\n",
      "Epoch 00113: val_loss did not improve from 0.14684\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1505 - acc: 0.9522 - val_loss: 0.1472 - val_acc: 0.9592\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1514 - acc: 0.9505\n",
      "Epoch 00114: val_loss did not improve from 0.14684\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1514 - acc: 0.9505 - val_loss: 0.1564 - val_acc: 0.9583\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1477 - acc: 0.9532\n",
      "Epoch 00115: val_loss did not improve from 0.14684\n",
      "36805/36805 [==============================] - 31s 838us/sample - loss: 0.1477 - acc: 0.9532 - val_loss: 0.1608 - val_acc: 0.9569\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9528\n",
      "Epoch 00116: val_loss improved from 0.14684 to 0.14257, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/116-0.1426.hdf5\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1435 - acc: 0.9528 - val_loss: 0.1426 - val_acc: 0.9592\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9535\n",
      "Epoch 00117: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1465 - acc: 0.9535 - val_loss: 0.1657 - val_acc: 0.9569\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9519\n",
      "Epoch 00118: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1472 - acc: 0.9519 - val_loss: 0.1582 - val_acc: 0.9578\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1461 - acc: 0.9539\n",
      "Epoch 00119: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1461 - acc: 0.9539 - val_loss: 0.1574 - val_acc: 0.9550\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9541\n",
      "Epoch 00120: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1395 - acc: 0.9541 - val_loss: 0.1626 - val_acc: 0.9555\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9550\n",
      "Epoch 00121: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1407 - acc: 0.9550 - val_loss: 0.1514 - val_acc: 0.9618\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9557\n",
      "Epoch 00122: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1373 - acc: 0.9556 - val_loss: 0.1600 - val_acc: 0.9581\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9542\n",
      "Epoch 00123: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1386 - acc: 0.9542 - val_loss: 0.1445 - val_acc: 0.9588\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9563\n",
      "Epoch 00124: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1383 - acc: 0.9563 - val_loss: 0.1487 - val_acc: 0.9592\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9561\n",
      "Epoch 00125: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 840us/sample - loss: 0.1354 - acc: 0.9561 - val_loss: 0.1575 - val_acc: 0.9592\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1327 - acc: 0.9571\n",
      "Epoch 00126: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1327 - acc: 0.9571 - val_loss: 0.1505 - val_acc: 0.9588\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9565\n",
      "Epoch 00127: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1365 - acc: 0.9565 - val_loss: 0.1646 - val_acc: 0.9560\n",
      "Epoch 128/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9572\n",
      "Epoch 00128: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1342 - acc: 0.9572 - val_loss: 0.1502 - val_acc: 0.9606\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9584\n",
      "Epoch 00129: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1295 - acc: 0.9584 - val_loss: 0.1499 - val_acc: 0.9597\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9568\n",
      "Epoch 00130: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 840us/sample - loss: 0.1293 - acc: 0.9568 - val_loss: 0.1476 - val_acc: 0.9613\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9582\n",
      "Epoch 00131: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1297 - acc: 0.9582 - val_loss: 0.1441 - val_acc: 0.9606\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9578\n",
      "Epoch 00132: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1281 - acc: 0.9578 - val_loss: 0.1518 - val_acc: 0.9606\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9596\n",
      "Epoch 00133: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1230 - acc: 0.9596 - val_loss: 0.1602 - val_acc: 0.9592\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9582\n",
      "Epoch 00134: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1277 - acc: 0.9582 - val_loss: 0.1589 - val_acc: 0.9606\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9589\n",
      "Epoch 00135: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1267 - acc: 0.9589 - val_loss: 0.1562 - val_acc: 0.9595\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9582\n",
      "Epoch 00136: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1247 - acc: 0.9582 - val_loss: 0.1454 - val_acc: 0.9639\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9592\n",
      "Epoch 00137: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1237 - acc: 0.9592 - val_loss: 0.1445 - val_acc: 0.9613\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9602\n",
      "Epoch 00138: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1219 - acc: 0.9602 - val_loss: 0.1445 - val_acc: 0.9620\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9591\n",
      "Epoch 00139: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1249 - acc: 0.9591 - val_loss: 0.1530 - val_acc: 0.9616\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9602\n",
      "Epoch 00140: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1199 - acc: 0.9602 - val_loss: 0.1481 - val_acc: 0.9595\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9597\n",
      "Epoch 00141: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1202 - acc: 0.9597 - val_loss: 0.1627 - val_acc: 0.9611\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9615\n",
      "Epoch 00142: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1192 - acc: 0.9615 - val_loss: 0.1537 - val_acc: 0.9597\n",
      "Epoch 143/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9601\n",
      "Epoch 00143: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1212 - acc: 0.9601 - val_loss: 0.1712 - val_acc: 0.9569\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9604\n",
      "Epoch 00144: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1225 - acc: 0.9604 - val_loss: 0.1529 - val_acc: 0.9574\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9625\n",
      "Epoch 00145: val_loss did not improve from 0.14257\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1163 - acc: 0.9625 - val_loss: 0.1441 - val_acc: 0.9606\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9639\n",
      "Epoch 00146: val_loss improved from 0.14257 to 0.14196, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_6_conv_checkpoint/146-0.1420.hdf5\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1115 - acc: 0.9639 - val_loss: 0.1420 - val_acc: 0.9623\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9626\n",
      "Epoch 00147: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1147 - acc: 0.9626 - val_loss: 0.1604 - val_acc: 0.9592\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9619\n",
      "Epoch 00148: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1160 - acc: 0.9619 - val_loss: 0.1518 - val_acc: 0.9613\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9633\n",
      "Epoch 00149: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1140 - acc: 0.9633 - val_loss: 0.1569 - val_acc: 0.9581\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9618\n",
      "Epoch 00150: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1129 - acc: 0.9618 - val_loss: 0.1546 - val_acc: 0.9597\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9636\n",
      "Epoch 00151: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1110 - acc: 0.9636 - val_loss: 0.1491 - val_acc: 0.9609\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9635\n",
      "Epoch 00152: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1108 - acc: 0.9635 - val_loss: 0.1587 - val_acc: 0.9595\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9628\n",
      "Epoch 00153: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1119 - acc: 0.9628 - val_loss: 0.1461 - val_acc: 0.9602\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9636\n",
      "Epoch 00154: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1124 - acc: 0.9636 - val_loss: 0.1570 - val_acc: 0.9578\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9643\n",
      "Epoch 00155: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1084 - acc: 0.9643 - val_loss: 0.1478 - val_acc: 0.9627\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9648\n",
      "Epoch 00156: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1071 - acc: 0.9648 - val_loss: 0.1501 - val_acc: 0.9602\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9654\n",
      "Epoch 00157: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 840us/sample - loss: 0.1068 - acc: 0.9654 - val_loss: 0.1434 - val_acc: 0.9630\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9648\n",
      "Epoch 00158: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1070 - acc: 0.9648 - val_loss: 0.1616 - val_acc: 0.9618\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9647\n",
      "Epoch 00159: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1063 - acc: 0.9647 - val_loss: 0.1586 - val_acc: 0.9613\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9668\n",
      "Epoch 00160: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1024 - acc: 0.9668 - val_loss: 0.1501 - val_acc: 0.9616\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9665\n",
      "Epoch 00161: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1062 - acc: 0.9665 - val_loss: 0.1557 - val_acc: 0.9602\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9653\n",
      "Epoch 00162: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1051 - acc: 0.9653 - val_loss: 0.1530 - val_acc: 0.9620\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9660\n",
      "Epoch 00163: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1015 - acc: 0.9660 - val_loss: 0.1591 - val_acc: 0.9609\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9648\n",
      "Epoch 00164: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1030 - acc: 0.9648 - val_loss: 0.1561 - val_acc: 0.9616\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9664\n",
      "Epoch 00165: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.1008 - acc: 0.9664 - val_loss: 0.1594 - val_acc: 0.9616\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9674\n",
      "Epoch 00166: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1023 - acc: 0.9675 - val_loss: 0.1581 - val_acc: 0.9583\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9667\n",
      "Epoch 00167: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0993 - acc: 0.9667 - val_loss: 0.1613 - val_acc: 0.9604\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9671\n",
      "Epoch 00168: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1007 - acc: 0.9672 - val_loss: 0.1563 - val_acc: 0.9611\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9675\n",
      "Epoch 00169: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.0957 - acc: 0.9675 - val_loss: 0.1588 - val_acc: 0.9592\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9672\n",
      "Epoch 00170: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.0989 - acc: 0.9672 - val_loss: 0.1577 - val_acc: 0.9625\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9684\n",
      "Epoch 00171: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.0977 - acc: 0.9684 - val_loss: 0.1658 - val_acc: 0.9592\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9685\n",
      "Epoch 00172: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.0972 - acc: 0.9685 - val_loss: 0.1524 - val_acc: 0.9632\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9689\n",
      "Epoch 00173: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.0957 - acc: 0.9689 - val_loss: 0.1601 - val_acc: 0.9611\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9689\n",
      "Epoch 00174: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.0947 - acc: 0.9689 - val_loss: 0.1567 - val_acc: 0.9620\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9679\n",
      "Epoch 00175: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0955 - acc: 0.9679 - val_loss: 0.1471 - val_acc: 0.9609\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9690\n",
      "Epoch 00176: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.0918 - acc: 0.9691 - val_loss: 0.1579 - val_acc: 0.9616\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9693\n",
      "Epoch 00177: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.0919 - acc: 0.9693 - val_loss: 0.1591 - val_acc: 0.9627\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9690\n",
      "Epoch 00178: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 839us/sample - loss: 0.0926 - acc: 0.9691 - val_loss: 0.1575 - val_acc: 0.9604\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9700\n",
      "Epoch 00179: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0945 - acc: 0.9700 - val_loss: 0.1588 - val_acc: 0.9625\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9696\n",
      "Epoch 00180: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0918 - acc: 0.9697 - val_loss: 0.1573 - val_acc: 0.9630\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9706\n",
      "Epoch 00181: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0891 - acc: 0.9706 - val_loss: 0.1630 - val_acc: 0.9623\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9706\n",
      "Epoch 00182: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0895 - acc: 0.9706 - val_loss: 0.1562 - val_acc: 0.9618\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9695\n",
      "Epoch 00183: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0904 - acc: 0.9695 - val_loss: 0.1550 - val_acc: 0.9630\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9711\n",
      "Epoch 00184: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.0888 - acc: 0.9711 - val_loss: 0.1616 - val_acc: 0.9590\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9697\n",
      "Epoch 00185: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 839us/sample - loss: 0.0917 - acc: 0.9697 - val_loss: 0.1601 - val_acc: 0.9620\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9716\n",
      "Epoch 00186: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0864 - acc: 0.9716 - val_loss: 0.1565 - val_acc: 0.9623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9704\n",
      "Epoch 00187: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.0855 - acc: 0.9704 - val_loss: 0.1623 - val_acc: 0.9641\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9723\n",
      "Epoch 00188: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0843 - acc: 0.9723 - val_loss: 0.1455 - val_acc: 0.9618\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9720\n",
      "Epoch 00189: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0845 - acc: 0.9720 - val_loss: 0.1522 - val_acc: 0.9627\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9710\n",
      "Epoch 00190: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0873 - acc: 0.9710 - val_loss: 0.1627 - val_acc: 0.9611\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9723\n",
      "Epoch 00191: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.0852 - acc: 0.9723 - val_loss: 0.1563 - val_acc: 0.9630\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9732\n",
      "Epoch 00192: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0812 - acc: 0.9732 - val_loss: 0.1555 - val_acc: 0.9618\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9712\n",
      "Epoch 00193: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0874 - acc: 0.9712 - val_loss: 0.1600 - val_acc: 0.9604\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9724\n",
      "Epoch 00194: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.0837 - acc: 0.9724 - val_loss: 0.1538 - val_acc: 0.9613\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9729\n",
      "Epoch 00195: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0829 - acc: 0.9729 - val_loss: 0.1591 - val_acc: 0.9625\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9723\n",
      "Epoch 00196: val_loss did not improve from 0.14196\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0834 - acc: 0.9723 - val_loss: 0.1700 - val_acc: 0.9602\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 434us/sample - loss: 0.1792 - acc: 0.9485\n",
      "Loss: 0.17919919491433156 Accuracy: 0.9484943\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3266 - acc: 0.2350\n",
      "Epoch 00001: val_loss improved from inf to 1.58544, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/001-1.5854.hdf5\n",
      "36805/36805 [==============================] - 35s 941us/sample - loss: 2.3264 - acc: 0.2350 - val_loss: 1.5854 - val_acc: 0.4992\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5036 - acc: 0.5141\n",
      "Epoch 00002: val_loss improved from 1.58544 to 1.06838, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/002-1.0684.hdf5\n",
      "36805/36805 [==============================] - 32s 863us/sample - loss: 1.5035 - acc: 0.5141 - val_loss: 1.0684 - val_acc: 0.6834\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1797 - acc: 0.6280\n",
      "Epoch 00003: val_loss improved from 1.06838 to 0.86442, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/003-0.8644.hdf5\n",
      "36805/36805 [==============================] - 32s 863us/sample - loss: 1.1798 - acc: 0.6279 - val_loss: 0.8644 - val_acc: 0.7414\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0029 - acc: 0.6851\n",
      "Epoch 00004: val_loss improved from 0.86442 to 0.73046, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/004-0.7305.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 1.0030 - acc: 0.6851 - val_loss: 0.7305 - val_acc: 0.7878\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8792 - acc: 0.7266\n",
      "Epoch 00005: val_loss improved from 0.73046 to 0.63228, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/005-0.6323.hdf5\n",
      "36805/36805 [==============================] - 32s 864us/sample - loss: 0.8792 - acc: 0.7266 - val_loss: 0.6323 - val_acc: 0.8237\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7913 - acc: 0.7563\n",
      "Epoch 00006: val_loss improved from 0.63228 to 0.56725, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/006-0.5673.hdf5\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.7913 - acc: 0.7563 - val_loss: 0.5673 - val_acc: 0.8428\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7115 - acc: 0.7778\n",
      "Epoch 00007: val_loss improved from 0.56725 to 0.51523, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/007-0.5152.hdf5\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.7115 - acc: 0.7778 - val_loss: 0.5152 - val_acc: 0.8463\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6544 - acc: 0.7963\n",
      "Epoch 00008: val_loss improved from 0.51523 to 0.44187, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/008-0.4419.hdf5\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.6544 - acc: 0.7963 - val_loss: 0.4419 - val_acc: 0.8712\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6091 - acc: 0.8121\n",
      "Epoch 00009: val_loss improved from 0.44187 to 0.39804, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/009-0.3980.hdf5\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 0.6091 - acc: 0.8121 - val_loss: 0.3980 - val_acc: 0.8812\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5648 - acc: 0.8235\n",
      "Epoch 00010: val_loss improved from 0.39804 to 0.38769, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/010-0.3877.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.5647 - acc: 0.8236 - val_loss: 0.3877 - val_acc: 0.8870\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5269 - acc: 0.8347\n",
      "Epoch 00011: val_loss improved from 0.38769 to 0.33861, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/011-0.3386.hdf5\n",
      "36805/36805 [==============================] - 32s 864us/sample - loss: 0.5268 - acc: 0.8348 - val_loss: 0.3386 - val_acc: 0.9019\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4973 - acc: 0.8457\n",
      "Epoch 00012: val_loss improved from 0.33861 to 0.31367, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/012-0.3137.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.4972 - acc: 0.8457 - val_loss: 0.3137 - val_acc: 0.9050\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4743 - acc: 0.8510\n",
      "Epoch 00013: val_loss did not improve from 0.31367\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.4743 - acc: 0.8510 - val_loss: 0.3250 - val_acc: 0.9005\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4470 - acc: 0.8619\n",
      "Epoch 00014: val_loss improved from 0.31367 to 0.29581, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/014-0.2958.hdf5\n",
      "36805/36805 [==============================] - 32s 863us/sample - loss: 0.4470 - acc: 0.8619 - val_loss: 0.2958 - val_acc: 0.9115\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4289 - acc: 0.8676\n",
      "Epoch 00015: val_loss improved from 0.29581 to 0.27909, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/015-0.2791.hdf5\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.4289 - acc: 0.8676 - val_loss: 0.2791 - val_acc: 0.9152\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4064 - acc: 0.8749\n",
      "Epoch 00016: val_loss improved from 0.27909 to 0.25480, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/016-0.2548.hdf5\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.4064 - acc: 0.8749 - val_loss: 0.2548 - val_acc: 0.9278\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3884 - acc: 0.8799\n",
      "Epoch 00017: val_loss did not improve from 0.25480\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.3883 - acc: 0.8799 - val_loss: 0.2571 - val_acc: 0.9220\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3745 - acc: 0.8832\n",
      "Epoch 00018: val_loss improved from 0.25480 to 0.25179, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/018-0.2518.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.3744 - acc: 0.8832 - val_loss: 0.2518 - val_acc: 0.9229\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3552 - acc: 0.8887\n",
      "Epoch 00019: val_loss improved from 0.25179 to 0.21373, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/019-0.2137.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.3551 - acc: 0.8887 - val_loss: 0.2137 - val_acc: 0.9364\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3441 - acc: 0.8936\n",
      "Epoch 00020: val_loss did not improve from 0.21373\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.3442 - acc: 0.8935 - val_loss: 0.2423 - val_acc: 0.9273\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3310 - acc: 0.8977\n",
      "Epoch 00021: val_loss did not improve from 0.21373\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.3309 - acc: 0.8978 - val_loss: 0.2155 - val_acc: 0.9317\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.9029\n",
      "Epoch 00022: val_loss improved from 0.21373 to 0.20345, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/022-0.2034.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.3156 - acc: 0.9029 - val_loss: 0.2034 - val_acc: 0.9378\n",
      "Epoch 23/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3048 - acc: 0.9059\n",
      "Epoch 00023: val_loss improved from 0.20345 to 0.19899, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/023-0.1990.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.3047 - acc: 0.9059 - val_loss: 0.1990 - val_acc: 0.9387\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2902 - acc: 0.9076\n",
      "Epoch 00024: val_loss improved from 0.19899 to 0.18582, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/024-0.1858.hdf5\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.2901 - acc: 0.9076 - val_loss: 0.1858 - val_acc: 0.9436\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2786 - acc: 0.9143\n",
      "Epoch 00025: val_loss improved from 0.18582 to 0.18246, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/025-0.1825.hdf5\n",
      "36805/36805 [==============================] - 32s 863us/sample - loss: 0.2786 - acc: 0.9143 - val_loss: 0.1825 - val_acc: 0.9460\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2695 - acc: 0.9157\n",
      "Epoch 00026: val_loss did not improve from 0.18246\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.2695 - acc: 0.9157 - val_loss: 0.2025 - val_acc: 0.9352\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2669 - acc: 0.9183\n",
      "Epoch 00027: val_loss improved from 0.18246 to 0.16561, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/027-0.1656.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.2669 - acc: 0.9182 - val_loss: 0.1656 - val_acc: 0.9527\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2573 - acc: 0.9200\n",
      "Epoch 00028: val_loss did not improve from 0.16561\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.2573 - acc: 0.9200 - val_loss: 0.1770 - val_acc: 0.9483\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2444 - acc: 0.9230\n",
      "Epoch 00029: val_loss did not improve from 0.16561\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.2444 - acc: 0.9231 - val_loss: 0.1659 - val_acc: 0.9483\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2436 - acc: 0.9248\n",
      "Epoch 00030: val_loss improved from 0.16561 to 0.15926, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/030-0.1593.hdf5\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.2437 - acc: 0.9248 - val_loss: 0.1593 - val_acc: 0.9529\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2333 - acc: 0.9264\n",
      "Epoch 00031: val_loss improved from 0.15926 to 0.15641, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/031-0.1564.hdf5\n",
      "36805/36805 [==============================] - 32s 863us/sample - loss: 0.2333 - acc: 0.9264 - val_loss: 0.1564 - val_acc: 0.9532\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2304 - acc: 0.9282\n",
      "Epoch 00032: val_loss did not improve from 0.15641\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.2304 - acc: 0.9282 - val_loss: 0.1710 - val_acc: 0.9448\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9314\n",
      "Epoch 00033: val_loss improved from 0.15641 to 0.15057, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/033-0.1506.hdf5\n",
      "36805/36805 [==============================] - 32s 863us/sample - loss: 0.2223 - acc: 0.9314 - val_loss: 0.1506 - val_acc: 0.9525\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2180 - acc: 0.9307\n",
      "Epoch 00034: val_loss did not improve from 0.15057\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.2180 - acc: 0.9307 - val_loss: 0.1528 - val_acc: 0.9520\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9332\n",
      "Epoch 00035: val_loss did not improve from 0.15057\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.2109 - acc: 0.9332 - val_loss: 0.1901 - val_acc: 0.9411\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2029 - acc: 0.9337\n",
      "Epoch 00036: val_loss improved from 0.15057 to 0.15016, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/036-0.1502.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.2029 - acc: 0.9338 - val_loss: 0.1502 - val_acc: 0.9534\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9373\n",
      "Epoch 00037: val_loss improved from 0.15016 to 0.14069, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/037-0.1407.hdf5\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.2018 - acc: 0.9373 - val_loss: 0.1407 - val_acc: 0.9555\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9376\n",
      "Epoch 00038: val_loss did not improve from 0.14069\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.1975 - acc: 0.9376 - val_loss: 0.1451 - val_acc: 0.9536\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1891 - acc: 0.9403\n",
      "Epoch 00039: val_loss did not improve from 0.14069\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.1891 - acc: 0.9403 - val_loss: 0.1463 - val_acc: 0.9541\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9426\n",
      "Epoch 00040: val_loss did not improve from 0.14069\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.1853 - acc: 0.9426 - val_loss: 0.1446 - val_acc: 0.9569\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1812 - acc: 0.9420\n",
      "Epoch 00041: val_loss did not improve from 0.14069\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.1812 - acc: 0.9420 - val_loss: 0.1492 - val_acc: 0.9539\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1758 - acc: 0.9442\n",
      "Epoch 00042: val_loss did not improve from 0.14069\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.1758 - acc: 0.9442 - val_loss: 0.1458 - val_acc: 0.9567\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9464\n",
      "Epoch 00043: val_loss improved from 0.14069 to 0.13587, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/043-0.1359.hdf5\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.1697 - acc: 0.9464 - val_loss: 0.1359 - val_acc: 0.9569\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9458\n",
      "Epoch 00044: val_loss did not improve from 0.13587\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.1679 - acc: 0.9458 - val_loss: 0.1372 - val_acc: 0.9583\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1683 - acc: 0.9461\n",
      "Epoch 00045: val_loss did not improve from 0.13587\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.1683 - acc: 0.9461 - val_loss: 0.1379 - val_acc: 0.9590\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9480\n",
      "Epoch 00046: val_loss improved from 0.13587 to 0.13443, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/046-0.1344.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.1604 - acc: 0.9480 - val_loss: 0.1344 - val_acc: 0.9616\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9499\n",
      "Epoch 00047: val_loss did not improve from 0.13443\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.1547 - acc: 0.9499 - val_loss: 0.1458 - val_acc: 0.9588\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9504\n",
      "Epoch 00048: val_loss improved from 0.13443 to 0.13146, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/048-0.1315.hdf5\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.1576 - acc: 0.9504 - val_loss: 0.1315 - val_acc: 0.9602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9517\n",
      "Epoch 00049: val_loss improved from 0.13146 to 0.12949, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/049-0.1295.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.1484 - acc: 0.9517 - val_loss: 0.1295 - val_acc: 0.9599\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9523\n",
      "Epoch 00050: val_loss did not improve from 0.12949\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.1512 - acc: 0.9523 - val_loss: 0.1364 - val_acc: 0.9567\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9533\n",
      "Epoch 00051: val_loss improved from 0.12949 to 0.12915, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/051-0.1291.hdf5\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.1449 - acc: 0.9533 - val_loss: 0.1291 - val_acc: 0.9646\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9544\n",
      "Epoch 00052: val_loss did not improve from 0.12915\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.1394 - acc: 0.9544 - val_loss: 0.1307 - val_acc: 0.9602\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9555\n",
      "Epoch 00053: val_loss did not improve from 0.12915\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.1377 - acc: 0.9555 - val_loss: 0.1460 - val_acc: 0.9557\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9570\n",
      "Epoch 00054: val_loss did not improve from 0.12915\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.1365 - acc: 0.9570 - val_loss: 0.1342 - val_acc: 0.9597\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1365 - acc: 0.9552\n",
      "Epoch 00055: val_loss did not improve from 0.12915\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.1365 - acc: 0.9552 - val_loss: 0.1320 - val_acc: 0.9637\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9575\n",
      "Epoch 00056: val_loss did not improve from 0.12915\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.1302 - acc: 0.9575 - val_loss: 0.1321 - val_acc: 0.9627\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9582\n",
      "Epoch 00057: val_loss did not improve from 0.12915\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.1268 - acc: 0.9582 - val_loss: 0.1373 - val_acc: 0.9609\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9585\n",
      "Epoch 00058: val_loss improved from 0.12915 to 0.12073, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/058-0.1207.hdf5\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.1286 - acc: 0.9585 - val_loss: 0.1207 - val_acc: 0.9623\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9598\n",
      "Epoch 00059: val_loss did not improve from 0.12073\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.1206 - acc: 0.9598 - val_loss: 0.1274 - val_acc: 0.9641\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9607\n",
      "Epoch 00060: val_loss did not improve from 0.12073\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.1209 - acc: 0.9607 - val_loss: 0.1282 - val_acc: 0.9620\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9626\n",
      "Epoch 00061: val_loss improved from 0.12073 to 0.12000, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/061-0.1200.hdf5\n",
      "36805/36805 [==============================] - 32s 863us/sample - loss: 0.1170 - acc: 0.9626 - val_loss: 0.1200 - val_acc: 0.9674\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9613\n",
      "Epoch 00062: val_loss did not improve from 0.12000\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.1156 - acc: 0.9613 - val_loss: 0.1267 - val_acc: 0.9674\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9631\n",
      "Epoch 00063: val_loss did not improve from 0.12000\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.1127 - acc: 0.9631 - val_loss: 0.1234 - val_acc: 0.9669\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9635\n",
      "Epoch 00064: val_loss did not improve from 0.12000\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.1133 - acc: 0.9635 - val_loss: 0.1319 - val_acc: 0.9630\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9633\n",
      "Epoch 00065: val_loss did not improve from 0.12000\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.1103 - acc: 0.9633 - val_loss: 0.1311 - val_acc: 0.9585\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9642\n",
      "Epoch 00066: val_loss did not improve from 0.12000\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.1082 - acc: 0.9642 - val_loss: 0.1444 - val_acc: 0.9618\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9640\n",
      "Epoch 00067: val_loss did not improve from 0.12000\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.1065 - acc: 0.9641 - val_loss: 0.1356 - val_acc: 0.9620\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9668\n",
      "Epoch 00068: val_loss improved from 0.12000 to 0.11964, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_7_conv_checkpoint/068-0.1196.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.1020 - acc: 0.9667 - val_loss: 0.1196 - val_acc: 0.9672\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9659\n",
      "Epoch 00069: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.1035 - acc: 0.9659 - val_loss: 0.1357 - val_acc: 0.9646\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9668\n",
      "Epoch 00070: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.1007 - acc: 0.9669 - val_loss: 0.1255 - val_acc: 0.9641\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9668\n",
      "Epoch 00071: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.0977 - acc: 0.9668 - val_loss: 0.1202 - val_acc: 0.9676\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9671\n",
      "Epoch 00072: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.0984 - acc: 0.9671 - val_loss: 0.1265 - val_acc: 0.9641\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9692\n",
      "Epoch 00073: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.0926 - acc: 0.9692 - val_loss: 0.1228 - val_acc: 0.9651\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9694\n",
      "Epoch 00074: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.0929 - acc: 0.9694 - val_loss: 0.1298 - val_acc: 0.9651\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9710\n",
      "Epoch 00075: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.0896 - acc: 0.9710 - val_loss: 0.1325 - val_acc: 0.9623\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9696\n",
      "Epoch 00076: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.0899 - acc: 0.9696 - val_loss: 0.1420 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9702\n",
      "Epoch 00077: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.0888 - acc: 0.9702 - val_loss: 0.1217 - val_acc: 0.9639\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9714\n",
      "Epoch 00078: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.0871 - acc: 0.9714 - val_loss: 0.1304 - val_acc: 0.9653\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9724\n",
      "Epoch 00079: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.0824 - acc: 0.9724 - val_loss: 0.1337 - val_acc: 0.9653\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9719\n",
      "Epoch 00080: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.0848 - acc: 0.9719 - val_loss: 0.1307 - val_acc: 0.9648\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9733\n",
      "Epoch 00081: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.0802 - acc: 0.9733 - val_loss: 0.1312 - val_acc: 0.9632\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9732\n",
      "Epoch 00082: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.0800 - acc: 0.9732 - val_loss: 0.1223 - val_acc: 0.9655\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9722\n",
      "Epoch 00083: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 857us/sample - loss: 0.0811 - acc: 0.9722 - val_loss: 0.1301 - val_acc: 0.9665\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9735\n",
      "Epoch 00084: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.0779 - acc: 0.9735 - val_loss: 0.1509 - val_acc: 0.9597\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9729\n",
      "Epoch 00085: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.0792 - acc: 0.9729 - val_loss: 0.1205 - val_acc: 0.9700\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9747\n",
      "Epoch 00086: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 857us/sample - loss: 0.0772 - acc: 0.9747 - val_loss: 0.1364 - val_acc: 0.9646\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9745\n",
      "Epoch 00087: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.0746 - acc: 0.9745 - val_loss: 0.1254 - val_acc: 0.9676\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9760\n",
      "Epoch 00088: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.0718 - acc: 0.9759 - val_loss: 0.1345 - val_acc: 0.9672\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9761\n",
      "Epoch 00089: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.0717 - acc: 0.9761 - val_loss: 0.1362 - val_acc: 0.9623\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9750\n",
      "Epoch 00090: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.0716 - acc: 0.9750 - val_loss: 0.1222 - val_acc: 0.9665\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9760\n",
      "Epoch 00091: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.0721 - acc: 0.9760 - val_loss: 0.1403 - val_acc: 0.9634\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9784\n",
      "Epoch 00092: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.0642 - acc: 0.9784 - val_loss: 0.1344 - val_acc: 0.9646\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9778\n",
      "Epoch 00093: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.0662 - acc: 0.9778 - val_loss: 0.1375 - val_acc: 0.9630\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9773\n",
      "Epoch 00094: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.0681 - acc: 0.9773 - val_loss: 0.1255 - val_acc: 0.9669\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9778\n",
      "Epoch 00095: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.0652 - acc: 0.9778 - val_loss: 0.1349 - val_acc: 0.9658\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9779\n",
      "Epoch 00096: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.0637 - acc: 0.9779 - val_loss: 0.1383 - val_acc: 0.9681\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9777\n",
      "Epoch 00097: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.0647 - acc: 0.9777 - val_loss: 0.1252 - val_acc: 0.9662\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9781\n",
      "Epoch 00098: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.0658 - acc: 0.9781 - val_loss: 0.1296 - val_acc: 0.9660\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9779\n",
      "Epoch 00099: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.0636 - acc: 0.9779 - val_loss: 0.1222 - val_acc: 0.9693\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9797\n",
      "Epoch 00100: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 856us/sample - loss: 0.0599 - acc: 0.9796 - val_loss: 0.1442 - val_acc: 0.9627\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9795\n",
      "Epoch 00101: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 861us/sample - loss: 0.0621 - acc: 0.9795 - val_loss: 0.1350 - val_acc: 0.9644\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9794\n",
      "Epoch 00102: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.0603 - acc: 0.9794 - val_loss: 0.1454 - val_acc: 0.9609\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9811\n",
      "Epoch 00103: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.0588 - acc: 0.9811 - val_loss: 0.1283 - val_acc: 0.9669\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9790\n",
      "Epoch 00104: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.0614 - acc: 0.9790 - val_loss: 0.1507 - val_acc: 0.9651\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9810\n",
      "Epoch 00105: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.0555 - acc: 0.9810 - val_loss: 0.1340 - val_acc: 0.9669\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9820\n",
      "Epoch 00106: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.0540 - acc: 0.9820 - val_loss: 0.1256 - val_acc: 0.9665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9820\n",
      "Epoch 00107: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.0558 - acc: 0.9820 - val_loss: 0.1384 - val_acc: 0.9667\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9808\n",
      "Epoch 00108: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.0565 - acc: 0.9808 - val_loss: 0.1382 - val_acc: 0.9651\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9832\n",
      "Epoch 00109: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.0512 - acc: 0.9832 - val_loss: 0.1271 - val_acc: 0.9669\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9822\n",
      "Epoch 00110: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.0539 - acc: 0.9822 - val_loss: 0.1396 - val_acc: 0.9653\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9818\n",
      "Epoch 00111: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 863us/sample - loss: 0.0534 - acc: 0.9818 - val_loss: 0.1382 - val_acc: 0.9653\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9826\n",
      "Epoch 00112: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 857us/sample - loss: 0.0523 - acc: 0.9826 - val_loss: 0.1542 - val_acc: 0.9660\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9825\n",
      "Epoch 00113: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 858us/sample - loss: 0.0522 - acc: 0.9825 - val_loss: 0.1346 - val_acc: 0.9679\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9829\n",
      "Epoch 00114: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 859us/sample - loss: 0.0491 - acc: 0.9829 - val_loss: 0.1336 - val_acc: 0.9646\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9831\n",
      "Epoch 00115: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.0486 - acc: 0.9831 - val_loss: 0.1568 - val_acc: 0.9660\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9845\n",
      "Epoch 00116: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.0467 - acc: 0.9845 - val_loss: 0.1483 - val_acc: 0.9667\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9844\n",
      "Epoch 00117: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 857us/sample - loss: 0.0475 - acc: 0.9844 - val_loss: 0.1458 - val_acc: 0.9660\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9839\n",
      "Epoch 00118: val_loss did not improve from 0.11964\n",
      "36805/36805 [==============================] - 32s 860us/sample - loss: 0.0476 - acc: 0.9839 - val_loss: 0.1496 - val_acc: 0.9651\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 442us/sample - loss: 0.1847 - acc: 0.9433\n",
      "Loss: 0.18465333684644472 Accuracy: 0.94330215\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1575 - acc: 0.3076\n",
      "Epoch 00001: val_loss improved from inf to 1.21334, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/001-1.2133.hdf5\n",
      "36805/36805 [==============================] - 37s 999us/sample - loss: 2.1573 - acc: 0.3077 - val_loss: 1.2133 - val_acc: 0.6369\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1797 - acc: 0.6171\n",
      "Epoch 00002: val_loss improved from 1.21334 to 0.78498, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/002-0.7850.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 1.1796 - acc: 0.6171 - val_loss: 0.7850 - val_acc: 0.7491\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8695 - acc: 0.7194\n",
      "Epoch 00003: val_loss improved from 0.78498 to 0.57762, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/003-0.5776.hdf5\n",
      "36805/36805 [==============================] - 33s 890us/sample - loss: 0.8696 - acc: 0.7194 - val_loss: 0.5776 - val_acc: 0.8328\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7008 - acc: 0.7755\n",
      "Epoch 00004: val_loss improved from 0.57762 to 0.50873, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/004-0.5087.hdf5\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.7009 - acc: 0.7754 - val_loss: 0.5087 - val_acc: 0.8393\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5856 - acc: 0.8149\n",
      "Epoch 00005: val_loss improved from 0.50873 to 0.40488, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/005-0.4049.hdf5\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.5855 - acc: 0.8149 - val_loss: 0.4049 - val_acc: 0.8810\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5072 - acc: 0.8409\n",
      "Epoch 00006: val_loss improved from 0.40488 to 0.36352, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/006-0.3635.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.5072 - acc: 0.8409 - val_loss: 0.3635 - val_acc: 0.8884\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4553 - acc: 0.8562\n",
      "Epoch 00007: val_loss improved from 0.36352 to 0.28937, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/007-0.2894.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.4554 - acc: 0.8562 - val_loss: 0.2894 - val_acc: 0.9138\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4013 - acc: 0.8728\n",
      "Epoch 00008: val_loss improved from 0.28937 to 0.25813, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/008-0.2581.hdf5\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.4013 - acc: 0.8728 - val_loss: 0.2581 - val_acc: 0.9215\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3737 - acc: 0.8803\n",
      "Epoch 00009: val_loss improved from 0.25813 to 0.25444, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/009-0.2544.hdf5\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.3738 - acc: 0.8803 - val_loss: 0.2544 - val_acc: 0.9220\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3481 - acc: 0.8918\n",
      "Epoch 00010: val_loss improved from 0.25444 to 0.23056, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/010-0.2306.hdf5\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.3484 - acc: 0.8918 - val_loss: 0.2306 - val_acc: 0.9278\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3258 - acc: 0.8973\n",
      "Epoch 00011: val_loss improved from 0.23056 to 0.22424, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/011-0.2242.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.3258 - acc: 0.8973 - val_loss: 0.2242 - val_acc: 0.9301\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2986 - acc: 0.9074\n",
      "Epoch 00012: val_loss did not improve from 0.22424\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.2986 - acc: 0.9074 - val_loss: 0.2351 - val_acc: 0.9271\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2868 - acc: 0.9094\n",
      "Epoch 00013: val_loss improved from 0.22424 to 0.20284, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/013-0.2028.hdf5\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.2868 - acc: 0.9094 - val_loss: 0.2028 - val_acc: 0.9338\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2680 - acc: 0.9160\n",
      "Epoch 00014: val_loss improved from 0.20284 to 0.20118, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/014-0.2012.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.2680 - acc: 0.9160 - val_loss: 0.2012 - val_acc: 0.9366\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2549 - acc: 0.9183\n",
      "Epoch 00015: val_loss improved from 0.20118 to 0.18464, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/015-0.1846.hdf5\n",
      "36805/36805 [==============================] - 33s 890us/sample - loss: 0.2548 - acc: 0.9183 - val_loss: 0.1846 - val_acc: 0.9474\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2424 - acc: 0.9235\n",
      "Epoch 00016: val_loss did not improve from 0.18464\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.2426 - acc: 0.9235 - val_loss: 0.2083 - val_acc: 0.9383\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2366 - acc: 0.9258\n",
      "Epoch 00017: val_loss did not improve from 0.18464\n",
      "36805/36805 [==============================] - 32s 883us/sample - loss: 0.2365 - acc: 0.9258 - val_loss: 0.1966 - val_acc: 0.9394\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2201 - acc: 0.9304\n",
      "Epoch 00018: val_loss did not improve from 0.18464\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.2202 - acc: 0.9303 - val_loss: 0.1847 - val_acc: 0.9422\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9332\n",
      "Epoch 00019: val_loss improved from 0.18464 to 0.15360, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/019-0.1536.hdf5\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.2106 - acc: 0.9332 - val_loss: 0.1536 - val_acc: 0.9511\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9371\n",
      "Epoch 00020: val_loss improved from 0.15360 to 0.15339, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/020-0.1534.hdf5\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.1958 - acc: 0.9371 - val_loss: 0.1534 - val_acc: 0.9520\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1897 - acc: 0.9391\n",
      "Epoch 00021: val_loss improved from 0.15339 to 0.14678, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/021-0.1468.hdf5\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.1897 - acc: 0.9391 - val_loss: 0.1468 - val_acc: 0.9560\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9414\n",
      "Epoch 00022: val_loss did not improve from 0.14678\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.1821 - acc: 0.9413 - val_loss: 0.1664 - val_acc: 0.9476\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9427\n",
      "Epoch 00023: val_loss improved from 0.14678 to 0.14497, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/023-0.1450.hdf5\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.1789 - acc: 0.9428 - val_loss: 0.1450 - val_acc: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9451\n",
      "Epoch 00024: val_loss did not improve from 0.14497\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.1696 - acc: 0.9451 - val_loss: 0.1485 - val_acc: 0.9539\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9482\n",
      "Epoch 00025: val_loss did not improve from 0.14497\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.1600 - acc: 0.9482 - val_loss: 0.1569 - val_acc: 0.9492\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9492\n",
      "Epoch 00026: val_loss did not improve from 0.14497\n",
      "36805/36805 [==============================] - 32s 881us/sample - loss: 0.1587 - acc: 0.9492 - val_loss: 0.1457 - val_acc: 0.9569\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9520\n",
      "Epoch 00027: val_loss did not improve from 0.14497\n",
      "36805/36805 [==============================] - 33s 883us/sample - loss: 0.1495 - acc: 0.9520 - val_loss: 0.1704 - val_acc: 0.9495\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9526\n",
      "Epoch 00028: val_loss did not improve from 0.14497\n",
      "36805/36805 [==============================] - 32s 883us/sample - loss: 0.1448 - acc: 0.9526 - val_loss: 0.1506 - val_acc: 0.9536\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9553\n",
      "Epoch 00029: val_loss did not improve from 0.14497\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.1374 - acc: 0.9553 - val_loss: 0.1518 - val_acc: 0.9564\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9558\n",
      "Epoch 00030: val_loss improved from 0.14497 to 0.14448, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/030-0.1445.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.1317 - acc: 0.9558 - val_loss: 0.1445 - val_acc: 0.9541\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9592\n",
      "Epoch 00031: val_loss did not improve from 0.14448\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.1259 - acc: 0.9592 - val_loss: 0.1582 - val_acc: 0.9555\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9599\n",
      "Epoch 00032: val_loss improved from 0.14448 to 0.14059, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/032-0.1406.hdf5\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.1220 - acc: 0.9599 - val_loss: 0.1406 - val_acc: 0.9595\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9592\n",
      "Epoch 00033: val_loss improved from 0.14059 to 0.12745, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/033-0.1275.hdf5\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.1227 - acc: 0.9592 - val_loss: 0.1275 - val_acc: 0.9595\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.9606\n",
      "Epoch 00034: val_loss did not improve from 0.12745\n",
      "36805/36805 [==============================] - 33s 883us/sample - loss: 0.1185 - acc: 0.9606 - val_loss: 0.1333 - val_acc: 0.9567\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9643\n",
      "Epoch 00035: val_loss improved from 0.12745 to 0.12290, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/035-0.1229.hdf5\n",
      "36805/36805 [==============================] - 33s 891us/sample - loss: 0.1077 - acc: 0.9643 - val_loss: 0.1229 - val_acc: 0.9648\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9641\n",
      "Epoch 00036: val_loss did not improve from 0.12290\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.1065 - acc: 0.9641 - val_loss: 0.1933 - val_acc: 0.9429\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9635\n",
      "Epoch 00037: val_loss did not improve from 0.12290\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.1097 - acc: 0.9635 - val_loss: 0.1310 - val_acc: 0.9602\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9668\n",
      "Epoch 00038: val_loss did not improve from 0.12290\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0994 - acc: 0.9668 - val_loss: 0.1372 - val_acc: 0.9606\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9673\n",
      "Epoch 00039: val_loss did not improve from 0.12290\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0953 - acc: 0.9672 - val_loss: 0.1350 - val_acc: 0.9609\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9684\n",
      "Epoch 00040: val_loss did not improve from 0.12290\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.0931 - acc: 0.9684 - val_loss: 0.1800 - val_acc: 0.9513\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9702\n",
      "Epoch 00041: val_loss did not improve from 0.12290\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.0880 - acc: 0.9702 - val_loss: 0.1477 - val_acc: 0.9569\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9710\n",
      "Epoch 00042: val_loss did not improve from 0.12290\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.0850 - acc: 0.9710 - val_loss: 0.1347 - val_acc: 0.9588\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9722\n",
      "Epoch 00043: val_loss did not improve from 0.12290\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0807 - acc: 0.9722 - val_loss: 0.1453 - val_acc: 0.9571\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9705\n",
      "Epoch 00044: val_loss improved from 0.12290 to 0.12083, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_DO_8_conv_checkpoint/044-0.1208.hdf5\n",
      "36805/36805 [==============================] - 33s 890us/sample - loss: 0.0843 - acc: 0.9705 - val_loss: 0.1208 - val_acc: 0.9646\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9733\n",
      "Epoch 00045: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.0784 - acc: 0.9733 - val_loss: 0.1407 - val_acc: 0.9611\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9752\n",
      "Epoch 00046: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0746 - acc: 0.9752 - val_loss: 0.1347 - val_acc: 0.9630\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9757\n",
      "Epoch 00047: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.0720 - acc: 0.9757 - val_loss: 0.1420 - val_acc: 0.9609\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9753\n",
      "Epoch 00048: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.0722 - acc: 0.9753 - val_loss: 0.1379 - val_acc: 0.9602\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9760\n",
      "Epoch 00049: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 892us/sample - loss: 0.0695 - acc: 0.9760 - val_loss: 0.1357 - val_acc: 0.9623\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9767\n",
      "Epoch 00050: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.0691 - acc: 0.9767 - val_loss: 0.1616 - val_acc: 0.9569\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9760\n",
      "Epoch 00051: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.0680 - acc: 0.9760 - val_loss: 0.1657 - val_acc: 0.9560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9784\n",
      "Epoch 00052: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.0623 - acc: 0.9784 - val_loss: 0.1446 - val_acc: 0.9609\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9794\n",
      "Epoch 00053: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.0608 - acc: 0.9794 - val_loss: 0.1610 - val_acc: 0.9557\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9795\n",
      "Epoch 00054: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.0610 - acc: 0.9795 - val_loss: 0.1330 - val_acc: 0.9632\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9802\n",
      "Epoch 00055: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 883us/sample - loss: 0.0588 - acc: 0.9802 - val_loss: 0.1474 - val_acc: 0.9623\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9793\n",
      "Epoch 00056: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.0601 - acc: 0.9793 - val_loss: 0.1392 - val_acc: 0.9620\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9817\n",
      "Epoch 00057: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 892us/sample - loss: 0.0535 - acc: 0.9817 - val_loss: 0.1400 - val_acc: 0.9627\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9819\n",
      "Epoch 00058: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.0524 - acc: 0.9819 - val_loss: 0.1664 - val_acc: 0.9555\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9817\n",
      "Epoch 00059: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0519 - acc: 0.9817 - val_loss: 0.1484 - val_acc: 0.9604\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9828\n",
      "Epoch 00060: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0504 - acc: 0.9828 - val_loss: 0.1631 - val_acc: 0.9578\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9832\n",
      "Epoch 00061: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.0500 - acc: 0.9832 - val_loss: 0.1500 - val_acc: 0.9620\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9828\n",
      "Epoch 00062: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.0501 - acc: 0.9828 - val_loss: 0.1605 - val_acc: 0.9585\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9833\n",
      "Epoch 00063: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 892us/sample - loss: 0.0468 - acc: 0.9833 - val_loss: 0.1395 - val_acc: 0.9653\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9844\n",
      "Epoch 00064: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0459 - acc: 0.9844 - val_loss: 0.1697 - val_acc: 0.9597\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9837\n",
      "Epoch 00065: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 895us/sample - loss: 0.0473 - acc: 0.9838 - val_loss: 0.1470 - val_acc: 0.9632\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9851\n",
      "Epoch 00066: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0434 - acc: 0.9851 - val_loss: 0.1492 - val_acc: 0.9606\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9865\n",
      "Epoch 00067: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 895us/sample - loss: 0.0410 - acc: 0.9865 - val_loss: 0.1556 - val_acc: 0.9630\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9863\n",
      "Epoch 00068: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 890us/sample - loss: 0.0414 - acc: 0.9863 - val_loss: 0.1636 - val_acc: 0.9606\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9855\n",
      "Epoch 00069: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0424 - acc: 0.9855 - val_loss: 0.1536 - val_acc: 0.9641\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9866\n",
      "Epoch 00070: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.0390 - acc: 0.9866 - val_loss: 0.1851 - val_acc: 0.9569\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9860\n",
      "Epoch 00071: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 32s 882us/sample - loss: 0.0407 - acc: 0.9860 - val_loss: 0.1712 - val_acc: 0.9595\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9883\n",
      "Epoch 00072: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.0360 - acc: 0.9883 - val_loss: 0.1637 - val_acc: 0.9613\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9879\n",
      "Epoch 00073: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0370 - acc: 0.9879 - val_loss: 0.1731 - val_acc: 0.9604\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9869\n",
      "Epoch 00074: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 892us/sample - loss: 0.0396 - acc: 0.9869 - val_loss: 0.1686 - val_acc: 0.9616\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9887\n",
      "Epoch 00075: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 891us/sample - loss: 0.0339 - acc: 0.9887 - val_loss: 0.1726 - val_acc: 0.9613\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9886\n",
      "Epoch 00076: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 32s 880us/sample - loss: 0.0330 - acc: 0.9886 - val_loss: 0.1596 - val_acc: 0.9644\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9884\n",
      "Epoch 00077: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 32s 881us/sample - loss: 0.0348 - acc: 0.9884 - val_loss: 0.1803 - val_acc: 0.9599\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9887\n",
      "Epoch 00078: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 892us/sample - loss: 0.0337 - acc: 0.9888 - val_loss: 0.1681 - val_acc: 0.9632\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9901\n",
      "Epoch 00079: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 32s 881us/sample - loss: 0.0299 - acc: 0.9901 - val_loss: 0.1800 - val_acc: 0.9606\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9895\n",
      "Epoch 00080: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 883us/sample - loss: 0.0316 - acc: 0.9895 - val_loss: 0.1753 - val_acc: 0.9634\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9886\n",
      "Epoch 00081: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 32s 880us/sample - loss: 0.0325 - acc: 0.9886 - val_loss: 0.1929 - val_acc: 0.9567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9898\n",
      "Epoch 00082: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0315 - acc: 0.9898 - val_loss: 0.1716 - val_acc: 0.9616\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9895\n",
      "Epoch 00083: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 891us/sample - loss: 0.0300 - acc: 0.9895 - val_loss: 0.1993 - val_acc: 0.9604\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9899\n",
      "Epoch 00084: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 891us/sample - loss: 0.0294 - acc: 0.9899 - val_loss: 0.1894 - val_acc: 0.9639\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9906\n",
      "Epoch 00085: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 895us/sample - loss: 0.0276 - acc: 0.9906 - val_loss: 0.1769 - val_acc: 0.9632\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9901\n",
      "Epoch 00086: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 890us/sample - loss: 0.0294 - acc: 0.9901 - val_loss: 0.1831 - val_acc: 0.9616\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9907\n",
      "Epoch 00087: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0278 - acc: 0.9907 - val_loss: 0.1832 - val_acc: 0.9588\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9920\n",
      "Epoch 00088: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 894us/sample - loss: 0.0239 - acc: 0.9920 - val_loss: 0.1803 - val_acc: 0.9613\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9908\n",
      "Epoch 00089: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 898us/sample - loss: 0.0275 - acc: 0.9908 - val_loss: 0.1889 - val_acc: 0.9634\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9914\n",
      "Epoch 00090: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.0254 - acc: 0.9914 - val_loss: 0.1868 - val_acc: 0.9611\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9899\n",
      "Epoch 00091: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 893us/sample - loss: 0.0298 - acc: 0.9899 - val_loss: 0.1773 - val_acc: 0.9609\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9916\n",
      "Epoch 00092: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 892us/sample - loss: 0.0260 - acc: 0.9916 - val_loss: 0.1824 - val_acc: 0.9648\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9918\n",
      "Epoch 00093: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 890us/sample - loss: 0.0245 - acc: 0.9918 - val_loss: 0.1851 - val_acc: 0.9623\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9924\n",
      "Epoch 00094: val_loss did not improve from 0.12083\n",
      "36805/36805 [==============================] - 33s 890us/sample - loss: 0.0239 - acc: 0.9924 - val_loss: 0.2007 - val_acc: 0.9632\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 467us/sample - loss: 0.2023 - acc: 0.9458\n",
      "Loss: 0.20229810329457804 Accuracy: 0.9457944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_multi_3_GAP_DO'\n",
    "\n",
    "for i in range(3, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_cnn(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 64)    384         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 64)    0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 64)     0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 64)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 64)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 64)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 64)           0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 64)           0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 64)           0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 192)          0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_average_pooling1d_19[0][0]\n",
      "                                                                 global_average_pooling1d_20[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 192)          0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           3088        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,560\n",
      "Trainable params: 44,560\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 445us/sample - loss: 0.7133 - acc: 0.7884\n",
      "Loss: 0.7133490382944189 Accuracy: 0.78836966\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 16000, 64)    384         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16000, 64)    0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 5333, 64)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5333, 64)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1777, 64)     0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1777, 64)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 592, 64)      0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 592, 64)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 197, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 64)           0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 64)           0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 64)           0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 192)          0           global_average_pooling1d_21[0][0]\n",
      "                                                                 global_average_pooling1d_22[0][0]\n",
      "                                                                 global_average_pooling1d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 192)          0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           3088        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 65,104\n",
      "Trainable params: 65,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 448us/sample - loss: 0.4625 - acc: 0.8704\n",
      "Loss: 0.4625137715696174 Accuracy: 0.87040496\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 16000, 64)    384         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16000, 64)    0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 5333, 64)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5333, 64)     0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1777, 64)     0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1777, 64)     0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 592, 64)      0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 592, 64)      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 197, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 197, 128)     0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 65, 128)      0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 64)           0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 64)           0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_26 (Gl (None, 128)          0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 256)          0           global_average_pooling1d_24[0][0]\n",
      "                                                                 global_average_pooling1d_25[0][0]\n",
      "                                                                 global_average_pooling1d_26[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 256)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           4112        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 107,216\n",
      "Trainable params: 107,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 442us/sample - loss: 0.2658 - acc: 0.9234\n",
      "Loss: 0.26581726950648416 Accuracy: 0.92336446\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 16000, 64)    384         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16000, 64)    0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 5333, 64)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5333, 64)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1777, 64)     0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1777, 64)     0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 592, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 592, 64)      0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 197, 64)      0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 197, 128)     0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 65, 128)      0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 65, 128)      0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 21, 128)      0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_27 (Gl (None, 64)           0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_28 (Gl (None, 128)          0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_29 (Gl (None, 128)          0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 320)          0           global_average_pooling1d_27[0][0]\n",
      "                                                                 global_average_pooling1d_28[0][0]\n",
      "                                                                 global_average_pooling1d_29[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 320)          0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           5136        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 190,288\n",
      "Trainable params: 190,288\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 456us/sample - loss: 0.1792 - acc: 0.9485\n",
      "Loss: 0.17919919491433156 Accuracy: 0.9484943\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 16000, 64)    384         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16000, 64)    0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 5333, 64)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5333, 64)     0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 1777, 64)     0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1777, 64)     0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 592, 64)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 592, 64)      0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 197, 64)      0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 197, 128)     0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 65, 128)      0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 65, 128)      0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 21, 128)      0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 21, 128)      82048       max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 21, 128)      0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 7, 128)       0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_30 (Gl (None, 128)          0           max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_31 (Gl (None, 128)          0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_32 (Gl (None, 128)          0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 384)          0           global_average_pooling1d_30[0][0]\n",
      "                                                                 global_average_pooling1d_31[0][0]\n",
      "                                                                 global_average_pooling1d_32[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 384)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           6160        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 273,360\n",
      "Trainable params: 273,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 480us/sample - loss: 0.1847 - acc: 0.9433\n",
      "Loss: 0.18465333684644472 Accuracy: 0.94330215\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 16000, 64)    384         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16000, 64)    0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 5333, 64)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5333, 64)     0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 1777, 64)     0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1777, 64)     0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 592, 64)      0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 592, 64)      0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 197, 64)      0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 197, 128)     0           conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 65, 128)      0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 65, 128)      0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 21, 128)      0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 21, 128)      82048       max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 21, 128)      0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 7, 128)       0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 7, 128)       82048       max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 128)       0           conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 2, 128)       0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_33 (Gl (None, 128)          0           max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_34 (Gl (None, 128)          0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_35 (Gl (None, 128)          0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 384)          0           global_average_pooling1d_33[0][0]\n",
      "                                                                 global_average_pooling1d_34[0][0]\n",
      "                                                                 global_average_pooling1d_35[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 384)          0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           6160        dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 355,408\n",
      "Trainable params: 355,408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 483us/sample - loss: 0.2023 - acc: 0.9458\n",
      "Loss: 0.20229810329457804 Accuracy: 0.9457944\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_multi_3_GAP_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 9):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 64)    384         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 64)    0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 64)     0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 64)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 64)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 64)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 64)           0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 64)           0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 64)           0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 192)          0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_average_pooling1d_19[0][0]\n",
      "                                                                 global_average_pooling1d_20[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 192)          0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           3088        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,560\n",
      "Trainable params: 44,560\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 443us/sample - loss: 0.7279 - acc: 0.7836\n",
      "Loss: 0.7278818261710035 Accuracy: 0.78359294\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 16000, 64)    384         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16000, 64)    0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 5333, 64)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5333, 64)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1777, 64)     0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1777, 64)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 592, 64)      0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 592, 64)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 197, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 64)           0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 64)           0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 64)           0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 192)          0           global_average_pooling1d_21[0][0]\n",
      "                                                                 global_average_pooling1d_22[0][0]\n",
      "                                                                 global_average_pooling1d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 192)          0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           3088        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 65,104\n",
      "Trainable params: 65,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 481us/sample - loss: 0.4678 - acc: 0.8687\n",
      "Loss: 0.4678284607572348 Accuracy: 0.86874354\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 16000, 64)    384         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16000, 64)    0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 5333, 64)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5333, 64)     0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1777, 64)     0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1777, 64)     0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 592, 64)      0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 592, 64)      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 197, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 197, 128)     0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 65, 128)      0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 64)           0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 64)           0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_26 (Gl (None, 128)          0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 256)          0           global_average_pooling1d_24[0][0]\n",
      "                                                                 global_average_pooling1d_25[0][0]\n",
      "                                                                 global_average_pooling1d_26[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 256)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           4112        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 107,216\n",
      "Trainable params: 107,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 477us/sample - loss: 0.2665 - acc: 0.9211\n",
      "Loss: 0.2664700121027906 Accuracy: 0.92107993\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 16000, 64)    384         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16000, 64)    0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 5333, 64)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5333, 64)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1777, 64)     0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1777, 64)     0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 592, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 592, 64)      0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 197, 64)      0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 197, 128)     0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 65, 128)      0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 65, 128)      0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 21, 128)      0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_27 (Gl (None, 64)           0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_28 (Gl (None, 128)          0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_29 (Gl (None, 128)          0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 320)          0           global_average_pooling1d_27[0][0]\n",
      "                                                                 global_average_pooling1d_28[0][0]\n",
      "                                                                 global_average_pooling1d_29[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 320)          0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           5136        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 190,288\n",
      "Trainable params: 190,288\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 520us/sample - loss: 0.1991 - acc: 0.9477\n",
      "Loss: 0.19911163761623799 Accuracy: 0.94766355\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 16000, 64)    384         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16000, 64)    0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 5333, 64)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5333, 64)     0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 1777, 64)     0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1777, 64)     0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 592, 64)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 592, 64)      0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 197, 64)      0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 197, 128)     0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 65, 128)      0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 65, 128)      0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 21, 128)      0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 21, 128)      82048       max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 21, 128)      0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 7, 128)       0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_30 (Gl (None, 128)          0           max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_31 (Gl (None, 128)          0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_32 (Gl (None, 128)          0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 384)          0           global_average_pooling1d_30[0][0]\n",
      "                                                                 global_average_pooling1d_31[0][0]\n",
      "                                                                 global_average_pooling1d_32[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 384)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           6160        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 273,360\n",
      "Trainable params: 273,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 577us/sample - loss: 0.2103 - acc: 0.9479\n",
      "Loss: 0.21034224205287724 Accuracy: 0.9478712\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 16000, 64)    384         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16000, 64)    0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 5333, 64)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5333, 64)     0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 1777, 64)     0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1777, 64)     0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 592, 64)      0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 592, 64)      0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 197, 64)      0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 197, 128)     0           conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 65, 128)      0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 65, 128)      0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 21, 128)      0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 21, 128)      82048       max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 21, 128)      0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 7, 128)       0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 7, 128)       82048       max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 128)       0           conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 2, 128)       0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_33 (Gl (None, 128)          0           max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_34 (Gl (None, 128)          0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_35 (Gl (None, 128)          0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 384)          0           global_average_pooling1d_33[0][0]\n",
      "                                                                 global_average_pooling1d_34[0][0]\n",
      "                                                                 global_average_pooling1d_35[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 384)          0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           6160        dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 355,408\n",
      "Trainable params: 355,408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 568us/sample - loss: 0.3125 - acc: 0.9472\n",
      "Loss: 0.3124849086933695 Accuracy: 0.94724816\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
