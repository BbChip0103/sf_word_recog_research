{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, \\\n",
    "                                    Flatten, Conv1D, MaxPooling1D, Dropout, \\\n",
    "                                    Concatenate, GlobalMaxPool1D, GlobalAvgPool1D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(conv_num=1):\n",
    "    filter_size = 32\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    layer_outputs = []\n",
    "    for i in range(conv_num):\n",
    "        x = Conv1D (kernel_size=5, filters=filter_size*(2**(i//4)), \n",
    "                          strides=1, padding='same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling1D(pool_size=3, strides=3)(x)\n",
    "        layer_outputs.append(x)    \n",
    "    \n",
    "    x = Concatenate()([GlobalMaxPool1D()(output) for output in layer_outputs[-3:]])\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 16000, 32)    192         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16000, 32)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 5333, 32)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 5333, 32)     5152        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5333, 32)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1777, 32)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1777, 32)     5152        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1777, 32)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 592, 32)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 32)           0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 32)           0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 32)           0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96)           0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 96)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           1552        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,048\n",
      "Trainable params: 12,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 16000, 32)    192         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16000, 32)    0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 5333, 32)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 5333, 32)     5152        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 5333, 32)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1777, 32)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1777, 32)     5152        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1777, 32)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 592, 32)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 592, 32)      5152        max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 592, 32)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 197, 32)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 32)           0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 32)           0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 32)           0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96)           0           global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 96)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           1552        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,200\n",
      "Trainable params: 17,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 16000, 32)    192         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16000, 32)    0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 5333, 32)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 5333, 32)     5152        max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5333, 32)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1777, 32)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1777, 32)     5152        max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1777, 32)     0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 592, 32)      0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 592, 32)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 197, 32)      0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 197, 64)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 65, 64)       0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 32)           0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 32)           0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 64)           0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128)          0           global_max_pooling1d_6[0][0]     \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           2064        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,016\n",
      "Trainable params: 28,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 16000, 32)    192         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16000, 32)    0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 5333, 32)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5333, 32)     0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1777, 32)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1777, 32)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 592, 32)      0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 592, 32)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 197, 32)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 197, 64)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 65, 64)       0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 65, 64)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 21, 64)       0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 32)           0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 64)           0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 64)           0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 160)          0           global_max_pooling1d_9[0][0]     \n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 160)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           2576        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 49,072\n",
      "Trainable params: 49,072\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 16000, 32)    192         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16000, 32)    0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 5333, 32)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 5333, 32)     0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1777, 32)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1777, 32)     0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 592, 32)      0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 592, 32)      0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 197, 32)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 197, 64)      0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 65, 64)       0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 65, 64)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 21, 64)       0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 21, 64)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 7, 64)        0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 64)           0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 64)           0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 64)           0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 192)          0           global_max_pooling1d_12[0][0]    \n",
      "                                                                 global_max_pooling1d_13[0][0]    \n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 192)          0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           3088        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 70,128\n",
      "Trainable params: 70,128\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 16000, 32)    192         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16000, 32)    0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 5333, 32)     0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 5333, 32)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1777, 32)     0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1777, 32)     0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 592, 32)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 592, 32)      0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 197, 32)      0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 197, 64)      0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 65, 64)       0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 65, 64)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 21, 64)       0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 21, 64)       0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 7, 64)        0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 7, 64)        20544       max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 64)        0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 2, 64)        0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (Global (None, 64)           0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_16 (Global (None, 64)           0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_17 (Global (None, 64)           0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 192)          0           global_max_pooling1d_15[0][0]    \n",
      "                                                                 global_max_pooling1d_16[0][0]    \n",
      "                                                                 global_max_pooling1d_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 192)          0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           3088        dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 90,672\n",
      "Trainable params: 90,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 9):\n",
    "    model = build_cnn(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7241 - acc: 0.0946\n",
      "Epoch 00001: val_loss improved from inf to 2.62484, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/001-2.6248.hdf5\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 2.7241 - acc: 0.0946 - val_loss: 2.6248 - val_acc: 0.2020\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.5582 - acc: 0.1571\n",
      "Epoch 00002: val_loss improved from 2.62484 to 2.37893, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/002-2.3789.hdf5\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 2.5580 - acc: 0.1573 - val_loss: 2.3789 - val_acc: 0.2826\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3976 - acc: 0.1975\n",
      "Epoch 00003: val_loss improved from 2.37893 to 2.21924, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/003-2.2192.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 2.3976 - acc: 0.1975 - val_loss: 2.2192 - val_acc: 0.3103\n",
      "Epoch 4/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.3023 - acc: 0.2234\n",
      "Epoch 00004: val_loss improved from 2.21924 to 2.11848, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/004-2.1185.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 2.3022 - acc: 0.2233 - val_loss: 2.1185 - val_acc: 0.3394\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.2337 - acc: 0.2442\n",
      "Epoch 00005: val_loss improved from 2.11848 to 2.04275, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/005-2.0428.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 2.2335 - acc: 0.2441 - val_loss: 2.0428 - val_acc: 0.3580\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.1679 - acc: 0.2621\n",
      "Epoch 00006: val_loss improved from 2.04275 to 1.97012, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/006-1.9701.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 2.1680 - acc: 0.2621 - val_loss: 1.9701 - val_acc: 0.3816\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1148 - acc: 0.2815\n",
      "Epoch 00007: val_loss improved from 1.97012 to 1.90514, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/007-1.9051.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 2.1148 - acc: 0.2815 - val_loss: 1.9051 - val_acc: 0.4011\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0771 - acc: 0.2912\n",
      "Epoch 00008: val_loss improved from 1.90514 to 1.84901, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/008-1.8490.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 2.0772 - acc: 0.2912 - val_loss: 1.8490 - val_acc: 0.4253\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0322 - acc: 0.3108\n",
      "Epoch 00009: val_loss improved from 1.84901 to 1.79633, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/009-1.7963.hdf5\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 2.0323 - acc: 0.3108 - val_loss: 1.7963 - val_acc: 0.4444\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.9862 - acc: 0.3247\n",
      "Epoch 00010: val_loss improved from 1.79633 to 1.74356, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/010-1.7436.hdf5\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.9861 - acc: 0.3247 - val_loss: 1.7436 - val_acc: 0.4647\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9509 - acc: 0.3422\n",
      "Epoch 00011: val_loss improved from 1.74356 to 1.69748, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/011-1.6975.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 1.9509 - acc: 0.3422 - val_loss: 1.6975 - val_acc: 0.4773\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.9105 - acc: 0.3534\n",
      "Epoch 00012: val_loss improved from 1.69748 to 1.65379, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/012-1.6538.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.9104 - acc: 0.3535 - val_loss: 1.6538 - val_acc: 0.4915\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8837 - acc: 0.3646\n",
      "Epoch 00013: val_loss improved from 1.65379 to 1.61648, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/013-1.6165.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.8837 - acc: 0.3646 - val_loss: 1.6165 - val_acc: 0.5052\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8489 - acc: 0.3765\n",
      "Epoch 00014: val_loss improved from 1.61648 to 1.58159, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/014-1.5816.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.8488 - acc: 0.3765 - val_loss: 1.5816 - val_acc: 0.5215\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8135 - acc: 0.3910\n",
      "Epoch 00015: val_loss improved from 1.58159 to 1.53818, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/015-1.5382.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.8133 - acc: 0.3910 - val_loss: 1.5382 - val_acc: 0.5283\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7889 - acc: 0.3979\n",
      "Epoch 00016: val_loss improved from 1.53818 to 1.50665, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/016-1.5066.hdf5\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.7890 - acc: 0.3979 - val_loss: 1.5066 - val_acc: 0.5441\n",
      "Epoch 17/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7584 - acc: 0.4099\n",
      "Epoch 00017: val_loss improved from 1.50665 to 1.47145, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/017-1.4714.hdf5\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.7584 - acc: 0.4098 - val_loss: 1.4714 - val_acc: 0.5597\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7396 - acc: 0.4187\n",
      "Epoch 00018: val_loss improved from 1.47145 to 1.45582, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/018-1.4558.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.7394 - acc: 0.4188 - val_loss: 1.4558 - val_acc: 0.5656\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7153 - acc: 0.4262\n",
      "Epoch 00019: val_loss improved from 1.45582 to 1.43081, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/019-1.4308.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.7152 - acc: 0.4261 - val_loss: 1.4308 - val_acc: 0.5761\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6940 - acc: 0.4340\n",
      "Epoch 00020: val_loss improved from 1.43081 to 1.40201, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/020-1.4020.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.6941 - acc: 0.4340 - val_loss: 1.4020 - val_acc: 0.5779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6744 - acc: 0.4385\n",
      "Epoch 00021: val_loss improved from 1.40201 to 1.37769, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/021-1.3777.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.6744 - acc: 0.4385 - val_loss: 1.3777 - val_acc: 0.5877\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6582 - acc: 0.4497\n",
      "Epoch 00022: val_loss improved from 1.37769 to 1.35210, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/022-1.3521.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.6583 - acc: 0.4497 - val_loss: 1.3521 - val_acc: 0.5898\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6380 - acc: 0.4552\n",
      "Epoch 00023: val_loss improved from 1.35210 to 1.34376, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/023-1.3438.hdf5\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.6380 - acc: 0.4552 - val_loss: 1.3438 - val_acc: 0.5907\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6218 - acc: 0.4604\n",
      "Epoch 00024: val_loss improved from 1.34376 to 1.31439, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/024-1.3144.hdf5\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.6217 - acc: 0.4604 - val_loss: 1.3144 - val_acc: 0.6035\n",
      "Epoch 25/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6124 - acc: 0.4628\n",
      "Epoch 00025: val_loss improved from 1.31439 to 1.29654, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/025-1.2965.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.6124 - acc: 0.4629 - val_loss: 1.2965 - val_acc: 0.6077\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5943 - acc: 0.4696\n",
      "Epoch 00026: val_loss improved from 1.29654 to 1.28076, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/026-1.2808.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.5942 - acc: 0.4697 - val_loss: 1.2808 - val_acc: 0.6105\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5867 - acc: 0.4746\n",
      "Epoch 00027: val_loss improved from 1.28076 to 1.26861, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/027-1.2686.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.5867 - acc: 0.4746 - val_loss: 1.2686 - val_acc: 0.6164\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5670 - acc: 0.4774\n",
      "Epoch 00028: val_loss improved from 1.26861 to 1.24996, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/028-1.2500.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.5669 - acc: 0.4775 - val_loss: 1.2500 - val_acc: 0.6189\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5562 - acc: 0.4809\n",
      "Epoch 00029: val_loss improved from 1.24996 to 1.23190, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/029-1.2319.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.5561 - acc: 0.4810 - val_loss: 1.2319 - val_acc: 0.6212\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5535 - acc: 0.4879\n",
      "Epoch 00030: val_loss improved from 1.23190 to 1.22175, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/030-1.2218.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.5539 - acc: 0.4877 - val_loss: 1.2218 - val_acc: 0.6292\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5260 - acc: 0.4987\n",
      "Epoch 00031: val_loss improved from 1.22175 to 1.21015, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/031-1.2101.hdf5\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 1.5259 - acc: 0.4988 - val_loss: 1.2101 - val_acc: 0.6301\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5214 - acc: 0.4965\n",
      "Epoch 00032: val_loss improved from 1.21015 to 1.19455, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/032-1.1946.hdf5\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 1.5214 - acc: 0.4965 - val_loss: 1.1946 - val_acc: 0.6366\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5115 - acc: 0.5012\n",
      "Epoch 00033: val_loss improved from 1.19455 to 1.18262, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/033-1.1826.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.5114 - acc: 0.5012 - val_loss: 1.1826 - val_acc: 0.6403\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5042 - acc: 0.5025\n",
      "Epoch 00034: val_loss did not improve from 1.18262\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.5042 - acc: 0.5024 - val_loss: 1.1831 - val_acc: 0.6359\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4838 - acc: 0.5096\n",
      "Epoch 00035: val_loss improved from 1.18262 to 1.16880, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/035-1.1688.hdf5\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.4837 - acc: 0.5096 - val_loss: 1.1688 - val_acc: 0.6469\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4748 - acc: 0.5118\n",
      "Epoch 00036: val_loss improved from 1.16880 to 1.15292, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/036-1.1529.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.4748 - acc: 0.5118 - val_loss: 1.1529 - val_acc: 0.6525\n",
      "Epoch 37/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4762 - acc: 0.5087\n",
      "Epoch 00037: val_loss improved from 1.15292 to 1.15201, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/037-1.1520.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.4763 - acc: 0.5086 - val_loss: 1.1520 - val_acc: 0.6529\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4657 - acc: 0.5189\n",
      "Epoch 00038: val_loss improved from 1.15201 to 1.13723, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/038-1.1372.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.4658 - acc: 0.5188 - val_loss: 1.1372 - val_acc: 0.6585\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4574 - acc: 0.5218\n",
      "Epoch 00039: val_loss improved from 1.13723 to 1.12796, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/039-1.1280.hdf5\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 1.4574 - acc: 0.5217 - val_loss: 1.1280 - val_acc: 0.6594\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4521 - acc: 0.5225\n",
      "Epoch 00040: val_loss improved from 1.12796 to 1.11962, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/040-1.1196.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.4520 - acc: 0.5225 - val_loss: 1.1196 - val_acc: 0.6629\n",
      "Epoch 41/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4483 - acc: 0.5250\n",
      "Epoch 00041: val_loss improved from 1.11962 to 1.11209, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/041-1.1121.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.4483 - acc: 0.5251 - val_loss: 1.1121 - val_acc: 0.6618\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4435 - acc: 0.5268\n",
      "Epoch 00042: val_loss improved from 1.11209 to 1.10279, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/042-1.1028.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.4434 - acc: 0.5268 - val_loss: 1.1028 - val_acc: 0.6660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4284 - acc: 0.5324\n",
      "Epoch 00043: val_loss improved from 1.10279 to 1.09408, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/043-1.0941.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.4283 - acc: 0.5324 - val_loss: 1.0941 - val_acc: 0.6699\n",
      "Epoch 44/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4329 - acc: 0.5322\n",
      "Epoch 00044: val_loss improved from 1.09408 to 1.08849, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/044-1.0885.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.4332 - acc: 0.5322 - val_loss: 1.0885 - val_acc: 0.6711\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4194 - acc: 0.5358\n",
      "Epoch 00045: val_loss improved from 1.08849 to 1.07681, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/045-1.0768.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.4195 - acc: 0.5357 - val_loss: 1.0768 - val_acc: 0.6748\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4190 - acc: 0.5357\n",
      "Epoch 00046: val_loss improved from 1.07681 to 1.07055, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/046-1.0705.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.4188 - acc: 0.5357 - val_loss: 1.0705 - val_acc: 0.6765\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4080 - acc: 0.5401\n",
      "Epoch 00047: val_loss improved from 1.07055 to 1.06857, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/047-1.0686.hdf5\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.4081 - acc: 0.5401 - val_loss: 1.0686 - val_acc: 0.6739\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4020 - acc: 0.5397\n",
      "Epoch 00048: val_loss improved from 1.06857 to 1.06001, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/048-1.0600.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.4020 - acc: 0.5397 - val_loss: 1.0600 - val_acc: 0.6790\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3907 - acc: 0.5456\n",
      "Epoch 00049: val_loss improved from 1.06001 to 1.04828, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/049-1.0483.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.3907 - acc: 0.5456 - val_loss: 1.0483 - val_acc: 0.6816\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3987 - acc: 0.5452\n",
      "Epoch 00050: val_loss improved from 1.04828 to 1.04395, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/050-1.0439.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.3986 - acc: 0.5452 - val_loss: 1.0439 - val_acc: 0.6862\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3862 - acc: 0.5472\n",
      "Epoch 00051: val_loss did not improve from 1.04395\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.3864 - acc: 0.5472 - val_loss: 1.0505 - val_acc: 0.6811\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3895 - acc: 0.5453\n",
      "Epoch 00052: val_loss improved from 1.04395 to 1.03786, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/052-1.0379.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.3894 - acc: 0.5453 - val_loss: 1.0379 - val_acc: 0.6900\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3795 - acc: 0.5480\n",
      "Epoch 00053: val_loss improved from 1.03786 to 1.03150, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/053-1.0315.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.3794 - acc: 0.5481 - val_loss: 1.0315 - val_acc: 0.6881\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3769 - acc: 0.5507\n",
      "Epoch 00054: val_loss did not improve from 1.03150\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.3770 - acc: 0.5507 - val_loss: 1.0376 - val_acc: 0.6855\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3726 - acc: 0.5549\n",
      "Epoch 00055: val_loss improved from 1.03150 to 1.02487, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/055-1.0249.hdf5\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 1.3726 - acc: 0.5549 - val_loss: 1.0249 - val_acc: 0.6881\n",
      "Epoch 56/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3621 - acc: 0.5559\n",
      "Epoch 00056: val_loss improved from 1.02487 to 1.01219, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/056-1.0122.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.3620 - acc: 0.5560 - val_loss: 1.0122 - val_acc: 0.6974\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3612 - acc: 0.5560\n",
      "Epoch 00057: val_loss did not improve from 1.01219\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.3613 - acc: 0.5560 - val_loss: 1.0159 - val_acc: 0.6981\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3634 - acc: 0.5557\n",
      "Epoch 00058: val_loss improved from 1.01219 to 1.00570, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/058-1.0057.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.3635 - acc: 0.5557 - val_loss: 1.0057 - val_acc: 0.6995\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3560 - acc: 0.5579\n",
      "Epoch 00059: val_loss did not improve from 1.00570\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.3560 - acc: 0.5578 - val_loss: 1.0073 - val_acc: 0.6969\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3512 - acc: 0.5596\n",
      "Epoch 00060: val_loss did not improve from 1.00570\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.3512 - acc: 0.5596 - val_loss: 1.0060 - val_acc: 0.7000\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3438 - acc: 0.5626\n",
      "Epoch 00061: val_loss improved from 1.00570 to 0.98625, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/061-0.9862.hdf5\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.3437 - acc: 0.5627 - val_loss: 0.9862 - val_acc: 0.7028\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3421 - acc: 0.5639\n",
      "Epoch 00062: val_loss did not improve from 0.98625\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.3421 - acc: 0.5639 - val_loss: 0.9925 - val_acc: 0.7014\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3454 - acc: 0.5613\n",
      "Epoch 00063: val_loss did not improve from 0.98625\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.3454 - acc: 0.5612 - val_loss: 0.9880 - val_acc: 0.7032\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3298 - acc: 0.5700\n",
      "Epoch 00064: val_loss improved from 0.98625 to 0.98421, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/064-0.9842.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.3299 - acc: 0.5699 - val_loss: 0.9842 - val_acc: 0.7032\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3322 - acc: 0.5678\n",
      "Epoch 00065: val_loss improved from 0.98421 to 0.97401, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/065-0.9740.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.3323 - acc: 0.5677 - val_loss: 0.9740 - val_acc: 0.7100\n",
      "Epoch 66/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3315 - acc: 0.5675\n",
      "Epoch 00066: val_loss improved from 0.97401 to 0.97339, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/066-0.9734.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.3314 - acc: 0.5675 - val_loss: 0.9734 - val_acc: 0.7088\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3203 - acc: 0.5702\n",
      "Epoch 00067: val_loss improved from 0.97339 to 0.96545, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/067-0.9654.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.3203 - acc: 0.5702 - val_loss: 0.9654 - val_acc: 0.7102\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3263 - acc: 0.5686\n",
      "Epoch 00068: val_loss did not improve from 0.96545\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.3263 - acc: 0.5685 - val_loss: 0.9670 - val_acc: 0.7116\n",
      "Epoch 69/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3209 - acc: 0.5732\n",
      "Epoch 00069: val_loss improved from 0.96545 to 0.96228, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/069-0.9623.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.3211 - acc: 0.5732 - val_loss: 0.9623 - val_acc: 0.7126\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3165 - acc: 0.5730\n",
      "Epoch 00070: val_loss improved from 0.96228 to 0.96053, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/070-0.9605.hdf5\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 1.3165 - acc: 0.5730 - val_loss: 0.9605 - val_acc: 0.7147\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3109 - acc: 0.5737\n",
      "Epoch 00071: val_loss improved from 0.96053 to 0.95918, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/071-0.9592.hdf5\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 1.3109 - acc: 0.5737 - val_loss: 0.9592 - val_acc: 0.7147\n",
      "Epoch 72/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3096 - acc: 0.5740\n",
      "Epoch 00072: val_loss improved from 0.95918 to 0.95378, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/072-0.9538.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.3096 - acc: 0.5740 - val_loss: 0.9538 - val_acc: 0.7179\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3080 - acc: 0.5720\n",
      "Epoch 00073: val_loss improved from 0.95378 to 0.94683, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/073-0.9468.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.3079 - acc: 0.5720 - val_loss: 0.9468 - val_acc: 0.7147\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3044 - acc: 0.5757\n",
      "Epoch 00074: val_loss did not improve from 0.94683\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.3043 - acc: 0.5757 - val_loss: 0.9473 - val_acc: 0.7158\n",
      "Epoch 75/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3054 - acc: 0.5745\n",
      "Epoch 00075: val_loss did not improve from 0.94683\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.3055 - acc: 0.5744 - val_loss: 0.9481 - val_acc: 0.7174\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3067 - acc: 0.5776\n",
      "Epoch 00076: val_loss did not improve from 0.94683\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.3067 - acc: 0.5776 - val_loss: 0.9470 - val_acc: 0.7184\n",
      "Epoch 77/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2972 - acc: 0.5761\n",
      "Epoch 00077: val_loss improved from 0.94683 to 0.94667, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/077-0.9467.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2974 - acc: 0.5761 - val_loss: 0.9467 - val_acc: 0.7191\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2995 - acc: 0.5783\n",
      "Epoch 00078: val_loss did not improve from 0.94667\n",
      "36805/36805 [==============================] - 23s 611us/sample - loss: 1.2994 - acc: 0.5783 - val_loss: 0.9477 - val_acc: 0.7207\n",
      "Epoch 79/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2981 - acc: 0.5818\n",
      "Epoch 00079: val_loss improved from 0.94667 to 0.94220, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/079-0.9422.hdf5\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 1.2980 - acc: 0.5819 - val_loss: 0.9422 - val_acc: 0.7242\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2932 - acc: 0.5800\n",
      "Epoch 00080: val_loss improved from 0.94220 to 0.92467, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/080-0.9247.hdf5\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 1.2932 - acc: 0.5800 - val_loss: 0.9247 - val_acc: 0.7216\n",
      "Epoch 81/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2859 - acc: 0.5823\n",
      "Epoch 00081: val_loss did not improve from 0.92467\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.2857 - acc: 0.5825 - val_loss: 0.9343 - val_acc: 0.7233\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2920 - acc: 0.5767\n",
      "Epoch 00082: val_loss did not improve from 0.92467\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.2921 - acc: 0.5767 - val_loss: 0.9355 - val_acc: 0.7202\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2961 - acc: 0.5771\n",
      "Epoch 00083: val_loss improved from 0.92467 to 0.92364, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/083-0.9236.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.2961 - acc: 0.5771 - val_loss: 0.9236 - val_acc: 0.7249\n",
      "Epoch 84/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2921 - acc: 0.5756\n",
      "Epoch 00084: val_loss did not improve from 0.92364\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2919 - acc: 0.5756 - val_loss: 0.9301 - val_acc: 0.7249\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2794 - acc: 0.5846\n",
      "Epoch 00085: val_loss did not improve from 0.92364\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2795 - acc: 0.5846 - val_loss: 0.9256 - val_acc: 0.7249\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2839 - acc: 0.5800\n",
      "Epoch 00086: val_loss improved from 0.92364 to 0.92049, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/086-0.9205.hdf5\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 1.2838 - acc: 0.5800 - val_loss: 0.9205 - val_acc: 0.7258\n",
      "Epoch 87/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2793 - acc: 0.5845\n",
      "Epoch 00087: val_loss did not improve from 0.92049\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2796 - acc: 0.5843 - val_loss: 0.9277 - val_acc: 0.7261\n",
      "Epoch 88/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2807 - acc: 0.5841\n",
      "Epoch 00088: val_loss did not improve from 0.92049\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2805 - acc: 0.5843 - val_loss: 0.9322 - val_acc: 0.7261\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2862 - acc: 0.5792\n",
      "Epoch 00089: val_loss did not improve from 0.92049\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2862 - acc: 0.5793 - val_loss: 0.9222 - val_acc: 0.7282\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2770 - acc: 0.5854\n",
      "Epoch 00090: val_loss improved from 0.92049 to 0.91494, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/090-0.9149.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.2769 - acc: 0.5854 - val_loss: 0.9149 - val_acc: 0.7314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2671 - acc: 0.5876\n",
      "Epoch 00091: val_loss did not improve from 0.91494\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.2673 - acc: 0.5875 - val_loss: 0.9253 - val_acc: 0.7270\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2713 - acc: 0.5876\n",
      "Epoch 00092: val_loss improved from 0.91494 to 0.91052, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/092-0.9105.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2714 - acc: 0.5875 - val_loss: 0.9105 - val_acc: 0.7303\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2712 - acc: 0.5871\n",
      "Epoch 00093: val_loss improved from 0.91052 to 0.90419, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/093-0.9042.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2713 - acc: 0.5871 - val_loss: 0.9042 - val_acc: 0.7354\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2640 - acc: 0.5878\n",
      "Epoch 00094: val_loss improved from 0.90419 to 0.90148, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/094-0.9015.hdf5\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 1.2641 - acc: 0.5878 - val_loss: 0.9015 - val_acc: 0.7345\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2623 - acc: 0.5924\n",
      "Epoch 00095: val_loss did not improve from 0.90148\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2623 - acc: 0.5924 - val_loss: 0.9074 - val_acc: 0.7305\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2661 - acc: 0.5851\n",
      "Epoch 00096: val_loss did not improve from 0.90148\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2660 - acc: 0.5852 - val_loss: 0.9075 - val_acc: 0.7352\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2690 - acc: 0.5883\n",
      "Epoch 00097: val_loss improved from 0.90148 to 0.90101, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/097-0.9010.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.2690 - acc: 0.5883 - val_loss: 0.9010 - val_acc: 0.7363\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2602 - acc: 0.5917\n",
      "Epoch 00098: val_loss improved from 0.90101 to 0.89481, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/098-0.8948.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2602 - acc: 0.5917 - val_loss: 0.8948 - val_acc: 0.7321\n",
      "Epoch 99/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2592 - acc: 0.5931\n",
      "Epoch 00099: val_loss did not improve from 0.89481\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2592 - acc: 0.5931 - val_loss: 0.9049 - val_acc: 0.7347\n",
      "Epoch 100/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2597 - acc: 0.5879\n",
      "Epoch 00100: val_loss improved from 0.89481 to 0.89164, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/100-0.8916.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.2595 - acc: 0.5880 - val_loss: 0.8916 - val_acc: 0.7368\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2577 - acc: 0.5886\n",
      "Epoch 00101: val_loss did not improve from 0.89164\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 1.2578 - acc: 0.5886 - val_loss: 0.9018 - val_acc: 0.7319\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2602 - acc: 0.5903\n",
      "Epoch 00102: val_loss did not improve from 0.89164\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 1.2603 - acc: 0.5903 - val_loss: 0.8928 - val_acc: 0.7328\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2519 - acc: 0.5925\n",
      "Epoch 00103: val_loss improved from 0.89164 to 0.88966, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/103-0.8897.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.2519 - acc: 0.5925 - val_loss: 0.8897 - val_acc: 0.7349\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2582 - acc: 0.5921\n",
      "Epoch 00104: val_loss improved from 0.88966 to 0.88917, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/104-0.8892.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.2582 - acc: 0.5922 - val_loss: 0.8892 - val_acc: 0.7349\n",
      "Epoch 105/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2513 - acc: 0.5910\n",
      "Epoch 00105: val_loss improved from 0.88917 to 0.88749, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/105-0.8875.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2511 - acc: 0.5909 - val_loss: 0.8875 - val_acc: 0.7361\n",
      "Epoch 106/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2491 - acc: 0.5928\n",
      "Epoch 00106: val_loss improved from 0.88749 to 0.88246, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/106-0.8825.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2492 - acc: 0.5928 - val_loss: 0.8825 - val_acc: 0.7405\n",
      "Epoch 107/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2454 - acc: 0.5940\n",
      "Epoch 00107: val_loss did not improve from 0.88246\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2455 - acc: 0.5940 - val_loss: 0.8872 - val_acc: 0.7386\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2459 - acc: 0.5969\n",
      "Epoch 00108: val_loss improved from 0.88246 to 0.87666, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/108-0.8767.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.2458 - acc: 0.5969 - val_loss: 0.8767 - val_acc: 0.7426\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2455 - acc: 0.5982\n",
      "Epoch 00109: val_loss did not improve from 0.87666\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 1.2456 - acc: 0.5982 - val_loss: 0.8844 - val_acc: 0.7372\n",
      "Epoch 110/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2456 - acc: 0.5967\n",
      "Epoch 00110: val_loss did not improve from 0.87666\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.2458 - acc: 0.5966 - val_loss: 0.8794 - val_acc: 0.7421\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2413 - acc: 0.5940\n",
      "Epoch 00111: val_loss improved from 0.87666 to 0.87326, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/111-0.8733.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2413 - acc: 0.5939 - val_loss: 0.8733 - val_acc: 0.7417\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2411 - acc: 0.5993\n",
      "Epoch 00112: val_loss did not improve from 0.87326\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2411 - acc: 0.5993 - val_loss: 0.8764 - val_acc: 0.7424\n",
      "Epoch 113/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2407 - acc: 0.5958\n",
      "Epoch 00113: val_loss did not improve from 0.87326\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2405 - acc: 0.5959 - val_loss: 0.8739 - val_acc: 0.7435\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2390 - acc: 0.5952\n",
      "Epoch 00114: val_loss did not improve from 0.87326\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.2389 - acc: 0.5952 - val_loss: 0.8733 - val_acc: 0.7435\n",
      "Epoch 115/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2382 - acc: 0.5991\n",
      "Epoch 00115: val_loss improved from 0.87326 to 0.87319, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/115-0.8732.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2383 - acc: 0.5992 - val_loss: 0.8732 - val_acc: 0.7454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2348 - acc: 0.5997\n",
      "Epoch 00116: val_loss improved from 0.87319 to 0.87161, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/116-0.8716.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2347 - acc: 0.5997 - val_loss: 0.8716 - val_acc: 0.7438\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2309 - acc: 0.6003\n",
      "Epoch 00117: val_loss did not improve from 0.87161\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.2310 - acc: 0.6002 - val_loss: 0.8757 - val_acc: 0.7412\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2364 - acc: 0.5999\n",
      "Epoch 00118: val_loss did not improve from 0.87161\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2363 - acc: 0.5999 - val_loss: 0.8741 - val_acc: 0.7428\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2349 - acc: 0.6007\n",
      "Epoch 00119: val_loss improved from 0.87161 to 0.86399, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/119-0.8640.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.2349 - acc: 0.6007 - val_loss: 0.8640 - val_acc: 0.7442\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2345 - acc: 0.6018\n",
      "Epoch 00120: val_loss improved from 0.86399 to 0.85680, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/120-0.8568.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.2344 - acc: 0.6018 - val_loss: 0.8568 - val_acc: 0.7477\n",
      "Epoch 121/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2271 - acc: 0.6007\n",
      "Epoch 00121: val_loss did not improve from 0.85680\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.2268 - acc: 0.6007 - val_loss: 0.8600 - val_acc: 0.7477\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2287 - acc: 0.6010\n",
      "Epoch 00122: val_loss did not improve from 0.85680\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2287 - acc: 0.6010 - val_loss: 0.8598 - val_acc: 0.7466\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2271 - acc: 0.6057\n",
      "Epoch 00123: val_loss did not improve from 0.85680\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2272 - acc: 0.6058 - val_loss: 0.8737 - val_acc: 0.7470\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2340 - acc: 0.5987\n",
      "Epoch 00124: val_loss did not improve from 0.85680\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2340 - acc: 0.5986 - val_loss: 0.8647 - val_acc: 0.7470\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2257 - acc: 0.6043\n",
      "Epoch 00125: val_loss did not improve from 0.85680\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.2256 - acc: 0.6043 - val_loss: 0.8706 - val_acc: 0.7431\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2224 - acc: 0.6048\n",
      "Epoch 00126: val_loss did not improve from 0.85680\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.2224 - acc: 0.6048 - val_loss: 0.8679 - val_acc: 0.7456\n",
      "Epoch 127/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2264 - acc: 0.6041\n",
      "Epoch 00127: val_loss did not improve from 0.85680\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.2266 - acc: 0.6040 - val_loss: 0.8616 - val_acc: 0.7466\n",
      "Epoch 128/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2286 - acc: 0.6030\n",
      "Epoch 00128: val_loss did not improve from 0.85680\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.2287 - acc: 0.6030 - val_loss: 0.8583 - val_acc: 0.7517\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2282 - acc: 0.6014\n",
      "Epoch 00129: val_loss improved from 0.85680 to 0.85420, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/129-0.8542.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2282 - acc: 0.6014 - val_loss: 0.8542 - val_acc: 0.7482\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2215 - acc: 0.6035\n",
      "Epoch 00130: val_loss did not improve from 0.85420\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2214 - acc: 0.6035 - val_loss: 0.8544 - val_acc: 0.7475\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2208 - acc: 0.6001\n",
      "Epoch 00131: val_loss improved from 0.85420 to 0.84782, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/131-0.8478.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2207 - acc: 0.6001 - val_loss: 0.8478 - val_acc: 0.7480\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2254 - acc: 0.6020\n",
      "Epoch 00132: val_loss did not improve from 0.84782\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 1.2257 - acc: 0.6020 - val_loss: 0.8651 - val_acc: 0.7445\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2158 - acc: 0.6061\n",
      "Epoch 00133: val_loss did not improve from 0.84782\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 1.2158 - acc: 0.6061 - val_loss: 0.8510 - val_acc: 0.7496\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2172 - acc: 0.6029\n",
      "Epoch 00134: val_loss did not improve from 0.84782\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2172 - acc: 0.6029 - val_loss: 0.8544 - val_acc: 0.7498\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2216 - acc: 0.6025\n",
      "Epoch 00135: val_loss did not improve from 0.84782\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2216 - acc: 0.6024 - val_loss: 0.8511 - val_acc: 0.7510\n",
      "Epoch 136/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2143 - acc: 0.6089\n",
      "Epoch 00136: val_loss improved from 0.84782 to 0.84303, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/136-0.8430.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.2147 - acc: 0.6087 - val_loss: 0.8430 - val_acc: 0.7522\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2133 - acc: 0.6046\n",
      "Epoch 00137: val_loss did not improve from 0.84303\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2133 - acc: 0.6045 - val_loss: 0.8526 - val_acc: 0.7489\n",
      "Epoch 138/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2154 - acc: 0.6060\n",
      "Epoch 00138: val_loss improved from 0.84303 to 0.84273, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/138-0.8427.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2154 - acc: 0.6058 - val_loss: 0.8427 - val_acc: 0.7498\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2185 - acc: 0.6030\n",
      "Epoch 00139: val_loss did not improve from 0.84273\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2185 - acc: 0.6030 - val_loss: 0.8427 - val_acc: 0.7522\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2191 - acc: 0.6061\n",
      "Epoch 00140: val_loss did not improve from 0.84273\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.2192 - acc: 0.6060 - val_loss: 0.8544 - val_acc: 0.7512\n",
      "Epoch 141/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2060 - acc: 0.6091\n",
      "Epoch 00141: val_loss did not improve from 0.84273\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 1.2055 - acc: 0.6092 - val_loss: 0.8440 - val_acc: 0.7522\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2023 - acc: 0.6104\n",
      "Epoch 00142: val_loss improved from 0.84273 to 0.83698, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/142-0.8370.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2023 - acc: 0.6104 - val_loss: 0.8370 - val_acc: 0.7498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2009 - acc: 0.6127\n",
      "Epoch 00143: val_loss did not improve from 0.83698\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.2008 - acc: 0.6128 - val_loss: 0.8396 - val_acc: 0.7531\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2023 - acc: 0.6121\n",
      "Epoch 00144: val_loss did not improve from 0.83698\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2023 - acc: 0.6121 - val_loss: 0.8461 - val_acc: 0.7522\n",
      "Epoch 145/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2102 - acc: 0.6079\n",
      "Epoch 00145: val_loss did not improve from 0.83698\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.2104 - acc: 0.6079 - val_loss: 0.8619 - val_acc: 0.7494\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2131 - acc: 0.6086\n",
      "Epoch 00146: val_loss did not improve from 0.83698\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2130 - acc: 0.6086 - val_loss: 0.8431 - val_acc: 0.7482\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2112 - acc: 0.6057\n",
      "Epoch 00147: val_loss did not improve from 0.83698\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.2112 - acc: 0.6057 - val_loss: 0.8556 - val_acc: 0.7529\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2010 - acc: 0.6100\n",
      "Epoch 00148: val_loss improved from 0.83698 to 0.83370, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/148-0.8337.hdf5\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 1.2009 - acc: 0.6100 - val_loss: 0.8337 - val_acc: 0.7510\n",
      "Epoch 149/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2036 - acc: 0.6085\n",
      "Epoch 00149: val_loss did not improve from 0.83370\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 1.2034 - acc: 0.6084 - val_loss: 0.8361 - val_acc: 0.7533\n",
      "Epoch 150/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2062 - acc: 0.6097\n",
      "Epoch 00150: val_loss did not improve from 0.83370\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2063 - acc: 0.6096 - val_loss: 0.8431 - val_acc: 0.7573\n",
      "Epoch 151/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2056 - acc: 0.6094\n",
      "Epoch 00151: val_loss did not improve from 0.83370\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.2060 - acc: 0.6093 - val_loss: 0.8380 - val_acc: 0.7543\n",
      "Epoch 152/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2097 - acc: 0.6080\n",
      "Epoch 00152: val_loss did not improve from 0.83370\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2093 - acc: 0.6081 - val_loss: 0.8382 - val_acc: 0.7563\n",
      "Epoch 153/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2025 - acc: 0.6108\n",
      "Epoch 00153: val_loss improved from 0.83370 to 0.83347, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/153-0.8335.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2024 - acc: 0.6109 - val_loss: 0.8335 - val_acc: 0.7491\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1985 - acc: 0.6129\n",
      "Epoch 00154: val_loss improved from 0.83347 to 0.83331, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/154-0.8333.hdf5\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.1985 - acc: 0.6129 - val_loss: 0.8333 - val_acc: 0.7538\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2103 - acc: 0.6096\n",
      "Epoch 00155: val_loss did not improve from 0.83331\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 1.2104 - acc: 0.6096 - val_loss: 0.8357 - val_acc: 0.7568\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2039 - acc: 0.6085\n",
      "Epoch 00156: val_loss did not improve from 0.83331\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2038 - acc: 0.6084 - val_loss: 0.8399 - val_acc: 0.7545\n",
      "Epoch 157/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2084 - acc: 0.6087\n",
      "Epoch 00157: val_loss did not improve from 0.83331\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.2085 - acc: 0.6087 - val_loss: 0.8389 - val_acc: 0.7536\n",
      "Epoch 158/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1931 - acc: 0.6125\n",
      "Epoch 00158: val_loss improved from 0.83331 to 0.83120, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/158-0.8312.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1933 - acc: 0.6126 - val_loss: 0.8312 - val_acc: 0.7603\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1943 - acc: 0.6135\n",
      "Epoch 00159: val_loss improved from 0.83120 to 0.82900, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/159-0.8290.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1943 - acc: 0.6135 - val_loss: 0.8290 - val_acc: 0.7603\n",
      "Epoch 160/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1947 - acc: 0.6121\n",
      "Epoch 00160: val_loss improved from 0.82900 to 0.82782, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/160-0.8278.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1945 - acc: 0.6122 - val_loss: 0.8278 - val_acc: 0.7591\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1932 - acc: 0.6132\n",
      "Epoch 00161: val_loss improved from 0.82782 to 0.82408, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/161-0.8241.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1932 - acc: 0.6132 - val_loss: 0.8241 - val_acc: 0.7563\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1961 - acc: 0.6152\n",
      "Epoch 00162: val_loss did not improve from 0.82408\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 1.1960 - acc: 0.6152 - val_loss: 0.8307 - val_acc: 0.7573\n",
      "Epoch 163/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1886 - acc: 0.6137\n",
      "Epoch 00163: val_loss improved from 0.82408 to 0.82387, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/163-0.8239.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1879 - acc: 0.6139 - val_loss: 0.8239 - val_acc: 0.7559\n",
      "Epoch 164/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1889 - acc: 0.6160\n",
      "Epoch 00164: val_loss improved from 0.82387 to 0.82200, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/164-0.8220.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1890 - acc: 0.6160 - val_loss: 0.8220 - val_acc: 0.7615\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1923 - acc: 0.6133\n",
      "Epoch 00165: val_loss did not improve from 0.82200\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1923 - acc: 0.6133 - val_loss: 0.8329 - val_acc: 0.7612\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1899 - acc: 0.6157\n",
      "Epoch 00166: val_loss improved from 0.82200 to 0.81746, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/166-0.8175.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.1899 - acc: 0.6158 - val_loss: 0.8175 - val_acc: 0.7587\n",
      "Epoch 167/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1863 - acc: 0.6183\n",
      "Epoch 00167: val_loss did not improve from 0.81746\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1861 - acc: 0.6184 - val_loss: 0.8310 - val_acc: 0.7566\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1887 - acc: 0.6149\n",
      "Epoch 00168: val_loss did not improve from 0.81746\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1887 - acc: 0.6149 - val_loss: 0.8334 - val_acc: 0.7594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1830 - acc: 0.6168\n",
      "Epoch 00169: val_loss did not improve from 0.81746\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1829 - acc: 0.6169 - val_loss: 0.8175 - val_acc: 0.7605\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1923 - acc: 0.6158\n",
      "Epoch 00170: val_loss did not improve from 0.81746\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.1925 - acc: 0.6157 - val_loss: 0.8257 - val_acc: 0.7543\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1895 - acc: 0.6162\n",
      "Epoch 00171: val_loss did not improve from 0.81746\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1895 - acc: 0.6162 - val_loss: 0.8299 - val_acc: 0.7517\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1861 - acc: 0.6135\n",
      "Epoch 00172: val_loss did not improve from 0.81746\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1860 - acc: 0.6136 - val_loss: 0.8251 - val_acc: 0.7563\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1820 - acc: 0.6182\n",
      "Epoch 00173: val_loss did not improve from 0.81746\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1820 - acc: 0.6183 - val_loss: 0.8186 - val_acc: 0.7638\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1885 - acc: 0.6171\n",
      "Epoch 00174: val_loss improved from 0.81746 to 0.81341, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/174-0.8134.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1886 - acc: 0.6170 - val_loss: 0.8134 - val_acc: 0.7615\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1813 - acc: 0.6190\n",
      "Epoch 00175: val_loss did not improve from 0.81341\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1814 - acc: 0.6189 - val_loss: 0.8152 - val_acc: 0.7603\n",
      "Epoch 176/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1837 - acc: 0.6179\n",
      "Epoch 00176: val_loss did not improve from 0.81341\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1834 - acc: 0.6180 - val_loss: 0.8191 - val_acc: 0.7638\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1847 - acc: 0.6162\n",
      "Epoch 00177: val_loss did not improve from 0.81341\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 1.1846 - acc: 0.6162 - val_loss: 0.8204 - val_acc: 0.7631\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1835 - acc: 0.6174\n",
      "Epoch 00178: val_loss improved from 0.81341 to 0.80834, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/178-0.8083.hdf5\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 1.1836 - acc: 0.6174 - val_loss: 0.8083 - val_acc: 0.7589\n",
      "Epoch 179/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1790 - acc: 0.6184\n",
      "Epoch 00179: val_loss did not improve from 0.80834\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 1.1787 - acc: 0.6184 - val_loss: 0.8139 - val_acc: 0.7582\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1755 - acc: 0.6174\n",
      "Epoch 00180: val_loss did not improve from 0.80834\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1755 - acc: 0.6174 - val_loss: 0.8189 - val_acc: 0.7610\n",
      "Epoch 181/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1817 - acc: 0.6204\n",
      "Epoch 00181: val_loss did not improve from 0.80834\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1816 - acc: 0.6204 - val_loss: 0.8110 - val_acc: 0.7617\n",
      "Epoch 182/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1768 - acc: 0.6213\n",
      "Epoch 00182: val_loss improved from 0.80834 to 0.80660, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/182-0.8066.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1769 - acc: 0.6213 - val_loss: 0.8066 - val_acc: 0.7629\n",
      "Epoch 183/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1801 - acc: 0.6168\n",
      "Epoch 00183: val_loss did not improve from 0.80660\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1801 - acc: 0.6168 - val_loss: 0.8188 - val_acc: 0.7617\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1802 - acc: 0.6168\n",
      "Epoch 00184: val_loss improved from 0.80660 to 0.80385, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/184-0.8039.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1803 - acc: 0.6168 - val_loss: 0.8039 - val_acc: 0.7617\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1696 - acc: 0.6212\n",
      "Epoch 00185: val_loss improved from 0.80385 to 0.80079, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/185-0.8008.hdf5\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 1.1696 - acc: 0.6212 - val_loss: 0.8008 - val_acc: 0.7640\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1738 - acc: 0.6198\n",
      "Epoch 00186: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1738 - acc: 0.6198 - val_loss: 0.8076 - val_acc: 0.7626\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1709 - acc: 0.6200\n",
      "Epoch 00187: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1709 - acc: 0.6200 - val_loss: 0.8165 - val_acc: 0.7601\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1711 - acc: 0.6205\n",
      "Epoch 00188: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1711 - acc: 0.6204 - val_loss: 0.8144 - val_acc: 0.7577\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1723 - acc: 0.6208\n",
      "Epoch 00189: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.1722 - acc: 0.6208 - val_loss: 0.8123 - val_acc: 0.7626\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1733 - acc: 0.6170\n",
      "Epoch 00190: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1732 - acc: 0.6170 - val_loss: 0.8133 - val_acc: 0.7612\n",
      "Epoch 191/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1660 - acc: 0.6214\n",
      "Epoch 00191: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.1658 - acc: 0.6215 - val_loss: 0.8011 - val_acc: 0.7629\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1768 - acc: 0.6180\n",
      "Epoch 00192: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1769 - acc: 0.6180 - val_loss: 0.8105 - val_acc: 0.7610\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1701 - acc: 0.6212\n",
      "Epoch 00193: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 1.1701 - acc: 0.6212 - val_loss: 0.8205 - val_acc: 0.7619\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1743 - acc: 0.6208\n",
      "Epoch 00194: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.1744 - acc: 0.6208 - val_loss: 0.8009 - val_acc: 0.7659\n",
      "Epoch 195/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1656 - acc: 0.6225\n",
      "Epoch 00195: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1662 - acc: 0.6222 - val_loss: 0.8121 - val_acc: 0.7631\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1637 - acc: 0.6226\n",
      "Epoch 00196: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1638 - acc: 0.6226 - val_loss: 0.8045 - val_acc: 0.7631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1699 - acc: 0.6193\n",
      "Epoch 00197: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.1697 - acc: 0.6193 - val_loss: 0.8097 - val_acc: 0.7636\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1638 - acc: 0.6267\n",
      "Epoch 00198: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1639 - acc: 0.6267 - val_loss: 0.8083 - val_acc: 0.7612\n",
      "Epoch 199/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1624 - acc: 0.6251\n",
      "Epoch 00199: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1620 - acc: 0.6251 - val_loss: 0.8081 - val_acc: 0.7652\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1589 - acc: 0.6237\n",
      "Epoch 00200: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1589 - acc: 0.6237 - val_loss: 0.8029 - val_acc: 0.7636\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1690 - acc: 0.6232\n",
      "Epoch 00201: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.1690 - acc: 0.6232 - val_loss: 0.8045 - val_acc: 0.7608\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1612 - acc: 0.6252\n",
      "Epoch 00202: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1611 - acc: 0.6252 - val_loss: 0.8019 - val_acc: 0.7654\n",
      "Epoch 203/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1693 - acc: 0.6227\n",
      "Epoch 00203: val_loss did not improve from 0.80079\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1701 - acc: 0.6226 - val_loss: 0.8061 - val_acc: 0.7619\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1630 - acc: 0.6263\n",
      "Epoch 00204: val_loss improved from 0.80079 to 0.79709, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/204-0.7971.hdf5\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 1.1629 - acc: 0.6263 - val_loss: 0.7971 - val_acc: 0.7640\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1617 - acc: 0.6243\n",
      "Epoch 00205: val_loss improved from 0.79709 to 0.79700, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/205-0.7970.hdf5\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 1.1616 - acc: 0.6244 - val_loss: 0.7970 - val_acc: 0.7638\n",
      "Epoch 206/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1591 - acc: 0.6267\n",
      "Epoch 00206: val_loss did not improve from 0.79700\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1590 - acc: 0.6267 - val_loss: 0.7971 - val_acc: 0.7668\n",
      "Epoch 207/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1554 - acc: 0.6259\n",
      "Epoch 00207: val_loss did not improve from 0.79700\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1554 - acc: 0.6258 - val_loss: 0.8076 - val_acc: 0.7629\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1606 - acc: 0.6248\n",
      "Epoch 00208: val_loss did not improve from 0.79700\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1606 - acc: 0.6248 - val_loss: 0.7996 - val_acc: 0.7584\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1518 - acc: 0.6250\n",
      "Epoch 00209: val_loss improved from 0.79700 to 0.79630, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/209-0.7963.hdf5\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 1.1518 - acc: 0.6250 - val_loss: 0.7963 - val_acc: 0.7633\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1631 - acc: 0.6266\n",
      "Epoch 00210: val_loss improved from 0.79630 to 0.79594, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/210-0.7959.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1632 - acc: 0.6265 - val_loss: 0.7959 - val_acc: 0.7666\n",
      "Epoch 211/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1651 - acc: 0.6242\n",
      "Epoch 00211: val_loss did not improve from 0.79594\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.1646 - acc: 0.6244 - val_loss: 0.8001 - val_acc: 0.7624\n",
      "Epoch 212/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1614 - acc: 0.6256\n",
      "Epoch 00212: val_loss improved from 0.79594 to 0.79024, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/212-0.7902.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1613 - acc: 0.6256 - val_loss: 0.7902 - val_acc: 0.7696\n",
      "Epoch 213/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1577 - acc: 0.6307\n",
      "Epoch 00213: val_loss did not improve from 0.79024\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1580 - acc: 0.6308 - val_loss: 0.7939 - val_acc: 0.7643\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1548 - acc: 0.6262\n",
      "Epoch 00214: val_loss improved from 0.79024 to 0.78606, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/214-0.7861.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1549 - acc: 0.6261 - val_loss: 0.7861 - val_acc: 0.7622\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1636 - acc: 0.6231\n",
      "Epoch 00215: val_loss did not improve from 0.78606\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1636 - acc: 0.6231 - val_loss: 0.7975 - val_acc: 0.7615\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1510 - acc: 0.6266\n",
      "Epoch 00216: val_loss did not improve from 0.78606\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.1510 - acc: 0.6266 - val_loss: 0.7917 - val_acc: 0.7687\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1517 - acc: 0.6273\n",
      "Epoch 00217: val_loss did not improve from 0.78606\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.1517 - acc: 0.6273 - val_loss: 0.7963 - val_acc: 0.7633\n",
      "Epoch 218/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1615 - acc: 0.6247\n",
      "Epoch 00218: val_loss improved from 0.78606 to 0.78305, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/218-0.7831.hdf5\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 1.1611 - acc: 0.6248 - val_loss: 0.7831 - val_acc: 0.7640\n",
      "Epoch 219/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1498 - acc: 0.6273\n",
      "Epoch 00219: val_loss did not improve from 0.78305\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1496 - acc: 0.6272 - val_loss: 0.8014 - val_acc: 0.7668\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1566 - acc: 0.6245\n",
      "Epoch 00220: val_loss did not improve from 0.78305\n",
      "36805/36805 [==============================] - 23s 611us/sample - loss: 1.1567 - acc: 0.6245 - val_loss: 0.8013 - val_acc: 0.7629\n",
      "Epoch 221/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1466 - acc: 0.6290\n",
      "Epoch 00221: val_loss did not improve from 0.78305\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.1468 - acc: 0.6289 - val_loss: 0.7853 - val_acc: 0.7647\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1503 - acc: 0.6295\n",
      "Epoch 00222: val_loss did not improve from 0.78305\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.1502 - acc: 0.6295 - val_loss: 0.7937 - val_acc: 0.7673\n",
      "Epoch 223/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1537 - acc: 0.6274\n",
      "Epoch 00223: val_loss did not improve from 0.78305\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1539 - acc: 0.6274 - val_loss: 0.7906 - val_acc: 0.7654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1529 - acc: 0.6295\n",
      "Epoch 00224: val_loss did not improve from 0.78305\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.1530 - acc: 0.6295 - val_loss: 0.7885 - val_acc: 0.7654\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1491 - acc: 0.6280\n",
      "Epoch 00225: val_loss did not improve from 0.78305\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1491 - acc: 0.6280 - val_loss: 0.8041 - val_acc: 0.7619\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1449 - acc: 0.6323\n",
      "Epoch 00226: val_loss did not improve from 0.78305\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1450 - acc: 0.6322 - val_loss: 0.7840 - val_acc: 0.7673\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1505 - acc: 0.6299\n",
      "Epoch 00227: val_loss did not improve from 0.78305\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1504 - acc: 0.6299 - val_loss: 0.7937 - val_acc: 0.7626\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1538 - acc: 0.6258\n",
      "Epoch 00228: val_loss did not improve from 0.78305\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1538 - acc: 0.6258 - val_loss: 0.7882 - val_acc: 0.7647\n",
      "Epoch 229/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1541 - acc: 0.6285\n",
      "Epoch 00229: val_loss did not improve from 0.78305\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.1541 - acc: 0.6284 - val_loss: 0.7882 - val_acc: 0.7615\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1505 - acc: 0.6322\n",
      "Epoch 00230: val_loss improved from 0.78305 to 0.78185, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/230-0.7818.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.1505 - acc: 0.6323 - val_loss: 0.7818 - val_acc: 0.7661\n",
      "Epoch 231/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1395 - acc: 0.6286\n",
      "Epoch 00231: val_loss did not improve from 0.78185\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1395 - acc: 0.6287 - val_loss: 0.7885 - val_acc: 0.7703\n",
      "Epoch 232/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1517 - acc: 0.6255\n",
      "Epoch 00232: val_loss did not improve from 0.78185\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.1517 - acc: 0.6255 - val_loss: 0.7906 - val_acc: 0.7661\n",
      "Epoch 233/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1491 - acc: 0.6269\n",
      "Epoch 00233: val_loss did not improve from 0.78185\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1488 - acc: 0.6270 - val_loss: 0.7884 - val_acc: 0.7626\n",
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1441 - acc: 0.6279\n",
      "Epoch 00234: val_loss did not improve from 0.78185\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1441 - acc: 0.6278 - val_loss: 0.7869 - val_acc: 0.7708\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1480 - acc: 0.6310\n",
      "Epoch 00235: val_loss did not improve from 0.78185\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1479 - acc: 0.6310 - val_loss: 0.7890 - val_acc: 0.7668\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1424 - acc: 0.6313\n",
      "Epoch 00236: val_loss did not improve from 0.78185\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1423 - acc: 0.6314 - val_loss: 0.7908 - val_acc: 0.7612\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1413 - acc: 0.6312\n",
      "Epoch 00237: val_loss improved from 0.78185 to 0.77960, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/237-0.7796.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1413 - acc: 0.6312 - val_loss: 0.7796 - val_acc: 0.7687\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1374 - acc: 0.6312\n",
      "Epoch 00238: val_loss did not improve from 0.77960\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1373 - acc: 0.6312 - val_loss: 0.7814 - val_acc: 0.7638\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1365 - acc: 0.6310\n",
      "Epoch 00239: val_loss did not improve from 0.77960\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.1365 - acc: 0.6310 - val_loss: 0.7825 - val_acc: 0.7682\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1410 - acc: 0.6306\n",
      "Epoch 00240: val_loss improved from 0.77960 to 0.77882, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/240-0.7788.hdf5\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.1409 - acc: 0.6307 - val_loss: 0.7788 - val_acc: 0.7680\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1357 - acc: 0.6295\n",
      "Epoch 00241: val_loss improved from 0.77882 to 0.77213, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/241-0.7721.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1357 - acc: 0.6295 - val_loss: 0.7721 - val_acc: 0.7699\n",
      "Epoch 242/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1417 - acc: 0.6320\n",
      "Epoch 00242: val_loss did not improve from 0.77213\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 1.1415 - acc: 0.6320 - val_loss: 0.7763 - val_acc: 0.7652\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1447 - acc: 0.6296\n",
      "Epoch 00243: val_loss did not improve from 0.77213\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.1447 - acc: 0.6296 - val_loss: 0.7807 - val_acc: 0.7678\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1391 - acc: 0.6324\n",
      "Epoch 00244: val_loss did not improve from 0.77213\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1391 - acc: 0.6324 - val_loss: 0.7810 - val_acc: 0.7680\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1306 - acc: 0.6330\n",
      "Epoch 00245: val_loss did not improve from 0.77213\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1305 - acc: 0.6330 - val_loss: 0.7849 - val_acc: 0.7729\n",
      "Epoch 246/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1348 - acc: 0.6332\n",
      "Epoch 00246: val_loss did not improve from 0.77213\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1349 - acc: 0.6331 - val_loss: 0.7910 - val_acc: 0.7689\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1366 - acc: 0.6302\n",
      "Epoch 00247: val_loss did not improve from 0.77213\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.1366 - acc: 0.6302 - val_loss: 0.7787 - val_acc: 0.7645\n",
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1395 - acc: 0.6306\n",
      "Epoch 00248: val_loss did not improve from 0.77213\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 1.1396 - acc: 0.6306 - val_loss: 0.7861 - val_acc: 0.7661\n",
      "Epoch 249/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1347 - acc: 0.6353\n",
      "Epoch 00249: val_loss did not improve from 0.77213\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1342 - acc: 0.6355 - val_loss: 0.7850 - val_acc: 0.7692\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1318 - acc: 0.6368\n",
      "Epoch 00250: val_loss did not improve from 0.77213\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1317 - acc: 0.6368 - val_loss: 0.7766 - val_acc: 0.7706\n",
      "Epoch 251/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1395 - acc: 0.6343\n",
      "Epoch 00251: val_loss did not improve from 0.77213\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1400 - acc: 0.6341 - val_loss: 0.7870 - val_acc: 0.7629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1301 - acc: 0.6351\n",
      "Epoch 00252: val_loss improved from 0.77213 to 0.77197, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/252-0.7720.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1301 - acc: 0.6350 - val_loss: 0.7720 - val_acc: 0.7734\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1419 - acc: 0.6299\n",
      "Epoch 00253: val_loss did not improve from 0.77197\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1420 - acc: 0.6299 - val_loss: 0.7806 - val_acc: 0.7664\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1332 - acc: 0.6355\n",
      "Epoch 00254: val_loss did not improve from 0.77197\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1332 - acc: 0.6355 - val_loss: 0.7747 - val_acc: 0.7710\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1304 - acc: 0.6348\n",
      "Epoch 00255: val_loss improved from 0.77197 to 0.76544, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/255-0.7654.hdf5\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 1.1303 - acc: 0.6348 - val_loss: 0.7654 - val_acc: 0.7687\n",
      "Epoch 256/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1317 - acc: 0.6337\n",
      "Epoch 00256: val_loss did not improve from 0.76544\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 1.1318 - acc: 0.6336 - val_loss: 0.7733 - val_acc: 0.7680\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1393 - acc: 0.6353\n",
      "Epoch 00257: val_loss did not improve from 0.76544\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1393 - acc: 0.6353 - val_loss: 0.7711 - val_acc: 0.7675\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1289 - acc: 0.6352\n",
      "Epoch 00258: val_loss did not improve from 0.76544\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1290 - acc: 0.6352 - val_loss: 0.7709 - val_acc: 0.7645\n",
      "Epoch 259/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1283 - acc: 0.6373\n",
      "Epoch 00259: val_loss did not improve from 0.76544\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1280 - acc: 0.6374 - val_loss: 0.7740 - val_acc: 0.7701\n",
      "Epoch 260/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1316 - acc: 0.6334\n",
      "Epoch 00260: val_loss did not improve from 0.76544\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1316 - acc: 0.6334 - val_loss: 0.7690 - val_acc: 0.7757\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1373 - acc: 0.6328\n",
      "Epoch 00261: val_loss did not improve from 0.76544\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1373 - acc: 0.6328 - val_loss: 0.7789 - val_acc: 0.7657\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1292 - acc: 0.6348\n",
      "Epoch 00262: val_loss improved from 0.76544 to 0.76502, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/262-0.7650.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1292 - acc: 0.6349 - val_loss: 0.7650 - val_acc: 0.7692\n",
      "Epoch 263/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1279 - acc: 0.6337\n",
      "Epoch 00263: val_loss did not improve from 0.76502\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 1.1279 - acc: 0.6337 - val_loss: 0.7714 - val_acc: 0.7708\n",
      "Epoch 264/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1389 - acc: 0.6336\n",
      "Epoch 00264: val_loss did not improve from 0.76502\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1389 - acc: 0.6335 - val_loss: 0.7696 - val_acc: 0.7720\n",
      "Epoch 265/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1237 - acc: 0.6375\n",
      "Epoch 00265: val_loss did not improve from 0.76502\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 1.1233 - acc: 0.6376 - val_loss: 0.7700 - val_acc: 0.7720\n",
      "Epoch 266/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1155 - acc: 0.6386\n",
      "Epoch 00266: val_loss did not improve from 0.76502\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1157 - acc: 0.6385 - val_loss: 0.7744 - val_acc: 0.7678\n",
      "Epoch 267/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1328 - acc: 0.6337\n",
      "Epoch 00267: val_loss did not improve from 0.76502\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1335 - acc: 0.6334 - val_loss: 0.7763 - val_acc: 0.7736\n",
      "Epoch 268/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1203 - acc: 0.6396\n",
      "Epoch 00268: val_loss improved from 0.76502 to 0.75819, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/268-0.7582.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1203 - acc: 0.6396 - val_loss: 0.7582 - val_acc: 0.7685\n",
      "Epoch 269/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1189 - acc: 0.6381\n",
      "Epoch 00269: val_loss did not improve from 0.75819\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1192 - acc: 0.6380 - val_loss: 0.7652 - val_acc: 0.7745\n",
      "Epoch 270/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1276 - acc: 0.6376\n",
      "Epoch 00270: val_loss improved from 0.75819 to 0.75730, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/270-0.7573.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.1276 - acc: 0.6376 - val_loss: 0.7573 - val_acc: 0.7741\n",
      "Epoch 271/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1248 - acc: 0.6377\n",
      "Epoch 00271: val_loss did not improve from 0.75730\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.1248 - acc: 0.6377 - val_loss: 0.7654 - val_acc: 0.7687\n",
      "Epoch 272/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1234 - acc: 0.6359\n",
      "Epoch 00272: val_loss improved from 0.75730 to 0.75638, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/272-0.7564.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1236 - acc: 0.6359 - val_loss: 0.7564 - val_acc: 0.7750\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1192 - acc: 0.6378\n",
      "Epoch 00273: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1193 - acc: 0.6377 - val_loss: 0.7644 - val_acc: 0.7675\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1299 - acc: 0.6340\n",
      "Epoch 00274: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1300 - acc: 0.6340 - val_loss: 0.7665 - val_acc: 0.7750\n",
      "Epoch 275/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1242 - acc: 0.6370\n",
      "Epoch 00275: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.1244 - acc: 0.6371 - val_loss: 0.7623 - val_acc: 0.7703\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1234 - acc: 0.6380\n",
      "Epoch 00276: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1235 - acc: 0.6379 - val_loss: 0.7622 - val_acc: 0.7687\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1302 - acc: 0.6351\n",
      "Epoch 00277: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1303 - acc: 0.6351 - val_loss: 0.7654 - val_acc: 0.7771\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1273 - acc: 0.6367\n",
      "Epoch 00278: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1274 - acc: 0.6366 - val_loss: 0.7638 - val_acc: 0.7741\n",
      "Epoch 279/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1192 - acc: 0.6396\n",
      "Epoch 00279: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.1192 - acc: 0.6396 - val_loss: 0.7688 - val_acc: 0.7696\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1170 - acc: 0.6365\n",
      "Epoch 00280: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1170 - acc: 0.6366 - val_loss: 0.7646 - val_acc: 0.7675\n",
      "Epoch 281/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1193 - acc: 0.6390\n",
      "Epoch 00281: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.1196 - acc: 0.6388 - val_loss: 0.7753 - val_acc: 0.7706\n",
      "Epoch 282/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1239 - acc: 0.6386\n",
      "Epoch 00282: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1236 - acc: 0.6387 - val_loss: 0.7760 - val_acc: 0.7731\n",
      "Epoch 283/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1243 - acc: 0.6390\n",
      "Epoch 00283: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1247 - acc: 0.6389 - val_loss: 0.7578 - val_acc: 0.7734\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1148 - acc: 0.6429\n",
      "Epoch 00284: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1148 - acc: 0.6429 - val_loss: 0.7636 - val_acc: 0.7720\n",
      "Epoch 285/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1144 - acc: 0.6399\n",
      "Epoch 00285: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1146 - acc: 0.6398 - val_loss: 0.7598 - val_acc: 0.7766\n",
      "Epoch 286/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1238 - acc: 0.6371\n",
      "Epoch 00286: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 1.1238 - acc: 0.6371 - val_loss: 0.7698 - val_acc: 0.7699\n",
      "Epoch 287/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1135 - acc: 0.6418\n",
      "Epoch 00287: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1134 - acc: 0.6418 - val_loss: 0.7676 - val_acc: 0.7689\n",
      "Epoch 288/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1191 - acc: 0.6382\n",
      "Epoch 00288: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1191 - acc: 0.6383 - val_loss: 0.7628 - val_acc: 0.7664\n",
      "Epoch 289/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1238 - acc: 0.6347\n",
      "Epoch 00289: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1239 - acc: 0.6346 - val_loss: 0.7671 - val_acc: 0.7715\n",
      "Epoch 290/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1179 - acc: 0.6401\n",
      "Epoch 00290: val_loss did not improve from 0.75638\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1183 - acc: 0.6398 - val_loss: 0.7591 - val_acc: 0.7773\n",
      "Epoch 291/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1187 - acc: 0.6393\n",
      "Epoch 00291: val_loss improved from 0.75638 to 0.75419, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/291-0.7542.hdf5\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.1185 - acc: 0.6394 - val_loss: 0.7542 - val_acc: 0.7778\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1121 - acc: 0.6394\n",
      "Epoch 00292: val_loss did not improve from 0.75419\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1122 - acc: 0.6394 - val_loss: 0.7650 - val_acc: 0.7761\n",
      "Epoch 293/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1108 - acc: 0.6410\n",
      "Epoch 00293: val_loss did not improve from 0.75419\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 1.1109 - acc: 0.6410 - val_loss: 0.7548 - val_acc: 0.7757\n",
      "Epoch 294/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1141 - acc: 0.6432\n",
      "Epoch 00294: val_loss did not improve from 0.75419\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 1.1141 - acc: 0.6433 - val_loss: 0.7577 - val_acc: 0.7750\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1215 - acc: 0.6403\n",
      "Epoch 00295: val_loss did not improve from 0.75419\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1215 - acc: 0.6403 - val_loss: 0.7690 - val_acc: 0.7747\n",
      "Epoch 296/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1168 - acc: 0.6387\n",
      "Epoch 00296: val_loss did not improve from 0.75419\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1167 - acc: 0.6387 - val_loss: 0.7706 - val_acc: 0.7729\n",
      "Epoch 297/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1048 - acc: 0.6430\n",
      "Epoch 00297: val_loss did not improve from 0.75419\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1047 - acc: 0.6429 - val_loss: 0.7604 - val_acc: 0.7715\n",
      "Epoch 298/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1105 - acc: 0.6430\n",
      "Epoch 00298: val_loss improved from 0.75419 to 0.75343, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/298-0.7534.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1105 - acc: 0.6430 - val_loss: 0.7534 - val_acc: 0.7743\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1133 - acc: 0.6386\n",
      "Epoch 00299: val_loss did not improve from 0.75343\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1133 - acc: 0.6385 - val_loss: 0.7552 - val_acc: 0.7754\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1143 - acc: 0.6376\n",
      "Epoch 00300: val_loss did not improve from 0.75343\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.1144 - acc: 0.6375 - val_loss: 0.7580 - val_acc: 0.7775\n",
      "Epoch 301/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1171 - acc: 0.6379\n",
      "Epoch 00301: val_loss improved from 0.75343 to 0.75256, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/301-0.7526.hdf5\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 1.1171 - acc: 0.6379 - val_loss: 0.7526 - val_acc: 0.7761\n",
      "Epoch 302/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1105 - acc: 0.6408\n",
      "Epoch 00302: val_loss did not improve from 0.75256\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 1.1106 - acc: 0.6408 - val_loss: 0.7603 - val_acc: 0.7703\n",
      "Epoch 303/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1092 - acc: 0.6412\n",
      "Epoch 00303: val_loss did not improve from 0.75256\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 1.1089 - acc: 0.6412 - val_loss: 0.7576 - val_acc: 0.7780\n",
      "Epoch 304/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1150 - acc: 0.6369\n",
      "Epoch 00304: val_loss improved from 0.75256 to 0.75214, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/304-0.7521.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1151 - acc: 0.6369 - val_loss: 0.7521 - val_acc: 0.7743\n",
      "Epoch 305/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1018 - acc: 0.6455\n",
      "Epoch 00305: val_loss did not improve from 0.75214\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1018 - acc: 0.6455 - val_loss: 0.7648 - val_acc: 0.7654\n",
      "Epoch 306/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1165 - acc: 0.6370\n",
      "Epoch 00306: val_loss did not improve from 0.75214\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1166 - acc: 0.6370 - val_loss: 0.7586 - val_acc: 0.7722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1131 - acc: 0.6402\n",
      "Epoch 00307: val_loss did not improve from 0.75214\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1132 - acc: 0.6402 - val_loss: 0.7577 - val_acc: 0.7738\n",
      "Epoch 308/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1140 - acc: 0.6404\n",
      "Epoch 00308: val_loss did not improve from 0.75214\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1139 - acc: 0.6404 - val_loss: 0.7593 - val_acc: 0.7706\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1061 - acc: 0.6445\n",
      "Epoch 00309: val_loss did not improve from 0.75214\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 1.1062 - acc: 0.6445 - val_loss: 0.7524 - val_acc: 0.7785\n",
      "Epoch 310/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1116 - acc: 0.6436\n",
      "Epoch 00310: val_loss did not improve from 0.75214\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1115 - acc: 0.6435 - val_loss: 0.7558 - val_acc: 0.7738\n",
      "Epoch 311/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1065 - acc: 0.6420\n",
      "Epoch 00311: val_loss did not improve from 0.75214\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1066 - acc: 0.6420 - val_loss: 0.7563 - val_acc: 0.7764\n",
      "Epoch 312/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1122 - acc: 0.6405\n",
      "Epoch 00312: val_loss did not improve from 0.75214\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1122 - acc: 0.6405 - val_loss: 0.7573 - val_acc: 0.7734\n",
      "Epoch 313/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1110 - acc: 0.6395\n",
      "Epoch 00313: val_loss did not improve from 0.75214\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1108 - acc: 0.6396 - val_loss: 0.7535 - val_acc: 0.7757\n",
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1159 - acc: 0.6367\n",
      "Epoch 00314: val_loss did not improve from 0.75214\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1159 - acc: 0.6367 - val_loss: 0.7557 - val_acc: 0.7731\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1111 - acc: 0.6412\n",
      "Epoch 00315: val_loss did not improve from 0.75214\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1110 - acc: 0.6413 - val_loss: 0.7589 - val_acc: 0.7764\n",
      "Epoch 316/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1065 - acc: 0.6429\n",
      "Epoch 00316: val_loss improved from 0.75214 to 0.75035, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/316-0.7504.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1064 - acc: 0.6429 - val_loss: 0.7504 - val_acc: 0.7731\n",
      "Epoch 317/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1012 - acc: 0.6448\n",
      "Epoch 00317: val_loss did not improve from 0.75035\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.1011 - acc: 0.6448 - val_loss: 0.7631 - val_acc: 0.7766\n",
      "Epoch 318/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1047 - acc: 0.6433\n",
      "Epoch 00318: val_loss did not improve from 0.75035\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.1046 - acc: 0.6433 - val_loss: 0.7504 - val_acc: 0.7761\n",
      "Epoch 319/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1047 - acc: 0.6430\n",
      "Epoch 00319: val_loss did not improve from 0.75035\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1047 - acc: 0.6430 - val_loss: 0.7636 - val_acc: 0.7745\n",
      "Epoch 320/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0989 - acc: 0.6466\n",
      "Epoch 00320: val_loss did not improve from 0.75035\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0989 - acc: 0.6465 - val_loss: 0.7523 - val_acc: 0.7778\n",
      "Epoch 321/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1005 - acc: 0.6445\n",
      "Epoch 00321: val_loss did not improve from 0.75035\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1006 - acc: 0.6445 - val_loss: 0.7563 - val_acc: 0.7720\n",
      "Epoch 322/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0976 - acc: 0.6458\n",
      "Epoch 00322: val_loss improved from 0.75035 to 0.74828, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/322-0.7483.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0978 - acc: 0.6459 - val_loss: 0.7483 - val_acc: 0.7824\n",
      "Epoch 323/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1065 - acc: 0.6437\n",
      "Epoch 00323: val_loss did not improve from 0.74828\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1064 - acc: 0.6437 - val_loss: 0.7513 - val_acc: 0.7771\n",
      "Epoch 324/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0986 - acc: 0.6446\n",
      "Epoch 00324: val_loss improved from 0.74828 to 0.74542, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/324-0.7454.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0987 - acc: 0.6445 - val_loss: 0.7454 - val_acc: 0.7775\n",
      "Epoch 325/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1010 - acc: 0.6439\n",
      "Epoch 00325: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.1010 - acc: 0.6438 - val_loss: 0.7518 - val_acc: 0.7741\n",
      "Epoch 326/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1041 - acc: 0.6442\n",
      "Epoch 00326: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1042 - acc: 0.6442 - val_loss: 0.7463 - val_acc: 0.7738\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1075 - acc: 0.6446\n",
      "Epoch 00327: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1075 - acc: 0.6446 - val_loss: 0.7579 - val_acc: 0.7761\n",
      "Epoch 328/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1004 - acc: 0.6393\n",
      "Epoch 00328: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1005 - acc: 0.6392 - val_loss: 0.7508 - val_acc: 0.7752\n",
      "Epoch 329/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0989 - acc: 0.6443\n",
      "Epoch 00329: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0990 - acc: 0.6443 - val_loss: 0.7583 - val_acc: 0.7706\n",
      "Epoch 330/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1002 - acc: 0.6440\n",
      "Epoch 00330: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1002 - acc: 0.6440 - val_loss: 0.7561 - val_acc: 0.7785\n",
      "Epoch 331/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0976 - acc: 0.6448\n",
      "Epoch 00331: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0975 - acc: 0.6448 - val_loss: 0.7491 - val_acc: 0.7743\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0989 - acc: 0.6432\n",
      "Epoch 00332: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.0989 - acc: 0.6433 - val_loss: 0.7559 - val_acc: 0.7771\n",
      "Epoch 333/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1024 - acc: 0.6433\n",
      "Epoch 00333: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 1.1027 - acc: 0.6433 - val_loss: 0.7529 - val_acc: 0.7768\n",
      "Epoch 334/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1024 - acc: 0.6460\n",
      "Epoch 00334: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1023 - acc: 0.6460 - val_loss: 0.7512 - val_acc: 0.7773\n",
      "Epoch 335/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0981 - acc: 0.6441\n",
      "Epoch 00335: val_loss improved from 0.74542 to 0.74456, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/335-0.7446.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0982 - acc: 0.6440 - val_loss: 0.7446 - val_acc: 0.7775\n",
      "Epoch 336/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1009 - acc: 0.6476\n",
      "Epoch 00336: val_loss did not improve from 0.74456\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1008 - acc: 0.6475 - val_loss: 0.7566 - val_acc: 0.7754\n",
      "Epoch 337/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1032 - acc: 0.6420\n",
      "Epoch 00337: val_loss did not improve from 0.74456\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.1035 - acc: 0.6419 - val_loss: 0.7499 - val_acc: 0.7782\n",
      "Epoch 338/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1003 - acc: 0.6425\n",
      "Epoch 00338: val_loss improved from 0.74456 to 0.74310, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/338-0.7431.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.1004 - acc: 0.6425 - val_loss: 0.7431 - val_acc: 0.7799\n",
      "Epoch 339/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0995 - acc: 0.6446\n",
      "Epoch 00339: val_loss did not improve from 0.74310\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0994 - acc: 0.6446 - val_loss: 0.7467 - val_acc: 0.7836\n",
      "Epoch 340/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0953 - acc: 0.6466\n",
      "Epoch 00340: val_loss did not improve from 0.74310\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 1.0953 - acc: 0.6467 - val_loss: 0.7491 - val_acc: 0.7768\n",
      "Epoch 341/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0956 - acc: 0.6466\n",
      "Epoch 00341: val_loss did not improve from 0.74310\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 1.0952 - acc: 0.6467 - val_loss: 0.7442 - val_acc: 0.7775\n",
      "Epoch 342/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1021 - acc: 0.6450\n",
      "Epoch 00342: val_loss did not improve from 0.74310\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 1.1016 - acc: 0.6451 - val_loss: 0.7504 - val_acc: 0.7771\n",
      "Epoch 343/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0940 - acc: 0.6468\n",
      "Epoch 00343: val_loss did not improve from 0.74310\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0943 - acc: 0.6468 - val_loss: 0.7439 - val_acc: 0.7785\n",
      "Epoch 344/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0924 - acc: 0.6462\n",
      "Epoch 00344: val_loss did not improve from 0.74310\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.0922 - acc: 0.6463 - val_loss: 0.7437 - val_acc: 0.7829\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0979 - acc: 0.6469\n",
      "Epoch 00345: val_loss improved from 0.74310 to 0.73906, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/345-0.7391.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0980 - acc: 0.6469 - val_loss: 0.7391 - val_acc: 0.7815\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0912 - acc: 0.6493\n",
      "Epoch 00346: val_loss did not improve from 0.73906\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0912 - acc: 0.6494 - val_loss: 0.7503 - val_acc: 0.7750\n",
      "Epoch 347/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0956 - acc: 0.6458\n",
      "Epoch 00347: val_loss did not improve from 0.73906\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0955 - acc: 0.6459 - val_loss: 0.7490 - val_acc: 0.7796\n",
      "Epoch 348/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0912 - acc: 0.6452\n",
      "Epoch 00348: val_loss did not improve from 0.73906\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 1.0912 - acc: 0.6453 - val_loss: 0.7622 - val_acc: 0.7750\n",
      "Epoch 349/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0933 - acc: 0.6460\n",
      "Epoch 00349: val_loss did not improve from 0.73906\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0931 - acc: 0.6462 - val_loss: 0.7459 - val_acc: 0.7815\n",
      "Epoch 350/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0887 - acc: 0.6471\n",
      "Epoch 00350: val_loss did not improve from 0.73906\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0886 - acc: 0.6472 - val_loss: 0.7471 - val_acc: 0.7750\n",
      "Epoch 351/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0931 - acc: 0.6475\n",
      "Epoch 00351: val_loss did not improve from 0.73906\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0931 - acc: 0.6475 - val_loss: 0.7447 - val_acc: 0.7813\n",
      "Epoch 352/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0990 - acc: 0.6463\n",
      "Epoch 00352: val_loss did not improve from 0.73906\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0990 - acc: 0.6463 - val_loss: 0.7475 - val_acc: 0.7803\n",
      "Epoch 353/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0942 - acc: 0.6446\n",
      "Epoch 00353: val_loss improved from 0.73906 to 0.73742, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/353-0.7374.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0942 - acc: 0.6446 - val_loss: 0.7374 - val_acc: 0.7789\n",
      "Epoch 354/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0881 - acc: 0.6470\n",
      "Epoch 00354: val_loss did not improve from 0.73742\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0881 - acc: 0.6469 - val_loss: 0.7423 - val_acc: 0.7852\n",
      "Epoch 355/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0895 - acc: 0.6485\n",
      "Epoch 00355: val_loss improved from 0.73742 to 0.73118, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/355-0.7312.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0896 - acc: 0.6484 - val_loss: 0.7312 - val_acc: 0.7848\n",
      "Epoch 356/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0976 - acc: 0.6439\n",
      "Epoch 00356: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 1.0976 - acc: 0.6439 - val_loss: 0.7498 - val_acc: 0.7750\n",
      "Epoch 357/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0975 - acc: 0.6468\n",
      "Epoch 00357: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0975 - acc: 0.6468 - val_loss: 0.7519 - val_acc: 0.7771\n",
      "Epoch 358/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0888 - acc: 0.6475\n",
      "Epoch 00358: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0888 - acc: 0.6475 - val_loss: 0.7477 - val_acc: 0.7789\n",
      "Epoch 359/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0947 - acc: 0.6476\n",
      "Epoch 00359: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0948 - acc: 0.6475 - val_loss: 0.7416 - val_acc: 0.7817\n",
      "Epoch 360/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0867 - acc: 0.6520\n",
      "Epoch 00360: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0871 - acc: 0.6519 - val_loss: 0.7501 - val_acc: 0.7750\n",
      "Epoch 361/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0859 - acc: 0.6485\n",
      "Epoch 00361: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0856 - acc: 0.6486 - val_loss: 0.7348 - val_acc: 0.7820\n",
      "Epoch 362/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0860 - acc: 0.6470\n",
      "Epoch 00362: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0860 - acc: 0.6470 - val_loss: 0.7366 - val_acc: 0.7808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0890 - acc: 0.6514\n",
      "Epoch 00363: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 1.0890 - acc: 0.6514 - val_loss: 0.7441 - val_acc: 0.7745\n",
      "Epoch 364/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0899 - acc: 0.6482\n",
      "Epoch 00364: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0898 - acc: 0.6483 - val_loss: 0.7363 - val_acc: 0.7801\n",
      "Epoch 365/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0827 - acc: 0.6504\n",
      "Epoch 00365: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0826 - acc: 0.6504 - val_loss: 0.7375 - val_acc: 0.7806\n",
      "Epoch 366/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0857 - acc: 0.6489\n",
      "Epoch 00366: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.0858 - acc: 0.6488 - val_loss: 0.7395 - val_acc: 0.7799\n",
      "Epoch 367/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0900 - acc: 0.6470\n",
      "Epoch 00367: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0899 - acc: 0.6470 - val_loss: 0.7434 - val_acc: 0.7843\n",
      "Epoch 368/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0880 - acc: 0.6497\n",
      "Epoch 00368: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0881 - acc: 0.6496 - val_loss: 0.7441 - val_acc: 0.7754\n",
      "Epoch 369/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0915 - acc: 0.6446\n",
      "Epoch 00369: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0915 - acc: 0.6446 - val_loss: 0.7376 - val_acc: 0.7801\n",
      "Epoch 370/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0808 - acc: 0.6500\n",
      "Epoch 00370: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0808 - acc: 0.6500 - val_loss: 0.7424 - val_acc: 0.7789\n",
      "Epoch 371/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0888 - acc: 0.6489\n",
      "Epoch 00371: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 1.0888 - acc: 0.6490 - val_loss: 0.7449 - val_acc: 0.7820\n",
      "Epoch 372/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0885 - acc: 0.6496\n",
      "Epoch 00372: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0885 - acc: 0.6496 - val_loss: 0.7372 - val_acc: 0.7831\n",
      "Epoch 373/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0849 - acc: 0.6499\n",
      "Epoch 00373: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0850 - acc: 0.6499 - val_loss: 0.7494 - val_acc: 0.7780\n",
      "Epoch 374/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0792 - acc: 0.6522\n",
      "Epoch 00374: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0796 - acc: 0.6521 - val_loss: 0.7425 - val_acc: 0.7754\n",
      "Epoch 375/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0867 - acc: 0.6487\n",
      "Epoch 00375: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0867 - acc: 0.6487 - val_loss: 0.7406 - val_acc: 0.7799\n",
      "Epoch 376/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0914 - acc: 0.6479\n",
      "Epoch 00376: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0917 - acc: 0.6478 - val_loss: 0.7371 - val_acc: 0.7806\n",
      "Epoch 377/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0890 - acc: 0.6478\n",
      "Epoch 00377: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0894 - acc: 0.6476 - val_loss: 0.7326 - val_acc: 0.7855\n",
      "Epoch 378/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0796 - acc: 0.6532\n",
      "Epoch 00378: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0795 - acc: 0.6532 - val_loss: 0.7371 - val_acc: 0.7824\n",
      "Epoch 379/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0914 - acc: 0.6494\n",
      "Epoch 00379: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 1.0916 - acc: 0.6492 - val_loss: 0.7366 - val_acc: 0.7827\n",
      "Epoch 380/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0886 - acc: 0.6487\n",
      "Epoch 00380: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.0886 - acc: 0.6487 - val_loss: 0.7385 - val_acc: 0.7771\n",
      "Epoch 381/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0874 - acc: 0.6482\n",
      "Epoch 00381: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.0866 - acc: 0.6485 - val_loss: 0.7395 - val_acc: 0.7787\n",
      "Epoch 382/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0846 - acc: 0.6488\n",
      "Epoch 00382: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0847 - acc: 0.6488 - val_loss: 0.7373 - val_acc: 0.7803\n",
      "Epoch 383/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0823 - acc: 0.6493\n",
      "Epoch 00383: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0823 - acc: 0.6494 - val_loss: 0.7355 - val_acc: 0.7803\n",
      "Epoch 384/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0785 - acc: 0.6500\n",
      "Epoch 00384: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 1.0786 - acc: 0.6499 - val_loss: 0.7360 - val_acc: 0.7803\n",
      "Epoch 385/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0884 - acc: 0.6490\n",
      "Epoch 00385: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0889 - acc: 0.6490 - val_loss: 0.7361 - val_acc: 0.7817\n",
      "Epoch 386/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0772 - acc: 0.6533\n",
      "Epoch 00386: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 1.0772 - acc: 0.6533 - val_loss: 0.7321 - val_acc: 0.7836\n",
      "Epoch 387/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0813 - acc: 0.6477\n",
      "Epoch 00387: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 1.0812 - acc: 0.6477 - val_loss: 0.7355 - val_acc: 0.7775\n",
      "Epoch 388/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0758 - acc: 0.6498\n",
      "Epoch 00388: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0758 - acc: 0.6498 - val_loss: 0.7418 - val_acc: 0.7771\n",
      "Epoch 389/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0781 - acc: 0.6535\n",
      "Epoch 00389: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0781 - acc: 0.6534 - val_loss: 0.7378 - val_acc: 0.7789\n",
      "Epoch 390/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0813 - acc: 0.6493\n",
      "Epoch 00390: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0813 - acc: 0.6493 - val_loss: 0.7321 - val_acc: 0.7852\n",
      "Epoch 391/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0787 - acc: 0.6493\n",
      "Epoch 00391: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0786 - acc: 0.6493 - val_loss: 0.7390 - val_acc: 0.7822\n",
      "Epoch 392/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0813 - acc: 0.6482\n",
      "Epoch 00392: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0820 - acc: 0.6479 - val_loss: 0.7411 - val_acc: 0.7808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0848 - acc: 0.6476\n",
      "Epoch 00393: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0849 - acc: 0.6476 - val_loss: 0.7424 - val_acc: 0.7827\n",
      "Epoch 394/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0755 - acc: 0.6518\n",
      "Epoch 00394: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 1.0755 - acc: 0.6519 - val_loss: 0.7354 - val_acc: 0.7829\n",
      "Epoch 395/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0832 - acc: 0.6504\n",
      "Epoch 00395: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0832 - acc: 0.6504 - val_loss: 0.7381 - val_acc: 0.7834\n",
      "Epoch 396/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0757 - acc: 0.6528\n",
      "Epoch 00396: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 1.0755 - acc: 0.6529 - val_loss: 0.7315 - val_acc: 0.7794\n",
      "Epoch 397/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0810 - acc: 0.6512\n",
      "Epoch 00397: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0809 - acc: 0.6512 - val_loss: 0.7342 - val_acc: 0.7857\n",
      "Epoch 398/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0739 - acc: 0.6525\n",
      "Epoch 00398: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0744 - acc: 0.6523 - val_loss: 0.7335 - val_acc: 0.7827\n",
      "Epoch 399/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0716 - acc: 0.6538\n",
      "Epoch 00399: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.0715 - acc: 0.6538 - val_loss: 0.7389 - val_acc: 0.7838\n",
      "Epoch 400/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0794 - acc: 0.6512\n",
      "Epoch 00400: val_loss did not improve from 0.73118\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0793 - acc: 0.6512 - val_loss: 0.7503 - val_acc: 0.7754\n",
      "Epoch 401/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0753 - acc: 0.6535\n",
      "Epoch 00401: val_loss improved from 0.73118 to 0.72380, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/401-0.7238.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0752 - acc: 0.6535 - val_loss: 0.7238 - val_acc: 0.7845\n",
      "Epoch 402/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0781 - acc: 0.6497\n",
      "Epoch 00402: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 1.0780 - acc: 0.6497 - val_loss: 0.7351 - val_acc: 0.7838\n",
      "Epoch 403/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0738 - acc: 0.6535\n",
      "Epoch 00403: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0737 - acc: 0.6536 - val_loss: 0.7253 - val_acc: 0.7878\n",
      "Epoch 404/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0838 - acc: 0.6511\n",
      "Epoch 00404: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 1.0839 - acc: 0.6512 - val_loss: 0.7409 - val_acc: 0.7792\n",
      "Epoch 405/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0733 - acc: 0.6531\n",
      "Epoch 00405: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0734 - acc: 0.6530 - val_loss: 0.7464 - val_acc: 0.7789\n",
      "Epoch 406/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0707 - acc: 0.6567\n",
      "Epoch 00406: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0706 - acc: 0.6567 - val_loss: 0.7436 - val_acc: 0.7803\n",
      "Epoch 407/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0849 - acc: 0.6484\n",
      "Epoch 00407: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0849 - acc: 0.6484 - val_loss: 0.7333 - val_acc: 0.7806\n",
      "Epoch 408/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0776 - acc: 0.6516\n",
      "Epoch 00408: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0779 - acc: 0.6515 - val_loss: 0.7420 - val_acc: 0.7778\n",
      "Epoch 409/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0779 - acc: 0.6493\n",
      "Epoch 00409: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.0779 - acc: 0.6493 - val_loss: 0.7382 - val_acc: 0.7859\n",
      "Epoch 410/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0774 - acc: 0.6533\n",
      "Epoch 00410: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 1.0773 - acc: 0.6533 - val_loss: 0.7363 - val_acc: 0.7824\n",
      "Epoch 411/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0883 - acc: 0.6467\n",
      "Epoch 00411: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0883 - acc: 0.6467 - val_loss: 0.7401 - val_acc: 0.7857\n",
      "Epoch 412/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0727 - acc: 0.6532\n",
      "Epoch 00412: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 23s 611us/sample - loss: 1.0727 - acc: 0.6532 - val_loss: 0.7428 - val_acc: 0.7806\n",
      "Epoch 413/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0734 - acc: 0.6537\n",
      "Epoch 00413: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0734 - acc: 0.6537 - val_loss: 0.7328 - val_acc: 0.7829\n",
      "Epoch 414/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0827 - acc: 0.6519\n",
      "Epoch 00414: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0829 - acc: 0.6517 - val_loss: 0.7353 - val_acc: 0.7838\n",
      "Epoch 415/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0782 - acc: 0.6507\n",
      "Epoch 00415: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0782 - acc: 0.6506 - val_loss: 0.7314 - val_acc: 0.7857\n",
      "Epoch 416/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0711 - acc: 0.6556\n",
      "Epoch 00416: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0715 - acc: 0.6554 - val_loss: 0.7312 - val_acc: 0.7897\n",
      "Epoch 417/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0736 - acc: 0.6511\n",
      "Epoch 00417: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0736 - acc: 0.6510 - val_loss: 0.7287 - val_acc: 0.7862\n",
      "Epoch 418/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0733 - acc: 0.6557\n",
      "Epoch 00418: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 1.0733 - acc: 0.6557 - val_loss: 0.7436 - val_acc: 0.7810\n",
      "Epoch 419/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0736 - acc: 0.6563\n",
      "Epoch 00419: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0736 - acc: 0.6562 - val_loss: 0.7281 - val_acc: 0.7834\n",
      "Epoch 420/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0802 - acc: 0.6498\n",
      "Epoch 00420: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0801 - acc: 0.6498 - val_loss: 0.7342 - val_acc: 0.7796\n",
      "Epoch 421/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0756 - acc: 0.6525\n",
      "Epoch 00421: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0755 - acc: 0.6526 - val_loss: 0.7315 - val_acc: 0.7859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0725 - acc: 0.6555\n",
      "Epoch 00422: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 1.0726 - acc: 0.6554 - val_loss: 0.7360 - val_acc: 0.7836\n",
      "Epoch 423/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0802 - acc: 0.6516\n",
      "Epoch 00423: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0802 - acc: 0.6516 - val_loss: 0.7269 - val_acc: 0.7838\n",
      "Epoch 424/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0677 - acc: 0.6552\n",
      "Epoch 00424: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 1.0681 - acc: 0.6552 - val_loss: 0.7340 - val_acc: 0.7785\n",
      "Epoch 425/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0728 - acc: 0.6523\n",
      "Epoch 00425: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 1.0728 - acc: 0.6522 - val_loss: 0.7279 - val_acc: 0.7838\n",
      "Epoch 426/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0722 - acc: 0.6562\n",
      "Epoch 00426: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 23s 625us/sample - loss: 1.0722 - acc: 0.6562 - val_loss: 0.7355 - val_acc: 0.7813\n",
      "Epoch 427/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0725 - acc: 0.6498\n",
      "Epoch 00427: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0724 - acc: 0.6499 - val_loss: 0.7325 - val_acc: 0.7845\n",
      "Epoch 428/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0665 - acc: 0.6534\n",
      "Epoch 00428: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0664 - acc: 0.6534 - val_loss: 0.7258 - val_acc: 0.7864\n",
      "Epoch 429/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0729 - acc: 0.6535\n",
      "Epoch 00429: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0730 - acc: 0.6535 - val_loss: 0.7363 - val_acc: 0.7848\n",
      "Epoch 430/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0741 - acc: 0.6562\n",
      "Epoch 00430: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0742 - acc: 0.6563 - val_loss: 0.7450 - val_acc: 0.7836\n",
      "Epoch 431/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0694 - acc: 0.6545\n",
      "Epoch 00431: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0692 - acc: 0.6545 - val_loss: 0.7247 - val_acc: 0.7873\n",
      "Epoch 432/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0694 - acc: 0.6552\n",
      "Epoch 00432: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0693 - acc: 0.6553 - val_loss: 0.7327 - val_acc: 0.7817\n",
      "Epoch 433/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0666 - acc: 0.6528\n",
      "Epoch 00433: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 1.0667 - acc: 0.6528 - val_loss: 0.7288 - val_acc: 0.7822\n",
      "Epoch 434/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0690 - acc: 0.6574\n",
      "Epoch 00434: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 1.0691 - acc: 0.6574 - val_loss: 0.7411 - val_acc: 0.7855\n",
      "Epoch 435/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0676 - acc: 0.6569\n",
      "Epoch 00435: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0675 - acc: 0.6569 - val_loss: 0.7327 - val_acc: 0.7775\n",
      "Epoch 436/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0628 - acc: 0.6572\n",
      "Epoch 00436: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0628 - acc: 0.6572 - val_loss: 0.7455 - val_acc: 0.7771\n",
      "Epoch 437/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0721 - acc: 0.6506\n",
      "Epoch 00437: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0721 - acc: 0.6506 - val_loss: 0.7432 - val_acc: 0.7827\n",
      "Epoch 438/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0737 - acc: 0.6527\n",
      "Epoch 00438: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0739 - acc: 0.6527 - val_loss: 0.7327 - val_acc: 0.7782\n",
      "Epoch 439/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0658 - acc: 0.6538\n",
      "Epoch 00439: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0663 - acc: 0.6537 - val_loss: 0.7356 - val_acc: 0.7836\n",
      "Epoch 440/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0670 - acc: 0.6516\n",
      "Epoch 00440: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0671 - acc: 0.6515 - val_loss: 0.7266 - val_acc: 0.7890\n",
      "Epoch 441/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0737 - acc: 0.6507\n",
      "Epoch 00441: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 1.0736 - acc: 0.6507 - val_loss: 0.7347 - val_acc: 0.7848\n",
      "Epoch 442/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0679 - acc: 0.6546\n",
      "Epoch 00442: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0679 - acc: 0.6546 - val_loss: 0.7385 - val_acc: 0.7808\n",
      "Epoch 443/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0719 - acc: 0.6520\n",
      "Epoch 00443: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0720 - acc: 0.6519 - val_loss: 0.7394 - val_acc: 0.7852\n",
      "Epoch 444/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0686 - acc: 0.6531\n",
      "Epoch 00444: val_loss did not improve from 0.72380\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0686 - acc: 0.6531 - val_loss: 0.7309 - val_acc: 0.7869\n",
      "Epoch 445/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0683 - acc: 0.6552\n",
      "Epoch 00445: val_loss improved from 0.72380 to 0.72236, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/445-0.7224.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0684 - acc: 0.6552 - val_loss: 0.7224 - val_acc: 0.7890\n",
      "Epoch 446/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0644 - acc: 0.6549\n",
      "Epoch 00446: val_loss did not improve from 0.72236\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0644 - acc: 0.6549 - val_loss: 0.7319 - val_acc: 0.7831\n",
      "Epoch 447/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0643 - acc: 0.6572\n",
      "Epoch 00447: val_loss did not improve from 0.72236\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.0643 - acc: 0.6571 - val_loss: 0.7342 - val_acc: 0.7831\n",
      "Epoch 448/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0634 - acc: 0.6570\n",
      "Epoch 00448: val_loss did not improve from 0.72236\n",
      "36805/36805 [==============================] - 23s 611us/sample - loss: 1.0633 - acc: 0.6570 - val_loss: 0.7264 - val_acc: 0.7864\n",
      "Epoch 449/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0644 - acc: 0.6555\n",
      "Epoch 00449: val_loss did not improve from 0.72236\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 1.0645 - acc: 0.6554 - val_loss: 0.7454 - val_acc: 0.7754\n",
      "Epoch 450/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0638 - acc: 0.6562\n",
      "Epoch 00450: val_loss did not improve from 0.72236\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 1.0637 - acc: 0.6562 - val_loss: 0.7280 - val_acc: 0.7820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0627 - acc: 0.6565\n",
      "Epoch 00451: val_loss did not improve from 0.72236\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0627 - acc: 0.6565 - val_loss: 0.7299 - val_acc: 0.7824\n",
      "Epoch 452/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0666 - acc: 0.6557\n",
      "Epoch 00452: val_loss did not improve from 0.72236\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0660 - acc: 0.6558 - val_loss: 0.7320 - val_acc: 0.7878\n",
      "Epoch 453/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0602 - acc: 0.6583\n",
      "Epoch 00453: val_loss did not improve from 0.72236\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.0599 - acc: 0.6585 - val_loss: 0.7291 - val_acc: 0.7813\n",
      "Epoch 454/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0700 - acc: 0.6544\n",
      "Epoch 00454: val_loss did not improve from 0.72236\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0701 - acc: 0.6544 - val_loss: 0.7379 - val_acc: 0.7829\n",
      "Epoch 455/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0678 - acc: 0.6555\n",
      "Epoch 00455: val_loss improved from 0.72236 to 0.72062, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/455-0.7206.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0677 - acc: 0.6555 - val_loss: 0.7206 - val_acc: 0.7878\n",
      "Epoch 456/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0624 - acc: 0.6592\n",
      "Epoch 00456: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0624 - acc: 0.6591 - val_loss: 0.7257 - val_acc: 0.7864\n",
      "Epoch 457/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0652 - acc: 0.6549\n",
      "Epoch 00457: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 1.0652 - acc: 0.6549 - val_loss: 0.7247 - val_acc: 0.7897\n",
      "Epoch 458/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0578 - acc: 0.6576\n",
      "Epoch 00458: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 1.0578 - acc: 0.6576 - val_loss: 0.7294 - val_acc: 0.7859\n",
      "Epoch 459/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0593 - acc: 0.6572\n",
      "Epoch 00459: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0595 - acc: 0.6572 - val_loss: 0.7446 - val_acc: 0.7850\n",
      "Epoch 460/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0629 - acc: 0.6576\n",
      "Epoch 00460: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0629 - acc: 0.6576 - val_loss: 0.7425 - val_acc: 0.7792\n",
      "Epoch 461/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0642 - acc: 0.6573\n",
      "Epoch 00461: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0641 - acc: 0.6572 - val_loss: 0.7330 - val_acc: 0.7813\n",
      "Epoch 462/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0631 - acc: 0.6546\n",
      "Epoch 00462: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0629 - acc: 0.6545 - val_loss: 0.7374 - val_acc: 0.7852\n",
      "Epoch 463/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0681 - acc: 0.6539\n",
      "Epoch 00463: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0680 - acc: 0.6540 - val_loss: 0.7246 - val_acc: 0.7836\n",
      "Epoch 464/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0673 - acc: 0.6535\n",
      "Epoch 00464: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0673 - acc: 0.6534 - val_loss: 0.7284 - val_acc: 0.7850\n",
      "Epoch 465/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0676 - acc: 0.6555\n",
      "Epoch 00465: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 1.0675 - acc: 0.6556 - val_loss: 0.7322 - val_acc: 0.7829\n",
      "Epoch 466/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0551 - acc: 0.6603\n",
      "Epoch 00466: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.0550 - acc: 0.6603 - val_loss: 0.7318 - val_acc: 0.7848\n",
      "Epoch 467/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0602 - acc: 0.6592\n",
      "Epoch 00467: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.0602 - acc: 0.6592 - val_loss: 0.7312 - val_acc: 0.7873\n",
      "Epoch 468/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0640 - acc: 0.6533\n",
      "Epoch 00468: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0640 - acc: 0.6533 - val_loss: 0.7289 - val_acc: 0.7855\n",
      "Epoch 469/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0670 - acc: 0.6545\n",
      "Epoch 00469: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.0667 - acc: 0.6545 - val_loss: 0.7284 - val_acc: 0.7817\n",
      "Epoch 470/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0636 - acc: 0.6567\n",
      "Epoch 00470: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0637 - acc: 0.6566 - val_loss: 0.7273 - val_acc: 0.7876\n",
      "Epoch 471/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0630 - acc: 0.6575\n",
      "Epoch 00471: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 1.0633 - acc: 0.6574 - val_loss: 0.7220 - val_acc: 0.7885\n",
      "Epoch 472/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0613 - acc: 0.6549\n",
      "Epoch 00472: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0613 - acc: 0.6549 - val_loss: 0.7373 - val_acc: 0.7850\n",
      "Epoch 473/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0606 - acc: 0.6559\n",
      "Epoch 00473: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0606 - acc: 0.6559 - val_loss: 0.7268 - val_acc: 0.7857\n",
      "Epoch 474/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0565 - acc: 0.6582\n",
      "Epoch 00474: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 1.0564 - acc: 0.6582 - val_loss: 0.7311 - val_acc: 0.7850\n",
      "Epoch 475/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0597 - acc: 0.6579\n",
      "Epoch 00475: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0597 - acc: 0.6579 - val_loss: 0.7223 - val_acc: 0.7901\n",
      "Epoch 476/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0595 - acc: 0.6590\n",
      "Epoch 00476: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0595 - acc: 0.6590 - val_loss: 0.7278 - val_acc: 0.7852\n",
      "Epoch 477/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0586 - acc: 0.6592\n",
      "Epoch 00477: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0585 - acc: 0.6592 - val_loss: 0.7287 - val_acc: 0.7911\n",
      "Epoch 478/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0613 - acc: 0.6568\n",
      "Epoch 00478: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.0616 - acc: 0.6567 - val_loss: 0.7227 - val_acc: 0.7887\n",
      "Epoch 479/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0577 - acc: 0.6594\n",
      "Epoch 00479: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0577 - acc: 0.6594 - val_loss: 0.7254 - val_acc: 0.7894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0571 - acc: 0.6577\n",
      "Epoch 00480: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0570 - acc: 0.6577 - val_loss: 0.7333 - val_acc: 0.7878\n",
      "Epoch 481/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0585 - acc: 0.6557\n",
      "Epoch 00481: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 1.0585 - acc: 0.6557 - val_loss: 0.7249 - val_acc: 0.7873\n",
      "Epoch 482/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0597 - acc: 0.6580\n",
      "Epoch 00482: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.0600 - acc: 0.6579 - val_loss: 0.7258 - val_acc: 0.7845\n",
      "Epoch 483/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0595 - acc: 0.6565\n",
      "Epoch 00483: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0595 - acc: 0.6565 - val_loss: 0.7222 - val_acc: 0.7887\n",
      "Epoch 484/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0577 - acc: 0.6566\n",
      "Epoch 00484: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0578 - acc: 0.6565 - val_loss: 0.7211 - val_acc: 0.7901\n",
      "Epoch 485/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0574 - acc: 0.6570\n",
      "Epoch 00485: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0574 - acc: 0.6570 - val_loss: 0.7275 - val_acc: 0.7850\n",
      "Epoch 486/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0614 - acc: 0.6559\n",
      "Epoch 00486: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0613 - acc: 0.6560 - val_loss: 0.7263 - val_acc: 0.7859\n",
      "Epoch 487/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0586 - acc: 0.6560\n",
      "Epoch 00487: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.0587 - acc: 0.6560 - val_loss: 0.7367 - val_acc: 0.7817\n",
      "Epoch 488/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0518 - acc: 0.6610\n",
      "Epoch 00488: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.0522 - acc: 0.6611 - val_loss: 0.7219 - val_acc: 0.7862\n",
      "Epoch 489/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0540 - acc: 0.6596\n",
      "Epoch 00489: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 1.0541 - acc: 0.6596 - val_loss: 0.7232 - val_acc: 0.7869\n",
      "Epoch 490/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0610 - acc: 0.6575\n",
      "Epoch 00490: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0609 - acc: 0.6577 - val_loss: 0.7277 - val_acc: 0.7796\n",
      "Epoch 491/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0570 - acc: 0.6604\n",
      "Epoch 00491: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0575 - acc: 0.6603 - val_loss: 0.7321 - val_acc: 0.7862\n",
      "Epoch 492/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0557 - acc: 0.6585\n",
      "Epoch 00492: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0555 - acc: 0.6585 - val_loss: 0.7283 - val_acc: 0.7850\n",
      "Epoch 493/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0529 - acc: 0.6634\n",
      "Epoch 00493: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 21s 584us/sample - loss: 1.0529 - acc: 0.6634 - val_loss: 0.7267 - val_acc: 0.7852\n",
      "Epoch 494/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0567 - acc: 0.6604\n",
      "Epoch 00494: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 23s 623us/sample - loss: 1.0566 - acc: 0.6605 - val_loss: 0.7271 - val_acc: 0.7862\n",
      "Epoch 495/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0560 - acc: 0.6569\n",
      "Epoch 00495: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.0558 - acc: 0.6570 - val_loss: 0.7257 - val_acc: 0.7864\n",
      "Epoch 496/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0559 - acc: 0.6612\n",
      "Epoch 00496: val_loss did not improve from 0.72062\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.0557 - acc: 0.6613 - val_loss: 0.7328 - val_acc: 0.7834\n",
      "Epoch 497/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0580 - acc: 0.6567\n",
      "Epoch 00497: val_loss improved from 0.72062 to 0.71920, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv_checkpoint/497-0.7192.hdf5\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 1.0579 - acc: 0.6567 - val_loss: 0.7192 - val_acc: 0.7866\n",
      "Epoch 498/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0657 - acc: 0.6553\n",
      "Epoch 00498: val_loss did not improve from 0.71920\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.0655 - acc: 0.6553 - val_loss: 0.7387 - val_acc: 0.7855\n",
      "Epoch 499/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0562 - acc: 0.6587\n",
      "Epoch 00499: val_loss did not improve from 0.71920\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0562 - acc: 0.6587 - val_loss: 0.7226 - val_acc: 0.7838\n",
      "Epoch 500/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0490 - acc: 0.6594\n",
      "Epoch 00500: val_loss did not improve from 0.71920\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 1.0490 - acc: 0.6594 - val_loss: 0.7313 - val_acc: 0.7883\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 352us/sample - loss: 0.7881 - acc: 0.7618\n",
      "Loss: 0.7881466261322996 Accuracy: 0.7617861\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6827 - acc: 0.1090\n",
      "Epoch 00001: val_loss improved from inf to 2.51702, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/001-2.5170.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 2.6827 - acc: 0.1091 - val_loss: 2.5170 - val_acc: 0.2266\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4341 - acc: 0.1878\n",
      "Epoch 00002: val_loss improved from 2.51702 to 2.21746, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/002-2.2175.hdf5\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 2.4342 - acc: 0.1877 - val_loss: 2.2175 - val_acc: 0.3208\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2755 - acc: 0.2303\n",
      "Epoch 00003: val_loss improved from 2.21746 to 2.08291, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/003-2.0829.hdf5\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 2.2755 - acc: 0.2303 - val_loss: 2.0829 - val_acc: 0.3529\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1901 - acc: 0.2571\n",
      "Epoch 00004: val_loss improved from 2.08291 to 1.98948, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/004-1.9895.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 2.1902 - acc: 0.2571 - val_loss: 1.9895 - val_acc: 0.3755\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1210 - acc: 0.2846\n",
      "Epoch 00005: val_loss improved from 1.98948 to 1.90729, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/005-1.9073.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 2.1210 - acc: 0.2846 - val_loss: 1.9073 - val_acc: 0.4139\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.0419 - acc: 0.3067\n",
      "Epoch 00006: val_loss improved from 1.90729 to 1.81185, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/006-1.8118.hdf5\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 2.0418 - acc: 0.3068 - val_loss: 1.8118 - val_acc: 0.4461\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9744 - acc: 0.3298\n",
      "Epoch 00007: val_loss improved from 1.81185 to 1.72742, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/007-1.7274.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 1.9745 - acc: 0.3298 - val_loss: 1.7274 - val_acc: 0.4759\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9073 - acc: 0.3511\n",
      "Epoch 00008: val_loss improved from 1.72742 to 1.64258, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/008-1.6426.hdf5\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 1.9074 - acc: 0.3511 - val_loss: 1.6426 - val_acc: 0.4920\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8412 - acc: 0.3760\n",
      "Epoch 00009: val_loss improved from 1.64258 to 1.56711, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/009-1.5671.hdf5\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 1.8412 - acc: 0.3759 - val_loss: 1.5671 - val_acc: 0.5104\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7892 - acc: 0.3993\n",
      "Epoch 00010: val_loss improved from 1.56711 to 1.51052, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/010-1.5105.hdf5\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 1.7892 - acc: 0.3993 - val_loss: 1.5105 - val_acc: 0.5327\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7403 - acc: 0.4164\n",
      "Epoch 00011: val_loss improved from 1.51052 to 1.46040, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/011-1.4604.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.7404 - acc: 0.4164 - val_loss: 1.4604 - val_acc: 0.5535\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6947 - acc: 0.4296\n",
      "Epoch 00012: val_loss improved from 1.46040 to 1.40957, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/012-1.4096.hdf5\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 1.6943 - acc: 0.4298 - val_loss: 1.4096 - val_acc: 0.5714\n",
      "Epoch 13/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6593 - acc: 0.4392\n",
      "Epoch 00013: val_loss improved from 1.40957 to 1.35850, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/013-1.3585.hdf5\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 1.6592 - acc: 0.4393 - val_loss: 1.3585 - val_acc: 0.5772\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6158 - acc: 0.4611\n",
      "Epoch 00014: val_loss improved from 1.35850 to 1.31605, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/014-1.3160.hdf5\n",
      "36805/36805 [==============================] - 23s 611us/sample - loss: 1.6158 - acc: 0.4610 - val_loss: 1.3160 - val_acc: 0.5989\n",
      "Epoch 15/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5839 - acc: 0.4744\n",
      "Epoch 00015: val_loss improved from 1.31605 to 1.27734, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/015-1.2773.hdf5\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 1.5838 - acc: 0.4745 - val_loss: 1.2773 - val_acc: 0.6080\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5630 - acc: 0.4790\n",
      "Epoch 00016: val_loss improved from 1.27734 to 1.25697, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/016-1.2570.hdf5\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 1.5630 - acc: 0.4790 - val_loss: 1.2570 - val_acc: 0.6168\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5304 - acc: 0.4907\n",
      "Epoch 00017: val_loss improved from 1.25697 to 1.22777, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/017-1.2278.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.5304 - acc: 0.4907 - val_loss: 1.2278 - val_acc: 0.6252\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5036 - acc: 0.4979\n",
      "Epoch 00018: val_loss improved from 1.22777 to 1.20339, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/018-1.2034.hdf5\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 1.5035 - acc: 0.4979 - val_loss: 1.2034 - val_acc: 0.6355\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4782 - acc: 0.5125\n",
      "Epoch 00019: val_loss improved from 1.20339 to 1.16439, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/019-1.1644.hdf5\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 1.4783 - acc: 0.5124 - val_loss: 1.1644 - val_acc: 0.6422\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4545 - acc: 0.5201\n",
      "Epoch 00020: val_loss improved from 1.16439 to 1.14037, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/020-1.1404.hdf5\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.4545 - acc: 0.5201 - val_loss: 1.1404 - val_acc: 0.6520\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4361 - acc: 0.5246\n",
      "Epoch 00021: val_loss improved from 1.14037 to 1.12773, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/021-1.1277.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.4363 - acc: 0.5246 - val_loss: 1.1277 - val_acc: 0.6578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4129 - acc: 0.5324\n",
      "Epoch 00022: val_loss improved from 1.12773 to 1.11020, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/022-1.1102.hdf5\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 1.4129 - acc: 0.5324 - val_loss: 1.1102 - val_acc: 0.6667\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3940 - acc: 0.5396\n",
      "Epoch 00023: val_loss improved from 1.11020 to 1.08533, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/023-1.0853.hdf5\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 1.3940 - acc: 0.5396 - val_loss: 1.0853 - val_acc: 0.6690\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3733 - acc: 0.5463\n",
      "Epoch 00024: val_loss improved from 1.08533 to 1.06054, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/024-1.0605.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.3733 - acc: 0.5463 - val_loss: 1.0605 - val_acc: 0.6785\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3690 - acc: 0.5523\n",
      "Epoch 00025: val_loss improved from 1.06054 to 1.05413, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/025-1.0541.hdf5\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 1.3689 - acc: 0.5524 - val_loss: 1.0541 - val_acc: 0.6797\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3417 - acc: 0.5591\n",
      "Epoch 00026: val_loss improved from 1.05413 to 1.04902, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/026-1.0490.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 1.3416 - acc: 0.5592 - val_loss: 1.0490 - val_acc: 0.6893\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3285 - acc: 0.5625\n",
      "Epoch 00027: val_loss improved from 1.04902 to 1.01857, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/027-1.0186.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 1.3285 - acc: 0.5625 - val_loss: 1.0186 - val_acc: 0.6951\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3140 - acc: 0.5675\n",
      "Epoch 00028: val_loss improved from 1.01857 to 1.00706, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/028-1.0071.hdf5\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 1.3139 - acc: 0.5675 - val_loss: 1.0071 - val_acc: 0.6946\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2957 - acc: 0.5779\n",
      "Epoch 00029: val_loss improved from 1.00706 to 0.99466, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/029-0.9947.hdf5\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 1.2957 - acc: 0.5779 - val_loss: 0.9947 - val_acc: 0.7049\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2862 - acc: 0.5785\n",
      "Epoch 00030: val_loss improved from 0.99466 to 0.98067, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/030-0.9807.hdf5\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 1.2862 - acc: 0.5785 - val_loss: 0.9807 - val_acc: 0.7107\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2806 - acc: 0.5813\n",
      "Epoch 00031: val_loss improved from 0.98067 to 0.96474, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/031-0.9647.hdf5\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 1.2806 - acc: 0.5813 - val_loss: 0.9647 - val_acc: 0.7102\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2609 - acc: 0.5868\n",
      "Epoch 00032: val_loss improved from 0.96474 to 0.95777, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/032-0.9578.hdf5\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 1.2609 - acc: 0.5868 - val_loss: 0.9578 - val_acc: 0.7137\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2619 - acc: 0.5892\n",
      "Epoch 00033: val_loss improved from 0.95777 to 0.95369, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/033-0.9537.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.2619 - acc: 0.5892 - val_loss: 0.9537 - val_acc: 0.7128\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2461 - acc: 0.5941\n",
      "Epoch 00034: val_loss improved from 0.95369 to 0.93981, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/034-0.9398.hdf5\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 1.2461 - acc: 0.5941 - val_loss: 0.9398 - val_acc: 0.7151\n",
      "Epoch 35/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2363 - acc: 0.5960\n",
      "Epoch 00035: val_loss improved from 0.93981 to 0.93164, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/035-0.9316.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 1.2364 - acc: 0.5960 - val_loss: 0.9316 - val_acc: 0.7230\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2293 - acc: 0.5972\n",
      "Epoch 00036: val_loss improved from 0.93164 to 0.91819, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/036-0.9182.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.2294 - acc: 0.5971 - val_loss: 0.9182 - val_acc: 0.7247\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2216 - acc: 0.6020\n",
      "Epoch 00037: val_loss improved from 0.91819 to 0.91193, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/037-0.9119.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 1.2215 - acc: 0.6020 - val_loss: 0.9119 - val_acc: 0.7261\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2100 - acc: 0.6059\n",
      "Epoch 00038: val_loss did not improve from 0.91193\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 1.2099 - acc: 0.6059 - val_loss: 0.9120 - val_acc: 0.7277\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2033 - acc: 0.6099\n",
      "Epoch 00039: val_loss did not improve from 0.91193\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.2033 - acc: 0.6099 - val_loss: 0.9242 - val_acc: 0.7242\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2025 - acc: 0.6100\n",
      "Epoch 00040: val_loss improved from 0.91193 to 0.88546, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/040-0.8855.hdf5\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 1.2022 - acc: 0.6099 - val_loss: 0.8855 - val_acc: 0.7321\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1950 - acc: 0.6108\n",
      "Epoch 00041: val_loss improved from 0.88546 to 0.87564, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/041-0.8756.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 1.1949 - acc: 0.6108 - val_loss: 0.8756 - val_acc: 0.7345\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1802 - acc: 0.6154\n",
      "Epoch 00042: val_loss did not improve from 0.87564\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 1.1802 - acc: 0.6154 - val_loss: 0.8872 - val_acc: 0.7335\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1768 - acc: 0.6171\n",
      "Epoch 00043: val_loss improved from 0.87564 to 0.86349, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/043-0.8635.hdf5\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 1.1768 - acc: 0.6171 - val_loss: 0.8635 - val_acc: 0.7407\n",
      "Epoch 44/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1786 - acc: 0.6185\n",
      "Epoch 00044: val_loss improved from 0.86349 to 0.85803, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/044-0.8580.hdf5\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 1.1782 - acc: 0.6186 - val_loss: 0.8580 - val_acc: 0.7428\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1646 - acc: 0.6189\n",
      "Epoch 00045: val_loss did not improve from 0.85803\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 1.1645 - acc: 0.6189 - val_loss: 0.8719 - val_acc: 0.7405\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1640 - acc: 0.6224\n",
      "Epoch 00046: val_loss improved from 0.85803 to 0.85382, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/046-0.8538.hdf5\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 1.1640 - acc: 0.6224 - val_loss: 0.8538 - val_acc: 0.7477\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1523 - acc: 0.6248\n",
      "Epoch 00047: val_loss improved from 0.85382 to 0.84479, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/047-0.8448.hdf5\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 1.1524 - acc: 0.6248 - val_loss: 0.8448 - val_acc: 0.7463\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1444 - acc: 0.6279\n",
      "Epoch 00048: val_loss improved from 0.84479 to 0.84205, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/048-0.8421.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 1.1444 - acc: 0.6279 - val_loss: 0.8421 - val_acc: 0.7470\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1406 - acc: 0.6273\n",
      "Epoch 00049: val_loss improved from 0.84205 to 0.83187, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/049-0.8319.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.1406 - acc: 0.6273 - val_loss: 0.8319 - val_acc: 0.7526\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1428 - acc: 0.6285\n",
      "Epoch 00050: val_loss improved from 0.83187 to 0.82662, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/050-0.8266.hdf5\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 1.1429 - acc: 0.6285 - val_loss: 0.8266 - val_acc: 0.7529\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1373 - acc: 0.6313\n",
      "Epoch 00051: val_loss improved from 0.82662 to 0.82265, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/051-0.8227.hdf5\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 1.1369 - acc: 0.6313 - val_loss: 0.8227 - val_acc: 0.7522\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1289 - acc: 0.6334\n",
      "Epoch 00052: val_loss improved from 0.82265 to 0.82141, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/052-0.8214.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.1289 - acc: 0.6334 - val_loss: 0.8214 - val_acc: 0.7526\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1227 - acc: 0.6354\n",
      "Epoch 00053: val_loss improved from 0.82141 to 0.80508, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/053-0.8051.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 1.1227 - acc: 0.6354 - val_loss: 0.8051 - val_acc: 0.7559\n",
      "Epoch 54/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1208 - acc: 0.6349\n",
      "Epoch 00054: val_loss did not improve from 0.80508\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 1.1212 - acc: 0.6349 - val_loss: 0.8152 - val_acc: 0.7510\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1213 - acc: 0.6369\n",
      "Epoch 00055: val_loss did not improve from 0.80508\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.1213 - acc: 0.6370 - val_loss: 0.8122 - val_acc: 0.7552\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1160 - acc: 0.6373\n",
      "Epoch 00056: val_loss improved from 0.80508 to 0.80029, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/056-0.8003.hdf5\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 1.1160 - acc: 0.6373 - val_loss: 0.8003 - val_acc: 0.7591\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1045 - acc: 0.6429\n",
      "Epoch 00057: val_loss did not improve from 0.80029\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 1.1045 - acc: 0.6428 - val_loss: 0.8118 - val_acc: 0.7589\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0983 - acc: 0.6451\n",
      "Epoch 00058: val_loss improved from 0.80029 to 0.79543, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/058-0.7954.hdf5\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 1.0984 - acc: 0.6450 - val_loss: 0.7954 - val_acc: 0.7566\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1078 - acc: 0.6412\n",
      "Epoch 00059: val_loss improved from 0.79543 to 0.79416, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/059-0.7942.hdf5\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 1.1078 - acc: 0.6411 - val_loss: 0.7942 - val_acc: 0.7615\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1043 - acc: 0.6425\n",
      "Epoch 00060: val_loss improved from 0.79416 to 0.79169, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/060-0.7917.hdf5\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 1.1041 - acc: 0.6426 - val_loss: 0.7917 - val_acc: 0.7605\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1007 - acc: 0.6485\n",
      "Epoch 00061: val_loss improved from 0.79169 to 0.78662, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/061-0.7866.hdf5\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 1.1006 - acc: 0.6485 - val_loss: 0.7866 - val_acc: 0.7605\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0965 - acc: 0.6461\n",
      "Epoch 00062: val_loss improved from 0.78662 to 0.78437, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/062-0.7844.hdf5\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 1.0967 - acc: 0.6461 - val_loss: 0.7844 - val_acc: 0.7596\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0889 - acc: 0.6511\n",
      "Epoch 00063: val_loss improved from 0.78437 to 0.77942, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/063-0.7794.hdf5\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 1.0890 - acc: 0.6511 - val_loss: 0.7794 - val_acc: 0.7650\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0808 - acc: 0.6493\n",
      "Epoch 00064: val_loss improved from 0.77942 to 0.76608, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/064-0.7661.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0807 - acc: 0.6493 - val_loss: 0.7661 - val_acc: 0.7673\n",
      "Epoch 65/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0772 - acc: 0.6520\n",
      "Epoch 00065: val_loss improved from 0.76608 to 0.76593, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/065-0.7659.hdf5\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 1.0775 - acc: 0.6519 - val_loss: 0.7659 - val_acc: 0.7629\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0845 - acc: 0.6503\n",
      "Epoch 00066: val_loss improved from 0.76593 to 0.76186, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/066-0.7619.hdf5\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 1.0852 - acc: 0.6501 - val_loss: 0.7619 - val_acc: 0.7624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0765 - acc: 0.6510\n",
      "Epoch 00067: val_loss did not improve from 0.76186\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 1.0766 - acc: 0.6509 - val_loss: 0.7725 - val_acc: 0.7622\n",
      "Epoch 68/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0697 - acc: 0.6572\n",
      "Epoch 00068: val_loss did not improve from 0.76186\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 1.0699 - acc: 0.6572 - val_loss: 0.7807 - val_acc: 0.7624\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0729 - acc: 0.6568\n",
      "Epoch 00069: val_loss did not improve from 0.76186\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 1.0729 - acc: 0.6568 - val_loss: 0.7652 - val_acc: 0.7703\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0709 - acc: 0.6542\n",
      "Epoch 00070: val_loss improved from 0.76186 to 0.76044, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/070-0.7604.hdf5\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 1.0709 - acc: 0.6542 - val_loss: 0.7604 - val_acc: 0.7675\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0603 - acc: 0.6568\n",
      "Epoch 00071: val_loss improved from 0.76044 to 0.74947, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/071-0.7495.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0603 - acc: 0.6568 - val_loss: 0.7495 - val_acc: 0.7703\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0650 - acc: 0.6558\n",
      "Epoch 00072: val_loss did not improve from 0.74947\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 1.0650 - acc: 0.6559 - val_loss: 0.7525 - val_acc: 0.7689\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0559 - acc: 0.6600\n",
      "Epoch 00073: val_loss improved from 0.74947 to 0.74676, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/073-0.7468.hdf5\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 1.0559 - acc: 0.6600 - val_loss: 0.7468 - val_acc: 0.7734\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0551 - acc: 0.6606\n",
      "Epoch 00074: val_loss improved from 0.74676 to 0.73775, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/074-0.7378.hdf5\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 1.0551 - acc: 0.6606 - val_loss: 0.7378 - val_acc: 0.7689\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0574 - acc: 0.6610\n",
      "Epoch 00075: val_loss did not improve from 0.73775\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 1.0573 - acc: 0.6610 - val_loss: 0.7518 - val_acc: 0.7699\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0522 - acc: 0.6601\n",
      "Epoch 00076: val_loss did not improve from 0.73775\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 1.0522 - acc: 0.6601 - val_loss: 0.7475 - val_acc: 0.7741\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0450 - acc: 0.6643\n",
      "Epoch 00077: val_loss improved from 0.73775 to 0.73101, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/077-0.7310.hdf5\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 1.0450 - acc: 0.6643 - val_loss: 0.7310 - val_acc: 0.7745\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0582 - acc: 0.6570\n",
      "Epoch 00078: val_loss improved from 0.73101 to 0.73090, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/078-0.7309.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 1.0582 - acc: 0.6570 - val_loss: 0.7309 - val_acc: 0.7757\n",
      "Epoch 79/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0472 - acc: 0.6637\n",
      "Epoch 00079: val_loss improved from 0.73090 to 0.72943, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/079-0.7294.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 1.0473 - acc: 0.6635 - val_loss: 0.7294 - val_acc: 0.7720\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0397 - acc: 0.6657\n",
      "Epoch 00080: val_loss improved from 0.72943 to 0.72691, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/080-0.7269.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0396 - acc: 0.6657 - val_loss: 0.7269 - val_acc: 0.7768\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0410 - acc: 0.6652\n",
      "Epoch 00081: val_loss did not improve from 0.72691\n",
      "36805/36805 [==============================] - 20s 552us/sample - loss: 1.0410 - acc: 0.6653 - val_loss: 0.7339 - val_acc: 0.7761\n",
      "Epoch 82/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0425 - acc: 0.6653\n",
      "Epoch 00082: val_loss did not improve from 0.72691\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0423 - acc: 0.6655 - val_loss: 0.7269 - val_acc: 0.7775\n",
      "Epoch 83/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0391 - acc: 0.6650\n",
      "Epoch 00083: val_loss did not improve from 0.72691\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0392 - acc: 0.6649 - val_loss: 0.7298 - val_acc: 0.7815\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0330 - acc: 0.6680\n",
      "Epoch 00084: val_loss did not improve from 0.72691\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0331 - acc: 0.6679 - val_loss: 0.7317 - val_acc: 0.7768\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0333 - acc: 0.6664\n",
      "Epoch 00085: val_loss did not improve from 0.72691\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 1.0333 - acc: 0.6663 - val_loss: 0.7303 - val_acc: 0.7778\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0274 - acc: 0.6704\n",
      "Epoch 00086: val_loss did not improve from 0.72691\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 1.0274 - acc: 0.6704 - val_loss: 0.7275 - val_acc: 0.7789\n",
      "Epoch 87/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0218 - acc: 0.6727\n",
      "Epoch 00087: val_loss improved from 0.72691 to 0.71156, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/087-0.7116.hdf5\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 1.0218 - acc: 0.6728 - val_loss: 0.7116 - val_acc: 0.7810\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0266 - acc: 0.6696\n",
      "Epoch 00088: val_loss did not improve from 0.71156\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0267 - acc: 0.6696 - val_loss: 0.7236 - val_acc: 0.7761\n",
      "Epoch 89/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0201 - acc: 0.6703\n",
      "Epoch 00089: val_loss improved from 0.71156 to 0.70346, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/089-0.7035.hdf5\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 1.0201 - acc: 0.6703 - val_loss: 0.7035 - val_acc: 0.7845\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0191 - acc: 0.6714\n",
      "Epoch 00090: val_loss did not improve from 0.70346\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0191 - acc: 0.6713 - val_loss: 0.7100 - val_acc: 0.7848\n",
      "Epoch 91/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0178 - acc: 0.6723\n",
      "Epoch 00091: val_loss improved from 0.70346 to 0.70226, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/091-0.7023.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 1.0177 - acc: 0.6722 - val_loss: 0.7023 - val_acc: 0.7862\n",
      "Epoch 92/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0151 - acc: 0.6716\n",
      "Epoch 00092: val_loss did not improve from 0.70226\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 1.0151 - acc: 0.6716 - val_loss: 0.7190 - val_acc: 0.7822\n",
      "Epoch 93/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0183 - acc: 0.6728\n",
      "Epoch 00093: val_loss improved from 0.70226 to 0.69708, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/093-0.6971.hdf5\n",
      "36805/36805 [==============================] - 23s 611us/sample - loss: 1.0186 - acc: 0.6728 - val_loss: 0.6971 - val_acc: 0.7813\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0098 - acc: 0.6771\n",
      "Epoch 00094: val_loss did not improve from 0.69708\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.0099 - acc: 0.6771 - val_loss: 0.7008 - val_acc: 0.7890\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0065 - acc: 0.6780\n",
      "Epoch 00095: val_loss did not improve from 0.69708\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 1.0067 - acc: 0.6780 - val_loss: 0.6981 - val_acc: 0.7922\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0185 - acc: 0.6725\n",
      "Epoch 00096: val_loss did not improve from 0.69708\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 1.0184 - acc: 0.6725 - val_loss: 0.6973 - val_acc: 0.7894\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0096 - acc: 0.6788\n",
      "Epoch 00097: val_loss improved from 0.69708 to 0.68999, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/097-0.6900.hdf5\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 1.0096 - acc: 0.6788 - val_loss: 0.6900 - val_acc: 0.7929\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0060 - acc: 0.6766\n",
      "Epoch 00098: val_loss did not improve from 0.68999\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 1.0060 - acc: 0.6766 - val_loss: 0.6917 - val_acc: 0.7920\n",
      "Epoch 99/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0012 - acc: 0.6768\n",
      "Epoch 00099: val_loss improved from 0.68999 to 0.68441, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/099-0.6844.hdf5\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 1.0013 - acc: 0.6767 - val_loss: 0.6844 - val_acc: 0.7906\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0005 - acc: 0.6784\n",
      "Epoch 00100: val_loss did not improve from 0.68441\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 1.0004 - acc: 0.6784 - val_loss: 0.6880 - val_acc: 0.7927\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9986 - acc: 0.6774\n",
      "Epoch 00101: val_loss did not improve from 0.68441\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.9986 - acc: 0.6774 - val_loss: 0.6881 - val_acc: 0.7922\n",
      "Epoch 102/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9866 - acc: 0.6831\n",
      "Epoch 00102: val_loss did not improve from 0.68441\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.9865 - acc: 0.6831 - val_loss: 0.6848 - val_acc: 0.7913\n",
      "Epoch 103/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9939 - acc: 0.6796\n",
      "Epoch 00103: val_loss did not improve from 0.68441\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.9945 - acc: 0.6793 - val_loss: 0.6879 - val_acc: 0.7915\n",
      "Epoch 104/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9948 - acc: 0.6852\n",
      "Epoch 00104: val_loss improved from 0.68441 to 0.68044, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/104-0.6804.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.9949 - acc: 0.6852 - val_loss: 0.6804 - val_acc: 0.7939\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9939 - acc: 0.6812\n",
      "Epoch 00105: val_loss did not improve from 0.68044\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.9940 - acc: 0.6812 - val_loss: 0.6892 - val_acc: 0.7922\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9840 - acc: 0.6825\n",
      "Epoch 00106: val_loss improved from 0.68044 to 0.67760, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/106-0.6776.hdf5\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.9840 - acc: 0.6825 - val_loss: 0.6776 - val_acc: 0.7955\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9930 - acc: 0.6806\n",
      "Epoch 00107: val_loss improved from 0.67760 to 0.67726, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/107-0.6773.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.9930 - acc: 0.6805 - val_loss: 0.6773 - val_acc: 0.8001\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9925 - acc: 0.6793\n",
      "Epoch 00108: val_loss did not improve from 0.67726\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.9924 - acc: 0.6794 - val_loss: 0.6843 - val_acc: 0.7885\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9881 - acc: 0.6834\n",
      "Epoch 00109: val_loss did not improve from 0.67726\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.9882 - acc: 0.6834 - val_loss: 0.6805 - val_acc: 0.7936\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9843 - acc: 0.6861\n",
      "Epoch 00110: val_loss did not improve from 0.67726\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.9843 - acc: 0.6861 - val_loss: 0.6839 - val_acc: 0.7962\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9828 - acc: 0.6871\n",
      "Epoch 00111: val_loss improved from 0.67726 to 0.67562, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/111-0.6756.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.9827 - acc: 0.6871 - val_loss: 0.6756 - val_acc: 0.7973\n",
      "Epoch 112/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9853 - acc: 0.6842\n",
      "Epoch 00112: val_loss improved from 0.67562 to 0.66657, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/112-0.6666.hdf5\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.9857 - acc: 0.6839 - val_loss: 0.6666 - val_acc: 0.7943\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9764 - acc: 0.6858\n",
      "Epoch 00113: val_loss improved from 0.66657 to 0.65638, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/113-0.6564.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.9763 - acc: 0.6859 - val_loss: 0.6564 - val_acc: 0.8006\n",
      "Epoch 114/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9814 - acc: 0.6852\n",
      "Epoch 00114: val_loss did not improve from 0.65638\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.9812 - acc: 0.6853 - val_loss: 0.6718 - val_acc: 0.7929\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9794 - acc: 0.6867\n",
      "Epoch 00115: val_loss did not improve from 0.65638\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.9793 - acc: 0.6868 - val_loss: 0.6715 - val_acc: 0.7952\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9733 - acc: 0.6877\n",
      "Epoch 00116: val_loss did not improve from 0.65638\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.9733 - acc: 0.6877 - val_loss: 0.6684 - val_acc: 0.7978\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9785 - acc: 0.6903\n",
      "Epoch 00117: val_loss did not improve from 0.65638\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 0.9784 - acc: 0.6903 - val_loss: 0.6675 - val_acc: 0.7973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9792 - acc: 0.6868\n",
      "Epoch 00118: val_loss did not improve from 0.65638\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.9792 - acc: 0.6868 - val_loss: 0.6624 - val_acc: 0.7978\n",
      "Epoch 119/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9761 - acc: 0.6899\n",
      "Epoch 00119: val_loss did not improve from 0.65638\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 0.9758 - acc: 0.6899 - val_loss: 0.6597 - val_acc: 0.7992\n",
      "Epoch 120/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9738 - acc: 0.6888\n",
      "Epoch 00120: val_loss did not improve from 0.65638\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.9743 - acc: 0.6887 - val_loss: 0.6564 - val_acc: 0.8022\n",
      "Epoch 121/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9641 - acc: 0.6905\n",
      "Epoch 00121: val_loss did not improve from 0.65638\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.9640 - acc: 0.6906 - val_loss: 0.6631 - val_acc: 0.7987\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9704 - acc: 0.6913\n",
      "Epoch 00122: val_loss did not improve from 0.65638\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.9705 - acc: 0.6912 - val_loss: 0.6609 - val_acc: 0.7999\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9678 - acc: 0.6892\n",
      "Epoch 00123: val_loss improved from 0.65638 to 0.65017, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/123-0.6502.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.9678 - acc: 0.6892 - val_loss: 0.6502 - val_acc: 0.8055\n",
      "Epoch 124/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9677 - acc: 0.6911\n",
      "Epoch 00124: val_loss did not improve from 0.65017\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.9674 - acc: 0.6912 - val_loss: 0.6757 - val_acc: 0.7945\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9669 - acc: 0.6904\n",
      "Epoch 00125: val_loss did not improve from 0.65017\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.9669 - acc: 0.6904 - val_loss: 0.6580 - val_acc: 0.7971\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9606 - acc: 0.6895\n",
      "Epoch 00126: val_loss improved from 0.65017 to 0.64264, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/126-0.6426.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.9605 - acc: 0.6896 - val_loss: 0.6426 - val_acc: 0.8062\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9661 - acc: 0.6916\n",
      "Epoch 00127: val_loss did not improve from 0.64264\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.9661 - acc: 0.6916 - val_loss: 0.6535 - val_acc: 0.8006\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9631 - acc: 0.6942\n",
      "Epoch 00128: val_loss did not improve from 0.64264\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.9631 - acc: 0.6942 - val_loss: 0.6484 - val_acc: 0.7999\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9595 - acc: 0.6906\n",
      "Epoch 00129: val_loss did not improve from 0.64264\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.9594 - acc: 0.6906 - val_loss: 0.6470 - val_acc: 0.8057\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9615 - acc: 0.6931\n",
      "Epoch 00130: val_loss did not improve from 0.64264\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.9616 - acc: 0.6931 - val_loss: 0.6462 - val_acc: 0.8011\n",
      "Epoch 131/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9589 - acc: 0.6956\n",
      "Epoch 00131: val_loss did not improve from 0.64264\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.9593 - acc: 0.6956 - val_loss: 0.6455 - val_acc: 0.8041\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9569 - acc: 0.6919\n",
      "Epoch 00132: val_loss did not improve from 0.64264\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.9569 - acc: 0.6919 - val_loss: 0.6565 - val_acc: 0.7973\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9605 - acc: 0.6934\n",
      "Epoch 00133: val_loss improved from 0.64264 to 0.64233, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/133-0.6423.hdf5\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.9605 - acc: 0.6934 - val_loss: 0.6423 - val_acc: 0.8055\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9499 - acc: 0.6967\n",
      "Epoch 00134: val_loss did not improve from 0.64233\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.9500 - acc: 0.6966 - val_loss: 0.6449 - val_acc: 0.8055\n",
      "Epoch 135/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9586 - acc: 0.6938\n",
      "Epoch 00135: val_loss did not improve from 0.64233\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.9589 - acc: 0.6938 - val_loss: 0.6433 - val_acc: 0.8046\n",
      "Epoch 136/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9599 - acc: 0.6921\n",
      "Epoch 00136: val_loss did not improve from 0.64233\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.9600 - acc: 0.6920 - val_loss: 0.6466 - val_acc: 0.8053\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9498 - acc: 0.6971\n",
      "Epoch 00137: val_loss improved from 0.64233 to 0.64213, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/137-0.6421.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.9498 - acc: 0.6971 - val_loss: 0.6421 - val_acc: 0.8076\n",
      "Epoch 138/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9537 - acc: 0.6947\n",
      "Epoch 00138: val_loss improved from 0.64213 to 0.63983, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/138-0.6398.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.9538 - acc: 0.6948 - val_loss: 0.6398 - val_acc: 0.8043\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9468 - acc: 0.6962\n",
      "Epoch 00139: val_loss did not improve from 0.63983\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.9467 - acc: 0.6962 - val_loss: 0.6433 - val_acc: 0.8025\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9461 - acc: 0.6974\n",
      "Epoch 00140: val_loss improved from 0.63983 to 0.63455, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/140-0.6345.hdf5\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 0.9461 - acc: 0.6974 - val_loss: 0.6345 - val_acc: 0.8095\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9476 - acc: 0.6971\n",
      "Epoch 00141: val_loss improved from 0.63455 to 0.62908, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/141-0.6291.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.9476 - acc: 0.6971 - val_loss: 0.6291 - val_acc: 0.8085\n",
      "Epoch 142/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9492 - acc: 0.6959\n",
      "Epoch 00142: val_loss did not improve from 0.62908\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.9492 - acc: 0.6959 - val_loss: 0.6342 - val_acc: 0.8095\n",
      "Epoch 143/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9455 - acc: 0.6987\n",
      "Epoch 00143: val_loss improved from 0.62908 to 0.62849, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/143-0.6285.hdf5\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.9455 - acc: 0.6988 - val_loss: 0.6285 - val_acc: 0.8106\n",
      "Epoch 144/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9412 - acc: 0.6988\n",
      "Epoch 00144: val_loss did not improve from 0.62849\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.9413 - acc: 0.6988 - val_loss: 0.6476 - val_acc: 0.8048\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9416 - acc: 0.7011\n",
      "Epoch 00145: val_loss did not improve from 0.62849\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.9415 - acc: 0.7012 - val_loss: 0.6296 - val_acc: 0.8081\n",
      "Epoch 146/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9414 - acc: 0.7013\n",
      "Epoch 00146: val_loss did not improve from 0.62849\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.9419 - acc: 0.7013 - val_loss: 0.6365 - val_acc: 0.8099\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9397 - acc: 0.7002\n",
      "Epoch 00147: val_loss improved from 0.62849 to 0.62843, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/147-0.6284.hdf5\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 0.9396 - acc: 0.7002 - val_loss: 0.6284 - val_acc: 0.8104\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9401 - acc: 0.7002\n",
      "Epoch 00148: val_loss improved from 0.62843 to 0.62437, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/148-0.6244.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.9401 - acc: 0.7002 - val_loss: 0.6244 - val_acc: 0.8118\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9353 - acc: 0.7000\n",
      "Epoch 00149: val_loss did not improve from 0.62437\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.9352 - acc: 0.7000 - val_loss: 0.6324 - val_acc: 0.8060\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9396 - acc: 0.7009\n",
      "Epoch 00150: val_loss did not improve from 0.62437\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.9395 - acc: 0.7010 - val_loss: 0.6332 - val_acc: 0.8088\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9370 - acc: 0.7033\n",
      "Epoch 00151: val_loss did not improve from 0.62437\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.9369 - acc: 0.7034 - val_loss: 0.6312 - val_acc: 0.8097\n",
      "Epoch 152/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9308 - acc: 0.7038\n",
      "Epoch 00152: val_loss improved from 0.62437 to 0.61924, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/152-0.6192.hdf5\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.9312 - acc: 0.7037 - val_loss: 0.6192 - val_acc: 0.8123\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9311 - acc: 0.7031\n",
      "Epoch 00153: val_loss did not improve from 0.61924\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.9310 - acc: 0.7031 - val_loss: 0.6292 - val_acc: 0.8088\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9327 - acc: 0.7032\n",
      "Epoch 00154: val_loss did not improve from 0.61924\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.9327 - acc: 0.7032 - val_loss: 0.6236 - val_acc: 0.8095\n",
      "Epoch 155/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9286 - acc: 0.7049\n",
      "Epoch 00155: val_loss improved from 0.61924 to 0.61862, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/155-0.6186.hdf5\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.9283 - acc: 0.7050 - val_loss: 0.6186 - val_acc: 0.8160\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9293 - acc: 0.7006\n",
      "Epoch 00156: val_loss did not improve from 0.61862\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.9295 - acc: 0.7006 - val_loss: 0.6204 - val_acc: 0.8109\n",
      "Epoch 157/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9287 - acc: 0.7054\n",
      "Epoch 00157: val_loss improved from 0.61862 to 0.61230, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/157-0.6123.hdf5\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.9283 - acc: 0.7055 - val_loss: 0.6123 - val_acc: 0.8153\n",
      "Epoch 158/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9285 - acc: 0.7036\n",
      "Epoch 00158: val_loss did not improve from 0.61230\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.9285 - acc: 0.7035 - val_loss: 0.6309 - val_acc: 0.8132\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9249 - acc: 0.7061\n",
      "Epoch 00159: val_loss did not improve from 0.61230\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.9250 - acc: 0.7061 - val_loss: 0.6135 - val_acc: 0.8160\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9273 - acc: 0.7048\n",
      "Epoch 00160: val_loss improved from 0.61230 to 0.60915, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/160-0.6092.hdf5\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.9272 - acc: 0.7048 - val_loss: 0.6092 - val_acc: 0.8192\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9228 - acc: 0.7083\n",
      "Epoch 00161: val_loss did not improve from 0.60915\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 0.9227 - acc: 0.7084 - val_loss: 0.6132 - val_acc: 0.8137\n",
      "Epoch 162/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9290 - acc: 0.7046\n",
      "Epoch 00162: val_loss did not improve from 0.60915\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 0.9294 - acc: 0.7045 - val_loss: 0.6144 - val_acc: 0.8143\n",
      "Epoch 163/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9197 - acc: 0.7063\n",
      "Epoch 00163: val_loss did not improve from 0.60915\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.9192 - acc: 0.7066 - val_loss: 0.6161 - val_acc: 0.8120\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9137 - acc: 0.7085\n",
      "Epoch 00164: val_loss did not improve from 0.60915\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.9136 - acc: 0.7086 - val_loss: 0.6095 - val_acc: 0.8132\n",
      "Epoch 165/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9222 - acc: 0.7047\n",
      "Epoch 00165: val_loss did not improve from 0.60915\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.9218 - acc: 0.7049 - val_loss: 0.6116 - val_acc: 0.8139\n",
      "Epoch 166/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9146 - acc: 0.7076\n",
      "Epoch 00166: val_loss improved from 0.60915 to 0.60547, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/166-0.6055.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.9142 - acc: 0.7078 - val_loss: 0.6055 - val_acc: 0.8197\n",
      "Epoch 167/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9143 - acc: 0.7067\n",
      "Epoch 00167: val_loss did not improve from 0.60547\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.9145 - acc: 0.7067 - val_loss: 0.6189 - val_acc: 0.8099\n",
      "Epoch 168/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9191 - acc: 0.7077\n",
      "Epoch 00168: val_loss did not improve from 0.60547\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.9190 - acc: 0.7078 - val_loss: 0.6055 - val_acc: 0.8185\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9162 - acc: 0.7053\n",
      "Epoch 00169: val_loss did not improve from 0.60547\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.9163 - acc: 0.7053 - val_loss: 0.6137 - val_acc: 0.8174\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9128 - acc: 0.7090\n",
      "Epoch 00170: val_loss did not improve from 0.60547\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.9127 - acc: 0.7091 - val_loss: 0.6068 - val_acc: 0.8143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9160 - acc: 0.7081\n",
      "Epoch 00171: val_loss did not improve from 0.60547\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 0.9160 - acc: 0.7081 - val_loss: 0.6060 - val_acc: 0.8202\n",
      "Epoch 172/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9122 - acc: 0.7063\n",
      "Epoch 00172: val_loss improved from 0.60547 to 0.60468, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/172-0.6047.hdf5\n",
      "36805/36805 [==============================] - 23s 632us/sample - loss: 0.9121 - acc: 0.7063 - val_loss: 0.6047 - val_acc: 0.8164\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9149 - acc: 0.7109\n",
      "Epoch 00173: val_loss improved from 0.60468 to 0.60320, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/173-0.6032.hdf5\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.9148 - acc: 0.7110 - val_loss: 0.6032 - val_acc: 0.8176\n",
      "Epoch 174/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9099 - acc: 0.7094\n",
      "Epoch 00174: val_loss did not improve from 0.60320\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.9096 - acc: 0.7096 - val_loss: 0.6040 - val_acc: 0.8148\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9133 - acc: 0.7100\n",
      "Epoch 00175: val_loss did not improve from 0.60320\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.9132 - acc: 0.7101 - val_loss: 0.6098 - val_acc: 0.8153\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9017 - acc: 0.7106\n",
      "Epoch 00176: val_loss did not improve from 0.60320\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.9016 - acc: 0.7106 - val_loss: 0.6068 - val_acc: 0.8162\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9100 - acc: 0.7095\n",
      "Epoch 00177: val_loss improved from 0.60320 to 0.59562, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/177-0.5956.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.9100 - acc: 0.7096 - val_loss: 0.5956 - val_acc: 0.8218\n",
      "Epoch 178/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9059 - acc: 0.7111\n",
      "Epoch 00178: val_loss improved from 0.59562 to 0.59497, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/178-0.5950.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.9063 - acc: 0.7112 - val_loss: 0.5950 - val_acc: 0.8218\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9135 - acc: 0.7070\n",
      "Epoch 00179: val_loss did not improve from 0.59497\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.9135 - acc: 0.7071 - val_loss: 0.5953 - val_acc: 0.8248\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9045 - acc: 0.7121\n",
      "Epoch 00180: val_loss did not improve from 0.59497\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.9044 - acc: 0.7122 - val_loss: 0.5961 - val_acc: 0.8216\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9039 - acc: 0.7102\n",
      "Epoch 00181: val_loss did not improve from 0.59497\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.9039 - acc: 0.7102 - val_loss: 0.6026 - val_acc: 0.8167\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8992 - acc: 0.7178\n",
      "Epoch 00182: val_loss did not improve from 0.59497\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.8992 - acc: 0.7178 - val_loss: 0.5964 - val_acc: 0.8218\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8973 - acc: 0.7144\n",
      "Epoch 00183: val_loss improved from 0.59497 to 0.59238, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/183-0.5924.hdf5\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 0.8973 - acc: 0.7144 - val_loss: 0.5924 - val_acc: 0.8227\n",
      "Epoch 184/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8982 - acc: 0.7133\n",
      "Epoch 00184: val_loss improved from 0.59238 to 0.59034, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/184-0.5903.hdf5\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.8983 - acc: 0.7132 - val_loss: 0.5903 - val_acc: 0.8274\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8971 - acc: 0.7149\n",
      "Epoch 00185: val_loss did not improve from 0.59034\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8970 - acc: 0.7149 - val_loss: 0.5909 - val_acc: 0.8216\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9007 - acc: 0.7115\n",
      "Epoch 00186: val_loss improved from 0.59034 to 0.58926, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/186-0.5893.hdf5\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.9009 - acc: 0.7115 - val_loss: 0.5893 - val_acc: 0.8220\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8942 - acc: 0.7157\n",
      "Epoch 00187: val_loss improved from 0.58926 to 0.58416, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/187-0.5842.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8942 - acc: 0.7157 - val_loss: 0.5842 - val_acc: 0.8258\n",
      "Epoch 188/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8991 - acc: 0.7149\n",
      "Epoch 00188: val_loss did not improve from 0.58416\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.8992 - acc: 0.7150 - val_loss: 0.5960 - val_acc: 0.8190\n",
      "Epoch 189/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8927 - acc: 0.7150\n",
      "Epoch 00189: val_loss did not improve from 0.58416\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8925 - acc: 0.7151 - val_loss: 0.5914 - val_acc: 0.8209\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8929 - acc: 0.7170\n",
      "Epoch 00190: val_loss did not improve from 0.58416\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.8928 - acc: 0.7170 - val_loss: 0.5964 - val_acc: 0.8227\n",
      "Epoch 191/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9063 - acc: 0.7100\n",
      "Epoch 00191: val_loss did not improve from 0.58416\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.9063 - acc: 0.7101 - val_loss: 0.5942 - val_acc: 0.8223\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9010 - acc: 0.7120\n",
      "Epoch 00192: val_loss did not improve from 0.58416\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.9012 - acc: 0.7120 - val_loss: 0.5954 - val_acc: 0.8230\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8903 - acc: 0.7146\n",
      "Epoch 00193: val_loss did not improve from 0.58416\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.8902 - acc: 0.7146 - val_loss: 0.5900 - val_acc: 0.8237\n",
      "Epoch 194/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8852 - acc: 0.7165\n",
      "Epoch 00194: val_loss did not improve from 0.58416\n",
      "36805/36805 [==============================] - 23s 623us/sample - loss: 0.8855 - acc: 0.7164 - val_loss: 0.5949 - val_acc: 0.8239\n",
      "Epoch 195/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8876 - acc: 0.7183\n",
      "Epoch 00195: val_loss did not improve from 0.58416\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.8874 - acc: 0.7184 - val_loss: 0.5886 - val_acc: 0.8260\n",
      "Epoch 196/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8958 - acc: 0.7125\n",
      "Epoch 00196: val_loss did not improve from 0.58416\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8959 - acc: 0.7124 - val_loss: 0.5882 - val_acc: 0.8253\n",
      "Epoch 197/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8897 - acc: 0.7182\n",
      "Epoch 00197: val_loss improved from 0.58416 to 0.57869, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/197-0.5787.hdf5\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.8897 - acc: 0.7182 - val_loss: 0.5787 - val_acc: 0.8258\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8916 - acc: 0.7196\n",
      "Epoch 00198: val_loss did not improve from 0.57869\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.8916 - acc: 0.7196 - val_loss: 0.5883 - val_acc: 0.8283\n",
      "Epoch 199/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8874 - acc: 0.7155\n",
      "Epoch 00199: val_loss did not improve from 0.57869\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8873 - acc: 0.7154 - val_loss: 0.5949 - val_acc: 0.8197\n",
      "Epoch 200/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8889 - acc: 0.7177\n",
      "Epoch 00200: val_loss did not improve from 0.57869\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8893 - acc: 0.7175 - val_loss: 0.5944 - val_acc: 0.8230\n",
      "Epoch 201/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8900 - acc: 0.7163\n",
      "Epoch 00201: val_loss did not improve from 0.57869\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.8898 - acc: 0.7164 - val_loss: 0.5793 - val_acc: 0.8307\n",
      "Epoch 202/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8865 - acc: 0.7172\n",
      "Epoch 00202: val_loss did not improve from 0.57869\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.8864 - acc: 0.7171 - val_loss: 0.5793 - val_acc: 0.8267\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8850 - acc: 0.7167\n",
      "Epoch 00203: val_loss improved from 0.57869 to 0.57639, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/203-0.5764.hdf5\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.8850 - acc: 0.7166 - val_loss: 0.5764 - val_acc: 0.8279\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8824 - acc: 0.7205\n",
      "Epoch 00204: val_loss did not improve from 0.57639\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.8825 - acc: 0.7204 - val_loss: 0.5783 - val_acc: 0.8302\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8848 - acc: 0.7195\n",
      "Epoch 00205: val_loss did not improve from 0.57639\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 0.8849 - acc: 0.7194 - val_loss: 0.5845 - val_acc: 0.8267\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8914 - acc: 0.7142\n",
      "Epoch 00206: val_loss did not improve from 0.57639\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8913 - acc: 0.7143 - val_loss: 0.5883 - val_acc: 0.8251\n",
      "Epoch 207/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8870 - acc: 0.7183\n",
      "Epoch 00207: val_loss did not improve from 0.57639\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.8867 - acc: 0.7184 - val_loss: 0.5781 - val_acc: 0.8276\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8814 - acc: 0.7189\n",
      "Epoch 00208: val_loss improved from 0.57639 to 0.57384, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/208-0.5738.hdf5\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.8813 - acc: 0.7189 - val_loss: 0.5738 - val_acc: 0.8316\n",
      "Epoch 209/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8862 - acc: 0.7179\n",
      "Epoch 00209: val_loss did not improve from 0.57384\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8866 - acc: 0.7177 - val_loss: 0.5780 - val_acc: 0.8267\n",
      "Epoch 210/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8800 - acc: 0.7198\n",
      "Epoch 00210: val_loss did not improve from 0.57384\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8803 - acc: 0.7197 - val_loss: 0.5788 - val_acc: 0.8286\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8830 - acc: 0.7194\n",
      "Epoch 00211: val_loss improved from 0.57384 to 0.57244, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/211-0.5724.hdf5\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.8829 - acc: 0.7195 - val_loss: 0.5724 - val_acc: 0.8334\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8756 - acc: 0.7194\n",
      "Epoch 00212: val_loss did not improve from 0.57244\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8756 - acc: 0.7194 - val_loss: 0.5798 - val_acc: 0.8258\n",
      "Epoch 213/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8810 - acc: 0.7210\n",
      "Epoch 00213: val_loss did not improve from 0.57244\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.8816 - acc: 0.7209 - val_loss: 0.5734 - val_acc: 0.8318\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8769 - acc: 0.7231\n",
      "Epoch 00214: val_loss did not improve from 0.57244\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.8769 - acc: 0.7231 - val_loss: 0.5767 - val_acc: 0.8300\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8802 - acc: 0.7184\n",
      "Epoch 00215: val_loss improved from 0.57244 to 0.56867, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/215-0.5687.hdf5\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.8802 - acc: 0.7184 - val_loss: 0.5687 - val_acc: 0.8346\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8821 - acc: 0.7188\n",
      "Epoch 00216: val_loss did not improve from 0.56867\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.8820 - acc: 0.7188 - val_loss: 0.5759 - val_acc: 0.8339\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8716 - acc: 0.7202\n",
      "Epoch 00217: val_loss did not improve from 0.56867\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.8716 - acc: 0.7202 - val_loss: 0.5823 - val_acc: 0.8311\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8730 - acc: 0.7188\n",
      "Epoch 00218: val_loss did not improve from 0.56867\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 0.8729 - acc: 0.7189 - val_loss: 0.5798 - val_acc: 0.8283\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8836 - acc: 0.7185\n",
      "Epoch 00219: val_loss did not improve from 0.56867\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.8835 - acc: 0.7185 - val_loss: 0.5807 - val_acc: 0.8269\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8726 - acc: 0.7209\n",
      "Epoch 00220: val_loss improved from 0.56867 to 0.56572, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/220-0.5657.hdf5\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.8725 - acc: 0.7209 - val_loss: 0.5657 - val_acc: 0.8341\n",
      "Epoch 221/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8756 - acc: 0.7236\n",
      "Epoch 00221: val_loss did not improve from 0.56572\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 0.8762 - acc: 0.7235 - val_loss: 0.5736 - val_acc: 0.8300\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8649 - acc: 0.7276\n",
      "Epoch 00222: val_loss did not improve from 0.56572\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.8649 - acc: 0.7276 - val_loss: 0.5693 - val_acc: 0.8304\n",
      "Epoch 223/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8706 - acc: 0.7193\n",
      "Epoch 00223: val_loss did not improve from 0.56572\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.8706 - acc: 0.7193 - val_loss: 0.5705 - val_acc: 0.8332\n",
      "Epoch 224/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8721 - acc: 0.7214\n",
      "Epoch 00224: val_loss improved from 0.56572 to 0.56570, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/224-0.5657.hdf5\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.8721 - acc: 0.7214 - val_loss: 0.5657 - val_acc: 0.8323\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8704 - acc: 0.7235\n",
      "Epoch 00225: val_loss did not improve from 0.56570\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.8704 - acc: 0.7235 - val_loss: 0.5752 - val_acc: 0.8295\n",
      "Epoch 226/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8688 - acc: 0.7215\n",
      "Epoch 00226: val_loss did not improve from 0.56570\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.8687 - acc: 0.7216 - val_loss: 0.5720 - val_acc: 0.8334\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8679 - acc: 0.7230\n",
      "Epoch 00227: val_loss did not improve from 0.56570\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.8679 - acc: 0.7230 - val_loss: 0.5742 - val_acc: 0.8323\n",
      "Epoch 228/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8635 - acc: 0.7265\n",
      "Epoch 00228: val_loss did not improve from 0.56570\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.8641 - acc: 0.7264 - val_loss: 0.5741 - val_acc: 0.8309\n",
      "Epoch 229/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8662 - acc: 0.7273\n",
      "Epoch 00229: val_loss improved from 0.56570 to 0.56067, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/229-0.5607.hdf5\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.8663 - acc: 0.7273 - val_loss: 0.5607 - val_acc: 0.8351\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8662 - acc: 0.7262\n",
      "Epoch 00230: val_loss did not improve from 0.56067\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8662 - acc: 0.7262 - val_loss: 0.5677 - val_acc: 0.8321\n",
      "Epoch 231/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8612 - acc: 0.7255\n",
      "Epoch 00231: val_loss did not improve from 0.56067\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8612 - acc: 0.7255 - val_loss: 0.5632 - val_acc: 0.8344\n",
      "Epoch 232/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8668 - acc: 0.7233\n",
      "Epoch 00232: val_loss did not improve from 0.56067\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.8672 - acc: 0.7233 - val_loss: 0.5640 - val_acc: 0.8330\n",
      "Epoch 233/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8686 - acc: 0.7221\n",
      "Epoch 00233: val_loss did not improve from 0.56067\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8685 - acc: 0.7221 - val_loss: 0.5640 - val_acc: 0.8316\n",
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8620 - acc: 0.7232\n",
      "Epoch 00234: val_loss did not improve from 0.56067\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.8620 - acc: 0.7232 - val_loss: 0.5644 - val_acc: 0.8344\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8647 - acc: 0.7265\n",
      "Epoch 00235: val_loss improved from 0.56067 to 0.55556, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/235-0.5556.hdf5\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 0.8647 - acc: 0.7266 - val_loss: 0.5556 - val_acc: 0.8376\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8658 - acc: 0.7243\n",
      "Epoch 00236: val_loss did not improve from 0.55556\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.8658 - acc: 0.7242 - val_loss: 0.5584 - val_acc: 0.8353\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8651 - acc: 0.7264\n",
      "Epoch 00237: val_loss did not improve from 0.55556\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8651 - acc: 0.7264 - val_loss: 0.5652 - val_acc: 0.8365\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8714 - acc: 0.7207\n",
      "Epoch 00238: val_loss did not improve from 0.55556\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8714 - acc: 0.7207 - val_loss: 0.5566 - val_acc: 0.8360\n",
      "Epoch 239/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8557 - acc: 0.7284\n",
      "Epoch 00239: val_loss did not improve from 0.55556\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.8557 - acc: 0.7285 - val_loss: 0.5558 - val_acc: 0.8379\n",
      "Epoch 240/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8586 - acc: 0.7286\n",
      "Epoch 00240: val_loss did not improve from 0.55556\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.8583 - acc: 0.7288 - val_loss: 0.5666 - val_acc: 0.8316\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8584 - acc: 0.7260\n",
      "Epoch 00241: val_loss did not improve from 0.55556\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8584 - acc: 0.7260 - val_loss: 0.5608 - val_acc: 0.8369\n",
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8569 - acc: 0.7243\n",
      "Epoch 00242: val_loss did not improve from 0.55556\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.8569 - acc: 0.7243 - val_loss: 0.5582 - val_acc: 0.8339\n",
      "Epoch 243/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8595 - acc: 0.7259\n",
      "Epoch 00243: val_loss improved from 0.55556 to 0.55425, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/243-0.5542.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8594 - acc: 0.7259 - val_loss: 0.5542 - val_acc: 0.8355\n",
      "Epoch 244/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8533 - acc: 0.7292\n",
      "Epoch 00244: val_loss did not improve from 0.55425\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.8537 - acc: 0.7290 - val_loss: 0.5641 - val_acc: 0.8341\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8538 - acc: 0.7291\n",
      "Epoch 00245: val_loss did not improve from 0.55425\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8537 - acc: 0.7291 - val_loss: 0.5657 - val_acc: 0.8351\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8568 - acc: 0.7266\n",
      "Epoch 00246: val_loss did not improve from 0.55425\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.8567 - acc: 0.7266 - val_loss: 0.5561 - val_acc: 0.8372\n",
      "Epoch 247/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8520 - acc: 0.7289\n",
      "Epoch 00247: val_loss did not improve from 0.55425\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.8523 - acc: 0.7289 - val_loss: 0.5606 - val_acc: 0.8353\n",
      "Epoch 248/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8547 - acc: 0.7263\n",
      "Epoch 00248: val_loss did not improve from 0.55425\n",
      "36805/36805 [==============================] - 23s 611us/sample - loss: 0.8547 - acc: 0.7263 - val_loss: 0.5555 - val_acc: 0.8383\n",
      "Epoch 249/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8521 - acc: 0.7283\n",
      "Epoch 00249: val_loss improved from 0.55425 to 0.55128, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/249-0.5513.hdf5\n",
      "36805/36805 [==============================] - 23s 628us/sample - loss: 0.8521 - acc: 0.7284 - val_loss: 0.5513 - val_acc: 0.8360\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8474 - acc: 0.7289\n",
      "Epoch 00250: val_loss improved from 0.55128 to 0.54978, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/250-0.5498.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.8478 - acc: 0.7288 - val_loss: 0.5498 - val_acc: 0.8379\n",
      "Epoch 251/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8501 - acc: 0.7284\n",
      "Epoch 00251: val_loss did not improve from 0.54978\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.8501 - acc: 0.7284 - val_loss: 0.5511 - val_acc: 0.8372\n",
      "Epoch 252/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8527 - acc: 0.7271\n",
      "Epoch 00252: val_loss did not improve from 0.54978\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.8525 - acc: 0.7272 - val_loss: 0.5566 - val_acc: 0.8318\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8464 - acc: 0.7286\n",
      "Epoch 00253: val_loss improved from 0.54978 to 0.54883, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/253-0.5488.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8463 - acc: 0.7286 - val_loss: 0.5488 - val_acc: 0.8360\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8541 - acc: 0.7292\n",
      "Epoch 00254: val_loss did not improve from 0.54883\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 0.8540 - acc: 0.7292 - val_loss: 0.5626 - val_acc: 0.8341\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8454 - acc: 0.7287\n",
      "Epoch 00255: val_loss did not improve from 0.54883\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.8454 - acc: 0.7287 - val_loss: 0.5564 - val_acc: 0.8358\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8563 - acc: 0.7268\n",
      "Epoch 00256: val_loss did not improve from 0.54883\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8563 - acc: 0.7268 - val_loss: 0.5497 - val_acc: 0.8374\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8523 - acc: 0.7294\n",
      "Epoch 00257: val_loss did not improve from 0.54883\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.8522 - acc: 0.7294 - val_loss: 0.5558 - val_acc: 0.8344\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8449 - acc: 0.7290\n",
      "Epoch 00258: val_loss did not improve from 0.54883\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 0.8448 - acc: 0.7290 - val_loss: 0.5536 - val_acc: 0.8374\n",
      "Epoch 259/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8439 - acc: 0.7314\n",
      "Epoch 00259: val_loss improved from 0.54883 to 0.54321, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/259-0.5432.hdf5\n",
      "36805/36805 [==============================] - 23s 611us/sample - loss: 0.8448 - acc: 0.7313 - val_loss: 0.5432 - val_acc: 0.8360\n",
      "Epoch 260/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8465 - acc: 0.7289\n",
      "Epoch 00260: val_loss did not improve from 0.54321\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.8466 - acc: 0.7289 - val_loss: 0.5449 - val_acc: 0.8397\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8432 - acc: 0.7305\n",
      "Epoch 00261: val_loss did not improve from 0.54321\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.8432 - acc: 0.7305 - val_loss: 0.5513 - val_acc: 0.8395\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8347 - acc: 0.7328\n",
      "Epoch 00262: val_loss did not improve from 0.54321\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8346 - acc: 0.7328 - val_loss: 0.5471 - val_acc: 0.8388\n",
      "Epoch 263/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8474 - acc: 0.7269\n",
      "Epoch 00263: val_loss did not improve from 0.54321\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 0.8473 - acc: 0.7269 - val_loss: 0.5490 - val_acc: 0.8388\n",
      "Epoch 264/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8452 - acc: 0.7274\n",
      "Epoch 00264: val_loss did not improve from 0.54321\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.8451 - acc: 0.7275 - val_loss: 0.5542 - val_acc: 0.8376\n",
      "Epoch 265/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8446 - acc: 0.7320\n",
      "Epoch 00265: val_loss did not improve from 0.54321\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.8449 - acc: 0.7318 - val_loss: 0.5540 - val_acc: 0.8365\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8391 - acc: 0.7305\n",
      "Epoch 00266: val_loss improved from 0.54321 to 0.54212, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/266-0.5421.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8391 - acc: 0.7305 - val_loss: 0.5421 - val_acc: 0.8423\n",
      "Epoch 267/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8374 - acc: 0.7311\n",
      "Epoch 00267: val_loss did not improve from 0.54212\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.8371 - acc: 0.7312 - val_loss: 0.5451 - val_acc: 0.8397\n",
      "Epoch 268/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8433 - acc: 0.7312\n",
      "Epoch 00268: val_loss improved from 0.54212 to 0.54060, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/268-0.5406.hdf5\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.8433 - acc: 0.7312 - val_loss: 0.5406 - val_acc: 0.8411\n",
      "Epoch 269/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8481 - acc: 0.7311\n",
      "Epoch 00269: val_loss did not improve from 0.54060\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.8480 - acc: 0.7312 - val_loss: 0.5502 - val_acc: 0.8388\n",
      "Epoch 270/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8439 - acc: 0.7301\n",
      "Epoch 00270: val_loss improved from 0.54060 to 0.53727, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/270-0.5373.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8439 - acc: 0.7301 - val_loss: 0.5373 - val_acc: 0.8404\n",
      "Epoch 271/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8384 - acc: 0.7319\n",
      "Epoch 00271: val_loss did not improve from 0.53727\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.8383 - acc: 0.7319 - val_loss: 0.5478 - val_acc: 0.8402\n",
      "Epoch 272/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8413 - acc: 0.7309\n",
      "Epoch 00272: val_loss did not improve from 0.53727\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.8415 - acc: 0.7309 - val_loss: 0.5386 - val_acc: 0.8418\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8389 - acc: 0.7335\n",
      "Epoch 00273: val_loss improved from 0.53727 to 0.53575, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/273-0.5358.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8390 - acc: 0.7335 - val_loss: 0.5358 - val_acc: 0.8416\n",
      "Epoch 274/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8368 - acc: 0.7329\n",
      "Epoch 00274: val_loss did not improve from 0.53575\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8370 - acc: 0.7329 - val_loss: 0.5383 - val_acc: 0.8404\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8362 - acc: 0.7314\n",
      "Epoch 00275: val_loss did not improve from 0.53575\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.8362 - acc: 0.7314 - val_loss: 0.5449 - val_acc: 0.8372\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8315 - acc: 0.7354\n",
      "Epoch 00276: val_loss did not improve from 0.53575\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.8314 - acc: 0.7354 - val_loss: 0.5375 - val_acc: 0.8409\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8332 - acc: 0.7328\n",
      "Epoch 00277: val_loss improved from 0.53575 to 0.53565, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/277-0.5356.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8332 - acc: 0.7328 - val_loss: 0.5356 - val_acc: 0.8451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8329 - acc: 0.7325\n",
      "Epoch 00278: val_loss did not improve from 0.53565\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8329 - acc: 0.7325 - val_loss: 0.5443 - val_acc: 0.8379\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8288 - acc: 0.7357\n",
      "Epoch 00279: val_loss did not improve from 0.53565\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 0.8288 - acc: 0.7357 - val_loss: 0.5431 - val_acc: 0.8423\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8401 - acc: 0.7324\n",
      "Epoch 00280: val_loss did not improve from 0.53565\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.8400 - acc: 0.7324 - val_loss: 0.5455 - val_acc: 0.8358\n",
      "Epoch 281/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8307 - acc: 0.7340\n",
      "Epoch 00281: val_loss did not improve from 0.53565\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.8307 - acc: 0.7340 - val_loss: 0.5464 - val_acc: 0.8425\n",
      "Epoch 282/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8338 - acc: 0.7340\n",
      "Epoch 00282: val_loss did not improve from 0.53565\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8337 - acc: 0.7341 - val_loss: 0.5369 - val_acc: 0.8416\n",
      "Epoch 283/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8265 - acc: 0.7360\n",
      "Epoch 00283: val_loss improved from 0.53565 to 0.53368, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/283-0.5337.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.8265 - acc: 0.7360 - val_loss: 0.5337 - val_acc: 0.8442\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8313 - acc: 0.7329\n",
      "Epoch 00284: val_loss did not improve from 0.53368\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.8315 - acc: 0.7329 - val_loss: 0.5364 - val_acc: 0.8442\n",
      "Epoch 285/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8311 - acc: 0.7345\n",
      "Epoch 00285: val_loss did not improve from 0.53368\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.8311 - acc: 0.7345 - val_loss: 0.5381 - val_acc: 0.8423\n",
      "Epoch 286/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8289 - acc: 0.7348\n",
      "Epoch 00286: val_loss improved from 0.53368 to 0.53354, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/286-0.5335.hdf5\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8289 - acc: 0.7348 - val_loss: 0.5335 - val_acc: 0.8418\n",
      "Epoch 287/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8272 - acc: 0.7366\n",
      "Epoch 00287: val_loss improved from 0.53354 to 0.52685, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/287-0.5268.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8275 - acc: 0.7365 - val_loss: 0.5268 - val_acc: 0.8449\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8305 - acc: 0.7329\n",
      "Epoch 00288: val_loss did not improve from 0.52685\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.8304 - acc: 0.7329 - val_loss: 0.5382 - val_acc: 0.8386\n",
      "Epoch 289/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8220 - acc: 0.7348\n",
      "Epoch 00289: val_loss did not improve from 0.52685\n",
      "36805/36805 [==============================] - 23s 625us/sample - loss: 0.8215 - acc: 0.7350 - val_loss: 0.5357 - val_acc: 0.8404\n",
      "Epoch 290/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8313 - acc: 0.7367\n",
      "Epoch 00290: val_loss did not improve from 0.52685\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8313 - acc: 0.7367 - val_loss: 0.5353 - val_acc: 0.8407\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8256 - acc: 0.7366\n",
      "Epoch 00291: val_loss did not improve from 0.52685\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8256 - acc: 0.7366 - val_loss: 0.5324 - val_acc: 0.8421\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8241 - acc: 0.7374\n",
      "Epoch 00292: val_loss did not improve from 0.52685\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.8241 - acc: 0.7374 - val_loss: 0.5395 - val_acc: 0.8414\n",
      "Epoch 293/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8285 - acc: 0.7353\n",
      "Epoch 00293: val_loss did not improve from 0.52685\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8285 - acc: 0.7353 - val_loss: 0.5403 - val_acc: 0.8432\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8274 - acc: 0.7357\n",
      "Epoch 00294: val_loss did not improve from 0.52685\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.8273 - acc: 0.7357 - val_loss: 0.5314 - val_acc: 0.8446\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8225 - acc: 0.7373\n",
      "Epoch 00295: val_loss did not improve from 0.52685\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.8225 - acc: 0.7373 - val_loss: 0.5288 - val_acc: 0.8444\n",
      "Epoch 296/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8293 - acc: 0.7347\n",
      "Epoch 00296: val_loss did not improve from 0.52685\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8294 - acc: 0.7347 - val_loss: 0.5296 - val_acc: 0.8414\n",
      "Epoch 297/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8235 - acc: 0.7353\n",
      "Epoch 00297: val_loss did not improve from 0.52685\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.8237 - acc: 0.7352 - val_loss: 0.5328 - val_acc: 0.8423\n",
      "Epoch 298/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8270 - acc: 0.7350\n",
      "Epoch 00298: val_loss did not improve from 0.52685\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8271 - acc: 0.7350 - val_loss: 0.5316 - val_acc: 0.8444\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8271 - acc: 0.7388\n",
      "Epoch 00299: val_loss improved from 0.52685 to 0.52573, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/299-0.5257.hdf5\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.8270 - acc: 0.7388 - val_loss: 0.5257 - val_acc: 0.8435\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8278 - acc: 0.7374\n",
      "Epoch 00300: val_loss did not improve from 0.52573\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.8277 - acc: 0.7374 - val_loss: 0.5330 - val_acc: 0.8442\n",
      "Epoch 301/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8180 - acc: 0.7380\n",
      "Epoch 00301: val_loss improved from 0.52573 to 0.52487, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/301-0.5249.hdf5\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 0.8178 - acc: 0.7380 - val_loss: 0.5249 - val_acc: 0.8428\n",
      "Epoch 302/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8216 - acc: 0.7361\n",
      "Epoch 00302: val_loss did not improve from 0.52487\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.8215 - acc: 0.7361 - val_loss: 0.5319 - val_acc: 0.8402\n",
      "Epoch 303/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8230 - acc: 0.7373\n",
      "Epoch 00303: val_loss improved from 0.52487 to 0.52298, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/303-0.5230.hdf5\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.8230 - acc: 0.7373 - val_loss: 0.5230 - val_acc: 0.8467\n",
      "Epoch 304/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8238 - acc: 0.7368\n",
      "Epoch 00304: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8239 - acc: 0.7368 - val_loss: 0.5391 - val_acc: 0.8402\n",
      "Epoch 305/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8157 - acc: 0.7395\n",
      "Epoch 00305: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8157 - acc: 0.7395 - val_loss: 0.5291 - val_acc: 0.8444\n",
      "Epoch 306/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8169 - acc: 0.7376\n",
      "Epoch 00306: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.8166 - acc: 0.7377 - val_loss: 0.5307 - val_acc: 0.8435\n",
      "Epoch 307/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8089 - acc: 0.7425\n",
      "Epoch 00307: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.8090 - acc: 0.7425 - val_loss: 0.5266 - val_acc: 0.8446\n",
      "Epoch 308/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8135 - acc: 0.7403\n",
      "Epoch 00308: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8137 - acc: 0.7401 - val_loss: 0.5288 - val_acc: 0.8423\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8168 - acc: 0.7377\n",
      "Epoch 00309: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.8167 - acc: 0.7377 - val_loss: 0.5251 - val_acc: 0.8502\n",
      "Epoch 310/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8193 - acc: 0.7373\n",
      "Epoch 00310: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.8192 - acc: 0.7373 - val_loss: 0.5278 - val_acc: 0.8421\n",
      "Epoch 311/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8198 - acc: 0.7368\n",
      "Epoch 00311: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 0.8198 - acc: 0.7369 - val_loss: 0.5266 - val_acc: 0.8460\n",
      "Epoch 312/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8095 - acc: 0.7404\n",
      "Epoch 00312: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8094 - acc: 0.7404 - val_loss: 0.5279 - val_acc: 0.8423\n",
      "Epoch 313/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8148 - acc: 0.7400\n",
      "Epoch 00313: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.8149 - acc: 0.7399 - val_loss: 0.5428 - val_acc: 0.8339\n",
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8103 - acc: 0.7405\n",
      "Epoch 00314: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8104 - acc: 0.7405 - val_loss: 0.5345 - val_acc: 0.8430\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8091 - acc: 0.7399\n",
      "Epoch 00315: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.8091 - acc: 0.7399 - val_loss: 0.5271 - val_acc: 0.8444\n",
      "Epoch 316/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8077 - acc: 0.7408\n",
      "Epoch 00316: val_loss did not improve from 0.52298\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8076 - acc: 0.7408 - val_loss: 0.5231 - val_acc: 0.8486\n",
      "Epoch 317/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8134 - acc: 0.7395\n",
      "Epoch 00317: val_loss improved from 0.52298 to 0.52286, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/317-0.5229.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.8133 - acc: 0.7395 - val_loss: 0.5229 - val_acc: 0.8460\n",
      "Epoch 318/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8183 - acc: 0.7408\n",
      "Epoch 00318: val_loss did not improve from 0.52286\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8183 - acc: 0.7408 - val_loss: 0.5296 - val_acc: 0.8444\n",
      "Epoch 319/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8069 - acc: 0.7414\n",
      "Epoch 00319: val_loss did not improve from 0.52286\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.8069 - acc: 0.7414 - val_loss: 0.5400 - val_acc: 0.8386\n",
      "Epoch 320/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8114 - acc: 0.7440\n",
      "Epoch 00320: val_loss did not improve from 0.52286\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8113 - acc: 0.7440 - val_loss: 0.5234 - val_acc: 0.8463\n",
      "Epoch 321/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8137 - acc: 0.7381\n",
      "Epoch 00321: val_loss did not improve from 0.52286\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 0.8137 - acc: 0.7381 - val_loss: 0.5272 - val_acc: 0.8467\n",
      "Epoch 322/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8090 - acc: 0.7408\n",
      "Epoch 00322: val_loss improved from 0.52286 to 0.51789, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/322-0.5179.hdf5\n",
      "36805/36805 [==============================] - 23s 634us/sample - loss: 0.8090 - acc: 0.7408 - val_loss: 0.5179 - val_acc: 0.8458\n",
      "Epoch 323/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7997 - acc: 0.7445\n",
      "Epoch 00323: val_loss did not improve from 0.51789\n",
      "36805/36805 [==============================] - 23s 623us/sample - loss: 0.7996 - acc: 0.7445 - val_loss: 0.5219 - val_acc: 0.8458\n",
      "Epoch 324/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8112 - acc: 0.7425\n",
      "Epoch 00324: val_loss did not improve from 0.51789\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 0.8112 - acc: 0.7425 - val_loss: 0.5190 - val_acc: 0.8463\n",
      "Epoch 325/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8106 - acc: 0.7423\n",
      "Epoch 00325: val_loss did not improve from 0.51789\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.8105 - acc: 0.7423 - val_loss: 0.5310 - val_acc: 0.8432\n",
      "Epoch 326/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8035 - acc: 0.7415\n",
      "Epoch 00326: val_loss did not improve from 0.51789\n",
      "36805/36805 [==============================] - 23s 625us/sample - loss: 0.8035 - acc: 0.7416 - val_loss: 0.5220 - val_acc: 0.8474\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8084 - acc: 0.7427\n",
      "Epoch 00327: val_loss improved from 0.51789 to 0.51466, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/327-0.5147.hdf5\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 0.8084 - acc: 0.7428 - val_loss: 0.5147 - val_acc: 0.8528\n",
      "Epoch 328/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8154 - acc: 0.7405\n",
      "Epoch 00328: val_loss did not improve from 0.51466\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.8157 - acc: 0.7405 - val_loss: 0.5199 - val_acc: 0.8500\n",
      "Epoch 329/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8022 - acc: 0.7435\n",
      "Epoch 00329: val_loss improved from 0.51466 to 0.51431, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/329-0.5143.hdf5\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 0.8021 - acc: 0.7436 - val_loss: 0.5143 - val_acc: 0.8505\n",
      "Epoch 330/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8056 - acc: 0.7432\n",
      "Epoch 00330: val_loss did not improve from 0.51431\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.8055 - acc: 0.7432 - val_loss: 0.5315 - val_acc: 0.8481\n",
      "Epoch 331/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8049 - acc: 0.7452\n",
      "Epoch 00331: val_loss did not improve from 0.51431\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.8050 - acc: 0.7452 - val_loss: 0.5168 - val_acc: 0.8486\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8045 - acc: 0.7429\n",
      "Epoch 00332: val_loss did not improve from 0.51431\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 0.8046 - acc: 0.7429 - val_loss: 0.5223 - val_acc: 0.8479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8021 - acc: 0.7447\n",
      "Epoch 00333: val_loss did not improve from 0.51431\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.8021 - acc: 0.7447 - val_loss: 0.5147 - val_acc: 0.8512\n",
      "Epoch 334/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8012 - acc: 0.7451\n",
      "Epoch 00334: val_loss did not improve from 0.51431\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 0.8012 - acc: 0.7451 - val_loss: 0.5157 - val_acc: 0.8523\n",
      "Epoch 335/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8051 - acc: 0.7441\n",
      "Epoch 00335: val_loss did not improve from 0.51431\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.8052 - acc: 0.7441 - val_loss: 0.5214 - val_acc: 0.8449\n",
      "Epoch 336/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8039 - acc: 0.7416\n",
      "Epoch 00336: val_loss improved from 0.51431 to 0.51350, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/336-0.5135.hdf5\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 0.8037 - acc: 0.7416 - val_loss: 0.5135 - val_acc: 0.8530\n",
      "Epoch 337/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8035 - acc: 0.7444\n",
      "Epoch 00337: val_loss did not improve from 0.51350\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.8036 - acc: 0.7443 - val_loss: 0.5298 - val_acc: 0.8446\n",
      "Epoch 338/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8021 - acc: 0.7467\n",
      "Epoch 00338: val_loss did not improve from 0.51350\n",
      "36805/36805 [==============================] - 23s 625us/sample - loss: 0.8021 - acc: 0.7467 - val_loss: 0.5143 - val_acc: 0.8516\n",
      "Epoch 339/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7960 - acc: 0.7468\n",
      "Epoch 00339: val_loss did not improve from 0.51350\n",
      "36805/36805 [==============================] - 23s 626us/sample - loss: 0.7959 - acc: 0.7469 - val_loss: 0.5180 - val_acc: 0.8458\n",
      "Epoch 340/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7969 - acc: 0.7469\n",
      "Epoch 00340: val_loss did not improve from 0.51350\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 0.7971 - acc: 0.7469 - val_loss: 0.5159 - val_acc: 0.8505\n",
      "Epoch 341/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7997 - acc: 0.7450\n",
      "Epoch 00341: val_loss did not improve from 0.51350\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.7994 - acc: 0.7451 - val_loss: 0.5212 - val_acc: 0.8451\n",
      "Epoch 342/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8023 - acc: 0.7409\n",
      "Epoch 00342: val_loss improved from 0.51350 to 0.51128, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/342-0.5113.hdf5\n",
      "36805/36805 [==============================] - 23s 625us/sample - loss: 0.8025 - acc: 0.7409 - val_loss: 0.5113 - val_acc: 0.8500\n",
      "Epoch 343/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8006 - acc: 0.7446\n",
      "Epoch 00343: val_loss did not improve from 0.51128\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.8006 - acc: 0.7446 - val_loss: 0.5138 - val_acc: 0.8491\n",
      "Epoch 344/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8024 - acc: 0.7448\n",
      "Epoch 00344: val_loss improved from 0.51128 to 0.51057, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/344-0.5106.hdf5\n",
      "36805/36805 [==============================] - 23s 611us/sample - loss: 0.8025 - acc: 0.7447 - val_loss: 0.5106 - val_acc: 0.8493\n",
      "Epoch 345/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8028 - acc: 0.7436\n",
      "Epoch 00345: val_loss did not improve from 0.51057\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.8028 - acc: 0.7436 - val_loss: 0.5133 - val_acc: 0.8484\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7893 - acc: 0.7449\n",
      "Epoch 00346: val_loss improved from 0.51057 to 0.50718, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/346-0.5072.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.7892 - acc: 0.7449 - val_loss: 0.5072 - val_acc: 0.8493\n",
      "Epoch 347/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7965 - acc: 0.7450\n",
      "Epoch 00347: val_loss did not improve from 0.50718\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.7967 - acc: 0.7450 - val_loss: 0.5107 - val_acc: 0.8488\n",
      "Epoch 348/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8021 - acc: 0.7448\n",
      "Epoch 00348: val_loss did not improve from 0.50718\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.8019 - acc: 0.7447 - val_loss: 0.5128 - val_acc: 0.8498\n",
      "Epoch 349/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7960 - acc: 0.7453\n",
      "Epoch 00349: val_loss did not improve from 0.50718\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.7959 - acc: 0.7453 - val_loss: 0.5204 - val_acc: 0.8484\n",
      "Epoch 350/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7935 - acc: 0.7461\n",
      "Epoch 00350: val_loss did not improve from 0.50718\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.7935 - acc: 0.7461 - val_loss: 0.5134 - val_acc: 0.8500\n",
      "Epoch 351/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7919 - acc: 0.7469\n",
      "Epoch 00351: val_loss did not improve from 0.50718\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.7920 - acc: 0.7469 - val_loss: 0.5143 - val_acc: 0.8507\n",
      "Epoch 352/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8012 - acc: 0.7448\n",
      "Epoch 00352: val_loss did not improve from 0.50718\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.8013 - acc: 0.7448 - val_loss: 0.5077 - val_acc: 0.8479\n",
      "Epoch 353/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7941 - acc: 0.7461\n",
      "Epoch 00353: val_loss did not improve from 0.50718\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.7941 - acc: 0.7461 - val_loss: 0.5129 - val_acc: 0.8498\n",
      "Epoch 354/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7985 - acc: 0.7464\n",
      "Epoch 00354: val_loss did not improve from 0.50718\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.7985 - acc: 0.7464 - val_loss: 0.5120 - val_acc: 0.8486\n",
      "Epoch 355/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7929 - acc: 0.7449\n",
      "Epoch 00355: val_loss did not improve from 0.50718\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.7929 - acc: 0.7450 - val_loss: 0.5147 - val_acc: 0.8491\n",
      "Epoch 356/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7982 - acc: 0.7465\n",
      "Epoch 00356: val_loss did not improve from 0.50718\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.7982 - acc: 0.7465 - val_loss: 0.5177 - val_acc: 0.8528\n",
      "Epoch 357/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7968 - acc: 0.7442\n",
      "Epoch 00357: val_loss improved from 0.50718 to 0.50588, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/357-0.5059.hdf5\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.7966 - acc: 0.7444 - val_loss: 0.5059 - val_acc: 0.8512\n",
      "Epoch 358/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7976 - acc: 0.7472\n",
      "Epoch 00358: val_loss did not improve from 0.50588\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.7975 - acc: 0.7472 - val_loss: 0.5251 - val_acc: 0.8407\n",
      "Epoch 359/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7871 - acc: 0.7470\n",
      "Epoch 00359: val_loss did not improve from 0.50588\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 0.7871 - acc: 0.7470 - val_loss: 0.5201 - val_acc: 0.8470\n",
      "Epoch 360/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7951 - acc: 0.7462\n",
      "Epoch 00360: val_loss did not improve from 0.50588\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.7951 - acc: 0.7462 - val_loss: 0.5127 - val_acc: 0.8535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7941 - acc: 0.7460\n",
      "Epoch 00361: val_loss did not improve from 0.50588\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.7941 - acc: 0.7460 - val_loss: 0.5086 - val_acc: 0.8519\n",
      "Epoch 362/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7891 - acc: 0.7471\n",
      "Epoch 00362: val_loss did not improve from 0.50588\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 0.7892 - acc: 0.7471 - val_loss: 0.5184 - val_acc: 0.8493\n",
      "Epoch 363/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7894 - acc: 0.7483\n",
      "Epoch 00363: val_loss did not improve from 0.50588\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.7897 - acc: 0.7482 - val_loss: 0.5134 - val_acc: 0.8516\n",
      "Epoch 364/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7821 - acc: 0.7482\n",
      "Epoch 00364: val_loss did not improve from 0.50588\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.7818 - acc: 0.7483 - val_loss: 0.5121 - val_acc: 0.8451\n",
      "Epoch 365/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7905 - acc: 0.7467\n",
      "Epoch 00365: val_loss did not improve from 0.50588\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.7906 - acc: 0.7466 - val_loss: 0.5195 - val_acc: 0.8498\n",
      "Epoch 366/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7897 - acc: 0.7456\n",
      "Epoch 00366: val_loss improved from 0.50588 to 0.50459, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/366-0.5046.hdf5\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.7897 - acc: 0.7457 - val_loss: 0.5046 - val_acc: 0.8537\n",
      "Epoch 367/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7914 - acc: 0.7493\n",
      "Epoch 00367: val_loss did not improve from 0.50459\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.7913 - acc: 0.7493 - val_loss: 0.5093 - val_acc: 0.8530\n",
      "Epoch 368/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7916 - acc: 0.7467\n",
      "Epoch 00368: val_loss did not improve from 0.50459\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.7915 - acc: 0.7467 - val_loss: 0.5167 - val_acc: 0.8449\n",
      "Epoch 369/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7877 - acc: 0.7464\n",
      "Epoch 00369: val_loss did not improve from 0.50459\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 0.7877 - acc: 0.7464 - val_loss: 0.5066 - val_acc: 0.8481\n",
      "Epoch 370/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7925 - acc: 0.7477\n",
      "Epoch 00370: val_loss did not improve from 0.50459\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.7927 - acc: 0.7477 - val_loss: 0.5115 - val_acc: 0.8479\n",
      "Epoch 371/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7840 - acc: 0.7493\n",
      "Epoch 00371: val_loss did not improve from 0.50459\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.7839 - acc: 0.7493 - val_loss: 0.5066 - val_acc: 0.8526\n",
      "Epoch 372/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7842 - acc: 0.7501\n",
      "Epoch 00372: val_loss did not improve from 0.50459\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.7841 - acc: 0.7501 - val_loss: 0.5084 - val_acc: 0.8509\n",
      "Epoch 373/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7885 - acc: 0.7469\n",
      "Epoch 00373: val_loss did not improve from 0.50459\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.7885 - acc: 0.7469 - val_loss: 0.5147 - val_acc: 0.8484\n",
      "Epoch 374/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7894 - acc: 0.7462\n",
      "Epoch 00374: val_loss did not improve from 0.50459\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.7894 - acc: 0.7462 - val_loss: 0.5134 - val_acc: 0.8516\n",
      "Epoch 375/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7840 - acc: 0.7498\n",
      "Epoch 00375: val_loss did not improve from 0.50459\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.7838 - acc: 0.7498 - val_loss: 0.5112 - val_acc: 0.8509\n",
      "Epoch 376/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7818 - acc: 0.7470\n",
      "Epoch 00376: val_loss improved from 0.50459 to 0.50356, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/376-0.5036.hdf5\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.7819 - acc: 0.7470 - val_loss: 0.5036 - val_acc: 0.8528\n",
      "Epoch 377/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7879 - acc: 0.7458\n",
      "Epoch 00377: val_loss did not improve from 0.50356\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.7879 - acc: 0.7457 - val_loss: 0.5125 - val_acc: 0.8500\n",
      "Epoch 378/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7843 - acc: 0.7493\n",
      "Epoch 00378: val_loss did not improve from 0.50356\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.7842 - acc: 0.7494 - val_loss: 0.5075 - val_acc: 0.8526\n",
      "Epoch 379/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7796 - acc: 0.7499\n",
      "Epoch 00379: val_loss improved from 0.50356 to 0.50215, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/379-0.5021.hdf5\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.7795 - acc: 0.7499 - val_loss: 0.5021 - val_acc: 0.8532\n",
      "Epoch 380/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7863 - acc: 0.7496\n",
      "Epoch 00380: val_loss improved from 0.50215 to 0.50036, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/380-0.5004.hdf5\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.7862 - acc: 0.7497 - val_loss: 0.5004 - val_acc: 0.8546\n",
      "Epoch 381/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7810 - acc: 0.7499\n",
      "Epoch 00381: val_loss did not improve from 0.50036\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.7810 - acc: 0.7499 - val_loss: 0.5108 - val_acc: 0.8498\n",
      "Epoch 382/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7808 - acc: 0.7517\n",
      "Epoch 00382: val_loss did not improve from 0.50036\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 0.7808 - acc: 0.7517 - val_loss: 0.5084 - val_acc: 0.8528\n",
      "Epoch 383/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7865 - acc: 0.7480\n",
      "Epoch 00383: val_loss did not improve from 0.50036\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.7865 - acc: 0.7481 - val_loss: 0.5021 - val_acc: 0.8521\n",
      "Epoch 384/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7836 - acc: 0.7496\n",
      "Epoch 00384: val_loss improved from 0.50036 to 0.49879, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/384-0.4988.hdf5\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.7836 - acc: 0.7496 - val_loss: 0.4988 - val_acc: 0.8546\n",
      "Epoch 385/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7887 - acc: 0.7474\n",
      "Epoch 00385: val_loss did not improve from 0.49879\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.7887 - acc: 0.7475 - val_loss: 0.5060 - val_acc: 0.8535\n",
      "Epoch 386/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7812 - acc: 0.7477\n",
      "Epoch 00386: val_loss improved from 0.49879 to 0.49685, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/386-0.4969.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.7811 - acc: 0.7477 - val_loss: 0.4969 - val_acc: 0.8551\n",
      "Epoch 387/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7872 - acc: 0.7496\n",
      "Epoch 00387: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.7877 - acc: 0.7494 - val_loss: 0.5182 - val_acc: 0.8425\n",
      "Epoch 388/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7822 - acc: 0.7477\n",
      "Epoch 00388: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.7822 - acc: 0.7476 - val_loss: 0.5065 - val_acc: 0.8546\n",
      "Epoch 389/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7845 - acc: 0.7484\n",
      "Epoch 00389: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.7846 - acc: 0.7483 - val_loss: 0.5050 - val_acc: 0.8539\n",
      "Epoch 390/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7868 - acc: 0.7473\n",
      "Epoch 00390: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.7868 - acc: 0.7473 - val_loss: 0.5133 - val_acc: 0.8512\n",
      "Epoch 391/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7775 - acc: 0.7531\n",
      "Epoch 00391: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.7777 - acc: 0.7530 - val_loss: 0.5025 - val_acc: 0.8549\n",
      "Epoch 392/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7828 - acc: 0.7502\n",
      "Epoch 00392: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.7831 - acc: 0.7501 - val_loss: 0.5063 - val_acc: 0.8532\n",
      "Epoch 393/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7754 - acc: 0.7507\n",
      "Epoch 00393: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 0.7756 - acc: 0.7507 - val_loss: 0.5049 - val_acc: 0.8537\n",
      "Epoch 394/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7787 - acc: 0.7469\n",
      "Epoch 00394: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 0.7788 - acc: 0.7469 - val_loss: 0.5143 - val_acc: 0.8502\n",
      "Epoch 395/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7773 - acc: 0.7510\n",
      "Epoch 00395: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.7772 - acc: 0.7510 - val_loss: 0.5063 - val_acc: 0.8532\n",
      "Epoch 396/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7745 - acc: 0.7500\n",
      "Epoch 00396: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.7743 - acc: 0.7501 - val_loss: 0.5091 - val_acc: 0.8477\n",
      "Epoch 397/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7872 - acc: 0.7478\n",
      "Epoch 00397: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.7873 - acc: 0.7478 - val_loss: 0.5195 - val_acc: 0.8495\n",
      "Epoch 398/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7821 - acc: 0.7485\n",
      "Epoch 00398: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.7821 - acc: 0.7485 - val_loss: 0.5177 - val_acc: 0.8463\n",
      "Epoch 399/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7821 - acc: 0.7511\n",
      "Epoch 00399: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.7821 - acc: 0.7511 - val_loss: 0.5086 - val_acc: 0.8486\n",
      "Epoch 400/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7821 - acc: 0.7480\n",
      "Epoch 00400: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.7823 - acc: 0.7480 - val_loss: 0.5118 - val_acc: 0.8479\n",
      "Epoch 401/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7754 - acc: 0.7508\n",
      "Epoch 00401: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.7753 - acc: 0.7508 - val_loss: 0.5095 - val_acc: 0.8542\n",
      "Epoch 402/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7790 - acc: 0.7500\n",
      "Epoch 00402: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.7789 - acc: 0.7499 - val_loss: 0.5099 - val_acc: 0.8530\n",
      "Epoch 403/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7751 - acc: 0.7516\n",
      "Epoch 00403: val_loss did not improve from 0.49685\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.7748 - acc: 0.7516 - val_loss: 0.5113 - val_acc: 0.8521\n",
      "Epoch 404/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7833 - acc: 0.7499\n",
      "Epoch 00404: val_loss improved from 0.49685 to 0.49633, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/404-0.4963.hdf5\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.7833 - acc: 0.7499 - val_loss: 0.4963 - val_acc: 0.8532\n",
      "Epoch 405/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7800 - acc: 0.7496\n",
      "Epoch 00405: val_loss did not improve from 0.49633\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.7799 - acc: 0.7496 - val_loss: 0.5056 - val_acc: 0.8470\n",
      "Epoch 406/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7763 - acc: 0.7507\n",
      "Epoch 00406: val_loss did not improve from 0.49633\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.7765 - acc: 0.7506 - val_loss: 0.5071 - val_acc: 0.8542\n",
      "Epoch 407/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7720 - acc: 0.7505\n",
      "Epoch 00407: val_loss did not improve from 0.49633\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 0.7720 - acc: 0.7505 - val_loss: 0.5020 - val_acc: 0.8509\n",
      "Epoch 408/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7719 - acc: 0.7513\n",
      "Epoch 00408: val_loss did not improve from 0.49633\n",
      "36805/36805 [==============================] - 23s 624us/sample - loss: 0.7719 - acc: 0.7513 - val_loss: 0.4974 - val_acc: 0.8558\n",
      "Epoch 409/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7673 - acc: 0.7534\n",
      "Epoch 00409: val_loss improved from 0.49633 to 0.49521, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/409-0.4952.hdf5\n",
      "36805/36805 [==============================] - 23s 626us/sample - loss: 0.7673 - acc: 0.7534 - val_loss: 0.4952 - val_acc: 0.8567\n",
      "Epoch 410/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7746 - acc: 0.7522\n",
      "Epoch 00410: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.7749 - acc: 0.7521 - val_loss: 0.5088 - val_acc: 0.8509\n",
      "Epoch 411/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7770 - acc: 0.7501\n",
      "Epoch 00411: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 0.7770 - acc: 0.7501 - val_loss: 0.5067 - val_acc: 0.8512\n",
      "Epoch 412/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7788 - acc: 0.7482\n",
      "Epoch 00412: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.7788 - acc: 0.7481 - val_loss: 0.4971 - val_acc: 0.8551\n",
      "Epoch 413/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7741 - acc: 0.7532\n",
      "Epoch 00413: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.7740 - acc: 0.7532 - val_loss: 0.4987 - val_acc: 0.8505\n",
      "Epoch 414/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7721 - acc: 0.7507\n",
      "Epoch 00414: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.7721 - acc: 0.7507 - val_loss: 0.5008 - val_acc: 0.8567\n",
      "Epoch 415/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7703 - acc: 0.7517\n",
      "Epoch 00415: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.7704 - acc: 0.7516 - val_loss: 0.5067 - val_acc: 0.8514\n",
      "Epoch 416/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7659 - acc: 0.7534\n",
      "Epoch 00416: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.7659 - acc: 0.7534 - val_loss: 0.4962 - val_acc: 0.8530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7689 - acc: 0.7528\n",
      "Epoch 00417: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.7690 - acc: 0.7528 - val_loss: 0.4999 - val_acc: 0.8544\n",
      "Epoch 418/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7684 - acc: 0.7536\n",
      "Epoch 00418: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.7687 - acc: 0.7535 - val_loss: 0.5037 - val_acc: 0.8498\n",
      "Epoch 419/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7658 - acc: 0.7546\n",
      "Epoch 00419: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.7658 - acc: 0.7546 - val_loss: 0.5034 - val_acc: 0.8500\n",
      "Epoch 420/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7708 - acc: 0.7526\n",
      "Epoch 00420: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.7708 - acc: 0.7526 - val_loss: 0.5018 - val_acc: 0.8512\n",
      "Epoch 421/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7688 - acc: 0.7533\n",
      "Epoch 00421: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.7688 - acc: 0.7533 - val_loss: 0.5006 - val_acc: 0.8553\n",
      "Epoch 422/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7705 - acc: 0.7534\n",
      "Epoch 00422: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.7704 - acc: 0.7534 - val_loss: 0.4977 - val_acc: 0.8560\n",
      "Epoch 423/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7720 - acc: 0.7533\n",
      "Epoch 00423: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.7720 - acc: 0.7533 - val_loss: 0.4984 - val_acc: 0.8565\n",
      "Epoch 424/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7692 - acc: 0.7543\n",
      "Epoch 00424: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.7692 - acc: 0.7543 - val_loss: 0.5060 - val_acc: 0.8528\n",
      "Epoch 425/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7706 - acc: 0.7537\n",
      "Epoch 00425: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.7707 - acc: 0.7536 - val_loss: 0.5098 - val_acc: 0.8488\n",
      "Epoch 426/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7711 - acc: 0.7524\n",
      "Epoch 00426: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 0.7711 - acc: 0.7524 - val_loss: 0.4988 - val_acc: 0.8553\n",
      "Epoch 427/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7761 - acc: 0.7531\n",
      "Epoch 00427: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.7761 - acc: 0.7531 - val_loss: 0.4957 - val_acc: 0.8539\n",
      "Epoch 428/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7697 - acc: 0.7528\n",
      "Epoch 00428: val_loss did not improve from 0.49521\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.7697 - acc: 0.7528 - val_loss: 0.5000 - val_acc: 0.8551\n",
      "Epoch 429/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7667 - acc: 0.7542\n",
      "Epoch 00429: val_loss improved from 0.49521 to 0.49287, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/429-0.4929.hdf5\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.7667 - acc: 0.7542 - val_loss: 0.4929 - val_acc: 0.8551\n",
      "Epoch 430/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7635 - acc: 0.7540\n",
      "Epoch 00430: val_loss did not improve from 0.49287\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.7636 - acc: 0.7539 - val_loss: 0.4971 - val_acc: 0.8530\n",
      "Epoch 431/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7648 - acc: 0.7555\n",
      "Epoch 00431: val_loss did not improve from 0.49287\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.7651 - acc: 0.7555 - val_loss: 0.5046 - val_acc: 0.8505\n",
      "Epoch 432/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7615 - acc: 0.7553\n",
      "Epoch 00432: val_loss did not improve from 0.49287\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.7615 - acc: 0.7553 - val_loss: 0.4994 - val_acc: 0.8570\n",
      "Epoch 433/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7658 - acc: 0.7510\n",
      "Epoch 00433: val_loss did not improve from 0.49287\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.7658 - acc: 0.7510 - val_loss: 0.5061 - val_acc: 0.8519\n",
      "Epoch 434/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7667 - acc: 0.7544\n",
      "Epoch 00434: val_loss did not improve from 0.49287\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.7666 - acc: 0.7544 - val_loss: 0.4967 - val_acc: 0.8567\n",
      "Epoch 435/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7643 - acc: 0.7555\n",
      "Epoch 00435: val_loss did not improve from 0.49287\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.7643 - acc: 0.7555 - val_loss: 0.4959 - val_acc: 0.8507\n",
      "Epoch 436/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7629 - acc: 0.7550\n",
      "Epoch 00436: val_loss did not improve from 0.49287\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.7628 - acc: 0.7550 - val_loss: 0.4932 - val_acc: 0.8560\n",
      "Epoch 437/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7681 - acc: 0.7511\n",
      "Epoch 00437: val_loss did not improve from 0.49287\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.7681 - acc: 0.7510 - val_loss: 0.4930 - val_acc: 0.8574\n",
      "Epoch 438/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7678 - acc: 0.7552\n",
      "Epoch 00438: val_loss did not improve from 0.49287\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.7677 - acc: 0.7553 - val_loss: 0.4968 - val_acc: 0.8563\n",
      "Epoch 439/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7649 - acc: 0.7557\n",
      "Epoch 00439: val_loss did not improve from 0.49287\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.7651 - acc: 0.7556 - val_loss: 0.5142 - val_acc: 0.8465\n",
      "Epoch 440/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7658 - acc: 0.7551\n",
      "Epoch 00440: val_loss did not improve from 0.49287\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.7658 - acc: 0.7551 - val_loss: 0.5000 - val_acc: 0.8535\n",
      "Epoch 441/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7628 - acc: 0.7537\n",
      "Epoch 00441: val_loss improved from 0.49287 to 0.49066, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/441-0.4907.hdf5\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 0.7627 - acc: 0.7536 - val_loss: 0.4907 - val_acc: 0.8593\n",
      "Epoch 442/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7675 - acc: 0.7529\n",
      "Epoch 00442: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.7675 - acc: 0.7529 - val_loss: 0.4948 - val_acc: 0.8553\n",
      "Epoch 443/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7659 - acc: 0.7549\n",
      "Epoch 00443: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.7661 - acc: 0.7548 - val_loss: 0.5000 - val_acc: 0.8542\n",
      "Epoch 444/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7667 - acc: 0.7542\n",
      "Epoch 00444: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.7666 - acc: 0.7542 - val_loss: 0.5057 - val_acc: 0.8484\n",
      "Epoch 445/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7596 - acc: 0.7541\n",
      "Epoch 00445: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.7596 - acc: 0.7541 - val_loss: 0.5008 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7640 - acc: 0.7539\n",
      "Epoch 00446: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.7642 - acc: 0.7538 - val_loss: 0.4996 - val_acc: 0.8526\n",
      "Epoch 447/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7655 - acc: 0.7553\n",
      "Epoch 00447: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 0.7655 - acc: 0.7553 - val_loss: 0.5025 - val_acc: 0.8484\n",
      "Epoch 448/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7554 - acc: 0.7576\n",
      "Epoch 00448: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.7554 - acc: 0.7576 - val_loss: 0.4937 - val_acc: 0.8567\n",
      "Epoch 449/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7512 - acc: 0.7576\n",
      "Epoch 00449: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.7514 - acc: 0.7575 - val_loss: 0.4966 - val_acc: 0.8509\n",
      "Epoch 450/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7576 - acc: 0.7575\n",
      "Epoch 00450: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.7576 - acc: 0.7575 - val_loss: 0.4928 - val_acc: 0.8567\n",
      "Epoch 451/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7610 - acc: 0.7564\n",
      "Epoch 00451: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.7609 - acc: 0.7564 - val_loss: 0.4924 - val_acc: 0.8579\n",
      "Epoch 452/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7546 - acc: 0.7577\n",
      "Epoch 00452: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 604us/sample - loss: 0.7550 - acc: 0.7576 - val_loss: 0.5090 - val_acc: 0.8474\n",
      "Epoch 453/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7571 - acc: 0.7560\n",
      "Epoch 00453: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.7571 - acc: 0.7560 - val_loss: 0.4991 - val_acc: 0.8519\n",
      "Epoch 454/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7603 - acc: 0.7520\n",
      "Epoch 00454: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.7603 - acc: 0.7520 - val_loss: 0.5016 - val_acc: 0.8488\n",
      "Epoch 455/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7587 - acc: 0.7558\n",
      "Epoch 00455: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 606us/sample - loss: 0.7587 - acc: 0.7558 - val_loss: 0.5055 - val_acc: 0.8509\n",
      "Epoch 456/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7653 - acc: 0.7542\n",
      "Epoch 00456: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 0.7653 - acc: 0.7543 - val_loss: 0.5000 - val_acc: 0.8551\n",
      "Epoch 457/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7589 - acc: 0.7538\n",
      "Epoch 00457: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.7587 - acc: 0.7539 - val_loss: 0.5008 - val_acc: 0.8544\n",
      "Epoch 458/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7670 - acc: 0.7546\n",
      "Epoch 00458: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.7670 - acc: 0.7545 - val_loss: 0.4990 - val_acc: 0.8542\n",
      "Epoch 459/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7560 - acc: 0.7563\n",
      "Epoch 00459: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.7560 - acc: 0.7563 - val_loss: 0.5111 - val_acc: 0.8481\n",
      "Epoch 460/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7552 - acc: 0.7576\n",
      "Epoch 00460: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.7552 - acc: 0.7576 - val_loss: 0.5108 - val_acc: 0.8486\n",
      "Epoch 461/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7619 - acc: 0.7550\n",
      "Epoch 00461: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 0.7620 - acc: 0.7550 - val_loss: 0.4960 - val_acc: 0.8553\n",
      "Epoch 462/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7572 - acc: 0.7585\n",
      "Epoch 00462: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.7573 - acc: 0.7585 - val_loss: 0.4983 - val_acc: 0.8556\n",
      "Epoch 463/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7532 - acc: 0.7562\n",
      "Epoch 00463: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.7533 - acc: 0.7562 - val_loss: 0.4991 - val_acc: 0.8509\n",
      "Epoch 464/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7626 - acc: 0.7533\n",
      "Epoch 00464: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 23s 611us/sample - loss: 0.7627 - acc: 0.7532 - val_loss: 0.4992 - val_acc: 0.8551\n",
      "Epoch 465/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7535 - acc: 0.7583\n",
      "Epoch 00465: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.7534 - acc: 0.7583 - val_loss: 0.4959 - val_acc: 0.8528\n",
      "Epoch 466/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7580 - acc: 0.7564\n",
      "Epoch 00466: val_loss did not improve from 0.49066\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.7580 - acc: 0.7564 - val_loss: 0.5009 - val_acc: 0.8546\n",
      "Epoch 467/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7558 - acc: 0.7575\n",
      "Epoch 00467: val_loss improved from 0.49066 to 0.49052, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/467-0.4905.hdf5\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.7557 - acc: 0.7575 - val_loss: 0.4905 - val_acc: 0.8563\n",
      "Epoch 468/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7563 - acc: 0.7565\n",
      "Epoch 00468: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.7562 - acc: 0.7565 - val_loss: 0.4959 - val_acc: 0.8546\n",
      "Epoch 469/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7606 - acc: 0.7563\n",
      "Epoch 00469: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.7606 - acc: 0.7563 - val_loss: 0.4983 - val_acc: 0.8509\n",
      "Epoch 470/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7568 - acc: 0.7549\n",
      "Epoch 00470: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 0.7568 - acc: 0.7550 - val_loss: 0.4969 - val_acc: 0.8542\n",
      "Epoch 471/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7518 - acc: 0.7575\n",
      "Epoch 00471: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.7519 - acc: 0.7575 - val_loss: 0.4975 - val_acc: 0.8526\n",
      "Epoch 472/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7525 - acc: 0.7588\n",
      "Epoch 00472: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 0.7523 - acc: 0.7589 - val_loss: 0.4948 - val_acc: 0.8542\n",
      "Epoch 473/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7507 - acc: 0.7601\n",
      "Epoch 00473: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.7506 - acc: 0.7601 - val_loss: 0.5020 - val_acc: 0.8546\n",
      "Epoch 474/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7586 - acc: 0.7570\n",
      "Epoch 00474: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.7585 - acc: 0.7569 - val_loss: 0.4939 - val_acc: 0.8560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7586 - acc: 0.7571\n",
      "Epoch 00475: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 0.7586 - acc: 0.7570 - val_loss: 0.4971 - val_acc: 0.8516\n",
      "Epoch 476/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7498 - acc: 0.7573\n",
      "Epoch 00476: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 22s 605us/sample - loss: 0.7498 - acc: 0.7573 - val_loss: 0.4933 - val_acc: 0.8563\n",
      "Epoch 477/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7575 - acc: 0.7558\n",
      "Epoch 00477: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.7576 - acc: 0.7558 - val_loss: 0.4946 - val_acc: 0.8530\n",
      "Epoch 478/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7547 - acc: 0.7583\n",
      "Epoch 00478: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 0.7547 - acc: 0.7583 - val_loss: 0.4949 - val_acc: 0.8542\n",
      "Epoch 479/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7564 - acc: 0.7557\n",
      "Epoch 00479: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.7564 - acc: 0.7557 - val_loss: 0.5022 - val_acc: 0.8539\n",
      "Epoch 480/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7534 - acc: 0.7548\n",
      "Epoch 00480: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 0.7533 - acc: 0.7548 - val_loss: 0.4978 - val_acc: 0.8539\n",
      "Epoch 481/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7603 - acc: 0.7563\n",
      "Epoch 00481: val_loss did not improve from 0.49052\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.7602 - acc: 0.7563 - val_loss: 0.4957 - val_acc: 0.8556\n",
      "Epoch 482/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7516 - acc: 0.7588\n",
      "Epoch 00482: val_loss improved from 0.49052 to 0.49011, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv_checkpoint/482-0.4901.hdf5\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 0.7517 - acc: 0.7588 - val_loss: 0.4901 - val_acc: 0.8586\n",
      "Epoch 483/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7534 - acc: 0.7571\n",
      "Epoch 00483: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.7531 - acc: 0.7572 - val_loss: 0.4953 - val_acc: 0.8553\n",
      "Epoch 484/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7479 - acc: 0.7577\n",
      "Epoch 00484: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 22s 607us/sample - loss: 0.7479 - acc: 0.7578 - val_loss: 0.4936 - val_acc: 0.8546\n",
      "Epoch 485/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7528 - acc: 0.7558\n",
      "Epoch 00485: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 0.7528 - acc: 0.7558 - val_loss: 0.4938 - val_acc: 0.8565\n",
      "Epoch 486/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7534 - acc: 0.7570\n",
      "Epoch 00486: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.7534 - acc: 0.7570 - val_loss: 0.4964 - val_acc: 0.8539\n",
      "Epoch 487/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7510 - acc: 0.7585\n",
      "Epoch 00487: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.7509 - acc: 0.7586 - val_loss: 0.4973 - val_acc: 0.8535\n",
      "Epoch 488/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7523 - acc: 0.7592\n",
      "Epoch 00488: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.7525 - acc: 0.7591 - val_loss: 0.5012 - val_acc: 0.8528\n",
      "Epoch 489/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7531 - acc: 0.7565\n",
      "Epoch 00489: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.7532 - acc: 0.7565 - val_loss: 0.4954 - val_acc: 0.8530\n",
      "Epoch 490/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7498 - acc: 0.7566\n",
      "Epoch 00490: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.7497 - acc: 0.7566 - val_loss: 0.4962 - val_acc: 0.8539\n",
      "Epoch 491/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7566 - acc: 0.7571\n",
      "Epoch 00491: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.7567 - acc: 0.7571 - val_loss: 0.4939 - val_acc: 0.8556\n",
      "Epoch 492/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7514 - acc: 0.7593\n",
      "Epoch 00492: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.7515 - acc: 0.7593 - val_loss: 0.4940 - val_acc: 0.8523\n",
      "Epoch 493/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7516 - acc: 0.7581\n",
      "Epoch 00493: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.7516 - acc: 0.7581 - val_loss: 0.4945 - val_acc: 0.8558\n",
      "Epoch 494/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7524 - acc: 0.7568\n",
      "Epoch 00494: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.7525 - acc: 0.7568 - val_loss: 0.5028 - val_acc: 0.8528\n",
      "Epoch 495/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7429 - acc: 0.7599\n",
      "Epoch 00495: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.7429 - acc: 0.7599 - val_loss: 0.4907 - val_acc: 0.8579\n",
      "Epoch 496/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7473 - acc: 0.7591\n",
      "Epoch 00496: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.7473 - acc: 0.7591 - val_loss: 0.4926 - val_acc: 0.8530\n",
      "Epoch 497/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7498 - acc: 0.7586\n",
      "Epoch 00497: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.7498 - acc: 0.7587 - val_loss: 0.4911 - val_acc: 0.8551\n",
      "Epoch 498/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7463 - acc: 0.7580\n",
      "Epoch 00498: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.7462 - acc: 0.7580 - val_loss: 0.4971 - val_acc: 0.8512\n",
      "Epoch 499/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7490 - acc: 0.7593\n",
      "Epoch 00499: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 23s 626us/sample - loss: 0.7490 - acc: 0.7593 - val_loss: 0.4910 - val_acc: 0.8537\n",
      "Epoch 500/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7504 - acc: 0.7597\n",
      "Epoch 00500: val_loss did not improve from 0.49011\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.7504 - acc: 0.7597 - val_loss: 0.4981 - val_acc: 0.8542\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 347us/sample - loss: 0.5601 - acc: 0.8363\n",
      "Loss: 0.5600777815559324 Accuracy: 0.8363448\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6348 - acc: 0.1261\n",
      "Epoch 00001: val_loss improved from inf to 2.31960, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/001-2.3196.hdf5\n",
      "36805/36805 [==============================] - 26s 698us/sample - loss: 2.6347 - acc: 0.1261 - val_loss: 2.3196 - val_acc: 0.2609\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2696 - acc: 0.2257\n",
      "Epoch 00002: val_loss improved from 2.31960 to 2.01404, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/002-2.0140.hdf5\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 2.2696 - acc: 0.2257 - val_loss: 2.0140 - val_acc: 0.3913\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0756 - acc: 0.2984\n",
      "Epoch 00003: val_loss improved from 2.01404 to 1.77968, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/003-1.7797.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 2.0755 - acc: 0.2984 - val_loss: 1.7797 - val_acc: 0.4689\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9030 - acc: 0.3655\n",
      "Epoch 00004: val_loss improved from 1.77968 to 1.58508, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/004-1.5851.hdf5\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 1.9030 - acc: 0.3655 - val_loss: 1.5851 - val_acc: 0.5094\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7619 - acc: 0.4147\n",
      "Epoch 00005: val_loss improved from 1.58508 to 1.41123, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/005-1.4112.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 1.7619 - acc: 0.4148 - val_loss: 1.4112 - val_acc: 0.5693\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6394 - acc: 0.4544\n",
      "Epoch 00006: val_loss improved from 1.41123 to 1.31243, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/006-1.3124.hdf5\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 1.6391 - acc: 0.4544 - val_loss: 1.3124 - val_acc: 0.6019\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5493 - acc: 0.4882\n",
      "Epoch 00007: val_loss improved from 1.31243 to 1.19160, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/007-1.1916.hdf5\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 1.5494 - acc: 0.4881 - val_loss: 1.1916 - val_acc: 0.6422\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4619 - acc: 0.5199\n",
      "Epoch 00008: val_loss improved from 1.19160 to 1.10672, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/008-1.1067.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 1.4618 - acc: 0.5198 - val_loss: 1.1067 - val_acc: 0.6823\n",
      "Epoch 9/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3887 - acc: 0.5468\n",
      "Epoch 00009: val_loss improved from 1.10672 to 1.04216, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/009-1.0422.hdf5\n",
      "36805/36805 [==============================] - 24s 651us/sample - loss: 1.3885 - acc: 0.5468 - val_loss: 1.0422 - val_acc: 0.6997\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3171 - acc: 0.5696\n",
      "Epoch 00010: val_loss improved from 1.04216 to 0.97489, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/010-0.9749.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 1.3172 - acc: 0.5696 - val_loss: 0.9749 - val_acc: 0.7221\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2589 - acc: 0.5952\n",
      "Epoch 00011: val_loss improved from 0.97489 to 0.90787, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/011-0.9079.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 1.2589 - acc: 0.5952 - val_loss: 0.9079 - val_acc: 0.7340\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1999 - acc: 0.6147\n",
      "Epoch 00012: val_loss improved from 0.90787 to 0.84950, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/012-0.8495.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 1.1999 - acc: 0.6147 - val_loss: 0.8495 - val_acc: 0.7591\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1462 - acc: 0.6346\n",
      "Epoch 00013: val_loss improved from 0.84950 to 0.79809, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/013-0.7981.hdf5\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 1.1462 - acc: 0.6346 - val_loss: 0.7981 - val_acc: 0.7678\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0991 - acc: 0.6518\n",
      "Epoch 00014: val_loss improved from 0.79809 to 0.78187, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/014-0.7819.hdf5\n",
      "36805/36805 [==============================] - 24s 651us/sample - loss: 1.0991 - acc: 0.6518 - val_loss: 0.7819 - val_acc: 0.7803\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0723 - acc: 0.6606\n",
      "Epoch 00015: val_loss improved from 0.78187 to 0.73154, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/015-0.7315.hdf5\n",
      "36805/36805 [==============================] - 24s 651us/sample - loss: 1.0722 - acc: 0.6606 - val_loss: 0.7315 - val_acc: 0.7929\n",
      "Epoch 16/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0324 - acc: 0.6722\n",
      "Epoch 00016: val_loss improved from 0.73154 to 0.69370, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/016-0.6937.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 1.0326 - acc: 0.6721 - val_loss: 0.6937 - val_acc: 0.7971\n",
      "Epoch 17/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9973 - acc: 0.6824\n",
      "Epoch 00017: val_loss improved from 0.69370 to 0.69349, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/017-0.6935.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.9974 - acc: 0.6824 - val_loss: 0.6935 - val_acc: 0.8118\n",
      "Epoch 18/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9712 - acc: 0.6939\n",
      "Epoch 00018: val_loss improved from 0.69349 to 0.68071, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/018-0.6807.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.9708 - acc: 0.6939 - val_loss: 0.6807 - val_acc: 0.8020\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9458 - acc: 0.7036\n",
      "Epoch 00019: val_loss improved from 0.68071 to 0.63315, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/019-0.6332.hdf5\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.9457 - acc: 0.7037 - val_loss: 0.6332 - val_acc: 0.8169\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9224 - acc: 0.7147\n",
      "Epoch 00020: val_loss improved from 0.63315 to 0.61002, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/020-0.6100.hdf5\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.9225 - acc: 0.7146 - val_loss: 0.6100 - val_acc: 0.8314\n",
      "Epoch 21/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8983 - acc: 0.7216\n",
      "Epoch 00021: val_loss improved from 0.61002 to 0.58559, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/021-0.5856.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.8988 - acc: 0.7215 - val_loss: 0.5856 - val_acc: 0.8328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8735 - acc: 0.7279\n",
      "Epoch 00022: val_loss improved from 0.58559 to 0.57951, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/022-0.5795.hdf5\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.8735 - acc: 0.7279 - val_loss: 0.5795 - val_acc: 0.8334\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8628 - acc: 0.7349\n",
      "Epoch 00023: val_loss improved from 0.57951 to 0.56685, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/023-0.5669.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.8628 - acc: 0.7349 - val_loss: 0.5669 - val_acc: 0.8372\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8552 - acc: 0.7344\n",
      "Epoch 00024: val_loss improved from 0.56685 to 0.54176, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/024-0.5418.hdf5\n",
      "36805/36805 [==============================] - 24s 652us/sample - loss: 0.8556 - acc: 0.7343 - val_loss: 0.5418 - val_acc: 0.8514\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8291 - acc: 0.7439\n",
      "Epoch 00025: val_loss improved from 0.54176 to 0.52904, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/025-0.5290.hdf5\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.8292 - acc: 0.7439 - val_loss: 0.5290 - val_acc: 0.8486\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8134 - acc: 0.7467\n",
      "Epoch 00026: val_loss improved from 0.52904 to 0.52175, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/026-0.5218.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.8135 - acc: 0.7466 - val_loss: 0.5218 - val_acc: 0.8544\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7975 - acc: 0.7521\n",
      "Epoch 00027: val_loss improved from 0.52175 to 0.49902, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/027-0.4990.hdf5\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.7975 - acc: 0.7521 - val_loss: 0.4990 - val_acc: 0.8593\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7822 - acc: 0.7587\n",
      "Epoch 00028: val_loss did not improve from 0.49902\n",
      "36805/36805 [==============================] - 24s 651us/sample - loss: 0.7825 - acc: 0.7586 - val_loss: 0.5125 - val_acc: 0.8491\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7770 - acc: 0.7607\n",
      "Epoch 00029: val_loss improved from 0.49902 to 0.49690, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/029-0.4969.hdf5\n",
      "36805/36805 [==============================] - 24s 652us/sample - loss: 0.7770 - acc: 0.7607 - val_loss: 0.4969 - val_acc: 0.8609\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7625 - acc: 0.7629\n",
      "Epoch 00030: val_loss improved from 0.49690 to 0.47755, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/030-0.4775.hdf5\n",
      "36805/36805 [==============================] - 24s 653us/sample - loss: 0.7625 - acc: 0.7630 - val_loss: 0.4775 - val_acc: 0.8640\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7536 - acc: 0.7653\n",
      "Epoch 00031: val_loss improved from 0.47755 to 0.46271, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/031-0.4627.hdf5\n",
      "36805/36805 [==============================] - 24s 652us/sample - loss: 0.7536 - acc: 0.7652 - val_loss: 0.4627 - val_acc: 0.8689\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7490 - acc: 0.7679\n",
      "Epoch 00032: val_loss did not improve from 0.46271\n",
      "36805/36805 [==============================] - 24s 653us/sample - loss: 0.7490 - acc: 0.7680 - val_loss: 0.4744 - val_acc: 0.8663\n",
      "Epoch 33/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7383 - acc: 0.7731\n",
      "Epoch 00033: val_loss improved from 0.46271 to 0.44932, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/033-0.4493.hdf5\n",
      "36805/36805 [==============================] - 24s 655us/sample - loss: 0.7380 - acc: 0.7732 - val_loss: 0.4493 - val_acc: 0.8714\n",
      "Epoch 34/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7294 - acc: 0.7744\n",
      "Epoch 00034: val_loss did not improve from 0.44932\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.7295 - acc: 0.7745 - val_loss: 0.4537 - val_acc: 0.8675\n",
      "Epoch 35/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7172 - acc: 0.7785\n",
      "Epoch 00035: val_loss did not improve from 0.44932\n",
      "36805/36805 [==============================] - 23s 634us/sample - loss: 0.7177 - acc: 0.7784 - val_loss: 0.4564 - val_acc: 0.8686\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7121 - acc: 0.7809\n",
      "Epoch 00036: val_loss improved from 0.44932 to 0.44873, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/036-0.4487.hdf5\n",
      "36805/36805 [==============================] - 24s 652us/sample - loss: 0.7122 - acc: 0.7809 - val_loss: 0.4487 - val_acc: 0.8698\n",
      "Epoch 37/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6993 - acc: 0.7849\n",
      "Epoch 00037: val_loss improved from 0.44873 to 0.43298, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/037-0.4330.hdf5\n",
      "36805/36805 [==============================] - 24s 655us/sample - loss: 0.6994 - acc: 0.7849 - val_loss: 0.4330 - val_acc: 0.8779\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6992 - acc: 0.7847\n",
      "Epoch 00038: val_loss improved from 0.43298 to 0.42934, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/038-0.4293.hdf5\n",
      "36805/36805 [==============================] - 24s 653us/sample - loss: 0.6995 - acc: 0.7846 - val_loss: 0.4293 - val_acc: 0.8777\n",
      "Epoch 39/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6909 - acc: 0.7868\n",
      "Epoch 00039: val_loss did not improve from 0.42934\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.6913 - acc: 0.7867 - val_loss: 0.4333 - val_acc: 0.8786\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6848 - acc: 0.7907\n",
      "Epoch 00040: val_loss did not improve from 0.42934\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.6847 - acc: 0.7908 - val_loss: 0.4295 - val_acc: 0.8779\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6811 - acc: 0.7894\n",
      "Epoch 00041: val_loss improved from 0.42934 to 0.40743, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/041-0.4074.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.6811 - acc: 0.7894 - val_loss: 0.4074 - val_acc: 0.8814\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6685 - acc: 0.7921\n",
      "Epoch 00042: val_loss did not improve from 0.40743\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.6684 - acc: 0.7922 - val_loss: 0.4110 - val_acc: 0.8817\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6660 - acc: 0.7941\n",
      "Epoch 00043: val_loss did not improve from 0.40743\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.6661 - acc: 0.7940 - val_loss: 0.4100 - val_acc: 0.8810\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6590 - acc: 0.7983\n",
      "Epoch 00044: val_loss improved from 0.40743 to 0.40355, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/044-0.4036.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.6591 - acc: 0.7983 - val_loss: 0.4036 - val_acc: 0.8800\n",
      "Epoch 45/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6589 - acc: 0.7986\n",
      "Epoch 00045: val_loss did not improve from 0.40355\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.6587 - acc: 0.7986 - val_loss: 0.4164 - val_acc: 0.8779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6488 - acc: 0.7996\n",
      "Epoch 00046: val_loss did not improve from 0.40355\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.6489 - acc: 0.7996 - val_loss: 0.4113 - val_acc: 0.8786\n",
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6475 - acc: 0.8009\n",
      "Epoch 00047: val_loss improved from 0.40355 to 0.38719, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/047-0.3872.hdf5\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.6480 - acc: 0.8008 - val_loss: 0.3872 - val_acc: 0.8859\n",
      "Epoch 48/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6456 - acc: 0.8014\n",
      "Epoch 00048: val_loss did not improve from 0.38719\n",
      "36805/36805 [==============================] - 24s 653us/sample - loss: 0.6455 - acc: 0.8014 - val_loss: 0.3881 - val_acc: 0.8908\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6371 - acc: 0.8048\n",
      "Epoch 00049: val_loss improved from 0.38719 to 0.38554, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/049-0.3855.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.6372 - acc: 0.8048 - val_loss: 0.3855 - val_acc: 0.8910\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6387 - acc: 0.8051\n",
      "Epoch 00050: val_loss improved from 0.38554 to 0.37490, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/050-0.3749.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.6386 - acc: 0.8051 - val_loss: 0.3749 - val_acc: 0.8933\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6284 - acc: 0.8077\n",
      "Epoch 00051: val_loss did not improve from 0.37490\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.6279 - acc: 0.8078 - val_loss: 0.3830 - val_acc: 0.8898\n",
      "Epoch 52/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6230 - acc: 0.8068\n",
      "Epoch 00052: val_loss improved from 0.37490 to 0.37401, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/052-0.3740.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.6231 - acc: 0.8067 - val_loss: 0.3740 - val_acc: 0.8915\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6219 - acc: 0.8053\n",
      "Epoch 00053: val_loss did not improve from 0.37401\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.6219 - acc: 0.8053 - val_loss: 0.3758 - val_acc: 0.8891\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6133 - acc: 0.8100\n",
      "Epoch 00054: val_loss improved from 0.37401 to 0.36450, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/054-0.3645.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.6132 - acc: 0.8100 - val_loss: 0.3645 - val_acc: 0.8924\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6103 - acc: 0.8112\n",
      "Epoch 00055: val_loss did not improve from 0.36450\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.6106 - acc: 0.8111 - val_loss: 0.3645 - val_acc: 0.8942\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6143 - acc: 0.8117\n",
      "Epoch 00056: val_loss improved from 0.36450 to 0.36386, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/056-0.3639.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.6143 - acc: 0.8117 - val_loss: 0.3639 - val_acc: 0.8961\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6030 - acc: 0.8165\n",
      "Epoch 00057: val_loss improved from 0.36386 to 0.35983, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/057-0.3598.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.6030 - acc: 0.8165 - val_loss: 0.3598 - val_acc: 0.8987\n",
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5989 - acc: 0.8163\n",
      "Epoch 00058: val_loss did not improve from 0.35983\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.5988 - acc: 0.8163 - val_loss: 0.3857 - val_acc: 0.8866\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5992 - acc: 0.8160\n",
      "Epoch 00059: val_loss improved from 0.35983 to 0.35016, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/059-0.3502.hdf5\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.5996 - acc: 0.8159 - val_loss: 0.3502 - val_acc: 0.9001\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6006 - acc: 0.8151\n",
      "Epoch 00060: val_loss did not improve from 0.35016\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.6008 - acc: 0.8151 - val_loss: 0.3644 - val_acc: 0.8968\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5946 - acc: 0.8153\n",
      "Epoch 00061: val_loss did not improve from 0.35016\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.5947 - acc: 0.8153 - val_loss: 0.3643 - val_acc: 0.8973\n",
      "Epoch 62/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5889 - acc: 0.8186\n",
      "Epoch 00062: val_loss did not improve from 0.35016\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.5888 - acc: 0.8186 - val_loss: 0.3583 - val_acc: 0.8926\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5867 - acc: 0.8203\n",
      "Epoch 00063: val_loss improved from 0.35016 to 0.34290, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/063-0.3429.hdf5\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.5868 - acc: 0.8203 - val_loss: 0.3429 - val_acc: 0.9040\n",
      "Epoch 64/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5775 - acc: 0.8222\n",
      "Epoch 00064: val_loss did not improve from 0.34290\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.5777 - acc: 0.8221 - val_loss: 0.3820 - val_acc: 0.8915\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5846 - acc: 0.8189\n",
      "Epoch 00065: val_loss improved from 0.34290 to 0.34127, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/065-0.3413.hdf5\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.5846 - acc: 0.8189 - val_loss: 0.3413 - val_acc: 0.9033\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5780 - acc: 0.8228\n",
      "Epoch 00066: val_loss did not improve from 0.34127\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.5781 - acc: 0.8228 - val_loss: 0.3491 - val_acc: 0.8947\n",
      "Epoch 67/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5741 - acc: 0.8221\n",
      "Epoch 00067: val_loss did not improve from 0.34127\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.5741 - acc: 0.8220 - val_loss: 0.3507 - val_acc: 0.9017\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5767 - acc: 0.8220\n",
      "Epoch 00068: val_loss improved from 0.34127 to 0.33517, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/068-0.3352.hdf5\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.5767 - acc: 0.8220 - val_loss: 0.3352 - val_acc: 0.9036\n",
      "Epoch 69/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5599 - acc: 0.8272\n",
      "Epoch 00069: val_loss did not improve from 0.33517\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.5599 - acc: 0.8273 - val_loss: 0.3431 - val_acc: 0.8991\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5644 - acc: 0.8286\n",
      "Epoch 00070: val_loss improved from 0.33517 to 0.33360, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/070-0.3336.hdf5\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.5643 - acc: 0.8287 - val_loss: 0.3336 - val_acc: 0.9057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5700 - acc: 0.8244\n",
      "Epoch 00071: val_loss did not improve from 0.33360\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.5700 - acc: 0.8244 - val_loss: 0.3341 - val_acc: 0.9040\n",
      "Epoch 72/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5633 - acc: 0.8234\n",
      "Epoch 00072: val_loss improved from 0.33360 to 0.32785, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/072-0.3279.hdf5\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.5632 - acc: 0.8235 - val_loss: 0.3279 - val_acc: 0.9054\n",
      "Epoch 73/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5556 - acc: 0.8284\n",
      "Epoch 00073: val_loss did not improve from 0.32785\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.5558 - acc: 0.8283 - val_loss: 0.3379 - val_acc: 0.9052\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5565 - acc: 0.8283\n",
      "Epoch 00074: val_loss did not improve from 0.32785\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.5565 - acc: 0.8283 - val_loss: 0.3388 - val_acc: 0.9029\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5613 - acc: 0.8260\n",
      "Epoch 00075: val_loss did not improve from 0.32785\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.5613 - acc: 0.8260 - val_loss: 0.3389 - val_acc: 0.9054\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5462 - acc: 0.8313\n",
      "Epoch 00076: val_loss improved from 0.32785 to 0.32433, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/076-0.3243.hdf5\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.5462 - acc: 0.8312 - val_loss: 0.3243 - val_acc: 0.9075\n",
      "Epoch 77/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5501 - acc: 0.8299\n",
      "Epoch 00077: val_loss did not improve from 0.32433\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.5503 - acc: 0.8299 - val_loss: 0.3300 - val_acc: 0.9066\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5554 - acc: 0.8288\n",
      "Epoch 00078: val_loss did not improve from 0.32433\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.5555 - acc: 0.8288 - val_loss: 0.3296 - val_acc: 0.9073\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5493 - acc: 0.8314\n",
      "Epoch 00079: val_loss did not improve from 0.32433\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.5493 - acc: 0.8314 - val_loss: 0.3329 - val_acc: 0.8982\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5404 - acc: 0.8321\n",
      "Epoch 00080: val_loss improved from 0.32433 to 0.31797, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/080-0.3180.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.5404 - acc: 0.8321 - val_loss: 0.3180 - val_acc: 0.9103\n",
      "Epoch 81/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5436 - acc: 0.8338\n",
      "Epoch 00081: val_loss did not improve from 0.31797\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.5432 - acc: 0.8339 - val_loss: 0.3195 - val_acc: 0.9096\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5391 - acc: 0.8349\n",
      "Epoch 00082: val_loss did not improve from 0.31797\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.5392 - acc: 0.8348 - val_loss: 0.3261 - val_acc: 0.9073\n",
      "Epoch 83/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5363 - acc: 0.8348\n",
      "Epoch 00083: val_loss improved from 0.31797 to 0.31788, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/083-0.3179.hdf5\n",
      "36805/36805 [==============================] - 24s 652us/sample - loss: 0.5367 - acc: 0.8347 - val_loss: 0.3179 - val_acc: 0.9119\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5342 - acc: 0.8368\n",
      "Epoch 00084: val_loss did not improve from 0.31788\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.5342 - acc: 0.8368 - val_loss: 0.3259 - val_acc: 0.9099\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5352 - acc: 0.8353\n",
      "Epoch 00085: val_loss improved from 0.31788 to 0.31600, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/085-0.3160.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.5352 - acc: 0.8353 - val_loss: 0.3160 - val_acc: 0.9103\n",
      "Epoch 86/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5268 - acc: 0.8366\n",
      "Epoch 00086: val_loss improved from 0.31600 to 0.31274, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/086-0.3127.hdf5\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.5269 - acc: 0.8366 - val_loss: 0.3127 - val_acc: 0.9096\n",
      "Epoch 87/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5268 - acc: 0.8369\n",
      "Epoch 00087: val_loss improved from 0.31274 to 0.31002, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/087-0.3100.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.5268 - acc: 0.8369 - val_loss: 0.3100 - val_acc: 0.9133\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5262 - acc: 0.8368\n",
      "Epoch 00088: val_loss did not improve from 0.31002\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.5262 - acc: 0.8369 - val_loss: 0.3146 - val_acc: 0.9147\n",
      "Epoch 89/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5288 - acc: 0.8375\n",
      "Epoch 00089: val_loss did not improve from 0.31002\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.5286 - acc: 0.8376 - val_loss: 0.3288 - val_acc: 0.9103\n",
      "Epoch 90/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5191 - acc: 0.8390\n",
      "Epoch 00090: val_loss did not improve from 0.31002\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.5190 - acc: 0.8390 - val_loss: 0.3107 - val_acc: 0.9154\n",
      "Epoch 91/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5161 - acc: 0.8408\n",
      "Epoch 00091: val_loss improved from 0.31002 to 0.30877, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/091-0.3088.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.5160 - acc: 0.8408 - val_loss: 0.3088 - val_acc: 0.9124\n",
      "Epoch 92/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5109 - acc: 0.8413\n",
      "Epoch 00092: val_loss improved from 0.30877 to 0.30820, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/092-0.3082.hdf5\n",
      "36805/36805 [==============================] - 24s 639us/sample - loss: 0.5110 - acc: 0.8413 - val_loss: 0.3082 - val_acc: 0.9154\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5088 - acc: 0.8432\n",
      "Epoch 00093: val_loss improved from 0.30820 to 0.30449, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/093-0.3045.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.5088 - acc: 0.8432 - val_loss: 0.3045 - val_acc: 0.9168\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5118 - acc: 0.8415\n",
      "Epoch 00094: val_loss did not improve from 0.30449\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.5118 - acc: 0.8415 - val_loss: 0.3091 - val_acc: 0.9101\n",
      "Epoch 95/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5051 - acc: 0.8452\n",
      "Epoch 00095: val_loss did not improve from 0.30449\n",
      "36805/36805 [==============================] - 24s 654us/sample - loss: 0.5052 - acc: 0.8452 - val_loss: 0.3092 - val_acc: 0.9133\n",
      "Epoch 96/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5080 - acc: 0.8440\n",
      "Epoch 00096: val_loss improved from 0.30449 to 0.29791, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/096-0.2979.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.5078 - acc: 0.8441 - val_loss: 0.2979 - val_acc: 0.9159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5100 - acc: 0.8430\n",
      "Epoch 00097: val_loss did not improve from 0.29791\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.5095 - acc: 0.8431 - val_loss: 0.3073 - val_acc: 0.9166\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5037 - acc: 0.8448\n",
      "Epoch 00098: val_loss improved from 0.29791 to 0.29623, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/098-0.2962.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.5038 - acc: 0.8448 - val_loss: 0.2962 - val_acc: 0.9180\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5067 - acc: 0.8424\n",
      "Epoch 00099: val_loss did not improve from 0.29623\n",
      "36805/36805 [==============================] - 24s 652us/sample - loss: 0.5067 - acc: 0.8424 - val_loss: 0.3004 - val_acc: 0.9171\n",
      "Epoch 100/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5050 - acc: 0.8449\n",
      "Epoch 00100: val_loss did not improve from 0.29623\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.5049 - acc: 0.8449 - val_loss: 0.3105 - val_acc: 0.9113\n",
      "Epoch 101/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5010 - acc: 0.8441\n",
      "Epoch 00101: val_loss did not improve from 0.29623\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.5015 - acc: 0.8441 - val_loss: 0.3000 - val_acc: 0.9152\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4949 - acc: 0.8486\n",
      "Epoch 00102: val_loss did not improve from 0.29623\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.4948 - acc: 0.8486 - val_loss: 0.2975 - val_acc: 0.9147\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4903 - acc: 0.8470\n",
      "Epoch 00103: val_loss did not improve from 0.29623\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4903 - acc: 0.8470 - val_loss: 0.3102 - val_acc: 0.9122\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4998 - acc: 0.8447\n",
      "Epoch 00104: val_loss improved from 0.29623 to 0.29608, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/104-0.2961.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4999 - acc: 0.8446 - val_loss: 0.2961 - val_acc: 0.9168\n",
      "Epoch 105/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4992 - acc: 0.8467\n",
      "Epoch 00105: val_loss did not improve from 0.29608\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.4996 - acc: 0.8466 - val_loss: 0.3020 - val_acc: 0.9106\n",
      "Epoch 106/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4888 - acc: 0.8490\n",
      "Epoch 00106: val_loss did not improve from 0.29608\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4886 - acc: 0.8490 - val_loss: 0.3029 - val_acc: 0.9126\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4939 - acc: 0.8477\n",
      "Epoch 00107: val_loss improved from 0.29608 to 0.29123, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/107-0.2912.hdf5\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.4938 - acc: 0.8477 - val_loss: 0.2912 - val_acc: 0.9194\n",
      "Epoch 108/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4969 - acc: 0.8473\n",
      "Epoch 00108: val_loss did not improve from 0.29123\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.4969 - acc: 0.8474 - val_loss: 0.3040 - val_acc: 0.9189\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4895 - acc: 0.8491\n",
      "Epoch 00109: val_loss improved from 0.29123 to 0.29071, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/109-0.2907.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.4895 - acc: 0.8492 - val_loss: 0.2907 - val_acc: 0.9173\n",
      "Epoch 110/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4846 - acc: 0.8524\n",
      "Epoch 00110: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4848 - acc: 0.8522 - val_loss: 0.2937 - val_acc: 0.9171\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4869 - acc: 0.8495\n",
      "Epoch 00111: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4868 - acc: 0.8495 - val_loss: 0.2949 - val_acc: 0.9175\n",
      "Epoch 112/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4858 - acc: 0.8496\n",
      "Epoch 00112: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.4857 - acc: 0.8496 - val_loss: 0.2985 - val_acc: 0.9147\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4788 - acc: 0.8517\n",
      "Epoch 00113: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 24s 640us/sample - loss: 0.4788 - acc: 0.8517 - val_loss: 0.2921 - val_acc: 0.9147\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4858 - acc: 0.8502\n",
      "Epoch 00114: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4858 - acc: 0.8502 - val_loss: 0.3015 - val_acc: 0.9124\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4805 - acc: 0.8521\n",
      "Epoch 00115: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4804 - acc: 0.8521 - val_loss: 0.3082 - val_acc: 0.9082\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4784 - acc: 0.8523\n",
      "Epoch 00116: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4785 - acc: 0.8523 - val_loss: 0.2921 - val_acc: 0.9182\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.8484\n",
      "Epoch 00117: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4789 - acc: 0.8484 - val_loss: 0.3023 - val_acc: 0.9152\n",
      "Epoch 118/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4769 - acc: 0.8524\n",
      "Epoch 00118: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4766 - acc: 0.8526 - val_loss: 0.2964 - val_acc: 0.9152\n",
      "Epoch 119/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4756 - acc: 0.8529\n",
      "Epoch 00119: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4755 - acc: 0.8530 - val_loss: 0.2965 - val_acc: 0.9189\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4754 - acc: 0.8533\n",
      "Epoch 00120: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4755 - acc: 0.8533 - val_loss: 0.2929 - val_acc: 0.9164\n",
      "Epoch 121/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4785 - acc: 0.8507\n",
      "Epoch 00121: val_loss improved from 0.29071 to 0.28939, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/121-0.2894.hdf5\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4782 - acc: 0.8508 - val_loss: 0.2894 - val_acc: 0.9147\n",
      "Epoch 122/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4645 - acc: 0.8569\n",
      "Epoch 00122: val_loss did not improve from 0.28939\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4647 - acc: 0.8568 - val_loss: 0.2906 - val_acc: 0.9173\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4686 - acc: 0.8531\n",
      "Epoch 00123: val_loss did not improve from 0.28939\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4685 - acc: 0.8531 - val_loss: 0.2985 - val_acc: 0.9171\n",
      "Epoch 124/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8544\n",
      "Epoch 00124: val_loss improved from 0.28939 to 0.28693, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/124-0.2869.hdf5\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4656 - acc: 0.8545 - val_loss: 0.2869 - val_acc: 0.9213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4678 - acc: 0.8560\n",
      "Epoch 00125: val_loss did not improve from 0.28693\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.4678 - acc: 0.8560 - val_loss: 0.2936 - val_acc: 0.9178\n",
      "Epoch 126/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8545\n",
      "Epoch 00126: val_loss improved from 0.28693 to 0.28344, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/126-0.2834.hdf5\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.4656 - acc: 0.8545 - val_loss: 0.2834 - val_acc: 0.9208\n",
      "Epoch 127/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4579 - acc: 0.8584\n",
      "Epoch 00127: val_loss improved from 0.28344 to 0.27930, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/127-0.2793.hdf5\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4577 - acc: 0.8584 - val_loss: 0.2793 - val_acc: 0.9213\n",
      "Epoch 128/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4637 - acc: 0.8559\n",
      "Epoch 00128: val_loss did not improve from 0.27930\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.4639 - acc: 0.8558 - val_loss: 0.2877 - val_acc: 0.9178\n",
      "Epoch 129/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4617 - acc: 0.8548\n",
      "Epoch 00129: val_loss did not improve from 0.27930\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4620 - acc: 0.8547 - val_loss: 0.2830 - val_acc: 0.9199\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.8556\n",
      "Epoch 00130: val_loss did not improve from 0.27930\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4620 - acc: 0.8556 - val_loss: 0.2852 - val_acc: 0.9189\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4571 - acc: 0.8582\n",
      "Epoch 00131: val_loss did not improve from 0.27930\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.4570 - acc: 0.8582 - val_loss: 0.2873 - val_acc: 0.9189\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4611 - acc: 0.8579\n",
      "Epoch 00132: val_loss did not improve from 0.27930\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.4610 - acc: 0.8579 - val_loss: 0.2833 - val_acc: 0.9231\n",
      "Epoch 133/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8562\n",
      "Epoch 00133: val_loss did not improve from 0.27930\n",
      "36805/36805 [==============================] - 24s 639us/sample - loss: 0.4591 - acc: 0.8562 - val_loss: 0.2852 - val_acc: 0.9185\n",
      "Epoch 134/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4573 - acc: 0.8582\n",
      "Epoch 00134: val_loss improved from 0.27930 to 0.27664, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/134-0.2766.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.4571 - acc: 0.8581 - val_loss: 0.2766 - val_acc: 0.9213\n",
      "Epoch 135/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4554 - acc: 0.8597\n",
      "Epoch 00135: val_loss did not improve from 0.27664\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4556 - acc: 0.8596 - val_loss: 0.2980 - val_acc: 0.9113\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4516 - acc: 0.8602\n",
      "Epoch 00136: val_loss did not improve from 0.27664\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4515 - acc: 0.8603 - val_loss: 0.2839 - val_acc: 0.9215\n",
      "Epoch 137/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8592\n",
      "Epoch 00137: val_loss did not improve from 0.27664\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.4504 - acc: 0.8592 - val_loss: 0.2820 - val_acc: 0.9208\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4457 - acc: 0.8601\n",
      "Epoch 00138: val_loss did not improve from 0.27664\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.4457 - acc: 0.8600 - val_loss: 0.2834 - val_acc: 0.9203\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4471 - acc: 0.8620\n",
      "Epoch 00139: val_loss did not improve from 0.27664\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.4470 - acc: 0.8620 - val_loss: 0.2768 - val_acc: 0.9210\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4471 - acc: 0.8607\n",
      "Epoch 00140: val_loss improved from 0.27664 to 0.27542, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/140-0.2754.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4471 - acc: 0.8607 - val_loss: 0.2754 - val_acc: 0.9217\n",
      "Epoch 141/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8618\n",
      "Epoch 00141: val_loss did not improve from 0.27542\n",
      "36805/36805 [==============================] - 25s 667us/sample - loss: 0.4463 - acc: 0.8619 - val_loss: 0.2904 - val_acc: 0.9220\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4491 - acc: 0.8607\n",
      "Epoch 00142: val_loss did not improve from 0.27542\n",
      "36805/36805 [==============================] - 24s 653us/sample - loss: 0.4491 - acc: 0.8607 - val_loss: 0.2890 - val_acc: 0.9194\n",
      "Epoch 143/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4485 - acc: 0.8617\n",
      "Epoch 00143: val_loss did not improve from 0.27542\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.4486 - acc: 0.8617 - val_loss: 0.2771 - val_acc: 0.9206\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4426 - acc: 0.8644\n",
      "Epoch 00144: val_loss did not improve from 0.27542\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4426 - acc: 0.8644 - val_loss: 0.2797 - val_acc: 0.9215\n",
      "Epoch 145/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4435 - acc: 0.8625\n",
      "Epoch 00145: val_loss did not improve from 0.27542\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4438 - acc: 0.8624 - val_loss: 0.2809 - val_acc: 0.9217\n",
      "Epoch 146/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4407 - acc: 0.8641\n",
      "Epoch 00146: val_loss did not improve from 0.27542\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4407 - acc: 0.8642 - val_loss: 0.2910 - val_acc: 0.9136\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4411 - acc: 0.8625\n",
      "Epoch 00147: val_loss did not improve from 0.27542\n",
      "36805/36805 [==============================] - 24s 641us/sample - loss: 0.4411 - acc: 0.8625 - val_loss: 0.2855 - val_acc: 0.9168\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4376 - acc: 0.8657\n",
      "Epoch 00148: val_loss did not improve from 0.27542\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4375 - acc: 0.8657 - val_loss: 0.2867 - val_acc: 0.9182\n",
      "Epoch 149/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4334 - acc: 0.8665\n",
      "Epoch 00149: val_loss did not improve from 0.27542\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.4332 - acc: 0.8665 - val_loss: 0.2762 - val_acc: 0.9220\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4380 - acc: 0.8647\n",
      "Epoch 00150: val_loss did not improve from 0.27542\n",
      "36805/36805 [==============================] - 23s 632us/sample - loss: 0.4380 - acc: 0.8647 - val_loss: 0.2835 - val_acc: 0.9173\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4361 - acc: 0.8655\n",
      "Epoch 00151: val_loss improved from 0.27542 to 0.27251, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/151-0.2725.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4361 - acc: 0.8655 - val_loss: 0.2725 - val_acc: 0.9224\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4342 - acc: 0.8651\n",
      "Epoch 00152: val_loss did not improve from 0.27251\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.4342 - acc: 0.8651 - val_loss: 0.2731 - val_acc: 0.9208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4353 - acc: 0.8645\n",
      "Epoch 00153: val_loss did not improve from 0.27251\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4356 - acc: 0.8644 - val_loss: 0.2731 - val_acc: 0.9227\n",
      "Epoch 154/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4292 - acc: 0.8671\n",
      "Epoch 00154: val_loss did not improve from 0.27251\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.4291 - acc: 0.8672 - val_loss: 0.2759 - val_acc: 0.9220\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4339 - acc: 0.8665\n",
      "Epoch 00155: val_loss did not improve from 0.27251\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4338 - acc: 0.8665 - val_loss: 0.2823 - val_acc: 0.9201\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4291 - acc: 0.8649\n",
      "Epoch 00156: val_loss did not improve from 0.27251\n",
      "36805/36805 [==============================] - 24s 640us/sample - loss: 0.4291 - acc: 0.8649 - val_loss: 0.2825 - val_acc: 0.9178\n",
      "Epoch 157/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4259 - acc: 0.8658\n",
      "Epoch 00157: val_loss did not improve from 0.27251\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.4259 - acc: 0.8659 - val_loss: 0.2846 - val_acc: 0.9194\n",
      "Epoch 158/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4279 - acc: 0.8658\n",
      "Epoch 00158: val_loss did not improve from 0.27251\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.4284 - acc: 0.8657 - val_loss: 0.2778 - val_acc: 0.9196\n",
      "Epoch 159/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4326 - acc: 0.8664\n",
      "Epoch 00159: val_loss improved from 0.27251 to 0.27250, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/159-0.2725.hdf5\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4328 - acc: 0.8663 - val_loss: 0.2725 - val_acc: 0.9231\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4280 - acc: 0.8665\n",
      "Epoch 00160: val_loss did not improve from 0.27250\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4281 - acc: 0.8665 - val_loss: 0.2770 - val_acc: 0.9222\n",
      "Epoch 161/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4291 - acc: 0.8656\n",
      "Epoch 00161: val_loss improved from 0.27250 to 0.27096, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/161-0.2710.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.4292 - acc: 0.8657 - val_loss: 0.2710 - val_acc: 0.9248\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4211 - acc: 0.8684\n",
      "Epoch 00162: val_loss did not improve from 0.27096\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4210 - acc: 0.8684 - val_loss: 0.2718 - val_acc: 0.9224\n",
      "Epoch 163/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4237 - acc: 0.8679\n",
      "Epoch 00163: val_loss improved from 0.27096 to 0.26888, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/163-0.2689.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.4237 - acc: 0.8680 - val_loss: 0.2689 - val_acc: 0.9227\n",
      "Epoch 164/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4186 - acc: 0.8703\n",
      "Epoch 00164: val_loss improved from 0.26888 to 0.26814, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/164-0.2681.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4185 - acc: 0.8704 - val_loss: 0.2681 - val_acc: 0.9236\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4255 - acc: 0.8680\n",
      "Epoch 00165: val_loss did not improve from 0.26814\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4255 - acc: 0.8680 - val_loss: 0.2735 - val_acc: 0.9213\n",
      "Epoch 166/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4229 - acc: 0.8676\n",
      "Epoch 00166: val_loss did not improve from 0.26814\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4226 - acc: 0.8676 - val_loss: 0.2746 - val_acc: 0.9243\n",
      "Epoch 167/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4171 - acc: 0.8690\n",
      "Epoch 00167: val_loss did not improve from 0.26814\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4169 - acc: 0.8691 - val_loss: 0.2761 - val_acc: 0.9220\n",
      "Epoch 168/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4168 - acc: 0.8709\n",
      "Epoch 00168: val_loss did not improve from 0.26814\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4170 - acc: 0.8709 - val_loss: 0.2760 - val_acc: 0.9196\n",
      "Epoch 169/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4216 - acc: 0.8686\n",
      "Epoch 00169: val_loss did not improve from 0.26814\n",
      "36805/36805 [==============================] - 24s 651us/sample - loss: 0.4215 - acc: 0.8686 - val_loss: 0.2804 - val_acc: 0.9187\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4241 - acc: 0.8680\n",
      "Epoch 00170: val_loss did not improve from 0.26814\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4241 - acc: 0.8680 - val_loss: 0.2777 - val_acc: 0.9227\n",
      "Epoch 171/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4212 - acc: 0.8695\n",
      "Epoch 00171: val_loss did not improve from 0.26814\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4214 - acc: 0.8694 - val_loss: 0.2711 - val_acc: 0.9245\n",
      "Epoch 172/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4139 - acc: 0.8712\n",
      "Epoch 00172: val_loss did not improve from 0.26814\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.4142 - acc: 0.8711 - val_loss: 0.2833 - val_acc: 0.9203\n",
      "Epoch 173/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4195 - acc: 0.8679\n",
      "Epoch 00173: val_loss did not improve from 0.26814\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4192 - acc: 0.8680 - val_loss: 0.2730 - val_acc: 0.9213\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4158 - acc: 0.8709\n",
      "Epoch 00174: val_loss did not improve from 0.26814\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.4158 - acc: 0.8709 - val_loss: 0.2717 - val_acc: 0.9257\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4162 - acc: 0.8689\n",
      "Epoch 00175: val_loss improved from 0.26814 to 0.26381, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/175-0.2638.hdf5\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4162 - acc: 0.8689 - val_loss: 0.2638 - val_acc: 0.9255\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4085 - acc: 0.8737\n",
      "Epoch 00176: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 23s 638us/sample - loss: 0.4084 - acc: 0.8737 - val_loss: 0.2784 - val_acc: 0.9203\n",
      "Epoch 177/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4122 - acc: 0.8727\n",
      "Epoch 00177: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.4119 - acc: 0.8728 - val_loss: 0.2646 - val_acc: 0.9231\n",
      "Epoch 178/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4161 - acc: 0.8703\n",
      "Epoch 00178: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4160 - acc: 0.8702 - val_loss: 0.2729 - val_acc: 0.9238\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4165 - acc: 0.8696\n",
      "Epoch 00179: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4165 - acc: 0.8696 - val_loss: 0.2711 - val_acc: 0.9229\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4106 - acc: 0.8713\n",
      "Epoch 00180: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4106 - acc: 0.8713 - val_loss: 0.2678 - val_acc: 0.9248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4120 - acc: 0.8728\n",
      "Epoch 00181: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 652us/sample - loss: 0.4120 - acc: 0.8728 - val_loss: 0.2840 - val_acc: 0.9189\n",
      "Epoch 182/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4090 - acc: 0.8729\n",
      "Epoch 00182: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.4090 - acc: 0.8729 - val_loss: 0.2683 - val_acc: 0.9236\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4029 - acc: 0.8753\n",
      "Epoch 00183: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.4029 - acc: 0.8753 - val_loss: 0.2685 - val_acc: 0.9231\n",
      "Epoch 184/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4091 - acc: 0.8724\n",
      "Epoch 00184: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.4093 - acc: 0.8724 - val_loss: 0.2654 - val_acc: 0.9269\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4007 - acc: 0.8753\n",
      "Epoch 00185: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.4008 - acc: 0.8753 - val_loss: 0.2679 - val_acc: 0.9241\n",
      "Epoch 186/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4001 - acc: 0.8743\n",
      "Epoch 00186: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.4005 - acc: 0.8743 - val_loss: 0.2752 - val_acc: 0.9215\n",
      "Epoch 187/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4044 - acc: 0.8746\n",
      "Epoch 00187: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4045 - acc: 0.8746 - val_loss: 0.2666 - val_acc: 0.9234\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4066 - acc: 0.8746\n",
      "Epoch 00188: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.4066 - acc: 0.8746 - val_loss: 0.2668 - val_acc: 0.9269\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4025 - acc: 0.8729\n",
      "Epoch 00189: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 641us/sample - loss: 0.4024 - acc: 0.8729 - val_loss: 0.2656 - val_acc: 0.9250\n",
      "Epoch 190/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4024 - acc: 0.8731\n",
      "Epoch 00190: val_loss did not improve from 0.26381\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.4026 - acc: 0.8731 - val_loss: 0.2711 - val_acc: 0.9217\n",
      "Epoch 191/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4000 - acc: 0.8759\n",
      "Epoch 00191: val_loss improved from 0.26381 to 0.26336, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/191-0.2634.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3997 - acc: 0.8760 - val_loss: 0.2634 - val_acc: 0.9243\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3978 - acc: 0.8754\n",
      "Epoch 00192: val_loss improved from 0.26336 to 0.26155, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/192-0.2615.hdf5\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3980 - acc: 0.8753 - val_loss: 0.2615 - val_acc: 0.9273\n",
      "Epoch 193/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3934 - acc: 0.8765\n",
      "Epoch 00193: val_loss did not improve from 0.26155\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3937 - acc: 0.8764 - val_loss: 0.2650 - val_acc: 0.9241\n",
      "Epoch 194/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3905 - acc: 0.8761\n",
      "Epoch 00194: val_loss did not improve from 0.26155\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3904 - acc: 0.8761 - val_loss: 0.2618 - val_acc: 0.9255\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3952 - acc: 0.8748\n",
      "Epoch 00195: val_loss did not improve from 0.26155\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3952 - acc: 0.8748 - val_loss: 0.2705 - val_acc: 0.9248\n",
      "Epoch 196/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3964 - acc: 0.8758\n",
      "Epoch 00196: val_loss did not improve from 0.26155\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.3967 - acc: 0.8756 - val_loss: 0.2629 - val_acc: 0.9257\n",
      "Epoch 197/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3980 - acc: 0.8766\n",
      "Epoch 00197: val_loss did not improve from 0.26155\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3982 - acc: 0.8765 - val_loss: 0.2640 - val_acc: 0.9252\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3990 - acc: 0.8747\n",
      "Epoch 00198: val_loss did not improve from 0.26155\n",
      "36805/36805 [==============================] - 24s 639us/sample - loss: 0.3990 - acc: 0.8747 - val_loss: 0.2644 - val_acc: 0.9248\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3879 - acc: 0.8778\n",
      "Epoch 00199: val_loss improved from 0.26155 to 0.25997, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/199-0.2600.hdf5\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3879 - acc: 0.8778 - val_loss: 0.2600 - val_acc: 0.9259\n",
      "Epoch 200/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3984 - acc: 0.8748\n",
      "Epoch 00200: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3991 - acc: 0.8747 - val_loss: 0.2702 - val_acc: 0.9248\n",
      "Epoch 201/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3950 - acc: 0.8766\n",
      "Epoch 00201: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3949 - acc: 0.8767 - val_loss: 0.2682 - val_acc: 0.9250\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3922 - acc: 0.8760\n",
      "Epoch 00202: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3921 - acc: 0.8760 - val_loss: 0.2886 - val_acc: 0.9180\n",
      "Epoch 203/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3965 - acc: 0.8772\n",
      "Epoch 00203: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3962 - acc: 0.8772 - val_loss: 0.2641 - val_acc: 0.9252\n",
      "Epoch 204/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3949 - acc: 0.8782\n",
      "Epoch 00204: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3949 - acc: 0.8783 - val_loss: 0.2608 - val_acc: 0.9255\n",
      "Epoch 205/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3912 - acc: 0.8767\n",
      "Epoch 00205: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3912 - acc: 0.8768 - val_loss: 0.2679 - val_acc: 0.9224\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3922 - acc: 0.8763\n",
      "Epoch 00206: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3922 - acc: 0.8763 - val_loss: 0.2646 - val_acc: 0.9278\n",
      "Epoch 207/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3883 - acc: 0.8789\n",
      "Epoch 00207: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 23s 635us/sample - loss: 0.3881 - acc: 0.8789 - val_loss: 0.2698 - val_acc: 0.9255\n",
      "Epoch 208/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3857 - acc: 0.8788\n",
      "Epoch 00208: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3855 - acc: 0.8788 - val_loss: 0.2715 - val_acc: 0.9241\n",
      "Epoch 209/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3874 - acc: 0.8793\n",
      "Epoch 00209: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3875 - acc: 0.8793 - val_loss: 0.2710 - val_acc: 0.9224\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3917 - acc: 0.8782\n",
      "Epoch 00210: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.3917 - acc: 0.8782 - val_loss: 0.2627 - val_acc: 0.9266\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3856 - acc: 0.8789\n",
      "Epoch 00211: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3856 - acc: 0.8790 - val_loss: 0.2688 - val_acc: 0.9266\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3812 - acc: 0.8803\n",
      "Epoch 00212: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3812 - acc: 0.8803 - val_loss: 0.2669 - val_acc: 0.9234\n",
      "Epoch 213/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3937 - acc: 0.8764\n",
      "Epoch 00213: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 651us/sample - loss: 0.3940 - acc: 0.8763 - val_loss: 0.2652 - val_acc: 0.9238\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3834 - acc: 0.8813\n",
      "Epoch 00214: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3835 - acc: 0.8812 - val_loss: 0.2645 - val_acc: 0.9264\n",
      "Epoch 215/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3821 - acc: 0.8788\n",
      "Epoch 00215: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3825 - acc: 0.8787 - val_loss: 0.2637 - val_acc: 0.9255\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3872 - acc: 0.8770\n",
      "Epoch 00216: val_loss improved from 0.25997 to 0.25927, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/216-0.2593.hdf5\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3873 - acc: 0.8770 - val_loss: 0.2593 - val_acc: 0.9266\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3820 - acc: 0.8803\n",
      "Epoch 00217: val_loss improved from 0.25927 to 0.25885, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/217-0.2588.hdf5\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3820 - acc: 0.8803 - val_loss: 0.2588 - val_acc: 0.9266\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3847 - acc: 0.8802\n",
      "Epoch 00218: val_loss did not improve from 0.25885\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3848 - acc: 0.8801 - val_loss: 0.2695 - val_acc: 0.9224\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3858 - acc: 0.8787\n",
      "Epoch 00219: val_loss did not improve from 0.25885\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3857 - acc: 0.8787 - val_loss: 0.2679 - val_acc: 0.9259\n",
      "Epoch 220/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3814 - acc: 0.8810\n",
      "Epoch 00220: val_loss did not improve from 0.25885\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3813 - acc: 0.8811 - val_loss: 0.2604 - val_acc: 0.9269\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3795 - acc: 0.8804\n",
      "Epoch 00221: val_loss improved from 0.25885 to 0.25726, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/221-0.2573.hdf5\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3795 - acc: 0.8804 - val_loss: 0.2573 - val_acc: 0.9280\n",
      "Epoch 222/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3786 - acc: 0.8806\n",
      "Epoch 00222: val_loss improved from 0.25726 to 0.25601, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/222-0.2560.hdf5\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3783 - acc: 0.8807 - val_loss: 0.2560 - val_acc: 0.9287\n",
      "Epoch 223/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3800 - acc: 0.8808\n",
      "Epoch 00223: val_loss did not improve from 0.25601\n",
      "36805/36805 [==============================] - 24s 640us/sample - loss: 0.3802 - acc: 0.8807 - val_loss: 0.2726 - val_acc: 0.9224\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3830 - acc: 0.8791\n",
      "Epoch 00224: val_loss improved from 0.25601 to 0.25533, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/224-0.2553.hdf5\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3829 - acc: 0.8791 - val_loss: 0.2553 - val_acc: 0.9259\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3771 - acc: 0.8813\n",
      "Epoch 00225: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3771 - acc: 0.8813 - val_loss: 0.2613 - val_acc: 0.9283\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3810 - acc: 0.8815\n",
      "Epoch 00226: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3810 - acc: 0.8815 - val_loss: 0.2770 - val_acc: 0.9194\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3837 - acc: 0.8796\n",
      "Epoch 00227: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3839 - acc: 0.8796 - val_loss: 0.2592 - val_acc: 0.9278\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3807 - acc: 0.8802\n",
      "Epoch 00228: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.3807 - acc: 0.8802 - val_loss: 0.2657 - val_acc: 0.9266\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3756 - acc: 0.8836\n",
      "Epoch 00229: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3757 - acc: 0.8836 - val_loss: 0.2609 - val_acc: 0.9271\n",
      "Epoch 230/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3687 - acc: 0.8839\n",
      "Epoch 00230: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3686 - acc: 0.8839 - val_loss: 0.2616 - val_acc: 0.9248\n",
      "Epoch 231/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3716 - acc: 0.8826\n",
      "Epoch 00231: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3717 - acc: 0.8826 - val_loss: 0.2567 - val_acc: 0.9280\n",
      "Epoch 232/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3749 - acc: 0.8821\n",
      "Epoch 00232: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3750 - acc: 0.8821 - val_loss: 0.2556 - val_acc: 0.9271\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3701 - acc: 0.8830\n",
      "Epoch 00233: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 641us/sample - loss: 0.3700 - acc: 0.8831 - val_loss: 0.2610 - val_acc: 0.9280\n",
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3741 - acc: 0.8811\n",
      "Epoch 00234: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3740 - acc: 0.8811 - val_loss: 0.2684 - val_acc: 0.9220\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3714 - acc: 0.8842\n",
      "Epoch 00235: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3714 - acc: 0.8842 - val_loss: 0.2571 - val_acc: 0.9269\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3653 - acc: 0.8860\n",
      "Epoch 00236: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.3653 - acc: 0.8859 - val_loss: 0.2662 - val_acc: 0.9255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3768 - acc: 0.8831\n",
      "Epoch 00237: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3767 - acc: 0.8832 - val_loss: 0.2599 - val_acc: 0.9266\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3674 - acc: 0.8833\n",
      "Epoch 00238: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3674 - acc: 0.8833 - val_loss: 0.2610 - val_acc: 0.9266\n",
      "Epoch 239/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3696 - acc: 0.8849\n",
      "Epoch 00239: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3696 - acc: 0.8849 - val_loss: 0.2689 - val_acc: 0.9234\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3697 - acc: 0.8843\n",
      "Epoch 00240: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3696 - acc: 0.8844 - val_loss: 0.2567 - val_acc: 0.9280\n",
      "Epoch 241/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3682 - acc: 0.8852\n",
      "Epoch 00241: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.3682 - acc: 0.8852 - val_loss: 0.2581 - val_acc: 0.9269\n",
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3708 - acc: 0.8830\n",
      "Epoch 00242: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3707 - acc: 0.8830 - val_loss: 0.2614 - val_acc: 0.9252\n",
      "Epoch 243/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3677 - acc: 0.8848\n",
      "Epoch 00243: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3681 - acc: 0.8848 - val_loss: 0.2649 - val_acc: 0.9243\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3671 - acc: 0.8832\n",
      "Epoch 00244: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3671 - acc: 0.8832 - val_loss: 0.2597 - val_acc: 0.9280\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3635 - acc: 0.8845\n",
      "Epoch 00245: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3636 - acc: 0.8845 - val_loss: 0.2722 - val_acc: 0.9236\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3656 - acc: 0.8841\n",
      "Epoch 00246: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.3656 - acc: 0.8841 - val_loss: 0.2644 - val_acc: 0.9248\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3692 - acc: 0.8848\n",
      "Epoch 00247: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3691 - acc: 0.8848 - val_loss: 0.2591 - val_acc: 0.9278\n",
      "Epoch 248/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3674 - acc: 0.8841\n",
      "Epoch 00248: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 641us/sample - loss: 0.3676 - acc: 0.8839 - val_loss: 0.2655 - val_acc: 0.9245\n",
      "Epoch 249/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3602 - acc: 0.8855\n",
      "Epoch 00249: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.3603 - acc: 0.8854 - val_loss: 0.2557 - val_acc: 0.9271\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3632 - acc: 0.8858\n",
      "Epoch 00250: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3633 - acc: 0.8858 - val_loss: 0.2650 - val_acc: 0.9257\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3646 - acc: 0.8852\n",
      "Epoch 00251: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.3645 - acc: 0.8852 - val_loss: 0.2581 - val_acc: 0.9252\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3634 - acc: 0.8843\n",
      "Epoch 00252: val_loss did not improve from 0.25533\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3634 - acc: 0.8843 - val_loss: 0.2675 - val_acc: 0.9213\n",
      "Epoch 253/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3632 - acc: 0.8852\n",
      "Epoch 00253: val_loss improved from 0.25533 to 0.25500, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/253-0.2550.hdf5\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3631 - acc: 0.8853 - val_loss: 0.2550 - val_acc: 0.9290\n",
      "Epoch 254/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3612 - acc: 0.8868\n",
      "Epoch 00254: val_loss did not improve from 0.25500\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3611 - acc: 0.8868 - val_loss: 0.2627 - val_acc: 0.9257\n",
      "Epoch 255/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3565 - acc: 0.8870\n",
      "Epoch 00255: val_loss did not improve from 0.25500\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3567 - acc: 0.8869 - val_loss: 0.2582 - val_acc: 0.9285\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3624 - acc: 0.8872\n",
      "Epoch 00256: val_loss improved from 0.25500 to 0.25461, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/256-0.2546.hdf5\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3624 - acc: 0.8872 - val_loss: 0.2546 - val_acc: 0.9297\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3575 - acc: 0.8849\n",
      "Epoch 00257: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3574 - acc: 0.8850 - val_loss: 0.2670 - val_acc: 0.9278\n",
      "Epoch 258/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3591 - acc: 0.8846\n",
      "Epoch 00258: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 641us/sample - loss: 0.3593 - acc: 0.8846 - val_loss: 0.2592 - val_acc: 0.9273\n",
      "Epoch 259/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3662 - acc: 0.8843\n",
      "Epoch 00259: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3664 - acc: 0.8842 - val_loss: 0.2634 - val_acc: 0.9257\n",
      "Epoch 260/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3552 - acc: 0.8874\n",
      "Epoch 00260: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3550 - acc: 0.8875 - val_loss: 0.2615 - val_acc: 0.9264\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3571 - acc: 0.8861\n",
      "Epoch 00261: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.3571 - acc: 0.8861 - val_loss: 0.2646 - val_acc: 0.9255\n",
      "Epoch 262/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3620 - acc: 0.8856\n",
      "Epoch 00262: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3619 - acc: 0.8857 - val_loss: 0.2650 - val_acc: 0.9250\n",
      "Epoch 263/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3543 - acc: 0.8871\n",
      "Epoch 00263: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3544 - acc: 0.8870 - val_loss: 0.2579 - val_acc: 0.9299\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3575 - acc: 0.8875\n",
      "Epoch 00264: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3575 - acc: 0.8875 - val_loss: 0.2625 - val_acc: 0.9257\n",
      "Epoch 265/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3520 - acc: 0.8884\n",
      "Epoch 00265: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 23s 631us/sample - loss: 0.3521 - acc: 0.8884 - val_loss: 0.2727 - val_acc: 0.9208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3576 - acc: 0.8875\n",
      "Epoch 00266: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3574 - acc: 0.8875 - val_loss: 0.2630 - val_acc: 0.9278\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3552 - acc: 0.8871\n",
      "Epoch 00267: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3552 - acc: 0.8871 - val_loss: 0.2612 - val_acc: 0.9255\n",
      "Epoch 268/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3555 - acc: 0.8869\n",
      "Epoch 00268: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3555 - acc: 0.8869 - val_loss: 0.2643 - val_acc: 0.9257\n",
      "Epoch 269/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3576 - acc: 0.8872\n",
      "Epoch 00269: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3575 - acc: 0.8872 - val_loss: 0.2564 - val_acc: 0.9252\n",
      "Epoch 270/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3526 - acc: 0.8865\n",
      "Epoch 00270: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3523 - acc: 0.8866 - val_loss: 0.2675 - val_acc: 0.9264\n",
      "Epoch 271/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3490 - acc: 0.8893\n",
      "Epoch 00271: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3489 - acc: 0.8894 - val_loss: 0.2683 - val_acc: 0.9236\n",
      "Epoch 272/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3547 - acc: 0.8882\n",
      "Epoch 00272: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3545 - acc: 0.8882 - val_loss: 0.2573 - val_acc: 0.9278\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3569 - acc: 0.8875\n",
      "Epoch 00273: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3569 - acc: 0.8875 - val_loss: 0.2823 - val_acc: 0.9213\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3553 - acc: 0.8886\n",
      "Epoch 00274: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 640us/sample - loss: 0.3553 - acc: 0.8886 - val_loss: 0.2610 - val_acc: 0.9262\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3501 - acc: 0.8889\n",
      "Epoch 00275: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.3501 - acc: 0.8889 - val_loss: 0.2566 - val_acc: 0.9276\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3499 - acc: 0.8884\n",
      "Epoch 00276: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3499 - acc: 0.8884 - val_loss: 0.2589 - val_acc: 0.9287\n",
      "Epoch 277/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3482 - acc: 0.8896\n",
      "Epoch 00277: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3479 - acc: 0.8897 - val_loss: 0.2631 - val_acc: 0.9271\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3555 - acc: 0.8869\n",
      "Epoch 00278: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3554 - acc: 0.8869 - val_loss: 0.2591 - val_acc: 0.9280\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3452 - acc: 0.8903\n",
      "Epoch 00279: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3452 - acc: 0.8903 - val_loss: 0.2570 - val_acc: 0.9236\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3525 - acc: 0.8888\n",
      "Epoch 00280: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3524 - acc: 0.8888 - val_loss: 0.2613 - val_acc: 0.9248\n",
      "Epoch 281/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3531 - acc: 0.8875\n",
      "Epoch 00281: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.3531 - acc: 0.8875 - val_loss: 0.2566 - val_acc: 0.9257\n",
      "Epoch 282/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3479 - acc: 0.8891\n",
      "Epoch 00282: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3482 - acc: 0.8891 - val_loss: 0.2589 - val_acc: 0.9262\n",
      "Epoch 283/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3498 - acc: 0.8891\n",
      "Epoch 00283: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3497 - acc: 0.8891 - val_loss: 0.2580 - val_acc: 0.9269\n",
      "Epoch 284/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3497 - acc: 0.8883\n",
      "Epoch 00284: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3497 - acc: 0.8882 - val_loss: 0.2583 - val_acc: 0.9276\n",
      "Epoch 285/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3465 - acc: 0.8897\n",
      "Epoch 00285: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3463 - acc: 0.8897 - val_loss: 0.2640 - val_acc: 0.9243\n",
      "Epoch 286/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3526 - acc: 0.8867\n",
      "Epoch 00286: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3526 - acc: 0.8866 - val_loss: 0.2640 - val_acc: 0.9243\n",
      "Epoch 287/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3464 - acc: 0.8905\n",
      "Epoch 00287: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.3464 - acc: 0.8905 - val_loss: 0.2590 - val_acc: 0.9266\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3451 - acc: 0.8892\n",
      "Epoch 00288: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.3451 - acc: 0.8892 - val_loss: 0.2702 - val_acc: 0.9238\n",
      "Epoch 289/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3413 - acc: 0.8914\n",
      "Epoch 00289: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3411 - acc: 0.8914 - val_loss: 0.2563 - val_acc: 0.9250\n",
      "Epoch 290/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3445 - acc: 0.8899\n",
      "Epoch 00290: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3443 - acc: 0.8900 - val_loss: 0.2601 - val_acc: 0.9269\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3431 - acc: 0.8901\n",
      "Epoch 00291: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3430 - acc: 0.8901 - val_loss: 0.2627 - val_acc: 0.9266\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3493 - acc: 0.8883\n",
      "Epoch 00292: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3493 - acc: 0.8884 - val_loss: 0.2604 - val_acc: 0.9259\n",
      "Epoch 293/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3447 - acc: 0.8910\n",
      "Epoch 00293: val_loss did not improve from 0.25461\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3447 - acc: 0.8910 - val_loss: 0.2577 - val_acc: 0.9280\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3440 - acc: 0.8887\n",
      "Epoch 00294: val_loss improved from 0.25461 to 0.25263, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/294-0.2526.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.3440 - acc: 0.8887 - val_loss: 0.2526 - val_acc: 0.9273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3433 - acc: 0.8909\n",
      "Epoch 00295: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3433 - acc: 0.8909 - val_loss: 0.2570 - val_acc: 0.9266\n",
      "Epoch 296/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3416 - acc: 0.8914\n",
      "Epoch 00296: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3417 - acc: 0.8913 - val_loss: 0.2559 - val_acc: 0.9271\n",
      "Epoch 297/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3451 - acc: 0.8905\n",
      "Epoch 00297: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3451 - acc: 0.8905 - val_loss: 0.2575 - val_acc: 0.9238\n",
      "Epoch 298/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3441 - acc: 0.8910\n",
      "Epoch 00298: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3439 - acc: 0.8910 - val_loss: 0.2638 - val_acc: 0.9243\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3431 - acc: 0.8904\n",
      "Epoch 00299: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.3431 - acc: 0.8904 - val_loss: 0.2639 - val_acc: 0.9255\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3381 - acc: 0.8918\n",
      "Epoch 00300: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3381 - acc: 0.8918 - val_loss: 0.2761 - val_acc: 0.9215\n",
      "Epoch 301/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3414 - acc: 0.8923\n",
      "Epoch 00301: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3414 - acc: 0.8923 - val_loss: 0.2559 - val_acc: 0.9278\n",
      "Epoch 302/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3458 - acc: 0.8911\n",
      "Epoch 00302: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3457 - acc: 0.8911 - val_loss: 0.2573 - val_acc: 0.9255\n",
      "Epoch 303/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3391 - acc: 0.8926\n",
      "Epoch 00303: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3391 - acc: 0.8925 - val_loss: 0.2747 - val_acc: 0.9229\n",
      "Epoch 304/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3420 - acc: 0.8921\n",
      "Epoch 00304: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3420 - acc: 0.8921 - val_loss: 0.2583 - val_acc: 0.9287\n",
      "Epoch 305/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3338 - acc: 0.8936\n",
      "Epoch 00305: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3338 - acc: 0.8936 - val_loss: 0.2605 - val_acc: 0.9234\n",
      "Epoch 306/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3425 - acc: 0.8927\n",
      "Epoch 00306: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3428 - acc: 0.8926 - val_loss: 0.2616 - val_acc: 0.9252\n",
      "Epoch 307/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3370 - acc: 0.8926\n",
      "Epoch 00307: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3370 - acc: 0.8926 - val_loss: 0.2611 - val_acc: 0.9255\n",
      "Epoch 308/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3351 - acc: 0.8949\n",
      "Epoch 00308: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3350 - acc: 0.8950 - val_loss: 0.2568 - val_acc: 0.9271\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3321 - acc: 0.8943\n",
      "Epoch 00309: val_loss did not improve from 0.25263\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3321 - acc: 0.8943 - val_loss: 0.2609 - val_acc: 0.9252\n",
      "Epoch 310/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3351 - acc: 0.8920\n",
      "Epoch 00310: val_loss improved from 0.25263 to 0.25081, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv_checkpoint/310-0.2508.hdf5\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.3351 - acc: 0.8920 - val_loss: 0.2508 - val_acc: 0.9283\n",
      "Epoch 311/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3356 - acc: 0.8933\n",
      "Epoch 00311: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3357 - acc: 0.8933 - val_loss: 0.2567 - val_acc: 0.9283\n",
      "Epoch 312/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3361 - acc: 0.8920\n",
      "Epoch 00312: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3362 - acc: 0.8920 - val_loss: 0.2578 - val_acc: 0.9271\n",
      "Epoch 313/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3378 - acc: 0.8924\n",
      "Epoch 00313: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3377 - acc: 0.8924 - val_loss: 0.2553 - val_acc: 0.9285\n",
      "Epoch 314/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3313 - acc: 0.8940\n",
      "Epoch 00314: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3312 - acc: 0.8940 - val_loss: 0.2661 - val_acc: 0.9252\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3335 - acc: 0.8938\n",
      "Epoch 00315: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3336 - acc: 0.8938 - val_loss: 0.2675 - val_acc: 0.9248\n",
      "Epoch 316/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3352 - acc: 0.8932\n",
      "Epoch 00316: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 639us/sample - loss: 0.3352 - acc: 0.8932 - val_loss: 0.2601 - val_acc: 0.9262\n",
      "Epoch 317/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3324 - acc: 0.8950\n",
      "Epoch 00317: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3325 - acc: 0.8949 - val_loss: 0.2618 - val_acc: 0.9278\n",
      "Epoch 318/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3336 - acc: 0.8923\n",
      "Epoch 00318: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.3336 - acc: 0.8923 - val_loss: 0.2587 - val_acc: 0.9271\n",
      "Epoch 319/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3343 - acc: 0.8923\n",
      "Epoch 00319: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3343 - acc: 0.8922 - val_loss: 0.2600 - val_acc: 0.9266\n",
      "Epoch 320/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3352 - acc: 0.8929\n",
      "Epoch 00320: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3352 - acc: 0.8929 - val_loss: 0.2555 - val_acc: 0.9287\n",
      "Epoch 321/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3339 - acc: 0.8931\n",
      "Epoch 00321: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3339 - acc: 0.8931 - val_loss: 0.2597 - val_acc: 0.9264\n",
      "Epoch 322/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3356 - acc: 0.8919\n",
      "Epoch 00322: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 23s 631us/sample - loss: 0.3356 - acc: 0.8919 - val_loss: 0.2681 - val_acc: 0.9222\n",
      "Epoch 323/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3353 - acc: 0.8946\n",
      "Epoch 00323: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3353 - acc: 0.8947 - val_loss: 0.2593 - val_acc: 0.9271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3335 - acc: 0.8933\n",
      "Epoch 00324: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3338 - acc: 0.8932 - val_loss: 0.2590 - val_acc: 0.9290\n",
      "Epoch 325/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3289 - acc: 0.8953\n",
      "Epoch 00325: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3288 - acc: 0.8952 - val_loss: 0.2677 - val_acc: 0.9250\n",
      "Epoch 326/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3291 - acc: 0.8961\n",
      "Epoch 00326: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3291 - acc: 0.8962 - val_loss: 0.2593 - val_acc: 0.9252\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3298 - acc: 0.8953\n",
      "Epoch 00327: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3298 - acc: 0.8953 - val_loss: 0.2546 - val_acc: 0.9257\n",
      "Epoch 328/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3278 - acc: 0.8956\n",
      "Epoch 00328: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.3276 - acc: 0.8956 - val_loss: 0.2611 - val_acc: 0.9252\n",
      "Epoch 329/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3333 - acc: 0.8932\n",
      "Epoch 00329: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3332 - acc: 0.8932 - val_loss: 0.2597 - val_acc: 0.9255\n",
      "Epoch 330/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3291 - acc: 0.8941\n",
      "Epoch 00330: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3290 - acc: 0.8942 - val_loss: 0.2601 - val_acc: 0.9285\n",
      "Epoch 331/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3288 - acc: 0.8965\n",
      "Epoch 00331: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3289 - acc: 0.8964 - val_loss: 0.2631 - val_acc: 0.9224\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3259 - acc: 0.8974\n",
      "Epoch 00332: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3259 - acc: 0.8974 - val_loss: 0.2624 - val_acc: 0.9255\n",
      "Epoch 333/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3315 - acc: 0.8936\n",
      "Epoch 00333: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 643us/sample - loss: 0.3317 - acc: 0.8936 - val_loss: 0.2608 - val_acc: 0.9257\n",
      "Epoch 334/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.8961\n",
      "Epoch 00334: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3237 - acc: 0.8961 - val_loss: 0.2623 - val_acc: 0.9257\n",
      "Epoch 335/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3272 - acc: 0.8967\n",
      "Epoch 00335: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3273 - acc: 0.8966 - val_loss: 0.2647 - val_acc: 0.9255\n",
      "Epoch 336/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3230 - acc: 0.8959\n",
      "Epoch 00336: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 642us/sample - loss: 0.3227 - acc: 0.8960 - val_loss: 0.2606 - val_acc: 0.9262\n",
      "Epoch 337/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3243 - acc: 0.8961\n",
      "Epoch 00337: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.3243 - acc: 0.8961 - val_loss: 0.2574 - val_acc: 0.9259\n",
      "Epoch 338/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3268 - acc: 0.8966\n",
      "Epoch 00338: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3270 - acc: 0.8967 - val_loss: 0.2578 - val_acc: 0.9276\n",
      "Epoch 339/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3221 - acc: 0.8966\n",
      "Epoch 00339: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3220 - acc: 0.8967 - val_loss: 0.2592 - val_acc: 0.9264\n",
      "Epoch 340/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3265 - acc: 0.8939\n",
      "Epoch 00340: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 641us/sample - loss: 0.3265 - acc: 0.8939 - val_loss: 0.2606 - val_acc: 0.9252\n",
      "Epoch 341/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3257 - acc: 0.8954\n",
      "Epoch 00341: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 641us/sample - loss: 0.3258 - acc: 0.8954 - val_loss: 0.2631 - val_acc: 0.9271\n",
      "Epoch 342/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3246 - acc: 0.8970\n",
      "Epoch 00342: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3246 - acc: 0.8970 - val_loss: 0.2582 - val_acc: 0.9241\n",
      "Epoch 343/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3242 - acc: 0.8947\n",
      "Epoch 00343: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3242 - acc: 0.8947 - val_loss: 0.2596 - val_acc: 0.9262\n",
      "Epoch 344/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3214 - acc: 0.8962\n",
      "Epoch 00344: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.3218 - acc: 0.8961 - val_loss: 0.2589 - val_acc: 0.9269\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3224 - acc: 0.8969\n",
      "Epoch 00345: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.3224 - acc: 0.8969 - val_loss: 0.2602 - val_acc: 0.9264\n",
      "Epoch 346/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3220 - acc: 0.8991\n",
      "Epoch 00346: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3222 - acc: 0.8991 - val_loss: 0.2623 - val_acc: 0.9271\n",
      "Epoch 347/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3313 - acc: 0.8944\n",
      "Epoch 00347: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3313 - acc: 0.8944 - val_loss: 0.2596 - val_acc: 0.9252\n",
      "Epoch 348/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3287 - acc: 0.8941\n",
      "Epoch 00348: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3285 - acc: 0.8941 - val_loss: 0.2595 - val_acc: 0.9257\n",
      "Epoch 349/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3185 - acc: 0.8973\n",
      "Epoch 00349: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3185 - acc: 0.8973 - val_loss: 0.2679 - val_acc: 0.9231\n",
      "Epoch 350/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3259 - acc: 0.8954\n",
      "Epoch 00350: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.3258 - acc: 0.8954 - val_loss: 0.2584 - val_acc: 0.9264\n",
      "Epoch 351/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3280 - acc: 0.8943\n",
      "Epoch 00351: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3282 - acc: 0.8943 - val_loss: 0.2622 - val_acc: 0.9252\n",
      "Epoch 352/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3197 - acc: 0.8973\n",
      "Epoch 00352: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 647us/sample - loss: 0.3199 - acc: 0.8972 - val_loss: 0.2572 - val_acc: 0.9273\n",
      "Epoch 353/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3218 - acc: 0.8972\n",
      "Epoch 00353: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.3219 - acc: 0.8972 - val_loss: 0.2650 - val_acc: 0.9262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3202 - acc: 0.8955\n",
      "Epoch 00354: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.3201 - acc: 0.8955 - val_loss: 0.2613 - val_acc: 0.9262\n",
      "Epoch 355/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3172 - acc: 0.8985\n",
      "Epoch 00355: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 645us/sample - loss: 0.3174 - acc: 0.8985 - val_loss: 0.2635 - val_acc: 0.9264\n",
      "Epoch 356/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3207 - acc: 0.8972\n",
      "Epoch 00356: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 649us/sample - loss: 0.3207 - acc: 0.8972 - val_loss: 0.2602 - val_acc: 0.9276\n",
      "Epoch 357/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3181 - acc: 0.8977\n",
      "Epoch 00357: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 650us/sample - loss: 0.3180 - acc: 0.8977 - val_loss: 0.2607 - val_acc: 0.9259\n",
      "Epoch 358/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3179 - acc: 0.8988\n",
      "Epoch 00358: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3179 - acc: 0.8988 - val_loss: 0.2649 - val_acc: 0.9264\n",
      "Epoch 359/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3168 - acc: 0.9010\n",
      "Epoch 00359: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 646us/sample - loss: 0.3168 - acc: 0.9010 - val_loss: 0.2607 - val_acc: 0.9257\n",
      "Epoch 360/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.8992\n",
      "Epoch 00360: val_loss did not improve from 0.25081\n",
      "36805/36805 [==============================] - 24s 648us/sample - loss: 0.3157 - acc: 0.8992 - val_loss: 0.2635 - val_acc: 0.9255\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 383us/sample - loss: 0.2973 - acc: 0.9134\n",
      "Loss: 0.2973256352410757 Accuracy: 0.91339564\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5651 - acc: 0.1544\n",
      "Epoch 00001: val_loss improved from inf to 2.10545, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/001-2.1054.hdf5\n",
      "36805/36805 [==============================] - 27s 747us/sample - loss: 2.5651 - acc: 0.1544 - val_loss: 2.1054 - val_acc: 0.3664\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.0544 - acc: 0.3169\n",
      "Epoch 00002: val_loss improved from 2.10545 to 1.67195, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/002-1.6719.hdf5\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 2.0540 - acc: 0.3171 - val_loss: 1.6719 - val_acc: 0.4969\n",
      "Epoch 3/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7806 - acc: 0.4117\n",
      "Epoch 00003: val_loss improved from 1.67195 to 1.42856, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/003-1.4286.hdf5\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 1.7805 - acc: 0.4119 - val_loss: 1.4286 - val_acc: 0.5712\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5930 - acc: 0.4744\n",
      "Epoch 00004: val_loss improved from 1.42856 to 1.23480, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/004-1.2348.hdf5\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 1.5930 - acc: 0.4744 - val_loss: 1.2348 - val_acc: 0.6292\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4483 - acc: 0.5238\n",
      "Epoch 00005: val_loss improved from 1.23480 to 1.07755, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/005-1.0776.hdf5\n",
      "36805/36805 [==============================] - 25s 668us/sample - loss: 1.4483 - acc: 0.5238 - val_loss: 1.0776 - val_acc: 0.6839\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3187 - acc: 0.5660\n",
      "Epoch 00006: val_loss improved from 1.07755 to 0.95607, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/006-0.9561.hdf5\n",
      "36805/36805 [==============================] - 25s 666us/sample - loss: 1.3187 - acc: 0.5660 - val_loss: 0.9561 - val_acc: 0.7158\n",
      "Epoch 7/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1999 - acc: 0.6075\n",
      "Epoch 00007: val_loss improved from 0.95607 to 0.86326, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/007-0.8633.hdf5\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 1.2000 - acc: 0.6074 - val_loss: 0.8633 - val_acc: 0.7447\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1218 - acc: 0.6329\n",
      "Epoch 00008: val_loss improved from 0.86326 to 0.78145, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/008-0.7815.hdf5\n",
      "36805/36805 [==============================] - 24s 663us/sample - loss: 1.1217 - acc: 0.6330 - val_loss: 0.7815 - val_acc: 0.7775\n",
      "Epoch 9/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0353 - acc: 0.6647\n",
      "Epoch 00009: val_loss improved from 0.78145 to 0.70172, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/009-0.7017.hdf5\n",
      "36805/36805 [==============================] - 24s 659us/sample - loss: 1.0355 - acc: 0.6647 - val_loss: 0.7017 - val_acc: 0.8034\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9723 - acc: 0.6867\n",
      "Epoch 00010: val_loss improved from 0.70172 to 0.66640, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/010-0.6664.hdf5\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.9727 - acc: 0.6865 - val_loss: 0.6664 - val_acc: 0.8118\n",
      "Epoch 11/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9243 - acc: 0.7032\n",
      "Epoch 00011: val_loss improved from 0.66640 to 0.61029, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/011-0.6103.hdf5\n",
      "36805/36805 [==============================] - 24s 661us/sample - loss: 0.9244 - acc: 0.7034 - val_loss: 0.6103 - val_acc: 0.8262\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8706 - acc: 0.7241\n",
      "Epoch 00012: val_loss improved from 0.61029 to 0.57709, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/012-0.5771.hdf5\n",
      "36805/36805 [==============================] - 25s 668us/sample - loss: 0.8708 - acc: 0.7241 - val_loss: 0.5771 - val_acc: 0.8341\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8251 - acc: 0.7367\n",
      "Epoch 00013: val_loss improved from 0.57709 to 0.52194, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/013-0.5219.hdf5\n",
      "36805/36805 [==============================] - 25s 669us/sample - loss: 0.8251 - acc: 0.7367 - val_loss: 0.5219 - val_acc: 0.8446\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7942 - acc: 0.7483\n",
      "Epoch 00014: val_loss improved from 0.52194 to 0.50362, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/014-0.5036.hdf5\n",
      "36805/36805 [==============================] - 24s 664us/sample - loss: 0.7943 - acc: 0.7482 - val_loss: 0.5036 - val_acc: 0.8505\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7536 - acc: 0.7647\n",
      "Epoch 00015: val_loss improved from 0.50362 to 0.48976, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/015-0.4898.hdf5\n",
      "36805/36805 [==============================] - 24s 664us/sample - loss: 0.7536 - acc: 0.7648 - val_loss: 0.4898 - val_acc: 0.8628\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7350 - acc: 0.7687\n",
      "Epoch 00016: val_loss improved from 0.48976 to 0.44453, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/016-0.4445.hdf5\n",
      "36805/36805 [==============================] - 25s 668us/sample - loss: 0.7350 - acc: 0.7687 - val_loss: 0.4445 - val_acc: 0.8644\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7018 - acc: 0.7795\n",
      "Epoch 00017: val_loss improved from 0.44453 to 0.42983, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/017-0.4298.hdf5\n",
      "36805/36805 [==============================] - 25s 668us/sample - loss: 0.7017 - acc: 0.7795 - val_loss: 0.4298 - val_acc: 0.8651\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6868 - acc: 0.7831\n",
      "Epoch 00018: val_loss improved from 0.42983 to 0.41012, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/018-0.4101.hdf5\n",
      "36805/36805 [==============================] - 24s 652us/sample - loss: 0.6868 - acc: 0.7832 - val_loss: 0.4101 - val_acc: 0.8786\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6527 - acc: 0.7961\n",
      "Epoch 00019: val_loss improved from 0.41012 to 0.40227, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/019-0.4023.hdf5\n",
      "36805/36805 [==============================] - 24s 664us/sample - loss: 0.6531 - acc: 0.7960 - val_loss: 0.4023 - val_acc: 0.8807\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6334 - acc: 0.8013\n",
      "Epoch 00020: val_loss improved from 0.40227 to 0.38111, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/020-0.3811.hdf5\n",
      "36805/36805 [==============================] - 25s 669us/sample - loss: 0.6334 - acc: 0.8013 - val_loss: 0.3811 - val_acc: 0.8873\n",
      "Epoch 21/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6204 - acc: 0.8033\n",
      "Epoch 00021: val_loss improved from 0.38111 to 0.36929, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/021-0.3693.hdf5\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.6201 - acc: 0.8035 - val_loss: 0.3693 - val_acc: 0.8901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.8117\n",
      "Epoch 00022: val_loss did not improve from 0.36929\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.6017 - acc: 0.8117 - val_loss: 0.3900 - val_acc: 0.8805\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5910 - acc: 0.8140\n",
      "Epoch 00023: val_loss improved from 0.36929 to 0.35407, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/023-0.3541.hdf5\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.5909 - acc: 0.8140 - val_loss: 0.3541 - val_acc: 0.8945\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5695 - acc: 0.8217\n",
      "Epoch 00024: val_loss improved from 0.35407 to 0.33741, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/024-0.3374.hdf5\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.5696 - acc: 0.8217 - val_loss: 0.3374 - val_acc: 0.8977\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5623 - acc: 0.8261\n",
      "Epoch 00025: val_loss improved from 0.33741 to 0.32773, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/025-0.3277.hdf5\n",
      "36805/36805 [==============================] - 25s 669us/sample - loss: 0.5623 - acc: 0.8261 - val_loss: 0.3277 - val_acc: 0.9012\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5502 - acc: 0.8260\n",
      "Epoch 00026: val_loss improved from 0.32773 to 0.31847, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/026-0.3185.hdf5\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.5502 - acc: 0.8261 - val_loss: 0.3185 - val_acc: 0.9071\n",
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5391 - acc: 0.8321\n",
      "Epoch 00027: val_loss improved from 0.31847 to 0.31399, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/027-0.3140.hdf5\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.5391 - acc: 0.8322 - val_loss: 0.3140 - val_acc: 0.9052\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5285 - acc: 0.8364\n",
      "Epoch 00028: val_loss improved from 0.31399 to 0.30805, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/028-0.3081.hdf5\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.5285 - acc: 0.8364 - val_loss: 0.3081 - val_acc: 0.9092\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5214 - acc: 0.8374\n",
      "Epoch 00029: val_loss did not improve from 0.30805\n",
      "36805/36805 [==============================] - 24s 665us/sample - loss: 0.5217 - acc: 0.8373 - val_loss: 0.3153 - val_acc: 0.9052\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5129 - acc: 0.8401\n",
      "Epoch 00030: val_loss improved from 0.30805 to 0.30678, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/030-0.3068.hdf5\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.5129 - acc: 0.8401 - val_loss: 0.3068 - val_acc: 0.9082\n",
      "Epoch 31/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4986 - acc: 0.8425\n",
      "Epoch 00031: val_loss improved from 0.30678 to 0.29150, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/031-0.2915.hdf5\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.4985 - acc: 0.8425 - val_loss: 0.2915 - val_acc: 0.9150\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4964 - acc: 0.8446\n",
      "Epoch 00032: val_loss did not improve from 0.29150\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.4964 - acc: 0.8446 - val_loss: 0.2936 - val_acc: 0.9152\n",
      "Epoch 33/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4873 - acc: 0.8485\n",
      "Epoch 00033: val_loss improved from 0.29150 to 0.28546, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/033-0.2855.hdf5\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.4872 - acc: 0.8486 - val_loss: 0.2855 - val_acc: 0.9133\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4767 - acc: 0.8521\n",
      "Epoch 00034: val_loss improved from 0.28546 to 0.27414, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/034-0.2741.hdf5\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.4767 - acc: 0.8521 - val_loss: 0.2741 - val_acc: 0.9168\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.8539\n",
      "Epoch 00035: val_loss did not improve from 0.27414\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.4684 - acc: 0.8539 - val_loss: 0.2822 - val_acc: 0.9194\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4663 - acc: 0.8573\n",
      "Epoch 00036: val_loss did not improve from 0.27414\n",
      "36805/36805 [==============================] - 24s 660us/sample - loss: 0.4663 - acc: 0.8573 - val_loss: 0.2783 - val_acc: 0.9166\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.8564\n",
      "Epoch 00037: val_loss improved from 0.27414 to 0.26308, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/037-0.2631.hdf5\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.4582 - acc: 0.8565 - val_loss: 0.2631 - val_acc: 0.9185\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4528 - acc: 0.8588\n",
      "Epoch 00038: val_loss improved from 0.26308 to 0.26255, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/038-0.2625.hdf5\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.4528 - acc: 0.8588 - val_loss: 0.2625 - val_acc: 0.9220\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4393 - acc: 0.8633\n",
      "Epoch 00039: val_loss improved from 0.26255 to 0.26173, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/039-0.2617.hdf5\n",
      "36805/36805 [==============================] - 25s 670us/sample - loss: 0.4394 - acc: 0.8632 - val_loss: 0.2617 - val_acc: 0.9217\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4396 - acc: 0.8635\n",
      "Epoch 00040: val_loss improved from 0.26173 to 0.25964, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/040-0.2596.hdf5\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.4395 - acc: 0.8635 - val_loss: 0.2596 - val_acc: 0.9224\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4388 - acc: 0.8642\n",
      "Epoch 00041: val_loss improved from 0.25964 to 0.25824, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/041-0.2582.hdf5\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.4389 - acc: 0.8642 - val_loss: 0.2582 - val_acc: 0.9224\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4261 - acc: 0.8673\n",
      "Epoch 00042: val_loss improved from 0.25824 to 0.24387, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/042-0.2439.hdf5\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.4260 - acc: 0.8673 - val_loss: 0.2439 - val_acc: 0.9255\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4240 - acc: 0.8679\n",
      "Epoch 00043: val_loss improved from 0.24387 to 0.24282, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/043-0.2428.hdf5\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.4237 - acc: 0.8680 - val_loss: 0.2428 - val_acc: 0.9255\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4197 - acc: 0.8691\n",
      "Epoch 00044: val_loss did not improve from 0.24282\n",
      "36805/36805 [==============================] - 25s 669us/sample - loss: 0.4196 - acc: 0.8691 - val_loss: 0.2586 - val_acc: 0.9192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4136 - acc: 0.8690\n",
      "Epoch 00045: val_loss improved from 0.24282 to 0.23557, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/045-0.2356.hdf5\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.4133 - acc: 0.8691 - val_loss: 0.2356 - val_acc: 0.9285\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4061 - acc: 0.8733\n",
      "Epoch 00046: val_loss did not improve from 0.23557\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.4061 - acc: 0.8734 - val_loss: 0.2480 - val_acc: 0.9287\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4036 - acc: 0.8745\n",
      "Epoch 00047: val_loss improved from 0.23557 to 0.23503, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/047-0.2350.hdf5\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.4036 - acc: 0.8745 - val_loss: 0.2350 - val_acc: 0.9311\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3992 - acc: 0.8760\n",
      "Epoch 00048: val_loss did not improve from 0.23503\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.3992 - acc: 0.8760 - val_loss: 0.2362 - val_acc: 0.9299\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3996 - acc: 0.8740\n",
      "Epoch 00049: val_loss improved from 0.23503 to 0.22566, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/049-0.2257.hdf5\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.3996 - acc: 0.8740 - val_loss: 0.2257 - val_acc: 0.9311\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3865 - acc: 0.8772\n",
      "Epoch 00050: val_loss did not improve from 0.22566\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.3865 - acc: 0.8772 - val_loss: 0.2332 - val_acc: 0.9308\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3857 - acc: 0.8789\n",
      "Epoch 00051: val_loss improved from 0.22566 to 0.22120, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/051-0.2212.hdf5\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.3857 - acc: 0.8789 - val_loss: 0.2212 - val_acc: 0.9320\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.8783\n",
      "Epoch 00052: val_loss did not improve from 0.22120\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.3863 - acc: 0.8783 - val_loss: 0.2221 - val_acc: 0.9343\n",
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3800 - acc: 0.8786\n",
      "Epoch 00053: val_loss improved from 0.22120 to 0.22064, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/053-0.2206.hdf5\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.3804 - acc: 0.8785 - val_loss: 0.2206 - val_acc: 0.9387\n",
      "Epoch 54/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3753 - acc: 0.8825\n",
      "Epoch 00054: val_loss improved from 0.22064 to 0.21812, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/054-0.2181.hdf5\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.3751 - acc: 0.8826 - val_loss: 0.2181 - val_acc: 0.9352\n",
      "Epoch 55/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3758 - acc: 0.8850\n",
      "Epoch 00055: val_loss did not improve from 0.21812\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.3760 - acc: 0.8850 - val_loss: 0.2292 - val_acc: 0.9311\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3655 - acc: 0.8859\n",
      "Epoch 00056: val_loss improved from 0.21812 to 0.21693, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/056-0.2169.hdf5\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.3655 - acc: 0.8859 - val_loss: 0.2169 - val_acc: 0.9343\n",
      "Epoch 57/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3673 - acc: 0.8846\n",
      "Epoch 00057: val_loss did not improve from 0.21693\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.3674 - acc: 0.8845 - val_loss: 0.2183 - val_acc: 0.9345\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3597 - acc: 0.8871\n",
      "Epoch 00058: val_loss improved from 0.21693 to 0.21226, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/058-0.2123.hdf5\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.3597 - acc: 0.8871 - val_loss: 0.2123 - val_acc: 0.9355\n",
      "Epoch 59/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3612 - acc: 0.8864\n",
      "Epoch 00059: val_loss improved from 0.21226 to 0.20821, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/059-0.2082.hdf5\n",
      "36805/36805 [==============================] - 24s 662us/sample - loss: 0.3610 - acc: 0.8865 - val_loss: 0.2082 - val_acc: 0.9387\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3515 - acc: 0.8883\n",
      "Epoch 00060: val_loss improved from 0.20821 to 0.20271, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/060-0.2027.hdf5\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.3516 - acc: 0.8884 - val_loss: 0.2027 - val_acc: 0.9376\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3535 - acc: 0.8902\n",
      "Epoch 00061: val_loss did not improve from 0.20271\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.3534 - acc: 0.8903 - val_loss: 0.2077 - val_acc: 0.9383\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3478 - acc: 0.8911\n",
      "Epoch 00062: val_loss did not improve from 0.20271\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.3478 - acc: 0.8911 - val_loss: 0.2169 - val_acc: 0.9331\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3492 - acc: 0.8908\n",
      "Epoch 00063: val_loss did not improve from 0.20271\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.3491 - acc: 0.8909 - val_loss: 0.2053 - val_acc: 0.9385\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3463 - acc: 0.8911\n",
      "Epoch 00064: val_loss did not improve from 0.20271\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.3463 - acc: 0.8911 - val_loss: 0.2138 - val_acc: 0.9355\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3390 - acc: 0.8931\n",
      "Epoch 00065: val_loss did not improve from 0.20271\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.3391 - acc: 0.8931 - val_loss: 0.2037 - val_acc: 0.9371\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3305 - acc: 0.8960\n",
      "Epoch 00066: val_loss improved from 0.20271 to 0.19685, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/066-0.1968.hdf5\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.3305 - acc: 0.8960 - val_loss: 0.1968 - val_acc: 0.9408\n",
      "Epoch 67/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3329 - acc: 0.8949\n",
      "Epoch 00067: val_loss did not improve from 0.19685\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.3325 - acc: 0.8950 - val_loss: 0.1977 - val_acc: 0.9397\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.8959\n",
      "Epoch 00068: val_loss did not improve from 0.19685\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.3314 - acc: 0.8959 - val_loss: 0.1972 - val_acc: 0.9404\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3278 - acc: 0.8964\n",
      "Epoch 00069: val_loss did not improve from 0.19685\n",
      "36805/36805 [==============================] - 25s 670us/sample - loss: 0.3278 - acc: 0.8964 - val_loss: 0.2092 - val_acc: 0.9366\n",
      "Epoch 70/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3280 - acc: 0.8958\n",
      "Epoch 00070: val_loss improved from 0.19685 to 0.19647, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/070-0.1965.hdf5\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.3281 - acc: 0.8958 - val_loss: 0.1965 - val_acc: 0.9392\n",
      "Epoch 71/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3283 - acc: 0.8956\n",
      "Epoch 00071: val_loss did not improve from 0.19647\n",
      "36805/36805 [==============================] - 24s 664us/sample - loss: 0.3280 - acc: 0.8957 - val_loss: 0.2032 - val_acc: 0.9376\n",
      "Epoch 72/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3246 - acc: 0.8981\n",
      "Epoch 00072: val_loss did not improve from 0.19647\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.3247 - acc: 0.8982 - val_loss: 0.2077 - val_acc: 0.9359\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3213 - acc: 0.8965\n",
      "Epoch 00073: val_loss improved from 0.19647 to 0.19434, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/073-0.1943.hdf5\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.3213 - acc: 0.8965 - val_loss: 0.1943 - val_acc: 0.9420\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3170 - acc: 0.9007\n",
      "Epoch 00074: val_loss improved from 0.19434 to 0.19040, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/074-0.1904.hdf5\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.3171 - acc: 0.9007 - val_loss: 0.1904 - val_acc: 0.9439\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3193 - acc: 0.8992\n",
      "Epoch 00075: val_loss improved from 0.19040 to 0.18861, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/075-0.1886.hdf5\n",
      "36805/36805 [==============================] - 25s 667us/sample - loss: 0.3193 - acc: 0.8991 - val_loss: 0.1886 - val_acc: 0.9422\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3133 - acc: 0.9005\n",
      "Epoch 00076: val_loss did not improve from 0.18861\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.3133 - acc: 0.9005 - val_loss: 0.1899 - val_acc: 0.9418\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3088 - acc: 0.9026\n",
      "Epoch 00077: val_loss did not improve from 0.18861\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.3088 - acc: 0.9026 - val_loss: 0.1916 - val_acc: 0.9434\n",
      "Epoch 78/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3093 - acc: 0.9021\n",
      "Epoch 00078: val_loss did not improve from 0.18861\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.3092 - acc: 0.9021 - val_loss: 0.2124 - val_acc: 0.9352\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3058 - acc: 0.9038\n",
      "Epoch 00079: val_loss improved from 0.18861 to 0.18447, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/079-0.1845.hdf5\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.3059 - acc: 0.9038 - val_loss: 0.1845 - val_acc: 0.9441\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3074 - acc: 0.9011\n",
      "Epoch 00080: val_loss did not improve from 0.18447\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.3074 - acc: 0.9011 - val_loss: 0.1897 - val_acc: 0.9427\n",
      "Epoch 81/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3009 - acc: 0.9050\n",
      "Epoch 00081: val_loss did not improve from 0.18447\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.3013 - acc: 0.9048 - val_loss: 0.1943 - val_acc: 0.9429\n",
      "Epoch 82/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3001 - acc: 0.9045\n",
      "Epoch 00082: val_loss did not improve from 0.18447\n",
      "36805/36805 [==============================] - 24s 663us/sample - loss: 0.3001 - acc: 0.9044 - val_loss: 0.1851 - val_acc: 0.9432\n",
      "Epoch 83/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3037 - acc: 0.9043\n",
      "Epoch 00083: val_loss improved from 0.18447 to 0.18263, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/083-0.1826.hdf5\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.3036 - acc: 0.9044 - val_loss: 0.1826 - val_acc: 0.9450\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2952 - acc: 0.9073\n",
      "Epoch 00084: val_loss did not improve from 0.18263\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.2951 - acc: 0.9073 - val_loss: 0.1957 - val_acc: 0.9420\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2963 - acc: 0.9053\n",
      "Epoch 00085: val_loss improved from 0.18263 to 0.17868, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/085-0.1787.hdf5\n",
      "36805/36805 [==============================] - 25s 670us/sample - loss: 0.2963 - acc: 0.9053 - val_loss: 0.1787 - val_acc: 0.9474\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2933 - acc: 0.9071\n",
      "Epoch 00086: val_loss did not improve from 0.17868\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.2933 - acc: 0.9071 - val_loss: 0.1871 - val_acc: 0.9427\n",
      "Epoch 87/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2938 - acc: 0.9083\n",
      "Epoch 00087: val_loss did not improve from 0.17868\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.2938 - acc: 0.9083 - val_loss: 0.1860 - val_acc: 0.9427\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2942 - acc: 0.9062\n",
      "Epoch 00088: val_loss did not improve from 0.17868\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.2942 - acc: 0.9062 - val_loss: 0.1921 - val_acc: 0.9422\n",
      "Epoch 89/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2902 - acc: 0.9084\n",
      "Epoch 00089: val_loss improved from 0.17868 to 0.17742, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/089-0.1774.hdf5\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.2903 - acc: 0.9084 - val_loss: 0.1774 - val_acc: 0.9471\n",
      "Epoch 90/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2841 - acc: 0.9106\n",
      "Epoch 00090: val_loss did not improve from 0.17742\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.2841 - acc: 0.9106 - val_loss: 0.1808 - val_acc: 0.9436\n",
      "Epoch 91/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2843 - acc: 0.9088\n",
      "Epoch 00091: val_loss improved from 0.17742 to 0.17580, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/091-0.1758.hdf5\n",
      "36805/36805 [==============================] - 25s 670us/sample - loss: 0.2841 - acc: 0.9088 - val_loss: 0.1758 - val_acc: 0.9453\n",
      "Epoch 92/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2826 - acc: 0.9103\n",
      "Epoch 00092: val_loss did not improve from 0.17580\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.2826 - acc: 0.9102 - val_loss: 0.1839 - val_acc: 0.9436\n",
      "Epoch 93/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2826 - acc: 0.9107\n",
      "Epoch 00093: val_loss did not improve from 0.17580\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.2825 - acc: 0.9107 - val_loss: 0.1915 - val_acc: 0.9429\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2791 - acc: 0.9110\n",
      "Epoch 00094: val_loss did not improve from 0.17580\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.2791 - acc: 0.9110 - val_loss: 0.1768 - val_acc: 0.9450\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2759 - acc: 0.9123\n",
      "Epoch 00095: val_loss did not improve from 0.17580\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.2761 - acc: 0.9122 - val_loss: 0.1897 - val_acc: 0.9422\n",
      "Epoch 96/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2793 - acc: 0.9102\n",
      "Epoch 00096: val_loss did not improve from 0.17580\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.2790 - acc: 0.9103 - val_loss: 0.1833 - val_acc: 0.9434\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2766 - acc: 0.9117\n",
      "Epoch 00097: val_loss did not improve from 0.17580\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.2767 - acc: 0.9116 - val_loss: 0.1811 - val_acc: 0.9455\n",
      "Epoch 98/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2798 - acc: 0.9100\n",
      "Epoch 00098: val_loss did not improve from 0.17580\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.2799 - acc: 0.9099 - val_loss: 0.2013 - val_acc: 0.9369\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2728 - acc: 0.9144\n",
      "Epoch 00099: val_loss improved from 0.17580 to 0.17532, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/099-0.1753.hdf5\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.2728 - acc: 0.9144 - val_loss: 0.1753 - val_acc: 0.9450\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2706 - acc: 0.9142\n",
      "Epoch 00100: val_loss improved from 0.17532 to 0.16944, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/100-0.1694.hdf5\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.2706 - acc: 0.9141 - val_loss: 0.1694 - val_acc: 0.9474\n",
      "Epoch 101/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2784 - acc: 0.9113\n",
      "Epoch 00101: val_loss did not improve from 0.16944\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.2784 - acc: 0.9113 - val_loss: 0.1721 - val_acc: 0.9469\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2681 - acc: 0.9139\n",
      "Epoch 00102: val_loss did not improve from 0.16944\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.2681 - acc: 0.9139 - val_loss: 0.1730 - val_acc: 0.9443\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2674 - acc: 0.9162\n",
      "Epoch 00103: val_loss did not improve from 0.16944\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.2674 - acc: 0.9162 - val_loss: 0.1796 - val_acc: 0.9443\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2603 - acc: 0.9184\n",
      "Epoch 00104: val_loss did not improve from 0.16944\n",
      "36805/36805 [==============================] - 25s 670us/sample - loss: 0.2603 - acc: 0.9184 - val_loss: 0.1696 - val_acc: 0.9462\n",
      "Epoch 105/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2654 - acc: 0.9168\n",
      "Epoch 00105: val_loss did not improve from 0.16944\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.2654 - acc: 0.9169 - val_loss: 0.1715 - val_acc: 0.9464\n",
      "Epoch 106/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2620 - acc: 0.9163\n",
      "Epoch 00106: val_loss improved from 0.16944 to 0.16738, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/106-0.1674.hdf5\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.2620 - acc: 0.9163 - val_loss: 0.1674 - val_acc: 0.9490\n",
      "Epoch 107/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2650 - acc: 0.9152\n",
      "Epoch 00107: val_loss did not improve from 0.16738\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.2648 - acc: 0.9153 - val_loss: 0.1676 - val_acc: 0.9495\n",
      "Epoch 108/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.9165\n",
      "Epoch 00108: val_loss did not improve from 0.16738\n",
      "36805/36805 [==============================] - 25s 667us/sample - loss: 0.2609 - acc: 0.9165 - val_loss: 0.1682 - val_acc: 0.9467\n",
      "Epoch 109/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2580 - acc: 0.9174\n",
      "Epoch 00109: val_loss did not improve from 0.16738\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.2581 - acc: 0.9174 - val_loss: 0.1735 - val_acc: 0.9446\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2581 - acc: 0.9163\n",
      "Epoch 00110: val_loss did not improve from 0.16738\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.2580 - acc: 0.9163 - val_loss: 0.1704 - val_acc: 0.9469\n",
      "Epoch 111/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2575 - acc: 0.9165\n",
      "Epoch 00111: val_loss improved from 0.16738 to 0.16476, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/111-0.1648.hdf5\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.2578 - acc: 0.9164 - val_loss: 0.1648 - val_acc: 0.9476\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2533 - acc: 0.9191\n",
      "Epoch 00112: val_loss did not improve from 0.16476\n",
      "36805/36805 [==============================] - 24s 665us/sample - loss: 0.2533 - acc: 0.9191 - val_loss: 0.1651 - val_acc: 0.9460\n",
      "Epoch 113/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2562 - acc: 0.9180\n",
      "Epoch 00113: val_loss did not improve from 0.16476\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.2560 - acc: 0.9180 - val_loss: 0.1665 - val_acc: 0.9464\n",
      "Epoch 114/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2583 - acc: 0.9189\n",
      "Epoch 00114: val_loss did not improve from 0.16476\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.2579 - acc: 0.9190 - val_loss: 0.1692 - val_acc: 0.9481\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2554 - acc: 0.9189\n",
      "Epoch 00115: val_loss improved from 0.16476 to 0.16335, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/115-0.1633.hdf5\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.2555 - acc: 0.9189 - val_loss: 0.1633 - val_acc: 0.9490\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2505 - acc: 0.9187\n",
      "Epoch 00116: val_loss improved from 0.16335 to 0.16295, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/116-0.1630.hdf5\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.2504 - acc: 0.9187 - val_loss: 0.1630 - val_acc: 0.9511\n",
      "Epoch 117/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2459 - acc: 0.9215\n",
      "Epoch 00117: val_loss did not improve from 0.16295\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.2457 - acc: 0.9215 - val_loss: 0.1728 - val_acc: 0.9453\n",
      "Epoch 118/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2522 - acc: 0.9201\n",
      "Epoch 00118: val_loss did not improve from 0.16295\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.2523 - acc: 0.9200 - val_loss: 0.1739 - val_acc: 0.9439\n",
      "Epoch 119/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2453 - acc: 0.9210\n",
      "Epoch 00119: val_loss did not improve from 0.16295\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.2455 - acc: 0.9210 - val_loss: 0.1710 - val_acc: 0.9485\n",
      "Epoch 120/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2511 - acc: 0.9198\n",
      "Epoch 00120: val_loss did not improve from 0.16295\n",
      "36805/36805 [==============================] - 25s 667us/sample - loss: 0.2511 - acc: 0.9198 - val_loss: 0.1641 - val_acc: 0.9457\n",
      "Epoch 121/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2435 - acc: 0.9210\n",
      "Epoch 00121: val_loss did not improve from 0.16295\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.2434 - acc: 0.9211 - val_loss: 0.1660 - val_acc: 0.9471\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2450 - acc: 0.9216\n",
      "Epoch 00122: val_loss did not improve from 0.16295\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.2450 - acc: 0.9216 - val_loss: 0.1656 - val_acc: 0.9483\n",
      "Epoch 123/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2410 - acc: 0.9215\n",
      "Epoch 00123: val_loss did not improve from 0.16295\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.2408 - acc: 0.9216 - val_loss: 0.1670 - val_acc: 0.9460\n",
      "Epoch 124/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2450 - acc: 0.9207\n",
      "Epoch 00124: val_loss did not improve from 0.16295\n",
      "36805/36805 [==============================] - 24s 663us/sample - loss: 0.2449 - acc: 0.9207 - val_loss: 0.1640 - val_acc: 0.9478\n",
      "Epoch 125/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2451 - acc: 0.9220\n",
      "Epoch 00125: val_loss did not improve from 0.16295\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.2452 - acc: 0.9220 - val_loss: 0.1687 - val_acc: 0.9462\n",
      "Epoch 126/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2417 - acc: 0.9204\n",
      "Epoch 00126: val_loss improved from 0.16295 to 0.16124, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/126-0.1612.hdf5\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.2417 - acc: 0.9204 - val_loss: 0.1612 - val_acc: 0.9490\n",
      "Epoch 127/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2398 - acc: 0.9221\n",
      "Epoch 00127: val_loss did not improve from 0.16124\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.2399 - acc: 0.9220 - val_loss: 0.1649 - val_acc: 0.9504\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2378 - acc: 0.9239\n",
      "Epoch 00128: val_loss did not improve from 0.16124\n",
      "36805/36805 [==============================] - 24s 665us/sample - loss: 0.2378 - acc: 0.9240 - val_loss: 0.1659 - val_acc: 0.9474\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2394 - acc: 0.9237\n",
      "Epoch 00129: val_loss did not improve from 0.16124\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.2395 - acc: 0.9237 - val_loss: 0.1719 - val_acc: 0.9443\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9256\n",
      "Epoch 00130: val_loss did not improve from 0.16124\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.2362 - acc: 0.9256 - val_loss: 0.1613 - val_acc: 0.9490\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2383 - acc: 0.9237\n",
      "Epoch 00131: val_loss did not improve from 0.16124\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.2383 - acc: 0.9238 - val_loss: 0.1642 - val_acc: 0.9478\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2332 - acc: 0.9257\n",
      "Epoch 00132: val_loss did not improve from 0.16124\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.2333 - acc: 0.9257 - val_loss: 0.1755 - val_acc: 0.9469\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2393 - acc: 0.9225\n",
      "Epoch 00133: val_loss improved from 0.16124 to 0.15700, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/133-0.1570.hdf5\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.2393 - acc: 0.9225 - val_loss: 0.1570 - val_acc: 0.9485\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2242 - acc: 0.9279\n",
      "Epoch 00134: val_loss did not improve from 0.15700\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.2244 - acc: 0.9279 - val_loss: 0.1628 - val_acc: 0.9481\n",
      "Epoch 135/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2275 - acc: 0.9275\n",
      "Epoch 00135: val_loss did not improve from 0.15700\n",
      "36805/36805 [==============================] - 25s 668us/sample - loss: 0.2278 - acc: 0.9274 - val_loss: 0.1583 - val_acc: 0.9478\n",
      "Epoch 136/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9269\n",
      "Epoch 00136: val_loss did not improve from 0.15700\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.2263 - acc: 0.9269 - val_loss: 0.1627 - val_acc: 0.9485\n",
      "Epoch 137/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2308 - acc: 0.9261\n",
      "Epoch 00137: val_loss did not improve from 0.15700\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.2310 - acc: 0.9260 - val_loss: 0.1645 - val_acc: 0.9469\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2297 - acc: 0.9251\n",
      "Epoch 00138: val_loss did not improve from 0.15700\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.2296 - acc: 0.9251 - val_loss: 0.1630 - val_acc: 0.9471\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2265 - acc: 0.9278\n",
      "Epoch 00139: val_loss improved from 0.15700 to 0.15659, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/139-0.1566.hdf5\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.2264 - acc: 0.9278 - val_loss: 0.1566 - val_acc: 0.9522\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2225 - acc: 0.9285\n",
      "Epoch 00140: val_loss did not improve from 0.15659\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.2226 - acc: 0.9285 - val_loss: 0.1583 - val_acc: 0.9492\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2233 - acc: 0.9280\n",
      "Epoch 00141: val_loss did not improve from 0.15659\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.2233 - acc: 0.9280 - val_loss: 0.1634 - val_acc: 0.9455\n",
      "Epoch 142/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9302\n",
      "Epoch 00142: val_loss did not improve from 0.15659\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.2212 - acc: 0.9302 - val_loss: 0.1611 - val_acc: 0.9490\n",
      "Epoch 143/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2221 - acc: 0.9294\n",
      "Epoch 00143: val_loss did not improve from 0.15659\n",
      "36805/36805 [==============================] - 24s 660us/sample - loss: 0.2221 - acc: 0.9294 - val_loss: 0.1573 - val_acc: 0.9485\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2246 - acc: 0.9272\n",
      "Epoch 00144: val_loss did not improve from 0.15659\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.2246 - acc: 0.9272 - val_loss: 0.1620 - val_acc: 0.9460\n",
      "Epoch 145/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2218 - acc: 0.9281\n",
      "Epoch 00145: val_loss did not improve from 0.15659\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.2219 - acc: 0.9281 - val_loss: 0.1626 - val_acc: 0.9478\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2191 - acc: 0.9286\n",
      "Epoch 00146: val_loss did not improve from 0.15659\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.2191 - acc: 0.9286 - val_loss: 0.1627 - val_acc: 0.9478\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2217 - acc: 0.9284\n",
      "Epoch 00147: val_loss did not improve from 0.15659\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.2217 - acc: 0.9284 - val_loss: 0.1629 - val_acc: 0.9476\n",
      "Epoch 148/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2193 - acc: 0.9290\n",
      "Epoch 00148: val_loss did not improve from 0.15659\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.2194 - acc: 0.9290 - val_loss: 0.1573 - val_acc: 0.9497\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2210 - acc: 0.9287\n",
      "Epoch 00149: val_loss improved from 0.15659 to 0.15205, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/149-0.1520.hdf5\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.2210 - acc: 0.9287 - val_loss: 0.1520 - val_acc: 0.9506\n",
      "Epoch 150/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2201 - acc: 0.9288\n",
      "Epoch 00150: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 25s 667us/sample - loss: 0.2202 - acc: 0.9288 - val_loss: 0.1573 - val_acc: 0.9495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2096 - acc: 0.9318\n",
      "Epoch 00151: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 25s 668us/sample - loss: 0.2096 - acc: 0.9318 - val_loss: 0.1533 - val_acc: 0.9509\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2176 - acc: 0.9296\n",
      "Epoch 00152: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.2176 - acc: 0.9296 - val_loss: 0.1538 - val_acc: 0.9502\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2151 - acc: 0.9290\n",
      "Epoch 00153: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.2151 - acc: 0.9291 - val_loss: 0.1604 - val_acc: 0.9469\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2138 - acc: 0.9301\n",
      "Epoch 00154: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.2138 - acc: 0.9300 - val_loss: 0.1554 - val_acc: 0.9488\n",
      "Epoch 155/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9308\n",
      "Epoch 00155: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.2126 - acc: 0.9308 - val_loss: 0.1598 - val_acc: 0.9502\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2124 - acc: 0.9310\n",
      "Epoch 00156: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.2123 - acc: 0.9310 - val_loss: 0.1561 - val_acc: 0.9495\n",
      "Epoch 157/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2065 - acc: 0.9334\n",
      "Epoch 00157: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.2064 - acc: 0.9335 - val_loss: 0.1560 - val_acc: 0.9502\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9304\n",
      "Epoch 00158: val_loss improved from 0.15205 to 0.15121, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/158-0.1512.hdf5\n",
      "36805/36805 [==============================] - 25s 666us/sample - loss: 0.2101 - acc: 0.9304 - val_loss: 0.1512 - val_acc: 0.9492\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2111 - acc: 0.9315\n",
      "Epoch 00159: val_loss did not improve from 0.15121\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.2111 - acc: 0.9315 - val_loss: 0.1623 - val_acc: 0.9502\n",
      "Epoch 160/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2081 - acc: 0.9322\n",
      "Epoch 00160: val_loss did not improve from 0.15121\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.2085 - acc: 0.9322 - val_loss: 0.1596 - val_acc: 0.9499\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2066 - acc: 0.9325\n",
      "Epoch 00161: val_loss did not improve from 0.15121\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.2066 - acc: 0.9325 - val_loss: 0.1553 - val_acc: 0.9506\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9335\n",
      "Epoch 00162: val_loss did not improve from 0.15121\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.2048 - acc: 0.9335 - val_loss: 0.1553 - val_acc: 0.9497\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2084 - acc: 0.9317\n",
      "Epoch 00163: val_loss did not improve from 0.15121\n",
      "36805/36805 [==============================] - 25s 669us/sample - loss: 0.2084 - acc: 0.9317 - val_loss: 0.1568 - val_acc: 0.9502\n",
      "Epoch 164/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2081 - acc: 0.9325\n",
      "Epoch 00164: val_loss did not improve from 0.15121\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.2080 - acc: 0.9325 - val_loss: 0.1664 - val_acc: 0.9485\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2038 - acc: 0.9336\n",
      "Epoch 00165: val_loss did not improve from 0.15121\n",
      "36805/36805 [==============================] - 25s 668us/sample - loss: 0.2038 - acc: 0.9337 - val_loss: 0.1586 - val_acc: 0.9509\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2069 - acc: 0.9323\n",
      "Epoch 00166: val_loss did not improve from 0.15121\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.2069 - acc: 0.9322 - val_loss: 0.1631 - val_acc: 0.9467\n",
      "Epoch 167/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9322\n",
      "Epoch 00167: val_loss did not improve from 0.15121\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.2054 - acc: 0.9323 - val_loss: 0.1593 - val_acc: 0.9504\n",
      "Epoch 168/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9335\n",
      "Epoch 00168: val_loss improved from 0.15121 to 0.15015, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv_checkpoint/168-0.1502.hdf5\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.2024 - acc: 0.9334 - val_loss: 0.1502 - val_acc: 0.9527\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2041 - acc: 0.9341\n",
      "Epoch 00169: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.2041 - acc: 0.9341 - val_loss: 0.1628 - val_acc: 0.9483\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9336\n",
      "Epoch 00170: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.2010 - acc: 0.9336 - val_loss: 0.1567 - val_acc: 0.9527\n",
      "Epoch 171/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2043 - acc: 0.9339\n",
      "Epoch 00171: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.2043 - acc: 0.9339 - val_loss: 0.1569 - val_acc: 0.9506\n",
      "Epoch 172/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9347\n",
      "Epoch 00172: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.2020 - acc: 0.9346 - val_loss: 0.1657 - val_acc: 0.9495\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9356\n",
      "Epoch 00173: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 24s 666us/sample - loss: 0.1986 - acc: 0.9356 - val_loss: 0.1683 - val_acc: 0.9448\n",
      "Epoch 174/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2024 - acc: 0.9332\n",
      "Epoch 00174: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.2022 - acc: 0.9333 - val_loss: 0.1618 - val_acc: 0.9499\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2013 - acc: 0.9343\n",
      "Epoch 00175: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.2013 - acc: 0.9343 - val_loss: 0.1556 - val_acc: 0.9522\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2000 - acc: 0.9352\n",
      "Epoch 00176: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.2000 - acc: 0.9351 - val_loss: 0.1545 - val_acc: 0.9499\n",
      "Epoch 177/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9355\n",
      "Epoch 00177: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 666us/sample - loss: 0.2022 - acc: 0.9355 - val_loss: 0.1592 - val_acc: 0.9506\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1973 - acc: 0.9357\n",
      "Epoch 00178: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.1973 - acc: 0.9357 - val_loss: 0.1553 - val_acc: 0.9511\n",
      "Epoch 179/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1970 - acc: 0.9366\n",
      "Epoch 00179: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.1968 - acc: 0.9366 - val_loss: 0.1583 - val_acc: 0.9488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2001 - acc: 0.9350\n",
      "Epoch 00180: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.2002 - acc: 0.9350 - val_loss: 0.1556 - val_acc: 0.9518\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9360\n",
      "Epoch 00181: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 24s 662us/sample - loss: 0.1946 - acc: 0.9360 - val_loss: 0.1616 - val_acc: 0.9506\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1941 - acc: 0.9363\n",
      "Epoch 00182: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.1941 - acc: 0.9363 - val_loss: 0.1629 - val_acc: 0.9497\n",
      "Epoch 183/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9349\n",
      "Epoch 00183: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.1980 - acc: 0.9349 - val_loss: 0.1621 - val_acc: 0.9502\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1906 - acc: 0.9366\n",
      "Epoch 00184: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.1907 - acc: 0.9366 - val_loss: 0.1537 - val_acc: 0.9506\n",
      "Epoch 185/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1955 - acc: 0.9359\n",
      "Epoch 00185: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.1956 - acc: 0.9359 - val_loss: 0.1675 - val_acc: 0.9488\n",
      "Epoch 186/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9377\n",
      "Epoch 00186: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.1923 - acc: 0.9377 - val_loss: 0.1563 - val_acc: 0.9518\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1901 - acc: 0.9374\n",
      "Epoch 00187: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.1901 - acc: 0.9373 - val_loss: 0.1595 - val_acc: 0.9513\n",
      "Epoch 188/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1924 - acc: 0.9383\n",
      "Epoch 00188: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 24s 665us/sample - loss: 0.1924 - acc: 0.9383 - val_loss: 0.1606 - val_acc: 0.9499\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1900 - acc: 0.9387\n",
      "Epoch 00189: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.1899 - acc: 0.9387 - val_loss: 0.1599 - val_acc: 0.9504\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9369\n",
      "Epoch 00190: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.1874 - acc: 0.9369 - val_loss: 0.1584 - val_acc: 0.9504\n",
      "Epoch 191/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1869 - acc: 0.9389\n",
      "Epoch 00191: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.1867 - acc: 0.9390 - val_loss: 0.1526 - val_acc: 0.9529\n",
      "Epoch 192/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1871 - acc: 0.9385\n",
      "Epoch 00192: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.1870 - acc: 0.9385 - val_loss: 0.1606 - val_acc: 0.9529\n",
      "Epoch 193/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1909 - acc: 0.9372\n",
      "Epoch 00193: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.1909 - acc: 0.9372 - val_loss: 0.1596 - val_acc: 0.9520\n",
      "Epoch 194/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1895 - acc: 0.9379\n",
      "Epoch 00194: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.1896 - acc: 0.9378 - val_loss: 0.1599 - val_acc: 0.9509\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1870 - acc: 0.9383\n",
      "Epoch 00195: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.1870 - acc: 0.9384 - val_loss: 0.1556 - val_acc: 0.9527\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1867 - acc: 0.9389\n",
      "Epoch 00196: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 666us/sample - loss: 0.1866 - acc: 0.9389 - val_loss: 0.1606 - val_acc: 0.9506\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9397\n",
      "Epoch 00197: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.1809 - acc: 0.9397 - val_loss: 0.1539 - val_acc: 0.9527\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1814 - acc: 0.9405\n",
      "Epoch 00198: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.1813 - acc: 0.9406 - val_loss: 0.1527 - val_acc: 0.9527\n",
      "Epoch 199/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1845 - acc: 0.9420\n",
      "Epoch 00199: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.1844 - acc: 0.9419 - val_loss: 0.1607 - val_acc: 0.9495\n",
      "Epoch 200/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9397\n",
      "Epoch 00200: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 24s 660us/sample - loss: 0.1843 - acc: 0.9397 - val_loss: 0.1609 - val_acc: 0.9499\n",
      "Epoch 201/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9400\n",
      "Epoch 00201: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.1826 - acc: 0.9401 - val_loss: 0.1549 - val_acc: 0.9513\n",
      "Epoch 202/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9400\n",
      "Epoch 00202: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.1809 - acc: 0.9401 - val_loss: 0.1531 - val_acc: 0.9532\n",
      "Epoch 203/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1821 - acc: 0.9405\n",
      "Epoch 00203: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.1821 - acc: 0.9405 - val_loss: 0.1677 - val_acc: 0.9504\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1773 - acc: 0.9425\n",
      "Epoch 00204: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 24s 657us/sample - loss: 0.1773 - acc: 0.9425 - val_loss: 0.1602 - val_acc: 0.9506\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9407\n",
      "Epoch 00205: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.1792 - acc: 0.9407 - val_loss: 0.1612 - val_acc: 0.9520\n",
      "Epoch 206/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1803 - acc: 0.9413\n",
      "Epoch 00206: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 671us/sample - loss: 0.1802 - acc: 0.9413 - val_loss: 0.1629 - val_acc: 0.9504\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1757 - acc: 0.9413\n",
      "Epoch 00207: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 670us/sample - loss: 0.1757 - acc: 0.9413 - val_loss: 0.1547 - val_acc: 0.9522\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9402\n",
      "Epoch 00208: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 670us/sample - loss: 0.1830 - acc: 0.9402 - val_loss: 0.1601 - val_acc: 0.9495\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1794 - acc: 0.9406\n",
      "Epoch 00209: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.1793 - acc: 0.9406 - val_loss: 0.1565 - val_acc: 0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1692 - acc: 0.9441\n",
      "Epoch 00210: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.1693 - acc: 0.9441 - val_loss: 0.1726 - val_acc: 0.9497\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9417\n",
      "Epoch 00211: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.1770 - acc: 0.9417 - val_loss: 0.1606 - val_acc: 0.9513\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1794 - acc: 0.9401\n",
      "Epoch 00212: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 667us/sample - loss: 0.1794 - acc: 0.9401 - val_loss: 0.1523 - val_acc: 0.9546\n",
      "Epoch 213/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9424\n",
      "Epoch 00213: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.1758 - acc: 0.9424 - val_loss: 0.1650 - val_acc: 0.9476\n",
      "Epoch 214/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9422\n",
      "Epoch 00214: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 673us/sample - loss: 0.1791 - acc: 0.9421 - val_loss: 0.1675 - val_acc: 0.9492\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9396\n",
      "Epoch 00215: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.1819 - acc: 0.9396 - val_loss: 0.1531 - val_acc: 0.9527\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9430\n",
      "Epoch 00216: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.1737 - acc: 0.9430 - val_loss: 0.1638 - val_acc: 0.9490\n",
      "Epoch 217/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1751 - acc: 0.9415\n",
      "Epoch 00217: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.1751 - acc: 0.9415 - val_loss: 0.1551 - val_acc: 0.9511\n",
      "Epoch 218/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1726 - acc: 0.9428\n",
      "Epoch 00218: val_loss did not improve from 0.15015\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.1730 - acc: 0.9427 - val_loss: 0.1553 - val_acc: 0.9511\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 429us/sample - loss: 0.2019 - acc: 0.9394\n",
      "Loss: 0.2018641644549147 Accuracy: 0.9393562\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4417 - acc: 0.1912\n",
      "Epoch 00001: val_loss improved from inf to 1.75846, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/001-1.7585.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 2.4417 - acc: 0.1912 - val_loss: 1.7585 - val_acc: 0.5041\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7344 - acc: 0.4289\n",
      "Epoch 00002: val_loss improved from 1.75846 to 1.19114, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/002-1.1911.hdf5\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 1.7345 - acc: 0.4289 - val_loss: 1.1911 - val_acc: 0.6548\n",
      "Epoch 3/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3435 - acc: 0.5632\n",
      "Epoch 00003: val_loss improved from 1.19114 to 0.88587, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/003-0.8859.hdf5\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 1.3431 - acc: 0.5633 - val_loss: 0.8859 - val_acc: 0.7470\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1239 - acc: 0.6362\n",
      "Epoch 00004: val_loss improved from 0.88587 to 0.71699, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/004-0.7170.hdf5\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 1.1238 - acc: 0.6362 - val_loss: 0.7170 - val_acc: 0.8046\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9648 - acc: 0.6901\n",
      "Epoch 00005: val_loss improved from 0.71699 to 0.60849, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/005-0.6085.hdf5\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.9648 - acc: 0.6901 - val_loss: 0.6085 - val_acc: 0.8318\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8559 - acc: 0.7277\n",
      "Epoch 00006: val_loss improved from 0.60849 to 0.52052, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/006-0.5205.hdf5\n",
      "36805/36805 [==============================] - 25s 693us/sample - loss: 0.8558 - acc: 0.7277 - val_loss: 0.5205 - val_acc: 0.8516\n",
      "Epoch 7/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7784 - acc: 0.7549\n",
      "Epoch 00007: val_loss improved from 0.52052 to 0.47117, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/007-0.4712.hdf5\n",
      "36805/36805 [==============================] - 26s 695us/sample - loss: 0.7781 - acc: 0.7550 - val_loss: 0.4712 - val_acc: 0.8700\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6974 - acc: 0.7797\n",
      "Epoch 00008: val_loss improved from 0.47117 to 0.42011, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/008-0.4201.hdf5\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.6974 - acc: 0.7797 - val_loss: 0.4201 - val_acc: 0.8835\n",
      "Epoch 9/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6409 - acc: 0.7983\n",
      "Epoch 00009: val_loss improved from 0.42011 to 0.37906, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/009-0.3791.hdf5\n",
      "36805/36805 [==============================] - 26s 696us/sample - loss: 0.6407 - acc: 0.7983 - val_loss: 0.3791 - val_acc: 0.8970\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5909 - acc: 0.8142\n",
      "Epoch 00010: val_loss improved from 0.37906 to 0.34019, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/010-0.3402.hdf5\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.5909 - acc: 0.8142 - val_loss: 0.3402 - val_acc: 0.9031\n",
      "Epoch 11/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5480 - acc: 0.8285\n",
      "Epoch 00011: val_loss improved from 0.34019 to 0.31411, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/011-0.3141.hdf5\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.5477 - acc: 0.8285 - val_loss: 0.3141 - val_acc: 0.9094\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5173 - acc: 0.8389\n",
      "Epoch 00012: val_loss improved from 0.31411 to 0.28266, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/012-0.2827.hdf5\n",
      "36805/36805 [==============================] - 26s 693us/sample - loss: 0.5172 - acc: 0.8389 - val_loss: 0.2827 - val_acc: 0.9220\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4949 - acc: 0.8468\n",
      "Epoch 00013: val_loss improved from 0.28266 to 0.27233, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/013-0.2723.hdf5\n",
      "36805/36805 [==============================] - 26s 696us/sample - loss: 0.4949 - acc: 0.8468 - val_loss: 0.2723 - val_acc: 0.9229\n",
      "Epoch 14/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4653 - acc: 0.8546\n",
      "Epoch 00014: val_loss improved from 0.27233 to 0.26138, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/014-0.2614.hdf5\n",
      "36805/36805 [==============================] - 26s 695us/sample - loss: 0.4654 - acc: 0.8545 - val_loss: 0.2614 - val_acc: 0.9280\n",
      "Epoch 15/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4385 - acc: 0.8642\n",
      "Epoch 00015: val_loss improved from 0.26138 to 0.25204, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/015-0.2520.hdf5\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.4385 - acc: 0.8642 - val_loss: 0.2520 - val_acc: 0.9259\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4225 - acc: 0.8677\n",
      "Epoch 00016: val_loss improved from 0.25204 to 0.22642, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/016-0.2264.hdf5\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.4226 - acc: 0.8677 - val_loss: 0.2264 - val_acc: 0.9341\n",
      "Epoch 17/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4053 - acc: 0.8745\n",
      "Epoch 00017: val_loss improved from 0.22642 to 0.22505, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/017-0.2251.hdf5\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.4051 - acc: 0.8745 - val_loss: 0.2251 - val_acc: 0.9362\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3876 - acc: 0.8783\n",
      "Epoch 00018: val_loss improved from 0.22505 to 0.20826, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/018-0.2083.hdf5\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.3876 - acc: 0.8783 - val_loss: 0.2083 - val_acc: 0.9406\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3768 - acc: 0.8833\n",
      "Epoch 00019: val_loss did not improve from 0.20826\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.3770 - acc: 0.8832 - val_loss: 0.2090 - val_acc: 0.9390\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3627 - acc: 0.8874\n",
      "Epoch 00020: val_loss improved from 0.20826 to 0.19918, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/020-0.1992.hdf5\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.3627 - acc: 0.8874 - val_loss: 0.1992 - val_acc: 0.9439\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3529 - acc: 0.8900\n",
      "Epoch 00021: val_loss improved from 0.19918 to 0.18958, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/021-0.1896.hdf5\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.3530 - acc: 0.8900 - val_loss: 0.1896 - val_acc: 0.9446\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3498 - acc: 0.8922\n",
      "Epoch 00022: val_loss improved from 0.18958 to 0.18521, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/022-0.1852.hdf5\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.3496 - acc: 0.8923 - val_loss: 0.1852 - val_acc: 0.9460\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3337 - acc: 0.8968\n",
      "Epoch 00023: val_loss improved from 0.18521 to 0.18046, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/023-0.1805.hdf5\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.3336 - acc: 0.8968 - val_loss: 0.1805 - val_acc: 0.9483\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3220 - acc: 0.8986\n",
      "Epoch 00024: val_loss improved from 0.18046 to 0.17769, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/024-0.1777.hdf5\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.3224 - acc: 0.8985 - val_loss: 0.1777 - val_acc: 0.9478\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3125 - acc: 0.9039\n",
      "Epoch 00025: val_loss improved from 0.17769 to 0.17686, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/025-0.1769.hdf5\n",
      "36805/36805 [==============================] - 25s 692us/sample - loss: 0.3125 - acc: 0.9039 - val_loss: 0.1769 - val_acc: 0.9481\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3090 - acc: 0.9029\n",
      "Epoch 00026: val_loss improved from 0.17686 to 0.17629, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/026-0.1763.hdf5\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.3091 - acc: 0.9029 - val_loss: 0.1763 - val_acc: 0.9502\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2992 - acc: 0.9060\n",
      "Epoch 00027: val_loss improved from 0.17629 to 0.16310, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/027-0.1631.hdf5\n",
      "36805/36805 [==============================] - 26s 695us/sample - loss: 0.2992 - acc: 0.9060 - val_loss: 0.1631 - val_acc: 0.9522\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2934 - acc: 0.9083\n",
      "Epoch 00028: val_loss did not improve from 0.16310\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.2933 - acc: 0.9084 - val_loss: 0.1850 - val_acc: 0.9450\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2897 - acc: 0.9100\n",
      "Epoch 00029: val_loss did not improve from 0.16310\n",
      "36805/36805 [==============================] - 26s 693us/sample - loss: 0.2898 - acc: 0.9100 - val_loss: 0.1871 - val_acc: 0.9434\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2851 - acc: 0.9117\n",
      "Epoch 00030: val_loss did not improve from 0.16310\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.2850 - acc: 0.9117 - val_loss: 0.1688 - val_acc: 0.9485\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2779 - acc: 0.9135\n",
      "Epoch 00031: val_loss improved from 0.16310 to 0.15597, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/031-0.1560.hdf5\n",
      "36805/36805 [==============================] - 26s 696us/sample - loss: 0.2780 - acc: 0.9135 - val_loss: 0.1560 - val_acc: 0.9534\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2744 - acc: 0.9146\n",
      "Epoch 00032: val_loss improved from 0.15597 to 0.15567, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/032-0.1557.hdf5\n",
      "36805/36805 [==============================] - 26s 693us/sample - loss: 0.2744 - acc: 0.9146 - val_loss: 0.1557 - val_acc: 0.9539\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2696 - acc: 0.9172\n",
      "Epoch 00033: val_loss did not improve from 0.15567\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.2696 - acc: 0.9172 - val_loss: 0.1738 - val_acc: 0.9460\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2659 - acc: 0.9173\n",
      "Epoch 00034: val_loss improved from 0.15567 to 0.15013, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/034-0.1501.hdf5\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.2659 - acc: 0.9173 - val_loss: 0.1501 - val_acc: 0.9567\n",
      "Epoch 35/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2589 - acc: 0.9195\n",
      "Epoch 00035: val_loss did not improve from 0.15013\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.2588 - acc: 0.9195 - val_loss: 0.1592 - val_acc: 0.9522\n",
      "Epoch 36/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2558 - acc: 0.9186\n",
      "Epoch 00036: val_loss improved from 0.15013 to 0.14511, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/036-0.1451.hdf5\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.2555 - acc: 0.9187 - val_loss: 0.1451 - val_acc: 0.9557\n",
      "Epoch 37/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2469 - acc: 0.9243\n",
      "Epoch 00037: val_loss did not improve from 0.14511\n",
      "36805/36805 [==============================] - 26s 695us/sample - loss: 0.2467 - acc: 0.9244 - val_loss: 0.1475 - val_acc: 0.9567\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2478 - acc: 0.9233\n",
      "Epoch 00038: val_loss improved from 0.14511 to 0.14236, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/038-0.1424.hdf5\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.2477 - acc: 0.9233 - val_loss: 0.1424 - val_acc: 0.9585\n",
      "Epoch 39/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2459 - acc: 0.9226\n",
      "Epoch 00039: val_loss did not improve from 0.14236\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.2458 - acc: 0.9226 - val_loss: 0.1429 - val_acc: 0.9590\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9261\n",
      "Epoch 00040: val_loss did not improve from 0.14236\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.2364 - acc: 0.9260 - val_loss: 0.1475 - val_acc: 0.9564\n",
      "Epoch 41/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2366 - acc: 0.9248\n",
      "Epoch 00041: val_loss did not improve from 0.14236\n",
      "36805/36805 [==============================] - 26s 693us/sample - loss: 0.2368 - acc: 0.9248 - val_loss: 0.1433 - val_acc: 0.9578\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2307 - acc: 0.9272\n",
      "Epoch 00042: val_loss did not improve from 0.14236\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.2307 - acc: 0.9272 - val_loss: 0.1520 - val_acc: 0.9522\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2281 - acc: 0.9291\n",
      "Epoch 00043: val_loss did not improve from 0.14236\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.2279 - acc: 0.9292 - val_loss: 0.1432 - val_acc: 0.9536\n",
      "Epoch 44/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2226 - acc: 0.9300\n",
      "Epoch 00044: val_loss improved from 0.14236 to 0.13916, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/044-0.1392.hdf5\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.2229 - acc: 0.9299 - val_loss: 0.1392 - val_acc: 0.9583\n",
      "Epoch 45/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2185 - acc: 0.9307\n",
      "Epoch 00045: val_loss improved from 0.13916 to 0.13626, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/045-0.1363.hdf5\n",
      "36805/36805 [==============================] - 25s 692us/sample - loss: 0.2189 - acc: 0.9306 - val_loss: 0.1363 - val_acc: 0.9583\n",
      "Epoch 46/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9310\n",
      "Epoch 00046: val_loss did not improve from 0.13626\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.2188 - acc: 0.9310 - val_loss: 0.1423 - val_acc: 0.9576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9319\n",
      "Epoch 00047: val_loss did not improve from 0.13626\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.2139 - acc: 0.9319 - val_loss: 0.1384 - val_acc: 0.9599\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2115 - acc: 0.9326\n",
      "Epoch 00048: val_loss did not improve from 0.13626\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.2115 - acc: 0.9326 - val_loss: 0.1368 - val_acc: 0.9578\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9339\n",
      "Epoch 00049: val_loss improved from 0.13626 to 0.12747, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/049-0.1275.hdf5\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.2078 - acc: 0.9339 - val_loss: 0.1275 - val_acc: 0.9613\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9343\n",
      "Epoch 00050: val_loss improved from 0.12747 to 0.12746, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/050-0.1275.hdf5\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.2077 - acc: 0.9344 - val_loss: 0.1275 - val_acc: 0.9620\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2051 - acc: 0.9348\n",
      "Epoch 00051: val_loss did not improve from 0.12746\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.2053 - acc: 0.9348 - val_loss: 0.1297 - val_acc: 0.9609\n",
      "Epoch 52/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1979 - acc: 0.9368\n",
      "Epoch 00052: val_loss did not improve from 0.12746\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1977 - acc: 0.9369 - val_loss: 0.1288 - val_acc: 0.9611\n",
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1999 - acc: 0.9355\n",
      "Epoch 00053: val_loss improved from 0.12746 to 0.12737, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/053-0.1274.hdf5\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.1997 - acc: 0.9356 - val_loss: 0.1274 - val_acc: 0.9595\n",
      "Epoch 54/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1970 - acc: 0.9381\n",
      "Epoch 00054: val_loss did not improve from 0.12737\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1968 - acc: 0.9382 - val_loss: 0.1283 - val_acc: 0.9599\n",
      "Epoch 55/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1937 - acc: 0.9378\n",
      "Epoch 00055: val_loss did not improve from 0.12737\n",
      "36805/36805 [==============================] - 25s 691us/sample - loss: 0.1938 - acc: 0.9379 - val_loss: 0.1314 - val_acc: 0.9597\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1918 - acc: 0.9389\n",
      "Epoch 00056: val_loss improved from 0.12737 to 0.12654, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/056-0.1265.hdf5\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.1917 - acc: 0.9389 - val_loss: 0.1265 - val_acc: 0.9585\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1906 - acc: 0.9391\n",
      "Epoch 00057: val_loss did not improve from 0.12654\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.1906 - acc: 0.9391 - val_loss: 0.1382 - val_acc: 0.9560\n",
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1867 - acc: 0.9410\n",
      "Epoch 00058: val_loss improved from 0.12654 to 0.12526, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/058-0.1253.hdf5\n",
      "36805/36805 [==============================] - 25s 691us/sample - loss: 0.1865 - acc: 0.9410 - val_loss: 0.1253 - val_acc: 0.9597\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9413\n",
      "Epoch 00059: val_loss did not improve from 0.12526\n",
      "36805/36805 [==============================] - 26s 693us/sample - loss: 0.1842 - acc: 0.9413 - val_loss: 0.1274 - val_acc: 0.9606\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9413\n",
      "Epoch 00060: val_loss improved from 0.12526 to 0.12197, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/060-0.1220.hdf5\n",
      "36805/36805 [==============================] - 26s 694us/sample - loss: 0.1843 - acc: 0.9413 - val_loss: 0.1220 - val_acc: 0.9609\n",
      "Epoch 61/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1795 - acc: 0.9426\n",
      "Epoch 00061: val_loss did not improve from 0.12197\n",
      "36805/36805 [==============================] - 26s 695us/sample - loss: 0.1795 - acc: 0.9426 - val_loss: 0.1303 - val_acc: 0.9590\n",
      "Epoch 62/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1814 - acc: 0.9419- ETA: 2s - lo\n",
      "Epoch 00062: val_loss improved from 0.12197 to 0.12019, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/062-0.1202.hdf5\n",
      "36805/36805 [==============================] - 25s 667us/sample - loss: 0.1813 - acc: 0.9419 - val_loss: 0.1202 - val_acc: 0.9639\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9446\n",
      "Epoch 00063: val_loss did not improve from 0.12019\n",
      "36805/36805 [==============================] - 25s 692us/sample - loss: 0.1776 - acc: 0.9446 - val_loss: 0.1246 - val_acc: 0.9606\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9435\n",
      "Epoch 00064: val_loss did not improve from 0.12019\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.1762 - acc: 0.9435 - val_loss: 0.1279 - val_acc: 0.9611\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1734 - acc: 0.9460\n",
      "Epoch 00065: val_loss improved from 0.12019 to 0.11934, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/065-0.1193.hdf5\n",
      "36805/36805 [==============================] - 26s 693us/sample - loss: 0.1734 - acc: 0.9460 - val_loss: 0.1193 - val_acc: 0.9623\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1706 - acc: 0.9454\n",
      "Epoch 00066: val_loss did not improve from 0.11934\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.1704 - acc: 0.9455 - val_loss: 0.1229 - val_acc: 0.9634\n",
      "Epoch 67/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9469\n",
      "Epoch 00067: val_loss improved from 0.11934 to 0.11904, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/067-0.1190.hdf5\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.1679 - acc: 0.9470 - val_loss: 0.1190 - val_acc: 0.9609\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9474\n",
      "Epoch 00068: val_loss improved from 0.11904 to 0.11558, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/068-0.1156.hdf5\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1636 - acc: 0.9474 - val_loss: 0.1156 - val_acc: 0.9658\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1659 - acc: 0.9472\n",
      "Epoch 00069: val_loss did not improve from 0.11558\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.1659 - acc: 0.9472 - val_loss: 0.1185 - val_acc: 0.9613\n",
      "Epoch 70/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1659 - acc: 0.9469\n",
      "Epoch 00070: val_loss did not improve from 0.11558\n",
      "36805/36805 [==============================] - 25s 691us/sample - loss: 0.1659 - acc: 0.9469 - val_loss: 0.1235 - val_acc: 0.9632\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9467\n",
      "Epoch 00071: val_loss did not improve from 0.11558\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.1674 - acc: 0.9467 - val_loss: 0.1215 - val_acc: 0.9644\n",
      "Epoch 72/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9480\n",
      "Epoch 00072: val_loss did not improve from 0.11558\n",
      "36805/36805 [==============================] - 25s 691us/sample - loss: 0.1635 - acc: 0.9480 - val_loss: 0.1187 - val_acc: 0.9623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9494\n",
      "Epoch 00073: val_loss did not improve from 0.11558\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.1609 - acc: 0.9494 - val_loss: 0.1199 - val_acc: 0.9627\n",
      "Epoch 74/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9496\n",
      "Epoch 00074: val_loss did not improve from 0.11558\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.1567 - acc: 0.9495 - val_loss: 0.1199 - val_acc: 0.9623\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1585 - acc: 0.9492\n",
      "Epoch 00075: val_loss did not improve from 0.11558\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.1585 - acc: 0.9492 - val_loss: 0.1184 - val_acc: 0.9639\n",
      "Epoch 76/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9506\n",
      "Epoch 00076: val_loss did not improve from 0.11558\n",
      "36805/36805 [==============================] - 25s 693us/sample - loss: 0.1552 - acc: 0.9506 - val_loss: 0.1209 - val_acc: 0.9634\n",
      "Epoch 77/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9514\n",
      "Epoch 00077: val_loss did not improve from 0.11558\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.1521 - acc: 0.9514 - val_loss: 0.1169 - val_acc: 0.9655\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1485 - acc: 0.9524\n",
      "Epoch 00078: val_loss improved from 0.11558 to 0.11127, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/078-0.1113.hdf5\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1485 - acc: 0.9524 - val_loss: 0.1113 - val_acc: 0.9667\n",
      "Epoch 79/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1534 - acc: 0.9497\n",
      "Epoch 00079: val_loss did not improve from 0.11127\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.1535 - acc: 0.9497 - val_loss: 0.1244 - val_acc: 0.9611\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9529\n",
      "Epoch 00080: val_loss did not improve from 0.11127\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1473 - acc: 0.9529 - val_loss: 0.1290 - val_acc: 0.9620\n",
      "Epoch 81/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9521\n",
      "Epoch 00081: val_loss did not improve from 0.11127\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1479 - acc: 0.9521 - val_loss: 0.1169 - val_acc: 0.9655\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9530\n",
      "Epoch 00082: val_loss did not improve from 0.11127\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.1459 - acc: 0.9530 - val_loss: 0.1162 - val_acc: 0.9641\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1436 - acc: 0.9529\n",
      "Epoch 00083: val_loss improved from 0.11127 to 0.10895, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv_checkpoint/083-0.1089.hdf5\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.1436 - acc: 0.9529 - val_loss: 0.1089 - val_acc: 0.9660\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9532\n",
      "Epoch 00084: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1431 - acc: 0.9532 - val_loss: 0.1179 - val_acc: 0.9641\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9545\n",
      "Epoch 00085: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1406 - acc: 0.9545 - val_loss: 0.1126 - val_acc: 0.9648\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1391 - acc: 0.9535\n",
      "Epoch 00086: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1391 - acc: 0.9535 - val_loss: 0.1161 - val_acc: 0.9627\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9551\n",
      "Epoch 00087: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1387 - acc: 0.9551 - val_loss: 0.1221 - val_acc: 0.9641\n",
      "Epoch 88/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9539\n",
      "Epoch 00088: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.1386 - acc: 0.9538 - val_loss: 0.1143 - val_acc: 0.9632\n",
      "Epoch 89/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9569\n",
      "Epoch 00089: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 26s 694us/sample - loss: 0.1345 - acc: 0.9569 - val_loss: 0.1309 - val_acc: 0.9620\n",
      "Epoch 90/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9558\n",
      "Epoch 00090: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.1340 - acc: 0.9559 - val_loss: 0.1220 - val_acc: 0.9625\n",
      "Epoch 91/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1322 - acc: 0.9564\n",
      "Epoch 00091: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.1323 - acc: 0.9563 - val_loss: 0.1124 - val_acc: 0.9651\n",
      "Epoch 92/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9562\n",
      "Epoch 00092: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.1341 - acc: 0.9561 - val_loss: 0.1111 - val_acc: 0.9660\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9575\n",
      "Epoch 00093: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1321 - acc: 0.9575 - val_loss: 0.1239 - val_acc: 0.9613\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9573\n",
      "Epoch 00094: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1333 - acc: 0.9573 - val_loss: 0.1161 - val_acc: 0.9646\n",
      "Epoch 95/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9577\n",
      "Epoch 00095: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.1294 - acc: 0.9577 - val_loss: 0.1170 - val_acc: 0.9651\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9582\n",
      "Epoch 00096: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 691us/sample - loss: 0.1302 - acc: 0.9582 - val_loss: 0.1194 - val_acc: 0.9616\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9586\n",
      "Epoch 00097: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.1272 - acc: 0.9586 - val_loss: 0.1173 - val_acc: 0.9639\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9580\n",
      "Epoch 00098: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.1287 - acc: 0.9580 - val_loss: 0.1124 - val_acc: 0.9655\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9592\n",
      "Epoch 00099: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1261 - acc: 0.9592 - val_loss: 0.1223 - val_acc: 0.9641\n",
      "Epoch 100/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9588\n",
      "Epoch 00100: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.1255 - acc: 0.9588 - val_loss: 0.1128 - val_acc: 0.9653\n",
      "Epoch 101/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9601\n",
      "Epoch 00101: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 674us/sample - loss: 0.1237 - acc: 0.9601 - val_loss: 0.1117 - val_acc: 0.9665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9594\n",
      "Epoch 00102: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 691us/sample - loss: 0.1254 - acc: 0.9594 - val_loss: 0.1203 - val_acc: 0.9609\n",
      "Epoch 103/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9599\n",
      "Epoch 00103: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 693us/sample - loss: 0.1204 - acc: 0.9600 - val_loss: 0.1238 - val_acc: 0.9627\n",
      "Epoch 104/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9595\n",
      "Epoch 00104: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1236 - acc: 0.9595 - val_loss: 0.1183 - val_acc: 0.9641\n",
      "Epoch 105/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9606\n",
      "Epoch 00105: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 693us/sample - loss: 0.1195 - acc: 0.9606 - val_loss: 0.1227 - val_acc: 0.9634\n",
      "Epoch 106/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9603\n",
      "Epoch 00106: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.1204 - acc: 0.9602 - val_loss: 0.1136 - val_acc: 0.9648\n",
      "Epoch 107/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9622\n",
      "Epoch 00107: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1146 - acc: 0.9623 - val_loss: 0.1216 - val_acc: 0.9627\n",
      "Epoch 108/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9626\n",
      "Epoch 00108: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 672us/sample - loss: 0.1157 - acc: 0.9625 - val_loss: 0.1211 - val_acc: 0.9655\n",
      "Epoch 109/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9614\n",
      "Epoch 00109: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1166 - acc: 0.9614 - val_loss: 0.1182 - val_acc: 0.9625\n",
      "Epoch 110/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9632\n",
      "Epoch 00110: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.1134 - acc: 0.9631 - val_loss: 0.1204 - val_acc: 0.9641\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9622\n",
      "Epoch 00111: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.1137 - acc: 0.9622 - val_loss: 0.1180 - val_acc: 0.9651\n",
      "Epoch 112/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9622\n",
      "Epoch 00112: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.1140 - acc: 0.9622 - val_loss: 0.1192 - val_acc: 0.9646\n",
      "Epoch 113/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9638\n",
      "Epoch 00113: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1102 - acc: 0.9637 - val_loss: 0.1185 - val_acc: 0.9644\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9636\n",
      "Epoch 00114: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 0.1105 - acc: 0.9636 - val_loss: 0.1217 - val_acc: 0.9644\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9640\n",
      "Epoch 00115: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 669us/sample - loss: 0.1091 - acc: 0.9640 - val_loss: 0.1156 - val_acc: 0.9639\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9644\n",
      "Epoch 00116: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.1102 - acc: 0.9644 - val_loss: 0.1191 - val_acc: 0.9651\n",
      "Epoch 117/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9634\n",
      "Epoch 00117: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1120 - acc: 0.9633 - val_loss: 0.1232 - val_acc: 0.9632\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9642\n",
      "Epoch 00118: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.1091 - acc: 0.9642 - val_loss: 0.1138 - val_acc: 0.9644\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9645\n",
      "Epoch 00119: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.1061 - acc: 0.9645 - val_loss: 0.1277 - val_acc: 0.9630\n",
      "Epoch 120/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9641\n",
      "Epoch 00120: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 26s 693us/sample - loss: 0.1082 - acc: 0.9641 - val_loss: 0.1217 - val_acc: 0.9623\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9641\n",
      "Epoch 00121: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.1076 - acc: 0.9641 - val_loss: 0.1195 - val_acc: 0.9651\n",
      "Epoch 122/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9653\n",
      "Epoch 00122: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 676us/sample - loss: 0.1048 - acc: 0.9653 - val_loss: 0.1250 - val_acc: 0.9648\n",
      "Epoch 123/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9645\n",
      "Epoch 00123: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1055 - acc: 0.9645 - val_loss: 0.1267 - val_acc: 0.9646\n",
      "Epoch 124/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9667\n",
      "Epoch 00124: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.1013 - acc: 0.9667 - val_loss: 0.1252 - val_acc: 0.9639\n",
      "Epoch 125/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9655\n",
      "Epoch 00125: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1019 - acc: 0.9656 - val_loss: 0.1237 - val_acc: 0.9644\n",
      "Epoch 126/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9668\n",
      "Epoch 00126: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.0993 - acc: 0.9668 - val_loss: 0.1190 - val_acc: 0.9653\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9663\n",
      "Epoch 00127: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 26s 694us/sample - loss: 0.1022 - acc: 0.9663 - val_loss: 0.1266 - val_acc: 0.9627\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9665\n",
      "Epoch 00128: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.1005 - acc: 0.9665 - val_loss: 0.1188 - val_acc: 0.9658\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9680\n",
      "Epoch 00129: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 677us/sample - loss: 0.0968 - acc: 0.9680 - val_loss: 0.1202 - val_acc: 0.9648\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9664\n",
      "Epoch 00130: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.1019 - acc: 0.9664 - val_loss: 0.1299 - val_acc: 0.9641\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9676\n",
      "Epoch 00131: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.1010 - acc: 0.9676 - val_loss: 0.1203 - val_acc: 0.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9679\n",
      "Epoch 00132: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.0975 - acc: 0.9679 - val_loss: 0.1182 - val_acc: 0.9646\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9685\n",
      "Epoch 00133: val_loss did not improve from 0.10895\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0971 - acc: 0.9685 - val_loss: 0.1285 - val_acc: 0.9634\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XmcHFW58PHf03vPvmayZyYQsu8JBCJh00ACRhAhKIig4qvXjcuVFwRfBVdQVEREbkQUlMtyWWSVIJgQEIIkISEJCWTPZJ0lMz1b733eP07PZDKZmUyS6VnSz/fzqU93V1VXPV0zXU+fc+qcEmMMSimlFICjtwNQSinVd2hSUEop1UKTglJKqRaaFJRSSrXQpKCUUqqFJgWllFItNCkopZRqoUlBKaVUC00KSimlWrh6O4CjVVRUZEpLS3s7DKWU6ldWrlxZZYwpPtJ6/S4plJaWsmLFit4OQyml+hUR2dGV9VJWfSQiw0RkiYh8ICLrReTb7axztogERGR1cvp+quJRSil1ZKksKcSA/zLGrBKRbGCliPzDGPNBm/XeMMZclMI4lFJKdVHKSgrGmL3GmFXJ5/XABmBIqvanlFLq+PVIm4KIlAJTgXfaWXy6iKwB9gDfMcasb+f9XwG+AjB8+PDDNhCNRtm1axehUKgbo04vPp+PoUOH4na7ezsUpVQvSnlSEJEs4CngemNMXZvFq4ARxpgGEZkP/A0Y1XYbxphFwCKAGTNmHHYDiF27dpGdnU1paSki0u2f4URnjKG6uppdu3ZRVlbW2+EopXpRSvspiIgbmxAeMcY83Xa5MabOGNOQfP4S4BaRoqPdTygUorCwUBPCMRIRCgsLtaSllErp1UcC/BHYYIz5VQfrDEyuh4icmoyn+hj3d6yhKvT4KaWsVFYfzQY+D6wVkdXJebcAwwGMMfcDnwG+JiIxIAhcYVJ0f9B4PEgsdgC3ewAOh9abK6VUe1J59dGbxhgxxkwyxkxJTi8ZY+5PJgSMMfcaY8YbYyYbY2YZY95KVTyJRIhIZC/GRLt927W1tdx3333H9N758+dTW1vb5fVvu+027rrrrmPal1JKHUnajH0k0vxRE92+7c6SQiwW6/S9L730Enl5ed0ek1JKHYu0SQrNH9WY7k8KN998M1u2bGHKlCnceOONLF26lDPPPJMFCxYwbtw4AC6++GKmT5/O+PHjWbRoUct7S0tLqaqqYvv27YwdO5brrruO8ePHM3fuXILBYKf7Xb16NbNmzWLSpElccskl1NTUAHDPPfcwbtw4Jk2axBVXXAHA66+/zpQpU5gyZQpTp06lvr6+24+DUqr/63djHx3Jpk3X09Cwup0lceLxJhwOPyJH97GzsqYwatTdHS6/4447WLduHatX2/0uXbqUVatWsW7dupZLPB988EEKCgoIBoPMnDmTSy+9lMLCwjaxb+LRRx/lD3/4A5dffjlPPfUUV111VYf7vfrqq/ntb3/LWWedxfe//31uv/127r77bu644w62bduG1+ttqZq66667+N3vfsfs2bNpaGjA5/Md1TFQSqWHNCop9OzVNaeeeuoh1/zfc889TJ48mVmzZlFeXs6mTZsOe09ZWRlTpkwBYPr06Wzfvr3D7QcCAWpraznrrLMA+MIXvsCyZcsAmDRpEldeeSV//etfcblsApw9ezY33HAD99xzD7W1tS3zlVKqtRPuzNDRL/pEIkxj41p8vlLc7qPuCnHUMjMzW54vXbqUV199lbfffpuMjAzOPvvsdvsEeL3eludOp/OI1UcdefHFF1m2bBnPP/88P/nJT1i7di0333wzF154IS+99BKzZ89m8eLFjBkz5pi2r5Q6caVRSSF1bQrZ2dmd1tEHAgHy8/PJyMhg48aNLF++/Lj3mZubS35+Pm+88QYAf/nLXzjrrLNIJBKUl5dzzjnncOeddxIIBGhoaGDLli1MnDiRm266iZkzZ7Jx48bjjkEpdeI54UoKHUnl1UeFhYXMnj2bCRMmMG/ePC688MJDll9wwQXcf//9jB07ltGjRzNr1qxu2e9DDz3EV7/6VZqamhg5ciR/+tOfiMfjXHXVVQQCAYwxfOtb3yIvL4//9//+H0uWLMHhcDB+/HjmzZvXLTEopU4skqK+YikzY8YM0/YmOxs2bGDs2LGdvs+YBA0Nq/B4BuP1Dk5liP1WV46jUqp/EpGVxpgZR1ovbaqPbElBSEVJQSmlThRpkxQsR0raFJRS6kSRVknBlhY0KSilVEfSKiloSUEppTqXVklBSwpKKdW5tEoKWlJQSqnOpVVS6EslhaysrKOar5RSPSGtkoKWFJRSqnNplRRSVVK4+eab+d3vftfyuvlGOA0NDZx33nlMmzaNiRMn8uyzz3Z5m8YYbrzxRiZMmMDEiRN5/PHHAdi7dy9z5sxhypQpTJgwgTfeeIN4PM4111zTsu6vf/3rbv+MSqn0cOINc3H99bC6vaGzwZMIgYmDM7Pd5R2aMgXu7njo7IULF3L99dfz9a9/HYAnnniCxYsX4/P5eOaZZ8jJyaGqqopZs2axYMGCLt0P+emnn2b16tWsWbOGqqoqZs6cyZw5c/if//kfzj//fG699Vbi8ThNTU2sXr2a3bt3s27dOoCjupObUkq1duIlhU4IYOj+YT2mTp1KRUUFe/bsobKykvz8fIYNG0Y0GuWWW25h2bJlOBwOdu/ezf79+xk4cOARt/nmm2/y2c9+FqfTSUlJCWeddRbvvvsuM2fO5Itf/CLRaJSLL76YKVOmMHLkSLZu3co3v/lNLrzwQubOndvtn1EplR5OvKTQyS/6SKicaLSS7Oxp3b7byy67jCeffJJ9+/axcOFCAB555BEqKytZuXIlbreb0tLSdofMPhpz5sxh2bJlvPjii1xzzTXccMMNXH311axZs4bFixdz//3388QTT/Dggw92x8dSSqWZtGxTSMUggAsXLuSxxx7jySef5LLLLgPskNkDBgzA7XazZMkSduzY0eXtnXnmmTz++OPE43EqKytZtmwZp556Kjt27KCkpITrrruOL3/5y6xatYqqqioSiQSXXnopP/7xj1m1alW3fz6lVHo48UoKnWrOgYbuvhPb+PHjqa+vZ8iQIQwaNAiAK6+8kk9+8pNMnDiRGTNmHNVNbS655BLefvttJk+ejIjw85//nIEDB/LQQw/xi1/8ArfbTVZWFg8//DC7d+/m2muvJZGwjeg/+9nPuvWzKaXSR9oMnQ0QiewnHC4nM3MKDkea5cMu0KGzlTpx6dDZ7UrdjXaUUupEkFZJofnua9qBTSml2pdWSUFLCkop1bm0SgpaUlBKqc6lVVLQkoJSSnUurZKClhSUUqpzaZUUUlVSqK2t5b777jum986fP1/HKlJK9RlplRRSVVLoLCnEYrFO3/vSSy+Rl5fXrfEopdSxSqukkKqSws0338yWLVuYMmUKN954I0uXLuXMM89kwYIFjBs3DoCLL76Y6dOnM378eBYtWtTy3tLSUqqqqti+fTtjx47luuuuY/z48cydO5dgMHjYvp5//nlOO+00pk6dysc//nH2798PQENDA9deey0TJ05k0qRJPPXUUwC8/PLLTJs2jcmTJ3Peeed16+dWSp14TrhuvZ2MnA24iMdHI+LFcRTp8AgjZ3PHHXewbt06Vid3vHTpUlatWsW6desoKysD4MEHH6SgoIBgMMjMmTO59NJLKSwsPGQ7mzZt4tFHH+UPf/gDl19+OU899RRXXXXVIet87GMfY/ny5YgIDzzwAD//+c/55S9/yY9+9CNyc3NZu3YtADU1NVRWVnLdddexbNkyysrKOHDgQNc/tFIqLaUsKYjIMOBhoAQ72NAiY8xv2qwjwG+A+UATcI0xpgdGc0v90B6nnnpqS0IAuOeee3jmmWcAKC8vZ9OmTYclhbKyMqZMmQLA9OnT2b59+2Hb3bVrFwsXLmTv3r1EIpGWfbz66qs89thjLevl5+fz/PPPM2fOnJZ1CgoKuvUzKqVOPKksKcSA/zLGrBKRbGCliPzDGPNBq3XmAaOS02nA75OPx6yzX/Qg1Nd/hNtdgs839Hh2c0SZmQdv5LN06VJeffVV3n77bTIyMjj77LPbHULb6/W2PHc6ne1WH33zm9/khhtuYMGCBSxdupTbbrstJfErpdJTytoUjDF7m3/1G2PqgQ3AkDarfQp42FjLgTwRGZSqmKzuvyVndnY29fX1HS4PBALk5+eTkZHBxo0bWb58+THvKxAIMGSIPYwPPfRQy/xPfOITh9wStKamhlmzZrFs2TK2bdsGoNVHSqkj6pGGZhEpBaYC77RZNAQob/V6F4cnDkTkKyKyQkRWVFZWHmcs3Z8UCgsLmT17NhMmTODGG288bPkFF1xALBZj7Nix3HzzzcyaNeuY93Xbbbdx2WWXMX36dIqKilrmf+9736OmpoYJEyYwefJklixZQnFxMYsWLeLTn/40kydPbrn5j1JKdSTlQ2eLSBbwOvATY8zTbZa9ANxhjHkz+fo14CZjzIrDt2Qdz9DZAA0Na3E6M/H7Rx7dB0kDOnS2UieuPjF0toi4gaeAR9omhKTdwLBWr4cm56Uwpu4vKSil1IkiZUkheWXRH4ENxphfdbDac8DVYs0CAsaYvamKyXLoMBdKKdWBVF59NBv4PLBWRJp7DtwCDAcwxtwPvIS9HHUz9pLUa1MYD6AlBaWU6kzKkkKynaDTGyEb26Dx9VTF0D4HxkR7dpdKKdVPpNkwF1pSUEqpzqRdUtA2BaWU6ljaJYW+UlLIysrq7RCUUuowaZcUtKSglFIdS7uk0FxS6M5OezfffPMhQ0zcdttt3HXXXTQ0NHDeeecxbdo0Jk6cyLPPPnvEbXU0xHZ7Q2B3NFy2UkodqxNv6OyXr2f1vg7HziaRiGBMGKczu8vbnDJwCndf0PFIewsXLuT666/n61+3F1I98cQTLF68GJ/PxzPPPENOTg5VVVXMmjWLBQsWYLtwtK+9IbYTiUS7Q2C3N1y2UkodjxMuKRyJCNhCguEIV8x22dSpU6moqGDPnj1UVlaSn5/PsGHDiEaj3HLLLSxbtgyHw8Hu3bvZv38/AwcO7HBb7Q2xXVlZ2e4Q2O0Nl62UUsfjhEsKnf2iB4hEKgmHd5CZOQmHw9Nt+73ssst48skn2bdvX8vAc4888giVlZWsXLkSt9tNaWlpu0NmN+vqENtKKZUqadqm0P33aV64cCGPPfYYTz75JJdddhlgh7keMGAAbrebJUuWsGPHjk630dEQ2x0Ngd3ecNlKKXU80i4ppOo+zePHj6e+vp4hQ4YwaJC9JcSVV17JihUrmDhxIg8//DBjxozpdBsdDbHd0RDY7Q2XrZRSxyPlQ2d3t+MdOjsWCxAMbsLvH4PLpX0FWtOhs5U6cfWJobP7ptSUFJRS6kSQdkkhVW0KSil1IjhhkkLXq8G0pNCe/laNqJRKjRMiKfh8Pqqrqzs/sdXWwurVSDgGaEmhNWMM1dXV+Hy+3g5FKdXLToh+CkOHDmXXrl1UVlZ2vFJTE1RWYjCETRUuVwKXq5P104zP52Po0KG9HYZSqpedEEnB7Xa39Pbt0JIlMG8e8Vf/zhvOeYwceSfDh//fnglQKaX6iROi+qhLkkNVO5qigJNYLNC78SilVB+UdklBGhpwuwuIxQ70ckBKKdX3pE9SyE6OitrQgMtVQDSqSUEppdpKn6TQfKezlpKCjhOklFJtpV9SqK/XkoJSSnUgfZKCywU+X6uSgiYFpZRqK32SAtjSQkMDLle+lhSUUqod6ZcU6utxuwuIxwMkErHejkgppfqU9EoK2dktVx8BxGK1vRyQUkr1LemVFJLVR253c1LQKiSllGot/ZJC8uojQNsVlFKqjfRKCsnqIy0pKKVU+9IrKbRcfaQlBaWUak96JYXs7GT1UT6A9mpWSqk20isptJQU8gCtPlJKqbbSLylEIjhiCZzOXK0+UkqpNlKWFETkQRGpEJF1HSw/W0QCIrI6OX0/VbG0aDVSqg51oZRSh0vlndf+DNwLPNzJOm8YYy5KYQyHajVSqg6Kp5RSh0tZScEYswzoW2fdw4bP7lvhKaVUb+vtNoXTRWSNiPxdRManfG/N1Uc6fLZSSrWrN5PCKmCEMWYy8Fvgbx2tKCJfEZEVIrKisrLy2PeoJQWllOpUryUFY0ydMaYh+fwlwC0iRR2su8gYM8MYM6O4uPjYd3pIm4IdPtuYxLFvTymlTjC9lhREZKCISPL5qclYqlO601bVR3aoiwTxeH1Kd6mUUv1Jyq4+EpFHgbOBIhHZBfwAcAMYY+4HPgN8TURiQBC4whhjUhUPcNjVRwDRaA0uV25Kd6uUUv1FypKCMeazR1h+L/aS1Z5zSJvCIKC5V3Npj4ahlFJ9VW9ffdSzMjPtow6frZRS7UqvpOBw2MSgw2crpVS70ispgA6frZRSnUi/pHDY8NmaFJRSqln6JYVkScHp9OFw+LWkoJRSraRtUgBwubRXs1JKtZZ+SSFZfQTgduv4R0op1VqXkoKIfFtEcsT6o4isEpG5qQ4uJQ4rKaS2E7VSSvUnXS0pfNEYUwfMBfKBzwN3pCyqVGqVFLzewYTDu3s5IKWU6ju6mhQk+Tgf+IsxZn2ref1Lq+ojn6+UcLgcY+K9HJRSSvUNXU0KK0XkFWxSWCwi2UD/HF60uaRgDD5fKcbECIf39HZUSinVJ3R17KMvAVOArcaYJhEpAK5NXVgplJ0N8TiEw/h8pQCEQtvx+Yb1blxKKdUHdLWkcDrwoTGmVkSuAr4HBFIXVgo1D4pXX39IUlBKKdX1pPB7oElEJgP/BWwBHk5ZVKnUaqRUr3c4oElBKaWadTUpxJL3OvgUcK8x5ndAdurCSqHmG+0kezV7PIM0KSilVFJX2xTqReS72EtRzxQRB8kb5vQ7raqPwF6BpElBKaWsrpYUFgJhbH+FfcBQ4BcpiyqVWlUfgSYFpZRqrUtJIZkIHgFyReQiIGSM6Z9tCq2qj6C5r8JO7auglFJ0fZiLy4F/A5cBlwPviMhnUhlYyrRTfaR9FZRSyupqm8KtwExjTAWAiBQDrwJPpiqwlGmn+gi0r4JSSkHX2xQczQkhqfoo3tu3NFcf1dUB4PONAPSyVKWUgq6XFF4WkcXAo8nXC4GXUhNSivn9kJEBVVUA2ldBKaVa6VJSMMbcKCKXArOTsxYZY55JXVgpVlIC+/cD4HT68XgGalJQSim6XlLAGPMU8FQKY+k5rZICNF+WuqMXA1JKqb6h06QgIvWAaW8RYIwxOSmJKtVKSmDr1paXPl8pdXXv9mJASinVN3TaWGyMyTbG5LQzZffbhADtlhS0r4JSSvXXK4iOV0mJbWiO2yTg843EmCih0M5eDkwppXpX+iaFRKLlCqTMzPEANDau782olFKq16VvUoCWKqSDSWFdb0WklFJ9QnomhQED7GMyKbhcuXi9wzQpKKXSXnomhTYlBYDMzAmaFJRSaU+TQlJm5gSamjaQSMR6KSillOp96ZkUcnPB44GKg8M5ZWZOwJgIweDmXgxMKaV6V8qSgog8KCIVItJunYxY94jIZhF5X0SmpSqWdnZ+WF+FzMwJgDY2K6XSWypLCn8GLuhk+TxgVHL6CvD7FMZyuDZJISNjLCCaFJRSaS1lScEYsww40MkqnwIeNtZyIE9EBqUqnsO0SQpOpx+//2RNCkqptNabbQpDgPJWr3cl5/WMNkkB9AokpZTqFw3NIvIVEVkhIisqKyu7Z6MlJbahOZFomZWZOYFgcBPxeKh79qGUUv1Ml4fOToHdQOv7Xw5NzjuMMWYRsAhgxowZ7Y3aevRKSiAWg5oaKCwEmhubEzQ1bSQ7e0q37Ealn2A0iNPhxOP0HNd2jDHEEjEi8QiReISmaBON0UYK/YUUZhQetn4oFiJhEvhdfgCaok3UR+rJ9mST4c5ARDDGfn1E5KhiSZgEjZFGgrEgboebfH9+u7E6xIHT4Ww3tmg8SqYnE4c4SJgEwWiQxmgjjZFG8nx5h22zs+PSOv5oPErcxPG5fO3GHY1HcTqcOMXZ6edu/gwuhyt5rOxvxuYpHj/0dSxmCMUikHBgjGASDkxCMEYOWz8ajxOKhnHjb1keiUUJhAO48OLEi8O4SSSk032OGgUTJnTpMB2z3kwKzwHfEJHHgNOAgDFmb4/tvXVfhUOSAjQ2vp82SSEUCxGMBoklYhT4C1q+0I2RRv5V/i8GZQ3ilMJTiCaibKvZRkVjBU3RpnYnl8PFwKyB5PnyaIw2EowGOangJKYPmk6eL49wPMz+hv2sr1zPR9UfEU/EW76sToeTSDxCZWMltaFacn25FPgLqAnWsD2wncrGSsLxMPFEHL/bT4Y7o+Xk4na4yfXmkuWx9982GIwxGAxuh5tMTya53lwGZg0k35/P7rrdbK3ZSiAcIBKPEE1EicQjJEyCXG8uud5cyuvKeX//+zRGGxmeO5yBWQOJJWKEYiHCsTChWKjlJJ0wCUoyS8j357O1ZiubqjfhEAcnF5zM4OzBNEQaqAvXtUw+l4+ijCIy3BktJ/yOJtPuyPVQmlfK6MLRROIRGqON7AzsZF/DPgCc4sQhDqKJaMv6HqcHQQjHw7gcLgp8hWR7cgjGmmiI2PuVux1unOKGhBsxbtzixuV0Uhc9QG20ggQHRxHOdZZQ4j6ZhvgBqmM7CZtGABy4yJNh5MhgQqaeJnOAINVECdo3GsGFl5gcXhrPjZ9EQWI0ERoJEyAstYQlgCGB03gxQMxRT9wRxBXLwRkpJO5oIuatADE4w4U4QwMwjjAJVwMJVwPG3XToToyAcYBxQsJ58DkG3E3giEPMC8F8QMDdCI4YxPwQzUhOfvAFIHsPuMLtf7ESDvt+47Dbdib7P8U80DAQnFHI2gfS6u9rxO7bOEASrSZj9xnNZM7Kb/H6j29pf5/dJGVJQUQeBc4GikRkF/ADwA1gjLkfezvP+cBmoAm4NlWxtKt1Uhg3DoCMjNE4nbkEAm8ycODVPRpOa8YYdgR2sK1m22En3gPBA1Q0VtAQaUBEEKTl109duI7qYDVVTVVUNVURjUeZPXw255aeS2leKbm+XCobK3l///us2b+GNfvXsLXm4H0l8n35zD1pLtmebB5f/zj1kXoABOnw5NRVLoeLWBc6BjrFSa4vl0AoQNzEcYqT4bnDKckqwev04nV5aYw0UtFo+5g4xEE4FiYQDtAYsScmEcEhDgRpOWkmTOKQ/XicHvJ9+bidbjwOD05xIzioCweoDddQkjGYcYUT8Ttz2H5gJysqN+J2evA6vTgSPkwsF2diIEWOTEQcBBoq2BWvIMdMZHb0c8SJUl3xAZsq9+OlEK+UMUhyKSObcDhEQ10VNYkmiHsxMQ8m5sEV8+BOeMjBgyQ8xCMeYuGDU7Qpg2hjJo68PdQMX8Gb2VuJBn1EGnOR+nm4G8qQhIeEq564iSPBfEwoG7z1RPzJaz7iHmKOGBX+aip8AYhkQiQrefCj4Ii2eYxBUyE0ltgTZcwHrhCB4g8IFGyG4BgIzIVQHiRcJNxNHMjbzoGsvRAZAU3TIFgIwQKIu8Fbj/EGkUgGJpyJy2Tid2ZiMvfRVPQu9dlbkWgOzugwHJEJuGO5OHAhrjCIwRfJhpgfd3YAV3Y1HsnAVzMYJ27Cnt2EXRW4En7c4SzcoSw8JssmOonbE6wjbp87kq8ljpE4IuCJZ+JO+IhJA6HMAyDglUyc4iLuCxGVJmI0EaUJv2MCeY7BZDhz7UlbEogYDAnEYV+DPaGLA7wOH26Hh8ZEDYH4Plziotg7jBx3IQkiRAkRM2GiJmQTnMORLHU5EIFIIkgo0cgFJ48+ru9hV6QsKRhjPnuE5Qb4eqr2f0Tt9GoWcZKXN4fa2iUp221TtInXtr7GhqoNVDdVs7t+NxuqNrD5wGY8Tg+53lwqmyqpC9d1uI0cbw7ZnmzA/ipOmATGGHK8ORRlFDEsZxhTB04lbuIs3b6Upzc8fcj7BWFU4SimDZrG1ZOuJteXi1OcvLfvPf6++e8EQgEuG38ZV4y/gtpQLRurNuJz+SjLL2Nw9mAy3ZlkuDMOmfxuP5F4hP0N+6kN1ZLpycTr9LKxaiMr9qxoqcbI9xVycu44SrPGYGIegqE4TeE4wVCMeNSNN5FPNOIgFDLUBOuQaCaxiItwGMJB7GMHUyTS/vxQ2BCMN9Ak+wk5qonXDiZaPYRA2EE4DKadfLcjOR2t3YDbDU7nocX+Vk1XiNhbhft89rH5uc9nl8Vi4HBAZqa9nXhGBmTkQ8YQu24wCHv3QuNWGDoUhgy1223+LC6X3X/zo8Nx+CTS/rzsbBg2DIqK7PEMBu18l+vw7XZ1XjwO0ajdTmam3RfYWI+yFkv1gN6sPupd7SQFgLy8c6iufp5QaBc+39Cj2mQsEePFj15kZ2AnoViIXXW7WL1/NVtrtpLnyyPLk8XqfasJxWzR2eP0MDBrIGOKxnDG0DOImziBcIA8bx6TSiYxqnAUWZ6sgydel598f367dacdMcawM7CT/Y37CYQC5HhzmDBgApmezHbXT5iErVcVD/X1EAjARLFfXq8XqvbCW+/Cxo32S998YvP5oLHRx/btI6ioGIHfb09mdXXDqKz8BFVVUFkJ9fVdjVyA3E7X8HhsTJ1NWVlQWCh4vdl4PNl4vScf8T0ejz2JRyL2+aBBtoax+SSZm2v/ffz+g3W+rU/szsOr1JN/C7tu8wk4nfj9h89Lt2PQX6RvUsjPt9/ew5LC2QAEAq/j8115xM0YY9has5UXPnqBu9+5m+2121uWZbozmTxwMueWnUt9uJ6aUA3/Z/r/4aJTLuK0IaeR5ck66ga/o9HUBHv2CHv3jqCmZgSBAHwYgNfq7Mm+7VRXB4GAg0DAJoT2fkE3y02er4NBe7IEe7IbNsyeMPfts/vPzobiYttAVlwMeXn2xHmkE3NXTtz97aQi0nHCUKqvSN+k4HDYIbTbJIWsrEm4XHnU1i6lpKT9pLB632pe2fIKb5W/xVvlb1HZZC+TPWPYGdx9/t3MHj4bn8vX0hjanUIh+PBD2LHDnsj374f33oM1a+zJOSPDViPs3WuXd8TrhZwce3JvnkpKDp9g1RdVAAAgAElEQVSXm2tP7CJ2u9nZMGMGDBly8KScSNhlbrctPSil+q/0/gq304FNxElu7hxqag5vV1i+azm3v347L29+GYBRBaOYN2oeZww9g48N/xjjB4w/7pCqq23VzIcfwrZtNrzW086dh9ZPg61XnjrV1tc2NdmT8yc+AYMH22ngQCgoOPRE7/Ued6gtHI72qweUUv1PeieFwYNh9+FdI/Lyzqa6+jlCoXJ8vmG8Vf4Wt79+O69seYVCfyE/PfenfGnalxiQOeCYdx2NwooV8M47sGHDwSl5h1DAnmyLimzuKimBk0+Gz38exo+HkSPtib6gwNaEKaVUd0jvpDB6NCxZcrD1Lykv7xwAtu17kdtXLOXx9Y9TnFHMzz/+c74282st18MfjQ8/hCeftCf+bdtsdU+jvYKSggIYOxYuvtg+jhljQxsxQqtjlFI9K71POePG2ZbSHTugrKxldlbWJFbXZfGzJ/6LA+EIPzz7h9xw+g0dXrHTnkQCVq2Cv/8dnn0WVq60dfDDh0NpKVx7LZx1FnzsY7Z6Ryml+oL0Tgpjx9rHDRtakkIwGuS7r32X37zXwIgMJ29/8S1mDDm1S5sLheD55+20ePHBe/jMnAm//CVccYWtsVJKqb5KkwLABx/A/PmUB8qZ98g81leu58sTL+QzuS9S5uts9G9r+3a46y545BGorbXVQeefD/Pm2ccBx970oJRSPSq9k0JBgW3B3bCBnYGdnPPQOVQ1VfHylS/ziZFn869/lVBR8SiFhe3fK6i2Fn76U7jnHvv60ktttdA55+j16Eqp/im9kwLAuHHs2bK6JSG8ctUrnDb0NACKiz9NZeWTxOP/jdN5sBdxJAK//z388Id2kNWrr4Yf/ch23FJKqf6sX9xPIaXGjuV7xWvZU7+Hf3z+Hy0JAWDAgM8Sj9dz4MDfW+a9/TZMmgTXXw/TptnG5D//WROCUurEkPZJYecpJfxlbJTrRn+OU9s0KOflnYPbXUxFxaPEYnDLLfZqoWAQXnoJXnkFpqTHCNtKqTSR9knhlxmrAfiO/7zDljkcLoqLL2P37te4+OIYP/sZXHMNrF1rG5H729g7Sil1JGndplDZWMkf9v+dq96H4cXV7a7jdn+eG264kg8+cHLfffC1r/VwkEop1YPSuqTwm3d+Qyge5qb3s21fhTaqq+GSS07jo4+mc9ddd2hCUEqd8NI2KRhjeGTtI8wbNY8xAyfYvgqtVFfDeefBxo3CokUPM336D4hGj9xnQSml+rO0TQofVH7A9trtXDz6YjvcRauSQiQC8+fb0Uqfew4uvXQaxkSprHy6ky0qpVT/l7ZJ4YWPXgBg/qj5NilUVLSMS3HrrfDvf9seynPnQlbWNPz+UVRUPNabISulVMqlb1LY9ALTBk1jSM4QOP10O3PZMhYvtkNWfO1rtocy2BvBDxhwBbW1SwiH9/Ve0EoplWJpmRSqm6p5q/wtLhp1kZ0xYwZkZlK7+B2uvhomTLAD2LU2YMDngAR79/53j8erlFI9JS2TwsubXyZhElx0SjIpuN3wsY/x67+VUVEBDz98+J3EMjPHUFi4gF27fkMs1uW7zyulVL+SlknhhU0vUJJZwvTB01vmHThtHr+uuorPfDLE1Kntv2/EiFuJxWrYs+f+HopUKaV6VtolhXgizsubX+bCURfikIMf/5c7PkMDWfxgztIO35uTcyr5+XMpL/8l8XiwB6JVSqmelXZJYdOBTdSGapkzYk7LvKoq+M2Tg1noeooJW5/r9P0jRtxKNLqfvXsfSHWoSinV49IuKby//30AJg+c3DLv97+Hxkbh+6e/au/Z3Im8vDnk5Z3Njh0/1rYFpdQJJ+2Swpp9a3CKk7FF9q5rxtihr889F8Z+8mTbY21f55edjhx5J9FoBeXld/VAxEop1XPSLim8X/E+Y4rG4HV5AXjzTdi61Y5+ytln25WOUFrIyTmV4uKFlJffRTi8J6XxKqVUT0q7pLBm35pDqo7+/GfIyoJPfxp715ziYnj++SNuZ+TIn2JMlO3bf5C6YJVSqoelVVKoCdZQXlfOpAGTAGhshCeegMsvh8xM7I2VP/lJePFFOwBSJ/z+kQwZ8g327v0jdXXv9ED0SimVemmVFNZWrAUONjI//TQ0NCSrjppdfDHU1cHrrx9xe6Wlt+P1DuHDD68jkYimIGKllOpZaZUU1uxbA8CkEltSeOwxKCuzt9hs8fGPQ0YG/O1vR9yey5XNqFG/o7FxrTY6K6VOCGmVFN7f/z6F/kIGZQ3CGFi+3F51dMhtNf1+OP98ePZZe2nSERQVLaCo6FK2b7+dhoY1qQteKaV6QEqTgohcICIfishmEbm5neXXiEiliKxOTl9OZTxr9ttGZhFh+3Y4cMCOhXeYiy+G3bth5coubXfUqN/idhfx/vvzCIV2dGvMSinVk1KWFETECfwOmAeMAz4rIuPaWfVxY8yU5JSybsLxRJx1FetaGplXrLDz200KF15oG52feaZL2/Z6BzFp0sskEkHWrDmfSKSqm6JWSqmelcqSwqnAZmPMVmNMBHgM+FQK99epLTVbCMaCLY3MK1aAxwMTJ7azcmEhfOIT8Ic/2EbnLsjKmsCECc8SCm3nvfdm09i4sRujV0qpnpHKpDAEKG/1eldyXluXisj7IvKkiAxLVTBtG5lXrIBJk8Dr7eANP/oRVFbCL37R5X3k5c1h8uR/EIvVsGrVaVRX//14w1ZKqR7V2w3NzwOlxphJwD+Ah9pbSUS+IiIrRGRFZWXlMe1o9vDZ/PWSvzKueByJhG0uaLfqqNmMGbBwIfzqV7Cn672W8/LOZPr0Ffj9I1m37lMcOPDKMcWrlFK9IZVJYTfQ+pf/0OS8FsaYamNMOPnyAWA67TDGLDLGzDDGzCguLj6mYAZnD+bKSVfic/nYsgUCgSMkBYCf/ASiUbjttqPal883nMmTl5CRMY516y4hEFh+TDErpVRPS2VSeBcYJSJlIuIBrgAOGZdaRAa1erkA2JDCeFp02sjc2kkn2Zs1//GPsOHoQnO785g06WU8nkGsXTuf+vpVxxasUkr1oJQlBWNMDPgGsBh7sn/CGLNeRH4oIguSq31LRNaLyBrgW8A1qYqntRUrwOeDce1dC9XW975nB0f67nePej9e70AmT34VpzObNWvOo65uxdEHq5RSPUhMFzpo9SUzZswwK1Yc38n1rLPs0EZvv93FN/z0p3DrrfDGG226P3dNMLidNWvOIRqtYdy4RyksnHfU21BKqeMhIiuNMUeqH+n1huYel0jAqlUwc+ZRvOn662HwYLjxxi71cm7L7y9lypTX8XqHsHbtfNat+wyh0K6j3o5SSqVa2iWF/fvtIHhjxhzFmzIy4Ic/tONi/PWvx7Rfn284M2asoqzsJxw48CL//vcYyst/qQPpKaX6lLRLCjt32sfhw4/yjddcA7Nnwze/CbuO7Ve+w+FlxIhbmDnzA/Lzz2HLlu+wcuV0HXpbKdVnpF1SKE92pzvqpOB02jvyRKPwpS8dUzVSM7+/jIkTn2fChL8lO7qdzqZN3yISqTjmbSqlVHdIu6TQXFIYdix9p08+Ge66C155Be6//7hjKSr6FDNnfsCQIV9n9+57efvtIaxb92lqapYe97aVUupYpF1SKC+3V5jm5R3jBr76VZg7F77zHdi8+bjjsfdk+C0zZ65nyJBvEwi8yZo157BmzVwCgbfpb1eHKaX6t7RLCjt32lLCIfdQOBoitjObxwNf+ALE490SV2bmWE4++S5mzdrJSSf9ioaG93jvvTP497/Hsn377VRWPkN9/XvaMK2USqm0Swrl5cfQntDW0KFw773w1ltHNWBeVzidPoYN+09OO20rp5yyCI9nINu338b69Z9m5cppvPvuOKqrX+zWfSqlVLO0SwrNJYXj9rnPwWc+Yzu1/elP3bDBQ7lc2QwefB1Tpy5l9uwDTJ++kjFj/gI4Wbv2IlavPo+Kiv8lkQgfcVtKKdVVrt4OoCeFw7afQrckBRF7NVIgAF/8IjQ1wde/3g0bPpzbnY/bnU929jQGDLic3bvvZdeuX/PBB5fjchVSUnIVgwZ9iays9m4OoZRSXZdWSaG5e8FxVx81y8yE55+3Q2x/4xv25gxfTukdRXE4PAwbdgNDh36bmppX2bv3j+zZcx+7d/8GlysPn6+UrKyplJRcSV7e2dgb4CmlVNekVVJo7qPQLSWFZl4v/O//woIF9sqk4cPt1UkpJuKkoOB8Cgrs7T8rK/+Xxsb1hELbqKx8in37/oTbXUJu7mxyck4jI2MMPl8pfv/JOJ0ZKY9PKdU/pVVSOObezEfidsMTT8CZZ9p2hr/+FebPB1fPHF6Pp4ghQ77W8joeD1Jd/QJVVc9QV/cOVVVPt1pb8PtPJitrKnl5Z5GXdw4ZGadoiUIpBaRZUmguKQwdmoKNZ2fDCy/AnDnwqU/BwIHw+c/by1bHj0/BDjvmdPoZMOAyBgy4DIBo9ADB4BZCoW00NW2goWEtdXVvU1n5BAAiHvz+k/D7R5GRcQp+/ynJ56Pxegd1tiul1AkmrZLCzp1QXAx+f4p2MHQobNwIL74IDz0Ev/61vWR1+nQ7dtJnPwuFhSnaecfc7gLc7gJycg4ODWuMIRTaSm3tGzQ1bSQY/Iimpo84cGAxB2+GBz7fSeTnn0tm5iR8vlIyMyfg95f2+GdQSvWMtLqfwvz59uqjlSu7OaiOVFTAo4/aq5RWr7bVTHfeCf/5nz0UwNEzJk44vIumpo9obFxHbe1SamtfJx4PtKyTlTWFgoJ5iDiJx4M4nRm43YVkZIwlL+8cHA53L34CpVR7uno/hbRKChMmwKhR8Mwz3RxUV6xZAz/4ATz7rL2b2w9/eBzdqnuWMQkikQpCoe3U1f2Lysqnqat7C3DgcPhIJIKA/T9yuQopKJiLvQNrgoyMceTmnkFm5gRcrnykn3xmpU40mhTakZtrq/jvuaebg+qqeNxeofTAA3DaaVBSAiNGwE03wZAhvRTUsUkkYog4ERGMSRCL1RIIvElFxWMEAm8CAiQIhw8OM+5w+PB6h5GRMZbMzHFkZIwjM3McLpetUnO5cnC7C3rnAyl1gutqUkibNoVAAOrquvly1KPldMKiRVBWBi+9BDt2wOLFtnrpBz+AKVNsD7vRo+Gkk3ox0CNzOA7+64g4cLsLKCpaQFHRgkPWi0SqqKtbTjC4iUhkL6HQNhobN3DgwN8x5vBxnDyeQWRmjsfjGYTbXYTbXZx8LGrzOl+vmFIqBdImKRzzfRS6mwjccoudALZssR3fvvOdQ9c79VS48krbMa6kpOfj7CYeTxFFRRcdNj+RiBIMbqap6QNisToAotFqGhvX0tS0gWBwM5FIJYlEYwdbdpCdPZ2CgvPx+cqIRg+QSITweAbg8QzE4xmUnEq0jUOpo5A2SeG47qOQSiedZEsNK1ZAMGgbo//1L3jkEfj2t+GGG+C882DaNNsg0jyVlHS9TeK992DTJqiutqWR009P7WfqAofDTWbmWDIzx3a6XjweJBqtJhqtSk6VRKNVRCJ7qa19nR07fgokOtmCtJQwnM5MnM5sfL4yMjJOwesdhsczAKczBzCIuPH7R+FyZXXnR1WqX0mbpJCZaTsal5X1diTtEIGZBy8X5fTTbclh/XqbHP72N/jnPyEWO7hOdra96c/IkfbDeTy2d7XHA+PGwVVX2c5z3/2uvTFQa//xH/YqqKx2Tn6VlXY8kKlTU/NZj5LT6cfpHIrP137nkmi0llisBre7EIfDRyRSQSSyt9W0j3B4L9FoFYlEI7FYgOrqF9i3b3+H+/T5SgEnsVgNIi78/pF4vSNwufKS7R4D8HoH4/EMbnnURKJOFGnV0NyvxWK2DWLTpoPTRx/ZecEgRCK2PSIUsoPzDRpkG7GXL7dJ4D/+A3JybN+Ju++2fSpuuskO5uf329uLPvqovQd1TY3tX3HDDTZhRSK2BHMCXTkUiwUIh/cQjVYSi9UhIiQSIRobN9DUtB4QXK58EokwodA2wuGdxGJ1xON1JBKhw7bndGbj9Q5Jdvobg4i7ZdtWnHi8gVisHpcrD7+/DJ9vJD5fWfJ5GS5XDmAvCwa0zUR1K736KF0ZA0uWwI9/bO/3cN999sTf2ptvwo032oRRUGATRCRiO96ddppNKH/7mx0ePBCwtx8dPRpuvx0uucQmn8ZG+962iSIet+/Jz7fLqqps9ZjbbTuK5Ob23LFIAWMM8Xg94fAeIpE9hzyGw+UtnQCNieN2F+Fy5QKCiOB0ZuN0ZhOLHSAY3Eo8XnfItl2uAoyJE48HEHHh9Q7D5yvF5xuB1zui5Xk83kBDw2qi0WpycmaSnX0qDocXY6KIeHG783E4MvTyX3UITQrKnug9nvaXGQNvvGHvIhcI2JP5eefZkoKIrXb6+c9ty/wnPwmvvgoffgg+ny2NABQVwaRJthoqGoW9e21iCYVsqWTYMNiwARLJOn+3G2bPtm0iZWVQWmqnvXvh7bdt1dVJJ9kqsYICe8/UiRPbr+Y6FqEQvPOOrarLSN2ggPaXviDS8e1KjDHEYjUEg1sJhbYRCm0lFNqBiBuXKx9jIoRCO5LTdiKRPTT3BWnmcPiTfUQOZ7eTl5zyk1Mebnd+yzynMwcRVzJOByIOXK4CMjJOwecrxeHo4H9H9UuaFNTxO3Dg4C/+WMxWL61aZccK8fnggw9g7VqbfFwuO4THhAm2pLF1K2zfbhvIm0sXTz8Nr79u51dWHrovj8cmmT17Dp3v98OFF9rBBp1Om3yqquzkctn2lObJ47En/sZGm2h27bLzJ02y8x54wL6vqAiuv962m1RX2+1OnWpLTP/8J/zjH7a95nOfgwEDbOzbttkqux07YPJkOOMM+z5jbELtbPBDY+z10JmZxzxIYiIRIRwuJxTagcPhI9M7FueajYRXvUJ08yrC500gNm00iUSIWKyGWKyWaNQ+Nr9u/WhMrP0dGSheCgX/hpppwoHZbky2FxEPDoc7+ehBxI2zUYj5w8QTTbhcBfj9J+PxlJBIhDEmhsczEK/XtgXZUpEDj2cgbndR8oowxyEJCRw4nZlk+EbjCkSgsJBYogmHw43D4bXHsadKP83/045kYq+qssPkn3QSzJhx6I+Kujr74+fAAfvc47E/inJybNtfYaH9nxOx/0vLl9v2v5kz7f8Q2M+2ejU8+aRdf+HCQ/su7dtnB9qcMQPOPvuYPpImBdW3NTTYE+z27fZLMHWq/aIEg3Zeba39Ii5ebIcmr6g4+F6Hw74nHrcn+3A7d58bMMB+qQIBm6AcDju8+aWX2uT20ksdx+b32zicThg82CaXtt+T4mK7bNs2qK+3CaW5lDNypC0d7d5tLzles8YmQREbd0mJja+5hBWJ2Mdo1CbbnBybhPfvt5+vtBROOcVeOTZjhi1V3Xmn/VytnXEGnHOOPY4DBtjnJ59s13/uOXsimz4dk5+P2fohiQ1rkXdX4Vi9DjNyBPFPnAn/ehv30ndJ+N04glESHidNZ5VRP28kwYkFxDPAvbmKwgfWkf3GPiKDMmg8cxiRYiHeWAUNjXhqBFdDgqg/QiQnQXAINJ4E7loo+Qdkfwg1M6DiXGgaAgkfZG6Dojchbw349oEjCrEMaBgFGMgod+CICoE5edSdmkXuJh/Zb9fgrA1iPE4SGW7iA7KI52fgakjgDEQhw0+iKA/jdSGNQSQSw+HNxuHNRSor7SWJ2dn2wo6TToIdOzCbN8PmTbCzHAYPQhZeYU/y995r/2fh4P9FcbFtv/vww8P/P9oqKrL7WLfO/k3BloanT7c/ZPbssf8rTqf9vxaxf+8BA+z/wtKldv5NN8Edd3S+rw5oUlAnjnjc/goD+6XJyzv4Cw7sl6apyZ5cfT57Une2aqStr7eJo6jo4LwPP7QN6kVFNgG89549wZ95pp02bYKHH7YJ4eSTD05Dhhw8ydbW2mqwvDyb4LZutdPevXYfRUW2sX/SJBgzxp4MKirsyb6iwr72eGy1msdjf5mGQvbXpsNhR9r1+21cH3108GQC9lfm9dfbx+JiOwDjvffa/SdaXaLbnODcbnucWn/fHQ5bPTd1qi31vfuuTUg/+Ql85Sv29eOP26Tc/JmaFRfbQR43b7ZVi/X1Nv6sLHsiy8vDBAJQWYEcqGl5mxk6mNip43H98x2k9tA2FZPlJ3LmRELDPATzg/jKI/g3BDAOQ7DUjYk0kfN6Na66KHEv1E6BUAlIHFyN4K0CVx3Esu3kCIPnAEjMJp6Exz53RCGSL4SLwV0v5Kw3uOsM0VwhONgQHALBQZC1xZaYHDGomTuAmmun4Kiqwbt6D559YVyBOLjdRCYOJT6hjFiel3imA48U4o8OwB10Y+oDOCpqcG+qwLl1D/ExpYTPGgfBIN5/rsG5cSeSk4/k5ZOYey4N88ZC9X48T72Oe8VGHDVNSDgCF11kh2MYPfoovjiH0qSgVG9parJJyevtvm0mEjYxrFhhf6Wec07HVSmxmE0kr71mSylnnmlPKg6HraIIBA626bSuBqmutskpO/vwfb/1lk0A9fV2+eWXH3xvPG6TTUdVYxUV8P77NmGfcYaNIxKBZctsCaqx0Sbbc8898jGLRGD9eszo0YQdtsOi0+nH4chI3jxKko3+O5M95p3J4VicLVeShULbSCSiiDgxJkI8Vg8NjUhOAS5XDk5nDk5nNvF4A9HKLcRqdtBYUEMkUoHLlYPLVYiIC2MixGIBIpG9RKOViLgRcRGP13fhD3qQiBuPp4RweA/t9blxu4txOPyIuBg8+KsMH37jUW3/4H40KSilVI+LxQI0NW0kFqtFxAvEiUQqiEYrcLny8XqHIOIiGq0hGt1PMLiNSGQ3Pt9IsrIm43LlkUgEiUYPEArtIBwux5gIxsQoKLiQkpIrjikuHftIKaV6gcuVS07Oab0dxjHr+Jo5pZRSaUeTglJKqRYpTQoicoGIfCgim0Xk5naWe0Xk8eTyd0SkNJXxKKWU6lzKkoLYgVt+B8wDxgGfFZFxbVb7ElBjjDkZ+DVwZ6riUUopdWSpLCmcCmw2xmw1xkSAx4BPtVnnU8BDyedPAueJDtiilFK9JpVJYQhQ3ur1ruS8dtcxtt99AChMYUxKKaU60S8amkXkKyKyQkRWVLYdM0cppVS3SWVS2A20vs/Z0OS8dtcREReQC1S33ZAxZpExZoYxZkZxcXGKwlVKKZXKzmvvAqNEpAx78r8C+FybdZ4DvgC8DXwG+Kc5QhfrlStXVonIjmOMqQioOsb39rb+GrvG3bM07p7Vn+Ie0ZWVUpYUjDExEfkGsBhwAg8aY9aLyA+BFcaY54A/An8Rkc3AAWziONJ2j7moICIrutLNuy/qr7Fr3D1L4+5Z/TXuzqR0mAtjzEvAS23mfb/V8xBwWSpjUEop1XX9oqFZKaVUz0i3pLCotwM4Dv01do27Z2ncPau/xt2hfjd0tlJKqdRJt5KCUkqpTqRNUjjS4Hx9hYgME5ElIvKBiKwXkW8n5xeIyD9EZFPyMb+3Y22PiDhF5D0ReSH5uiw52OHm5OCHnt6OsS0RyRORJ0Vko4hsEJHT+8PxFpH/TP6PrBORR0XE11ePt4g8KCIVIrKu1bx2j7FY9yQ/w/siMq2Pxf2L5P/K+yLyjIjktVr23WTcH4rI+b0T9fFJi6TQxcH5+ooY8F/GmHHALODryVhvBl4zxowCXku+7ou+DWxo9fpO4NfJQQ9rsIMg9jW/AV42xowBJmPj79PHW0SGAN8CZhhjJmAv+76Cvnu8/wxc0GZeR8d4HjAqOX0F+H0PxdieP3N43P8AJhhjJgEfAd8FSH5PrwDGJ99zX/Lc06+kRVKga4Pz9QnGmL3GmFXJ5/XYE9QQDh088CHg4t6JsGMiMhS4EHgg+VqAc7GDHUIfjFtEcoE52D4zGGMixpha+sHxxl5S7k+OBpAB7KWPHm9jzDJsX6TWOjrGnwIeNtZyIE9EBvVMpIdqL25jzCvJsdoAlmNHawAb92PGmLAxZhuwGXvu6VfSJSl0ZXC+Pid5f4mpwDtAiTFmb3LRPqCkl8LqzN3A/+Xg3ccLgdpWX6C+eNzLgErgT8lqrwdEJJM+fryNMbuBu4Cd2GQQAFbS9493ax0d4/70ff0i8Pfk8/4Ud4fSJSn0OyKSBTwFXG+MqWu9LDkUSJ+6bExELgIqjDErezuWo+QCpgG/N8ZMBRppU1XUR493PvaXaRkwGMjk8GqOfqMvHuMjEZFbsdW9j/R2LN0pXZJCVwbn6zNExI1NCI8YY55Ozt7fXIROPlb0VnwdmA0sEJHt2Oq5c7F19XnJ6g3om8d9F7DLGPNO8vWT2CTR14/3x4FtxphKY0wUeBr7N+jrx7u1jo5xn/++isg1wEXAla3Ga+vzcXdFuiSFlsH5kldjXIEdjK/PSdbD/xHYYIz5VatFzYMHknx8tqdj64wx5rvGmKHGmFLs8f2nMeZKYAl2sEPom3HvA8pFZHRy1nnAB/Tx442tNpolIhnJ/5nmuPv08W6jo2P8HHB18iqkWUCgVTVTrxORC7DVpAuMMU2tFj0HXCH2NsNl2Ibyf/dGjMfFGJMWEzAfe6XAFuDW3o6nkzg/hi1Gvw+sTk7zsfXzrwGbgFeBgt6OtZPPcDbwQvL5SOwXYzPwv4C3t+NrJ94pwIrkMf8bkN8fjjdwO7ARWAf8BfD21eMNPIpt+4hiS2df6ugYA4K9WnALsBZ7hVVfinsztu2g+ft5f6v1b03G/SEwr7eP+7FM2qNZKaVUi3SpPlJKKdUFmhSUUkq10KSglFKqhSYFpZRSLTQpKKWUaqFJQakeJCJnN48gq1RfpElBKaVUC00KSrVDRK4SkX+LyGoR+e/kfSIaROTXyXsYvCYixcl1p4jI8lbj6zffF+BkEXlVRNaIyCoROSm5+axW9294JNkjWak+QV0egJAAAAGKSURBVJOCUm2IyFhgITDbGDMFiANXYgedW2GMGQ+8Dvwg+ZaHgZuMHV9/bav5jwC/M8ZMBs7A9owFO/Lt9dh7e4zEjlmkVJ/gOvIqSqWd84DpwLvJH/F+7GBtCfj/7d2xShxRFIfx759GEANWNhbmKezyDim0Ebaw9gmE2OQpYimkEUF7wWJhKysrS6utbESwSIpwLObmYtYisrBriu9XzZy5XOYWd87cGTiX09bmB3De9mNYr6pxi58AZ0k+AptVdQFQVT8BWn/XVTVt5zfAJ2Cy+GFJ/2ZSkF4LcFJVh38Fk6OZdvPWiPn14vg3zkP9R/x8JL12Bewk2YC+l/AWw3z5U4F0D5hU1SPwkORzi4+AcQ275k2TfGl9rCRZXeoopDn4hiLNqKrbJF+ByyQfGCpkHjBswLPdrt0z/HeAoezz9/bQvwP2W3wEHCf51vrYXeIwpLlYJVV6oyRPVbX23vchLZKfjyRJnSsFSVLnSkGS1JkUJEmdSUGS1JkUJEmdSUGS1JkUJEndM9ZHOCWn+SU3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 439us/sample - loss: 0.1657 - acc: 0.9489\n",
      "Loss: 0.16570895418586637 Accuracy: 0.94890964\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3417 - acc: 0.2352\n",
      "Epoch 00001: val_loss improved from inf to 1.51866, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/001-1.5187.hdf5\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 2.3417 - acc: 0.2352 - val_loss: 1.5187 - val_acc: 0.5577\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4928 - acc: 0.5201\n",
      "Epoch 00002: val_loss improved from 1.51866 to 1.02238, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/002-1.0224.hdf5\n",
      "36805/36805 [==============================] - 26s 702us/sample - loss: 1.4927 - acc: 0.5201 - val_loss: 1.0224 - val_acc: 0.7051\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1841 - acc: 0.6177\n",
      "Epoch 00003: val_loss improved from 1.02238 to 0.81960, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/003-0.8196.hdf5\n",
      "36805/36805 [==============================] - 26s 717us/sample - loss: 1.1841 - acc: 0.6177 - val_loss: 0.8196 - val_acc: 0.7561\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0009 - acc: 0.6778\n",
      "Epoch 00004: val_loss improved from 0.81960 to 0.69964, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/004-0.6996.hdf5\n",
      "36805/36805 [==============================] - 26s 715us/sample - loss: 1.0010 - acc: 0.6778 - val_loss: 0.6996 - val_acc: 0.7859\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8804 - acc: 0.7163\n",
      "Epoch 00005: val_loss improved from 0.69964 to 0.60294, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/005-0.6029.hdf5\n",
      "36805/36805 [==============================] - 26s 717us/sample - loss: 0.8803 - acc: 0.7163 - val_loss: 0.6029 - val_acc: 0.8171\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7921 - acc: 0.7470\n",
      "Epoch 00006: val_loss improved from 0.60294 to 0.53166, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/006-0.5317.hdf5\n",
      "36805/36805 [==============================] - 26s 710us/sample - loss: 0.7921 - acc: 0.7470 - val_loss: 0.5317 - val_acc: 0.8414\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7118 - acc: 0.7728\n",
      "Epoch 00007: val_loss improved from 0.53166 to 0.46675, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/007-0.4668.hdf5\n",
      "36805/36805 [==============================] - 26s 706us/sample - loss: 0.7119 - acc: 0.7728 - val_loss: 0.4668 - val_acc: 0.8642\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6545 - acc: 0.7937\n",
      "Epoch 00008: val_loss improved from 0.46675 to 0.46331, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/008-0.4633.hdf5\n",
      "36805/36805 [==============================] - 26s 717us/sample - loss: 0.6544 - acc: 0.7937 - val_loss: 0.4633 - val_acc: 0.8598\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5954 - acc: 0.8122\n",
      "Epoch 00009: val_loss improved from 0.46331 to 0.40496, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/009-0.4050.hdf5\n",
      "36805/36805 [==============================] - 26s 712us/sample - loss: 0.5955 - acc: 0.8122 - val_loss: 0.4050 - val_acc: 0.8763\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5468 - acc: 0.8286\n",
      "Epoch 00010: val_loss improved from 0.40496 to 0.34907, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/010-0.3491.hdf5\n",
      "36805/36805 [==============================] - 27s 721us/sample - loss: 0.5469 - acc: 0.8286 - val_loss: 0.3491 - val_acc: 0.8977\n",
      "Epoch 11/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5100 - acc: 0.8393\n",
      "Epoch 00011: val_loss improved from 0.34907 to 0.31948, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/011-0.3195.hdf5\n",
      "36805/36805 [==============================] - 26s 700us/sample - loss: 0.5101 - acc: 0.8393 - val_loss: 0.3195 - val_acc: 0.9024\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4737 - acc: 0.8517\n",
      "Epoch 00012: val_loss improved from 0.31948 to 0.29084, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/012-0.2908.hdf5\n",
      "36805/36805 [==============================] - 27s 724us/sample - loss: 0.4737 - acc: 0.8517 - val_loss: 0.2908 - val_acc: 0.9129\n",
      "Epoch 13/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4345 - acc: 0.8644\n",
      "Epoch 00013: val_loss improved from 0.29084 to 0.28346, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/013-0.2835.hdf5\n",
      "36805/36805 [==============================] - 26s 716us/sample - loss: 0.4343 - acc: 0.8644 - val_loss: 0.2835 - val_acc: 0.9143\n",
      "Epoch 14/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4153 - acc: 0.8715\n",
      "Epoch 00014: val_loss improved from 0.28346 to 0.25443, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/014-0.2544.hdf5\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.4156 - acc: 0.8714 - val_loss: 0.2544 - val_acc: 0.9276\n",
      "Epoch 15/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3927 - acc: 0.8786\n",
      "Epoch 00015: val_loss did not improve from 0.25443\n",
      "36805/36805 [==============================] - 26s 701us/sample - loss: 0.3926 - acc: 0.8785 - val_loss: 0.2559 - val_acc: 0.9222\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3691 - acc: 0.8849\n",
      "Epoch 00016: val_loss improved from 0.25443 to 0.24697, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/016-0.2470.hdf5\n",
      "36805/36805 [==============================] - 26s 718us/sample - loss: 0.3692 - acc: 0.8848 - val_loss: 0.2470 - val_acc: 0.9241\n",
      "Epoch 17/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3572 - acc: 0.8887\n",
      "Epoch 00017: val_loss improved from 0.24697 to 0.23494, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/017-0.2349.hdf5\n",
      "36805/36805 [==============================] - 26s 719us/sample - loss: 0.3571 - acc: 0.8888 - val_loss: 0.2349 - val_acc: 0.9278\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3438 - acc: 0.8924\n",
      "Epoch 00018: val_loss improved from 0.23494 to 0.20764, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/018-0.2076.hdf5\n",
      "36805/36805 [==============================] - 26s 711us/sample - loss: 0.3438 - acc: 0.8924 - val_loss: 0.2076 - val_acc: 0.9352\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3255 - acc: 0.8989\n",
      "Epoch 00019: val_loss did not improve from 0.20764\n",
      "36805/36805 [==============================] - 26s 707us/sample - loss: 0.3255 - acc: 0.8989 - val_loss: 0.2108 - val_acc: 0.9369\n",
      "Epoch 20/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3109 - acc: 0.9047\n",
      "Epoch 00020: val_loss improved from 0.20764 to 0.19932, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/020-0.1993.hdf5\n",
      "36805/36805 [==============================] - 26s 717us/sample - loss: 0.3110 - acc: 0.9047 - val_loss: 0.1993 - val_acc: 0.9408\n",
      "Epoch 21/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2966 - acc: 0.9074\n",
      "Epoch 00021: val_loss improved from 0.19932 to 0.19513, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/021-0.1951.hdf5\n",
      "36805/36805 [==============================] - 26s 714us/sample - loss: 0.2966 - acc: 0.9073 - val_loss: 0.1951 - val_acc: 0.9366\n",
      "Epoch 22/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2889 - acc: 0.9094\n",
      "Epoch 00022: val_loss improved from 0.19513 to 0.18971, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/022-0.1897.hdf5\n",
      "36805/36805 [==============================] - 26s 718us/sample - loss: 0.2888 - acc: 0.9095 - val_loss: 0.1897 - val_acc: 0.9422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.9120\n",
      "Epoch 00023: val_loss improved from 0.18971 to 0.18490, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/023-0.1849.hdf5\n",
      "36805/36805 [==============================] - 26s 715us/sample - loss: 0.2756 - acc: 0.9121 - val_loss: 0.1849 - val_acc: 0.9432\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2706 - acc: 0.9144\n",
      "Epoch 00024: val_loss improved from 0.18490 to 0.17965, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/024-0.1797.hdf5\n",
      "36805/36805 [==============================] - 26s 702us/sample - loss: 0.2707 - acc: 0.9143 - val_loss: 0.1797 - val_acc: 0.9446\n",
      "Epoch 25/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2629 - acc: 0.9171\n",
      "Epoch 00025: val_loss improved from 0.17965 to 0.17520, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/025-0.1752.hdf5\n",
      "36805/36805 [==============================] - 26s 714us/sample - loss: 0.2634 - acc: 0.9170 - val_loss: 0.1752 - val_acc: 0.9462\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.9198\n",
      "Epoch 00026: val_loss did not improve from 0.17520\n",
      "36805/36805 [==============================] - 26s 713us/sample - loss: 0.2554 - acc: 0.9197 - val_loss: 0.1824 - val_acc: 0.9413\n",
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2471 - acc: 0.9224\n",
      "Epoch 00027: val_loss improved from 0.17520 to 0.16780, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/027-0.1678.hdf5\n",
      "36805/36805 [==============================] - 26s 717us/sample - loss: 0.2472 - acc: 0.9224 - val_loss: 0.1678 - val_acc: 0.9492\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2406 - acc: 0.9245\n",
      "Epoch 00028: val_loss did not improve from 0.16780\n",
      "36805/36805 [==============================] - 26s 699us/sample - loss: 0.2407 - acc: 0.9245 - val_loss: 0.1873 - val_acc: 0.9429\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2334 - acc: 0.9259\n",
      "Epoch 00029: val_loss did not improve from 0.16780\n",
      "36805/36805 [==============================] - 26s 711us/sample - loss: 0.2334 - acc: 0.9259 - val_loss: 0.1782 - val_acc: 0.9464\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2258 - acc: 0.9293\n",
      "Epoch 00030: val_loss improved from 0.16780 to 0.16666, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/030-0.1667.hdf5\n",
      "36805/36805 [==============================] - 26s 701us/sample - loss: 0.2259 - acc: 0.9292 - val_loss: 0.1667 - val_acc: 0.9460\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2221 - acc: 0.9292\n",
      "Epoch 00031: val_loss improved from 0.16666 to 0.16353, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/031-0.1635.hdf5\n",
      "36805/36805 [==============================] - 24s 644us/sample - loss: 0.2221 - acc: 0.9292 - val_loss: 0.1635 - val_acc: 0.9485\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9312\n",
      "Epoch 00032: val_loss improved from 0.16353 to 0.15167, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/032-0.1517.hdf5\n",
      "36805/36805 [==============================] - 19s 521us/sample - loss: 0.2194 - acc: 0.9312 - val_loss: 0.1517 - val_acc: 0.9539\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2130 - acc: 0.9333\n",
      "Epoch 00033: val_loss did not improve from 0.15167\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.2130 - acc: 0.9333 - val_loss: 0.1520 - val_acc: 0.9513\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2045 - acc: 0.9343\n",
      "Epoch 00034: val_loss did not improve from 0.15167\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.2045 - acc: 0.9344 - val_loss: 0.1774 - val_acc: 0.9404\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9362\n",
      "Epoch 00035: val_loss did not improve from 0.15167\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.1994 - acc: 0.9362 - val_loss: 0.1591 - val_acc: 0.9478\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9381\n",
      "Epoch 00036: val_loss improved from 0.15167 to 0.15158, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/036-0.1516.hdf5\n",
      "36805/36805 [==============================] - 19s 522us/sample - loss: 0.1982 - acc: 0.9381 - val_loss: 0.1516 - val_acc: 0.9546\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1925 - acc: 0.9378\n",
      "Epoch 00037: val_loss improved from 0.15158 to 0.14165, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/037-0.1416.hdf5\n",
      "36805/36805 [==============================] - 19s 522us/sample - loss: 0.1925 - acc: 0.9378 - val_loss: 0.1416 - val_acc: 0.9567\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1899 - acc: 0.9388\n",
      "Epoch 00038: val_loss did not improve from 0.14165\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.1899 - acc: 0.9388 - val_loss: 0.1485 - val_acc: 0.9553\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9412\n",
      "Epoch 00039: val_loss did not improve from 0.14165\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.1828 - acc: 0.9412 - val_loss: 0.1549 - val_acc: 0.9495\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1806 - acc: 0.9412\n",
      "Epoch 00040: val_loss did not improve from 0.14165\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.1807 - acc: 0.9411 - val_loss: 0.1446 - val_acc: 0.9539\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9432\n",
      "Epoch 00041: val_loss did not improve from 0.14165\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.1753 - acc: 0.9432 - val_loss: 0.1425 - val_acc: 0.9557\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1749 - acc: 0.9433\n",
      "Epoch 00042: val_loss did not improve from 0.14165\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.1749 - acc: 0.9433 - val_loss: 0.1486 - val_acc: 0.9529\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1700 - acc: 0.9449\n",
      "Epoch 00043: val_loss did not improve from 0.14165\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.1700 - acc: 0.9449 - val_loss: 0.1417 - val_acc: 0.9548\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1645 - acc: 0.9479\n",
      "Epoch 00044: val_loss improved from 0.14165 to 0.13810, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/044-0.1381.hdf5\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.1645 - acc: 0.9479 - val_loss: 0.1381 - val_acc: 0.9578\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1632 - acc: 0.9470\n",
      "Epoch 00045: val_loss did not improve from 0.13810\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.1632 - acc: 0.9470 - val_loss: 0.1387 - val_acc: 0.9557\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1603 - acc: 0.9479\n",
      "Epoch 00046: val_loss improved from 0.13810 to 0.13740, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/046-0.1374.hdf5\n",
      "36805/36805 [==============================] - 19s 524us/sample - loss: 0.1602 - acc: 0.9479 - val_loss: 0.1374 - val_acc: 0.9571\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9497\n",
      "Epoch 00047: val_loss improved from 0.13740 to 0.13585, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/047-0.1358.hdf5\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.1568 - acc: 0.9497 - val_loss: 0.1358 - val_acc: 0.9585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9503\n",
      "Epoch 00048: val_loss did not improve from 0.13585\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.1543 - acc: 0.9503 - val_loss: 0.1377 - val_acc: 0.9560\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9518\n",
      "Epoch 00049: val_loss improved from 0.13585 to 0.13330, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/049-0.1333.hdf5\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.1501 - acc: 0.9518 - val_loss: 0.1333 - val_acc: 0.9592\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9496\n",
      "Epoch 00050: val_loss did not improve from 0.13330\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.1514 - acc: 0.9497 - val_loss: 0.1361 - val_acc: 0.9597\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9514\n",
      "Epoch 00051: val_loss did not improve from 0.13330\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.1487 - acc: 0.9514 - val_loss: 0.1397 - val_acc: 0.9581\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9538\n",
      "Epoch 00052: val_loss did not improve from 0.13330\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.1421 - acc: 0.9538 - val_loss: 0.1379 - val_acc: 0.9560\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9527\n",
      "Epoch 00053: val_loss improved from 0.13330 to 0.12945, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/053-0.1294.hdf5\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.1452 - acc: 0.9527 - val_loss: 0.1294 - val_acc: 0.9604\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9548\n",
      "Epoch 00054: val_loss did not improve from 0.12945\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.1412 - acc: 0.9548 - val_loss: 0.1341 - val_acc: 0.9592\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9551\n",
      "Epoch 00055: val_loss did not improve from 0.12945\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.1360 - acc: 0.9551 - val_loss: 0.1352 - val_acc: 0.9585\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9567\n",
      "Epoch 00056: val_loss improved from 0.12945 to 0.12731, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/056-0.1273.hdf5\n",
      "36805/36805 [==============================] - 19s 522us/sample - loss: 0.1341 - acc: 0.9567 - val_loss: 0.1273 - val_acc: 0.9599\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9561\n",
      "Epoch 00057: val_loss did not improve from 0.12731\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.1340 - acc: 0.9561 - val_loss: 0.1368 - val_acc: 0.9595\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9565\n",
      "Epoch 00058: val_loss did not improve from 0.12731\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.1316 - acc: 0.9565 - val_loss: 0.1344 - val_acc: 0.9585\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9581\n",
      "Epoch 00059: val_loss did not improve from 0.12731\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.1283 - acc: 0.9581 - val_loss: 0.1294 - val_acc: 0.9625\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9593\n",
      "Epoch 00060: val_loss did not improve from 0.12731\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.1244 - acc: 0.9594 - val_loss: 0.1279 - val_acc: 0.9609\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9609\n",
      "Epoch 00061: val_loss improved from 0.12731 to 0.12620, saving model to model/checkpoint/1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv_checkpoint/061-0.1262.hdf5\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.1218 - acc: 0.9609 - val_loss: 0.1262 - val_acc: 0.9632\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9593\n",
      "Epoch 00062: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.1228 - acc: 0.9593 - val_loss: 0.1442 - val_acc: 0.9557\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9615\n",
      "Epoch 00063: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.1181 - acc: 0.9615 - val_loss: 0.1289 - val_acc: 0.9613\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9600\n",
      "Epoch 00064: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.1197 - acc: 0.9600 - val_loss: 0.1330 - val_acc: 0.9597\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9617\n",
      "Epoch 00065: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.1168 - acc: 0.9617 - val_loss: 0.1386 - val_acc: 0.9592\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9633\n",
      "Epoch 00066: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.1132 - acc: 0.9633 - val_loss: 0.1298 - val_acc: 0.9606\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9641\n",
      "Epoch 00067: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.1108 - acc: 0.9641 - val_loss: 0.1286 - val_acc: 0.9620\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9646\n",
      "Epoch 00068: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.1089 - acc: 0.9646 - val_loss: 0.1340 - val_acc: 0.9609\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9635\n",
      "Epoch 00069: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.1101 - acc: 0.9635 - val_loss: 0.1322 - val_acc: 0.9616\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9627\n",
      "Epoch 00070: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.1112 - acc: 0.9627 - val_loss: 0.1327 - val_acc: 0.9613\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9653\n",
      "Epoch 00071: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 524us/sample - loss: 0.1048 - acc: 0.9653 - val_loss: 0.1364 - val_acc: 0.9618\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9641\n",
      "Epoch 00072: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.1076 - acc: 0.9641 - val_loss: 0.1346 - val_acc: 0.9597\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9655\n",
      "Epoch 00073: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.1040 - acc: 0.9655 - val_loss: 0.1321 - val_acc: 0.9611\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9666\n",
      "Epoch 00074: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 522us/sample - loss: 0.1001 - acc: 0.9666 - val_loss: 0.1315 - val_acc: 0.9632\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9673\n",
      "Epoch 00075: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 524us/sample - loss: 0.0976 - acc: 0.9673 - val_loss: 0.1290 - val_acc: 0.9634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9679\n",
      "Epoch 00076: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 510us/sample - loss: 0.0960 - acc: 0.9679 - val_loss: 0.1438 - val_acc: 0.9585\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9692\n",
      "Epoch 00077: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.0932 - acc: 0.9692 - val_loss: 0.1324 - val_acc: 0.9634\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9692\n",
      "Epoch 00078: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.0933 - acc: 0.9692 - val_loss: 0.1283 - val_acc: 0.9632\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9697\n",
      "Epoch 00079: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 521us/sample - loss: 0.0918 - acc: 0.9697 - val_loss: 0.1335 - val_acc: 0.9618\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9695\n",
      "Epoch 00080: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.0918 - acc: 0.9695 - val_loss: 0.1367 - val_acc: 0.9606\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9696\n",
      "Epoch 00081: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 522us/sample - loss: 0.0933 - acc: 0.9696 - val_loss: 0.1376 - val_acc: 0.9627\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9711\n",
      "Epoch 00082: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.0874 - acc: 0.9711 - val_loss: 0.1374 - val_acc: 0.9620\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9708\n",
      "Epoch 00083: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 521us/sample - loss: 0.0897 - acc: 0.9708 - val_loss: 0.1329 - val_acc: 0.9616\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9700\n",
      "Epoch 00084: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.0860 - acc: 0.9700 - val_loss: 0.1276 - val_acc: 0.9637\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9702\n",
      "Epoch 00085: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.0880 - acc: 0.9702 - val_loss: 0.1374 - val_acc: 0.9632\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9727\n",
      "Epoch 00086: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.0846 - acc: 0.9727 - val_loss: 0.1347 - val_acc: 0.9623\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9723\n",
      "Epoch 00087: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.0819 - acc: 0.9723 - val_loss: 0.1450 - val_acc: 0.9599\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9731\n",
      "Epoch 00088: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 0.0792 - acc: 0.9731 - val_loss: 0.1387 - val_acc: 0.9639\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9726\n",
      "Epoch 00089: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.0822 - acc: 0.9726 - val_loss: 0.1412 - val_acc: 0.9625\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9742\n",
      "Epoch 00090: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.0790 - acc: 0.9742 - val_loss: 0.1499 - val_acc: 0.9611\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9727\n",
      "Epoch 00091: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 525us/sample - loss: 0.0810 - acc: 0.9727 - val_loss: 0.1495 - val_acc: 0.9562\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9748\n",
      "Epoch 00092: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 521us/sample - loss: 0.0757 - acc: 0.9748 - val_loss: 0.1423 - val_acc: 0.9620\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9729\n",
      "Epoch 00093: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.0787 - acc: 0.9729 - val_loss: 0.1401 - val_acc: 0.9613\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9746\n",
      "Epoch 00094: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.0735 - acc: 0.9746 - val_loss: 0.1420 - val_acc: 0.9632\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9766\n",
      "Epoch 00095: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.0714 - acc: 0.9766 - val_loss: 0.1352 - val_acc: 0.9632\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9762\n",
      "Epoch 00096: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 522us/sample - loss: 0.0707 - acc: 0.9763 - val_loss: 0.1366 - val_acc: 0.9641\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9744\n",
      "Epoch 00097: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 523us/sample - loss: 0.0754 - acc: 0.9743 - val_loss: 0.1344 - val_acc: 0.9627\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9755\n",
      "Epoch 00098: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.0728 - acc: 0.9755 - val_loss: 0.1611 - val_acc: 0.9578\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9766\n",
      "Epoch 00099: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 0.0690 - acc: 0.9766 - val_loss: 0.1541 - val_acc: 0.9597\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9770\n",
      "Epoch 00100: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0674 - acc: 0.9770 - val_loss: 0.1524 - val_acc: 0.9627\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9780\n",
      "Epoch 00101: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.0652 - acc: 0.9780 - val_loss: 0.1470 - val_acc: 0.9623\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9769\n",
      "Epoch 00102: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.0692 - acc: 0.9769 - val_loss: 0.1534 - val_acc: 0.9620\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9771\n",
      "Epoch 00103: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.0665 - acc: 0.9771 - val_loss: 0.1450 - val_acc: 0.9613\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9768\n",
      "Epoch 00104: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.0671 - acc: 0.9768 - val_loss: 0.1430 - val_acc: 0.9653\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9785\n",
      "Epoch 00105: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 522us/sample - loss: 0.0651 - acc: 0.9784 - val_loss: 0.1570 - val_acc: 0.9588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9763\n",
      "Epoch 00106: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.0687 - acc: 0.9763 - val_loss: 0.1554 - val_acc: 0.9602\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9786\n",
      "Epoch 00107: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.0628 - acc: 0.9785 - val_loss: 0.1513 - val_acc: 0.9620\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9793\n",
      "Epoch 00108: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.0615 - acc: 0.9794 - val_loss: 0.1446 - val_acc: 0.9606\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9789\n",
      "Epoch 00109: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.0617 - acc: 0.9789 - val_loss: 0.1581 - val_acc: 0.9630\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9783\n",
      "Epoch 00110: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.0621 - acc: 0.9783 - val_loss: 0.1470 - val_acc: 0.9660\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9798\n",
      "Epoch 00111: val_loss did not improve from 0.12620\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.0587 - acc: 0.9798 - val_loss: 0.1437 - val_acc: 0.9641\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 389us/sample - loss: 0.1822 - acc: 0.9406\n",
      "Loss: 0.18217745269663238 Accuracy: 0.9406023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_multi_3_GMP_ch_32_DO'\n",
    "\n",
    "for i in range(3, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_cnn(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 32)    192         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 32)    0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 32)     0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 32)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 32)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 32)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 32)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_18 (Global (None, 32)           0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_19 (Global (None, 32)           0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 32)           0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 96)           0           global_max_pooling1d_18[0][0]    \n",
      "                                                                 global_max_pooling1d_19[0][0]    \n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 96)           0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           1552        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,048\n",
      "Trainable params: 12,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 337us/sample - loss: 0.7881 - acc: 0.7618\n",
      "Loss: 0.7881466261322996 Accuracy: 0.7617861\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 16000, 32)    192         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16000, 32)    0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 5333, 32)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5333, 32)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1777, 32)     0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1777, 32)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 592, 32)      0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 592, 32)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 197, 32)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 32)           0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 32)           0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 32)           0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 96)           0           global_max_pooling1d_21[0][0]    \n",
      "                                                                 global_max_pooling1d_22[0][0]    \n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 96)           0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           1552        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,200\n",
      "Trainable params: 17,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 374us/sample - loss: 0.5601 - acc: 0.8363\n",
      "Loss: 0.5600777815559324 Accuracy: 0.8363448\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 16000, 32)    192         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16000, 32)    0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 5333, 32)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5333, 32)     0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1777, 32)     0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1777, 32)     0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 592, 32)      0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 592, 32)      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 197, 32)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 197, 64)      0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 65, 64)       0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 32)           0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 32)           0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_26 (Global (None, 64)           0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128)          0           global_max_pooling1d_24[0][0]    \n",
      "                                                                 global_max_pooling1d_25[0][0]    \n",
      "                                                                 global_max_pooling1d_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           2064        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,016\n",
      "Trainable params: 28,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 352us/sample - loss: 0.2973 - acc: 0.9134\n",
      "Loss: 0.2973256352410757 Accuracy: 0.91339564\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 16000, 32)    192         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16000, 32)    0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 5333, 32)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5333, 32)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1777, 32)     0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1777, 32)     0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 592, 32)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 592, 32)      0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 197, 32)      0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 197, 64)      0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 65, 64)       0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 65, 64)       0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 21, 64)       0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_27 (Global (None, 32)           0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_28 (Global (None, 64)           0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_29 (Global (None, 64)           0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 160)          0           global_max_pooling1d_27[0][0]    \n",
      "                                                                 global_max_pooling1d_28[0][0]    \n",
      "                                                                 global_max_pooling1d_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 160)          0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           2576        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 49,072\n",
      "Trainable params: 49,072\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 397us/sample - loss: 0.2019 - acc: 0.9394\n",
      "Loss: 0.2018641644549147 Accuracy: 0.9393562\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 16000, 32)    192         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16000, 32)    0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 5333, 32)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5333, 32)     0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 1777, 32)     0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1777, 32)     0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 592, 32)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 592, 32)      0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 197, 32)      0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 197, 64)      0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 65, 64)       0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 65, 64)       0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 21, 64)       0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 21, 64)       0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 7, 64)        0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_30 (Global (None, 64)           0           max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_31 (Global (None, 64)           0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_32 (Global (None, 64)           0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 192)          0           global_max_pooling1d_30[0][0]    \n",
      "                                                                 global_max_pooling1d_31[0][0]    \n",
      "                                                                 global_max_pooling1d_32[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 192)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           3088        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 70,128\n",
      "Trainable params: 70,128\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 385us/sample - loss: 0.1657 - acc: 0.9489\n",
      "Loss: 0.16570895418586637 Accuracy: 0.94890964\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 16000, 32)    192         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16000, 32)    0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 5333, 32)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5333, 32)     0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 1777, 32)     0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1777, 32)     0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 592, 32)      0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 592, 32)      0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 197, 32)      0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 197, 64)      0           conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 65, 64)       0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 65, 64)       0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 21, 64)       0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 21, 64)       0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 7, 64)        0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 7, 64)        20544       max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 64)        0           conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 2, 64)        0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_33 (Global (None, 64)           0           max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_34 (Global (None, 64)           0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_35 (Global (None, 64)           0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 192)          0           global_max_pooling1d_33[0][0]    \n",
      "                                                                 global_max_pooling1d_34[0][0]    \n",
      "                                                                 global_max_pooling1d_35[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 192)          0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           3088        dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 90,672\n",
      "Trainable params: 90,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 406us/sample - loss: 0.1822 - acc: 0.9406\n",
      "Loss: 0.18217745269663238 Accuracy: 0.9406023\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_multi_3_GMP_ch_32_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 9):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 32)    192         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 32)    0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 32)     0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 32)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 32)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 32)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 32)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_18 (Global (None, 32)           0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_19 (Global (None, 32)           0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 32)           0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 96)           0           global_max_pooling1d_18[0][0]    \n",
      "                                                                 global_max_pooling1d_19[0][0]    \n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 96)           0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           1552        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,048\n",
      "Trainable params: 12,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 413us/sample - loss: 0.7945 - acc: 0.7643\n",
      "Loss: 0.7944726919706985 Accuracy: 0.7642783\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 16000, 32)    192         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16000, 32)    0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 5333, 32)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5333, 32)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1777, 32)     0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1777, 32)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 592, 32)      0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 592, 32)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 197, 32)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 32)           0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 32)           0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 32)           0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 96)           0           global_max_pooling1d_21[0][0]    \n",
      "                                                                 global_max_pooling1d_22[0][0]    \n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 96)           0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           1552        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,200\n",
      "Trainable params: 17,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 412us/sample - loss: 0.5621 - acc: 0.8336\n",
      "Loss: 0.5620785628461887 Accuracy: 0.83364487\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 16000, 32)    192         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16000, 32)    0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 5333, 32)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5333, 32)     0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1777, 32)     0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1777, 32)     0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 592, 32)      0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 592, 32)      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 197, 32)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 197, 64)      0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 65, 64)       0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 32)           0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 32)           0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_26 (Global (None, 64)           0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128)          0           global_max_pooling1d_24[0][0]    \n",
      "                                                                 global_max_pooling1d_25[0][0]    \n",
      "                                                                 global_max_pooling1d_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           2064        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,016\n",
      "Trainable params: 28,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 436us/sample - loss: 0.3060 - acc: 0.9109\n",
      "Loss: 0.3060402023705614 Accuracy: 0.91090345\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 16000, 32)    192         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16000, 32)    0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 5333, 32)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5333, 32)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1777, 32)     0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1777, 32)     0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 592, 32)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 592, 32)      0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 197, 32)      0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 197, 64)      0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 65, 64)       0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 65, 64)       0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 21, 64)       0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_27 (Global (None, 32)           0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_28 (Global (None, 64)           0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_29 (Global (None, 64)           0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 160)          0           global_max_pooling1d_27[0][0]    \n",
      "                                                                 global_max_pooling1d_28[0][0]    \n",
      "                                                                 global_max_pooling1d_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 160)          0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           2576        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 49,072\n",
      "Trainable params: 49,072\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 458us/sample - loss: 0.2087 - acc: 0.9383\n",
      "Loss: 0.20871542110373792 Accuracy: 0.9383178\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 16000, 32)    192         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16000, 32)    0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 5333, 32)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5333, 32)     0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 1777, 32)     0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1777, 32)     0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 592, 32)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 592, 32)      0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 197, 32)      0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 197, 64)      0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 65, 64)       0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 65, 64)       0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 21, 64)       0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 21, 64)       0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 7, 64)        0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_30 (Global (None, 64)           0           max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_31 (Global (None, 64)           0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_32 (Global (None, 64)           0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 192)          0           global_max_pooling1d_30[0][0]    \n",
      "                                                                 global_max_pooling1d_31[0][0]    \n",
      "                                                                 global_max_pooling1d_32[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 192)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           3088        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 70,128\n",
      "Trainable params: 70,128\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 461us/sample - loss: 0.1690 - acc: 0.9499\n",
      "Loss: 0.1689887554165235 Accuracy: 0.9499481\n",
      "\n",
      "1D_CNN_custom_multi_3_GMP_ch_32_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 16000, 32)    192         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16000, 32)    0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 5333, 32)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5333, 32)     0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 1777, 32)     0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1777, 32)     0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 592, 32)      0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 592, 32)      0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 197, 32)      0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 197, 64)      0           conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 65, 64)       0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 65, 64)       0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 21, 64)       0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 21, 64)       0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 7, 64)        0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 7, 64)        20544       max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 64)        0           conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 2, 64)        0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_33 (Global (None, 64)           0           max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_34 (Global (None, 64)           0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_35 (Global (None, 64)           0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 192)          0           global_max_pooling1d_33[0][0]    \n",
      "                                                                 global_max_pooling1d_34[0][0]    \n",
      "                                                                 global_max_pooling1d_35[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 192)          0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           3088        dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 90,672\n",
      "Trainable params: 90,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 501us/sample - loss: 0.2041 - acc: 0.9493\n",
      "Loss: 0.20407272546928326 Accuracy: 0.949325\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
