{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_ch_32_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=32, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=32*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,058,896\n",
      "Trainable params: 2,058,704\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,040,176\n",
      "Trainable params: 1,039,920\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,050,736\n",
      "Trainable params: 1,050,352\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 559,536\n",
      "Trainable params: 559,024\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 324,336\n",
      "Trainable params: 323,696\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                128016    \n",
      "=================================================================\n",
      "Total params: 217,136\n",
      "Trainable params: 216,368\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 257,712\n",
      "Trainable params: 256,688\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                63504     \n",
      "=================================================================\n",
      "Total params: 276,784\n",
      "Trainable params: 275,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_52 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                30736     \n",
      "=================================================================\n",
      "Total params: 326,576\n",
      "Trainable params: 325,040\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 392,752\n",
      "Trainable params: 390,960\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                12304     \n",
      "=================================================================\n",
      "Total params: 555,824\n",
      "Trainable params: 553,520\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 14):\n",
    "    model = build_1d_cnn_custom_ch_32_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5685 - acc: 0.3053\n",
      "Epoch 00001: val_loss improved from inf to 1.99143, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_3_conv_checkpoint/001-1.9914.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 2.5685 - acc: 0.3053 - val_loss: 1.9914 - val_acc: 0.3811\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6426 - acc: 0.5107\n",
      "Epoch 00002: val_loss improved from 1.99143 to 1.85257, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_3_conv_checkpoint/002-1.8526.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.6426 - acc: 0.5107 - val_loss: 1.8526 - val_acc: 0.4556\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2643 - acc: 0.6139\n",
      "Epoch 00003: val_loss improved from 1.85257 to 1.73208, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_3_conv_checkpoint/003-1.7321.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.2643 - acc: 0.6139 - val_loss: 1.7321 - val_acc: 0.5034\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9607 - acc: 0.6971\n",
      "Epoch 00004: val_loss improved from 1.73208 to 1.67348, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_3_conv_checkpoint/004-1.6735.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.9607 - acc: 0.6971 - val_loss: 1.6735 - val_acc: 0.5090\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7623 - acc: 0.7563\n",
      "Epoch 00005: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.7627 - acc: 0.7563 - val_loss: 2.0000 - val_acc: 0.4764\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6251 - acc: 0.8004\n",
      "Epoch 00006: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.6251 - acc: 0.8004 - val_loss: 1.8529 - val_acc: 0.5099\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5015 - acc: 0.8392\n",
      "Epoch 00007: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5014 - acc: 0.8393 - val_loss: 1.9985 - val_acc: 0.4917\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4336 - acc: 0.8605\n",
      "Epoch 00008: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4336 - acc: 0.8605 - val_loss: 2.4354 - val_acc: 0.4633\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3579 - acc: 0.8860\n",
      "Epoch 00009: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3581 - acc: 0.8859 - val_loss: 2.3448 - val_acc: 0.4677\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3229 - acc: 0.8960\n",
      "Epoch 00010: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3229 - acc: 0.8960 - val_loss: 2.7126 - val_acc: 0.4251\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2934 - acc: 0.9064\n",
      "Epoch 00011: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2934 - acc: 0.9064 - val_loss: 2.3205 - val_acc: 0.4922\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2620 - acc: 0.9171\n",
      "Epoch 00012: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2621 - acc: 0.9171 - val_loss: 2.3134 - val_acc: 0.5167\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2284 - acc: 0.9276\n",
      "Epoch 00013: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2285 - acc: 0.9276 - val_loss: 2.1574 - val_acc: 0.5220\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2150 - acc: 0.9312\n",
      "Epoch 00014: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2150 - acc: 0.9312 - val_loss: 2.2751 - val_acc: 0.5276\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2001 - acc: 0.9376\n",
      "Epoch 00015: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2003 - acc: 0.9376 - val_loss: 2.5842 - val_acc: 0.4955\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9390\n",
      "Epoch 00016: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1977 - acc: 0.9389 - val_loss: 2.4750 - val_acc: 0.5369\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9446\n",
      "Epoch 00017: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1785 - acc: 0.9445 - val_loss: 2.3954 - val_acc: 0.5229\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1726 - acc: 0.9484\n",
      "Epoch 00018: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1726 - acc: 0.9484 - val_loss: 2.1520 - val_acc: 0.5611\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9510\n",
      "Epoch 00019: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1598 - acc: 0.9510 - val_loss: 2.9094 - val_acc: 0.4929\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9555\n",
      "Epoch 00020: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1441 - acc: 0.9555 - val_loss: 2.9403 - val_acc: 0.4782\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9549\n",
      "Epoch 00021: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1459 - acc: 0.9549 - val_loss: 2.7161 - val_acc: 0.5120\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9557\n",
      "Epoch 00022: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1438 - acc: 0.9557 - val_loss: 2.4933 - val_acc: 0.5469\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9601\n",
      "Epoch 00023: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1307 - acc: 0.9600 - val_loss: 2.4722 - val_acc: 0.5355\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9641\n",
      "Epoch 00024: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1203 - acc: 0.9641 - val_loss: 2.4863 - val_acc: 0.5474\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1191 - acc: 0.9645\n",
      "Epoch 00025: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1192 - acc: 0.9645 - val_loss: 2.5012 - val_acc: 0.5386\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9654\n",
      "Epoch 00026: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1144 - acc: 0.9654 - val_loss: 2.6459 - val_acc: 0.5516\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9656\n",
      "Epoch 00027: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1153 - acc: 0.9656 - val_loss: 2.6406 - val_acc: 0.5395\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9696\n",
      "Epoch 00028: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1024 - acc: 0.9696 - val_loss: 3.0485 - val_acc: 0.5171\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9681\n",
      "Epoch 00029: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1063 - acc: 0.9681 - val_loss: 2.7981 - val_acc: 0.5392\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9678\n",
      "Epoch 00030: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1066 - acc: 0.9678 - val_loss: 2.5381 - val_acc: 0.5462\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9689\n",
      "Epoch 00031: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1041 - acc: 0.9689 - val_loss: 3.2343 - val_acc: 0.5153\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9699\n",
      "Epoch 00032: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1029 - acc: 0.9699 - val_loss: 2.6729 - val_acc: 0.5437\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9704\n",
      "Epoch 00033: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0976 - acc: 0.9704 - val_loss: 2.8730 - val_acc: 0.5365\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9723\n",
      "Epoch 00034: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0936 - acc: 0.9723 - val_loss: 2.6059 - val_acc: 0.5584\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9743\n",
      "Epoch 00035: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0864 - acc: 0.9744 - val_loss: 2.6184 - val_acc: 0.5553\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9751\n",
      "Epoch 00036: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0853 - acc: 0.9751 - val_loss: 3.7125 - val_acc: 0.4698\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9746\n",
      "Epoch 00037: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0855 - acc: 0.9747 - val_loss: 2.8156 - val_acc: 0.5523\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9748\n",
      "Epoch 00038: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0870 - acc: 0.9747 - val_loss: 3.3159 - val_acc: 0.4873\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9759\n",
      "Epoch 00039: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0829 - acc: 0.9759 - val_loss: 2.8732 - val_acc: 0.5458\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9746\n",
      "Epoch 00040: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0854 - acc: 0.9745 - val_loss: 2.7103 - val_acc: 0.5607\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9747\n",
      "Epoch 00041: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0862 - acc: 0.9747 - val_loss: 2.6365 - val_acc: 0.5637\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9789\n",
      "Epoch 00042: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0739 - acc: 0.9789 - val_loss: 2.8283 - val_acc: 0.5427\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9792\n",
      "Epoch 00043: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0745 - acc: 0.9792 - val_loss: 3.0678 - val_acc: 0.5439\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9776\n",
      "Epoch 00044: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0763 - acc: 0.9776 - val_loss: 3.1858 - val_acc: 0.5351\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9793\n",
      "Epoch 00045: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0739 - acc: 0.9793 - val_loss: 2.8106 - val_acc: 0.5532\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9800\n",
      "Epoch 00046: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0702 - acc: 0.9800 - val_loss: 2.9114 - val_acc: 0.5439\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9797\n",
      "Epoch 00047: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0731 - acc: 0.9797 - val_loss: 3.2245 - val_acc: 0.5281\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9807\n",
      "Epoch 00048: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0681 - acc: 0.9807 - val_loss: 3.4823 - val_acc: 0.4836\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9808\n",
      "Epoch 00049: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0676 - acc: 0.9807 - val_loss: 3.3719 - val_acc: 0.5232\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9800\n",
      "Epoch 00050: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0722 - acc: 0.9800 - val_loss: 2.8289 - val_acc: 0.5549\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9827\n",
      "Epoch 00051: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0592 - acc: 0.9827 - val_loss: 2.8498 - val_acc: 0.5625\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9832\n",
      "Epoch 00052: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0596 - acc: 0.9832 - val_loss: 4.0352 - val_acc: 0.4694\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9833\n",
      "Epoch 00053: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0583 - acc: 0.9833 - val_loss: 3.2392 - val_acc: 0.5290\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9803\n",
      "Epoch 00054: val_loss did not improve from 1.67348\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0703 - acc: 0.9803 - val_loss: 3.2246 - val_acc: 0.5318\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 546us/sample - loss: 1.7968 - acc: 0.4739\n",
      "Loss: 1.796771149942313 Accuracy: 0.4739356\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2761 - acc: 0.3258\n",
      "Epoch 00001: val_loss improved from inf to 1.74845, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_4_conv_checkpoint/001-1.7484.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 2.2761 - acc: 0.3259 - val_loss: 1.7484 - val_acc: 0.4274\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5482 - acc: 0.5187\n",
      "Epoch 00002: val_loss improved from 1.74845 to 1.34322, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_4_conv_checkpoint/002-1.3432.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 1.5481 - acc: 0.5187 - val_loss: 1.3432 - val_acc: 0.5819\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2470 - acc: 0.6102\n",
      "Epoch 00003: val_loss did not improve from 1.34322\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 1.2470 - acc: 0.6102 - val_loss: 1.3900 - val_acc: 0.5693\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0485 - acc: 0.6672\n",
      "Epoch 00004: val_loss improved from 1.34322 to 1.30939, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_4_conv_checkpoint/004-1.3094.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 1.0484 - acc: 0.6672 - val_loss: 1.3094 - val_acc: 0.6080\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8937 - acc: 0.7170\n",
      "Epoch 00005: val_loss did not improve from 1.30939\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.8938 - acc: 0.7170 - val_loss: 1.4291 - val_acc: 0.5735\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7539 - acc: 0.7590\n",
      "Epoch 00006: val_loss did not improve from 1.30939\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.7540 - acc: 0.7590 - val_loss: 1.3950 - val_acc: 0.5835\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6514 - acc: 0.7916\n",
      "Epoch 00007: val_loss improved from 1.30939 to 1.28756, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_4_conv_checkpoint/007-1.2876.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.6514 - acc: 0.7916 - val_loss: 1.2876 - val_acc: 0.6306\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5678 - acc: 0.8156\n",
      "Epoch 00008: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5678 - acc: 0.8156 - val_loss: 1.3070 - val_acc: 0.6266\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5052 - acc: 0.8363\n",
      "Epoch 00009: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5053 - acc: 0.8362 - val_loss: 1.3617 - val_acc: 0.6287\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4543 - acc: 0.8528\n",
      "Epoch 00010: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.4548 - acc: 0.8527 - val_loss: 1.4135 - val_acc: 0.6182\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4053 - acc: 0.8687\n",
      "Epoch 00011: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.4052 - acc: 0.8687 - val_loss: 1.3465 - val_acc: 0.6327\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3596 - acc: 0.8826\n",
      "Epoch 00012: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3597 - acc: 0.8826 - val_loss: 1.4491 - val_acc: 0.6229\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3331 - acc: 0.8927\n",
      "Epoch 00013: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3331 - acc: 0.8927 - val_loss: 1.6022 - val_acc: 0.5905\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3108 - acc: 0.8977\n",
      "Epoch 00014: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3108 - acc: 0.8977 - val_loss: 1.4402 - val_acc: 0.6320\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2810 - acc: 0.9104\n",
      "Epoch 00015: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2814 - acc: 0.9103 - val_loss: 1.5283 - val_acc: 0.6154\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2682 - acc: 0.9133\n",
      "Epoch 00016: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2682 - acc: 0.9134 - val_loss: 1.5441 - val_acc: 0.6240\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2493 - acc: 0.9198\n",
      "Epoch 00017: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2492 - acc: 0.9198 - val_loss: 1.5018 - val_acc: 0.6303\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2314 - acc: 0.9246\n",
      "Epoch 00018: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2315 - acc: 0.9245 - val_loss: 1.4612 - val_acc: 0.6359\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9306\n",
      "Epoch 00019: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2127 - acc: 0.9306 - val_loss: 1.5520 - val_acc: 0.6483\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2089 - acc: 0.9321\n",
      "Epoch 00020: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2089 - acc: 0.9322 - val_loss: 1.5758 - val_acc: 0.6362\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9374\n",
      "Epoch 00021: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1956 - acc: 0.9375 - val_loss: 1.5077 - val_acc: 0.6394\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1869 - acc: 0.9394\n",
      "Epoch 00022: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1869 - acc: 0.9394 - val_loss: 1.6248 - val_acc: 0.6299\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9412\n",
      "Epoch 00023: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1815 - acc: 0.9411 - val_loss: 1.6795 - val_acc: 0.6392\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1845 - acc: 0.9419\n",
      "Epoch 00024: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1845 - acc: 0.9419 - val_loss: 1.6067 - val_acc: 0.6392\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9467\n",
      "Epoch 00025: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1679 - acc: 0.9467 - val_loss: 1.5912 - val_acc: 0.6476\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9473\n",
      "Epoch 00026: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1638 - acc: 0.9472 - val_loss: 1.5463 - val_acc: 0.6601\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1647 - acc: 0.9470\n",
      "Epoch 00027: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1647 - acc: 0.9470 - val_loss: 1.5446 - val_acc: 0.6650\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9518\n",
      "Epoch 00028: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1507 - acc: 0.9518 - val_loss: 1.6583 - val_acc: 0.6511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1446 - acc: 0.9542\n",
      "Epoch 00029: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1446 - acc: 0.9542 - val_loss: 1.6980 - val_acc: 0.6452\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9527\n",
      "Epoch 00030: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1457 - acc: 0.9527 - val_loss: 1.6228 - val_acc: 0.6625\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9563\n",
      "Epoch 00031: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1389 - acc: 0.9563 - val_loss: 1.6884 - val_acc: 0.6594\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9589\n",
      "Epoch 00032: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1302 - acc: 0.9589 - val_loss: 1.6870 - val_acc: 0.6557\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9596\n",
      "Epoch 00033: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1258 - acc: 0.9596 - val_loss: 1.6750 - val_acc: 0.6571\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9613\n",
      "Epoch 00034: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1235 - acc: 0.9613 - val_loss: 1.5808 - val_acc: 0.6664\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9607\n",
      "Epoch 00035: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1219 - acc: 0.9607 - val_loss: 1.6945 - val_acc: 0.6532\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9617\n",
      "Epoch 00036: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1162 - acc: 0.9617 - val_loss: 1.7911 - val_acc: 0.6422\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9648\n",
      "Epoch 00037: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1130 - acc: 0.9648 - val_loss: 1.6920 - val_acc: 0.6622\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9640\n",
      "Epoch 00038: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1125 - acc: 0.9639 - val_loss: 1.6871 - val_acc: 0.6550\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9618\n",
      "Epoch 00039: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1182 - acc: 0.9617 - val_loss: 1.7420 - val_acc: 0.6573\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9653\n",
      "Epoch 00040: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1097 - acc: 0.9653 - val_loss: 1.6275 - val_acc: 0.6713\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9683\n",
      "Epoch 00041: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1004 - acc: 0.9683 - val_loss: 1.6644 - val_acc: 0.6608\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9671\n",
      "Epoch 00042: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1053 - acc: 0.9671 - val_loss: 1.7449 - val_acc: 0.6613\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9672\n",
      "Epoch 00043: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1082 - acc: 0.9672 - val_loss: 1.7600 - val_acc: 0.6592\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9686\n",
      "Epoch 00044: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0984 - acc: 0.9686 - val_loss: 1.7514 - val_acc: 0.6601\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9669\n",
      "Epoch 00045: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1085 - acc: 0.9669 - val_loss: 1.7546 - val_acc: 0.6695\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9708\n",
      "Epoch 00046: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0950 - acc: 0.9708 - val_loss: 1.8037 - val_acc: 0.6592\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9698\n",
      "Epoch 00047: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0948 - acc: 0.9698 - val_loss: 1.6935 - val_acc: 0.6704\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9715\n",
      "Epoch 00048: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0905 - acc: 0.9715 - val_loss: 1.7440 - val_acc: 0.6739\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9727\n",
      "Epoch 00049: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0889 - acc: 0.9727 - val_loss: 1.7674 - val_acc: 0.6699\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9707\n",
      "Epoch 00050: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0950 - acc: 0.9707 - val_loss: 1.6790 - val_acc: 0.6785\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9741\n",
      "Epoch 00051: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0840 - acc: 0.9741 - val_loss: 1.8192 - val_acc: 0.6622\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9722\n",
      "Epoch 00052: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0874 - acc: 0.9722 - val_loss: 1.9910 - val_acc: 0.6443\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9749\n",
      "Epoch 00053: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0830 - acc: 0.9749 - val_loss: 1.7775 - val_acc: 0.6795\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9755\n",
      "Epoch 00054: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0798 - acc: 0.9755 - val_loss: 1.7277 - val_acc: 0.6720\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9732\n",
      "Epoch 00055: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0866 - acc: 0.9732 - val_loss: 1.7787 - val_acc: 0.6758\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9739\n",
      "Epoch 00056: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0836 - acc: 0.9739 - val_loss: 3.6478 - val_acc: 0.4880\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9765\n",
      "Epoch 00057: val_loss did not improve from 1.28756\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0786 - acc: 0.9764 - val_loss: 1.8486 - val_acc: 0.6627\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 637us/sample - loss: 1.3985 - acc: 0.5985\n",
      "Loss: 1.3984589152123204 Accuracy: 0.5985462\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1453 - acc: 0.3645\n",
      "Epoch 00001: val_loss improved from inf to 1.53033, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_5_conv_checkpoint/001-1.5303.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 2.1451 - acc: 0.3645 - val_loss: 1.5303 - val_acc: 0.5297\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3749 - acc: 0.5683\n",
      "Epoch 00002: val_loss improved from 1.53033 to 1.47438, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_5_conv_checkpoint/002-1.4744.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 1.3748 - acc: 0.5683 - val_loss: 1.4744 - val_acc: 0.5558\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1122 - acc: 0.6517\n",
      "Epoch 00003: val_loss improved from 1.47438 to 1.21720, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_5_conv_checkpoint/003-1.2172.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 1.1122 - acc: 0.6517 - val_loss: 1.2172 - val_acc: 0.6210\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9324 - acc: 0.7076\n",
      "Epoch 00004: val_loss improved from 1.21720 to 1.16455, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_5_conv_checkpoint/004-1.1645.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.9327 - acc: 0.7075 - val_loss: 1.1645 - val_acc: 0.6485\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7957 - acc: 0.7473\n",
      "Epoch 00005: val_loss did not improve from 1.16455\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.7957 - acc: 0.7473 - val_loss: 1.1754 - val_acc: 0.6513\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6737 - acc: 0.7855\n",
      "Epoch 00006: val_loss did not improve from 1.16455\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.6736 - acc: 0.7855 - val_loss: 1.1954 - val_acc: 0.6389\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5773 - acc: 0.8135\n",
      "Epoch 00007: val_loss did not improve from 1.16455\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.5774 - acc: 0.8134 - val_loss: 1.1928 - val_acc: 0.6634\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5051 - acc: 0.8356\n",
      "Epoch 00008: val_loss did not improve from 1.16455\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.5052 - acc: 0.8356 - val_loss: 1.2812 - val_acc: 0.6394\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4379 - acc: 0.8579\n",
      "Epoch 00009: val_loss did not improve from 1.16455\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.4379 - acc: 0.8579 - val_loss: 1.4382 - val_acc: 0.6112\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3797 - acc: 0.8748\n",
      "Epoch 00010: val_loss improved from 1.16455 to 1.16180, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_5_conv_checkpoint/010-1.1618.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.3797 - acc: 0.8748 - val_loss: 1.1618 - val_acc: 0.6944\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3407 - acc: 0.8890\n",
      "Epoch 00011: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.3407 - acc: 0.8890 - val_loss: 1.2520 - val_acc: 0.6834\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3119 - acc: 0.8984\n",
      "Epoch 00012: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.3119 - acc: 0.8984 - val_loss: 1.3691 - val_acc: 0.6501\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2843 - acc: 0.9077\n",
      "Epoch 00013: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2843 - acc: 0.9077 - val_loss: 1.2595 - val_acc: 0.6816\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2584 - acc: 0.9164\n",
      "Epoch 00014: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2585 - acc: 0.9164 - val_loss: 1.3711 - val_acc: 0.6795\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2328 - acc: 0.9251\n",
      "Epoch 00015: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2328 - acc: 0.9251 - val_loss: 1.2056 - val_acc: 0.7039\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2230 - acc: 0.9281\n",
      "Epoch 00016: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2230 - acc: 0.9281 - val_loss: 1.2828 - val_acc: 0.6881\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2072 - acc: 0.9320\n",
      "Epoch 00017: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2073 - acc: 0.9319 - val_loss: 1.2807 - val_acc: 0.6844\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9364\n",
      "Epoch 00018: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1979 - acc: 0.9363 - val_loss: 1.3676 - val_acc: 0.6956\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9388\n",
      "Epoch 00019: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1920 - acc: 0.9388 - val_loss: 1.4502 - val_acc: 0.6818\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.9431\n",
      "Epoch 00020: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1765 - acc: 0.9431 - val_loss: 1.6485 - val_acc: 0.6357\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1717 - acc: 0.9449\n",
      "Epoch 00021: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1720 - acc: 0.9448 - val_loss: 1.9841 - val_acc: 0.5993\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1534 - acc: 0.9506\n",
      "Epoch 00022: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1534 - acc: 0.9506 - val_loss: 1.3985 - val_acc: 0.6923\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9530\n",
      "Epoch 00023: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1479 - acc: 0.9530 - val_loss: 1.3913 - val_acc: 0.6925\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9560\n",
      "Epoch 00024: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1383 - acc: 0.9560 - val_loss: 1.3844 - val_acc: 0.7098\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9522\n",
      "Epoch 00025: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1452 - acc: 0.9522 - val_loss: 1.4537 - val_acc: 0.6986\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9566\n",
      "Epoch 00026: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1357 - acc: 0.9566 - val_loss: 1.4368 - val_acc: 0.7011\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9588\n",
      "Epoch 00027: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1286 - acc: 0.9588 - val_loss: 1.4273 - val_acc: 0.7049\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9587\n",
      "Epoch 00028: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1267 - acc: 0.9586 - val_loss: 1.4590 - val_acc: 0.7032\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9607\n",
      "Epoch 00029: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1189 - acc: 0.9607 - val_loss: 1.3803 - val_acc: 0.7184\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9633\n",
      "Epoch 00030: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1163 - acc: 0.9633 - val_loss: 1.7053 - val_acc: 0.6569\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9635\n",
      "Epoch 00031: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1138 - acc: 0.9635 - val_loss: 1.7968 - val_acc: 0.6380\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9646\n",
      "Epoch 00032: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1115 - acc: 0.9646 - val_loss: 1.5968 - val_acc: 0.6911\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9651\n",
      "Epoch 00033: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1104 - acc: 0.9651 - val_loss: 1.3569 - val_acc: 0.7265\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9681\n",
      "Epoch 00034: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1001 - acc: 0.9680 - val_loss: 1.4110 - val_acc: 0.7184\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9668\n",
      "Epoch 00035: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1035 - acc: 0.9668 - val_loss: 1.4709 - val_acc: 0.7077\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9683\n",
      "Epoch 00036: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1017 - acc: 0.9683 - val_loss: 1.9951 - val_acc: 0.6282\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9698\n",
      "Epoch 00037: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0949 - acc: 0.9698 - val_loss: 1.5185 - val_acc: 0.7018\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9710\n",
      "Epoch 00038: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0896 - acc: 0.9710 - val_loss: 1.5332 - val_acc: 0.6981\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9714\n",
      "Epoch 00039: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0933 - acc: 0.9714 - val_loss: 2.0878 - val_acc: 0.6259\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9704\n",
      "Epoch 00040: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0951 - acc: 0.9704 - val_loss: 1.4570 - val_acc: 0.7086\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9744\n",
      "Epoch 00041: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0836 - acc: 0.9744 - val_loss: 1.4153 - val_acc: 0.7303\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9726\n",
      "Epoch 00042: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0875 - acc: 0.9726 - val_loss: 1.4249 - val_acc: 0.7270\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9743\n",
      "Epoch 00043: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0823 - acc: 0.9743 - val_loss: 1.7442 - val_acc: 0.6781\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9757\n",
      "Epoch 00044: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0784 - acc: 0.9756 - val_loss: 1.4417 - val_acc: 0.7263\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9741\n",
      "Epoch 00045: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0806 - acc: 0.9741 - val_loss: 2.1147 - val_acc: 0.6396\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9754\n",
      "Epoch 00046: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0806 - acc: 0.9754 - val_loss: 1.5916 - val_acc: 0.7072\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9740\n",
      "Epoch 00047: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0836 - acc: 0.9739 - val_loss: 2.7552 - val_acc: 0.5828\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9771\n",
      "Epoch 00048: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0723 - acc: 0.9771 - val_loss: 1.6906 - val_acc: 0.7039\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9745\n",
      "Epoch 00049: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0826 - acc: 0.9745 - val_loss: 1.4329 - val_acc: 0.7354\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9780\n",
      "Epoch 00050: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0732 - acc: 0.9780 - val_loss: 2.5079 - val_acc: 0.6157\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9761\n",
      "Epoch 00051: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0787 - acc: 0.9761 - val_loss: 1.5547 - val_acc: 0.7140\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9770\n",
      "Epoch 00052: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0722 - acc: 0.9770 - val_loss: 1.4908 - val_acc: 0.7198\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9794\n",
      "Epoch 00053: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0687 - acc: 0.9794 - val_loss: 1.4836 - val_acc: 0.7221\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9778\n",
      "Epoch 00054: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0729 - acc: 0.9778 - val_loss: 1.4851 - val_acc: 0.7331\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9774\n",
      "Epoch 00055: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0719 - acc: 0.9774 - val_loss: 2.2618 - val_acc: 0.6459\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9788\n",
      "Epoch 00056: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0682 - acc: 0.9788 - val_loss: 1.6794 - val_acc: 0.6983\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9786\n",
      "Epoch 00057: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0707 - acc: 0.9786 - val_loss: 1.5723 - val_acc: 0.7142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9803\n",
      "Epoch 00058: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0649 - acc: 0.9803 - val_loss: 1.5649 - val_acc: 0.7149\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9810\n",
      "Epoch 00059: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0626 - acc: 0.9810 - val_loss: 1.6654 - val_acc: 0.7095\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9791\n",
      "Epoch 00060: val_loss did not improve from 1.16180\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0672 - acc: 0.9791 - val_loss: 1.5352 - val_acc: 0.7216\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 650us/sample - loss: 1.3318 - acc: 0.6422\n",
      "Loss: 1.3317909630659586 Accuracy: 0.64215994\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1095 - acc: 0.3631\n",
      "Epoch 00001: val_loss improved from inf to 1.70086, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_6_conv_checkpoint/001-1.7009.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 2.1094 - acc: 0.3631 - val_loss: 1.7009 - val_acc: 0.4573\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3837 - acc: 0.5738\n",
      "Epoch 00002: val_loss improved from 1.70086 to 1.16782, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_6_conv_checkpoint/002-1.1678.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 1.3839 - acc: 0.5738 - val_loss: 1.1678 - val_acc: 0.6292\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1279 - acc: 0.6530\n",
      "Epoch 00003: val_loss improved from 1.16782 to 0.97426, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_6_conv_checkpoint/003-0.9743.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 1.1279 - acc: 0.6530 - val_loss: 0.9743 - val_acc: 0.7126\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9833 - acc: 0.6986\n",
      "Epoch 00004: val_loss improved from 0.97426 to 0.96210, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_6_conv_checkpoint/004-0.9621.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.9834 - acc: 0.6985 - val_loss: 0.9621 - val_acc: 0.7116\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8835 - acc: 0.7291\n",
      "Epoch 00005: val_loss improved from 0.96210 to 0.90324, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_6_conv_checkpoint/005-0.9032.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.8837 - acc: 0.7291 - val_loss: 0.9032 - val_acc: 0.7361\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8000 - acc: 0.7549\n",
      "Epoch 00006: val_loss did not improve from 0.90324\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.8001 - acc: 0.7549 - val_loss: 1.3131 - val_acc: 0.6315\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7228 - acc: 0.7803\n",
      "Epoch 00007: val_loss improved from 0.90324 to 0.84144, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_6_conv_checkpoint/007-0.8414.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.7228 - acc: 0.7803 - val_loss: 0.8414 - val_acc: 0.7566\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6475 - acc: 0.8020\n",
      "Epoch 00008: val_loss did not improve from 0.84144\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.6475 - acc: 0.8020 - val_loss: 0.9463 - val_acc: 0.7282\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5991 - acc: 0.8137\n",
      "Epoch 00009: val_loss improved from 0.84144 to 0.82055, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_6_conv_checkpoint/009-0.8206.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.5991 - acc: 0.8137 - val_loss: 0.8206 - val_acc: 0.7638\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5410 - acc: 0.8323\n",
      "Epoch 00010: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.5417 - acc: 0.8322 - val_loss: 0.8709 - val_acc: 0.7545\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5136 - acc: 0.8420\n",
      "Epoch 00011: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.5137 - acc: 0.8420 - val_loss: 0.9623 - val_acc: 0.7319\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4563 - acc: 0.8578\n",
      "Epoch 00012: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.4564 - acc: 0.8577 - val_loss: 0.8491 - val_acc: 0.7708\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4334 - acc: 0.8640\n",
      "Epoch 00013: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.4333 - acc: 0.8640 - val_loss: 0.8930 - val_acc: 0.7566\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3984 - acc: 0.8739\n",
      "Epoch 00014: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.3985 - acc: 0.8738 - val_loss: 0.8217 - val_acc: 0.7699\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3688 - acc: 0.8855\n",
      "Epoch 00015: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.3687 - acc: 0.8856 - val_loss: 0.9605 - val_acc: 0.7473\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3430 - acc: 0.8916\n",
      "Epoch 00016: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.3431 - acc: 0.8916 - val_loss: 0.8550 - val_acc: 0.7664\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3246 - acc: 0.8952\n",
      "Epoch 00017: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.3246 - acc: 0.8953 - val_loss: 0.8390 - val_acc: 0.7734\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.9055\n",
      "Epoch 00018: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.2981 - acc: 0.9055 - val_loss: 0.8735 - val_acc: 0.7661\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2906 - acc: 0.9052\n",
      "Epoch 00019: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.2906 - acc: 0.9053 - val_loss: 0.8264 - val_acc: 0.7759\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2685 - acc: 0.9148\n",
      "Epoch 00020: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.2686 - acc: 0.9147 - val_loss: 0.8325 - val_acc: 0.7703\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2568 - acc: 0.9185\n",
      "Epoch 00021: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.2569 - acc: 0.9185 - val_loss: 0.8893 - val_acc: 0.7696\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2419 - acc: 0.9233\n",
      "Epoch 00022: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.2419 - acc: 0.9233 - val_loss: 0.9245 - val_acc: 0.7657\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.9238\n",
      "Epoch 00023: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.2386 - acc: 0.9238 - val_loss: 0.8805 - val_acc: 0.7834\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2152 - acc: 0.9314\n",
      "Epoch 00024: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.2153 - acc: 0.9313 - val_loss: 0.9837 - val_acc: 0.7582\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9307\n",
      "Epoch 00025: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.2174 - acc: 0.9307 - val_loss: 0.8446 - val_acc: 0.7922\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2118 - acc: 0.9332\n",
      "Epoch 00026: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.2118 - acc: 0.9332 - val_loss: 0.9078 - val_acc: 0.7831\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9374\n",
      "Epoch 00027: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1935 - acc: 0.9373 - val_loss: 0.9512 - val_acc: 0.7668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2028 - acc: 0.9356\n",
      "Epoch 00028: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.2028 - acc: 0.9356 - val_loss: 0.8967 - val_acc: 0.7871\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1798 - acc: 0.9421\n",
      "Epoch 00029: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1798 - acc: 0.9421 - val_loss: 0.8665 - val_acc: 0.7927\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1765 - acc: 0.9430\n",
      "Epoch 00030: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1765 - acc: 0.9430 - val_loss: 0.8826 - val_acc: 0.7852\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1732 - acc: 0.9431\n",
      "Epoch 00031: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1732 - acc: 0.9431 - val_loss: 0.9080 - val_acc: 0.7801\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1667 - acc: 0.9478\n",
      "Epoch 00032: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1667 - acc: 0.9478 - val_loss: 0.8822 - val_acc: 0.7883\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1618 - acc: 0.9476\n",
      "Epoch 00033: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1618 - acc: 0.9476 - val_loss: 0.8643 - val_acc: 0.8001\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1611 - acc: 0.9489\n",
      "Epoch 00034: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1611 - acc: 0.9489 - val_loss: 0.9690 - val_acc: 0.7757\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9526\n",
      "Epoch 00035: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1486 - acc: 0.9526 - val_loss: 0.8944 - val_acc: 0.7894\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9502\n",
      "Epoch 00036: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1527 - acc: 0.9502 - val_loss: 0.8894 - val_acc: 0.7973\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9525\n",
      "Epoch 00037: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1476 - acc: 0.9525 - val_loss: 1.0660 - val_acc: 0.7687\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1443 - acc: 0.9536\n",
      "Epoch 00038: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1444 - acc: 0.9536 - val_loss: 1.0693 - val_acc: 0.7561\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9562\n",
      "Epoch 00039: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1392 - acc: 0.9562 - val_loss: 0.9765 - val_acc: 0.7831\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9602\n",
      "Epoch 00040: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1301 - acc: 0.9602 - val_loss: 0.9588 - val_acc: 0.7876\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9579\n",
      "Epoch 00041: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1293 - acc: 0.9579 - val_loss: 0.8924 - val_acc: 0.8025\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9593\n",
      "Epoch 00042: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1265 - acc: 0.9593 - val_loss: 1.0003 - val_acc: 0.7862\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9599\n",
      "Epoch 00043: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1267 - acc: 0.9599 - val_loss: 1.0487 - val_acc: 0.7745\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9600\n",
      "Epoch 00044: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1254 - acc: 0.9600 - val_loss: 0.9483 - val_acc: 0.7932\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9615\n",
      "Epoch 00045: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1214 - acc: 0.9615 - val_loss: 1.0076 - val_acc: 0.7843\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9640\n",
      "Epoch 00046: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1151 - acc: 0.9639 - val_loss: 0.9772 - val_acc: 0.7864\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9654\n",
      "Epoch 00047: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1106 - acc: 0.9654 - val_loss: 1.0207 - val_acc: 0.7713\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9657\n",
      "Epoch 00048: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1089 - acc: 0.9656 - val_loss: 1.0061 - val_acc: 0.7827\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9620\n",
      "Epoch 00049: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1184 - acc: 0.9620 - val_loss: 0.9172 - val_acc: 0.7976\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9665\n",
      "Epoch 00050: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1062 - acc: 0.9666 - val_loss: 0.9942 - val_acc: 0.7929\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9664\n",
      "Epoch 00051: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1078 - acc: 0.9664 - val_loss: 0.9568 - val_acc: 0.7987\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9670\n",
      "Epoch 00052: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1071 - acc: 0.9670 - val_loss: 1.0894 - val_acc: 0.7708\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9687\n",
      "Epoch 00053: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1026 - acc: 0.9687 - val_loss: 0.9789 - val_acc: 0.7920\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9655\n",
      "Epoch 00054: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1091 - acc: 0.9655 - val_loss: 0.9588 - val_acc: 0.8011\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9683\n",
      "Epoch 00055: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1001 - acc: 0.9683 - val_loss: 1.0045 - val_acc: 0.7913\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9679\n",
      "Epoch 00056: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1004 - acc: 0.9679 - val_loss: 0.9730 - val_acc: 0.8076\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9692\n",
      "Epoch 00057: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0966 - acc: 0.9692 - val_loss: 0.9367 - val_acc: 0.7987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9723\n",
      "Epoch 00058: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0904 - acc: 0.9723 - val_loss: 1.0321 - val_acc: 0.7880\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9708\n",
      "Epoch 00059: val_loss did not improve from 0.82055\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0922 - acc: 0.9708 - val_loss: 1.0326 - val_acc: 0.7820\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 692us/sample - loss: 0.8959 - acc: 0.7481\n",
      "Loss: 0.8959385441471112 Accuracy: 0.74807894\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1358 - acc: 0.3452\n",
      "Epoch 00001: val_loss improved from inf to 1.49942, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_7_conv_checkpoint/001-1.4994.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.1356 - acc: 0.3452 - val_loss: 1.4994 - val_acc: 0.5076\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3457 - acc: 0.5744\n",
      "Epoch 00002: val_loss improved from 1.49942 to 1.05996, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_7_conv_checkpoint/002-1.0600.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 1.3459 - acc: 0.5744 - val_loss: 1.0600 - val_acc: 0.6744\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1043 - acc: 0.6558\n",
      "Epoch 00003: val_loss improved from 1.05996 to 0.91729, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_7_conv_checkpoint/003-0.9173.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 1.1043 - acc: 0.6558 - val_loss: 0.9173 - val_acc: 0.7214\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9472 - acc: 0.7092\n",
      "Epoch 00004: val_loss did not improve from 0.91729\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.9472 - acc: 0.7092 - val_loss: 1.0921 - val_acc: 0.6790\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8588 - acc: 0.7396\n",
      "Epoch 00005: val_loss improved from 0.91729 to 0.74603, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_7_conv_checkpoint/005-0.7460.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.8589 - acc: 0.7395 - val_loss: 0.7460 - val_acc: 0.7803\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7873 - acc: 0.7626\n",
      "Epoch 00006: val_loss did not improve from 0.74603\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.7875 - acc: 0.7625 - val_loss: 0.7475 - val_acc: 0.7838\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7305 - acc: 0.7788\n",
      "Epoch 00007: val_loss did not improve from 0.74603\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.7306 - acc: 0.7787 - val_loss: 0.7607 - val_acc: 0.7855\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6757 - acc: 0.7970\n",
      "Epoch 00008: val_loss improved from 0.74603 to 0.66885, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_7_conv_checkpoint/008-0.6689.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.6758 - acc: 0.7970 - val_loss: 0.6689 - val_acc: 0.8132\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6392 - acc: 0.8075\n",
      "Epoch 00009: val_loss did not improve from 0.66885\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.6393 - acc: 0.8075 - val_loss: 0.6868 - val_acc: 0.8050\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5991 - acc: 0.8182\n",
      "Epoch 00010: val_loss did not improve from 0.66885\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.5992 - acc: 0.8181 - val_loss: 0.6717 - val_acc: 0.8015\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5641 - acc: 0.8326\n",
      "Epoch 00011: val_loss did not improve from 0.66885\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.5640 - acc: 0.8326 - val_loss: 0.7811 - val_acc: 0.7752\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5304 - acc: 0.8421\n",
      "Epoch 00012: val_loss improved from 0.66885 to 0.63464, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_7_conv_checkpoint/012-0.6346.hdf5\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.5303 - acc: 0.8421 - val_loss: 0.6346 - val_acc: 0.8199\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5031 - acc: 0.8479\n",
      "Epoch 00013: val_loss did not improve from 0.63464\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.5031 - acc: 0.8479 - val_loss: 0.7007 - val_acc: 0.8085\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4818 - acc: 0.8549\n",
      "Epoch 00014: val_loss improved from 0.63464 to 0.63378, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_7_conv_checkpoint/014-0.6338.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.4818 - acc: 0.8549 - val_loss: 0.6338 - val_acc: 0.8218\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4514 - acc: 0.8626\n",
      "Epoch 00015: val_loss did not improve from 0.63378\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.4514 - acc: 0.8627 - val_loss: 0.6477 - val_acc: 0.8230\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4287 - acc: 0.8692\n",
      "Epoch 00016: val_loss did not improve from 0.63378\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.4287 - acc: 0.8692 - val_loss: 0.6641 - val_acc: 0.8183\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4190 - acc: 0.8732\n",
      "Epoch 00017: val_loss did not improve from 0.63378\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.4190 - acc: 0.8732 - val_loss: 1.1559 - val_acc: 0.7114\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3916 - acc: 0.8804\n",
      "Epoch 00018: val_loss did not improve from 0.63378\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.3916 - acc: 0.8804 - val_loss: 0.6628 - val_acc: 0.8125\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3735 - acc: 0.8861\n",
      "Epoch 00019: val_loss did not improve from 0.63378\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.3738 - acc: 0.8860 - val_loss: 0.7005 - val_acc: 0.8020\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3628 - acc: 0.8864\n",
      "Epoch 00020: val_loss improved from 0.63378 to 0.59417, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_7_conv_checkpoint/020-0.5942.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3630 - acc: 0.8863 - val_loss: 0.5942 - val_acc: 0.8316\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3373 - acc: 0.8954\n",
      "Epoch 00021: val_loss did not improve from 0.59417\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.3373 - acc: 0.8954 - val_loss: 0.6755 - val_acc: 0.8202\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3224 - acc: 0.9002\n",
      "Epoch 00022: val_loss did not improve from 0.59417\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3224 - acc: 0.9002 - val_loss: 0.6858 - val_acc: 0.8113\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3145 - acc: 0.9017\n",
      "Epoch 00023: val_loss improved from 0.59417 to 0.57785, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_7_conv_checkpoint/023-0.5779.hdf5\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.3145 - acc: 0.9017 - val_loss: 0.5779 - val_acc: 0.8374\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2963 - acc: 0.9084\n",
      "Epoch 00024: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2966 - acc: 0.9083 - val_loss: 0.6453 - val_acc: 0.8344\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2897 - acc: 0.9114\n",
      "Epoch 00025: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2901 - acc: 0.9113 - val_loss: 0.6723 - val_acc: 0.8279\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2757 - acc: 0.9150\n",
      "Epoch 00026: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2757 - acc: 0.9150 - val_loss: 0.6444 - val_acc: 0.8297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2620 - acc: 0.9190\n",
      "Epoch 00027: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2621 - acc: 0.9190 - val_loss: 0.6102 - val_acc: 0.8355\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2572 - acc: 0.9197\n",
      "Epoch 00028: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2571 - acc: 0.9197 - val_loss: 0.8480 - val_acc: 0.7880\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2458 - acc: 0.9241\n",
      "Epoch 00029: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2459 - acc: 0.9241 - val_loss: 0.6291 - val_acc: 0.8334\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2431 - acc: 0.9236\n",
      "Epoch 00030: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2431 - acc: 0.9236 - val_loss: 0.6606 - val_acc: 0.8272\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2294 - acc: 0.9279\n",
      "Epoch 00031: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2293 - acc: 0.9279 - val_loss: 0.6335 - val_acc: 0.8351\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2227 - acc: 0.9316\n",
      "Epoch 00032: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2227 - acc: 0.9316 - val_loss: 0.8491 - val_acc: 0.7983\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9301\n",
      "Epoch 00033: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2200 - acc: 0.9301 - val_loss: 0.6673 - val_acc: 0.8239\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2064 - acc: 0.9344\n",
      "Epoch 00034: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2065 - acc: 0.9344 - val_loss: 0.6724 - val_acc: 0.8237\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2093 - acc: 0.9344\n",
      "Epoch 00035: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2093 - acc: 0.9344 - val_loss: 0.6451 - val_acc: 0.8339\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1989 - acc: 0.9365\n",
      "Epoch 00036: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1989 - acc: 0.9365 - val_loss: 0.6128 - val_acc: 0.8421\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1874 - acc: 0.9419\n",
      "Epoch 00037: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1874 - acc: 0.9419 - val_loss: 0.6250 - val_acc: 0.8390\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1887 - acc: 0.9409\n",
      "Epoch 00038: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1888 - acc: 0.9409 - val_loss: 0.6718 - val_acc: 0.8190\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1844 - acc: 0.9411\n",
      "Epoch 00039: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1846 - acc: 0.9410 - val_loss: 0.6618 - val_acc: 0.8330\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9413\n",
      "Epoch 00040: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1893 - acc: 0.9413 - val_loss: 0.7306 - val_acc: 0.8123\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1697 - acc: 0.9455\n",
      "Epoch 00041: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1697 - acc: 0.9456 - val_loss: 0.6592 - val_acc: 0.8309\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1700 - acc: 0.9463\n",
      "Epoch 00042: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1701 - acc: 0.9462 - val_loss: 0.8002 - val_acc: 0.8078\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9486\n",
      "Epoch 00043: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1664 - acc: 0.9486 - val_loss: 0.6344 - val_acc: 0.8365\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9506\n",
      "Epoch 00044: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1576 - acc: 0.9506 - val_loss: 0.6412 - val_acc: 0.8411\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9509\n",
      "Epoch 00045: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1551 - acc: 0.9509 - val_loss: 0.6844 - val_acc: 0.8388\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9512\n",
      "Epoch 00046: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1530 - acc: 0.9512 - val_loss: 0.6759 - val_acc: 0.8351\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1477 - acc: 0.9546\n",
      "Epoch 00047: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1478 - acc: 0.9545 - val_loss: 0.7277 - val_acc: 0.8244\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9523\n",
      "Epoch 00048: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1521 - acc: 0.9522 - val_loss: 0.7004 - val_acc: 0.8330\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9537\n",
      "Epoch 00049: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1476 - acc: 0.9537 - val_loss: 0.6848 - val_acc: 0.8353\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9571\n",
      "Epoch 00050: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1387 - acc: 0.9572 - val_loss: 0.7180 - val_acc: 0.8323\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9554\n",
      "Epoch 00051: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1419 - acc: 0.9554 - val_loss: 0.6814 - val_acc: 0.8353\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9585\n",
      "Epoch 00052: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1342 - acc: 0.9585 - val_loss: 0.6470 - val_acc: 0.8470\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9619\n",
      "Epoch 00053: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1258 - acc: 0.9619 - val_loss: 0.7142 - val_acc: 0.8316\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9585\n",
      "Epoch 00054: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1341 - acc: 0.9585 - val_loss: 0.7721 - val_acc: 0.8202\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9603\n",
      "Epoch 00055: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1289 - acc: 0.9602 - val_loss: 0.8094 - val_acc: 0.8176\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9595\n",
      "Epoch 00056: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1275 - acc: 0.9595 - val_loss: 0.6506 - val_acc: 0.8446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9629\n",
      "Epoch 00057: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1181 - acc: 0.9629 - val_loss: 0.7774 - val_acc: 0.8164\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9607\n",
      "Epoch 00058: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1251 - acc: 0.9607 - val_loss: 0.7533 - val_acc: 0.8374\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9634\n",
      "Epoch 00059: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1180 - acc: 0.9634 - val_loss: 0.8261 - val_acc: 0.8160\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9617\n",
      "Epoch 00060: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1249 - acc: 0.9617 - val_loss: 0.7305 - val_acc: 0.8328\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9626\n",
      "Epoch 00061: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1171 - acc: 0.9626 - val_loss: 0.7166 - val_acc: 0.8355\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9656\n",
      "Epoch 00062: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1134 - acc: 0.9655 - val_loss: 0.7137 - val_acc: 0.8418\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9636\n",
      "Epoch 00063: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1153 - acc: 0.9636 - val_loss: 0.6403 - val_acc: 0.8532\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9639\n",
      "Epoch 00064: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1151 - acc: 0.9639 - val_loss: 0.6765 - val_acc: 0.8453\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9658\n",
      "Epoch 00065: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1133 - acc: 0.9658 - val_loss: 0.6842 - val_acc: 0.8395\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9669\n",
      "Epoch 00066: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1076 - acc: 0.9669 - val_loss: 0.6208 - val_acc: 0.8549\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9676\n",
      "Epoch 00067: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1068 - acc: 0.9676 - val_loss: 0.6574 - val_acc: 0.8512\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9691\n",
      "Epoch 00068: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1017 - acc: 0.9691 - val_loss: 0.6774 - val_acc: 0.8488\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9682\n",
      "Epoch 00069: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1052 - acc: 0.9682 - val_loss: 0.9567 - val_acc: 0.7980\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9682\n",
      "Epoch 00070: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1055 - acc: 0.9682 - val_loss: 0.7169 - val_acc: 0.8411\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9699\n",
      "Epoch 00071: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0984 - acc: 0.9699 - val_loss: 0.7418 - val_acc: 0.8390\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9682\n",
      "Epoch 00072: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1029 - acc: 0.9681 - val_loss: 0.7540 - val_acc: 0.8369\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9710\n",
      "Epoch 00073: val_loss did not improve from 0.57785\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0977 - acc: 0.9710 - val_loss: 0.6690 - val_acc: 0.8495\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 795us/sample - loss: 0.6977 - acc: 0.8123\n",
      "Loss: 0.6976641787918186 Accuracy: 0.81225336\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3045 - acc: 0.3024\n",
      "Epoch 00001: val_loss improved from inf to 1.54671, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/001-1.5467.hdf5\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 2.3044 - acc: 0.3024 - val_loss: 1.5467 - val_acc: 0.5141\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4055 - acc: 0.5520\n",
      "Epoch 00002: val_loss improved from 1.54671 to 1.48371, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/002-1.4837.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 1.4054 - acc: 0.5520 - val_loss: 1.4837 - val_acc: 0.5416\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1202 - acc: 0.6480\n",
      "Epoch 00003: val_loss improved from 1.48371 to 0.85118, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/003-0.8512.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 1.1202 - acc: 0.6480 - val_loss: 0.8512 - val_acc: 0.7393\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9627 - acc: 0.7014\n",
      "Epoch 00004: val_loss improved from 0.85118 to 0.77901, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/004-0.7790.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.9628 - acc: 0.7014 - val_loss: 0.7790 - val_acc: 0.7708\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8572 - acc: 0.7371\n",
      "Epoch 00005: val_loss did not improve from 0.77901\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.8571 - acc: 0.7371 - val_loss: 0.8762 - val_acc: 0.7403\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7856 - acc: 0.7599\n",
      "Epoch 00006: val_loss improved from 0.77901 to 0.72403, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/006-0.7240.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.7857 - acc: 0.7599 - val_loss: 0.7240 - val_acc: 0.7945\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7221 - acc: 0.7809\n",
      "Epoch 00007: val_loss improved from 0.72403 to 0.68427, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/007-0.6843.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.7221 - acc: 0.7809 - val_loss: 0.6843 - val_acc: 0.8048\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6705 - acc: 0.7996\n",
      "Epoch 00008: val_loss improved from 0.68427 to 0.66939, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/008-0.6694.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.6705 - acc: 0.7996 - val_loss: 0.6694 - val_acc: 0.8064\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6272 - acc: 0.8137\n",
      "Epoch 00009: val_loss improved from 0.66939 to 0.58029, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/009-0.5803.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.6273 - acc: 0.8136 - val_loss: 0.5803 - val_acc: 0.8386\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5869 - acc: 0.8238\n",
      "Epoch 00010: val_loss did not improve from 0.58029\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.5870 - acc: 0.8238 - val_loss: 0.6085 - val_acc: 0.8297\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5526 - acc: 0.8335\n",
      "Epoch 00011: val_loss did not improve from 0.58029\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.5527 - acc: 0.8334 - val_loss: 0.6416 - val_acc: 0.8106\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5231 - acc: 0.8460\n",
      "Epoch 00012: val_loss improved from 0.58029 to 0.52439, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/012-0.5244.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.5230 - acc: 0.8460 - val_loss: 0.5244 - val_acc: 0.8530\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4963 - acc: 0.8524\n",
      "Epoch 00013: val_loss did not improve from 0.52439\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.4962 - acc: 0.8524 - val_loss: 0.7041 - val_acc: 0.8004\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4692 - acc: 0.8612\n",
      "Epoch 00014: val_loss did not improve from 0.52439\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.4694 - acc: 0.8612 - val_loss: 0.5521 - val_acc: 0.8474\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4520 - acc: 0.8639\n",
      "Epoch 00015: val_loss did not improve from 0.52439\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.4520 - acc: 0.8639 - val_loss: 0.5753 - val_acc: 0.8367\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4296 - acc: 0.8718\n",
      "Epoch 00016: val_loss improved from 0.52439 to 0.49929, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/016-0.4993.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.4296 - acc: 0.8718 - val_loss: 0.4993 - val_acc: 0.8605\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4035 - acc: 0.8789\n",
      "Epoch 00017: val_loss did not improve from 0.49929\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.4038 - acc: 0.8788 - val_loss: 0.5726 - val_acc: 0.8418\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3914 - acc: 0.8816\n",
      "Epoch 00018: val_loss did not improve from 0.49929\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3913 - acc: 0.8816 - val_loss: 0.5461 - val_acc: 0.8507\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3681 - acc: 0.8893\n",
      "Epoch 00019: val_loss did not improve from 0.49929\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3681 - acc: 0.8893 - val_loss: 0.6068 - val_acc: 0.8204\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3571 - acc: 0.8936\n",
      "Epoch 00020: val_loss did not improve from 0.49929\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3572 - acc: 0.8935 - val_loss: 0.6300 - val_acc: 0.8279\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3447 - acc: 0.8949\n",
      "Epoch 00021: val_loss improved from 0.49929 to 0.47020, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/021-0.4702.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.3447 - acc: 0.8949 - val_loss: 0.4702 - val_acc: 0.8684\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3347 - acc: 0.8990\n",
      "Epoch 00022: val_loss improved from 0.47020 to 0.43253, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/022-0.4325.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3347 - acc: 0.8990 - val_loss: 0.4325 - val_acc: 0.8817\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3126 - acc: 0.9059\n",
      "Epoch 00023: val_loss did not improve from 0.43253\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3126 - acc: 0.9059 - val_loss: 0.6015 - val_acc: 0.8346\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3076 - acc: 0.9067\n",
      "Epoch 00024: val_loss did not improve from 0.43253\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3077 - acc: 0.9066 - val_loss: 0.4677 - val_acc: 0.8772\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2992 - acc: 0.9083\n",
      "Epoch 00025: val_loss did not improve from 0.43253\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2992 - acc: 0.9083 - val_loss: 0.4765 - val_acc: 0.8726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2855 - acc: 0.9134\n",
      "Epoch 00026: val_loss did not improve from 0.43253\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2855 - acc: 0.9134 - val_loss: 0.4868 - val_acc: 0.8588\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2734 - acc: 0.9159\n",
      "Epoch 00027: val_loss improved from 0.43253 to 0.41827, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/027-0.4183.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.2734 - acc: 0.9159 - val_loss: 0.4183 - val_acc: 0.8884\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2708 - acc: 0.9182\n",
      "Epoch 00028: val_loss did not improve from 0.41827\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2709 - acc: 0.9181 - val_loss: 0.7480 - val_acc: 0.7934\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2526 - acc: 0.9227\n",
      "Epoch 00029: val_loss did not improve from 0.41827\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2527 - acc: 0.9227 - val_loss: 0.4231 - val_acc: 0.8826\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2504 - acc: 0.9228\n",
      "Epoch 00030: val_loss did not improve from 0.41827\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2507 - acc: 0.9227 - val_loss: 0.5254 - val_acc: 0.8609\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2429 - acc: 0.9237\n",
      "Epoch 00031: val_loss improved from 0.41827 to 0.40990, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/031-0.4099.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2429 - acc: 0.9237 - val_loss: 0.4099 - val_acc: 0.8870\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2344 - acc: 0.9275\n",
      "Epoch 00032: val_loss did not improve from 0.40990\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2344 - acc: 0.9275 - val_loss: 0.4874 - val_acc: 0.8661\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9288\n",
      "Epoch 00033: val_loss did not improve from 0.40990\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2263 - acc: 0.9288 - val_loss: 0.4193 - val_acc: 0.8889\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2169 - acc: 0.9320\n",
      "Epoch 00034: val_loss did not improve from 0.40990\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2170 - acc: 0.9320 - val_loss: 0.4101 - val_acc: 0.8845\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2122 - acc: 0.9341\n",
      "Epoch 00035: val_loss did not improve from 0.40990\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2123 - acc: 0.9341 - val_loss: 0.4693 - val_acc: 0.8812\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2081 - acc: 0.9338\n",
      "Epoch 00036: val_loss did not improve from 0.40990\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2082 - acc: 0.9338 - val_loss: 0.4573 - val_acc: 0.8807\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1990 - acc: 0.9365\n",
      "Epoch 00037: val_loss did not improve from 0.40990\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1992 - acc: 0.9365 - val_loss: 0.4189 - val_acc: 0.8891\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9339\n",
      "Epoch 00038: val_loss did not improve from 0.40990\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2080 - acc: 0.9339 - val_loss: 0.4761 - val_acc: 0.8675\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9395\n",
      "Epoch 00039: val_loss improved from 0.40990 to 0.40350, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/039-0.4035.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1926 - acc: 0.9395 - val_loss: 0.4035 - val_acc: 0.8952\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9429\n",
      "Epoch 00040: val_loss did not improve from 0.40350\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1813 - acc: 0.9429 - val_loss: 0.4517 - val_acc: 0.8870\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9424\n",
      "Epoch 00041: val_loss did not improve from 0.40350\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1833 - acc: 0.9423 - val_loss: 0.4410 - val_acc: 0.8838\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1732 - acc: 0.9474\n",
      "Epoch 00042: val_loss did not improve from 0.40350\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1732 - acc: 0.9474 - val_loss: 0.4135 - val_acc: 0.8926\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1707 - acc: 0.9455\n",
      "Epoch 00043: val_loss did not improve from 0.40350\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1707 - acc: 0.9456 - val_loss: 0.4312 - val_acc: 0.8905\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9498\n",
      "Epoch 00044: val_loss did not improve from 0.40350\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1613 - acc: 0.9498 - val_loss: 0.4702 - val_acc: 0.8798\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1618 - acc: 0.9473\n",
      "Epoch 00045: val_loss did not improve from 0.40350\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1623 - acc: 0.9472 - val_loss: 0.4390 - val_acc: 0.8884\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1650 - acc: 0.9490\n",
      "Epoch 00046: val_loss did not improve from 0.40350\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1650 - acc: 0.9490 - val_loss: 0.4359 - val_acc: 0.8901\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9519\n",
      "Epoch 00047: val_loss did not improve from 0.40350\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1566 - acc: 0.9519 - val_loss: 0.4246 - val_acc: 0.8947\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1585 - acc: 0.9476\n",
      "Epoch 00048: val_loss did not improve from 0.40350\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1586 - acc: 0.9476 - val_loss: 0.4094 - val_acc: 0.8989\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9504\n",
      "Epoch 00049: val_loss did not improve from 0.40350\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1530 - acc: 0.9504 - val_loss: 0.4591 - val_acc: 0.8866\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9544\n",
      "Epoch 00050: val_loss did not improve from 0.40350\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1421 - acc: 0.9544 - val_loss: 0.4707 - val_acc: 0.8835\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9545\n",
      "Epoch 00051: val_loss did not improve from 0.40350\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1420 - acc: 0.9545 - val_loss: 0.4856 - val_acc: 0.8877\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1423 - acc: 0.9552\n",
      "Epoch 00052: val_loss improved from 0.40350 to 0.40134, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv_checkpoint/052-0.4013.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1422 - acc: 0.9552 - val_loss: 0.4013 - val_acc: 0.8945\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9574\n",
      "Epoch 00053: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1323 - acc: 0.9574 - val_loss: 0.4751 - val_acc: 0.8877\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9582\n",
      "Epoch 00054: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1300 - acc: 0.9581 - val_loss: 0.4385 - val_acc: 0.8928\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9578\n",
      "Epoch 00055: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1308 - acc: 0.9578 - val_loss: 0.5382 - val_acc: 0.8756\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9600\n",
      "Epoch 00056: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1261 - acc: 0.9600 - val_loss: 0.4356 - val_acc: 0.8945\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9615\n",
      "Epoch 00057: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1245 - acc: 0.9615 - val_loss: 0.4428 - val_acc: 0.8970\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9620\n",
      "Epoch 00058: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1208 - acc: 0.9620 - val_loss: 0.4893 - val_acc: 0.8772\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9617\n",
      "Epoch 00059: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1212 - acc: 0.9617 - val_loss: 0.4708 - val_acc: 0.8898\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9606\n",
      "Epoch 00060: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1232 - acc: 0.9606 - val_loss: 0.4507 - val_acc: 0.8961\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9640\n",
      "Epoch 00061: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1155 - acc: 0.9640 - val_loss: 0.4318 - val_acc: 0.8917\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9653\n",
      "Epoch 00062: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1093 - acc: 0.9653 - val_loss: 0.4573 - val_acc: 0.8891\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9636\n",
      "Epoch 00063: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1127 - acc: 0.9636 - val_loss: 0.4230 - val_acc: 0.8931\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9654\n",
      "Epoch 00064: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1077 - acc: 0.9654 - val_loss: 0.4422 - val_acc: 0.8991\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9645\n",
      "Epoch 00065: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1083 - acc: 0.9645 - val_loss: 0.4792 - val_acc: 0.8882\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9658\n",
      "Epoch 00066: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1065 - acc: 0.9658 - val_loss: 0.4987 - val_acc: 0.8821\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9676\n",
      "Epoch 00067: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1028 - acc: 0.9676 - val_loss: 0.4377 - val_acc: 0.8984\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9646\n",
      "Epoch 00068: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1072 - acc: 0.9646 - val_loss: 0.4531 - val_acc: 0.8875\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9670\n",
      "Epoch 00069: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1048 - acc: 0.9670 - val_loss: 0.7521 - val_acc: 0.8339\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9671\n",
      "Epoch 00070: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1016 - acc: 0.9670 - val_loss: 0.4279 - val_acc: 0.8961\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9690\n",
      "Epoch 00071: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0992 - acc: 0.9690 - val_loss: 0.4339 - val_acc: 0.9010\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9688\n",
      "Epoch 00072: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0972 - acc: 0.9688 - val_loss: 0.4684 - val_acc: 0.8901\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9703\n",
      "Epoch 00073: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0932 - acc: 0.9703 - val_loss: 0.5127 - val_acc: 0.8826\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9724\n",
      "Epoch 00074: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0894 - acc: 0.9724 - val_loss: 0.4830 - val_acc: 0.8833\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9697\n",
      "Epoch 00075: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0944 - acc: 0.9697 - val_loss: 0.5843 - val_acc: 0.8649\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9711\n",
      "Epoch 00076: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0906 - acc: 0.9711 - val_loss: 0.5602 - val_acc: 0.8777\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9735\n",
      "Epoch 00077: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0849 - acc: 0.9735 - val_loss: 0.4793 - val_acc: 0.8901\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9698\n",
      "Epoch 00078: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0941 - acc: 0.9698 - val_loss: 0.4613 - val_acc: 0.8940\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9733\n",
      "Epoch 00079: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0842 - acc: 0.9733 - val_loss: 0.4660 - val_acc: 0.8908\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9735\n",
      "Epoch 00080: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0862 - acc: 0.9735 - val_loss: 0.4474 - val_acc: 0.8915\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9700\n",
      "Epoch 00081: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0937 - acc: 0.9700 - val_loss: 0.4654 - val_acc: 0.8938\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9734\n",
      "Epoch 00082: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0847 - acc: 0.9734 - val_loss: 0.4532 - val_acc: 0.9003\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9734\n",
      "Epoch 00083: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0845 - acc: 0.9734 - val_loss: 0.5042 - val_acc: 0.8877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9725\n",
      "Epoch 00084: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0879 - acc: 0.9725 - val_loss: 0.4077 - val_acc: 0.9059\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9752\n",
      "Epoch 00085: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0790 - acc: 0.9752 - val_loss: 0.4489 - val_acc: 0.8947\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9727\n",
      "Epoch 00086: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0849 - acc: 0.9727 - val_loss: 0.4839 - val_acc: 0.8921\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9755\n",
      "Epoch 00087: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0762 - acc: 0.9755 - val_loss: 0.5109 - val_acc: 0.8831\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9744\n",
      "Epoch 00088: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0799 - acc: 0.9744 - val_loss: 0.4427 - val_acc: 0.8952\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9771\n",
      "Epoch 00089: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0736 - acc: 0.9771 - val_loss: 0.5138 - val_acc: 0.8873\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9764\n",
      "Epoch 00090: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0741 - acc: 0.9764 - val_loss: 0.4986 - val_acc: 0.8889\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9739\n",
      "Epoch 00091: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0833 - acc: 0.9739 - val_loss: 0.5118 - val_acc: 0.8877\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9758\n",
      "Epoch 00092: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0744 - acc: 0.9757 - val_loss: 0.4398 - val_acc: 0.9029\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9761\n",
      "Epoch 00093: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0749 - acc: 0.9761 - val_loss: 0.4963 - val_acc: 0.8998\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9771\n",
      "Epoch 00094: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0736 - acc: 0.9771 - val_loss: 0.5085 - val_acc: 0.8896\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9782\n",
      "Epoch 00095: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0672 - acc: 0.9782 - val_loss: 0.4283 - val_acc: 0.8991\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9761\n",
      "Epoch 00096: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0728 - acc: 0.9761 - val_loss: 0.5079 - val_acc: 0.8970\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9790\n",
      "Epoch 00097: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0667 - acc: 0.9790 - val_loss: 0.4912 - val_acc: 0.8949\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9783\n",
      "Epoch 00098: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0690 - acc: 0.9783 - val_loss: 0.4581 - val_acc: 0.8984\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9766\n",
      "Epoch 00099: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0745 - acc: 0.9766 - val_loss: 0.4365 - val_acc: 0.9005\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9795\n",
      "Epoch 00100: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0663 - acc: 0.9795 - val_loss: 0.6041 - val_acc: 0.8747\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9790\n",
      "Epoch 00101: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0672 - acc: 0.9790 - val_loss: 0.5458 - val_acc: 0.8789\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9794\n",
      "Epoch 00102: val_loss did not improve from 0.40134\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0653 - acc: 0.9794 - val_loss: 0.4309 - val_acc: 0.9022\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 840us/sample - loss: 0.5010 - acc: 0.8779\n",
      "Loss: 0.5010117996023699 Accuracy: 0.87788165\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3276 - acc: 0.2970\n",
      "Epoch 00001: val_loss improved from inf to 1.53821, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/001-1.5382.hdf5\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 2.3276 - acc: 0.2971 - val_loss: 1.5382 - val_acc: 0.5132\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3552 - acc: 0.5711\n",
      "Epoch 00002: val_loss improved from 1.53821 to 1.11776, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/002-1.1178.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 1.3550 - acc: 0.5711 - val_loss: 1.1178 - val_acc: 0.6641\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0422 - acc: 0.6772\n",
      "Epoch 00003: val_loss improved from 1.11776 to 0.83021, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/003-0.8302.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 1.0423 - acc: 0.6772 - val_loss: 0.8302 - val_acc: 0.7594\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8729 - acc: 0.7338\n",
      "Epoch 00004: val_loss improved from 0.83021 to 0.80522, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/004-0.8052.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.8729 - acc: 0.7338 - val_loss: 0.8052 - val_acc: 0.7594\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7591 - acc: 0.7716\n",
      "Epoch 00005: val_loss improved from 0.80522 to 0.73801, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/005-0.7380.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.7591 - acc: 0.7716 - val_loss: 0.7380 - val_acc: 0.7978\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6822 - acc: 0.7957\n",
      "Epoch 00006: val_loss improved from 0.73801 to 0.71718, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/006-0.7172.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.6823 - acc: 0.7957 - val_loss: 0.7172 - val_acc: 0.7922\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6028 - acc: 0.8197\n",
      "Epoch 00007: val_loss improved from 0.71718 to 0.55537, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/007-0.5554.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.6033 - acc: 0.8197 - val_loss: 0.5554 - val_acc: 0.8458\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5561 - acc: 0.8366\n",
      "Epoch 00008: val_loss improved from 0.55537 to 0.50801, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/008-0.5080.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.5561 - acc: 0.8366 - val_loss: 0.5080 - val_acc: 0.8588\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5042 - acc: 0.8499\n",
      "Epoch 00009: val_loss did not improve from 0.50801\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.5044 - acc: 0.8498 - val_loss: 0.5517 - val_acc: 0.8449\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4639 - acc: 0.8627\n",
      "Epoch 00010: val_loss did not improve from 0.50801\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.4639 - acc: 0.8627 - val_loss: 0.6267 - val_acc: 0.8307\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4260 - acc: 0.8727\n",
      "Epoch 00011: val_loss improved from 0.50801 to 0.40947, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/011-0.4095.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.4260 - acc: 0.8727 - val_loss: 0.4095 - val_acc: 0.8847\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3879 - acc: 0.8843\n",
      "Epoch 00012: val_loss did not improve from 0.40947\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.3881 - acc: 0.8843 - val_loss: 0.4544 - val_acc: 0.8784\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3652 - acc: 0.8886\n",
      "Epoch 00013: val_loss improved from 0.40947 to 0.40665, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/013-0.4066.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.3652 - acc: 0.8886 - val_loss: 0.4066 - val_acc: 0.8861\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3386 - acc: 0.8987\n",
      "Epoch 00014: val_loss did not improve from 0.40665\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.3386 - acc: 0.8987 - val_loss: 0.8426 - val_acc: 0.7741\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3211 - acc: 0.9027\n",
      "Epoch 00015: val_loss did not improve from 0.40665\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.3211 - acc: 0.9027 - val_loss: 0.5146 - val_acc: 0.8516\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3039 - acc: 0.9095\n",
      "Epoch 00016: val_loss improved from 0.40665 to 0.39473, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/016-0.3947.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.3041 - acc: 0.9095 - val_loss: 0.3947 - val_acc: 0.8882\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2865 - acc: 0.9125\n",
      "Epoch 00017: val_loss did not improve from 0.39473\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.2865 - acc: 0.9125 - val_loss: 0.4087 - val_acc: 0.8905\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2708 - acc: 0.9177\n",
      "Epoch 00018: val_loss improved from 0.39473 to 0.35911, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/018-0.3591.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.2708 - acc: 0.9177 - val_loss: 0.3591 - val_acc: 0.9043\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2519 - acc: 0.9229\n",
      "Epoch 00019: val_loss improved from 0.35911 to 0.34508, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/019-0.3451.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.2519 - acc: 0.9229 - val_loss: 0.3451 - val_acc: 0.9126\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2378 - acc: 0.9266\n",
      "Epoch 00020: val_loss did not improve from 0.34508\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.2379 - acc: 0.9266 - val_loss: 0.3661 - val_acc: 0.9052\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2342 - acc: 0.9265\n",
      "Epoch 00021: val_loss improved from 0.34508 to 0.33479, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/021-0.3348.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.2344 - acc: 0.9265 - val_loss: 0.3348 - val_acc: 0.9140\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9308\n",
      "Epoch 00022: val_loss did not improve from 0.33479\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.2256 - acc: 0.9308 - val_loss: 0.3976 - val_acc: 0.8982\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9345\n",
      "Epoch 00023: val_loss did not improve from 0.33479\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.2106 - acc: 0.9345 - val_loss: 0.7105 - val_acc: 0.8246\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9388\n",
      "Epoch 00024: val_loss did not improve from 0.33479\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1981 - acc: 0.9388 - val_loss: 0.4006 - val_acc: 0.8901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1878 - acc: 0.9418\n",
      "Epoch 00025: val_loss did not improve from 0.33479\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1878 - acc: 0.9419 - val_loss: 0.4310 - val_acc: 0.8849\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1847 - acc: 0.9419\n",
      "Epoch 00026: val_loss did not improve from 0.33479\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1847 - acc: 0.9419 - val_loss: 0.4410 - val_acc: 0.8852\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9471\n",
      "Epoch 00027: val_loss improved from 0.33479 to 0.31758, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/027-0.3176.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1720 - acc: 0.9470 - val_loss: 0.3176 - val_acc: 0.9234\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1688 - acc: 0.9473\n",
      "Epoch 00028: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1688 - acc: 0.9473 - val_loss: 0.3971 - val_acc: 0.9031\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1586 - acc: 0.9509\n",
      "Epoch 00029: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1586 - acc: 0.9509 - val_loss: 0.3370 - val_acc: 0.9094\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9509\n",
      "Epoch 00030: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1538 - acc: 0.9509 - val_loss: 0.4239 - val_acc: 0.8921\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1460 - acc: 0.9538\n",
      "Epoch 00031: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1461 - acc: 0.9538 - val_loss: 0.3421 - val_acc: 0.9045\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9532\n",
      "Epoch 00032: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1444 - acc: 0.9532 - val_loss: 0.3207 - val_acc: 0.9150\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9588\n",
      "Epoch 00033: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1331 - acc: 0.9587 - val_loss: 0.3442 - val_acc: 0.9113\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9584\n",
      "Epoch 00034: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1322 - acc: 0.9584 - val_loss: 0.3763 - val_acc: 0.9026\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9584\n",
      "Epoch 00035: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1317 - acc: 0.9584 - val_loss: 0.3833 - val_acc: 0.9075\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9619\n",
      "Epoch 00036: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1173 - acc: 0.9619 - val_loss: 0.4727 - val_acc: 0.8812\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9617\n",
      "Epoch 00037: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1197 - acc: 0.9617 - val_loss: 0.3430 - val_acc: 0.9110\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9647\n",
      "Epoch 00038: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1104 - acc: 0.9647 - val_loss: 0.3537 - val_acc: 0.9089\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9646\n",
      "Epoch 00039: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1103 - acc: 0.9646 - val_loss: 0.4982 - val_acc: 0.8882\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9667\n",
      "Epoch 00040: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1063 - acc: 0.9667 - val_loss: 1.0561 - val_acc: 0.7918\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9663\n",
      "Epoch 00041: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1064 - acc: 0.9663 - val_loss: 0.3850 - val_acc: 0.9136\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9677\n",
      "Epoch 00042: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0986 - acc: 0.9677 - val_loss: 0.3604 - val_acc: 0.9106\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9678\n",
      "Epoch 00043: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0991 - acc: 0.9678 - val_loss: 0.4944 - val_acc: 0.8861\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9671\n",
      "Epoch 00044: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1011 - acc: 0.9671 - val_loss: 0.3840 - val_acc: 0.9108\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9705\n",
      "Epoch 00045: val_loss did not improve from 0.31758\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0955 - acc: 0.9704 - val_loss: 0.3236 - val_acc: 0.9215\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9696\n",
      "Epoch 00046: val_loss improved from 0.31758 to 0.31395, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv_checkpoint/046-0.3140.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0953 - acc: 0.9697 - val_loss: 0.3140 - val_acc: 0.9299\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9740\n",
      "Epoch 00047: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0833 - acc: 0.9740 - val_loss: 0.5050 - val_acc: 0.8856\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9737\n",
      "Epoch 00048: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0832 - acc: 0.9736 - val_loss: 0.4464 - val_acc: 0.8982\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9740\n",
      "Epoch 00049: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0838 - acc: 0.9741 - val_loss: 0.3177 - val_acc: 0.9290\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9744\n",
      "Epoch 00050: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0803 - acc: 0.9744 - val_loss: 0.3756 - val_acc: 0.9129\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9754\n",
      "Epoch 00051: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0767 - acc: 0.9754 - val_loss: 0.3583 - val_acc: 0.9208\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9760\n",
      "Epoch 00052: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0768 - acc: 0.9759 - val_loss: 0.3627 - val_acc: 0.9187\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9731\n",
      "Epoch 00053: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0851 - acc: 0.9730 - val_loss: 0.3661 - val_acc: 0.9143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9775\n",
      "Epoch 00054: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0729 - acc: 0.9775 - val_loss: 0.3531 - val_acc: 0.9131\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9766\n",
      "Epoch 00055: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0710 - acc: 0.9766 - val_loss: 0.3328 - val_acc: 0.9217\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9785\n",
      "Epoch 00056: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0672 - acc: 0.9785 - val_loss: 0.3254 - val_acc: 0.9280\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9780\n",
      "Epoch 00057: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0672 - acc: 0.9780 - val_loss: 0.3614 - val_acc: 0.9178\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9789\n",
      "Epoch 00058: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0655 - acc: 0.9789 - val_loss: 0.3445 - val_acc: 0.9208\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9798\n",
      "Epoch 00059: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0650 - acc: 0.9798 - val_loss: 0.4159 - val_acc: 0.9087\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9763\n",
      "Epoch 00060: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0742 - acc: 0.9763 - val_loss: 0.3454 - val_acc: 0.9252\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9815\n",
      "Epoch 00061: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0578 - acc: 0.9816 - val_loss: 0.5124 - val_acc: 0.8917\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9798\n",
      "Epoch 00062: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0620 - acc: 0.9797 - val_loss: 0.4084 - val_acc: 0.9101\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9802\n",
      "Epoch 00063: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0627 - acc: 0.9802 - val_loss: 0.3763 - val_acc: 0.9203\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9814\n",
      "Epoch 00064: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0602 - acc: 0.9814 - val_loss: 0.3497 - val_acc: 0.9229\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9821\n",
      "Epoch 00065: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0562 - acc: 0.9821 - val_loss: 0.7760 - val_acc: 0.8488\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9819- ETA: 1s - loss: 0.057\n",
      "Epoch 00066: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0576 - acc: 0.9819 - val_loss: 0.4046 - val_acc: 0.9124\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9796\n",
      "Epoch 00067: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0642 - acc: 0.9795 - val_loss: 0.3993 - val_acc: 0.9161\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9842\n",
      "Epoch 00068: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0516 - acc: 0.9842 - val_loss: 0.5054 - val_acc: 0.8931\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9836\n",
      "Epoch 00069: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0526 - acc: 0.9836 - val_loss: 0.4563 - val_acc: 0.9019\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9844\n",
      "Epoch 00070: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0513 - acc: 0.9844 - val_loss: 0.4639 - val_acc: 0.9031\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9852\n",
      "Epoch 00071: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0493 - acc: 0.9851 - val_loss: 0.3334 - val_acc: 0.9271\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9816\n",
      "Epoch 00072: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0615 - acc: 0.9816 - val_loss: 0.3985 - val_acc: 0.9157\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9818\n",
      "Epoch 00073: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0566 - acc: 0.9818 - val_loss: 0.3749 - val_acc: 0.9203\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9849\n",
      "Epoch 00074: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0468 - acc: 0.9849 - val_loss: 0.3670 - val_acc: 0.9255\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9852\n",
      "Epoch 00075: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0477 - acc: 0.9852 - val_loss: 0.4027 - val_acc: 0.9138\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9871\n",
      "Epoch 00076: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0442 - acc: 0.9871 - val_loss: 0.4790 - val_acc: 0.9024\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9864\n",
      "Epoch 00077: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0456 - acc: 0.9864 - val_loss: 0.3513 - val_acc: 0.9231\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9865\n",
      "Epoch 00078: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0448 - acc: 0.9865 - val_loss: 0.4106 - val_acc: 0.9143\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9852\n",
      "Epoch 00079: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0466 - acc: 0.9852 - val_loss: 0.3627 - val_acc: 0.9290\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9866\n",
      "Epoch 00080: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0448 - acc: 0.9866 - val_loss: 0.3935 - val_acc: 0.9208\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9836\n",
      "Epoch 00081: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0521 - acc: 0.9836 - val_loss: 0.3825 - val_acc: 0.9229\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9874\n",
      "Epoch 00082: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0421 - acc: 0.9874 - val_loss: 0.3594 - val_acc: 0.9203\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9861\n",
      "Epoch 00083: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0436 - acc: 0.9861 - val_loss: 0.3994 - val_acc: 0.9136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9865\n",
      "Epoch 00084: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0423 - acc: 0.9866 - val_loss: 0.3658 - val_acc: 0.9317\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9868\n",
      "Epoch 00085: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0411 - acc: 0.9868 - val_loss: 0.3550 - val_acc: 0.9264\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9866\n",
      "Epoch 00086: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0440 - acc: 0.9866 - val_loss: 0.5411 - val_acc: 0.8968\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9883\n",
      "Epoch 00087: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0376 - acc: 0.9883 - val_loss: 0.3872 - val_acc: 0.9257\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9875\n",
      "Epoch 00088: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0410 - acc: 0.9875 - val_loss: 0.3884 - val_acc: 0.9199\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9876\n",
      "Epoch 00089: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0408 - acc: 0.9876 - val_loss: 0.3878 - val_acc: 0.9154\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9879\n",
      "Epoch 00090: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0415 - acc: 0.9879 - val_loss: 0.3955 - val_acc: 0.9180\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9849\n",
      "Epoch 00091: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0475 - acc: 0.9849 - val_loss: 0.3468 - val_acc: 0.9243\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9883\n",
      "Epoch 00092: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0374 - acc: 0.9883 - val_loss: 0.3511 - val_acc: 0.9252\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9865\n",
      "Epoch 00093: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0442 - acc: 0.9865 - val_loss: 0.3734 - val_acc: 0.9255\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9896\n",
      "Epoch 00094: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0351 - acc: 0.9896 - val_loss: 0.3671 - val_acc: 0.9224\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9879\n",
      "Epoch 00095: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0402 - acc: 0.9878 - val_loss: 0.3529 - val_acc: 0.9276\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9857\n",
      "Epoch 00096: val_loss did not improve from 0.31395\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0434 - acc: 0.9857 - val_loss: 0.3816 - val_acc: 0.9255\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 872us/sample - loss: 0.3824 - acc: 0.8989\n",
      "Loss: 0.3823787293577739 Accuracy: 0.8988577\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3021 - acc: 0.2948\n",
      "Epoch 00001: val_loss improved from inf to 1.66607, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/001-1.6661.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 2.3021 - acc: 0.2948 - val_loss: 1.6661 - val_acc: 0.4314\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3438 - acc: 0.5712\n",
      "Epoch 00002: val_loss improved from 1.66607 to 0.89485, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/002-0.8949.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 1.3439 - acc: 0.5712 - val_loss: 0.8949 - val_acc: 0.7349\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9861 - acc: 0.6931\n",
      "Epoch 00003: val_loss improved from 0.89485 to 0.69197, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/003-0.6920.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.9861 - acc: 0.6931 - val_loss: 0.6920 - val_acc: 0.8011\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7748 - acc: 0.7671\n",
      "Epoch 00004: val_loss improved from 0.69197 to 0.58280, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/004-0.5828.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.7748 - acc: 0.7671 - val_loss: 0.5828 - val_acc: 0.8360\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6446 - acc: 0.8070\n",
      "Epoch 00005: val_loss improved from 0.58280 to 0.50699, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/005-0.5070.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.6446 - acc: 0.8070 - val_loss: 0.5070 - val_acc: 0.8649\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5483 - acc: 0.8358\n",
      "Epoch 00006: val_loss improved from 0.50699 to 0.50540, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/006-0.5054.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.5483 - acc: 0.8358 - val_loss: 0.5054 - val_acc: 0.8558\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4737 - acc: 0.8575\n",
      "Epoch 00007: val_loss improved from 0.50540 to 0.43072, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/007-0.4307.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.4738 - acc: 0.8575 - val_loss: 0.4307 - val_acc: 0.8817\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4207 - acc: 0.8751\n",
      "Epoch 00008: val_loss did not improve from 0.43072\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.4211 - acc: 0.8751 - val_loss: 0.4625 - val_acc: 0.8623\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3831 - acc: 0.8836\n",
      "Epoch 00009: val_loss improved from 0.43072 to 0.32544, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/009-0.3254.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.3832 - acc: 0.8836 - val_loss: 0.3254 - val_acc: 0.9119\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3531 - acc: 0.8936\n",
      "Epoch 00010: val_loss did not improve from 0.32544\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.3531 - acc: 0.8936 - val_loss: 0.3344 - val_acc: 0.9040\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3107 - acc: 0.9044\n",
      "Epoch 00011: val_loss improved from 0.32544 to 0.30974, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/011-0.3097.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.3107 - acc: 0.9044 - val_loss: 0.3097 - val_acc: 0.9115\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2896 - acc: 0.9107\n",
      "Epoch 00012: val_loss did not improve from 0.30974\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.2896 - acc: 0.9106 - val_loss: 0.3193 - val_acc: 0.9124\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2642 - acc: 0.9185\n",
      "Epoch 00013: val_loss did not improve from 0.30974\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.2643 - acc: 0.9184 - val_loss: 0.9170 - val_acc: 0.7701\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2489 - acc: 0.9233\n",
      "Epoch 00014: val_loss improved from 0.30974 to 0.25556, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/014-0.2556.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.2489 - acc: 0.9233 - val_loss: 0.2556 - val_acc: 0.9297\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2318 - acc: 0.9272\n",
      "Epoch 00015: val_loss did not improve from 0.25556\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.2318 - acc: 0.9272 - val_loss: 0.3124 - val_acc: 0.9071\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9330\n",
      "Epoch 00016: val_loss improved from 0.25556 to 0.25177, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/016-0.2518.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.2136 - acc: 0.9330 - val_loss: 0.2518 - val_acc: 0.9343\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1951 - acc: 0.9394\n",
      "Epoch 00017: val_loss did not improve from 0.25177\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1951 - acc: 0.9394 - val_loss: 0.2581 - val_acc: 0.9273\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9409\n",
      "Epoch 00018: val_loss did not improve from 0.25177\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1910 - acc: 0.9409 - val_loss: 0.2742 - val_acc: 0.9264\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9440\n",
      "Epoch 00019: val_loss improved from 0.25177 to 0.22453, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/019-0.2245.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1770 - acc: 0.9441 - val_loss: 0.2245 - val_acc: 0.9399\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1708 - acc: 0.9460\n",
      "Epoch 00020: val_loss did not improve from 0.22453\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1708 - acc: 0.9460 - val_loss: 0.2527 - val_acc: 0.9301\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1601 - acc: 0.9496\n",
      "Epoch 00021: val_loss did not improve from 0.22453\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1602 - acc: 0.9495 - val_loss: 0.3585 - val_acc: 0.9033\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1545 - acc: 0.9511\n",
      "Epoch 00022: val_loss did not improve from 0.22453\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1545 - acc: 0.9511 - val_loss: 0.2464 - val_acc: 0.9359\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9522\n",
      "Epoch 00023: val_loss did not improve from 0.22453\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1462 - acc: 0.9522 - val_loss: 0.3371 - val_acc: 0.9054\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9572\n",
      "Epoch 00024: val_loss did not improve from 0.22453\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1349 - acc: 0.9572 - val_loss: 0.3008 - val_acc: 0.9173\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9592\n",
      "Epoch 00025: val_loss did not improve from 0.22453\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1298 - acc: 0.9592 - val_loss: 0.2301 - val_acc: 0.9420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9615\n",
      "Epoch 00026: val_loss did not improve from 0.22453\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1199 - acc: 0.9616 - val_loss: 0.2724 - val_acc: 0.9329\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9611\n",
      "Epoch 00027: val_loss improved from 0.22453 to 0.22443, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/027-0.2244.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1201 - acc: 0.9611 - val_loss: 0.2244 - val_acc: 0.9392\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9633\n",
      "Epoch 00028: val_loss did not improve from 0.22443\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1150 - acc: 0.9633 - val_loss: 0.4832 - val_acc: 0.8691\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9661\n",
      "Epoch 00029: val_loss did not improve from 0.22443\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1077 - acc: 0.9661 - val_loss: 0.2320 - val_acc: 0.9418\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9645\n",
      "Epoch 00030: val_loss did not improve from 0.22443\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1066 - acc: 0.9645 - val_loss: 0.2601 - val_acc: 0.9329\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9679\n",
      "Epoch 00031: val_loss did not improve from 0.22443\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0981 - acc: 0.9679 - val_loss: 0.2520 - val_acc: 0.9366\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9682\n",
      "Epoch 00032: val_loss did not improve from 0.22443\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0985 - acc: 0.9682 - val_loss: 0.2297 - val_acc: 0.9392\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9720\n",
      "Epoch 00033: val_loss did not improve from 0.22443\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0892 - acc: 0.9720 - val_loss: 0.2444 - val_acc: 0.9341\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9693\n",
      "Epoch 00034: val_loss improved from 0.22443 to 0.21883, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv_checkpoint/034-0.2188.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0973 - acc: 0.9693 - val_loss: 0.2188 - val_acc: 0.9439\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9725\n",
      "Epoch 00035: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0862 - acc: 0.9725 - val_loss: 0.2526 - val_acc: 0.9350\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9739\n",
      "Epoch 00036: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0815 - acc: 0.9738 - val_loss: 0.2336 - val_acc: 0.9429\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9743\n",
      "Epoch 00037: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0803 - acc: 0.9743 - val_loss: 0.2668 - val_acc: 0.9329\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9745\n",
      "Epoch 00038: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0814 - acc: 0.9745 - val_loss: 0.2794 - val_acc: 0.9350\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9768\n",
      "Epoch 00039: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0737 - acc: 0.9768 - val_loss: 0.2388 - val_acc: 0.9404\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9785\n",
      "Epoch 00040: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0680 - acc: 0.9784 - val_loss: 0.2562 - val_acc: 0.9397\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9738\n",
      "Epoch 00041: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0805 - acc: 0.9738 - val_loss: 0.4062 - val_acc: 0.8991\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9794\n",
      "Epoch 00042: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0645 - acc: 0.9794 - val_loss: 0.2341 - val_acc: 0.9432\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9786\n",
      "Epoch 00043: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0641 - acc: 0.9786 - val_loss: 0.3038 - val_acc: 0.9290\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9817\n",
      "Epoch 00044: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0579 - acc: 0.9817 - val_loss: 0.2347 - val_acc: 0.9446\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9815\n",
      "Epoch 00045: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0592 - acc: 0.9815 - val_loss: 0.2466 - val_acc: 0.9411\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9802\n",
      "Epoch 00046: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0605 - acc: 0.9802 - val_loss: 0.2614 - val_acc: 0.9415\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9832\n",
      "Epoch 00047: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0518 - acc: 0.9832 - val_loss: 0.2798 - val_acc: 0.9392\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9829\n",
      "Epoch 00048: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0551 - acc: 0.9829 - val_loss: 0.2950 - val_acc: 0.9292\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9842\n",
      "Epoch 00049: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0505 - acc: 0.9842 - val_loss: 0.3196 - val_acc: 0.9324\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9826\n",
      "Epoch 00050: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0543 - acc: 0.9826 - val_loss: 0.2530 - val_acc: 0.9411\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9838\n",
      "Epoch 00051: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0501 - acc: 0.9838 - val_loss: 0.2429 - val_acc: 0.9450\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9854\n",
      "Epoch 00052: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0455 - acc: 0.9854 - val_loss: 0.2379 - val_acc: 0.9448\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9852\n",
      "Epoch 00053: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0464 - acc: 0.9852 - val_loss: 0.2847 - val_acc: 0.9329\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9841\n",
      "Epoch 00054: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0479 - acc: 0.9841 - val_loss: 0.2410 - val_acc: 0.9446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9851\n",
      "Epoch 00055: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0454 - acc: 0.9851 - val_loss: 0.2953 - val_acc: 0.9343\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9848\n",
      "Epoch 00056: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0458 - acc: 0.9848 - val_loss: 0.3425 - val_acc: 0.9297\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9821\n",
      "Epoch 00057: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0573 - acc: 0.9821 - val_loss: 0.2434 - val_acc: 0.9436\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9906\n",
      "Epoch 00058: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0310 - acc: 0.9906 - val_loss: 0.2525 - val_acc: 0.9481\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9873\n",
      "Epoch 00059: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0391 - acc: 0.9872 - val_loss: 0.2637 - val_acc: 0.9420\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9811\n",
      "Epoch 00060: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0585 - acc: 0.9811 - val_loss: 0.2211 - val_acc: 0.9490\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9904\n",
      "Epoch 00061: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0317 - acc: 0.9904 - val_loss: 0.2232 - val_acc: 0.9460\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9887\n",
      "Epoch 00062: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0347 - acc: 0.9887 - val_loss: 0.3520 - val_acc: 0.9297\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9793\n",
      "Epoch 00063: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0645 - acc: 0.9793 - val_loss: 0.2688 - val_acc: 0.9415\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9885\n",
      "Epoch 00064: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0360 - acc: 0.9885 - val_loss: 0.2285 - val_acc: 0.9497\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9898\n",
      "Epoch 00065: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0340 - acc: 0.9898 - val_loss: 0.2313 - val_acc: 0.9488\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9904\n",
      "Epoch 00066: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0307 - acc: 0.9904 - val_loss: 0.2204 - val_acc: 0.9504\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9900\n",
      "Epoch 00067: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0321 - acc: 0.9900 - val_loss: 0.2786 - val_acc: 0.9390\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9877\n",
      "Epoch 00068: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0378 - acc: 0.9877 - val_loss: 0.2786 - val_acc: 0.9422\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9897\n",
      "Epoch 00069: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0325 - acc: 0.9897 - val_loss: 0.2856 - val_acc: 0.9436\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9900\n",
      "Epoch 00070: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0330 - acc: 0.9899 - val_loss: 0.2791 - val_acc: 0.9401\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9901\n",
      "Epoch 00071: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0331 - acc: 0.9901 - val_loss: 0.2624 - val_acc: 0.9478\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9879\n",
      "Epoch 00072: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0381 - acc: 0.9879 - val_loss: 0.3046 - val_acc: 0.9380\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9866\n",
      "Epoch 00073: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0420 - acc: 0.9866 - val_loss: 0.2510 - val_acc: 0.9453\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9919\n",
      "Epoch 00074: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0252 - acc: 0.9919 - val_loss: 0.3062 - val_acc: 0.9387\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9905\n",
      "Epoch 00075: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0294 - acc: 0.9905 - val_loss: 0.2493 - val_acc: 0.9483\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 00076: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0256 - acc: 0.9917 - val_loss: 0.2983 - val_acc: 0.9434\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9920\n",
      "Epoch 00077: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0275 - acc: 0.9919 - val_loss: 0.2646 - val_acc: 0.9476\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9887\n",
      "Epoch 00078: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0375 - acc: 0.9887 - val_loss: 0.2783 - val_acc: 0.9404\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9924\n",
      "Epoch 00079: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0257 - acc: 0.9924 - val_loss: 0.2655 - val_acc: 0.9450\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9914\n",
      "Epoch 00080: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0295 - acc: 0.9914 - val_loss: 0.2517 - val_acc: 0.9513\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9929\n",
      "Epoch 00081: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0237 - acc: 0.9929 - val_loss: 0.2540 - val_acc: 0.9467\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9915\n",
      "Epoch 00082: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0268 - acc: 0.9915 - val_loss: 0.2717 - val_acc: 0.9441\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9926\n",
      "Epoch 00083: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0252 - acc: 0.9926 - val_loss: 0.2421 - val_acc: 0.9495\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9920\n",
      "Epoch 00084: val_loss did not improve from 0.21883\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0256 - acc: 0.9920 - val_loss: 0.2681 - val_acc: 0.9441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 963us/sample - loss: 0.2690 - acc: 0.9263\n",
      "Loss: 0.2690025930804503 Accuracy: 0.9262721\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3497 - acc: 0.2829\n",
      "Epoch 00001: val_loss improved from inf to 1.51956, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/001-1.5196.hdf5\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 2.3496 - acc: 0.2830 - val_loss: 1.5196 - val_acc: 0.5164\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3251 - acc: 0.5730\n",
      "Epoch 00002: val_loss improved from 1.51956 to 0.88141, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/002-0.8814.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 1.3251 - acc: 0.5730 - val_loss: 0.8814 - val_acc: 0.7333\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9008 - acc: 0.7182\n",
      "Epoch 00003: val_loss improved from 0.88141 to 0.61372, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/003-0.6137.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.9007 - acc: 0.7182 - val_loss: 0.6137 - val_acc: 0.8209\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6564 - acc: 0.7967\n",
      "Epoch 00004: val_loss improved from 0.61372 to 0.45482, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/004-0.4548.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.6564 - acc: 0.7967 - val_loss: 0.4548 - val_acc: 0.8691\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5187 - acc: 0.8395\n",
      "Epoch 00005: val_loss improved from 0.45482 to 0.35086, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/005-0.3509.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.5187 - acc: 0.8395 - val_loss: 0.3509 - val_acc: 0.8947\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4269 - acc: 0.8685\n",
      "Epoch 00006: val_loss improved from 0.35086 to 0.32343, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/006-0.3234.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.4269 - acc: 0.8685 - val_loss: 0.3234 - val_acc: 0.9036\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3575 - acc: 0.8897\n",
      "Epoch 00007: val_loss improved from 0.32343 to 0.28345, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/007-0.2834.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.3576 - acc: 0.8897 - val_loss: 0.2834 - val_acc: 0.9206\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3187 - acc: 0.8997\n",
      "Epoch 00008: val_loss improved from 0.28345 to 0.26690, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/008-0.2669.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.3188 - acc: 0.8997 - val_loss: 0.2669 - val_acc: 0.9215\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2840 - acc: 0.9117\n",
      "Epoch 00009: val_loss improved from 0.26690 to 0.25563, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/009-0.2556.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.2840 - acc: 0.9117 - val_loss: 0.2556 - val_acc: 0.9322\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2556 - acc: 0.9201\n",
      "Epoch 00010: val_loss improved from 0.25563 to 0.22026, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/010-0.2203.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.2556 - acc: 0.9201 - val_loss: 0.2203 - val_acc: 0.9385\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2329 - acc: 0.9270\n",
      "Epoch 00011: val_loss did not improve from 0.22026\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.2330 - acc: 0.9270 - val_loss: 0.2423 - val_acc: 0.9252\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2165 - acc: 0.9318\n",
      "Epoch 00012: val_loss did not improve from 0.22026\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.2166 - acc: 0.9318 - val_loss: 0.2565 - val_acc: 0.9278\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9357\n",
      "Epoch 00013: val_loss improved from 0.22026 to 0.21074, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/013-0.2107.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.2006 - acc: 0.9357 - val_loss: 0.2107 - val_acc: 0.9404\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1826 - acc: 0.9428\n",
      "Epoch 00014: val_loss did not improve from 0.21074\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1826 - acc: 0.9428 - val_loss: 0.2267 - val_acc: 0.9385\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1721 - acc: 0.9450\n",
      "Epoch 00015: val_loss did not improve from 0.21074\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1721 - acc: 0.9450 - val_loss: 0.2500 - val_acc: 0.9266\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9503\n",
      "Epoch 00016: val_loss did not improve from 0.21074\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1572 - acc: 0.9503 - val_loss: 0.2323 - val_acc: 0.9406\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9542\n",
      "Epoch 00017: val_loss improved from 0.21074 to 0.19482, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/017-0.1948.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1438 - acc: 0.9542 - val_loss: 0.1948 - val_acc: 0.9404\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9552\n",
      "Epoch 00018: val_loss did not improve from 0.19482\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1395 - acc: 0.9552 - val_loss: 0.1948 - val_acc: 0.9476\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9588\n",
      "Epoch 00019: val_loss improved from 0.19482 to 0.16333, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/019-0.1633.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1286 - acc: 0.9588 - val_loss: 0.1633 - val_acc: 0.9522\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9604\n",
      "Epoch 00020: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1249 - acc: 0.9604 - val_loss: 0.2078 - val_acc: 0.9420\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9630\n",
      "Epoch 00021: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1146 - acc: 0.9630 - val_loss: 0.1768 - val_acc: 0.9518\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9668\n",
      "Epoch 00022: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1056 - acc: 0.9668 - val_loss: 0.2060 - val_acc: 0.9394\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9687\n",
      "Epoch 00023: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1005 - acc: 0.9687 - val_loss: 0.2987 - val_acc: 0.9194\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9692\n",
      "Epoch 00024: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0978 - acc: 0.9692 - val_loss: 0.2081 - val_acc: 0.9411\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9688\n",
      "Epoch 00025: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0931 - acc: 0.9688 - val_loss: 0.1818 - val_acc: 0.9499\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9728\n",
      "Epoch 00026: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0842 - acc: 0.9728 - val_loss: 0.2203 - val_acc: 0.9350\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9708\n",
      "Epoch 00027: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0893 - acc: 0.9708 - val_loss: 0.2237 - val_acc: 0.9408\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9747\n",
      "Epoch 00028: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0783 - acc: 0.9747 - val_loss: 0.2120 - val_acc: 0.9453\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9751\n",
      "Epoch 00029: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0785 - acc: 0.9751 - val_loss: 0.2001 - val_acc: 0.9448\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9758\n",
      "Epoch 00030: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0748 - acc: 0.9758 - val_loss: 0.1783 - val_acc: 0.9495\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9765\n",
      "Epoch 00031: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0735 - acc: 0.9765 - val_loss: 0.2177 - val_acc: 0.9415\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9806\n",
      "Epoch 00032: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0623 - acc: 0.9806 - val_loss: 0.1733 - val_acc: 0.9536\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9766\n",
      "Epoch 00033: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0705 - acc: 0.9766 - val_loss: 0.2151 - val_acc: 0.9392\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9809\n",
      "Epoch 00034: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0590 - acc: 0.9808 - val_loss: 0.1933 - val_acc: 0.9502\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9799\n",
      "Epoch 00035: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0640 - acc: 0.9799 - val_loss: 0.2251 - val_acc: 0.9411\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9803\n",
      "Epoch 00036: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0625 - acc: 0.9803 - val_loss: 0.1814 - val_acc: 0.9506\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9798\n",
      "Epoch 00037: val_loss did not improve from 0.16333\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0611 - acc: 0.9798 - val_loss: 0.1752 - val_acc: 0.9536\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9851\n",
      "Epoch 00038: val_loss improved from 0.16333 to 0.14792, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv_checkpoint/038-0.1479.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0487 - acc: 0.9851 - val_loss: 0.1479 - val_acc: 0.9588\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9854\n",
      "Epoch 00039: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0473 - acc: 0.9854 - val_loss: 0.1682 - val_acc: 0.9555\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9836\n",
      "Epoch 00040: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0497 - acc: 0.9836 - val_loss: 0.1804 - val_acc: 0.9515\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9856\n",
      "Epoch 00041: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0459 - acc: 0.9856 - val_loss: 0.1865 - val_acc: 0.9522\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9863\n",
      "Epoch 00042: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0429 - acc: 0.9863 - val_loss: 0.1626 - val_acc: 0.9592\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9861\n",
      "Epoch 00043: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0435 - acc: 0.9861 - val_loss: 0.2184 - val_acc: 0.9432\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9873\n",
      "Epoch 00044: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0413 - acc: 0.9873 - val_loss: 0.1622 - val_acc: 0.9576\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9871\n",
      "Epoch 00045: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0407 - acc: 0.9871 - val_loss: 0.1830 - val_acc: 0.9541\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9885\n",
      "Epoch 00046: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0372 - acc: 0.9884 - val_loss: 0.2227 - val_acc: 0.9506\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9860\n",
      "Epoch 00047: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0432 - acc: 0.9859 - val_loss: 0.1873 - val_acc: 0.9511\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9854\n",
      "Epoch 00048: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0467 - acc: 0.9854 - val_loss: 0.2105 - val_acc: 0.9543\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9888\n",
      "Epoch 00049: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0341 - acc: 0.9888 - val_loss: 0.1824 - val_acc: 0.9557\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9857\n",
      "Epoch 00050: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0478 - acc: 0.9857 - val_loss: 0.1853 - val_acc: 0.9522\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9909\n",
      "Epoch 00051: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0298 - acc: 0.9909 - val_loss: 0.1984 - val_acc: 0.9525\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9903\n",
      "Epoch 00052: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0326 - acc: 0.9903 - val_loss: 0.2002 - val_acc: 0.9518\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9899\n",
      "Epoch 00053: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0313 - acc: 0.9899 - val_loss: 0.1775 - val_acc: 0.9574\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9902\n",
      "Epoch 00054: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0307 - acc: 0.9902 - val_loss: 0.2536 - val_acc: 0.9406\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9891\n",
      "Epoch 00055: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0364 - acc: 0.9890 - val_loss: 0.2277 - val_acc: 0.9490\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9862\n",
      "Epoch 00056: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0424 - acc: 0.9863 - val_loss: 0.1710 - val_acc: 0.9616\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9919\n",
      "Epoch 00057: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0259 - acc: 0.9919 - val_loss: 0.2156 - val_acc: 0.9534\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9914\n",
      "Epoch 00058: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0271 - acc: 0.9914 - val_loss: 0.1826 - val_acc: 0.9590\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9932\n",
      "Epoch 00059: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0230 - acc: 0.9931 - val_loss: 0.1997 - val_acc: 0.9529\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9887\n",
      "Epoch 00060: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0349 - acc: 0.9887 - val_loss: 0.2473 - val_acc: 0.9392\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9891\n",
      "Epoch 00061: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0353 - acc: 0.9891 - val_loss: 0.1653 - val_acc: 0.9583\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9934\n",
      "Epoch 00062: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0211 - acc: 0.9934 - val_loss: 0.1823 - val_acc: 0.9583\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9930\n",
      "Epoch 00063: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0229 - acc: 0.9930 - val_loss: 0.2175 - val_acc: 0.9515\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9925\n",
      "Epoch 00064: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0242 - acc: 0.9925 - val_loss: 0.2171 - val_acc: 0.9504\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9934\n",
      "Epoch 00065: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0220 - acc: 0.9934 - val_loss: 0.2549 - val_acc: 0.9441\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9922\n",
      "Epoch 00066: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0261 - acc: 0.9922 - val_loss: 0.2207 - val_acc: 0.9506\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9934\n",
      "Epoch 00067: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0213 - acc: 0.9934 - val_loss: 0.1765 - val_acc: 0.9616\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9912\n",
      "Epoch 00068: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0269 - acc: 0.9913 - val_loss: 0.1992 - val_acc: 0.9564\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9929\n",
      "Epoch 00069: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0231 - acc: 0.9928 - val_loss: 0.1636 - val_acc: 0.9641\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9885\n",
      "Epoch 00070: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0366 - acc: 0.9885 - val_loss: 0.1932 - val_acc: 0.9550\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9924\n",
      "Epoch 00071: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0250 - acc: 0.9924 - val_loss: 0.1870 - val_acc: 0.9616\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9944\n",
      "Epoch 00072: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0189 - acc: 0.9944 - val_loss: 0.2058 - val_acc: 0.9513\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9878\n",
      "Epoch 00073: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0369 - acc: 0.9878 - val_loss: 0.1911 - val_acc: 0.9590\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9958\n",
      "Epoch 00074: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0151 - acc: 0.9958 - val_loss: 0.2102 - val_acc: 0.9560\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 00075: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0266 - acc: 0.9917 - val_loss: 0.1762 - val_acc: 0.9609\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9903\n",
      "Epoch 00076: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0327 - acc: 0.9902 - val_loss: 0.2058 - val_acc: 0.9548\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9938\n",
      "Epoch 00077: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0216 - acc: 0.9938 - val_loss: 0.2162 - val_acc: 0.9553\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9961\n",
      "Epoch 00078: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0140 - acc: 0.9961 - val_loss: 0.2063 - val_acc: 0.9564\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9956\n",
      "Epoch 00079: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0158 - acc: 0.9956 - val_loss: 0.1896 - val_acc: 0.9604\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9946\n",
      "Epoch 00080: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0178 - acc: 0.9946 - val_loss: 0.1866 - val_acc: 0.9613\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9949\n",
      "Epoch 00081: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0173 - acc: 0.9949 - val_loss: 0.2055 - val_acc: 0.9548\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9939\n",
      "Epoch 00082: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0187 - acc: 0.9939 - val_loss: 0.2435 - val_acc: 0.9474\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9939\n",
      "Epoch 00083: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0190 - acc: 0.9939 - val_loss: 0.1842 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9941\n",
      "Epoch 00084: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0182 - acc: 0.9941 - val_loss: 0.2027 - val_acc: 0.9616\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9938\n",
      "Epoch 00085: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0197 - acc: 0.9938 - val_loss: 0.1802 - val_acc: 0.9604\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9928\n",
      "Epoch 00086: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0221 - acc: 0.9928 - val_loss: 0.1935 - val_acc: 0.9553\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9961\n",
      "Epoch 00087: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0129 - acc: 0.9961 - val_loss: 0.1926 - val_acc: 0.9578\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9957\n",
      "Epoch 00088: val_loss did not improve from 0.14792\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0130 - acc: 0.9957 - val_loss: 0.2259 - val_acc: 0.9546\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 969us/sample - loss: 0.1830 - acc: 0.9502\n",
      "Loss: 0.1829569949479319 Accuracy: 0.95015574\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2798 - acc: 0.3155\n",
      "Epoch 00001: val_loss improved from inf to 1.42175, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/001-1.4217.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 2.2796 - acc: 0.3155 - val_loss: 1.4217 - val_acc: 0.5679\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1402 - acc: 0.6417\n",
      "Epoch 00002: val_loss improved from 1.42175 to 0.63712, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/002-0.6371.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 1.1403 - acc: 0.6417 - val_loss: 0.6371 - val_acc: 0.8174\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7318 - acc: 0.7734\n",
      "Epoch 00003: val_loss improved from 0.63712 to 0.42688, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/003-0.4269.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.7318 - acc: 0.7735 - val_loss: 0.4269 - val_acc: 0.8747\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5282 - acc: 0.8399\n",
      "Epoch 00004: val_loss did not improve from 0.42688\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.5282 - acc: 0.8399 - val_loss: 0.4595 - val_acc: 0.8703\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4228 - acc: 0.8689\n",
      "Epoch 00005: val_loss improved from 0.42688 to 0.33315, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/005-0.3332.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.4228 - acc: 0.8690 - val_loss: 0.3332 - val_acc: 0.9054\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3456 - acc: 0.8930\n",
      "Epoch 00006: val_loss improved from 0.33315 to 0.26049, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/006-0.2605.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.3457 - acc: 0.8929 - val_loss: 0.2605 - val_acc: 0.9257\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2991 - acc: 0.9080\n",
      "Epoch 00007: val_loss did not improve from 0.26049\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.2992 - acc: 0.9079 - val_loss: 0.2772 - val_acc: 0.9159\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2704 - acc: 0.9169\n",
      "Epoch 00008: val_loss improved from 0.26049 to 0.24056, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/008-0.2406.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.2705 - acc: 0.9169 - val_loss: 0.2406 - val_acc: 0.9292\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.9280\n",
      "Epoch 00009: val_loss improved from 0.24056 to 0.19247, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/009-0.1925.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.2356 - acc: 0.9280 - val_loss: 0.1925 - val_acc: 0.9443\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2120 - acc: 0.9335\n",
      "Epoch 00010: val_loss improved from 0.19247 to 0.18902, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/010-0.1890.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.2119 - acc: 0.9335 - val_loss: 0.1890 - val_acc: 0.9453\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9400\n",
      "Epoch 00011: val_loss improved from 0.18902 to 0.17355, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/011-0.1735.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1934 - acc: 0.9400 - val_loss: 0.1735 - val_acc: 0.9509\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1740 - acc: 0.9465\n",
      "Epoch 00012: val_loss did not improve from 0.17355\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.1742 - acc: 0.9464 - val_loss: 0.1845 - val_acc: 0.9478\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1641 - acc: 0.9477\n",
      "Epoch 00013: val_loss did not improve from 0.17355\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1641 - acc: 0.9477 - val_loss: 0.2285 - val_acc: 0.9315\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9531\n",
      "Epoch 00014: val_loss improved from 0.17355 to 0.16980, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/014-0.1698.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1486 - acc: 0.9531 - val_loss: 0.1698 - val_acc: 0.9513\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9580\n",
      "Epoch 00015: val_loss improved from 0.16980 to 0.16910, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/015-0.1691.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1345 - acc: 0.9580 - val_loss: 0.1691 - val_acc: 0.9534\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9608\n",
      "Epoch 00016: val_loss did not improve from 0.16910\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1232 - acc: 0.9608 - val_loss: 0.2346 - val_acc: 0.9294\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9630\n",
      "Epoch 00017: val_loss did not improve from 0.16910\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1157 - acc: 0.9630 - val_loss: 0.1950 - val_acc: 0.9397\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9659\n",
      "Epoch 00018: val_loss did not improve from 0.16910\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.1085 - acc: 0.9659 - val_loss: 0.1901 - val_acc: 0.9481\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9686\n",
      "Epoch 00019: val_loss improved from 0.16910 to 0.16085, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/019-0.1608.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0994 - acc: 0.9686 - val_loss: 0.1608 - val_acc: 0.9511\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9718\n",
      "Epoch 00020: val_loss did not improve from 0.16085\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0906 - acc: 0.9718 - val_loss: 0.1671 - val_acc: 0.9522\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9732\n",
      "Epoch 00021: val_loss improved from 0.16085 to 0.13819, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/021-0.1382.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0861 - acc: 0.9732 - val_loss: 0.1382 - val_acc: 0.9590\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9753\n",
      "Epoch 00022: val_loss did not improve from 0.13819\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0813 - acc: 0.9753 - val_loss: 0.1867 - val_acc: 0.9471\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9753\n",
      "Epoch 00023: val_loss did not improve from 0.13819\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0778 - acc: 0.9752 - val_loss: 0.1469 - val_acc: 0.9567\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9742\n",
      "Epoch 00024: val_loss did not improve from 0.13819\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0799 - acc: 0.9741 - val_loss: 0.1541 - val_acc: 0.9567\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9783\n",
      "Epoch 00025: val_loss did not improve from 0.13819\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0707 - acc: 0.9783 - val_loss: 0.1416 - val_acc: 0.9583\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9797\n",
      "Epoch 00026: val_loss improved from 0.13819 to 0.13142, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/026-0.1314.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0665 - acc: 0.9797 - val_loss: 0.1314 - val_acc: 0.9597\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9801\n",
      "Epoch 00027: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0630 - acc: 0.9801 - val_loss: 0.1623 - val_acc: 0.9513\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9795\n",
      "Epoch 00028: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0642 - acc: 0.9795 - val_loss: 0.1997 - val_acc: 0.9462\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9839\n",
      "Epoch 00029: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0527 - acc: 0.9839 - val_loss: 0.1538 - val_acc: 0.9529\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9827\n",
      "Epoch 00030: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0573 - acc: 0.9827 - val_loss: 0.1375 - val_acc: 0.9627\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9845\n",
      "Epoch 00031: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0500 - acc: 0.9845 - val_loss: 0.1671 - val_acc: 0.9583\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9857\n",
      "Epoch 00032: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0462 - acc: 0.9857 - val_loss: 0.1454 - val_acc: 0.9606\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9860\n",
      "Epoch 00033: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0461 - acc: 0.9860 - val_loss: 0.1507 - val_acc: 0.9606\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9863\n",
      "Epoch 00034: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0426 - acc: 0.9863 - val_loss: 0.1593 - val_acc: 0.9590\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9885\n",
      "Epoch 00035: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0386 - acc: 0.9884 - val_loss: 0.1467 - val_acc: 0.9625\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9826\n",
      "Epoch 00036: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0546 - acc: 0.9826 - val_loss: 0.1598 - val_acc: 0.9555\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9883\n",
      "Epoch 00037: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0408 - acc: 0.9882 - val_loss: 0.1896 - val_acc: 0.9506\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9869\n",
      "Epoch 00038: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0428 - acc: 0.9869 - val_loss: 0.1744 - val_acc: 0.9555\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9883\n",
      "Epoch 00039: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0375 - acc: 0.9882 - val_loss: 0.1531 - val_acc: 0.9569\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9847\n",
      "Epoch 00040: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0465 - acc: 0.9846 - val_loss: 0.1333 - val_acc: 0.9637\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9899\n",
      "Epoch 00041: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0346 - acc: 0.9899 - val_loss: 0.1442 - val_acc: 0.9623\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 00042: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0282 - acc: 0.9917 - val_loss: 0.1452 - val_acc: 0.9623\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9882\n",
      "Epoch 00043: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0366 - acc: 0.9882 - val_loss: 0.1498 - val_acc: 0.9632\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9918\n",
      "Epoch 00044: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0262 - acc: 0.9918 - val_loss: 0.1750 - val_acc: 0.9595\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9885\n",
      "Epoch 00045: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0378 - acc: 0.9885 - val_loss: 0.1381 - val_acc: 0.9602\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9924\n",
      "Epoch 00046: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0257 - acc: 0.9924 - val_loss: 0.2205 - val_acc: 0.9529\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9894\n",
      "Epoch 00047: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0335 - acc: 0.9893 - val_loss: 0.1955 - val_acc: 0.9532\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9907\n",
      "Epoch 00048: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0280 - acc: 0.9906 - val_loss: 0.1771 - val_acc: 0.9555\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9876\n",
      "Epoch 00049: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0415 - acc: 0.9876 - val_loss: 0.1469 - val_acc: 0.9658\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9937\n",
      "Epoch 00050: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0216 - acc: 0.9936 - val_loss: 0.1973 - val_acc: 0.9576\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9866\n",
      "Epoch 00051: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0434 - acc: 0.9866 - val_loss: 0.1446 - val_acc: 0.9644\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9925\n",
      "Epoch 00052: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0248 - acc: 0.9925 - val_loss: 0.1663 - val_acc: 0.9609\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9937\n",
      "Epoch 00053: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0213 - acc: 0.9937 - val_loss: 0.1408 - val_acc: 0.9651\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9942\n",
      "Epoch 00054: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0201 - acc: 0.9942 - val_loss: 0.2125 - val_acc: 0.9543\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9889\n",
      "Epoch 00055: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0347 - acc: 0.9889 - val_loss: 0.1686 - val_acc: 0.9620\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9950\n",
      "Epoch 00056: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0180 - acc: 0.9950 - val_loss: 0.1478 - val_acc: 0.9660\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9882\n",
      "Epoch 00057: val_loss did not improve from 0.13142\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0383 - acc: 0.9882 - val_loss: 0.1626 - val_acc: 0.9597\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9945\n",
      "Epoch 00058: val_loss improved from 0.13142 to 0.12456, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv_checkpoint/058-0.1246.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0194 - acc: 0.9945 - val_loss: 0.1246 - val_acc: 0.9665\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9954\n",
      "Epoch 00059: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0173 - acc: 0.9954 - val_loss: 0.1484 - val_acc: 0.9667\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9941\n",
      "Epoch 00060: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0198 - acc: 0.9941 - val_loss: 0.1513 - val_acc: 0.9672\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9942\n",
      "Epoch 00061: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0196 - acc: 0.9942 - val_loss: 0.1989 - val_acc: 0.9583\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9949\n",
      "Epoch 00062: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0161 - acc: 0.9949 - val_loss: 0.1725 - val_acc: 0.9651\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9949\n",
      "Epoch 00063: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0171 - acc: 0.9949 - val_loss: 0.1808 - val_acc: 0.9560\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9924\n",
      "Epoch 00064: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0240 - acc: 0.9924 - val_loss: 0.1776 - val_acc: 0.9599\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9905\n",
      "Epoch 00065: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0305 - acc: 0.9905 - val_loss: 0.1560 - val_acc: 0.9660\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9946\n",
      "Epoch 00066: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0188 - acc: 0.9946 - val_loss: 0.2199 - val_acc: 0.9578\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9926\n",
      "Epoch 00067: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0235 - acc: 0.9926 - val_loss: 0.1402 - val_acc: 0.9665\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9969\n",
      "Epoch 00068: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0109 - acc: 0.9969 - val_loss: 0.1782 - val_acc: 0.9620\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9953\n",
      "Epoch 00069: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0157 - acc: 0.9953 - val_loss: 0.1733 - val_acc: 0.9639\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9943\n",
      "Epoch 00070: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0178 - acc: 0.9943 - val_loss: 0.1808 - val_acc: 0.9597\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9926\n",
      "Epoch 00071: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0226 - acc: 0.9926 - val_loss: 0.1911 - val_acc: 0.9613\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9960\n",
      "Epoch 00072: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0133 - acc: 0.9960 - val_loss: 0.2280 - val_acc: 0.9467\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9952\n",
      "Epoch 00073: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0164 - acc: 0.9951 - val_loss: 0.1858 - val_acc: 0.9618\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9927\n",
      "Epoch 00074: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0242 - acc: 0.9927 - val_loss: 0.1540 - val_acc: 0.9651\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9964\n",
      "Epoch 00075: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0119 - acc: 0.9964 - val_loss: 0.1687 - val_acc: 0.9634\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9955\n",
      "Epoch 00076: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0138 - acc: 0.9954 - val_loss: 0.1911 - val_acc: 0.9564\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9901\n",
      "Epoch 00077: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0320 - acc: 0.9901 - val_loss: 0.1423 - val_acc: 0.9695\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9970\n",
      "Epoch 00078: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0104 - acc: 0.9970 - val_loss: 0.1332 - val_acc: 0.9709\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9975\n",
      "Epoch 00079: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0091 - acc: 0.9975 - val_loss: 0.1802 - val_acc: 0.9644\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9970\n",
      "Epoch 00080: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0111 - acc: 0.9970 - val_loss: 0.1681 - val_acc: 0.9651\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9924\n",
      "Epoch 00081: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0253 - acc: 0.9924 - val_loss: 0.1782 - val_acc: 0.9627\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9933\n",
      "Epoch 00082: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0224 - acc: 0.9933 - val_loss: 0.1677 - val_acc: 0.9669\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9936\n",
      "Epoch 00083: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0218 - acc: 0.9935 - val_loss: 0.1787 - val_acc: 0.9618\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9954\n",
      "Epoch 00084: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0151 - acc: 0.9954 - val_loss: 0.1583 - val_acc: 0.9683\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9969\n",
      "Epoch 00085: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0101 - acc: 0.9969 - val_loss: 0.1829 - val_acc: 0.9613\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9977\n",
      "Epoch 00086: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0083 - acc: 0.9977 - val_loss: 0.1788 - val_acc: 0.9634\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9958\n",
      "Epoch 00087: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0136 - acc: 0.9958 - val_loss: 0.1740 - val_acc: 0.9623\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9964\n",
      "Epoch 00088: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0125 - acc: 0.9963 - val_loss: 0.2272 - val_acc: 0.9560\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9923\n",
      "Epoch 00089: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0241 - acc: 0.9923 - val_loss: 0.1845 - val_acc: 0.9606\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9971\n",
      "Epoch 00090: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0093 - acc: 0.9971 - val_loss: 0.1780 - val_acc: 0.9632\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9942\n",
      "Epoch 00091: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0178 - acc: 0.9942 - val_loss: 0.1883 - val_acc: 0.9639\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9969\n",
      "Epoch 00092: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 0.0101 - acc: 0.9969 - val_loss: 0.1730 - val_acc: 0.9634\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9981\n",
      "Epoch 00093: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0073 - acc: 0.9981 - val_loss: 0.2027 - val_acc: 0.9623\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9961\n",
      "Epoch 00094: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0124 - acc: 0.9961 - val_loss: 0.2262 - val_acc: 0.9532\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9960\n",
      "Epoch 00095: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0136 - acc: 0.9960 - val_loss: 0.1494 - val_acc: 0.9676\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9965\n",
      "Epoch 00096: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0113 - acc: 0.9965 - val_loss: 0.1617 - val_acc: 0.9627\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9961\n",
      "Epoch 00097: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0118 - acc: 0.9961 - val_loss: 0.1729 - val_acc: 0.9674\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9977\n",
      "Epoch 00098: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0082 - acc: 0.9977 - val_loss: 0.1735 - val_acc: 0.9658\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9963\n",
      "Epoch 00099: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0115 - acc: 0.9963 - val_loss: 0.1895 - val_acc: 0.9623\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9952\n",
      "Epoch 00100: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0154 - acc: 0.9952 - val_loss: 0.2005 - val_acc: 0.9613\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9950\n",
      "Epoch 00101: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0144 - acc: 0.9950 - val_loss: 0.1762 - val_acc: 0.9644\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9978\n",
      "Epoch 00102: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0083 - acc: 0.9978 - val_loss: 0.2161 - val_acc: 0.9599\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9965\n",
      "Epoch 00103: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0107 - acc: 0.9965 - val_loss: 0.1671 - val_acc: 0.9618\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9963\n",
      "Epoch 00104: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0115 - acc: 0.9963 - val_loss: 0.1634 - val_acc: 0.9618\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9969\n",
      "Epoch 00105: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0112 - acc: 0.9969 - val_loss: 0.1968 - val_acc: 0.9611\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9968\n",
      "Epoch 00106: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0103 - acc: 0.9968 - val_loss: 0.2031 - val_acc: 0.9576\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9949\n",
      "Epoch 00107: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0168 - acc: 0.9949 - val_loss: 0.1550 - val_acc: 0.9658\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9978\n",
      "Epoch 00108: val_loss did not improve from 0.12456\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0079 - acc: 0.9978 - val_loss: 0.1582 - val_acc: 0.9665\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1675 - acc: 0.9585\n",
      "Loss: 0.1674612254484606 Accuracy: 0.95846313\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0037 - acc: 0.4027\n",
      "Epoch 00001: val_loss improved from inf to 1.13555, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv_checkpoint/001-1.1355.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 2.0039 - acc: 0.4027 - val_loss: 1.1355 - val_acc: 0.6415\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8605 - acc: 0.7291\n",
      "Epoch 00002: val_loss improved from 1.13555 to 0.53446, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv_checkpoint/002-0.5345.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.8604 - acc: 0.7291 - val_loss: 0.5345 - val_acc: 0.8321\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5539 - acc: 0.8273\n",
      "Epoch 00003: val_loss improved from 0.53446 to 0.37381, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv_checkpoint/003-0.3738.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.5539 - acc: 0.8273 - val_loss: 0.3738 - val_acc: 0.8821\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4210 - acc: 0.8697\n",
      "Epoch 00004: val_loss improved from 0.37381 to 0.29608, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv_checkpoint/004-0.2961.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.4210 - acc: 0.8697 - val_loss: 0.2961 - val_acc: 0.9106\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3389 - acc: 0.8951\n",
      "Epoch 00005: val_loss did not improve from 0.29608\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.3389 - acc: 0.8950 - val_loss: 0.3707 - val_acc: 0.8826\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2851 - acc: 0.9114\n",
      "Epoch 00006: val_loss improved from 0.29608 to 0.23902, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv_checkpoint/006-0.2390.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.2851 - acc: 0.9114 - val_loss: 0.2390 - val_acc: 0.9285\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2452 - acc: 0.9217\n",
      "Epoch 00007: val_loss did not improve from 0.23902\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.2452 - acc: 0.9217 - val_loss: 0.4579 - val_acc: 0.8549\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2134 - acc: 0.9336\n",
      "Epoch 00008: val_loss improved from 0.23902 to 0.19558, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv_checkpoint/008-0.1956.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.2134 - acc: 0.9336 - val_loss: 0.1956 - val_acc: 0.9415\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9396\n",
      "Epoch 00009: val_loss did not improve from 0.19558\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1919 - acc: 0.9396 - val_loss: 0.2399 - val_acc: 0.9299\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1659 - acc: 0.9470\n",
      "Epoch 00010: val_loss did not improve from 0.19558\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1659 - acc: 0.9470 - val_loss: 0.2441 - val_acc: 0.9255\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9518\n",
      "Epoch 00011: val_loss did not improve from 0.19558\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1543 - acc: 0.9518 - val_loss: 0.2154 - val_acc: 0.9364\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9567\n",
      "Epoch 00012: val_loss did not improve from 0.19558\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1344 - acc: 0.9567 - val_loss: 0.2839 - val_acc: 0.9119\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9608\n",
      "Epoch 00013: val_loss improved from 0.19558 to 0.18417, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv_checkpoint/013-0.1842.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1227 - acc: 0.9607 - val_loss: 0.1842 - val_acc: 0.9411\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9623\n",
      "Epoch 00014: val_loss improved from 0.18417 to 0.18060, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv_checkpoint/014-0.1806.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1160 - acc: 0.9623 - val_loss: 0.1806 - val_acc: 0.9469\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9665\n",
      "Epoch 00015: val_loss did not improve from 0.18060\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1029 - acc: 0.9665 - val_loss: 0.1935 - val_acc: 0.9418\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9697\n",
      "Epoch 00016: val_loss did not improve from 0.18060\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0942 - acc: 0.9697 - val_loss: 0.1860 - val_acc: 0.9481\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9725\n",
      "Epoch 00017: val_loss did not improve from 0.18060\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0875 - acc: 0.9725 - val_loss: 0.2070 - val_acc: 0.9387\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9757\n",
      "Epoch 00018: val_loss did not improve from 0.18060\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0783 - acc: 0.9756 - val_loss: 0.1956 - val_acc: 0.9425\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9722\n",
      "Epoch 00019: val_loss did not improve from 0.18060\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0856 - acc: 0.9721 - val_loss: 0.2292 - val_acc: 0.9341\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9766\n",
      "Epoch 00020: val_loss did not improve from 0.18060\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0741 - acc: 0.9766 - val_loss: 0.1969 - val_acc: 0.9439\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9804\n",
      "Epoch 00021: val_loss did not improve from 0.18060\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0618 - acc: 0.9803 - val_loss: 0.1836 - val_acc: 0.9497\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9771\n",
      "Epoch 00022: val_loss did not improve from 0.18060\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0710 - acc: 0.9771 - val_loss: 0.1873 - val_acc: 0.9478\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9838\n",
      "Epoch 00023: val_loss improved from 0.18060 to 0.15069, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv_checkpoint/023-0.1507.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0513 - acc: 0.9838 - val_loss: 0.1507 - val_acc: 0.9595\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9849\n",
      "Epoch 00024: val_loss did not improve from 0.15069\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0482 - acc: 0.9849 - val_loss: 0.1956 - val_acc: 0.9432\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9847\n",
      "Epoch 00025: val_loss did not improve from 0.15069\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0493 - acc: 0.9847 - val_loss: 0.1956 - val_acc: 0.9478\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9799\n",
      "Epoch 00026: val_loss improved from 0.15069 to 0.13635, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv_checkpoint/026-0.1363.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0633 - acc: 0.9799 - val_loss: 0.1363 - val_acc: 0.9616\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9880\n",
      "Epoch 00027: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0396 - acc: 0.9880 - val_loss: 0.1681 - val_acc: 0.9536\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9869\n",
      "Epoch 00028: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0422 - acc: 0.9869 - val_loss: 0.2224 - val_acc: 0.9411\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9845\n",
      "Epoch 00029: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0484 - acc: 0.9845 - val_loss: 0.2002 - val_acc: 0.9467\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9891\n",
      "Epoch 00030: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0353 - acc: 0.9891 - val_loss: 0.1788 - val_acc: 0.9522\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9899\n",
      "Epoch 00031: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0330 - acc: 0.9899 - val_loss: 0.2111 - val_acc: 0.9497\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9862\n",
      "Epoch 00032: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0422 - acc: 0.9862 - val_loss: 0.1554 - val_acc: 0.9571\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9900\n",
      "Epoch 00033: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0311 - acc: 0.9900 - val_loss: 0.1873 - val_acc: 0.9550\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9905\n",
      "Epoch 00034: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0306 - acc: 0.9905 - val_loss: 0.1757 - val_acc: 0.9553\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9864\n",
      "Epoch 00035: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0423 - acc: 0.9864 - val_loss: 0.2018 - val_acc: 0.9509\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9925\n",
      "Epoch 00036: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0242 - acc: 0.9925 - val_loss: 0.1634 - val_acc: 0.9602\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9897\n",
      "Epoch 00037: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0321 - acc: 0.9897 - val_loss: 0.1743 - val_acc: 0.9564\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9926\n",
      "Epoch 00038: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0241 - acc: 0.9926 - val_loss: 0.1645 - val_acc: 0.9571\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9937\n",
      "Epoch 00039: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0217 - acc: 0.9937 - val_loss: 0.1975 - val_acc: 0.9502\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9901\n",
      "Epoch 00040: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0313 - acc: 0.9901 - val_loss: 0.1449 - val_acc: 0.9620\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9929\n",
      "Epoch 00041: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0235 - acc: 0.9929 - val_loss: 0.1601 - val_acc: 0.9625\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9933\n",
      "Epoch 00042: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0225 - acc: 0.9933 - val_loss: 0.1708 - val_acc: 0.9592\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9927\n",
      "Epoch 00043: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0229 - acc: 0.9927 - val_loss: 0.1612 - val_acc: 0.9553\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9927\n",
      "Epoch 00044: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0228 - acc: 0.9927 - val_loss: 0.1937 - val_acc: 0.9536\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9898\n",
      "Epoch 00045: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0320 - acc: 0.9898 - val_loss: 0.1693 - val_acc: 0.9576\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9952\n",
      "Epoch 00046: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0176 - acc: 0.9952 - val_loss: 0.2232 - val_acc: 0.9471\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9930\n",
      "Epoch 00047: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0227 - acc: 0.9930 - val_loss: 0.1737 - val_acc: 0.9606\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9957\n",
      "Epoch 00048: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0145 - acc: 0.9957 - val_loss: 0.1835 - val_acc: 0.9578\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9961\n",
      "Epoch 00049: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0143 - acc: 0.9961 - val_loss: 0.1952 - val_acc: 0.9529\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9933\n",
      "Epoch 00050: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0224 - acc: 0.9933 - val_loss: 0.1870 - val_acc: 0.9513\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9940\n",
      "Epoch 00051: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0184 - acc: 0.9940 - val_loss: 0.1624 - val_acc: 0.9602\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9941\n",
      "Epoch 00052: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0186 - acc: 0.9941 - val_loss: 0.2240 - val_acc: 0.9455\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9957\n",
      "Epoch 00053: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0150 - acc: 0.9957 - val_loss: 0.2206 - val_acc: 0.9522\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9931\n",
      "Epoch 00054: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0222 - acc: 0.9931 - val_loss: 0.2220 - val_acc: 0.9525\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9960\n",
      "Epoch 00055: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0129 - acc: 0.9960 - val_loss: 0.1504 - val_acc: 0.9637\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9962\n",
      "Epoch 00056: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0122 - acc: 0.9962 - val_loss: 0.3586 - val_acc: 0.9180\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9958\n",
      "Epoch 00057: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0147 - acc: 0.9958 - val_loss: 0.1702 - val_acc: 0.9599\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9896\n",
      "Epoch 00058: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0329 - acc: 0.9896 - val_loss: 0.1939 - val_acc: 0.9581\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9964\n",
      "Epoch 00059: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0120 - acc: 0.9963 - val_loss: 0.1535 - val_acc: 0.9646\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9932\n",
      "Epoch 00060: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0220 - acc: 0.9931 - val_loss: 0.1817 - val_acc: 0.9590\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9953\n",
      "Epoch 00061: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0156 - acc: 0.9953 - val_loss: 0.1585 - val_acc: 0.9651\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9974\n",
      "Epoch 00062: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0097 - acc: 0.9974 - val_loss: 0.1773 - val_acc: 0.9604\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 00063: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0127 - acc: 0.9960 - val_loss: 0.2468 - val_acc: 0.9483\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9949\n",
      "Epoch 00064: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0158 - acc: 0.9949 - val_loss: 0.1896 - val_acc: 0.9560\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9956\n",
      "Epoch 00065: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0142 - acc: 0.9956 - val_loss: 0.1796 - val_acc: 0.9599\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9940\n",
      "Epoch 00066: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0198 - acc: 0.9940 - val_loss: 0.1664 - val_acc: 0.9637\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9968\n",
      "Epoch 00067: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0110 - acc: 0.9967 - val_loss: 0.1598 - val_acc: 0.9639\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9942\n",
      "Epoch 00068: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0198 - acc: 0.9942 - val_loss: 0.2071 - val_acc: 0.9553\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9978\n",
      "Epoch 00069: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0080 - acc: 0.9977 - val_loss: 0.1683 - val_acc: 0.9634\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9933\n",
      "Epoch 00070: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0222 - acc: 0.9933 - val_loss: 0.1491 - val_acc: 0.9674\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9953\n",
      "Epoch 00071: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0159 - acc: 0.9953 - val_loss: 0.1681 - val_acc: 0.9639\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9982\n",
      "Epoch 00072: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0073 - acc: 0.9982 - val_loss: 0.1709 - val_acc: 0.9639\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9970\n",
      "Epoch 00073: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0096 - acc: 0.9970 - val_loss: 0.2969 - val_acc: 0.9453\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9964\n",
      "Epoch 00074: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0114 - acc: 0.9964 - val_loss: 0.2661 - val_acc: 0.9455\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9939\n",
      "Epoch 00075: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0201 - acc: 0.9939 - val_loss: 0.1872 - val_acc: 0.9597\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9968\n",
      "Epoch 00076: val_loss did not improve from 0.13635\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0117 - acc: 0.9967 - val_loss: 0.1889 - val_acc: 0.9567\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 976us/sample - loss: 0.1817 - acc: 0.9553\n",
      "Loss: 0.18170474947353793 Accuracy: 0.9553479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 14):\n",
    "    base = '1D_CNN_custom_pool_2_ch_32_DO_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_ch_32_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_88 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,058,896\n",
      "Trainable params: 2,058,704\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 862us/sample - loss: 1.7968 - acc: 0.4739\n",
      "Loss: 1.796771149942313 Accuracy: 0.4739356\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_91 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,040,176\n",
      "Trainable params: 1,039,920\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 877us/sample - loss: 1.3985 - acc: 0.5985\n",
      "Loss: 1.3984589152123204 Accuracy: 0.5985462\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_95 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,050,736\n",
      "Trainable params: 1,050,352\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 943us/sample - loss: 1.3318 - acc: 0.6422\n",
      "Loss: 1.3317909630659586 Accuracy: 0.64215994\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_100 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 559,536\n",
      "Trainable params: 559,024\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.8959 - acc: 0.7481\n",
      "Loss: 0.8959385441471112 Accuracy: 0.74807894\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_106 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 324,336\n",
      "Trainable params: 323,696\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.6977 - acc: 0.8123\n",
      "Loss: 0.6976641787918186 Accuracy: 0.81225336\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_113 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                128016    \n",
      "=================================================================\n",
      "Total params: 217,136\n",
      "Trainable params: 216,368\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.5010 - acc: 0.8779\n",
      "Loss: 0.5010117996023699 Accuracy: 0.87788165\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_121 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 257,712\n",
      "Trainable params: 256,688\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.3824 - acc: 0.8989\n",
      "Loss: 0.3823787293577739 Accuracy: 0.8988577\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_130 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                63504     \n",
      "=================================================================\n",
      "Total params: 276,784\n",
      "Trainable params: 275,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2690 - acc: 0.9263\n",
      "Loss: 0.2690025930804503 Accuracy: 0.9262721\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_140 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                30736     \n",
      "=================================================================\n",
      "Total params: 326,576\n",
      "Trainable params: 325,040\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1830 - acc: 0.9502\n",
      "Loss: 0.1829569949479319 Accuracy: 0.95015574\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_151 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 392,752\n",
      "Trainable params: 390,960\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1675 - acc: 0.9585\n",
      "Loss: 0.1674612254484606 Accuracy: 0.95846313\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_163 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                12304     \n",
      "=================================================================\n",
      "Total params: 555,824\n",
      "Trainable params: 553,520\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1817 - acc: 0.9553\n",
      "Loss: 0.18170474947353793 Accuracy: 0.9553479\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_pool_2_ch_32_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 14):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_88 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,058,896\n",
      "Trainable params: 2,058,704\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 3.5015 - acc: 0.4924\n",
      "Loss: 3.501530915702986 Accuracy: 0.4924195\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_91 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,040,176\n",
      "Trainable params: 1,039,920\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.0261 - acc: 0.6372\n",
      "Loss: 2.0260566637647237 Accuracy: 0.6371755\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_95 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,050,736\n",
      "Trainable params: 1,050,352\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.7536 - acc: 0.6808\n",
      "Loss: 1.7535890278415145 Accuracy: 0.6807892\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_100 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 559,536\n",
      "Trainable params: 559,024\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.1897 - acc: 0.7410\n",
      "Loss: 1.189709453815488 Accuracy: 0.74101764\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_106 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 324,336\n",
      "Trainable params: 323,696\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.7833 - acc: 0.8235\n",
      "Loss: 0.7833376250410624 Accuracy: 0.8234683\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_113 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                128016    \n",
      "=================================================================\n",
      "Total params: 217,136\n",
      "Trainable params: 216,368\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.5592 - acc: 0.8758\n",
      "Loss: 0.5591648040159469 Accuracy: 0.8758048\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_121 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 257,712\n",
      "Trainable params: 256,688\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.4565 - acc: 0.9057\n",
      "Loss: 0.4565377076219299 Accuracy: 0.9057113\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_10_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_130 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                63504     \n",
      "=================================================================\n",
      "Total params: 276,784\n",
      "Trainable params: 275,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.3111 - acc: 0.9321\n",
      "Loss: 0.31109430122876836 Accuracy: 0.93208724\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_11_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_140 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                30736     \n",
      "=================================================================\n",
      "Total params: 326,576\n",
      "Trainable params: 325,040\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.2244 - acc: 0.9495\n",
      "Loss: 0.22439268051684366 Accuracy: 0.9495327\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_12_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_151 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 392,752\n",
      "Trainable params: 390,960\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2067 - acc: 0.9510\n",
      "Loss: 0.206679875364765 Accuracy: 0.9509865\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_DO_BN_13_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_163 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                12304     \n",
      "=================================================================\n",
      "Total params: 555,824\n",
      "Trainable params: 553,520\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2602 - acc: 0.9464\n",
      "Loss: 0.2601728303405347 Accuracy: 0.94641745\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 14):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
