{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5,6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_ch_32_DO_BN(conv_num=1):\n",
    "    kernel_size = 64\n",
    "    filter_size = 128\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3*kernel_size, filters=filter_size, strides=1, \n",
    "                      padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        target_kernel_size = 3 * (kernel_size//(2**(i+1)))\n",
    "        model.add(Conv1D (kernel_size=target_kernel_size if target_kernel_size != 0 else 3, \n",
    "                          filters=filter_size*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())    \n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 128)        24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 128)        1572992   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5333, 128)         786560    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 6,025,104\n",
      "Trainable params: 6,024,336\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 128)        24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 128)        1572992   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 128)         786560    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1777, 128)         393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 3,992,080\n",
      "Trainable params: 3,991,056\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 16000, 128)        24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 128)        1572992   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 5333, 128)         786560    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 1777, 128)         393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 592, 256)          393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 3,981,072\n",
      "Trainable params: 3,979,536\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 128)        24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 128)        1572992   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 5333, 128)         786560    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1777, 128)         393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 592, 256)          393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 197, 256)          393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 3,834,896\n",
      "Trainable params: 3,832,848\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 16000, 128)        24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 16000, 128)        1572992   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 5333, 128)         786560    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 1777, 128)         393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 592, 256)          393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 197, 256)          393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 65, 256)           196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 3,852,560\n",
      "Trainable params: 3,850,000\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 16000, 128)        24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 16000, 128)        1572992   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 5333, 128)         786560    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 1777, 128)         393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 256)          393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 197, 256)          393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 65, 256)           196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 21, 256)           196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 3,993,104\n",
      "Trainable params: 3,990,032\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 16000, 128)        24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 16000, 128)        1572992   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 128)         786560    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 128)         393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 592, 256)          393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 197, 256)          393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 65, 256)           196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 21, 256)           196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 7, 512)            393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 7, 512)            2048      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 4,376,592\n",
      "Trainable params: 4,372,496\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model = build_1d_cnn_custom_ch_32_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.5918 - acc: 0.3699\n",
      "Epoch 00001: val_loss improved from inf to 2.16208, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_3_conv_checkpoint/001-2.1621.hdf5\n",
      "36805/36805 [==============================] - 387s 11ms/sample - loss: 3.5913 - acc: 0.3700 - val_loss: 2.1621 - val_acc: 0.4521\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8277 - acc: 0.5726\n",
      "Epoch 00002: val_loss improved from 2.16208 to 1.73431, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_3_conv_checkpoint/002-1.7343.hdf5\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 1.8279 - acc: 0.5726 - val_loss: 1.7343 - val_acc: 0.5940\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4230 - acc: 0.6615\n",
      "Epoch 00003: val_loss improved from 1.73431 to 1.31500, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_3_conv_checkpoint/003-1.3150.hdf5\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 1.4231 - acc: 0.6614 - val_loss: 1.3150 - val_acc: 0.6229\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9746 - acc: 0.7097\n",
      "Epoch 00004: val_loss improved from 1.31500 to 0.98110, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_3_conv_checkpoint/004-0.9811.hdf5\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.9747 - acc: 0.7097 - val_loss: 0.9811 - val_acc: 0.7039\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8650 - acc: 0.7433\n",
      "Epoch 00005: val_loss did not improve from 0.98110\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.8649 - acc: 0.7434 - val_loss: 1.0372 - val_acc: 0.7160\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7569 - acc: 0.7723\n",
      "Epoch 00006: val_loss did not improve from 0.98110\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.7570 - acc: 0.7723 - val_loss: 1.1728 - val_acc: 0.6713\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6935 - acc: 0.7873\n",
      "Epoch 00007: val_loss improved from 0.98110 to 0.89268, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_3_conv_checkpoint/007-0.8927.hdf5\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.6935 - acc: 0.7873 - val_loss: 0.8927 - val_acc: 0.7389\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5824 - acc: 0.8222\n",
      "Epoch 00008: val_loss did not improve from 0.89268\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.5827 - acc: 0.8221 - val_loss: 1.1070 - val_acc: 0.7109\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5425 - acc: 0.8329\n",
      "Epoch 00009: val_loss did not improve from 0.89268\n",
      "36805/36805 [==============================] - 382s 10ms/sample - loss: 0.5425 - acc: 0.8328 - val_loss: 0.9603 - val_acc: 0.7424\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4617 - acc: 0.8581\n",
      "Epoch 00010: val_loss did not improve from 0.89268\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.4616 - acc: 0.8581 - val_loss: 0.9345 - val_acc: 0.7547\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4138 - acc: 0.8730\n",
      "Epoch 00011: val_loss improved from 0.89268 to 0.87066, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_3_conv_checkpoint/011-0.8707.hdf5\n",
      "36805/36805 [==============================] - 382s 10ms/sample - loss: 0.4138 - acc: 0.8730 - val_loss: 0.8707 - val_acc: 0.7808\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3769 - acc: 0.8816\n",
      "Epoch 00012: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.3769 - acc: 0.8816 - val_loss: 0.9046 - val_acc: 0.7850\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3210 - acc: 0.8988\n",
      "Epoch 00013: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.3212 - acc: 0.8988 - val_loss: 1.2475 - val_acc: 0.7184\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3041 - acc: 0.9049\n",
      "Epoch 00014: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 382s 10ms/sample - loss: 0.3040 - acc: 0.9050 - val_loss: 0.9324 - val_acc: 0.7787\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2595 - acc: 0.9185\n",
      "Epoch 00015: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.2597 - acc: 0.9184 - val_loss: 1.1994 - val_acc: 0.7538\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2598 - acc: 0.9196\n",
      "Epoch 00016: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.2597 - acc: 0.9197 - val_loss: 1.1328 - val_acc: 0.7559\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2025 - acc: 0.9351\n",
      "Epoch 00017: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 382s 10ms/sample - loss: 0.2025 - acc: 0.9351 - val_loss: 1.1144 - val_acc: 0.7575\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1968 - acc: 0.9364\n",
      "Epoch 00018: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.1968 - acc: 0.9364 - val_loss: 1.0605 - val_acc: 0.7801\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9484\n",
      "Epoch 00019: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.1646 - acc: 0.9483 - val_loss: 1.3475 - val_acc: 0.7426\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2062 - acc: 0.9379\n",
      "Epoch 00020: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.2064 - acc: 0.9379 - val_loss: 1.0697 - val_acc: 0.7799\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9500\n",
      "Epoch 00021: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.1627 - acc: 0.9500 - val_loss: 1.0947 - val_acc: 0.7789\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9573\n",
      "Epoch 00022: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.1353 - acc: 0.9573 - val_loss: 1.1411 - val_acc: 0.7857\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9579\n",
      "Epoch 00023: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.1376 - acc: 0.9579 - val_loss: 1.0715 - val_acc: 0.7913\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9624\n",
      "Epoch 00024: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.1209 - acc: 0.9624 - val_loss: 1.0951 - val_acc: 0.7883\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9532\n",
      "Epoch 00025: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.1541 - acc: 0.9532 - val_loss: 1.0887 - val_acc: 0.7934\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9487\n",
      "Epoch 00026: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.1770 - acc: 0.9487 - val_loss: 1.1572 - val_acc: 0.7883\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9751\n",
      "Epoch 00027: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 377s 10ms/sample - loss: 0.0860 - acc: 0.9751 - val_loss: 1.1170 - val_acc: 0.7952\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9670\n",
      "Epoch 00028: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.1100 - acc: 0.9670 - val_loss: 1.1258 - val_acc: 0.7992\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9662\n",
      "Epoch 00029: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 378s 10ms/sample - loss: 0.1150 - acc: 0.9662 - val_loss: 1.0194 - val_acc: 0.8120\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9775\n",
      "Epoch 00030: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.0748 - acc: 0.9774 - val_loss: 1.1142 - val_acc: 0.7999\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9682\n",
      "Epoch 00031: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.1110 - acc: 0.9682 - val_loss: 1.2277 - val_acc: 0.7794\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9774\n",
      "Epoch 00032: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.0754 - acc: 0.9774 - val_loss: 1.0901 - val_acc: 0.8141\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9782\n",
      "Epoch 00033: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 379s 10ms/sample - loss: 0.0734 - acc: 0.9782 - val_loss: 1.1009 - val_acc: 0.8039\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9715\n",
      "Epoch 00034: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.0951 - acc: 0.9715 - val_loss: 1.2479 - val_acc: 0.7866\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9786\n",
      "Epoch 00035: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.0729 - acc: 0.9785 - val_loss: 1.1311 - val_acc: 0.8081\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9748\n",
      "Epoch 00036: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.0867 - acc: 0.9748 - val_loss: 1.0920 - val_acc: 0.8046\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9779\n",
      "Epoch 00037: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 378s 10ms/sample - loss: 0.0777 - acc: 0.9779 - val_loss: 1.1735 - val_acc: 0.7950\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9782\n",
      "Epoch 00038: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 379s 10ms/sample - loss: 0.0756 - acc: 0.9782 - val_loss: 1.1200 - val_acc: 0.8015\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9835\n",
      "Epoch 00039: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 378s 10ms/sample - loss: 0.0580 - acc: 0.9835 - val_loss: 1.2876 - val_acc: 0.8013\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9813\n",
      "Epoch 00040: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.0645 - acc: 0.9813 - val_loss: 1.2317 - val_acc: 0.7964\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9790\n",
      "Epoch 00041: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.0742 - acc: 0.9791 - val_loss: 1.2917 - val_acc: 0.7878\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9843\n",
      "Epoch 00042: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 382s 10ms/sample - loss: 0.0537 - acc: 0.9843 - val_loss: 1.2062 - val_acc: 0.8127\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9809\n",
      "Epoch 00043: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 379s 10ms/sample - loss: 0.0675 - acc: 0.9809 - val_loss: 1.5307 - val_acc: 0.7619\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9828\n",
      "Epoch 00044: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 382s 10ms/sample - loss: 0.0590 - acc: 0.9828 - val_loss: 1.1600 - val_acc: 0.8118\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9871\n",
      "Epoch 00045: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.0457 - acc: 0.9871 - val_loss: 1.1954 - val_acc: 0.8055\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9835\n",
      "Epoch 00046: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 379s 10ms/sample - loss: 0.0605 - acc: 0.9835 - val_loss: 1.4299 - val_acc: 0.7671\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9858\n",
      "Epoch 00047: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.0543 - acc: 0.9858 - val_loss: 1.0632 - val_acc: 0.8255\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9853\n",
      "Epoch 00048: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 382s 10ms/sample - loss: 0.0525 - acc: 0.9853 - val_loss: 1.2179 - val_acc: 0.7992\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9824\n",
      "Epoch 00049: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 382s 10ms/sample - loss: 0.0651 - acc: 0.9824 - val_loss: 1.4072 - val_acc: 0.7873\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9894\n",
      "Epoch 00050: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.0423 - acc: 0.9894 - val_loss: 1.3638 - val_acc: 0.7943\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9874\n",
      "Epoch 00051: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.0472 - acc: 0.9874 - val_loss: 1.2969 - val_acc: 0.7939\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9861\n",
      "Epoch 00052: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 379s 10ms/sample - loss: 0.0493 - acc: 0.9861 - val_loss: 1.0802 - val_acc: 0.8248\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9878\n",
      "Epoch 00053: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.0468 - acc: 0.9878 - val_loss: 1.2417 - val_acc: 0.8013\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9845\n",
      "Epoch 00054: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.0573 - acc: 0.9845 - val_loss: 1.1269 - val_acc: 0.8195\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9884\n",
      "Epoch 00055: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 382s 10ms/sample - loss: 0.0425 - acc: 0.9884 - val_loss: 1.1725 - val_acc: 0.8176\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9916\n",
      "Epoch 00056: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.0347 - acc: 0.9916 - val_loss: 1.2325 - val_acc: 0.8067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9839\n",
      "Epoch 00057: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 380s 10ms/sample - loss: 0.0578 - acc: 0.9838 - val_loss: 1.1663 - val_acc: 0.8116\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9882\n",
      "Epoch 00058: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 382s 10ms/sample - loss: 0.0448 - acc: 0.9882 - val_loss: 1.1414 - val_acc: 0.8246\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9920\n",
      "Epoch 00059: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 376s 10ms/sample - loss: 0.0325 - acc: 0.9920 - val_loss: 1.2371 - val_acc: 0.8046\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9868\n",
      "Epoch 00060: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 382s 10ms/sample - loss: 0.0530 - acc: 0.9867 - val_loss: 1.2985 - val_acc: 0.8013\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9886\n",
      "Epoch 00061: val_loss did not improve from 0.87066\n",
      "36805/36805 [==============================] - 381s 10ms/sample - loss: 0.0433 - acc: 0.9886 - val_loss: 1.1833 - val_acc: 0.8216\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 15s 3ms/sample - loss: 1.0545 - acc: 0.7387\n",
      "Loss: 1.0545296205043297 Accuracy: 0.7387331\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0487 - acc: 0.3958\n",
      "Epoch 00001: val_loss improved from inf to 1.36275, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_4_conv_checkpoint/001-1.3627.hdf5\n",
      "36805/36805 [==============================] - 373s 10ms/sample - loss: 2.0486 - acc: 0.3959 - val_loss: 1.3627 - val_acc: 0.5926\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1849 - acc: 0.6327\n",
      "Epoch 00002: val_loss improved from 1.36275 to 0.91128, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_4_conv_checkpoint/002-0.9113.hdf5\n",
      "36805/36805 [==============================] - 388s 11ms/sample - loss: 1.1849 - acc: 0.6328 - val_loss: 0.9113 - val_acc: 0.7205\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9281 - acc: 0.7176\n",
      "Epoch 00003: val_loss did not improve from 0.91128\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.9282 - acc: 0.7176 - val_loss: 1.0774 - val_acc: 0.6741\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7803 - acc: 0.7653\n",
      "Epoch 00004: val_loss improved from 0.91128 to 0.86499, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_4_conv_checkpoint/004-0.8650.hdf5\n",
      "36805/36805 [==============================] - 389s 11ms/sample - loss: 0.7805 - acc: 0.7652 - val_loss: 0.8650 - val_acc: 0.7484\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6853 - acc: 0.7942\n",
      "Epoch 00005: val_loss improved from 0.86499 to 0.83987, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_4_conv_checkpoint/005-0.8399.hdf5\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.6853 - acc: 0.7942 - val_loss: 0.8399 - val_acc: 0.7713\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5973 - acc: 0.8190\n",
      "Epoch 00006: val_loss improved from 0.83987 to 0.71423, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_4_conv_checkpoint/006-0.7142.hdf5\n",
      "36805/36805 [==============================] - 390s 11ms/sample - loss: 0.5975 - acc: 0.8190 - val_loss: 0.7142 - val_acc: 0.8095\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5450 - acc: 0.8360\n",
      "Epoch 00007: val_loss improved from 0.71423 to 0.64260, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_4_conv_checkpoint/007-0.6426.hdf5\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.5451 - acc: 0.8359 - val_loss: 0.6426 - val_acc: 0.8248\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4866 - acc: 0.8531\n",
      "Epoch 00008: val_loss improved from 0.64260 to 0.60428, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_4_conv_checkpoint/008-0.6043.hdf5\n",
      "36805/36805 [==============================] - 388s 11ms/sample - loss: 0.4866 - acc: 0.8531 - val_loss: 0.6043 - val_acc: 0.8388\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4410 - acc: 0.8680\n",
      "Epoch 00009: val_loss improved from 0.60428 to 0.51247, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_4_conv_checkpoint/009-0.5125.hdf5\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.4411 - acc: 0.8680 - val_loss: 0.5125 - val_acc: 0.8574\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4007 - acc: 0.8754\n",
      "Epoch 00010: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 393s 11ms/sample - loss: 0.4010 - acc: 0.8754 - val_loss: 0.5329 - val_acc: 0.8519\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3705 - acc: 0.8849\n",
      "Epoch 00011: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.3706 - acc: 0.8848 - val_loss: 0.6042 - val_acc: 0.8390\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3529 - acc: 0.8910\n",
      "Epoch 00012: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 389s 11ms/sample - loss: 0.3533 - acc: 0.8910 - val_loss: 0.6007 - val_acc: 0.8376\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3258 - acc: 0.8994\n",
      "Epoch 00013: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 406s 11ms/sample - loss: 0.3258 - acc: 0.8994 - val_loss: 0.5490 - val_acc: 0.8584\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2934 - acc: 0.9090\n",
      "Epoch 00014: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 392s 11ms/sample - loss: 0.2934 - acc: 0.9090 - val_loss: 0.5616 - val_acc: 0.8556\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2693 - acc: 0.9153\n",
      "Epoch 00015: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 405s 11ms/sample - loss: 0.2695 - acc: 0.9153 - val_loss: 0.6037 - val_acc: 0.8505\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2614 - acc: 0.9174\n",
      "Epoch 00016: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 391s 11ms/sample - loss: 0.2615 - acc: 0.9174 - val_loss: 0.6251 - val_acc: 0.8353\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2493 - acc: 0.9208\n",
      "Epoch 00017: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.2493 - acc: 0.9208 - val_loss: 0.5194 - val_acc: 0.8737\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2147 - acc: 0.9318\n",
      "Epoch 00018: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 392s 11ms/sample - loss: 0.2148 - acc: 0.9318 - val_loss: 0.6387 - val_acc: 0.8481\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2146 - acc: 0.9307\n",
      "Epoch 00019: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.2147 - acc: 0.9306 - val_loss: 0.5845 - val_acc: 0.8614\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1938 - acc: 0.9372\n",
      "Epoch 00020: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 391s 11ms/sample - loss: 0.1937 - acc: 0.9372 - val_loss: 0.5379 - val_acc: 0.8672\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9434\n",
      "Epoch 00021: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.1793 - acc: 0.9434 - val_loss: 0.5217 - val_acc: 0.8805\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1635 - acc: 0.9473\n",
      "Epoch 00022: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 394s 11ms/sample - loss: 0.1635 - acc: 0.9472 - val_loss: 0.6357 - val_acc: 0.8626\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1671 - acc: 0.9461\n",
      "Epoch 00023: val_loss did not improve from 0.51247\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.1672 - acc: 0.9461 - val_loss: 0.5935 - val_acc: 0.8682\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2155 - acc: 0.9319\n",
      "Epoch 00024: val_loss improved from 0.51247 to 0.49031, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_4_conv_checkpoint/024-0.4903.hdf5\n",
      "36805/36805 [==============================] - 393s 11ms/sample - loss: 0.2156 - acc: 0.9319 - val_loss: 0.4903 - val_acc: 0.8861\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9521\n",
      "Epoch 00025: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.1492 - acc: 0.9521 - val_loss: 0.6004 - val_acc: 0.8719\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9520\n",
      "Epoch 00026: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 396s 11ms/sample - loss: 0.1491 - acc: 0.9520 - val_loss: 0.6125 - val_acc: 0.8591\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9595\n",
      "Epoch 00027: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 405s 11ms/sample - loss: 0.1236 - acc: 0.9594 - val_loss: 0.5969 - val_acc: 0.8744\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9560\n",
      "Epoch 00028: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 393s 11ms/sample - loss: 0.1329 - acc: 0.9560 - val_loss: 0.5286 - val_acc: 0.8877\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9628\n",
      "Epoch 00029: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.1107 - acc: 0.9628 - val_loss: 0.5557 - val_acc: 0.8784\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9657\n",
      "Epoch 00030: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 393s 11ms/sample - loss: 0.1052 - acc: 0.9656 - val_loss: 0.8274 - val_acc: 0.8362\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9609\n",
      "Epoch 00031: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.1196 - acc: 0.9609 - val_loss: 0.6428 - val_acc: 0.8651\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9670\n",
      "Epoch 00032: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 390s 11ms/sample - loss: 0.1004 - acc: 0.9669 - val_loss: 0.7029 - val_acc: 0.8591\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9632\n",
      "Epoch 00033: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.1141 - acc: 0.9632 - val_loss: 0.6792 - val_acc: 0.8675\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9607\n",
      "Epoch 00034: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 388s 11ms/sample - loss: 0.1208 - acc: 0.9606 - val_loss: 0.5791 - val_acc: 0.8803\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9705\n",
      "Epoch 00035: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0896 - acc: 0.9705 - val_loss: 0.5726 - val_acc: 0.8870\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9680\n",
      "Epoch 00036: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 393s 11ms/sample - loss: 0.1014 - acc: 0.9680 - val_loss: 0.6925 - val_acc: 0.8647\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9727\n",
      "Epoch 00037: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0830 - acc: 0.9727 - val_loss: 0.6814 - val_acc: 0.8751\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9711\n",
      "Epoch 00038: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 393s 11ms/sample - loss: 0.0881 - acc: 0.9711 - val_loss: 0.5996 - val_acc: 0.8882\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9702\n",
      "Epoch 00039: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 405s 11ms/sample - loss: 0.0915 - acc: 0.9702 - val_loss: 0.6594 - val_acc: 0.8744\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9745\n",
      "Epoch 00040: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 395s 11ms/sample - loss: 0.0791 - acc: 0.9745 - val_loss: 0.6779 - val_acc: 0.8712\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9764\n",
      "Epoch 00041: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0754 - acc: 0.9763 - val_loss: 0.6895 - val_acc: 0.8744\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9731\n",
      "Epoch 00042: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 394s 11ms/sample - loss: 0.0803 - acc: 0.9731 - val_loss: 0.5699 - val_acc: 0.8938\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9778\n",
      "Epoch 00043: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0677 - acc: 0.9777 - val_loss: 0.6243 - val_acc: 0.8908\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9793\n",
      "Epoch 00044: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 392s 11ms/sample - loss: 0.0636 - acc: 0.9793 - val_loss: 0.5457 - val_acc: 0.8991\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9779\n",
      "Epoch 00045: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0666 - acc: 0.9779 - val_loss: 0.6617 - val_acc: 0.8845\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9737\n",
      "Epoch 00046: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 391s 11ms/sample - loss: 0.0831 - acc: 0.9737 - val_loss: 0.6477 - val_acc: 0.8805\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9792\n",
      "Epoch 00047: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0637 - acc: 0.9792 - val_loss: 0.6873 - val_acc: 0.8810\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9739\n",
      "Epoch 00048: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 388s 11ms/sample - loss: 0.0830 - acc: 0.9738 - val_loss: 0.6134 - val_acc: 0.8908\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9785\n",
      "Epoch 00049: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0683 - acc: 0.9784 - val_loss: 0.6795 - val_acc: 0.8675\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9804\n",
      "Epoch 00050: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 389s 11ms/sample - loss: 0.0623 - acc: 0.9804 - val_loss: 0.6008 - val_acc: 0.8956\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9852\n",
      "Epoch 00051: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0475 - acc: 0.9851 - val_loss: 0.6119 - val_acc: 0.8889\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9801\n",
      "Epoch 00052: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 390s 11ms/sample - loss: 0.0603 - acc: 0.9801 - val_loss: 0.6039 - val_acc: 0.8970\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9820\n",
      "Epoch 00053: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.0554 - acc: 0.9820 - val_loss: 0.6817 - val_acc: 0.8733\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9816\n",
      "Epoch 00054: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 389s 11ms/sample - loss: 0.0589 - acc: 0.9816 - val_loss: 0.6333 - val_acc: 0.8884\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9827\n",
      "Epoch 00055: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0582 - acc: 0.9827 - val_loss: 0.6492 - val_acc: 0.8880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9744\n",
      "Epoch 00056: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 387s 11ms/sample - loss: 0.0864 - acc: 0.9743 - val_loss: 0.7033 - val_acc: 0.8812\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9700\n",
      "Epoch 00057: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.1008 - acc: 0.9699 - val_loss: 0.6293 - val_acc: 0.8919\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9852\n",
      "Epoch 00058: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 391s 11ms/sample - loss: 0.0480 - acc: 0.9851 - val_loss: 0.5837 - val_acc: 0.8966\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9849\n",
      "Epoch 00059: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0491 - acc: 0.9849 - val_loss: 0.6353 - val_acc: 0.8903\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9860\n",
      "Epoch 00060: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 387s 11ms/sample - loss: 0.0463 - acc: 0.9860 - val_loss: 0.6591 - val_acc: 0.8938\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9815\n",
      "Epoch 00061: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0569 - acc: 0.9815 - val_loss: 0.6750 - val_acc: 0.8884\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9854\n",
      "Epoch 00062: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 388s 11ms/sample - loss: 0.0480 - acc: 0.9854 - val_loss: 0.5725 - val_acc: 0.8954\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9886\n",
      "Epoch 00063: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0388 - acc: 0.9886 - val_loss: 0.6076 - val_acc: 0.8961\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9861\n",
      "Epoch 00064: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 389s 11ms/sample - loss: 0.0439 - acc: 0.9860 - val_loss: 0.6145 - val_acc: 0.8933\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9815\n",
      "Epoch 00065: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.0590 - acc: 0.9815 - val_loss: 0.7208 - val_acc: 0.8800\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9827\n",
      "Epoch 00066: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 388s 11ms/sample - loss: 0.0559 - acc: 0.9827 - val_loss: 0.6353 - val_acc: 0.8915\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9882\n",
      "Epoch 00067: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.0378 - acc: 0.9881 - val_loss: 0.6403 - val_acc: 0.8977\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9821\n",
      "Epoch 00068: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 388s 11ms/sample - loss: 0.0612 - acc: 0.9821 - val_loss: 0.5801 - val_acc: 0.9001\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9887\n",
      "Epoch 00069: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.0355 - acc: 0.9887 - val_loss: 0.5799 - val_acc: 0.9045\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9847\n",
      "Epoch 00070: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 389s 11ms/sample - loss: 0.0499 - acc: 0.9847 - val_loss: 0.6178 - val_acc: 0.8959\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9876\n",
      "Epoch 00071: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0394 - acc: 0.9875 - val_loss: 0.5926 - val_acc: 0.9031\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9872\n",
      "Epoch 00072: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 389s 11ms/sample - loss: 0.0406 - acc: 0.9872 - val_loss: 0.6730 - val_acc: 0.8896\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9890\n",
      "Epoch 00073: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0342 - acc: 0.9890 - val_loss: 0.7078 - val_acc: 0.8905\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9843\n",
      "Epoch 00074: val_loss did not improve from 0.49031\n",
      "36805/36805 [==============================] - 388s 11ms/sample - loss: 0.0562 - acc: 0.9842 - val_loss: 0.6373 - val_acc: 0.8994\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd81dX5x98nmwyyIYxA2BAIBBKWiGBVBJXhQKxYrfNXa1WqVal2YFurdVRr1SpWW23dAxXU4iIgFCxDluyRmISVQUJCdu7z++PkJjf7ZlzCeN6v1/eV3O/3fM95vnecz3mes4yIoCiKoijN4dXRBiiKoiinBioYiqIoiluoYCiKoihuoYKhKIqiuIUKhqIoiuIWKhiKoiiKW6hgKIqiKG6hgqEoiqK4hQqGoiiK4hY+HW1AexIVFSVxcXEdbYaiKMopw/r167NFJNqdtKeVYMTFxbFu3bqONkNRFOWUwRiT5m5aDUkpiqIobqGCoSiKoriFCoaiKIriFqdVH0ZDlJeXk5GRQUlJSUebckoSEBBAz5498fX17WhTFEXpYE57wcjIyCAkJIS4uDiMMR1tzimFiJCTk0NGRgZ9+vTpaHMURelgTvuQVElJCZGRkSoWrcAYQ2RkpHpniqIAZ4BgACoWbUDfO0VRnJwRgtEcpaUHqKjI72gzFEVRTmpUMICyskNUVBzzSN55eXk899xzrbr3oosuIi8vz+30CxYs4PHHH29VWYqiKM3hMcEwxsQaY5YZY7YZY74zxtzZQBpjjHnaGLPHGLPZGDPK5dp1xpjdVcd1nrLTluUNVHok76YEo6Kiosl7P/nkE8LCwjxhlqIoSovxpIdRAdwtIvHAOOA2Y0x8nTTTgAFVxy3A3wCMMRHAb4GxwBjgt8aYcM+Z6o2IwyM5z58/n71795KYmMg999xDSkoKEydOZMaMGcTH27dj1qxZJCUlMXToUBYuXFh9b1xcHNnZ2aSmpjJkyBBuvvlmhg4dypQpUyguLm6y3I0bNzJu3DiGDx/OpZdeytGjRwF4+umniY+PZ/jw4Vx11VUALF++nMTERBITExk5ciQFBQUeeS8URTm18diwWhE5CBys+r/AGLMd6AFsc0k2E3hVRARYY4wJM8Z0AyYDn4tILoAx5nNgKvBGW2zavXsehYUb6513OIoAg5dXpxbnGRycyIABTzV6/ZFHHmHr1q1s3GjLTUlJYcOGDWzdurV6qOrLL79MREQExcXFjB49mssvv5zIyMg6tu/mjTfe4MUXX+TKK6/kvffe45prrmm03GuvvZa//vWvTJo0id/85jc8+OCDPPXUUzzyyCPs378ff3//6nDX448/zrPPPsuECRMoLCwkICCgxe+DoiinPyekD8MYEweMBL6pc6kHkO7yOqPqXGPnPYh4NnsXxowZU2tew9NPP82IESMYN24c6enp7N69u949ffr0ITExEYCkpCRSU1MbzT8/P5+8vDwmTZoEwHXXXceKFSsAGD58OHPnzuXf//43Pj62vTBhwgTuuusunn76afLy8qrPK4qiuOLxmsEYEwy8B8wTkXbvWTbG3IINZ9GrV68m0zbmCRQV7UaknKCguhEzzxAUFFT9f0pKCl988QWrV68mMDCQyZMnNzjvwd/fv/p/b2/vZkNSjfHxxx+zYsUKFi9ezEMPPcSWLVuYP38+F198MZ988gkTJkxg6dKlDB48uFX5K4py+uJRD8MY44sVi9dE5P0GkmQCsS6ve1ada+x8PURkoYgki0hydLRbS7o3YKc3Ip7p9A4JCWmyTyA/P5/w8HACAwPZsWMHa9asaXOZoaGhhIeH8/XXXwPwr3/9i0mTJuFwOEhPT+fcc8/lT3/6E/n5+RQWFrJ3714SEhK47777GD16NDt27GizDYqinH54zMMwdsbXS8B2EflzI8k+An5mjHkT28GdLyIHjTFLgT+6dHRPAX7pOVu9AM90ekdGRjJhwgSGDRvGtGnTuPjii2tdnzp1Ks8//zxDhgxh0KBBjBs3rl3KfeWVV/jJT35CUVERffv25R//+AeVlZVcc8015OfnIyLccccdhIWF8etf/5ply5bh5eXF0KFDmTZtWrvYoCjK6YWx/c0eyNiYs4GvgS3U1Mb3A70AROT5KlF5BtuhXQRcLyLrqu6/oSo9wEMi8o/mykxOTpa6Gyht376dIUOGNHlfSUk65eVZhISMajLdmYo776GiKKcmxpj1IpLsTlpPjpJaCTS5rkTV6KjbGrn2MvCyB0yrh9PDEBFdCkNRFKURdKY3AN5Vfz0TllIURTkdUMHA6WHgsY5vRVGU0wEVDJxLg+Cx2d6KoiinAyoYQE1ISj0MRVGUxlDBwDUkpR6GoihKY6hgUBOSOlk8jODg4BadVxRFORGoYADOt0E9DEVRlMZRwcC107v9PYz58+fz7LPPVr92bnJUWFjIeeedx6hRo0hISODDDz90O08R4Z577mHYsGEkJCTw1ltvAXDw4EHOOeccEhMTGTZsGF9//TWVlZX8+Mc/rk775JNPtvszKopyZnBmLUs6bx5srL+8uUHoVFmIl5c/GL+W5ZmYCE81vrz5nDlzmDdvHrfdZucnvv322yxdupSAgAAWLVpE586dyc7OZty4ccyYMcOtiYPvv/8+GzduZNOmTWRnZzN69GjOOeccXn/9dS688EIeeOABKisrKSoqYuPGjWRmZrJ161aAFu3gpyiK4sqZJRiNUlVJC83MTW85I0eO5MiRIxw4cICsrCzCw8OJjY2lvLyc+++/nxUrVuDl5UVmZiaHDx8mJiam2TxXrlzJD3/4Q7y9venatSuTJk1i7dq1jB49mhtuuIHy8nJmzZpFYmIiffv2Zd++fdx+++1cfPHFTJkypX0fUFGUM4YzSzAa8QQMUFywHl/frgQE9Gz3YmfPns27777LoUOHmDNnDgCvvfYaWVlZrF+/Hl9fX+Li4hpc1rwlnHPOOaxYsYKPP/6YH//4x9x1111ce+21bNq0iaVLl/L888/z9ttv8/LLJ2TFFUVRTjO0D6MKT+7rPWfOHN58803effddZs+eDdhlzbt06YKvry/Lli0jLS3N7fwmTpzIW2+9RWVlJVlZWaxYsYIxY8aQlpZG165dufnmm7npppvYsGED2dnZOBwOLr/8cv7whz+wYcMGjzyjoiinP2eWh9EkntsTY+jQoRQUFNCjRw+6desGwNy5c5k+fToJCQkkJye3aMOiSy+9lNWrVzNixAiMMTz66KPExMTwyiuv8Nhjj+Hr60twcDCvvvoqmZmZXH/99TgcdgTYww8/7JFnVBTl9Mdjy5t3BK1d3hzg+PHvMMafwMD+njLvlEWXN1eU05eWLG+uIalqPBeSUhRFOR1QwajCGC+duKcoitIEHhMMY8zLxpgjxpitjVy/xxizserYaoypNMZEVF1LNcZsqbq2rqH7299e9TAURVGawpMexj+xW682iIg8JiKJIpKI3a97uYjkuiQ5t+q6W7G1tqMehqIoSlN4TDBEZAWQ22xCyw+BNzxlizsY47lRUoqiKKcDHd6HYYwJxHoi77mcFuAzY8x6Y8wtJ8YOb5z7eiuKoij16XDBAKYDq+qEo84WkVHANOA2Y8w5jd1sjLnFGLPOGLMuKyurDWZ4YXWqfQUjLy+P5557rlX3XnTRRbr2k6IoJw0ng2BcRZ1wlIhkVv09AiwCxjR2s4gsFJFkEUmOjo5utRGeWrG2KcGoqKho8t5PPvmEsLCwdrVHURSltXSoYBhjQoFJwIcu54KMMSHO/4EpQIMjrdoX51vRvh3f8+fPZ+/evSQmJnLPPfeQkpLCxIkTmTFjBvHx8QDMmjWLpKQkhg4dysKFC6vvjYuLIzs7m9TUVIYMGcLNN9/M0KFDmTJlCsXFxfXKWrx4MWPHjmXkyJGcf/75HD58GIDCwkKuv/56EhISGD58OO+9Z6N///nPfxg1ahQjRozgvPPOa9fnVhTl9MNjS4MYY94AJgNRxpgM4LeAL4CIPF+V7FLgMxE57nJrV2BR1TLfPsDrIvKf9rCpkdXNsTaF4nAMwsvLBzdWGK+mmdXNeeSRR9i6dSsbqwpOSUlhw4YNbN26lT59+gDw8ssvExERQXFxMaNHj+byyy8nMjKyVj67d+/mjTfe4MUXX+TKK6/kvffe45prrqmV5uyzz2bNmjUYY/j73//Oo48+yhNPPMHvf/97QkND2bJlCwBHjx4lKyuLm2++mRUrVtCnTx9yc90dn6AoypmKxwRDRH7oRpp/Yoffup7bB4zwjFVN0c7rmjfBmDFjqsUC4Omnn2bRokUApKens3v37nqC0adPHxITEwFISkoiNTW1Xr4ZGRnMmTOHgwcPUlZWVl3GF198wZtvvlmdLjw8nMWLF3POOedUp4mIiGjXZ1QU5fTjjFp8sClPoKKihOLinXTqNAAfn1CP2hEUFFT9f0pKCl988QWrV68mMDCQyZMnN7jMub+/f/X/3t7eDYakbr/9du666y5mzJhBSkoKCxYs8Ij9iqKcmZwMnd4nBcY49/Vu307vkJAQCgoKGr2en59PeHg4gYGB7NixgzVr1rS6rPz8fHr06AHAK6+8Un3+ggsuqLVN7NGjRxk3bhwrVqxg//79ABqSUhSlWVQwqqgZJdW+nd6RkZFMmDCBYcOGcc8999S7PnXqVCoqKhgyZAjz589n3LhxrS5rwYIFzJ49m6SkJKKioqrP/+pXv+Lo0aMMGzaMESNGsGzZMqKjo1m4cCGXXXYZI0aMqN7YSVEUpTF0efMqHI5yjh/fhL9/LH5+XT1l4imJLm+uKKcvurx5K/CUh6EoinK6oIJRjak6dD0pRVGUhlDBqMLO+9AVaxVFURpDBcMFXbFWURSlcVQwXLBDa9XDUBRFaQgVjFqoh6EoitIYKhgunCz7egcHB3e0CYqiKPVQwXBB9/VWFEVpHBWMWrS/hzF//vxay3IsWLCAxx9/nMLCQs477zxGjRpFQkICH374YRO5WBpbBr2hZcobW9JcURSltZxRiw/O+888Nh5qZH1zwOEoQaQCb2/3Q0KJMYk8NbXxVQ3nzJnDvHnzuO222wB4++23Wbp0KQEBASxatIjOnTuTnZ3NuHHjmDFjRtXw3oZpaBl0h8PR4DLlDS1priiK0hbOKMFoHkN7b9E6cuRIjhw5woEDB8jKyiI8PJzY2FjKy8u5//77WbFiBV5eXmRmZnL48GFiYmIazauhZdCzsrIaXKa8oSXNFUVR2oInN1B6GbgEOCIiwxq4Phm7097+qlPvi8jvqq5NBf4CeAN/F5FH2sOmpjwBgNLSA5SVHSA4OKnJln5LmT17Nu+++y6HDh2qXuTvtddeIysri/Xr1+Pr60tcXFyDy5o7cXcZdEVRFE/hyT6MfwJTm0nztYgkVh1OsfAGngWmAfHAD40x8R60sxpP7es9Z84c3nzzTd59911mz54N2KXIu3Tpgq+vL8uWLSMtLa3JPBpbBr2xZcobWtJcURSlLXhMMERkBdCaTRbGAHtEZJ+IlAFvAjPb1bhG8cy+3kOHDqWgoIAePXrQrVs3AObOncu6detISEjg1VdfZfDgwU3m0dgy6I0tU97QkuaKoihtoaP7MMYbYzYBB4BfiMh3QA8g3SVNBjD2RBjjKQ8DqO58dhIVFcXq1asbTFtYWFjvnL+/P59++mmD6adNm8a0adNqnQsODq61iZKiKEpb6UjB2AD0FpFCY8xFwAfAgJZmYoy5BbgFoFevXm0yyCkYujyIoihKfTpsHoaIHBORwqr/PwF8jTFRQCYQ65K0Z9W5xvJZKCLJIpIcHR3dRqs8s02roijK6UCHCYYxJsZUDUUyxoypsiUHWAsMMMb0Mcb4AVcBH7WlLHd3FfRkSOpU5XTakVFRlLbhyWG1bwCTgShjTAbwW8AXQESeB64AbjXGVADFwFVia6cKY8zPgKXYYbUvV/VttIqAgABycnKIjIx0Y6isZzq9T1VEhJycHAICAjraFEVRTgJO+z29y8vLycjIcGvOgkglpaUZ+PhE4OMT4ikzTykCAgLo2bMnvr6+HW2KoigeoCV7enf0KCmP4+vrWz0LujkqK4/z9dcJ9O37KL163eNhyxRFUU4tdPFBF7y8AgFDZWVBR5uiKIpy0qGC4YIxBm/vYBUMRVGUBlDBqIMVjPoT5xRFUc50VDDq4O0dQkWFehiKoih1UcGog7d3iHoYiqIoDaCCUQftw1AURWkYFQwR2LQJUlMB8PEJUcFQFEVpABUMgHHj4LnnAO30VhRFaQwVDGMgJgYOHQKcfRjqYSiKotRFBQPqCYaOklIURamPCgbUEYxgHI7jiOgChIqiKK6oYIAVjIMHAethgF1XSlEURalBBQOsYGRnQ3k53t7BANrxrSiKUgcVDLCCAXDkSPWy5trxrSiKUhsVDKgRjEOHXEJSKhiKoiiueEwwjDEvG2OOGGO2NnJ9rjFmszFmizHmv8aYES7XUqvObzTGrGvo/nallmBoSEpRFKUhPOlh/BOY2sT1/cAkEUkAfg8srHP9XBFJdHcnqDbRgIehQ2sVRVFq4zHBEJEVQG4T1/8rIkerXq4BenrKlmZRD0NRFKVZTpY+jBuBT11eC/CZMWa9MeYWj5fu7w/h4dqHoSiK0gQdvqe3MeZcrGCc7XL6bBHJNMZ0AT43xuyo8lgauv8W4BaAXr16td6Qqsl7NR6GCoaiKIorHephGGOGA38HZopIjvO8iGRW/T0CLALGNJaHiCwUkWQRSY6Ojm69MfUEQ0NSiqIornSYYBhjegHvAz8SkV0u54OMMSHO/4EpQIMjrdqVqtneXl4+eHl1Ug9DURSlDh4LSRlj3gAmA1HGmAzgt4AvgIg8D/wGiASeM8YAVFSNiOoKLKo65wO8LiL/8ZSd1dRZT0o9DEVRlNp4TDBE5IfNXL8JuKmB8/uAEfXv8DAxMXD8OBQW6oq1iqIoDXCyjJLqeOoMrdWQlKIoSm1UMJy4CIa/f3dKS9M71h5FUZSTDBUMJy6CERgYT1HRdkQqO9YmRVGUkwgVDCcughEUFI/DUUJJSWqHmqQoinIyoYLhJCoKvL2rPQyA48e3dbBRiqIoJw8qGE68vKBr12oPA+D48e862ChFUZSTBxUMV6rmYvj4hOLn14OiIvUwFEVRnKhguOIyeS8oaKiGpBRFUVxwSzCMMXcaYzoby0vGmA3GmCmeNu6EU7U8CEBQkHOklKODjVIURTk5cNfDuEFEjmHXdQoHfgQ84jGrOoqYGDh8GBwOAgPjcTiKKClJ62irFEVRTgrcFQxT9fci4F8i8p3LudOHmBiorIScHIKChgLYfoziYjh6tJmbFUVRTm/cFYz1xpjPsIKxtGo12dMvVlNr8t4QoGqk1M9/DuPHd6BhiqIoHY+7gnEjMB8YLSJF2FVnr/eYVR2Fi2D4+obj59eN44Xfwccfw86dNlylKIpyhuKuYIwHdopInjHmGuBXQL7nzOogXAQD7Eipyp3fQkaGPb9+fQcZpiiK0vG4Kxh/A4qMMSOAu4G9wKses6qjqCMYgYHx+K3aWXNdBUNRlDMYdwWjQkQEmAk8IyLPAiHN3WSMedkYc8QY0+COeVXDdJ82xuwxxmw2xoxyuXadMWZ31XGdm3a2jeBgCAx08TDiCdtQhnTrCoMGqWAoinJG465gFBhjfokdTvuxMcaLqt3zmuGfwNQmrk8DBlQdt2A9GYwxEdgd+sZi9/P+rTEm3E1bW48x0K1bjYfRKZ6wjVB2djwkJalgKIpyRuOuYMwBSrHzMQ4BPYHHmrtJRFYAuU0kmQm8KpY1QJgxphtwIfC5iOSKyFHgc5oWnvbDdbZ3mjd+R6FwdJQVjIwM7fhWFOWMxS3BqBKJ14BQY8wlQImItEcfRg/AdaeijKpzjZ33PC6zvX1XbgAgb5RYwQD1MhRFOWNxa09vY8yVWI8iBTth76/GmHtE5F0P2uYWxphbsOEsevXq1fYMY2Lgq6/s/199RWn3APLCvocBI23Iav16uOiitpejKKcBIpCbCwUF0L07+PmduHL374fycrvQtDH2KC+HsjIoLbV/w8KgRw8IDbXXnRQV2WBBVhZkZ9sjJweOH7dpQ0PtveHhNkrdowd06tSwLWVlkJ5u7UlNtbsk9O9vj5gYW252NuzYUTM6Pzra5hsTAxERUFho5wbn5kJ+Pjgc9rm8ve39paXWNufRqRP07Amxsfbo2bNx+9oTtwQDeAA7B+MIgDEmGvgCaKtgZAKxLq97Vp3LBCbXOZ/SUAYishBYCJCcnCxttMd+gkeP2tndKSmUnNeHoqJtSEgIZuBA9TAUj1FaCkeO2MrDWTGUlEDnzhAZabdsCQuDY8dsdNR55OXZr2txsa0IRSAgwB6dOtmxHN262Qq9WzdbGWZk2Apu/37IzLR5x8XZo1cvm09mpk2XmWl/EoWFNUd2tq0kMzJsuVDTBdi7t/0Z1a3kwFaAzoqwvNymcR7R0daRdx5Dh9pnd63od+2C116zx9697r+3gYG20gcbcS4oaPnnExFhn8/5WZWV2c8nO9tW8A0RFAT+/lYI2gsvr/rlhYe3bxmN4a5geDnFoooc2mel24+Anxlj3sR2cOeLyEFjzFLgjy4d3VOAX7ZDec3jHFr72Wdw9CiVE2dSWbmd0tIMApKSYMWKE2KG0nZKSmxFd/SobbWFh9uWWHBwTZqyMltp7t5t03fpYrdF6dLFVs6mzgI4hYWwZg2sWgUbNtgWtbNFGhJiy3KtzCsqbGXVqZP96+8Pvr41R0WFjYAeOND2H7yvry3HGPsspaXu3efnZ9+HpvD2ts8XHGyP8HAYORJmzKh5TzMy4PvvIS3NVuwBAbbC7NLFPjvYiq6y0v718bHvh/NIT4dPP4VXXqkpNyjICl337raS37DBPt8PfgB3320FRaTm8POrOXx87Odx4IAVvcxMe29MjP2MnZ9zVFTNERhoBTk/3wpxTk7t+w8dsnm42t21K/TpY8W2Tx/7me7ZU3MUF9tBloMH27/dulmROXTIfva5ufa9DQ+3R1iYfb+d75PDYcsJCqoRoNLSmu9YenqNaHsadwXjP1WV+BtVr+cAnzR3kzHmDaynEGWMycCOfPIFEJHnq/K4CNgDFFE1e1xEco0xvwfWVmX1OxE5AfpJjWC8/joA3udfAkf+yfHj31nBeP1161N27XpCzFEsZWXWnd+yxR5ZWfYHHh1tj4AAW0lt3w7btlkBcLZq6xIWZiu5wkJbwTXWOvT2rh2ecDhg61b7QzbGVgBgK5f8fFtecHBNiGDoUPvjLiqyR3GxrcjLy23a8nJbRr9+MHGirUi6drWVh7NyCAiwFZgzZJKbW2N/z5621RwRYYXCp86v2eGwFcuxY7ZicgpTfr69t08fe0RG2so4Lc2GVNLSbNk9etSUUbel7ylErI3r19vP22nzgQP2GZ94Aq66ygqIp3CKR1vo1w8uvLDx685QUmsJCKgJe51IjJ1e4UZCYy4HJlS9/FpEFnnMqlaSnJws69ata1sm69bB6NH22xkbS9mWVfz3v9H06/cEsfuSYPJku1SI9mM0iMNhK/PDh20L6vBh21Lz9a1pkQUHwznn2IrPlYoKeOcd+POfbUUONZVUTo69DrZijIy0lWd5ee08eveGIUNsS65Ll5pWW+fONa1/ZyglKMj+4AYMsH8DA21I6PBh+zc7u6almZ9vyx89GiZMgHHjrJC4UllpBUBRTiWMMetFJNmdtO56GIjIe8B7rbbqVMHpYRQXww9+gJ9fFL6+XexmSiNv0o7vKnJybAtwxw7bst+92/7du9c999jX17bArrwSpk6FDz6AP/3J3j94MMyaVbtFGx4OCQn2GDTIhhxEbOs5K8u24Pv1syLQUahYKKc7TQqGMaYAaMgFMYCISGePWNWRdOlS8/+55wLOzZS+s83UM6DjOy0NvvzSDhZbudKGg5zegZ+fDRNkZ9ek9/WFvn1tS33KFBvmcMaJY2JsZe/awXnkCHz4Ibz9NixZUpNPUhK8/z7MnGk79prDmJqQkaIonqdJwRCRZpf/OO3w87PxjpwcG34CgoNHcuDA36isLMI7KQmWL+9YG1tBXp71ADIzbbzaeTjj487hhenpVjDAVviTJtkKubS0piN13LiaTrzBg20YqG78vCkGDbIx+8ceg2++gaVL7erxF1xwYuLkiqK0jhb8zM8gunWzR5W3ERExlYyMJ8nLSyHyJO/4FrFhnf/+1x5btlihcPUIXPHxqenki462Ffddd8F550F8vGcrcGOs+Iwb57kyFOVkQEQ4VnqMAwUHKCovIj46nk6+9SdOiAj5pfmE+odiTsLWkwpGQ/zpT3YYQhWhoefg5RVIbu6nRCZdYU+eJP0YBw7YoYbr19tjzRrrLYCNoCUmwqWX2nDRwIF2ZEbnzvYICbGPeRJ+L5VGSM9Pp7SylMhOkYQGhOJlvCgqL2LToU1sOLiB9QfX4+vly+yhs5kcNxkfr/b/ie/J3cPWI1sZFDmI/hH98fW2y8pVOirZnbubbw9+y6HCQ1wz/Bqig6Lbrdyi8iIyj2WScSyDjGMZ5BTn0Du0NwMjB9Ivoh8BPvY3W+GoIKcoh+yibEIDQuke0h0vUxPjFBEOHz/MtqxtHCw4SLmjnApHBRUOO6oiLCCM8IBwwjuF0yWoC71DezdZeecU5bArZ1f1cfj4YY6VHqs+souyOVBwgOPlNcP2vI03w7oMI7l7MoMiB5Gal8p3Wd+x9chWcopziAuL49LBl3Lp4Es5K/YsvL1qd5CVVZax+fBm1mau5X8H/kdBaQHvXun5edRuj5I6FWiXUVKNsGXLdI4f38bYIRsw4eHw4IPw6197pKyGSE+3A7h27rQdzM5OZufSVl5eNtQzdiycdZb1FOLj3esL6EiOlR5jya4lDIgYQHL35Ba3qnKLc/l418dsOryJ4V2HM67nOAZEDPBY6+xY6TF2ZO9ge9Z2MgsymR0/mwGRA5q8R0TYcHADi3ctpqyyjJmDZjKmxxi3bRQRVqSt4LH/PsbHuz+uPu9lvAgLCCOvJA+H2LHBUYFRlFaUUlBWQJegLsyOn830gdOJDY0lJjiG8IDweuU6xMFEPNYsAAAgAElEQVSO7B2s+n4Vq9JXsf7ges6OPZvfTv4tMcEx1ekqHBU8/t/H+W3KbymrtBM3fLx86B/Rn1D/ULYe2VqrUuzs35kHJj7AHWPvqK7MKx2VLE9bzjvfvUNuSS7exhtvL2+8jTfRgdEMiR7CkKghDIkeQlllGctTl7MsdRkpqSlsz97e6HtkMHQP6U5xRTG5xbVH4Pt6+dI7rDdxYXEUlxezLWsbR0vc33K5f0R/Zg2axazBsxjXcxyHCg/xxb4v+Hzf53y5/0sOFR6qTuttvOkS1IXQgFA6+3ems39nIjpF0COkB91DutMjpAe+3r5sPLSRdQfWse7AOnKKc+js35mh0UMZ1mUYcWFxrEpfxRf7vqCssowuQV2I7RxLuaOcssoyyirLyDiWUf0ZRAdGMz52PIvmLKoljO7SklFSKhhukpn5N3bv/iljxuwgcNRMWzt/+KFHysrKsqGkb7+1HsPq1bbvwUnXrtZjGDDAehBJSfZvW0cIiQh7j+6lX3i/Fle4hwoP8dHOj/hgxwccLTnKDYk3cHXC1QT5NWzU9qztPLv2WV7Z9AqFZYUAxIXFcWX8lcweOpukbkmN2nCg4ADvbXuPD3Z+wPLU5VRKJd7Gm0qpBCCiUwQTYifw5IVP0i+iX4ueoy75Jfks3buUxbsWs2z/MjILMmtd9zbe3DjyRn496df07Nyz+vyx0mOs/H4lH+/6mI92fUTGsQy8jBdexosKRwU9O/fkssGXMaXfFGKCY4gKjCIqMIpA38DqVmlOcQ47s3fy1//9lbUH1hIdGM1PR/+UvuF9yS3OrT4iOkWQ1C2JpO5J9AjpQUlFCZ/u+ZQ3t77J4l2LKakoqbbL18uXyMBIwApFpaOS4opiisqLAFv5DO86nOVpy/H39ufeCfdy1/i7SM1L5foPr2fdgXVcEX8F88bOY3/efrZnbWd79nbySvJI6JLAyG4jGRkzEi/jxf1f3c+SXUvoHdqbByY+wM6cnbyx9Q0OFBwg2C+Y7iHdq22olEoOFR6qrgRdCfYLZmKviYzvOZ64sDh6du5Jz849Ce8UTlpeWnXLfn/efgJ9A4kOjCY6KJqowCjySvJIzUtlf95+UvNS8fP2Y2j0UOKj44mPjie2cyx+3n74ePng6+2LQxzkleRxtPgoR0uOkpaXxpLdS/hy35eUO8oJ8QuhoKyg+r06v+/5JHdPZmDkQAZGDqRPWJ9qj8sdRIS8kjzCAsLqfd+PlR7j092f8tGuj8grycPXyxc/bz98vX3pHtydMT3GMLrH6GY9oOZQwfAAxcWpfPNNH/r1e5LY+WshJcU2+9uhCb9vH7zxBixbZoXiiMuc+rg46y2MG2e9hyFDbDipval0VHLnf+7k2bXPMjluMs9e9Czx0fH10jnEQeaxTPYe3cve3L3sPbqXlNQU1mSsQRD6hvcl0DeQrUe2EhYQxg2JNzBn2BxyinLYd3Qf+47uY/3B9SxPW46ftx9XDbuKG0feyN7cvbyz7R0+3/c5FY4KeoX24pIBlzB90HTOjTuXssoyFu1YxL82/4sv932JIMRHx1e3/EZ2G8mO7B2syVjDmow1vL/9fQJ9A1l23bIGPYBvMr7hyPEjDIgcQJ+wPvj7+ANwuPBwdWhnedpylqcup9xRTkSnCKb0m8KIriMYEjWEwVGDCfYL5k+r/sTz657Hy3jxk+Sf4G28WZ62nG8PfYtDHAT6BnJhvwuZMWgGFw+4GB8vH5bsWsJ7299j6d6ltSpzsC1lqTMwcUDEAO4efzfXjri2wbh3UxSUFrD+4HoOFR6qPnKKcjDG4G288TJe+Hn7MbzrcCb0mlDtne3O2c39X93Pu9vepUtQF/JK8gj1D+XZi55l9tDZbpf/5b4v+cXnv2DjoY34evkybcA05ibMZfrA6fWepdJRyf68/dUenEMcTIqbRFK3pBZVwp4gvySf/+z5D1/t/4oBkQO4oO8FJHRNaFWL/mRDBcND/O9/8fj792TEujlw0022Jn/mGRg1qvmb63DkCLz1lu0/X7P+OIz4F9FDt9I7LI5h3fsyZkAfpiT3p1+sewPVtmVt46k1T5FbnFsrBts1qCu9w3rTO7Q3saGx1aEBV0orSrlm0TW8u+1droi/gi/3fUlBWQE/H/dzfjPpNxgMn+39jA92fsCSXUtqufw+Xj6M6DqCWYNtxT00eigAK79fyTNrn+H97e9Xx4YBAnwC6B/Rn6uHXc1No26qF+POLc7lgx0f8NHOj/h83+cUlRcR5BuEIBSVF9EnrA/XDL+GqxOuZnDU4Ebfj82HN3Peq+fh5+3HsuuWMTByIGAr0Ls/u5sXN7xYndbLeNErtBflleW1PIj46HguHnAx0wdOZ3zs+Eb7A1LzUlmQsoB/bf4Xvl6+jO05lsm9JzMpbhLje45vtJIvLCtk06FN1d5EdlE2BaUFhHcKJyowishOkXQN7sqobqM6rGJanb6aXy37Fd2Cu/HkhU+2qk+i0lHJ6ozVDIkaUu3dKCcPKhgeYs+eX5CZ+VcmjM/C5/X34b77bPzollvgoYfscNwmELFexPPP24lq5Z3Sib7kWQoHLqSYowT7BVeHZ8CGOyb0msD0gdOZPnA6g6IG1ctz06FN/OHrP/DetvcI9A2kd1jvane6busVbGt1ztA5zB0+l8FRg8kvyWfWW7NISU3hiSlPcNf4u8guymb+F/N56duXiA6MpqCsgJKKEsIDwpk+aDrje46nf0R/+oX3IzY0tsmO1QMFB1j5/Up6du5Jn7A+xATHuO0+F5cXsyx1GUt2LcFguDrhas6KPcvt+7ce2coPXvkBPl4+LLtuGQcKDnDDRzfwff733HPWPcwcNJM9uXvYk7uH3bm78TJeJHVLYlS3UYzsNpLO/i1z5bKOZxHiH9KgKCvKyYoKhoc4evQrNm06j2HDPiIqarpdL2LBAvjrX+06Fxs22KU+65CdDf/8JyxcCLu/P0bQyCXEnPcOqX6LEYTLhlzGvLHzOCv2LPJL89l/dD/7ju7j20PfsnjXYjYf3gzYGH+XoC4E+ATQyacTxRXFrEhbQWf/ztw+5nbmjZtHVGDNIjglFSUcLDjI9/nfk5afRlpeGl9//zVf7v8ShzhI6pZESUUJO3N28s+Z/2Tu8Lm17F6TsYaHVz5MXGgcswbPYmLviR4ZdeNJvjvyHT949QeUVpSSX5pP/4j+vDLrFc6KPaujTVOUkwIVDA/hcJSxalUkXbtew8CBf6u5sH49JCfDH/4ADzwAWG9i+XJ44QV4b3Eh5f0+IPzsdyjsupRyKaVbcDeuTrian435GXFhcU2Wm5aXxpJdS0hJS6GwrJDi8mJKKkood5Qzc9BMbh9zO+Gd3N/B9mDBQd7c+iavbXmN9GPpvDrrVS7s38RKaac42458xxXPTeb8ARfy8OwXGu2IV5QzERUMD7J166UUFGxg3LjU2qGRCROgsBDZuInFi+He+ZXsLPsC3+R/I4Pfp8IU0bNzT64YcgVXxF/B+NjxJ0WHmYiclBOE2pW0NDt64Gc/s96goijVeGTxQcUSEXER2dkfUFS0naAgl1FEc+aw/c6/MW9iIZ/t34HP3Msh6HuC/MO4cug1/GjEjzgr9qyTQiRcOe3FAuwKiWA3sVAUpdWoYLSQiIhpAOTkfFItGAUF8NutN/BXbsUvZyl+t1xFt9AonpjyLpcMvKR6yKbSQTgFY9Mm+2GFnHlLpClKe3ByNXdPAQICehIUlEBu7qeA3YBvxAh46u/BnD3xPsqunMGQrv1ZfeNqLo+/XMXiZMApGA4H/O9/HWuLopzCeFQwjDFTjTE7jTF7jDHzG7j+pDFmY9WxyxiT53Kt0uXaR560s6VERFzEkSP/4847i+2Ctka49V+Pk3Lek0xME5aPe55uId062kzFyY4ddvs7YzQspShtwGMhKWOMN/AscAGQAaw1xnwkItucaUTk5y7pbwdGumRRLCKJnrKvLeTl3cQtt1xLWlonLr/jG46MmM9ze1K4st8MXn1oMf69PoFEXYL1pGHHDrtQpJeXCoaitAFPehhjgD0isk9EyoA3gZlNpP8hNXuGn7RkZMCsWf3J8y4k4Q89eS9iHDtzt/HMtGd4Y+4i/Ceea6dwn0ajz05p8vLsXrGDB9uRbKtX271UFUVpMZ4UjB5AusvrjKpz9TDG9Ab6AF+5nA4wxqwzxqwxxszynJnuk5cH06ZBdsxbFFx7Fnskk18kzWLvHXu5bcxtdgTUnDl2GdnNmzvaXAXs8r5QIxgFBbB1a8fapCinKCdLp/dVwLsi4tr06101Nvhq4CljTIPLjhpjbqkSlnVZzo0gPEBJid1nesf+AgIvnUdS91EsmhzPlV33EOTrMhHsssvs5s5vveUxW5QW4OzwHjzYrvsOGpZSlFbiScHIBGJdXvesOtcQV1EnHCUimVV/9wEp1O7fcE23UESSRSQ5Orp9Nms5Xnac8sry6tcOB1x7rZ25fdHDD5NbfohnLnqGEf3v5fjxrRw9+nnNzVFRdru6t9/WsNTJwPbtdtPxPn1qNhtXwVBay/ffn9G/a08KxlpggDGmjzHGDysK9UY7GWMGA+HAapdz4cYY/6r/o4AJwLa693qKC/99ISOeH0F2kd3X9Pe/h3fegV8+up+l+X/mR8N/xJgeY+jS5Sr8/GJIT/9z7QyuvNLuk7p+/YkyWWmMHTvsxiE+PnaU1IQJKhhK69i2Dfr2haee6mhLOgyPCYaIVAA/A5YC24G3ReQ7Y8zvjDEzXJJeBbwptdcoGQKsM8ZsApYBj7iOrvIke3L3sCp9Fduzt3PRaxexP7OARx+F2bNhd+978fby5uHzHgbAy8ufHj1+xtGjSyksdImLX3aZnRz24IMnwmSlKXbssOEoJxMm2KVCMus4uxs2wKefntGtx5OKrVvhiy862oraLFxoB0w88ggUFXWMDdnZMGMG/OQnHVO+iJw2R1JSkrSVP674o7AAeeabZ8T7QW/p/evzxfiWyKvLlwsLkN+l/K5W+tLSLFm+vJNs335D7Ywef1wERJYsabNNSispKxPx8RG5//6ac998Yz+Xt96qOZeRIRIRYc9PnCjyv/+1rrwlS0S+/FKkuLhtdjtxOESys9snr1OJ1FSRyEgRX1+R3bs72hpLUZFIeLjIsGH2e/LEEyfehs2bReLibPkg8umn7ZItsE7crGM7vJJvz6M9BGPk8yNl7ItjRUTk6RX/EBYgve6+UkY+P1Ji/xwrx8uO17tn586fSEqKn5SUHKw5WVoqMniwSL9+7VeBKC1j+3b7FX/11ZpzZWUinTqJ3HGHfV1ZKXL++SKBgSIPPSQSHW3vmTtXJC3N/bJ27ar5IQcEiJx3ns3v4MHm73UlO9uK2Y03ivTq5flGx9dfiyQm2r+NUVwsUl7e+jIcDpEVK2yl2xzFxSJJSSKdO4sEB4vMnNn6ctuTV1+1n8VXX9nPtksXkeP16wKPsWiRSFCQSLdu9rMaOFCkf3+RkpI2Z62C0Up25+wWFiCPr3pcRETuvVfETHhMWICwAHljyxsN3nf8+C5ZtsxL9uy5t/aFzz6zb/FDD7XJLqWVLFpk3/+6HsOkSbZSEhF58kmb5oUX7Ov8fJFf/lLE399WCoWF7pW1YIGIMSL//rfIz38uMny4zXfMGFthNoXDIbJsmcisWSJeXva+0FCRyy6zAnbppS15avf55BMrnmBbzg2JQmGhrZymT299Oe++a8u45JKmhcfhELnhBpv2o49EHn7Y/v/5560v25nvqlUiP/1p7cZDSzj7bFtBO8UPRP7857bZ5S5/+lPNdykz055z1i2//32bs1fBaCXOcFTq0VQ5csQ2OufOFXloxUNy3aLrxNHED/+7766SFSuCpaysTgjh8svtj7IlrVWlfXBWOPn5tc/ff7+It7fI6tVWGGbMqF+pp6TUFpKmcDhEBgwQOffc2ucXLrR5fPhhw/eVlor84x8iI0bYdJGRIvPnW7ucFeu8eSJ+fiK5uW49cj2OHLEVdt3733zThutGjhT5299s+c89V//+n/9cqj2n1lTcZWW2onWG/G69tXEBfeEFm+bXv7avi4tF+vQRGTq0dR5OerptrA0YUPMM4eHueTqufPedvffRR2vOnXuuSExMy/NqKRs32rJnz64fqZg923qz+/e3qQgVjFYy8vmRMubFMSIics89trG3Y4d79xYUbJZly5B9+35T+0JqqhWM2bPbZJvSCq67TqR79/rnP/64pvLo2tVWqnVxOGyoZtiw5j2E//3P5vf3v9c+76wshw+3oa+6+V99tVS37l98seHKZ+1am+bFF5u2oTGcLXZfX5Fp00ReeknkL3+x3tA554jk5VlbJk2yguUqLN98Y38EN9wg0ru3yKhR9Z+jOZ55xpb/8cf2RwUijzxSP93q1VYYp04VqaioOf/ee/aeZ591v8zcXCt0vr723kmTrDB/9JF9/Y9/tOwZ5s2zebl+T5wNiqeealleLeXii+339OjR+tfS022Yqo1hOxWMVrAnZ091OOrwYetdXHNNy/LYsmWWfP11mJSX59W+8LvfSXt2Up1Q3A3JnIyMHSvygx/UP5+bK9Utzo8/bvz+l16yaZYta7qcO++0lV1DP+rXXrN5vFEnnPmvf9nzv/lN04LkcNiQ0OTJTdvQEMePi4SE2Ernnntqd5hefHFtgfr2Wysi8+bZ16WlIgkJIj16WA/NaW/d52iK/HwbUps82T5HZaXIVVfZfF5/3cbf33nH2uLtbb2JnJz6zz95cn0xa4jSUluBh4fbZ7nxRpG9e2vnNWSIyOjR7j+Ds7N7zpz61yZNsn0KxcX22LXLDnpor4EKX3/duMA6cYar2tDPpYLRCh7++uHqcFRLvQsn+flrZdkyJDX1j7UvFBfbL2qnTqfWqKmMDFvh3HNP6/NYs8Z2Kp/o0S4Oh+0H+OlPG75+2WW2r6IpiopsKOXyyxtPU1FhvZTG+hkqK60HMXBgTVhl3z77vp59du3WdGM8+KCtANPTm0/ryuuv1xY8h0Nk/Xpb6ZeV1U9/8802TLV9u42Nu4bTKitt6KxvX1sxu8OvfiX1+pBKSqxn4+dXE6bq0cOGCTMyGs5n40b7g7zzzsbLysgQGTTI5nf++SKbNjWc7q9/rW9TUziF8ssv61/76it7rXPnGiEG643l5dVP3xIcDpEJE6wgNdW5Xlpq65Y+fVodHlPBaAWjXhhVHY7q16/1fXybNk2VlSujpKKiTsv88GHb0ertLfLyy622s93Iy7MdtTNnNv6FfOyxmh/Bm2+2rpxLL62pFE6kaBw8aMt9+um25XPvvfYz+/77hq87Ox/ffbfxPD74wKZ56SUrGmedZSuZ1FT3bNi9W+rF0EVspfLgg7WHCLsydaodaeVuGOnwYWvXmDG2Qr/yytrXP/3U/fc0M9M2kK66qv613Fw70uiqq0SWLnVPNP/v/6xoLFpU/1pRkUhysh1VtWRJ0x5bfr4N4/z4x82XKWKHWTs7u+vicNj+lptvtgL7yiv28PZuWXiioYp+yRL7Xv/tb83fn5Ji+8taGi6sQgWjhezN3SssQB5b9ZgUFEibBh/k5a2UZcuQ779vYATFsWMiF1xgC/jjH5uPjXuCvDxbyYSF1YhBYzHdxEQbtz7rLPsj27q1ZWVlZdnY78yZIlFRtj9h1y7373c4bOvykUfsvJbGWqANsWyZfbbPPmuZzXXZv99WVI15I9ddZz2ZpoZOOxy2Eu7Vy7aknSGZljB2rG3hu/KXv9i8QkLq98McPGjtfuCBlpXjnD8UHi5y6FD95/jBD+xn6RxIkJlpRx79/vci779v3y+HQ+Smm+xn7xoSagsFBfY98POr3dp3OKzwGGP7KNzhJz+xncV1Q0cOh/1+Llpkf5/OPqa6Qt0cCxaIW+E7h8O+b15eItdfX/N+V1bafq9+/Rr2BNsZFYwW8sjXjwgLkP1H98vq1dLkwBZ3+PbbybJqVXepqGigEiktrfkiLljgfqb79llX+5JLbCfkfffZCqOhuHljvPqqrQjAVuLr11s3fvz4+mmdI0OeespWCl272rBKS1ztp5+2eWzebA+naOzc2fR9//2vfcbu3WtEDWylcMEFNkzQXN+Kc+RPS8M4DeEUvLqiUFRkK+sbbmj4Plecngi0vHNMpOa9dIr211/b8NHEibbCcc4rcfLEEzZ9S+Oqzu9nY5Wvs4N/4kQbCnH9fJxHaKi1ydkf0l5kZ9sRU8HBNSGlP/7Rlvnww+7ns2mTvefxx2vOFRaKXHFF7efo2dOea8lvTMR6kePH2/ehsdGR5eXWawLbIPP1td7dU09ZLwVs/9cJQAWjhSS9kCSjF9qOMOfIvraMVMvN/aJqxNSvG05QWWk70QICbBjAHS65xLr4I0bYitQ5AuScc9yLKTuHeE6caIXCibNi2by5dvr777c/eufEs+XLras9a5b7ru+oUfZwsmWL7QTt1q1mPHldjh2z3kxoqB1Z9vLLIgcO2Jbfb35jY7XuxInvvNPm0x5e3Bdf2DL/+c/a5996y57/4ovm83A4RKZMsa3G1sS3Dx+27/8vf2nfj5gYGyrJy7Mhkbqt+REjrFfjCa691o4KufBCG7bcsMF6AN98Y39At95q+4g8MUs9M9N23kdG2grfGCtwLf2czz7bfhaVlbZST0y03/cFC+xz1B2K3VL27LHCNmlS/ZDb8eN2KDfYz9PhsMJ+4YU1YtXQyDoPoYLRAgpLCyXx+UR5dKV1O2+7zTYa21LPOBwO2bbtOlm2DDly5P2GE+3YYb/sv/pV8xkuXiz1WkQOR02H3P/9X9MGO1Vw2rT6reTsbDsX4bbbaucdF2crOFeck9zc8Yy2bLFp//KX2uc3b7Y/TNflOlx58UV73+rVDV93OOz74eVV2+a6XHhhzeS8tuIcXZOYaL0jZ5hgxgwrfu7E4EWssLdl3P7UqVYoJ060FfaWLfa8s7/ghz+0r51j9595pvVlNYXD4f4ze4I9e6xggh3x1Jr39I037P0PPmgnaHbubCcyticvv1zz+3z+efs7XLjQeh/G1P98HA7b3zVhgm2gnSBUMFpBpcOq+cSJ9vNqKxUVxbJu3RhZvjxICgq2NJzo0kttiKigoPGMiovtyJQhQxqOZ86fL02OU3eGZi6+uPFlBObOtT8YZ5hn5Up7T91ZsQ6HbV26M6HtF7+wIZOG5jjMmGF/pA15RuPGicTHN6/Yd9xhf3TffNPw9d697XO1F84htmCfa9Ag+/euu9qvjOZwNhAa6gNx9o2sWydy993W48jKOnG2nWg2b7bfxZb0a7lSWmq/g2A9tW3b2tc+Efsdnju35jNzHp062f6ekwQVjFbiHIl5661tyqaakpJMWbUqRlav7itlZTn1E6xZYz+CJ59sPBPn8MbGwh4VFTZc5e1d0xnocNg47X332XsvuaTpNWecSx289JJ9feut9kt97Fj9tGVl1lPx8rKTqhqivNz2ecya1fD1//xHGuwUdPabuLOwW36+Dc0lJtafBXz8uLRp5EJjrFtnw1K//KUNuYwf37JO/LZSUCASG2tHbtUlL8+GaZwzkBt775UaXn7ZVuh15360Jw6HDetmZlpxS09ve7irnVHBaCVpaeL2SDZ3ycv7r6Sk+MnGjedLZWUDyxucc46tBBryHtydJZ6fb1vlERHW/Y2NlerWzJw5zS9Q5gy5jBljW14REQ0Ph3RSWGg9AX//hie1OWdSNzQEUsTGZvv1s+6cK3fd1bhX0hDOWcCuAlNSUuN1vfOOe/mcSjS1RIYzZAiNi7mi1EEFo5U4uwpWrWpTNvU4cOAlWbaM+osTitRUrg0tinbZZTZW3dgcAFf27LEtzOBgG+p66aWWrZT61FPWDues9MWLm06fk2NFqnPn+pOgZs+2tjTVGe+c4+GMw5eW2pFIl13mvs0Oh/WegoKs2q9cWTNyZ+5c9yeYnS6UlNi+p/DwdlnFVDkzUMFoJQ89ZN8RT3iMO3bcIsuWITk5S2tfcDjsTGDXNYvy82sq7j/+sX5mjZGf3/qKIjfXjtry8rKVvTvjv9PTa7yZc86x4Zr0dDtWvu4wz7o4O9udM7GdK5o2tVRHQ6SmWlF1LnvRu/epuQRLe7F5c9NLlStKHU4awQCmAjuBPcD8Bq7/GMgCNlYdN7lcuw7YXXVc5055bRWMOXNsveMJKiqOyzffxMvKlV2ltLTOUFrnWvuvvmqHjjon1U2ffmJbis4O7ZZ04hw+bEWtf397r7e3/es6dLep8kJCbGx+2jQ7G7w1o2+efLJm3H9TAwgURanHSSEYgDewF+gL+AGbgPg6aX4MPNPAvRHAvqq/4VX/hzdXZlsFIz7eDuDxFAUFmyUlxV82bZomDofLGOuystr9DrNmtX7Xt7awbp0NablT2dfF4bAt2+uvtxPZ3BmX7Jwl+atftW5WsittXbtHUc5QWiIYPu253WsdxgB7RGQfgDHmTWAm4M7e3BcCn4tIbtW9n2O9lTc8ZCslJbBzp92O21MEByfQv/+f2b37NjIyniY2dp694OsLzz4LS5bA7bfDsGGeM6IpkpKgoKB19xoDZ59tD3cZOxYSE+EPf7Cvb7ihdWUDhIa2/l5FUdzCy4N59wDSXV5nVJ2ry+XGmM3GmHeNMbEtvBdjzC3GmHXGmHVZWVmtNnb7dru/+/Dhrc7CLbp3v5XIyJns23cvBQUbai5Mnw4vvNBxYtERGAM//an9/9xzoW/fjrVHUZQm8aRguMNiIE5EhgOfA6+0NAMRWSgiySKSHB0d3WpDNm+2fz0tGMYYBg9+CV/fLmzdeiklJenN33Q6c/XVMGEC3HtvR1uiKEozeFIwMoFYl9c9q85VIyI5IlJa9fLvQJK797Y3mzdDQAD07+/JUiy+vpEkJCymoiKPTZsuoKys9Z7RKU9QEKxcCVOndrQliqI0gycFYy0wwBjTxxjjByWIFtsAABa0SURBVFwFfOSawBjTzeXlDGB71f9LgSnGmHBjTDgwpeqcx9i82UaDvL09WUoNISEjSUhYQmlpGps3X0hFRf6JKVhRFKWVeEwwRKQC+Bm2ot8OvC0i3xljfmeMmVGV7A5jzHfGmE3AHdhRU1R1dv8eKzprgd85O8A9xebNng9H1SUsbCJDh77P8eNb2LJlOpWVRSfWAEVRlBZg7Kiq04Pk5GRZt25di+87fBhiYuCpp+DOOz1gWDMcOfIW27b9kIiICxk69H28vTudeCMURTkjMcasF5Fkd9J2dKf3SYGzwzshoWPK79JlDoMGvUhu7lK2bLmIiopWDm1VFEXxICoYdLxgAHTrdiNDhvybvLyv2bTpfMrLPRqBUxRFaTEqGFjB6NYN2jAqt13o2vVqhg17j8LCjWzcOJnS0kMda5CiKIoLKhjAli0nvsO7MaKiZpKQ8DHFxXv59tuzKSj4tqNNUhRFAVQwqKiA7747eQQDICLifEaM+AKHo4gNG8aSnv4EIo6ONktRlDMcT64ldUrg7Q07doDPSfZOhIaOJzl5Mzt33sTevb8gN3cpgwe/gr9/t+ZvVhRF8QBnvIdhDPTpA7Gxzac90fj5RTFs2CIGDnye/PyVrF2bwP79Cygt9eikd0VRlAY54wXjZMcYQ/fu/0dS0no6dx5NWtrvWL26N1u3Xkpu7mecTvNoFEU5uVHBOEUIChrC8OGfMnbsHmJjf0F+/ko2b76QTZvOo6hoT0ebpyjKGYAKxilGp0596dfvEcaPz2DAgL9RULCedesS+P77x3A4KjraPEVRTmNUME5RvLz86dHjJ4wZs43w8AvZt+9eNmwYR2Hh1o42TVGU0xQVjFMcf/8eDBu2iPj4tyktTWfDhjEcOtTibUUURVGaRQXjNMAYQ5cus0lO3kTnzuPYsePH7Nx5M5WVxR1tmqIopxEqGKcR/v4xDB/+Gb163c/Bg3/n22/Poqhod0ebpSjKaYIKxmmGl5cPffs+RELCx5SUfM/atcPYu/c+3aBJUZQ241HBMMZMNcbsNMbsMcbMb+D6XcaYbcaYzcaYL40xvV2uVRpjNlYdH9W9V2mayMiLGD16C127Xk16+mN8801/MjOf05FUiqK0Go9toGSM8QZ2ARcAGdid834oIttc0pwLfCMiRcaYW4HJIjKn6lqhiAS3pMzWbqB0ulNQsIG9e+8mLy8FP78YQkJGExw8kuDgREJCkgkIOAmnuSuKckJoyQZKnlxBaQywR0T2VRn1JjATqBYMEVnmkn4NcI0H7TljCQkZxYgRX5GTs5gjR96isPBbcnI+BuyChoGBg4mIuIiIiGmEhU3Ey8u/Yw1WFOWkxJOC0QNId3mdAYxtIv2NwKcurwOMMeuACuAREfmg/U08czDGEBU1g6gou516ZWURx49vIT9/Nbm5n5KZ+QwZGX/G27szAwY8S0yMareiKLU5KdZoNcZcAyQDk1xO9xaRTGNMX+ArY8wWEdnbwL23ALcA9OrV64TYezrg7R1I585j6dx5LLGx86isPM7Ro8tIT3+UHTt+xPHjm+jb9xFsZFFRFMWznd6ZgGtwvGfVuVoYY84HHgBmiEip87yIZFb93QekACMbKkREFopIsogkR3f0lnmnMN7eQURFXcKIEV/SvftPSU9/nM2bL6a8/GhHm6YoykmCJz2MtcAAY0wfrFBcBVztmsAYMxJ4AZgqIkdczocDRSJSaoyJAiYAj3rQVqUKLy9fBg58luDgRHbvvo0NG8YQEXExxhjAAF6EhU0kMnI6xrS9veFwlJKW9jBdulxFUNDgNuenKIrn8JhgiEiFMeZnwFLAG3hZRL4zxvwOWCciHwGPAcHAO7ZC4nsRmQEMAV4wxjiwXtAjrqOrFM/TvfvNBAXFs2PH9Rw69A9AAMHhKCcj4wmCgobTu/eviY6+rNXCIeJgx44fc+TIm2Rnf0BS0lq8vHzb9TkURWk/PDastiPQYbWex+Go4MiRN0hL+wPFxbsIDBxKbOzdREdfho9PaIvy2rv3PtLTHyUyciY5OR/St+8j9Op1n4csVxSlIVoyrFZneistwsvLh5iYHzFmzDaGDHkdEHbuvIFVq7qwZcsMDh9+jYqKgmbzycx8lvT0R+ne/VaGDfv/9u4+Oq66zuP4+zvPmU6SSfPUNmlDKdBS3dJSQXzgQbp6UFB8QAsqh+Nxl6PAWXDdVbviuuv+457jWdf14K6IIKwIBddqxbNWLdpVPNiGUqW0pU9pbfM0k6RJJpnM83f/uLchTaOdlqZz03xf58zJzJ07k8/MNP3O/d17f98NNDS8n0OH/smmMjHGw2wLw7wmqkoqtZVEYj2JxFPkcp34fFU0NLyfefPuoK7u+pOOtOrr28jOne+jvv5dvO51G/D5AmSzXWzdupzq6lVcdtmz7j4TY8x0O50tDCsY5qxRLTE09FsSicdJJJ6kUBgkHG5l7twbKZXS5HK95PMJRkd3EYtdxsqVv8TvnzP++K6ub7F3750sXfoQ8+d/vIKvxJjZwwqGqbhiMUN//0Z6eh5laOg3BINzCQabCIWaiUTaaGv7AqFQ0wmPUS2xY8f1jIzsYNWqLfj9teNHZ4VCzXYGujHTwAqGmbHS6b1s27aCCafkABAKzWPJkq/Q1PRhG64y5izyylxSxpy2aPQSVq/eSiq1neOH8qoW6O7+Frt3f5Surge5+OIHiMVej6qSyXQwPPw8uVwPzc23EwrZyZvGTBfbwjAzgmqR7u5vc/DgOgqFIeLxaxgd3Uk+nxxfx++P0dr6KRYu/PQpD/HNZI4SCNQQCNSc8ncXCinS6T0Ui6PE49faFo45r9iQlDlv5fP9dHTcz9DQc1RXr6am5ipqaq4C/Bw+/CWSyacJBOpYuPDvicevIRJZTCg0DxEfY2OHSCafIpF4ipGRF/D7Y8yf/9e0tt5LJDLeioXR0V0kkz9gaGgLo6O7yeVendGmvv7dLFv2CMFgfQVevTFnnxUMM2ulUtvp6LifgYFXJz4WCRMKzSObPQxAdfUVNDZ+gNHRnSQST6KqNDbeQlXVhfT1bSCd3gNALLaKOXNeTzR6KdHopWQyBzh48B8IBhtZvvx7xOPXjP+OsbEOhoZ+TSx2ObHY68/ti54FRkf3kMt1U1f3tkpHOe9YwTCz3tjYAdLpvWQyHWQyh8hmjxCLraSx8UNUVS0eXy+TOUJn53/Q1fWgO+R0HY2NH6Ch4WbC4QUnPW8qtZ1du25lbOwACxf+LaVSloGBTYyN7R1fJx5fQ2vrvdTX3zg+bYqqUigMkst1kc/3kcslyeeTiPipq3sHVVUXTPt7MtOk0/tJJteTSKxndPQlAC699Amam2+tcLLzixUMY05TsZhGNV/W9CaFQop9++6it/e7+HxVxOPXMXfuDdTWXs3AwCa6uh4gmz1KJLKEaHQpmcxhstk/Uiz+6TPgo9FLqa+/kbq6txMOLyIUaiYQiCMiqBbJZrvJZo+Qy3URjS4jGl1+2vtSSqUsfX0/Ynj4eZqa1lJTc3J7mnR6Hz09jxAOt9LYeMtJhz6fC5nMUfbu/QQDAz8BoKbmzTQ1rSWZfJpU6gVWrfot1dUrz3mu85UVDGPOgbGxA4RCLfj9kROWl0p5+vo20Nn5DYrFIcLhNiKRRUQibYRCCwiFmggGGwkGGygWU/T3/y8DAz9hcHALqvnx5xEJEgjUkc/3A8UTfkckcgFz595Iff1NVFe/gWCwfsoCoqqMju6ku/vb9PZ+l0KhH2dGoBK1tVezcOHfUV9/E8PDz3PkyFfo6/shzqzEJcBPXd0amppuo65uDeFwy1mZofhPUVV6eh5h//5PoVqgre3zNDffPt5COJfrpb19NSIBVq9uJxRqmLYss4kVDGNmoEIhRSq1jVyuZ/ys+Hy+n2CwkXB4IZGIs+WRSr1Af/8zHDu2mVIpDTjFJRSaRyg0H58vQqEwQD7fTz4/gGoWkSANDe9l/vy/oqbmjfT0fIcjR75KNnuYYLCBfL6PQKCOBQvuoqXlHvL5JInEEyQST5LJdADg80WIRJZQVXUR1dWX09j4oZOmpFdV0uk9pFJb3dyLiEQWEgjUolp0MyXJ5/tQLSESQCQIlDh8+F8YGPgptbXXsGzZw1RVLTnpPRoe3saLL15Nbe2bWbHiZ/h85Z8ZUCoVEJEzbgpWKhVIpdoREQKBeoLBegKB2j9bRIeGniOXS9DQcPO0FVtVJZ9PnvHWoBUMY2aBYjHD0NAW0uk9ZLPdbqHpplTKumfW1xMIzCUSuYDGxg+e9I28VCqQTD5NMvkU8fj1zJv3MQKB2AnrOHOFbSOV2s7Y2H4ymQOk0/tIp3cBSiy2iqam24jFVjAwsIn+/h8zNrb/pKw+X5RSaQzn3Jqp+XxRLrzwy7S03P1n/3Pt6XmMPXvuYMGCT9LcfDuqOUqlLKp5/P4YgUAdgUAdfn816fQuBgd/xeDgrxgaeg5wetxXV19BdfUV1NS8kUhk8Z8c3nNefzu9vc50N/l876Q1/MTj19HScg8NDe8eL0ajo7s5ePCz9Pf/2P2dV3LJJd+gunr1CY/OZrsYGvotsdhfUFV1yWkPMw4O/pqOjs+Ty3VzxRW7zqg9gBUMY8y0yma7SSaforf3e6RSWwEQCVFXt4b6+ncTj19HoTBINvtHMpk/kst14/dXEww2Ego5w3EiAUqlPKrOJRZbNT78dCr79t1HZ+fXys47Z84K4vFrAR+p1DZGRrZTKmUACAYbxg/Prqq6iGy2y93vdJiRkZfIZA4gEqK+/iaamtbi989xt5T6yeW6SCTWk80eIRxuo6Xlk4yNddDd/RB+f5RFi9YRDrdw4MBnyOcTLFjwCVpb7+XYsc0kEusZGvo1x4toMNhMPH4ttbVX4/fHKJUyqGbdLwCNRKNLiUaXEgzWMzzcTkfH/Rw7tolQaB5tbfczf/6dVjBOhxUMY84954i0fdTWvvWkLZTpolpkcPD/UM0hEsLnCyESoFgcIZ8/RqEwSKEwSFXVEuLxa046b6ZUyjM6+jKp1FaGh59nePh50und4/f7fHOIRNqoqlpCQ8PNNDR8gGAwPmWWUqlAf/9GOju/zuDgrxAJsGDBJ9350pyZBwqFITo6vkhn59dx9g9BNLqcpqa11NX9JaOjL7tbQltOOO9nKoHAXAqFAQKBehYt+hwtLXfh90fP+L30TMEQkRuAr+F03HtIVb886f4w8BiwGugH1qrqIfe+dcDHcfb2/Y2qbjrV77OCYYw5U/m8s0UUDrcQCMw9ozP60+m97r6eRVPePzLye44de5a6urdPeb6OqpLNHkW1iM8XxueL4POFyGa7GRt7hXTauUQibbS03FPWTAWn4omCIc5g3l7g7cBRnB7ft01stSoidwErVPUTInIr8D5VXSsiy4EngCuBBcAvgEtUtTj590xkBcMYY06PVzruXQnsV9WDqpoDngRunrTOzcCj7vXvA2vEKes3A0+qalZVO4D97vMZY4ypkOksGC3AkQm3j7rLplxHVQvAEFBf5mMBEJE7RaRdRNqTyeRUqxhjjDkLZnxPb1V9UFXfoKpvaGy0qa2NMWa6TGfB6AQmHiPX6i6bch0RCQC1ODu/y3msMcaYc2g6C8Y24GIRWSwiIeBWYOOkdTYCd7jXbwGeVWcv/EbgVhEJi8hi4GJg6zRmNcYYcwrT1nFPVQsicg+wCeew2odV9WUR+RLQrqobgW8D/y0i+4EBnKKCu95TwC6gANx9qiOkjDHGTC87cc8YY2YxrxxWa4wx5jxyXm1hiEgSOHyGD28A+s5inOkwEzKC5TzbZkLOmZARLOdU2lS1rENMz6uC8VqISHu5m2WVMhMyguU822ZCzpmQESzna2VDUsYYY8piBcMYY0xZrGC86sFKByjDTMgIlvNsmwk5Z0JGsJyvie3DMMYYUxbbwjDGGFOWWV8wROQGEXlFRPaLyOcqnec4EXlYRBIisnPCsrki8nMR2ef+rKtkRjfTQhH5pYjsEpGXReRer2UVkYiIbBWR37sZ/9ldvlhEfud+9uvdKWwqTkT8IvKiiDzj3vZcThE5JCIvicgOEWl3l3nmM3fzxEXk+yKyR0R2i8ibPJhxqfseHr8Mi8h9Xst53KwuGG6TpweAdwLLgdvc5k1e8B3ghknLPgdsVtWLgc3u7UorAJ9W1eXAVcDd7nvopaxZ4HpVvQxYCdwgIlcB/wp8VVUvAo7hdHj0gnuB3RNuezXn21R15YTDP730mYPT7fOnqroMuAznPfVURlV9xX0PV+J0Hk0DG/BYznGqOmsvwJuATRNurwPWVTrXhDwXADsn3H4FmO9enw+8UumMU2T+EU6XRU9mBaLAduCNOCdGBab6t1DBfK04/0FcDzwDiEdzHgIaJi3zzGeOM/N1B+5+Wi9mnCLzO4DnvJxzVm9hcBqNmjyiWVW73es9QHMlw0wmIhcAq4Df4bGs7jDPDiAB/Bw4AAyq07gLvPPZ/zvwGaDk3q7HmzkV+JmIvCAid7rLvPSZLwaSwCPu8N5DIjIHb2Wc7Fac1tTg0ZyzvWDMWOp89fDMIW4iEgP+B7hPVYcn3ueFrKpaVGezvxWn3e+ySuaZiojcBCRU9YVKZynDW1X1cpzh3LtF5JqJd3rgMw8AlwP/qaqrgFEmDet4IOM4d7/Ue4CnJ9/npZyzvWDMtEZNvSIyH8D9mahwHgBEJIhTLB5X1R+4iz2ZVVUHgV/iDO3E3cZd4I3P/i3Ae0TkEPAkzrDU1/BeTlS10/2ZwBlzvxJvfeZHgaOq+jv39vdxCoiXMk70TmC7qva6tz2Zc7YXjHKaPHnJxIZTd+DsL6goERGcvia7VfXfJtzlmawi0igicfd6Fc4+lt04heMWd7WKv5+quk5VW1X1Apx/i8+q6kfwWE4RmSMi1cev44y978RDn7mq9gBHRGSpu2gNTn8dz2Sc5DZeHY4Cr+as9E6USl+AdwF7cca0P1/pPBNyPQF0A3mcb0sfxxnP3gzsA34BzPVAzrfibC7/AdjhXt7lpazACuBFN+NO4B/d5RfidHLcjzMUEK70+zkh83XAM17M6eb5vXt5+fjfjZc+czfPSqDd/dx/CNR5LaObcw5Oa+raCcs8l1NV7UxvY4wx5ZntQ1LGGGPKZAXDGGNMWaxgGGOMKYsVDGOMMWWxgmGMMaYsVjCM8QARue747LTGeJUVDGOMMWWxgmHMaRCRj7q9NXaIyDfdSQ1HROSrbq+NzSLS6K67UkSeF5E/iMiG4z0NROQiEfmF259ju4gscZ8+NqF/w+PuWfTGeIYVDGPKJCKXAmuBt6gzkWER+AjOmbrtqvo6YAvwRfchjwGfVdUVwEsTlj8OPKBOf44345zRD85Mv/fh9Ga5EGduKWM8I3DqVYwxrjU4TW62uV/+q3AmhSsB6911vgv8QERqgbiqbnGXPwo87c7B1KKqGwBUNQPgPt9WVT3q3t6B0w/lN9P/sowpjxUMY8onwKOquu6EhSJfmLTemc63k51wvYj9fRqPsSEpY8q3GbhFRJpgvId1G87f0fHZZD8M/EZVh4BjInK1u/x2YIuqpoCjIvJe9znCIhI9p6/CmDNk32CMKZOq7hKR+3E6zflwZhK+G6c5z5XufQmc/RzgTEv9X25BOAh8zF1+O/BNEfmS+xwfPIcvw5gzZrPVGvMaiciIqsYqncOY6WZDUsYYY8piWxjGGGPKYlsYxhhjymIFwxhjTFmsYBhjjCmLFQxjjDFlsYJhjDGmLFYwjDHGlOX/AS++LVP+IuDVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 15s 3ms/sample - loss: 0.5914 - acc: 0.8579\n",
      "Loss: 0.5914090808554479 Accuracy: 0.85794395\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0040 - acc: 0.4029\n",
      "Epoch 00001: val_loss improved from inf to 1.37358, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv_checkpoint/001-1.3736.hdf5\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 2.0039 - acc: 0.4029 - val_loss: 1.3736 - val_acc: 0.5649\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1531 - acc: 0.6432\n",
      "Epoch 00002: val_loss improved from 1.37358 to 1.13171, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv_checkpoint/002-1.1317.hdf5\n",
      "36805/36805 [==============================] - 406s 11ms/sample - loss: 1.1532 - acc: 0.6432 - val_loss: 1.1317 - val_acc: 0.6683\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8700 - acc: 0.7360\n",
      "Epoch 00003: val_loss improved from 1.13171 to 0.80559, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv_checkpoint/003-0.8056.hdf5\n",
      "36805/36805 [==============================] - 405s 11ms/sample - loss: 0.8700 - acc: 0.7360 - val_loss: 0.8056 - val_acc: 0.7594\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6835 - acc: 0.7971\n",
      "Epoch 00004: val_loss improved from 0.80559 to 0.75683, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv_checkpoint/004-0.7568.hdf5\n",
      "36805/36805 [==============================] - 405s 11ms/sample - loss: 0.6837 - acc: 0.7970 - val_loss: 0.7568 - val_acc: 0.7883\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5870 - acc: 0.8234\n",
      "Epoch 00005: val_loss improved from 0.75683 to 0.65292, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv_checkpoint/005-0.6529.hdf5\n",
      "36805/36805 [==============================] - 406s 11ms/sample - loss: 0.5871 - acc: 0.8233 - val_loss: 0.6529 - val_acc: 0.8262\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5156 - acc: 0.8460\n",
      "Epoch 00006: val_loss did not improve from 0.65292\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.5159 - acc: 0.8459 - val_loss: 0.7015 - val_acc: 0.8143\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4599 - acc: 0.8617\n",
      "Epoch 00007: val_loss improved from 0.65292 to 0.60654, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv_checkpoint/007-0.6065.hdf5\n",
      "36805/36805 [==============================] - 404s 11ms/sample - loss: 0.4600 - acc: 0.8617 - val_loss: 0.6065 - val_acc: 0.8474\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4109 - acc: 0.8740\n",
      "Epoch 00008: val_loss did not improve from 0.60654\n",
      "36805/36805 [==============================] - 406s 11ms/sample - loss: 0.4110 - acc: 0.8740 - val_loss: 0.6819 - val_acc: 0.8185\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3834 - acc: 0.8853\n",
      "Epoch 00009: val_loss improved from 0.60654 to 0.58923, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv_checkpoint/009-0.5892.hdf5\n",
      "36805/36805 [==============================] - 406s 11ms/sample - loss: 0.3836 - acc: 0.8853 - val_loss: 0.5892 - val_acc: 0.8453\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3425 - acc: 0.8943\n",
      "Epoch 00010: val_loss improved from 0.58923 to 0.48246, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv_checkpoint/010-0.4825.hdf5\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.3425 - acc: 0.8943 - val_loss: 0.4825 - val_acc: 0.8758\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3227 - acc: 0.9004\n",
      "Epoch 00011: val_loss improved from 0.48246 to 0.41558, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv_checkpoint/011-0.4156.hdf5\n",
      "36805/36805 [==============================] - 404s 11ms/sample - loss: 0.3227 - acc: 0.9004 - val_loss: 0.4156 - val_acc: 0.8919\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2964 - acc: 0.9072\n",
      "Epoch 00012: val_loss did not improve from 0.41558\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.2964 - acc: 0.9072 - val_loss: 0.5961 - val_acc: 0.8458\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2716 - acc: 0.9149\n",
      "Epoch 00013: val_loss improved from 0.41558 to 0.40107, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv_checkpoint/013-0.4011.hdf5\n",
      "36805/36805 [==============================] - 403s 11ms/sample - loss: 0.2716 - acc: 0.9149 - val_loss: 0.4011 - val_acc: 0.9022\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2499 - acc: 0.9219\n",
      "Epoch 00014: val_loss did not improve from 0.40107\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.2499 - acc: 0.9219 - val_loss: 0.4164 - val_acc: 0.8991\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2349 - acc: 0.9264\n",
      "Epoch 00015: val_loss did not improve from 0.40107\n",
      "36805/36805 [==============================] - 403s 11ms/sample - loss: 0.2349 - acc: 0.9263 - val_loss: 0.4587 - val_acc: 0.8861\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2314 - acc: 0.9261\n",
      "Epoch 00016: val_loss did not improve from 0.40107\n",
      "36805/36805 [==============================] - 406s 11ms/sample - loss: 0.2314 - acc: 0.9261 - val_loss: 0.4863 - val_acc: 0.8821\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9333\n",
      "Epoch 00017: val_loss did not improve from 0.40107\n",
      "36805/36805 [==============================] - 402s 11ms/sample - loss: 0.2090 - acc: 0.9333 - val_loss: 0.4454 - val_acc: 0.8933\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9369\n",
      "Epoch 00018: val_loss did not improve from 0.40107\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.1948 - acc: 0.9369 - val_loss: 0.5963 - val_acc: 0.8696\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1848 - acc: 0.9422\n",
      "Epoch 00019: val_loss did not improve from 0.40107\n",
      "36805/36805 [==============================] - 404s 11ms/sample - loss: 0.1852 - acc: 0.9421 - val_loss: 0.8363 - val_acc: 0.8255\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1865 - acc: 0.9406\n",
      "Epoch 00020: val_loss improved from 0.40107 to 0.35359, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv_checkpoint/020-0.3536.hdf5\n",
      "36805/36805 [==============================] - 405s 11ms/sample - loss: 0.1865 - acc: 0.9406 - val_loss: 0.3536 - val_acc: 0.9164\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9500\n",
      "Epoch 00021: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.1533 - acc: 0.9500 - val_loss: 0.5563 - val_acc: 0.8768\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9490\n",
      "Epoch 00022: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.1538 - acc: 0.9490 - val_loss: 0.4650 - val_acc: 0.8977\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9514\n",
      "Epoch 00023: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 406s 11ms/sample - loss: 0.1491 - acc: 0.9514 - val_loss: 0.5992 - val_acc: 0.8726\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9561\n",
      "Epoch 00024: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 405s 11ms/sample - loss: 0.1342 - acc: 0.9560 - val_loss: 0.4756 - val_acc: 0.9024\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9504\n",
      "Epoch 00025: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 404s 11ms/sample - loss: 0.1505 - acc: 0.9504 - val_loss: 0.4387 - val_acc: 0.9075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9608\n",
      "Epoch 00026: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.1230 - acc: 0.9608 - val_loss: 0.5726 - val_acc: 0.8831\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9605\n",
      "Epoch 00027: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 405s 11ms/sample - loss: 0.1212 - acc: 0.9604 - val_loss: 0.4676 - val_acc: 0.9008\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9621\n",
      "Epoch 00028: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.1172 - acc: 0.9620 - val_loss: 0.5032 - val_acc: 0.8954\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9568\n",
      "Epoch 00029: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 404s 11ms/sample - loss: 0.1330 - acc: 0.9568 - val_loss: 0.4332 - val_acc: 0.9050\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9669\n",
      "Epoch 00030: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 403s 11ms/sample - loss: 0.0980 - acc: 0.9669 - val_loss: 0.8731 - val_acc: 0.8414\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9643\n",
      "Epoch 00031: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 403s 11ms/sample - loss: 0.1114 - acc: 0.9643 - val_loss: 0.5448 - val_acc: 0.8945\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9646\n",
      "Epoch 00032: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 404s 11ms/sample - loss: 0.1089 - acc: 0.9646 - val_loss: 0.4853 - val_acc: 0.9012\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9685\n",
      "Epoch 00033: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 402s 11ms/sample - loss: 0.0972 - acc: 0.9685 - val_loss: 0.4215 - val_acc: 0.9171\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9697\n",
      "Epoch 00034: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 406s 11ms/sample - loss: 0.0936 - acc: 0.9697 - val_loss: 0.5433 - val_acc: 0.9022\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9711\n",
      "Epoch 00035: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0862 - acc: 0.9710 - val_loss: 0.4879 - val_acc: 0.9085\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9655\n",
      "Epoch 00036: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.1042 - acc: 0.9655 - val_loss: 0.4632 - val_acc: 0.9096\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9753\n",
      "Epoch 00037: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 402s 11ms/sample - loss: 0.0753 - acc: 0.9753 - val_loss: 0.5760 - val_acc: 0.8919\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9709\n",
      "Epoch 00038: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 406s 11ms/sample - loss: 0.0942 - acc: 0.9709 - val_loss: 0.4650 - val_acc: 0.9129\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9773\n",
      "Epoch 00039: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 404s 11ms/sample - loss: 0.0707 - acc: 0.9773 - val_loss: 0.5482 - val_acc: 0.8954\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9715\n",
      "Epoch 00040: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0898 - acc: 0.9715 - val_loss: 0.5321 - val_acc: 0.8915\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9762\n",
      "Epoch 00041: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 403s 11ms/sample - loss: 0.0728 - acc: 0.9762 - val_loss: 0.5365 - val_acc: 0.9036\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9743\n",
      "Epoch 00042: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0777 - acc: 0.9742 - val_loss: 0.4539 - val_acc: 0.9171\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9764\n",
      "Epoch 00043: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0714 - acc: 0.9764 - val_loss: 0.4181 - val_acc: 0.9178\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9803\n",
      "Epoch 00044: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0592 - acc: 0.9803 - val_loss: 0.4397 - val_acc: 0.9157\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9790\n",
      "Epoch 00045: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 403s 11ms/sample - loss: 0.0632 - acc: 0.9790 - val_loss: 0.6895 - val_acc: 0.8733\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9793\n",
      "Epoch 00046: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0634 - acc: 0.9793 - val_loss: 0.4727 - val_acc: 0.9110\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9811\n",
      "Epoch 00047: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.0580 - acc: 0.9811 - val_loss: 0.5543 - val_acc: 0.9052\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9826\n",
      "Epoch 00048: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0538 - acc: 0.9826 - val_loss: 0.5090 - val_acc: 0.9085\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9818\n",
      "Epoch 00049: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 404s 11ms/sample - loss: 0.0568 - acc: 0.9817 - val_loss: 0.6816 - val_acc: 0.8894\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9791\n",
      "Epoch 00050: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0658 - acc: 0.9791 - val_loss: 0.5664 - val_acc: 0.8963\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9806\n",
      "Epoch 00051: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 401s 11ms/sample - loss: 0.0572 - acc: 0.9806 - val_loss: 0.5073 - val_acc: 0.9117\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9819\n",
      "Epoch 00052: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0555 - acc: 0.9819 - val_loss: 0.5495 - val_acc: 0.9024\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9795\n",
      "Epoch 00053: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0638 - acc: 0.9795 - val_loss: 0.5301 - val_acc: 0.9147\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9867\n",
      "Epoch 00054: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0426 - acc: 0.9866 - val_loss: 0.6452 - val_acc: 0.8982\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9820\n",
      "Epoch 00055: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0551 - acc: 0.9820 - val_loss: 0.5441 - val_acc: 0.9012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9868\n",
      "Epoch 00056: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0434 - acc: 0.9868 - val_loss: 0.4412 - val_acc: 0.9189\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9867\n",
      "Epoch 00057: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 404s 11ms/sample - loss: 0.0433 - acc: 0.9866 - val_loss: 0.5934 - val_acc: 0.8905\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9817\n",
      "Epoch 00058: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0574 - acc: 0.9817 - val_loss: 0.4518 - val_acc: 0.9255\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9859\n",
      "Epoch 00059: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 406s 11ms/sample - loss: 0.0415 - acc: 0.9859 - val_loss: 0.4591 - val_acc: 0.9210\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9849\n",
      "Epoch 00060: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0438 - acc: 0.9849 - val_loss: 0.5741 - val_acc: 0.9050\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9843\n",
      "Epoch 00061: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0489 - acc: 0.9843 - val_loss: 0.6739 - val_acc: 0.8873\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9826\n",
      "Epoch 00062: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0541 - acc: 0.9826 - val_loss: 0.9905 - val_acc: 0.8369\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9860\n",
      "Epoch 00063: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 405s 11ms/sample - loss: 0.0454 - acc: 0.9859 - val_loss: 0.4706 - val_acc: 0.9229\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9867\n",
      "Epoch 00064: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0402 - acc: 0.9867 - val_loss: 0.4622 - val_acc: 0.9201\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9867\n",
      "Epoch 00065: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 402s 11ms/sample - loss: 0.0423 - acc: 0.9867 - val_loss: 0.4787 - val_acc: 0.9201\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9887\n",
      "Epoch 00066: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 404s 11ms/sample - loss: 0.0360 - acc: 0.9887 - val_loss: 0.5575 - val_acc: 0.9026\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9846\n",
      "Epoch 00067: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 403s 11ms/sample - loss: 0.0484 - acc: 0.9846 - val_loss: 0.5201 - val_acc: 0.9164\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9883\n",
      "Epoch 00068: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 405s 11ms/sample - loss: 0.0360 - acc: 0.9882 - val_loss: 0.5514 - val_acc: 0.9094\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9845\n",
      "Epoch 00069: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 405s 11ms/sample - loss: 0.0478 - acc: 0.9845 - val_loss: 0.5359 - val_acc: 0.9154\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9885\n",
      "Epoch 00070: val_loss did not improve from 0.35359\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0341 - acc: 0.9885 - val_loss: 0.4882 - val_acc: 0.9227\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 15s 3ms/sample - loss: 0.4222 - acc: 0.8926\n",
      "Loss: 0.42219577449009305 Accuracy: 0.8926272\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9904 - acc: 0.3868\n",
      "Epoch 00001: val_loss improved from inf to 1.39049, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv_checkpoint/001-1.3905.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 1.9905 - acc: 0.3868 - val_loss: 1.3905 - val_acc: 0.5337\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1491 - acc: 0.6396\n",
      "Epoch 00002: val_loss improved from 1.39049 to 1.09689, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv_checkpoint/002-1.0969.hdf5\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 1.1493 - acc: 0.6396 - val_loss: 1.0969 - val_acc: 0.6648\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8308 - acc: 0.7491\n",
      "Epoch 00003: val_loss improved from 1.09689 to 0.65158, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv_checkpoint/003-0.6516.hdf5\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.8308 - acc: 0.7491 - val_loss: 0.6516 - val_acc: 0.8102\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6453 - acc: 0.8074\n",
      "Epoch 00004: val_loss did not improve from 0.65158\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.6456 - acc: 0.8074 - val_loss: 0.7306 - val_acc: 0.7955\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5397 - acc: 0.8377\n",
      "Epoch 00005: val_loss improved from 0.65158 to 0.49742, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv_checkpoint/005-0.4974.hdf5\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.5397 - acc: 0.8377 - val_loss: 0.4974 - val_acc: 0.8565\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4698 - acc: 0.8585\n",
      "Epoch 00006: val_loss did not improve from 0.49742\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.4702 - acc: 0.8584 - val_loss: 0.7101 - val_acc: 0.7971\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4172 - acc: 0.8743\n",
      "Epoch 00007: val_loss did not improve from 0.49742\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.4171 - acc: 0.8744 - val_loss: 0.8466 - val_acc: 0.7668\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3720 - acc: 0.8881\n",
      "Epoch 00008: val_loss improved from 0.49742 to 0.36581, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv_checkpoint/008-0.3658.hdf5\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.3721 - acc: 0.8880 - val_loss: 0.3658 - val_acc: 0.8970\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3458 - acc: 0.8939\n",
      "Epoch 00009: val_loss improved from 0.36581 to 0.33696, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv_checkpoint/009-0.3370.hdf5\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.3461 - acc: 0.8938 - val_loss: 0.3370 - val_acc: 0.9147\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3065 - acc: 0.9062\n",
      "Epoch 00010: val_loss did not improve from 0.33696\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.3065 - acc: 0.9062 - val_loss: 0.3406 - val_acc: 0.9017\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2714 - acc: 0.9163\n",
      "Epoch 00011: val_loss did not improve from 0.33696\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.2714 - acc: 0.9163 - val_loss: 0.4497 - val_acc: 0.8863\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2506 - acc: 0.9233\n",
      "Epoch 00012: val_loss did not improve from 0.33696\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.2507 - acc: 0.9232 - val_loss: 0.4956 - val_acc: 0.8772\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2431 - acc: 0.9230\n",
      "Epoch 00013: val_loss did not improve from 0.33696\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.2431 - acc: 0.9230 - val_loss: 0.3500 - val_acc: 0.9061\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9317\n",
      "Epoch 00014: val_loss improved from 0.33696 to 0.27514, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv_checkpoint/014-0.2751.hdf5\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.2196 - acc: 0.9317 - val_loss: 0.2751 - val_acc: 0.9196\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2081 - acc: 0.9345\n",
      "Epoch 00015: val_loss improved from 0.27514 to 0.25473, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv_checkpoint/015-0.2547.hdf5\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.2081 - acc: 0.9345 - val_loss: 0.2547 - val_acc: 0.9341\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2007 - acc: 0.9359\n",
      "Epoch 00016: val_loss did not improve from 0.25473\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.2007 - acc: 0.9359 - val_loss: 0.4442 - val_acc: 0.8868\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1837 - acc: 0.9420\n",
      "Epoch 00017: val_loss did not improve from 0.25473\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.1837 - acc: 0.9420 - val_loss: 0.4115 - val_acc: 0.8940\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9470\n",
      "Epoch 00018: val_loss did not improve from 0.25473\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.1685 - acc: 0.9470 - val_loss: 0.3148 - val_acc: 0.9259\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9465\n",
      "Epoch 00019: val_loss did not improve from 0.25473\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.1684 - acc: 0.9465 - val_loss: 0.3012 - val_acc: 0.9201\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9483\n",
      "Epoch 00020: val_loss did not improve from 0.25473\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.1616 - acc: 0.9482 - val_loss: 0.4596 - val_acc: 0.8889\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1488 - acc: 0.9512\n",
      "Epoch 00021: val_loss did not improve from 0.25473\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1488 - acc: 0.9512 - val_loss: 0.2802 - val_acc: 0.9304\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9560\n",
      "Epoch 00022: val_loss did not improve from 0.25473\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.1353 - acc: 0.9560 - val_loss: 0.2599 - val_acc: 0.9343\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9566\n",
      "Epoch 00023: val_loss did not improve from 0.25473\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.1334 - acc: 0.9566 - val_loss: 0.3675 - val_acc: 0.9015\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9607\n",
      "Epoch 00024: val_loss did not improve from 0.25473\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.1211 - acc: 0.9606 - val_loss: 0.2915 - val_acc: 0.9264\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9593\n",
      "Epoch 00025: val_loss did not improve from 0.25473\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.1267 - acc: 0.9593 - val_loss: 0.2556 - val_acc: 0.9315\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9596\n",
      "Epoch 00026: val_loss did not improve from 0.25473\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1233 - acc: 0.9596 - val_loss: 0.3093 - val_acc: 0.9241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9657\n",
      "Epoch 00027: val_loss improved from 0.25473 to 0.25299, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv_checkpoint/027-0.2530.hdf5\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1047 - acc: 0.9657 - val_loss: 0.2530 - val_acc: 0.9383\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9666\n",
      "Epoch 00028: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1050 - acc: 0.9666 - val_loss: 0.3873 - val_acc: 0.9115\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9617\n",
      "Epoch 00029: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.1123 - acc: 0.9617 - val_loss: 0.3132 - val_acc: 0.9278\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9694\n",
      "Epoch 00030: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0925 - acc: 0.9694 - val_loss: 0.2772 - val_acc: 0.9308\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9691\n",
      "Epoch 00031: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0957 - acc: 0.9691 - val_loss: 0.4946 - val_acc: 0.8814\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9693\n",
      "Epoch 00032: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0933 - acc: 0.9693 - val_loss: 0.2970 - val_acc: 0.9297\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9750\n",
      "Epoch 00033: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0797 - acc: 0.9749 - val_loss: 0.6406 - val_acc: 0.8642\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9715\n",
      "Epoch 00034: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0826 - acc: 0.9715 - val_loss: 0.2877 - val_acc: 0.9348\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9712\n",
      "Epoch 00035: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0803 - acc: 0.9712 - val_loss: 0.4003 - val_acc: 0.9089\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9751\n",
      "Epoch 00036: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0751 - acc: 0.9751 - val_loss: 0.2733 - val_acc: 0.9362\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9774\n",
      "Epoch 00037: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0687 - acc: 0.9774 - val_loss: 0.6046 - val_acc: 0.8707\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9740\n",
      "Epoch 00038: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0778 - acc: 0.9740 - val_loss: 0.3522 - val_acc: 0.9224\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9780\n",
      "Epoch 00039: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0661 - acc: 0.9780 - val_loss: 0.4976 - val_acc: 0.9052\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9783\n",
      "Epoch 00040: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0648 - acc: 0.9783 - val_loss: 0.3321 - val_acc: 0.9257\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9757\n",
      "Epoch 00041: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0735 - acc: 0.9757 - val_loss: 1.0093 - val_acc: 0.8188\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9805\n",
      "Epoch 00042: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0588 - acc: 0.9805 - val_loss: 0.4527 - val_acc: 0.9082\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9803\n",
      "Epoch 00043: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0609 - acc: 0.9803 - val_loss: 0.3929 - val_acc: 0.9185\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9818\n",
      "Epoch 00044: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0549 - acc: 0.9818 - val_loss: 0.2970 - val_acc: 0.9387\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9784\n",
      "Epoch 00045: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0655 - acc: 0.9783 - val_loss: 0.2568 - val_acc: 0.9429\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9808\n",
      "Epoch 00046: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0580 - acc: 0.9808 - val_loss: 0.5790 - val_acc: 0.8924\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9751\n",
      "Epoch 00047: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0768 - acc: 0.9751 - val_loss: 0.3050 - val_acc: 0.9394\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9857\n",
      "Epoch 00048: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0451 - acc: 0.9856 - val_loss: 0.3168 - val_acc: 0.9345\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9789\n",
      "Epoch 00049: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0669 - acc: 0.9788 - val_loss: 0.3004 - val_acc: 0.9425\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9802\n",
      "Epoch 00050: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0622 - acc: 0.9802 - val_loss: 0.2708 - val_acc: 0.9448\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9855\n",
      "Epoch 00051: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0439 - acc: 0.9854 - val_loss: 0.3292 - val_acc: 0.9320\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9828\n",
      "Epoch 00052: val_loss did not improve from 0.25299\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0520 - acc: 0.9828 - val_loss: 0.2894 - val_acc: 0.9392\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9817\n",
      "Epoch 00053: val_loss improved from 0.25299 to 0.25149, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv_checkpoint/053-0.2515.hdf5\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0529 - acc: 0.9817 - val_loss: 0.2515 - val_acc: 0.9478\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9857\n",
      "Epoch 00054: val_loss improved from 0.25149 to 0.24796, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv_checkpoint/054-0.2480.hdf5\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0408 - acc: 0.9857 - val_loss: 0.2480 - val_acc: 0.9497\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9851\n",
      "Epoch 00055: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0458 - acc: 0.9851 - val_loss: 0.2849 - val_acc: 0.9432\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9876\n",
      "Epoch 00056: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0377 - acc: 0.9876 - val_loss: 0.3422 - val_acc: 0.9345\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9873\n",
      "Epoch 00057: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0382 - acc: 0.9873 - val_loss: 0.3272 - val_acc: 0.9317\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9867\n",
      "Epoch 00058: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0407 - acc: 0.9867 - val_loss: 0.3126 - val_acc: 0.9390\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9851\n",
      "Epoch 00059: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0463 - acc: 0.9851 - val_loss: 0.3076 - val_acc: 0.9301\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9875\n",
      "Epoch 00060: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0375 - acc: 0.9875 - val_loss: 0.3149 - val_acc: 0.9383\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9880\n",
      "Epoch 00061: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0378 - acc: 0.9879 - val_loss: 0.3992 - val_acc: 0.9147\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9824\n",
      "Epoch 00062: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0555 - acc: 0.9824 - val_loss: 2.2233 - val_acc: 0.7277\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9880\n",
      "Epoch 00063: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0364 - acc: 0.9880 - val_loss: 0.2749 - val_acc: 0.9457\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9881\n",
      "Epoch 00064: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0397 - acc: 0.9880 - val_loss: 0.2935 - val_acc: 0.9385\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9852\n",
      "Epoch 00065: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0476 - acc: 0.9852 - val_loss: 0.3684 - val_acc: 0.9285\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9897\n",
      "Epoch 00066: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0312 - acc: 0.9897 - val_loss: 0.3132 - val_acc: 0.9311\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9901\n",
      "Epoch 00067: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0292 - acc: 0.9900 - val_loss: 0.4956 - val_acc: 0.9150\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9860\n",
      "Epoch 00068: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0412 - acc: 0.9860 - val_loss: 0.2634 - val_acc: 0.9518\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9867\n",
      "Epoch 00069: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0396 - acc: 0.9867 - val_loss: 0.3367 - val_acc: 0.9320\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9893\n",
      "Epoch 00070: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0329 - acc: 0.9893 - val_loss: 0.2651 - val_acc: 0.9448\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9894\n",
      "Epoch 00071: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0331 - acc: 0.9893 - val_loss: 0.3431 - val_acc: 0.9383\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9828\n",
      "Epoch 00072: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0537 - acc: 0.9828 - val_loss: 0.3134 - val_acc: 0.9378\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9914\n",
      "Epoch 00073: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0258 - acc: 0.9914 - val_loss: 0.3365 - val_acc: 0.9348\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9914\n",
      "Epoch 00074: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0277 - acc: 0.9914 - val_loss: 0.2847 - val_acc: 0.9490\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9907\n",
      "Epoch 00075: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0279 - acc: 0.9907 - val_loss: 0.2955 - val_acc: 0.9408\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9900\n",
      "Epoch 00076: val_loss did not improve from 0.24796\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0303 - acc: 0.9900 - val_loss: 1.9162 - val_acc: 0.7519\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9869\n",
      "Epoch 00077: val_loss improved from 0.24796 to 0.24675, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv_checkpoint/077-0.2467.hdf5\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0422 - acc: 0.9869 - val_loss: 0.2467 - val_acc: 0.9522\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9907\n",
      "Epoch 00078: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0283 - acc: 0.9907 - val_loss: 0.3068 - val_acc: 0.9408\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9912\n",
      "Epoch 00079: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0255 - acc: 0.9912 - val_loss: 0.3029 - val_acc: 0.9490\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9905\n",
      "Epoch 00080: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0294 - acc: 0.9904 - val_loss: 0.2874 - val_acc: 0.9488\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9867\n",
      "Epoch 00081: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0432 - acc: 0.9867 - val_loss: 0.3260 - val_acc: 0.9413\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9913\n",
      "Epoch 00082: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0251 - acc: 0.9913 - val_loss: 0.2909 - val_acc: 0.9399\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9919\n",
      "Epoch 00083: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0247 - acc: 0.9919 - val_loss: 0.7116 - val_acc: 0.8842\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9912\n",
      "Epoch 00084: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0275 - acc: 0.9911 - val_loss: 0.3897 - val_acc: 0.9299\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9908\n",
      "Epoch 00085: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0291 - acc: 0.9908 - val_loss: 0.3209 - val_acc: 0.9406\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9921\n",
      "Epoch 00086: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0240 - acc: 0.9920 - val_loss: 0.3608 - val_acc: 0.9311\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9881\n",
      "Epoch 00087: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0353 - acc: 0.9881 - val_loss: 0.2641 - val_acc: 0.9511\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9930\n",
      "Epoch 00088: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0205 - acc: 0.9930 - val_loss: 0.2680 - val_acc: 0.9485\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9909\n",
      "Epoch 00089: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0288 - acc: 0.9909 - val_loss: 0.4303 - val_acc: 0.9161\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9919\n",
      "Epoch 00090: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0266 - acc: 0.9918 - val_loss: 0.3416 - val_acc: 0.9371\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9888\n",
      "Epoch 00091: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0353 - acc: 0.9888 - val_loss: 0.3962 - val_acc: 0.9336\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9923\n",
      "Epoch 00092: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0242 - acc: 0.9922 - val_loss: 0.2592 - val_acc: 0.9522\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9923\n",
      "Epoch 00093: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0241 - acc: 0.9923 - val_loss: 0.2523 - val_acc: 0.9548\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9930\n",
      "Epoch 00094: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0206 - acc: 0.9930 - val_loss: 0.3261 - val_acc: 0.9441\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9940\n",
      "Epoch 00095: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0193 - acc: 0.9940 - val_loss: 0.7356 - val_acc: 0.8798\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9922\n",
      "Epoch 00096: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0242 - acc: 0.9921 - val_loss: 0.2860 - val_acc: 0.9515\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9887\n",
      "Epoch 00097: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0349 - acc: 0.9886 - val_loss: 0.3713 - val_acc: 0.9366\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9906\n",
      "Epoch 00098: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0314 - acc: 0.9906 - val_loss: 0.2691 - val_acc: 0.9522\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9933\n",
      "Epoch 00099: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0197 - acc: 0.9933 - val_loss: 0.3395 - val_acc: 0.9387\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9938\n",
      "Epoch 00100: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0185 - acc: 0.9938 - val_loss: 0.5037 - val_acc: 0.9180\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9929\n",
      "Epoch 00101: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0222 - acc: 0.9929 - val_loss: 0.3063 - val_acc: 0.9420\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9899\n",
      "Epoch 00102: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0324 - acc: 0.9899 - val_loss: 0.2645 - val_acc: 0.9553\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9942\n",
      "Epoch 00103: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0168 - acc: 0.9942 - val_loss: 0.2975 - val_acc: 0.9499\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9932\n",
      "Epoch 00104: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0208 - acc: 0.9932 - val_loss: 0.3010 - val_acc: 0.9478\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9926\n",
      "Epoch 00105: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0226 - acc: 0.9926 - val_loss: 0.3122 - val_acc: 0.9511\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9927\n",
      "Epoch 00106: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0212 - acc: 0.9927 - val_loss: 0.3861 - val_acc: 0.9385\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9940\n",
      "Epoch 00107: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0177 - acc: 0.9940 - val_loss: 0.3193 - val_acc: 0.9488\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9935\n",
      "Epoch 00108: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0188 - acc: 0.9935 - val_loss: 0.5439 - val_acc: 0.9164\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9947\n",
      "Epoch 00109: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0161 - acc: 0.9947 - val_loss: 0.3720 - val_acc: 0.9411\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9921\n",
      "Epoch 00110: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0229 - acc: 0.9921 - val_loss: 0.3374 - val_acc: 0.9448\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9934\n",
      "Epoch 00111: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0191 - acc: 0.9934 - val_loss: 0.2812 - val_acc: 0.9469\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9934\n",
      "Epoch 00112: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0206 - acc: 0.9934 - val_loss: 0.3105 - val_acc: 0.9448\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9940\n",
      "Epoch 00113: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.0180 - acc: 0.9940 - val_loss: 0.2620 - val_acc: 0.9522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9946\n",
      "Epoch 00114: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0164 - acc: 0.9946 - val_loss: 0.2856 - val_acc: 0.9522\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9927\n",
      "Epoch 00115: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0224 - acc: 0.9927 - val_loss: 0.4383 - val_acc: 0.9297\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9909\n",
      "Epoch 00116: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0269 - acc: 0.9908 - val_loss: 0.3106 - val_acc: 0.9481\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9922\n",
      "Epoch 00117: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0249 - acc: 0.9922 - val_loss: 0.2907 - val_acc: 0.9485\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9958\n",
      "Epoch 00118: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0134 - acc: 0.9958 - val_loss: 0.2908 - val_acc: 0.9515\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9954\n",
      "Epoch 00119: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.0140 - acc: 0.9954 - val_loss: 0.2745 - val_acc: 0.9564\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9921\n",
      "Epoch 00120: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0247 - acc: 0.9921 - val_loss: 0.2903 - val_acc: 0.9495\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9923\n",
      "Epoch 00121: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0242 - acc: 0.9923 - val_loss: 0.3018 - val_acc: 0.9495\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9951\n",
      "Epoch 00122: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0155 - acc: 0.9950 - val_loss: 0.5134 - val_acc: 0.9187\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9935\n",
      "Epoch 00123: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0206 - acc: 0.9935 - val_loss: 0.3710 - val_acc: 0.9357\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9930\n",
      "Epoch 00124: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0213 - acc: 0.9930 - val_loss: 0.3282 - val_acc: 0.9464\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9957\n",
      "Epoch 00125: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 422s 11ms/sample - loss: 0.0125 - acc: 0.9957 - val_loss: 0.3391 - val_acc: 0.9425\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 00126: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0265 - acc: 0.9917 - val_loss: 0.2792 - val_acc: 0.9534\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9948\n",
      "Epoch 00127: val_loss did not improve from 0.24675\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0157 - acc: 0.9948 - val_loss: 1.0333 - val_acc: 0.8502\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.2997 - acc: 0.9350\n",
      "Loss: 0.29974709408355804 Accuracy: 0.9349948\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1766 - acc: 0.3316\n",
      "Epoch 00001: val_loss improved from inf to 1.51519, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/001-1.5152.hdf5\n",
      "36805/36805 [==============================] - 435s 12ms/sample - loss: 2.1767 - acc: 0.3316 - val_loss: 1.5152 - val_acc: 0.5181\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2245 - acc: 0.6104\n",
      "Epoch 00002: val_loss improved from 1.51519 to 0.97042, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/002-0.9704.hdf5\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 1.2246 - acc: 0.6104 - val_loss: 0.9704 - val_acc: 0.7016\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8322 - acc: 0.7467\n",
      "Epoch 00003: val_loss did not improve from 0.97042\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.8324 - acc: 0.7466 - val_loss: 1.0080 - val_acc: 0.7035\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6613 - acc: 0.8000\n",
      "Epoch 00004: val_loss improved from 0.97042 to 0.47935, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/004-0.4793.hdf5\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.6614 - acc: 0.7999 - val_loss: 0.4793 - val_acc: 0.8656\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5323 - acc: 0.8388\n",
      "Epoch 00005: val_loss did not improve from 0.47935\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.5323 - acc: 0.8387 - val_loss: 0.7385 - val_acc: 0.7959\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8620\n",
      "Epoch 00006: val_loss improved from 0.47935 to 0.44352, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/006-0.4435.hdf5\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.4592 - acc: 0.8619 - val_loss: 0.4435 - val_acc: 0.8700\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4012 - acc: 0.8758\n",
      "Epoch 00007: val_loss improved from 0.44352 to 0.33690, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/007-0.3369.hdf5\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.4012 - acc: 0.8758 - val_loss: 0.3369 - val_acc: 0.9057\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3516 - acc: 0.8933\n",
      "Epoch 00008: val_loss did not improve from 0.33690\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.3517 - acc: 0.8932 - val_loss: 0.3764 - val_acc: 0.8952\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3211 - acc: 0.9014\n",
      "Epoch 00009: val_loss did not improve from 0.33690\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.3211 - acc: 0.9014 - val_loss: 0.4275 - val_acc: 0.8798\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2952 - acc: 0.9111\n",
      "Epoch 00010: val_loss did not improve from 0.33690\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.2954 - acc: 0.9111 - val_loss: 0.3373 - val_acc: 0.9078\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2679 - acc: 0.9170\n",
      "Epoch 00011: val_loss did not improve from 0.33690\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.2679 - acc: 0.9170 - val_loss: 0.3838 - val_acc: 0.8956\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2393 - acc: 0.9259\n",
      "Epoch 00012: val_loss improved from 0.33690 to 0.29981, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/012-0.2998.hdf5\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.2393 - acc: 0.9259 - val_loss: 0.2998 - val_acc: 0.9213\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2343 - acc: 0.9270\n",
      "Epoch 00013: val_loss improved from 0.29981 to 0.25903, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/013-0.2590.hdf5\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.2343 - acc: 0.9270 - val_loss: 0.2590 - val_acc: 0.9271\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9333\n",
      "Epoch 00014: val_loss improved from 0.25903 to 0.23179, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/014-0.2318.hdf5\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.2110 - acc: 0.9332 - val_loss: 0.2318 - val_acc: 0.9355\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9337\n",
      "Epoch 00015: val_loss did not improve from 0.23179\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.2132 - acc: 0.9337 - val_loss: 0.3387 - val_acc: 0.9033\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1879 - acc: 0.9403\n",
      "Epoch 00016: val_loss improved from 0.23179 to 0.20337, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/016-0.2034.hdf5\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.1880 - acc: 0.9403 - val_loss: 0.2034 - val_acc: 0.9467\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9442\n",
      "Epoch 00017: val_loss did not improve from 0.20337\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.1720 - acc: 0.9442 - val_loss: 0.2052 - val_acc: 0.9427\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9490\n",
      "Epoch 00018: val_loss did not improve from 0.20337\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.1601 - acc: 0.9490 - val_loss: 0.2871 - val_acc: 0.9238\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1581 - acc: 0.9490\n",
      "Epoch 00019: val_loss improved from 0.20337 to 0.19095, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/019-0.1910.hdf5\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.1581 - acc: 0.9490 - val_loss: 0.1910 - val_acc: 0.9460\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9541\n",
      "Epoch 00020: val_loss did not improve from 0.19095\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.1465 - acc: 0.9541 - val_loss: 0.4208 - val_acc: 0.8849\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1327 - acc: 0.9568\n",
      "Epoch 00021: val_loss did not improve from 0.19095\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.1329 - acc: 0.9568 - val_loss: 0.2148 - val_acc: 0.9422\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9580\n",
      "Epoch 00022: val_loss did not improve from 0.19095\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.1334 - acc: 0.9580 - val_loss: 0.2491 - val_acc: 0.9399\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9594\n",
      "Epoch 00023: val_loss did not improve from 0.19095\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.1258 - acc: 0.9594 - val_loss: 0.3364 - val_acc: 0.9052\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9631\n",
      "Epoch 00024: val_loss improved from 0.19095 to 0.18820, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/024-0.1882.hdf5\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.1151 - acc: 0.9631 - val_loss: 0.1882 - val_acc: 0.9469\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9651\n",
      "Epoch 00025: val_loss did not improve from 0.18820\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.1081 - acc: 0.9650 - val_loss: 2.1071 - val_acc: 0.6846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9635\n",
      "Epoch 00026: val_loss did not improve from 0.18820\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.1122 - acc: 0.9634 - val_loss: 0.2020 - val_acc: 0.9476\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9631\n",
      "Epoch 00027: val_loss improved from 0.18820 to 0.17888, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/027-0.1789.hdf5\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.1083 - acc: 0.9631 - val_loss: 0.1789 - val_acc: 0.9474\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9693\n",
      "Epoch 00028: val_loss did not improve from 0.17888\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0939 - acc: 0.9693 - val_loss: 0.2238 - val_acc: 0.9420\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9687\n",
      "Epoch 00029: val_loss did not improve from 0.17888\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0965 - acc: 0.9687 - val_loss: 0.2389 - val_acc: 0.9425\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9685\n",
      "Epoch 00030: val_loss improved from 0.17888 to 0.16303, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/030-0.1630.hdf5\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0925 - acc: 0.9684 - val_loss: 0.1630 - val_acc: 0.9571\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9703\n",
      "Epoch 00031: val_loss did not improve from 0.16303\n",
      "36805/36805 [==============================] - 426s 12ms/sample - loss: 0.0919 - acc: 0.9703 - val_loss: 0.2932 - val_acc: 0.9187\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9657\n",
      "Epoch 00032: val_loss did not improve from 0.16303\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.1047 - acc: 0.9656 - val_loss: 0.8659 - val_acc: 0.8150\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9741\n",
      "Epoch 00033: val_loss did not improve from 0.16303\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0795 - acc: 0.9741 - val_loss: 0.3407 - val_acc: 0.9203\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9720\n",
      "Epoch 00034: val_loss did not improve from 0.16303\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0861 - acc: 0.9720 - val_loss: 0.1695 - val_acc: 0.9536\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9754\n",
      "Epoch 00035: val_loss did not improve from 0.16303\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0757 - acc: 0.9753 - val_loss: 0.1856 - val_acc: 0.9504\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9730\n",
      "Epoch 00036: val_loss improved from 0.16303 to 0.14920, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/036-0.1492.hdf5\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.0836 - acc: 0.9729 - val_loss: 0.1492 - val_acc: 0.9592\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9758\n",
      "Epoch 00037: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0728 - acc: 0.9758 - val_loss: 0.1574 - val_acc: 0.9613\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9771\n",
      "Epoch 00038: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0686 - acc: 0.9771 - val_loss: 0.3012 - val_acc: 0.9269\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9787\n",
      "Epoch 00039: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0649 - acc: 0.9788 - val_loss: 0.1990 - val_acc: 0.9469\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9805\n",
      "Epoch 00040: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0597 - acc: 0.9805 - val_loss: 0.1874 - val_acc: 0.9564\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9784\n",
      "Epoch 00041: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0676 - acc: 0.9784 - val_loss: 0.2413 - val_acc: 0.9399\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9814\n",
      "Epoch 00042: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0578 - acc: 0.9814 - val_loss: 0.1858 - val_acc: 0.9504\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9805\n",
      "Epoch 00043: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.0601 - acc: 0.9804 - val_loss: 0.2204 - val_acc: 0.9453\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9813\n",
      "Epoch 00044: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0589 - acc: 0.9813 - val_loss: 0.1877 - val_acc: 0.9588\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9839\n",
      "Epoch 00045: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0502 - acc: 0.9839 - val_loss: 0.1799 - val_acc: 0.9546\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9813\n",
      "Epoch 00046: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0569 - acc: 0.9813 - val_loss: 0.2794 - val_acc: 0.9299\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9835\n",
      "Epoch 00047: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.0499 - acc: 0.9835 - val_loss: 0.2026 - val_acc: 0.9499\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9842\n",
      "Epoch 00048: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0512 - acc: 0.9842 - val_loss: 0.1811 - val_acc: 0.9548\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9850\n",
      "Epoch 00049: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0456 - acc: 0.9850 - val_loss: 0.2746 - val_acc: 0.9355\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9848\n",
      "Epoch 00050: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0457 - acc: 0.9848 - val_loss: 0.5130 - val_acc: 0.8945\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9796\n",
      "Epoch 00051: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0637 - acc: 0.9795 - val_loss: 0.2121 - val_acc: 0.9460\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9864\n",
      "Epoch 00052: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.0423 - acc: 0.9863 - val_loss: 0.1573 - val_acc: 0.9604\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9858\n",
      "Epoch 00053: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0431 - acc: 0.9858 - val_loss: 0.1628 - val_acc: 0.9583\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9876\n",
      "Epoch 00054: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0373 - acc: 0.9876 - val_loss: 0.1831 - val_acc: 0.9588\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9863\n",
      "Epoch 00055: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0424 - acc: 0.9863 - val_loss: 0.2243 - val_acc: 0.9495\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9837\n",
      "Epoch 00056: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0499 - acc: 0.9837 - val_loss: 0.3114 - val_acc: 0.9313\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9871\n",
      "Epoch 00057: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0399 - acc: 0.9871 - val_loss: 0.2512 - val_acc: 0.9422\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9887\n",
      "Epoch 00058: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0363 - acc: 0.9887 - val_loss: 0.1579 - val_acc: 0.9604\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9890\n",
      "Epoch 00059: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.0345 - acc: 0.9890 - val_loss: 0.2011 - val_acc: 0.9474\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9875\n",
      "Epoch 00060: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0391 - acc: 0.9875 - val_loss: 0.1688 - val_acc: 0.9625\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9883\n",
      "Epoch 00061: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0359 - acc: 0.9883 - val_loss: 0.2296 - val_acc: 0.9476\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9872\n",
      "Epoch 00062: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0419 - acc: 0.9872 - val_loss: 0.8786 - val_acc: 0.8439\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9899\n",
      "Epoch 00063: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0316 - acc: 0.9899 - val_loss: 0.2035 - val_acc: 0.9499\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9907\n",
      "Epoch 00064: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0287 - acc: 0.9907 - val_loss: 0.1768 - val_acc: 0.9560\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9856\n",
      "Epoch 00065: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0446 - acc: 0.9856 - val_loss: 0.1616 - val_acc: 0.9604\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9893\n",
      "Epoch 00066: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.0348 - acc: 0.9893 - val_loss: 0.7428 - val_acc: 0.8665\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9879\n",
      "Epoch 00067: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0372 - acc: 0.9879 - val_loss: 0.5483 - val_acc: 0.8942\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9891\n",
      "Epoch 00068: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0340 - acc: 0.9891 - val_loss: 0.1650 - val_acc: 0.9623\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9916\n",
      "Epoch 00069: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.0270 - acc: 0.9916 - val_loss: 0.3681 - val_acc: 0.9231\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9875\n",
      "Epoch 00070: val_loss did not improve from 0.14920\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0381 - acc: 0.9874 - val_loss: 0.2139 - val_acc: 0.9483\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9877\n",
      "Epoch 00071: val_loss improved from 0.14920 to 0.14674, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv_checkpoint/071-0.1467.hdf5\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0392 - acc: 0.9876 - val_loss: 0.1467 - val_acc: 0.9625\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9901\n",
      "Epoch 00072: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 427s 12ms/sample - loss: 0.0295 - acc: 0.9901 - val_loss: 0.1757 - val_acc: 0.9625\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9928\n",
      "Epoch 00073: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0225 - acc: 0.9928 - val_loss: 0.1770 - val_acc: 0.9597\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9916\n",
      "Epoch 00074: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0264 - acc: 0.9916 - val_loss: 0.1828 - val_acc: 0.9590\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9905\n",
      "Epoch 00075: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0288 - acc: 0.9905 - val_loss: 0.2017 - val_acc: 0.9553\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9900\n",
      "Epoch 00076: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 427s 12ms/sample - loss: 0.0301 - acc: 0.9900 - val_loss: 0.1577 - val_acc: 0.9623\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9924\n",
      "Epoch 00077: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0243 - acc: 0.9924 - val_loss: 0.1667 - val_acc: 0.9590\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9912\n",
      "Epoch 00078: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0272 - acc: 0.9912 - val_loss: 0.1984 - val_acc: 0.9543\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9906\n",
      "Epoch 00079: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0298 - acc: 0.9906 - val_loss: 0.1791 - val_acc: 0.9611\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9939\n",
      "Epoch 00080: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0205 - acc: 0.9939 - val_loss: 0.2054 - val_acc: 0.9553\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9926\n",
      "Epoch 00081: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0230 - acc: 0.9926 - val_loss: 0.3804 - val_acc: 0.9178\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9929\n",
      "Epoch 00082: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0208 - acc: 0.9929 - val_loss: 0.1827 - val_acc: 0.9595\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9931\n",
      "Epoch 00083: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0223 - acc: 0.9930 - val_loss: 0.2021 - val_acc: 0.9562\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9912\n",
      "Epoch 00084: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.0274 - acc: 0.9912 - val_loss: 0.1733 - val_acc: 0.9623\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9911\n",
      "Epoch 00085: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0275 - acc: 0.9911 - val_loss: 0.1558 - val_acc: 0.9646\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9924\n",
      "Epoch 00086: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.0230 - acc: 0.9924 - val_loss: 0.1651 - val_acc: 0.9639\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9933\n",
      "Epoch 00087: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0210 - acc: 0.9933 - val_loss: 0.2254 - val_acc: 0.9527\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9936\n",
      "Epoch 00088: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0194 - acc: 0.9936 - val_loss: 0.2366 - val_acc: 0.9499\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9933\n",
      "Epoch 00089: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0209 - acc: 0.9933 - val_loss: 0.1677 - val_acc: 0.9620\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9927\n",
      "Epoch 00090: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.0220 - acc: 0.9927 - val_loss: 0.1665 - val_acc: 0.9651\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 00091: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0251 - acc: 0.9917 - val_loss: 0.1548 - val_acc: 0.9620\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9925\n",
      "Epoch 00092: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0230 - acc: 0.9925 - val_loss: 0.1708 - val_acc: 0.9604\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9952\n",
      "Epoch 00093: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 435s 12ms/sample - loss: 0.0157 - acc: 0.9951 - val_loss: 0.1664 - val_acc: 0.9576\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9918\n",
      "Epoch 00094: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 435s 12ms/sample - loss: 0.0241 - acc: 0.9918 - val_loss: 0.1865 - val_acc: 0.9613\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9944\n",
      "Epoch 00095: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0191 - acc: 0.9944 - val_loss: 0.2207 - val_acc: 0.9541\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9957\n",
      "Epoch 00096: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0144 - acc: 0.9957 - val_loss: 0.2560 - val_acc: 0.9485\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9919\n",
      "Epoch 00097: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0251 - acc: 0.9919 - val_loss: 0.1816 - val_acc: 0.9616\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9951\n",
      "Epoch 00098: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 435s 12ms/sample - loss: 0.0170 - acc: 0.9951 - val_loss: 0.1902 - val_acc: 0.9639\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9955\n",
      "Epoch 00099: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0144 - acc: 0.9955 - val_loss: 0.2030 - val_acc: 0.9590\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9942\n",
      "Epoch 00100: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0179 - acc: 0.9942 - val_loss: 0.1714 - val_acc: 0.9625\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9939\n",
      "Epoch 00101: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0202 - acc: 0.9939 - val_loss: 0.3385 - val_acc: 0.9362\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9936\n",
      "Epoch 00102: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.0222 - acc: 0.9936 - val_loss: 0.2444 - val_acc: 0.9464\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9956\n",
      "Epoch 00103: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0149 - acc: 0.9956 - val_loss: 0.1917 - val_acc: 0.9627\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9952\n",
      "Epoch 00104: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0159 - acc: 0.9951 - val_loss: 0.1701 - val_acc: 0.9590\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9911\n",
      "Epoch 00105: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0275 - acc: 0.9911 - val_loss: 0.1609 - val_acc: 0.9651\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9946\n",
      "Epoch 00106: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.0176 - acc: 0.9946 - val_loss: 0.1998 - val_acc: 0.9585\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9971\n",
      "Epoch 00107: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0100 - acc: 0.9971 - val_loss: 0.2233 - val_acc: 0.9476\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9963\n",
      "Epoch 00108: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0126 - acc: 0.9963 - val_loss: 0.1851 - val_acc: 0.9658\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9947\n",
      "Epoch 00109: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0165 - acc: 0.9947 - val_loss: 0.1640 - val_acc: 0.9639\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9949\n",
      "Epoch 00110: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0153 - acc: 0.9949 - val_loss: 0.2257 - val_acc: 0.9522\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9951\n",
      "Epoch 00111: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0157 - acc: 0.9951 - val_loss: 0.2454 - val_acc: 0.9511\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9953\n",
      "Epoch 00112: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0149 - acc: 0.9953 - val_loss: 0.2147 - val_acc: 0.9597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9945\n",
      "Epoch 00113: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0182 - acc: 0.9945 - val_loss: 0.1661 - val_acc: 0.9676\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9947\n",
      "Epoch 00114: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 435s 12ms/sample - loss: 0.0166 - acc: 0.9947 - val_loss: 0.2216 - val_acc: 0.9525\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9943\n",
      "Epoch 00115: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0177 - acc: 0.9943 - val_loss: 0.1903 - val_acc: 0.9620\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 00116: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0260 - acc: 0.9917 - val_loss: 0.1601 - val_acc: 0.9665\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9961\n",
      "Epoch 00117: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0118 - acc: 0.9961 - val_loss: 0.1729 - val_acc: 0.9616\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9961\n",
      "Epoch 00118: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.0132 - acc: 0.9961 - val_loss: 0.1756 - val_acc: 0.9620\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 00119: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0107 - acc: 0.9967 - val_loss: 0.2888 - val_acc: 0.9443\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9962\n",
      "Epoch 00120: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0135 - acc: 0.9962 - val_loss: 0.2007 - val_acc: 0.9595\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9953\n",
      "Epoch 00121: val_loss did not improve from 0.14674\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0146 - acc: 0.9953 - val_loss: 0.2190 - val_acc: 0.9522\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.1993 - acc: 0.9514\n",
      "Loss: 0.1992731784651228 Accuracy: 0.9514019\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2161 - acc: 0.3386\n",
      "Epoch 00001: val_loss improved from inf to 1.20739, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/001-1.2074.hdf5\n",
      "36805/36805 [==============================] - 440s 12ms/sample - loss: 2.2161 - acc: 0.3386 - val_loss: 1.2074 - val_acc: 0.6313\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2003 - acc: 0.6164\n",
      "Epoch 00002: val_loss improved from 1.20739 to 0.68292, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/002-0.6829.hdf5\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 1.2002 - acc: 0.6165 - val_loss: 0.6829 - val_acc: 0.8034\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7869 - acc: 0.7554\n",
      "Epoch 00003: val_loss improved from 0.68292 to 0.50858, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/003-0.5086.hdf5\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.7870 - acc: 0.7554 - val_loss: 0.5086 - val_acc: 0.8500\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5746 - acc: 0.8232\n",
      "Epoch 00004: val_loss improved from 0.50858 to 0.43593, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/004-0.4359.hdf5\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.5747 - acc: 0.8231 - val_loss: 0.4359 - val_acc: 0.8779\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4560 - acc: 0.8595\n",
      "Epoch 00005: val_loss improved from 0.43593 to 0.34005, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/005-0.3400.hdf5\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.4563 - acc: 0.8594 - val_loss: 0.3400 - val_acc: 0.9029\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3829 - acc: 0.8844\n",
      "Epoch 00006: val_loss improved from 0.34005 to 0.25760, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/006-0.2576.hdf5\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.3832 - acc: 0.8843 - val_loss: 0.2576 - val_acc: 0.9257\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3353 - acc: 0.8970\n",
      "Epoch 00007: val_loss did not improve from 0.25760\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.3353 - acc: 0.8969 - val_loss: 0.2837 - val_acc: 0.9194\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2989 - acc: 0.9092\n",
      "Epoch 00008: val_loss improved from 0.25760 to 0.24742, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/008-0.2474.hdf5\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.2990 - acc: 0.9091 - val_loss: 0.2474 - val_acc: 0.9301\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2578 - acc: 0.9207\n",
      "Epoch 00009: val_loss improved from 0.24742 to 0.23052, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/009-0.2305.hdf5\n",
      "36805/36805 [==============================] - 435s 12ms/sample - loss: 0.2582 - acc: 0.9207 - val_loss: 0.2305 - val_acc: 0.9392\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2397 - acc: 0.9268\n",
      "Epoch 00010: val_loss improved from 0.23052 to 0.17837, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/010-0.1784.hdf5\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.2396 - acc: 0.9268 - val_loss: 0.1784 - val_acc: 0.9515\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2111 - acc: 0.9338\n",
      "Epoch 00011: val_loss improved from 0.17837 to 0.15761, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/011-0.1576.hdf5\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.2112 - acc: 0.9338 - val_loss: 0.1576 - val_acc: 0.9522\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9365\n",
      "Epoch 00012: val_loss did not improve from 0.15761\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.2020 - acc: 0.9364 - val_loss: 0.2800 - val_acc: 0.9152\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9385\n",
      "Epoch 00013: val_loss did not improve from 0.15761\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.1978 - acc: 0.9385 - val_loss: 0.1819 - val_acc: 0.9481\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9476\n",
      "Epoch 00014: val_loss did not improve from 0.15761\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.1666 - acc: 0.9476 - val_loss: 0.4162 - val_acc: 0.8735\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9521\n",
      "Epoch 00015: val_loss did not improve from 0.15761\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.1549 - acc: 0.9521 - val_loss: 0.3920 - val_acc: 0.8845\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1479 - acc: 0.9536\n",
      "Epoch 00016: val_loss improved from 0.15761 to 0.14717, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/016-0.1472.hdf5\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.1479 - acc: 0.9536 - val_loss: 0.1472 - val_acc: 0.9581\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9572\n",
      "Epoch 00017: val_loss did not improve from 0.14717\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.1353 - acc: 0.9572 - val_loss: 0.1493 - val_acc: 0.9571\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9573\n",
      "Epoch 00018: val_loss did not improve from 0.14717\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.1334 - acc: 0.9573 - val_loss: 0.2681 - val_acc: 0.9208\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9584\n",
      "Epoch 00019: val_loss did not improve from 0.14717\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.1313 - acc: 0.9583 - val_loss: 0.2244 - val_acc: 0.9376\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9636\n",
      "Epoch 00020: val_loss did not improve from 0.14717\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.1177 - acc: 0.9636 - val_loss: 0.1531 - val_acc: 0.9555\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9650\n",
      "Epoch 00021: val_loss improved from 0.14717 to 0.12689, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/021-0.1269.hdf5\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.1114 - acc: 0.9650 - val_loss: 0.1269 - val_acc: 0.9660\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9691\n",
      "Epoch 00022: val_loss did not improve from 0.12689\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0973 - acc: 0.9691 - val_loss: 0.1742 - val_acc: 0.9492\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9685\n",
      "Epoch 00023: val_loss did not improve from 0.12689\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0982 - acc: 0.9685 - val_loss: 0.3036 - val_acc: 0.9099\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9685\n",
      "Epoch 00024: val_loss did not improve from 0.12689\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.0999 - acc: 0.9684 - val_loss: 0.2418 - val_acc: 0.9259\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9696\n",
      "Epoch 00025: val_loss did not improve from 0.12689\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0939 - acc: 0.9696 - val_loss: 0.1335 - val_acc: 0.9625\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9744\n",
      "Epoch 00026: val_loss did not improve from 0.12689\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0794 - acc: 0.9744 - val_loss: 0.1601 - val_acc: 0.9495\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9746\n",
      "Epoch 00027: val_loss did not improve from 0.12689\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0817 - acc: 0.9745 - val_loss: 0.1604 - val_acc: 0.9513\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.9716\n",
      "Epoch 00028: val_loss did not improve from 0.12689\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0879 - acc: 0.9716 - val_loss: 0.1512 - val_acc: 0.9588\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9779\n",
      "Epoch 00029: val_loss did not improve from 0.12689\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.0680 - acc: 0.9779 - val_loss: 0.9044 - val_acc: 0.7911\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9793\n",
      "Epoch 00030: val_loss improved from 0.12689 to 0.11258, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/030-0.1126.hdf5\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0646 - acc: 0.9793 - val_loss: 0.1126 - val_acc: 0.9653\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9768\n",
      "Epoch 00031: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0712 - acc: 0.9768 - val_loss: 0.3603 - val_acc: 0.8980\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9812\n",
      "Epoch 00032: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0577 - acc: 0.9812 - val_loss: 0.1325 - val_acc: 0.9618\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9824\n",
      "Epoch 00033: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0568 - acc: 0.9823 - val_loss: 0.1659 - val_acc: 0.9548\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9759\n",
      "Epoch 00034: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0764 - acc: 0.9759 - val_loss: 0.1261 - val_acc: 0.9639\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9843\n",
      "Epoch 00035: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0495 - acc: 0.9842 - val_loss: 0.1821 - val_acc: 0.9511\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9802\n",
      "Epoch 00036: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0592 - acc: 0.9802 - val_loss: 0.1622 - val_acc: 0.9571\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9844\n",
      "Epoch 00037: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0487 - acc: 0.9844 - val_loss: 0.1741 - val_acc: 0.9506\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9839\n",
      "Epoch 00038: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0496 - acc: 0.9839 - val_loss: 0.2109 - val_acc: 0.9357\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9848\n",
      "Epoch 00039: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0474 - acc: 0.9847 - val_loss: 0.4925 - val_acc: 0.8828\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9798\n",
      "Epoch 00040: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0642 - acc: 0.9798 - val_loss: 0.2630 - val_acc: 0.9304\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9843\n",
      "Epoch 00041: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0507 - acc: 0.9842 - val_loss: 0.1302 - val_acc: 0.9651\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9842\n",
      "Epoch 00042: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0494 - acc: 0.9842 - val_loss: 0.1528 - val_acc: 0.9553\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9886\n",
      "Epoch 00043: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0362 - acc: 0.9886 - val_loss: 0.1195 - val_acc: 0.9686\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9885\n",
      "Epoch 00044: val_loss did not improve from 0.11258\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0380 - acc: 0.9885 - val_loss: 0.2161 - val_acc: 0.9432\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9824\n",
      "Epoch 00045: val_loss improved from 0.11258 to 0.10877, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/045-0.1088.hdf5\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0555 - acc: 0.9824 - val_loss: 0.1088 - val_acc: 0.9693\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9873\n",
      "Epoch 00046: val_loss did not improve from 0.10877\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0410 - acc: 0.9873 - val_loss: 0.2448 - val_acc: 0.9401\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9880\n",
      "Epoch 00047: val_loss improved from 0.10877 to 0.10723, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/047-0.1072.hdf5\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0381 - acc: 0.9880 - val_loss: 0.1072 - val_acc: 0.9697\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9903\n",
      "Epoch 00048: val_loss did not improve from 0.10723\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0317 - acc: 0.9903 - val_loss: 0.1693 - val_acc: 0.9569\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9889\n",
      "Epoch 00049: val_loss did not improve from 0.10723\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0340 - acc: 0.9889 - val_loss: 0.1247 - val_acc: 0.9665\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9899\n",
      "Epoch 00050: val_loss did not improve from 0.10723\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0340 - acc: 0.9899 - val_loss: 0.1447 - val_acc: 0.9616\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9884\n",
      "Epoch 00051: val_loss did not improve from 0.10723\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0347 - acc: 0.9883 - val_loss: 0.1394 - val_acc: 0.9639\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9880\n",
      "Epoch 00052: val_loss did not improve from 0.10723\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0379 - acc: 0.9879 - val_loss: 0.1559 - val_acc: 0.9541\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9897\n",
      "Epoch 00053: val_loss did not improve from 0.10723\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0346 - acc: 0.9896 - val_loss: 0.1539 - val_acc: 0.9602\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9840\n",
      "Epoch 00054: val_loss did not improve from 0.10723\n",
      "36805/36805 [==============================] - 435s 12ms/sample - loss: 0.0532 - acc: 0.9840 - val_loss: 0.1228 - val_acc: 0.9686\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9898\n",
      "Epoch 00055: val_loss did not improve from 0.10723\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0324 - acc: 0.9898 - val_loss: 0.1090 - val_acc: 0.9716\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9896\n",
      "Epoch 00056: val_loss improved from 0.10723 to 0.10278, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/056-0.1028.hdf5\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0323 - acc: 0.9896 - val_loss: 0.1028 - val_acc: 0.9737\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9939\n",
      "Epoch 00057: val_loss did not improve from 0.10278\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0207 - acc: 0.9939 - val_loss: 0.1279 - val_acc: 0.9662\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9892\n",
      "Epoch 00058: val_loss did not improve from 0.10278\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.0346 - acc: 0.9891 - val_loss: 0.1233 - val_acc: 0.9683\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9919\n",
      "Epoch 00059: val_loss did not improve from 0.10278\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0271 - acc: 0.9919 - val_loss: 0.1226 - val_acc: 0.9713\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9907\n",
      "Epoch 00060: val_loss did not improve from 0.10278\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0307 - acc: 0.9907 - val_loss: 0.1185 - val_acc: 0.9686\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9895\n",
      "Epoch 00061: val_loss did not improve from 0.10278\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0317 - acc: 0.9895 - val_loss: 0.1686 - val_acc: 0.9564\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9937\n",
      "Epoch 00062: val_loss did not improve from 0.10278\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0218 - acc: 0.9937 - val_loss: 0.1835 - val_acc: 0.9509\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9927\n",
      "Epoch 00063: val_loss did not improve from 0.10278\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0227 - acc: 0.9927 - val_loss: 0.1488 - val_acc: 0.9630\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9893\n",
      "Epoch 00064: val_loss did not improve from 0.10278\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0338 - acc: 0.9893 - val_loss: 0.1266 - val_acc: 0.9667\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9895\n",
      "Epoch 00065: val_loss improved from 0.10278 to 0.10064, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv_checkpoint/065-0.1006.hdf5\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0347 - acc: 0.9895 - val_loss: 0.1006 - val_acc: 0.9739\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9922\n",
      "Epoch 00066: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0244 - acc: 0.9922 - val_loss: 0.1411 - val_acc: 0.9667\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9942\n",
      "Epoch 00067: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0189 - acc: 0.9942 - val_loss: 0.1121 - val_acc: 0.9741\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9936\n",
      "Epoch 00068: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0203 - acc: 0.9936 - val_loss: 0.1373 - val_acc: 0.9655\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9948\n",
      "Epoch 00069: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0182 - acc: 0.9948 - val_loss: 0.1315 - val_acc: 0.9667\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9933\n",
      "Epoch 00070: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0211 - acc: 0.9933 - val_loss: 0.1529 - val_acc: 0.9641\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9928\n",
      "Epoch 00071: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0216 - acc: 0.9928 - val_loss: 0.1563 - val_acc: 0.9620\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9937\n",
      "Epoch 00072: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0212 - acc: 0.9936 - val_loss: 0.1598 - val_acc: 0.9613\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9926\n",
      "Epoch 00073: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0262 - acc: 0.9926 - val_loss: 0.1318 - val_acc: 0.9669\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9947\n",
      "Epoch 00074: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0166 - acc: 0.9947 - val_loss: 0.1223 - val_acc: 0.9709\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9953\n",
      "Epoch 00075: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0170 - acc: 0.9953 - val_loss: 0.2383 - val_acc: 0.9499\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9910\n",
      "Epoch 00076: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0282 - acc: 0.9909 - val_loss: 0.1844 - val_acc: 0.9606\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9932\n",
      "Epoch 00077: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0228 - acc: 0.9931 - val_loss: 0.1327 - val_acc: 0.9674\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9933\n",
      "Epoch 00078: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 435s 12ms/sample - loss: 0.0215 - acc: 0.9933 - val_loss: 0.1119 - val_acc: 0.9732\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9969\n",
      "Epoch 00079: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0118 - acc: 0.9969 - val_loss: 0.1251 - val_acc: 0.9686\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9955\n",
      "Epoch 00080: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0155 - acc: 0.9955 - val_loss: 0.1462 - val_acc: 0.9630\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9930\n",
      "Epoch 00081: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0214 - acc: 0.9929 - val_loss: 0.1392 - val_acc: 0.9681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9936\n",
      "Epoch 00082: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0212 - acc: 0.9936 - val_loss: 0.1496 - val_acc: 0.9683\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9959\n",
      "Epoch 00083: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0135 - acc: 0.9959 - val_loss: 0.1406 - val_acc: 0.9672\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9954\n",
      "Epoch 00084: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0150 - acc: 0.9954 - val_loss: 0.1559 - val_acc: 0.9646\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9943\n",
      "Epoch 00085: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0185 - acc: 0.9943 - val_loss: 0.1379 - val_acc: 0.9669\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9948\n",
      "Epoch 00086: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0176 - acc: 0.9948 - val_loss: 0.1678 - val_acc: 0.9630\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9925\n",
      "Epoch 00087: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0230 - acc: 0.9925 - val_loss: 0.2768 - val_acc: 0.9413\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9962\n",
      "Epoch 00088: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0134 - acc: 0.9962 - val_loss: 0.1272 - val_acc: 0.9667\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9952\n",
      "Epoch 00089: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0166 - acc: 0.9952 - val_loss: 0.1126 - val_acc: 0.9720\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9926\n",
      "Epoch 00090: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0230 - acc: 0.9926 - val_loss: 0.1161 - val_acc: 0.9725\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9959\n",
      "Epoch 00091: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0135 - acc: 0.9958 - val_loss: 0.1250 - val_acc: 0.9716\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9945\n",
      "Epoch 00092: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0182 - acc: 0.9945 - val_loss: 0.2056 - val_acc: 0.9534\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9943\n",
      "Epoch 00093: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0177 - acc: 0.9943 - val_loss: 0.1400 - val_acc: 0.9655\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9975\n",
      "Epoch 00094: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0093 - acc: 0.9975 - val_loss: 0.1303 - val_acc: 0.9720\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9966\n",
      "Epoch 00095: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0123 - acc: 0.9966 - val_loss: 0.1313 - val_acc: 0.9672\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9932\n",
      "Epoch 00096: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0216 - acc: 0.9932 - val_loss: 0.1131 - val_acc: 0.9730\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9976\n",
      "Epoch 00097: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0089 - acc: 0.9976 - val_loss: 0.1273 - val_acc: 0.9700\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9928\n",
      "Epoch 00098: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.0241 - acc: 0.9928 - val_loss: 0.1270 - val_acc: 0.9706\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9962\n",
      "Epoch 00099: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0126 - acc: 0.9962 - val_loss: 0.1267 - val_acc: 0.9716\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9946\n",
      "Epoch 00100: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0177 - acc: 0.9946 - val_loss: 0.1238 - val_acc: 0.9704\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9932\n",
      "Epoch 00101: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0219 - acc: 0.9932 - val_loss: 0.1010 - val_acc: 0.9758\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9974\n",
      "Epoch 00102: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0090 - acc: 0.9973 - val_loss: 0.1198 - val_acc: 0.9713\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9935\n",
      "Epoch 00103: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0203 - acc: 0.9935 - val_loss: 0.1734 - val_acc: 0.9616\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9942\n",
      "Epoch 00104: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0186 - acc: 0.9942 - val_loss: 0.1112 - val_acc: 0.9727\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9962\n",
      "Epoch 00105: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0120 - acc: 0.9963 - val_loss: 0.1076 - val_acc: 0.9760\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9972\n",
      "Epoch 00106: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0099 - acc: 0.9971 - val_loss: 0.1261 - val_acc: 0.9734\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9950\n",
      "Epoch 00107: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 0.0164 - acc: 0.9950 - val_loss: 0.2144 - val_acc: 0.9485\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9924\n",
      "Epoch 00108: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 0.0245 - acc: 0.9923 - val_loss: 0.1228 - val_acc: 0.9709\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9941\n",
      "Epoch 00109: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0202 - acc: 0.9941 - val_loss: 0.1403 - val_acc: 0.9688\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9957\n",
      "Epoch 00110: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0140 - acc: 0.9957 - val_loss: 0.1623 - val_acc: 0.9651\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9960\n",
      "Epoch 00111: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0142 - acc: 0.9960 - val_loss: 0.1337 - val_acc: 0.9709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9977\n",
      "Epoch 00112: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0083 - acc: 0.9977 - val_loss: 0.1106 - val_acc: 0.9762\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9976\n",
      "Epoch 00113: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0088 - acc: 0.9976 - val_loss: 0.1176 - val_acc: 0.9690\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9939\n",
      "Epoch 00114: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0211 - acc: 0.9939 - val_loss: 0.1547 - val_acc: 0.9651\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9961\n",
      "Epoch 00115: val_loss did not improve from 0.10064\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0130 - acc: 0.9961 - val_loss: 0.1116 - val_acc: 0.9737\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 16s 3ms/sample - loss: 0.1484 - acc: 0.9639\n",
      "Loss: 0.14835858476761174 Accuracy: 0.96386296\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8736 - acc: 0.4520\n",
      "Epoch 00001: val_loss improved from inf to 0.74232, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv_checkpoint/001-0.7423.hdf5\n",
      "36805/36805 [==============================] - 476s 13ms/sample - loss: 1.8734 - acc: 0.4520 - val_loss: 0.7423 - val_acc: 0.7650\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7932 - acc: 0.7514\n",
      "Epoch 00002: val_loss improved from 0.74232 to 0.42969, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv_checkpoint/002-0.4297.hdf5\n",
      "36805/36805 [==============================] - 423s 11ms/sample - loss: 0.7932 - acc: 0.7514 - val_loss: 0.4297 - val_acc: 0.8721\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5164 - acc: 0.8421\n",
      "Epoch 00003: val_loss improved from 0.42969 to 0.31817, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv_checkpoint/003-0.3182.hdf5\n",
      "36805/36805 [==============================] - 402s 11ms/sample - loss: 0.5169 - acc: 0.8421 - val_loss: 0.3182 - val_acc: 0.9017\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3824 - acc: 0.8827\n",
      "Epoch 00004: val_loss improved from 0.31817 to 0.29965, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv_checkpoint/004-0.2996.hdf5\n",
      "36805/36805 [==============================] - 450s 12ms/sample - loss: 0.3826 - acc: 0.8827 - val_loss: 0.2996 - val_acc: 0.9113\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3188 - acc: 0.9030\n",
      "Epoch 00005: val_loss did not improve from 0.29965\n",
      "36805/36805 [==============================] - 463s 13ms/sample - loss: 0.3191 - acc: 0.9030 - val_loss: 0.5074 - val_acc: 0.8579\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2868 - acc: 0.9105\n",
      "Epoch 00006: val_loss improved from 0.29965 to 0.25251, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv_checkpoint/006-0.2525.hdf5\n",
      "36805/36805 [==============================] - 426s 12ms/sample - loss: 0.2869 - acc: 0.9104 - val_loss: 0.2525 - val_acc: 0.9250\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2431 - acc: 0.9244\n",
      "Epoch 00007: val_loss improved from 0.25251 to 0.21175, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv_checkpoint/007-0.2117.hdf5\n",
      "36805/36805 [==============================] - 401s 11ms/sample - loss: 0.2433 - acc: 0.9244 - val_loss: 0.2117 - val_acc: 0.9387\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2158 - acc: 0.9332\n",
      "Epoch 00008: val_loss improved from 0.21175 to 0.15779, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv_checkpoint/008-0.1578.hdf5\n",
      "36805/36805 [==============================] - 450s 12ms/sample - loss: 0.2158 - acc: 0.9332 - val_loss: 0.1578 - val_acc: 0.9553\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1789 - acc: 0.9431\n",
      "Epoch 00009: val_loss improved from 0.15779 to 0.14459, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv_checkpoint/009-0.1446.hdf5\n",
      "36805/36805 [==============================] - 464s 13ms/sample - loss: 0.1790 - acc: 0.9430 - val_loss: 0.1446 - val_acc: 0.9557\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9465\n",
      "Epoch 00010: val_loss did not improve from 0.14459\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.1712 - acc: 0.9466 - val_loss: 0.2015 - val_acc: 0.9371\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9518\n",
      "Epoch 00011: val_loss did not improve from 0.14459\n",
      "36805/36805 [==============================] - 402s 11ms/sample - loss: 0.1522 - acc: 0.9518 - val_loss: 0.1663 - val_acc: 0.9462\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1484 - acc: 0.9536\n",
      "Epoch 00012: val_loss did not improve from 0.14459\n",
      "36805/36805 [==============================] - 454s 12ms/sample - loss: 0.1485 - acc: 0.9536 - val_loss: 0.1587 - val_acc: 0.9522\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9589\n",
      "Epoch 00013: val_loss improved from 0.14459 to 0.13946, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv_checkpoint/013-0.1395.hdf5\n",
      "36805/36805 [==============================] - 451s 12ms/sample - loss: 0.1308 - acc: 0.9589 - val_loss: 0.1395 - val_acc: 0.9602\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9642\n",
      "Epoch 00014: val_loss did not improve from 0.13946\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.1151 - acc: 0.9642 - val_loss: 0.1495 - val_acc: 0.9543\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9652\n",
      "Epoch 00015: val_loss improved from 0.13946 to 0.11977, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv_checkpoint/015-0.1198.hdf5\n",
      "36805/36805 [==============================] - 390s 11ms/sample - loss: 0.1100 - acc: 0.9652 - val_loss: 0.1198 - val_acc: 0.9651\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9680\n",
      "Epoch 00016: val_loss improved from 0.11977 to 0.10632, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv_checkpoint/016-0.1063.hdf5\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.1011 - acc: 0.9680 - val_loss: 0.1063 - val_acc: 0.9683\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9675\n",
      "Epoch 00017: val_loss did not improve from 0.10632\n",
      "36805/36805 [==============================] - 442s 12ms/sample - loss: 0.0988 - acc: 0.9675 - val_loss: 0.1257 - val_acc: 0.9623\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9682\n",
      "Epoch 00018: val_loss did not improve from 0.10632\n",
      "36805/36805 [==============================] - 407s 11ms/sample - loss: 0.0981 - acc: 0.9682 - val_loss: 0.1192 - val_acc: 0.9662\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9771\n",
      "Epoch 00019: val_loss did not improve from 0.10632\n",
      "36805/36805 [==============================] - 389s 11ms/sample - loss: 0.0744 - acc: 0.9771 - val_loss: 0.1864 - val_acc: 0.9446\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9770\n",
      "Epoch 00020: val_loss did not improve from 0.10632\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0722 - acc: 0.9770 - val_loss: 0.1358 - val_acc: 0.9602\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9763\n",
      "Epoch 00021: val_loss did not improve from 0.10632\n",
      "36805/36805 [==============================] - 443s 12ms/sample - loss: 0.0758 - acc: 0.9763 - val_loss: 0.1790 - val_acc: 0.9483\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9793\n",
      "Epoch 00022: val_loss did not improve from 0.10632\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0649 - acc: 0.9794 - val_loss: 0.1165 - val_acc: 0.9655\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9799\n",
      "Epoch 00023: val_loss did not improve from 0.10632\n",
      "36805/36805 [==============================] - 391s 11ms/sample - loss: 0.0626 - acc: 0.9798 - val_loss: 0.1200 - val_acc: 0.9662\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9802\n",
      "Epoch 00024: val_loss did not improve from 0.10632\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0622 - acc: 0.9801 - val_loss: 0.1802 - val_acc: 0.9457\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9777\n",
      "Epoch 00025: val_loss did not improve from 0.10632\n",
      "36805/36805 [==============================] - 442s 12ms/sample - loss: 0.0673 - acc: 0.9777 - val_loss: 0.1169 - val_acc: 0.9634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9843\n",
      "Epoch 00026: val_loss did not improve from 0.10632\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0505 - acc: 0.9842 - val_loss: 0.1414 - val_acc: 0.9625\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9836\n",
      "Epoch 00027: val_loss did not improve from 0.10632\n",
      "36805/36805 [==============================] - 389s 11ms/sample - loss: 0.0536 - acc: 0.9836 - val_loss: 0.1371 - val_acc: 0.9611\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9815\n",
      "Epoch 00028: val_loss improved from 0.10632 to 0.08217, saving model to model/checkpoint/1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv_checkpoint/028-0.0822.hdf5\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0565 - acc: 0.9815 - val_loss: 0.0822 - val_acc: 0.9755\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9854\n",
      "Epoch 00029: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 441s 12ms/sample - loss: 0.0454 - acc: 0.9854 - val_loss: 0.1183 - val_acc: 0.9646\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9845\n",
      "Epoch 00030: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0492 - acc: 0.9844 - val_loss: 0.1301 - val_acc: 0.9611\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9863\n",
      "Epoch 00031: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 390s 11ms/sample - loss: 0.0441 - acc: 0.9863 - val_loss: 0.1087 - val_acc: 0.9690\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9877\n",
      "Epoch 00032: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0409 - acc: 0.9877 - val_loss: 0.1195 - val_acc: 0.9662\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9851\n",
      "Epoch 00033: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 440s 12ms/sample - loss: 0.0468 - acc: 0.9851 - val_loss: 0.1173 - val_acc: 0.9669\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9893\n",
      "Epoch 00034: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0346 - acc: 0.9893 - val_loss: 0.1173 - val_acc: 0.9662\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9903\n",
      "Epoch 00035: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 391s 11ms/sample - loss: 0.0316 - acc: 0.9903 - val_loss: 0.1156 - val_acc: 0.9683\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9901\n",
      "Epoch 00036: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 428s 12ms/sample - loss: 0.0323 - acc: 0.9900 - val_loss: 0.1195 - val_acc: 0.9688\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9851\n",
      "Epoch 00037: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 441s 12ms/sample - loss: 0.0456 - acc: 0.9851 - val_loss: 0.1141 - val_acc: 0.9660\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9905\n",
      "Epoch 00038: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0318 - acc: 0.9905 - val_loss: 0.1092 - val_acc: 0.9660\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9884\n",
      "Epoch 00039: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 391s 11ms/sample - loss: 0.0381 - acc: 0.9884 - val_loss: 0.1082 - val_acc: 0.9718\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9920\n",
      "Epoch 00040: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0248 - acc: 0.9920 - val_loss: 0.1059 - val_acc: 0.9695\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9926\n",
      "Epoch 00041: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 441s 12ms/sample - loss: 0.0252 - acc: 0.9926 - val_loss: 0.1304 - val_acc: 0.9627\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9911\n",
      "Epoch 00042: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0285 - acc: 0.9911 - val_loss: 0.1055 - val_acc: 0.9730\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9926\n",
      "Epoch 00043: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 391s 11ms/sample - loss: 0.0246 - acc: 0.9926 - val_loss: 0.1209 - val_acc: 0.9704\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9916\n",
      "Epoch 00044: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0267 - acc: 0.9916 - val_loss: 0.1003 - val_acc: 0.9706\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9921\n",
      "Epoch 00045: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 442s 12ms/sample - loss: 0.0243 - acc: 0.9921 - val_loss: 0.1205 - val_acc: 0.9674\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9931\n",
      "Epoch 00046: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0216 - acc: 0.9931 - val_loss: 0.1081 - val_acc: 0.9732\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9935\n",
      "Epoch 00047: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 390s 11ms/sample - loss: 0.0215 - acc: 0.9935 - val_loss: 0.1213 - val_acc: 0.9688\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9909\n",
      "Epoch 00048: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0295 - acc: 0.9909 - val_loss: 0.1106 - val_acc: 0.9711\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9926\n",
      "Epoch 00049: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 442s 12ms/sample - loss: 0.0229 - acc: 0.9926 - val_loss: 0.1248 - val_acc: 0.9658\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9951\n",
      "Epoch 00050: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0168 - acc: 0.9951 - val_loss: 0.1284 - val_acc: 0.9674\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9940\n",
      "Epoch 00051: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 391s 11ms/sample - loss: 0.0185 - acc: 0.9940 - val_loss: 0.1346 - val_acc: 0.9658\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9914\n",
      "Epoch 00052: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0277 - acc: 0.9914 - val_loss: 0.0981 - val_acc: 0.9734\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9941\n",
      "Epoch 00053: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 442s 12ms/sample - loss: 0.0183 - acc: 0.9941 - val_loss: 0.1618 - val_acc: 0.9620\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9948\n",
      "Epoch 00054: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0180 - acc: 0.9948 - val_loss: 0.1087 - val_acc: 0.9732\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9957\n",
      "Epoch 00055: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 390s 11ms/sample - loss: 0.0146 - acc: 0.9956 - val_loss: 0.1500 - val_acc: 0.9644\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 00056: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0286 - acc: 0.9917 - val_loss: 0.1118 - val_acc: 0.9720\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9964\n",
      "Epoch 00057: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 441s 12ms/sample - loss: 0.0136 - acc: 0.9963 - val_loss: 0.1198 - val_acc: 0.9702\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9942\n",
      "Epoch 00058: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0201 - acc: 0.9941 - val_loss: 0.1490 - val_acc: 0.9625\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9939\n",
      "Epoch 00059: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 390s 11ms/sample - loss: 0.0197 - acc: 0.9939 - val_loss: 0.1175 - val_acc: 0.9734\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9967\n",
      "Epoch 00060: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0112 - acc: 0.9966 - val_loss: 0.1329 - val_acc: 0.9693\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9935\n",
      "Epoch 00061: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 443s 12ms/sample - loss: 0.0211 - acc: 0.9935 - val_loss: 0.1762 - val_acc: 0.9541\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9963\n",
      "Epoch 00062: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0134 - acc: 0.9963 - val_loss: 0.1052 - val_acc: 0.9753\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9962\n",
      "Epoch 00063: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 390s 11ms/sample - loss: 0.0123 - acc: 0.9962 - val_loss: 0.1368 - val_acc: 0.9681\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9933\n",
      "Epoch 00064: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 432s 12ms/sample - loss: 0.0212 - acc: 0.9933 - val_loss: 0.1317 - val_acc: 0.9718\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9959\n",
      "Epoch 00065: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 443s 12ms/sample - loss: 0.0139 - acc: 0.9959 - val_loss: 0.1258 - val_acc: 0.9693\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9916\n",
      "Epoch 00066: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.0264 - acc: 0.9916 - val_loss: 0.1223 - val_acc: 0.9688\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9977\n",
      "Epoch 00067: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 392s 11ms/sample - loss: 0.0084 - acc: 0.9977 - val_loss: 0.1012 - val_acc: 0.9744\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9971\n",
      "Epoch 00068: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 433s 12ms/sample - loss: 0.0099 - acc: 0.9970 - val_loss: 0.1300 - val_acc: 0.9686\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9943\n",
      "Epoch 00069: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 441s 12ms/sample - loss: 0.0193 - acc: 0.9943 - val_loss: 0.1076 - val_acc: 0.9751\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9962\n",
      "Epoch 00070: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 408s 11ms/sample - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0949 - val_acc: 0.9767\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9972\n",
      "Epoch 00071: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 391s 11ms/sample - loss: 0.0096 - acc: 0.9971 - val_loss: 0.1506 - val_acc: 0.9585\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9936\n",
      "Epoch 00072: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 0.0208 - acc: 0.9936 - val_loss: 0.1020 - val_acc: 0.9737\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9979\n",
      "Epoch 00073: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 444s 12ms/sample - loss: 0.0075 - acc: 0.9979 - val_loss: 0.1684 - val_acc: 0.9585\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9962\n",
      "Epoch 00074: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0115 - acc: 0.9962 - val_loss: 0.1260 - val_acc: 0.9718\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9971\n",
      "Epoch 00075: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 391s 11ms/sample - loss: 0.0096 - acc: 0.9971 - val_loss: 0.1193 - val_acc: 0.9730\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9968\n",
      "Epoch 00076: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 0.0106 - acc: 0.9968 - val_loss: 0.1151 - val_acc: 0.9727\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9962\n",
      "Epoch 00077: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 441s 12ms/sample - loss: 0.0132 - acc: 0.9962 - val_loss: 0.1521 - val_acc: 0.9653\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9946\n",
      "Epoch 00078: val_loss did not improve from 0.08217\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 0.0176 - acc: 0.9946 - val_loss: 0.1146 - val_acc: 0.9746\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.1158 - acc: 0.9664\n",
      "Loss: 0.11580744909464942 Accuracy: 0.96635514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    base = '1D_CNN_custom_kernel_192_ch_128_DO_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_ch_32_DO_BN(conv_num=i)\n",
    "    \n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "#         model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_42_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 16)           6025104     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Concatenate)           (None, 16)           0           sequential_7[1][0]               \n",
      "                                                                 sequential_7[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,025,104\n",
      "Trainable params: 6,024,336\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 16s 3ms/sample - loss: 1.0545 - acc: 0.7387\n",
      "Loss: 1.0545296205043297 Accuracy: 0.7387331\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_45_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 16)           3992080     lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Concatenate)           (None, 16)           0           sequential_8[1][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,992,080\n",
      "Trainable params: 3,991,056\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 16s 3ms/sample - loss: 0.5914 - acc: 0.8579\n",
      "Loss: 0.5914090808554479 Accuracy: 0.85794395\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_49_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 16)           3981072     lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Concatenate)           (None, 16)           0           sequential_9[1][0]               \n",
      "                                                                 sequential_9[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,981,072\n",
      "Trainable params: 3,979,536\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.4222 - acc: 0.8926\n",
      "Loss: 0.42219577449009305 Accuracy: 0.8926272\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_54_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 16)           3834896     lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Concatenate)          (None, 16)           0           sequential_10[1][0]              \n",
      "                                                                 sequential_10[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,834,896\n",
      "Trainable params: 3,832,848\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.2997 - acc: 0.9350\n",
      "Loss: 0.29974709408355804 Accuracy: 0.9349948\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_60_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 16)           3852560     lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Concatenate)          (None, 16)           0           sequential_11[1][0]              \n",
      "                                                                 sequential_11[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,852,560\n",
      "Trainable params: 3,850,000\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 17s 4ms/sample - loss: 0.1993 - acc: 0.9514\n",
      "Loss: 0.1992731784651228 Accuracy: 0.9514019\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_67_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 16)           3993104     lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Concatenate)          (None, 16)           0           sequential_12[1][0]              \n",
      "                                                                 sequential_12[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,993,104\n",
      "Trainable params: 3,990,032\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 16s 3ms/sample - loss: 0.1484 - acc: 0.9639\n",
      "Loss: 0.14835858476761174 Accuracy: 0.96386296\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_75_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 16)           4376592     lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Concatenate)          (None, 16)           0           sequential_13[1][0]              \n",
      "                                                                 sequential_13[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,376,592\n",
      "Trainable params: 4,372,496\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 17s 4ms/sample - loss: 0.1158 - acc: 0.96646s - loss: 0.1115 - acc: 0.96 - ETA: 6s - loss: 0.1111 -\n",
      "Loss: 0.11580744909464942 Accuracy: 0.96635514\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_kernel_192_ch_128_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_42_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 16)           6025104     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Concatenate)           (None, 16)           0           sequential_7[1][0]               \n",
      "                                                                 sequential_7[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,025,104\n",
      "Trainable params: 6,024,336\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 16s 3ms/sample - loss: 1.4259 - acc: 0.7882\n",
      "Loss: 1.4259431444967277 Accuracy: 0.788162\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_45_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 16)           3992080     lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Concatenate)           (None, 16)           0           sequential_8[1][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,992,080\n",
      "Trainable params: 3,991,056\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 17s 4ms/sample - loss: 0.8134 - acc: 0.8698\n",
      "Loss: 0.8133656402800313 Accuracy: 0.8697819\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_49_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 16)           3981072     lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Concatenate)           (None, 16)           0           sequential_9[1][0]               \n",
      "                                                                 sequential_9[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,981,072\n",
      "Trainable params: 3,979,536\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 17s 4ms/sample - loss: 0.5670 - acc: 0.9028\n",
      "Loss: 0.5669638490890416 Accuracy: 0.9028037\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_54_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 16)           3834896     lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Concatenate)          (None, 16)           0           sequential_10[1][0]              \n",
      "                                                                 sequential_10[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,834,896\n",
      "Trainable params: 3,832,848\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 1.2710 - acc: 0.8289\n",
      "Loss: 1.2710170707536759 Accuracy: 0.8288681\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_60_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 16)           3852560     lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Concatenate)          (None, 16)           0           sequential_11[1][0]              \n",
      "                                                                 sequential_11[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,852,560\n",
      "Trainable params: 3,850,000\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 17s 3ms/sample - loss: 0.3097 - acc: 0.9364\n",
      "Loss: 0.30966072024570573 Accuracy: 0.9364486\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_67_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 16)           3993104     lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Concatenate)          (None, 16)           0           sequential_12[1][0]              \n",
      "                                                                 sequential_12[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,993,104\n",
      "Trainable params: 3,990,032\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 0.1455 - acc: 0.9659\n",
      "Loss: 0.14547134661458727 Accuracy: 0.96593976\n",
      "\n",
      "1D_CNN_custom_kernel_192_ch_128_DO_BN_9_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_75_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 16)           4376592     lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Concatenate)          (None, 16)           0           sequential_13[1][0]              \n",
      "                                                                 sequential_13[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,376,592\n",
      "Trainable params: 4,372,496\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 0.1397 - acc: 0.9659\n",
      "Loss: 0.13972097238274783 Accuracy: 0.96593976\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
