{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                      activation='relu', input_shape=input_shape)) \n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                  activation='relu')) \n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))         \n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,498,320\n",
      "Trainable params: 5,498,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3342 - acc: 0.2681\n",
      "Epoch 00001: val_loss improved from inf to 2.11902, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_1_conv_checkpoint/001-2.1190.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 2.3342 - acc: 0.2680 - val_loss: 2.1190 - val_acc: 0.3361\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8677 - acc: 0.4412\n",
      "Epoch 00002: val_loss improved from 2.11902 to 1.97704, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_1_conv_checkpoint/002-1.9770.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.8677 - acc: 0.4411 - val_loss: 1.9770 - val_acc: 0.3946\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4978 - acc: 0.5650\n",
      "Epoch 00003: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.4979 - acc: 0.5650 - val_loss: 1.9807 - val_acc: 0.4018\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1864 - acc: 0.6626\n",
      "Epoch 00004: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.1863 - acc: 0.6626 - val_loss: 2.0509 - val_acc: 0.3755\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9279 - acc: 0.7422\n",
      "Epoch 00005: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.9279 - acc: 0.7422 - val_loss: 2.1401 - val_acc: 0.3755\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7272 - acc: 0.8094\n",
      "Epoch 00006: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.7272 - acc: 0.8094 - val_loss: 2.2356 - val_acc: 0.3876\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5647 - acc: 0.8575\n",
      "Epoch 00007: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.5647 - acc: 0.8575 - val_loss: 2.4169 - val_acc: 0.3736\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4370 - acc: 0.8951\n",
      "Epoch 00008: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4370 - acc: 0.8951 - val_loss: 2.5836 - val_acc: 0.3671\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3378 - acc: 0.9243\n",
      "Epoch 00009: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3378 - acc: 0.9244 - val_loss: 2.7661 - val_acc: 0.3648\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2655 - acc: 0.9439\n",
      "Epoch 00010: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2656 - acc: 0.9438 - val_loss: 2.8919 - val_acc: 0.3655\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9610\n",
      "Epoch 00011: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2040 - acc: 0.9609 - val_loss: 3.1045 - val_acc: 0.3648\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1660 - acc: 0.9704\n",
      "Epoch 00012: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1660 - acc: 0.9704 - val_loss: 3.2424 - val_acc: 0.3580\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9777\n",
      "Epoch 00013: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1342 - acc: 0.9777 - val_loss: 3.4207 - val_acc: 0.3608\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9831\n",
      "Epoch 00014: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1126 - acc: 0.9831 - val_loss: 3.4965 - val_acc: 0.3692\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9863\n",
      "Epoch 00015: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0970 - acc: 0.9863 - val_loss: 3.6642 - val_acc: 0.3552\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9901\n",
      "Epoch 00016: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0794 - acc: 0.9901 - val_loss: 3.8058 - val_acc: 0.3662\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9913\n",
      "Epoch 00017: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0717 - acc: 0.9913 - val_loss: 3.9215 - val_acc: 0.3587\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9919\n",
      "Epoch 00018: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0673 - acc: 0.9919 - val_loss: 4.0192 - val_acc: 0.3485\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9924\n",
      "Epoch 00019: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0633 - acc: 0.9924 - val_loss: 4.0036 - val_acc: 0.3676\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9937\n",
      "Epoch 00020: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0532 - acc: 0.9937 - val_loss: 4.1217 - val_acc: 0.3636\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9949\n",
      "Epoch 00021: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0472 - acc: 0.9949 - val_loss: 4.2238 - val_acc: 0.3594\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9946\n",
      "Epoch 00022: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0508 - acc: 0.9946 - val_loss: 4.2844 - val_acc: 0.3620\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9953\n",
      "Epoch 00023: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0421 - acc: 0.9953 - val_loss: 4.3568 - val_acc: 0.3631\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9951\n",
      "Epoch 00024: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0397 - acc: 0.9951 - val_loss: 4.4896 - val_acc: 0.3550\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9960\n",
      "Epoch 00025: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0368 - acc: 0.9960 - val_loss: 4.5489 - val_acc: 0.3566\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9956\n",
      "Epoch 00026: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0387 - acc: 0.9956 - val_loss: 4.6514 - val_acc: 0.3576\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9941\n",
      "Epoch 00027: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0437 - acc: 0.9941 - val_loss: 4.6112 - val_acc: 0.3538\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9954\n",
      "Epoch 00028: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0367 - acc: 0.9954 - val_loss: 4.5717 - val_acc: 0.3664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9967\n",
      "Epoch 00029: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0339 - acc: 0.9967 - val_loss: 4.6855 - val_acc: 0.3627\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9958\n",
      "Epoch 00030: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0350 - acc: 0.9958 - val_loss: 4.6992 - val_acc: 0.3657\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9970\n",
      "Epoch 00031: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0310 - acc: 0.9970 - val_loss: 4.7316 - val_acc: 0.3604\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9963\n",
      "Epoch 00032: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0310 - acc: 0.9963 - val_loss: 4.8478 - val_acc: 0.3683\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9961\n",
      "Epoch 00033: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0326 - acc: 0.9961 - val_loss: 4.8750 - val_acc: 0.3627\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9975\n",
      "Epoch 00034: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0267 - acc: 0.9975 - val_loss: 4.8643 - val_acc: 0.3634\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9971\n",
      "Epoch 00035: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0257 - acc: 0.9971 - val_loss: 4.9156 - val_acc: 0.3641\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9968\n",
      "Epoch 00036: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0271 - acc: 0.9968 - val_loss: 4.9692 - val_acc: 0.3683\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9969\n",
      "Epoch 00037: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0279 - acc: 0.9969 - val_loss: 5.0658 - val_acc: 0.3645\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9985\n",
      "Epoch 00038: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0219 - acc: 0.9985 - val_loss: 5.0794 - val_acc: 0.3552\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9981\n",
      "Epoch 00039: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0232 - acc: 0.9981 - val_loss: 5.1830 - val_acc: 0.3566\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9966\n",
      "Epoch 00040: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0271 - acc: 0.9966 - val_loss: 5.1424 - val_acc: 0.3611\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9961\n",
      "Epoch 00041: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0295 - acc: 0.9961 - val_loss: 5.1795 - val_acc: 0.3594\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9973\n",
      "Epoch 00042: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0257 - acc: 0.9973 - val_loss: 5.2156 - val_acc: 0.3638\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9970\n",
      "Epoch 00043: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0261 - acc: 0.9970 - val_loss: 5.2150 - val_acc: 0.3634\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9977\n",
      "Epoch 00044: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0239 - acc: 0.9977 - val_loss: 5.1809 - val_acc: 0.3680\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9976\n",
      "Epoch 00045: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0242 - acc: 0.9976 - val_loss: 5.2029 - val_acc: 0.3604\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9985\n",
      "Epoch 00046: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0206 - acc: 0.9985 - val_loss: 5.2594 - val_acc: 0.3636\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9974\n",
      "Epoch 00047: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0246 - acc: 0.9974 - val_loss: 5.2570 - val_acc: 0.3613\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9972\n",
      "Epoch 00048: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0237 - acc: 0.9972 - val_loss: 5.3461 - val_acc: 0.3510\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9978\n",
      "Epoch 00049: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0231 - acc: 0.9978 - val_loss: 5.2409 - val_acc: 0.3599\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9978\n",
      "Epoch 00050: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0211 - acc: 0.9978 - val_loss: 5.3052 - val_acc: 0.3590\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9984\n",
      "Epoch 00051: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0206 - acc: 0.9984 - val_loss: 5.3588 - val_acc: 0.3615\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9974\n",
      "Epoch 00052: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0234 - acc: 0.9974 - val_loss: 5.4649 - val_acc: 0.3594\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 465us/sample - loss: 1.9917 - acc: 0.3877\n",
      "Loss: 1.9917109709043492 Accuracy: 0.38774663\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2231 - acc: 0.3038\n",
      "Epoch 00001: val_loss improved from inf to 1.88607, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_2_conv_checkpoint/001-1.8861.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 2.2230 - acc: 0.3039 - val_loss: 1.8861 - val_acc: 0.4386\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7233 - acc: 0.4796\n",
      "Epoch 00002: val_loss improved from 1.88607 to 1.68747, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_2_conv_checkpoint/002-1.6875.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.7232 - acc: 0.4797 - val_loss: 1.6875 - val_acc: 0.4908\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4425 - acc: 0.5717\n",
      "Epoch 00003: val_loss improved from 1.68747 to 1.64934, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_2_conv_checkpoint/003-1.6493.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.4424 - acc: 0.5717 - val_loss: 1.6493 - val_acc: 0.4901\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1851 - acc: 0.6544\n",
      "Epoch 00004: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.1851 - acc: 0.6544 - val_loss: 1.6799 - val_acc: 0.4976\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9444 - acc: 0.7265\n",
      "Epoch 00005: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.9444 - acc: 0.7265 - val_loss: 1.7603 - val_acc: 0.4878\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7388 - acc: 0.7870\n",
      "Epoch 00006: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.7387 - acc: 0.7870 - val_loss: 1.8669 - val_acc: 0.4850\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5634 - acc: 0.8388\n",
      "Epoch 00007: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.5633 - acc: 0.8387 - val_loss: 2.0537 - val_acc: 0.4803\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4304 - acc: 0.8756\n",
      "Epoch 00008: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.4304 - acc: 0.8756 - val_loss: 2.1998 - val_acc: 0.4754\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3319 - acc: 0.9072\n",
      "Epoch 00009: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3319 - acc: 0.9072 - val_loss: 2.3268 - val_acc: 0.4771\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.9301\n",
      "Epoch 00010: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2609 - acc: 0.9301 - val_loss: 2.5561 - val_acc: 0.4801\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9445\n",
      "Epoch 00011: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2032 - acc: 0.9445 - val_loss: 2.7347 - val_acc: 0.4768\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9543\n",
      "Epoch 00012: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1691 - acc: 0.9543 - val_loss: 2.9239 - val_acc: 0.4624\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9599\n",
      "Epoch 00013: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1507 - acc: 0.9598 - val_loss: 3.0228 - val_acc: 0.4612\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9650\n",
      "Epoch 00014: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1335 - acc: 0.9650 - val_loss: 3.0994 - val_acc: 0.4628\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9690\n",
      "Epoch 00015: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1171 - acc: 0.9690 - val_loss: 3.1822 - val_acc: 0.4766\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9738\n",
      "Epoch 00016: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1056 - acc: 0.9738 - val_loss: 3.3066 - val_acc: 0.4684\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9760\n",
      "Epoch 00017: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0952 - acc: 0.9760 - val_loss: 3.4309 - val_acc: 0.4703\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9767\n",
      "Epoch 00018: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0939 - acc: 0.9767 - val_loss: 3.4582 - val_acc: 0.4631\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9785\n",
      "Epoch 00019: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0850 - acc: 0.9785 - val_loss: 3.4582 - val_acc: 0.4722\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9769\n",
      "Epoch 00020: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0909 - acc: 0.9769 - val_loss: 3.5330 - val_acc: 0.4570\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9814\n",
      "Epoch 00021: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0753 - acc: 0.9814 - val_loss: 3.5833 - val_acc: 0.4724\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9834\n",
      "Epoch 00022: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0690 - acc: 0.9834 - val_loss: 3.6398 - val_acc: 0.4731\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9848\n",
      "Epoch 00023: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0647 - acc: 0.9848 - val_loss: 3.6943 - val_acc: 0.4864\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9826\n",
      "Epoch 00024: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0718 - acc: 0.9826 - val_loss: 3.7163 - val_acc: 0.4715\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9817\n",
      "Epoch 00025: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0724 - acc: 0.9817 - val_loss: 3.6584 - val_acc: 0.4785\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9860\n",
      "Epoch 00026: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0605 - acc: 0.9860 - val_loss: 3.7579 - val_acc: 0.4715\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9871\n",
      "Epoch 00027: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0606 - acc: 0.9871 - val_loss: 3.8602 - val_acc: 0.4582\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9856\n",
      "Epoch 00028: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0607 - acc: 0.9856 - val_loss: 3.8860 - val_acc: 0.4733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9839\n",
      "Epoch 00029: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0650 - acc: 0.9839 - val_loss: 3.8565 - val_acc: 0.4857\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9885\n",
      "Epoch 00030: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0517 - acc: 0.9885 - val_loss: 3.9517 - val_acc: 0.4845\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9870\n",
      "Epoch 00031: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0583 - acc: 0.9870 - val_loss: 3.8449 - val_acc: 0.4819\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9884\n",
      "Epoch 00032: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0525 - acc: 0.9884 - val_loss: 3.8503 - val_acc: 0.4836\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9870\n",
      "Epoch 00033: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0552 - acc: 0.9870 - val_loss: 3.8762 - val_acc: 0.4815\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9893\n",
      "Epoch 00034: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0476 - acc: 0.9893 - val_loss: 3.8535 - val_acc: 0.4850\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9903\n",
      "Epoch 00035: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0478 - acc: 0.9903 - val_loss: 3.8204 - val_acc: 0.4878\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9893\n",
      "Epoch 00036: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0476 - acc: 0.9893 - val_loss: 4.0205 - val_acc: 0.4733\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9883\n",
      "Epoch 00037: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0528 - acc: 0.9883 - val_loss: 3.8648 - val_acc: 0.4801\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9896\n",
      "Epoch 00038: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0504 - acc: 0.9896 - val_loss: 3.9693 - val_acc: 0.4789\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9896\n",
      "Epoch 00039: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0469 - acc: 0.9896 - val_loss: 3.9250 - val_acc: 0.4908\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9897\n",
      "Epoch 00040: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0471 - acc: 0.9897 - val_loss: 4.0918 - val_acc: 0.4694\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9906\n",
      "Epoch 00041: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0448 - acc: 0.9906 - val_loss: 4.0546 - val_acc: 0.4794\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9924\n",
      "Epoch 00042: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0392 - acc: 0.9924 - val_loss: 4.1617 - val_acc: 0.4768\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9907\n",
      "Epoch 00043: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0447 - acc: 0.9907 - val_loss: 4.0562 - val_acc: 0.4894\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9915\n",
      "Epoch 00044: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0439 - acc: 0.9916 - val_loss: 3.9701 - val_acc: 0.4901\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9914\n",
      "Epoch 00045: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0417 - acc: 0.9914 - val_loss: 3.9810 - val_acc: 0.4964\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9922\n",
      "Epoch 00046: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0391 - acc: 0.9922 - val_loss: 4.2705 - val_acc: 0.4752\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9911\n",
      "Epoch 00047: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0416 - acc: 0.9911 - val_loss: 4.1379 - val_acc: 0.4812\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9920\n",
      "Epoch 00048: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0399 - acc: 0.9920 - val_loss: 4.0835 - val_acc: 0.4817\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9907\n",
      "Epoch 00049: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0440 - acc: 0.9907 - val_loss: 4.1667 - val_acc: 0.4745\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9924\n",
      "Epoch 00050: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0389 - acc: 0.9924 - val_loss: 4.1195 - val_acc: 0.4824\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9927\n",
      "Epoch 00051: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0395 - acc: 0.9927 - val_loss: 4.1374 - val_acc: 0.4896\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9920\n",
      "Epoch 00052: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0397 - acc: 0.9920 - val_loss: 4.1176 - val_acc: 0.4852\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9918\n",
      "Epoch 00053: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0406 - acc: 0.9918 - val_loss: 4.1606 - val_acc: 0.4887\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 769us/sample - loss: 1.7163 - acc: 0.4752\n",
      "Loss: 1.7163452906276826 Accuracy: 0.47518173\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2427 - acc: 0.2877\n",
      "Epoch 00001: val_loss improved from inf to 1.86165, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/001-1.8617.hdf5\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 2.2427 - acc: 0.2876 - val_loss: 1.8617 - val_acc: 0.4088\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6555 - acc: 0.4901\n",
      "Epoch 00002: val_loss improved from 1.86165 to 1.58989, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/002-1.5899.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.6555 - acc: 0.4901 - val_loss: 1.5899 - val_acc: 0.5236\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3620 - acc: 0.5856\n",
      "Epoch 00003: val_loss improved from 1.58989 to 1.41779, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/003-1.4178.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.3621 - acc: 0.5856 - val_loss: 1.4178 - val_acc: 0.5560\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1719 - acc: 0.6452\n",
      "Epoch 00004: val_loss improved from 1.41779 to 1.36893, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/004-1.3689.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.1718 - acc: 0.6452 - val_loss: 1.3689 - val_acc: 0.5733\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0111 - acc: 0.6928\n",
      "Epoch 00005: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.0111 - acc: 0.6929 - val_loss: 1.4107 - val_acc: 0.5614\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8679 - acc: 0.7391\n",
      "Epoch 00006: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.8681 - acc: 0.7391 - val_loss: 1.3838 - val_acc: 0.5924\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7480 - acc: 0.7732\n",
      "Epoch 00007: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.7483 - acc: 0.7731 - val_loss: 1.4656 - val_acc: 0.5782\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6420 - acc: 0.8010\n",
      "Epoch 00008: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.6420 - acc: 0.8011 - val_loss: 1.5133 - val_acc: 0.5798\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5498 - acc: 0.8286\n",
      "Epoch 00009: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.5498 - acc: 0.8286 - val_loss: 1.6002 - val_acc: 0.5898\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4692 - acc: 0.8540\n",
      "Epoch 00010: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.4692 - acc: 0.8540 - val_loss: 1.7021 - val_acc: 0.5681\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3995 - acc: 0.8750\n",
      "Epoch 00011: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3995 - acc: 0.8750 - val_loss: 1.7236 - val_acc: 0.5819\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3482 - acc: 0.8903\n",
      "Epoch 00012: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3482 - acc: 0.8903 - val_loss: 1.7801 - val_acc: 0.5956\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3013 - acc: 0.9052\n",
      "Epoch 00013: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3012 - acc: 0.9053 - val_loss: 1.9166 - val_acc: 0.5821\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2642 - acc: 0.9164\n",
      "Epoch 00014: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2642 - acc: 0.9163 - val_loss: 1.9004 - val_acc: 0.6056\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2394 - acc: 0.9255\n",
      "Epoch 00015: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2394 - acc: 0.9255 - val_loss: 2.0522 - val_acc: 0.5949\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2137 - acc: 0.9327\n",
      "Epoch 00016: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2137 - acc: 0.9327 - val_loss: 2.0799 - val_acc: 0.5980\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9409\n",
      "Epoch 00017: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1961 - acc: 0.9409 - val_loss: 2.1171 - val_acc: 0.6042\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1802 - acc: 0.9453\n",
      "Epoch 00018: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1803 - acc: 0.9453 - val_loss: 2.1780 - val_acc: 0.6012\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1718 - acc: 0.9486\n",
      "Epoch 00019: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1718 - acc: 0.9486 - val_loss: 2.1357 - val_acc: 0.6091\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9515\n",
      "Epoch 00020: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1603 - acc: 0.9516 - val_loss: 2.1922 - val_acc: 0.6129\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9571\n",
      "Epoch 00021: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1449 - acc: 0.9571 - val_loss: 2.2131 - val_acc: 0.6031\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9590\n",
      "Epoch 00022: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1447 - acc: 0.9590 - val_loss: 2.2093 - val_acc: 0.6143\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9599\n",
      "Epoch 00023: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1325 - acc: 0.9598 - val_loss: 2.2505 - val_acc: 0.6143\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9639\n",
      "Epoch 00024: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1233 - acc: 0.9639 - val_loss: 2.3105 - val_acc: 0.6063\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9632\n",
      "Epoch 00025: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1243 - acc: 0.9632 - val_loss: 2.2257 - val_acc: 0.6122\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9671\n",
      "Epoch 00026: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1129 - acc: 0.9671 - val_loss: 2.3252 - val_acc: 0.6133\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9695\n",
      "Epoch 00027: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1074 - acc: 0.9695 - val_loss: 2.4009 - val_acc: 0.6017\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9699\n",
      "Epoch 00028: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1064 - acc: 0.9699 - val_loss: 2.3222 - val_acc: 0.6245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9709\n",
      "Epoch 00029: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1023 - acc: 0.9709 - val_loss: 2.3492 - val_acc: 0.6189\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9735\n",
      "Epoch 00030: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0929 - acc: 0.9734 - val_loss: 2.4099 - val_acc: 0.6205\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9722\n",
      "Epoch 00031: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0977 - acc: 0.9722 - val_loss: 2.3612 - val_acc: 0.6236\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9758\n",
      "Epoch 00032: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0906 - acc: 0.9758 - val_loss: 2.3412 - val_acc: 0.6212\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9758\n",
      "Epoch 00033: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0853 - acc: 0.9758 - val_loss: 2.3562 - val_acc: 0.6257\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9756\n",
      "Epoch 00034: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0888 - acc: 0.9756 - val_loss: 2.3754 - val_acc: 0.6236\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9770\n",
      "Epoch 00035: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0824 - acc: 0.9770 - val_loss: 2.3804 - val_acc: 0.6273\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9759\n",
      "Epoch 00036: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0868 - acc: 0.9759 - val_loss: 2.4734 - val_acc: 0.6203\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9795\n",
      "Epoch 00037: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0767 - acc: 0.9795 - val_loss: 2.4426 - val_acc: 0.6203\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9794\n",
      "Epoch 00038: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0758 - acc: 0.9794 - val_loss: 2.4322 - val_acc: 0.6182\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9795\n",
      "Epoch 00039: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0751 - acc: 0.9795 - val_loss: 2.4554 - val_acc: 0.6268\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9793\n",
      "Epoch 00040: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0772 - acc: 0.9794 - val_loss: 2.4758 - val_acc: 0.6322\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9819\n",
      "Epoch 00041: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0713 - acc: 0.9819 - val_loss: 2.4982 - val_acc: 0.6194\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9815\n",
      "Epoch 00042: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0710 - acc: 0.9815 - val_loss: 2.5451 - val_acc: 0.6159\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9817\n",
      "Epoch 00043: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0727 - acc: 0.9817 - val_loss: 2.4605 - val_acc: 0.6231\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9811\n",
      "Epoch 00044: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0724 - acc: 0.9811 - val_loss: 2.4102 - val_acc: 0.6355\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9841\n",
      "Epoch 00045: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0636 - acc: 0.9841 - val_loss: 2.4372 - val_acc: 0.6308\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9835\n",
      "Epoch 00046: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0660 - acc: 0.9835 - val_loss: 2.4093 - val_acc: 0.6275\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9844\n",
      "Epoch 00047: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0617 - acc: 0.9844 - val_loss: 2.4658 - val_acc: 0.6394\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9847\n",
      "Epoch 00048: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0612 - acc: 0.9847 - val_loss: 2.5588 - val_acc: 0.6310\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9838\n",
      "Epoch 00049: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0651 - acc: 0.9838 - val_loss: 2.5034 - val_acc: 0.6282\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9848\n",
      "Epoch 00050: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0608 - acc: 0.9848 - val_loss: 2.6234 - val_acc: 0.6203\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9865\n",
      "Epoch 00051: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0549 - acc: 0.9865 - val_loss: 2.4700 - val_acc: 0.6273\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9847\n",
      "Epoch 00052: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0620 - acc: 0.9847 - val_loss: 2.5316 - val_acc: 0.6296\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9855\n",
      "Epoch 00053: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0593 - acc: 0.9855 - val_loss: 2.4410 - val_acc: 0.6362\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9845\n",
      "Epoch 00054: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0626 - acc: 0.9845 - val_loss: 2.4072 - val_acc: 0.6396\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8VNXZwPHfmSUz2feQEAIEQXYS1sKLuFbEDXEBtO5arVVbrcsrtdXaWlv317q0Fpcq7hbFpaAoVURxY5EdZIcEAlnInkwyy3n/OJOQQBICyWSSzPP9fO5nZu7cufe5Q7jP3LMqrTVCCCEEgCXYAQghhOg8JCkIIYSoJ0lBCCFEPUkKQggh6klSEEIIUU+SghBCiHqSFIQQQtSTpCCEEKKeJAUhhBD1bMEO4GglJSXpvn37BjsMIYToUlasWFGotU4+0nZdLin07duX5cuXBzsMIYToUpRSu1qznRQfCSGEqCdJQQghRD1JCkIIIep1uTqFprjdbnJzc3G5XMEOpctyOp306tULu90e7FCEEEHULZJCbm4u0dHR9O3bF6VUsMPpcrTWFBUVkZubS2ZmZrDDEUIEUbcoPnK5XCQmJkpCOEZKKRITE+VOSwjRPZICIAmhjeT7E0JAN0oKQggRdP/5D+xqVXeATkuSQjsoKSnh73//+zF99qyzzqKkpKTV29933308+uijx3QsIUQAffklnHsu/OxnoHWwozlmkhTaQUtJwePxtPjZBQsWEBcXF4iwhBAdpbYWfvELsNvh669h8eJgR3TMJCm0g1mzZrFt2zays7O58847Wbx4MZMmTWLq1KkMGTIEgGnTpjF69GiGDh3K7Nmz6z/bt29fCgsL2blzJ4MHD+a6665j6NChTJ48merq6haPu2rVKsaPH8+IESM4//zzKS4uBuDJJ59kyJAhjBgxgosvvhiAL774guzsbLKzsxk5ciTl5eUB+jaECEGPPgobN8Ibb0BaGtx/f7AjOmbdoklqQ1u23EpFxap23WdUVDYDBjzR7PsPPvgg69atY9Uqc9zFixezcuVK1q1bV9/E88UXXyQhIYHq6mrGjh3LhRdeSGJi4iGxb+GNN97gueeeY8aMGbzzzjtcdtllzR73iiuu4KmnnuKkk07i3nvv5Y9//CNPPPEEDz74IDt27MDhcNQXTT366KM888wzTJw4kYqKCpxOZ1u/FiEEwLZtJglcdBFceCHs3g233QZLl8LEicGO7qjJnUKAjBs3rlGb/yeffJKsrCzGjx9PTk4OW7ZsOewzmZmZZGdnAzB69Gh27tzZ7P5LS0spKSnhpJNOAuDKK69kyZIlAIwYMYJLL72UV199FZvN5P2JEydy22238eSTT1JSUlK/XgjRgpwceOopaO6uXWu46SZTbPS3v5l1118PSUnw5z93XJztqNtdGVr6Rd+RIiMj658vXryYRYsW8c033xAREcHJJ5/cZJ8Ah8NR/9xqtR6x+Kg58+fPZ8mSJXz44Yc88MADrF27llmzZnH22WezYMECJk6cyMKFCxk0aNAx7V+IgNIa3n0XBg6EYcOCF0dFBZx1FqxbB88/D2+/bWJq6O23YeFCePJJ6NnTrIuMhNtvh9/+FpYvhzFjOj72NgjYnYJSKkMp9blSaoNSar1S6pYmtjlZKVWqlFrlX+4NVDyBFB0d3WIZfWlpKfHx8URERLBp0ya+/fbbNh8zNjaW+Ph4vvzySwBeeeUVTjrpJHw+Hzk5OZxyyik89NBDlJaWUlFRwbZt2xg+fDh33XUXY8eOZdOmTW2OQYh2t2kTnHyyKYo5+WTYvDk4cWgNV18NGzbAH/8Ie/bA6NHwyisHtykpgVtvNRf9G29s/Pkbb4T4+JbvFvLy4MMPO11LpUAWH3mA27XWQ4DxwE1KqSFNbPel1jrbv/wpgPEETGJiIhMnTmTYsGHceeedh70/ZcoUPB4PgwcPZtasWYwfP75djvvyyy9z5513MmLECFatWsW9996L1+vlsssuY/jw4YwcOZJf//rXxMXF8cQTTzBs2DBGjBiB3W7nzDPPbJcYhGgXNTVw332QlQVr1sDDD4PFAlOmwP79HR/PQw/B3Lnm8d57YdUqGDUKrrjCJIvKSrj7bsjPh3/+E6zWxp+PiYFbboH33zfnc6jvvzdJZupUOMbm7AGjte6QBXgfOP2QdScD/zma/YwePVofasOGDYetE0dPvkcRFIsXaz1woNag9SWXaL1vn1n/3Xdah4drPWaM1hUVHRfPggVaK2Vi8fkOrne7tb7nHvPecceZx1tuaX4/RUVaR0drPWNG4/Wvvqq1w6F1ZqbWp52mtdWq9aJFgTmXBoDlujXX6tZs1NYF6AvsBmIOWX8yUASsBj4Chh5pX5IUAke+R9Fhdu3S+plntD7jDHMZyszU+qOPDt/ugw+0tli0Pvtsc1EOtC1btI6L0zorS+vKyqa3WbRI6x49tO7VS+uyspb3N2uWSR4bNmjt9ZrXoPVJJ2ldUGA+P3So1vHx5tgB1GmSAhAFrAAuaOK9GCDK//wsYEsz+7geWA4s792792EnKxez9iHfowgYj0frb77R+ne/03rECHPpAa3799f63nubvwBrrfWzz5ptr7++8S/39lZ3gU5I0Hr79pa3LS01F/Ujyc83dzsXXqj1ueea8/jFL7SuqTm4zbZtWicmaj14sNYlJW07hxZ0iqQA2IGFwG2t3H4nkNTSNnKnEDjyPYa4efPMr9+bbtJ63bq272/3bq2ff94UnyQkmMuN1Wp+JT/yiNabNrV+X7/9rfn8Aw+0Pa6meDxaX3CBuStp76Kc3/zm4Lk//XTTie3zz7W22bQ+80wTSwAEPSkACpgDPNHCNqmA8j8f5y9iUi3tV5JC4Mj3GMLWrtU6MlLrjAytw8J0fRHHW281/lXbktparf/7X1POPmjQwbuBnj21vuoqrV9/3ZSzHwufT+vLLjP7mzVLa5fr2PbTlH37tD71VLPvxx5rv/023P/552v96actb/ePf5gY7rij/WPQrU8KgeynMBG4HFirlKrrYnw30BtAa/0scBHwS6WUB6gGLvYHL4ToKMXFMG0aREfDt9+ajlj/+hc8+yzMnAmpqTBjBgwaBP37w3HHQe/eYLOZtvwLF8J778H8+WZfDodpTnrddTB5MgwdCm0dml0peOEFs+8HHzSjkb78smkR1JyKCnC7TdPQ5ixeDJdcYpqXvviiaVnU3nr0MP0ujuSGG2DtWjNkRq9eplNcMDqZtiZzdKZF7hQCR77HEOTxmMpeu13rr78+/L35800lr9N58Jc/mKKO444zrWjAFA9dcYXW774b+JZC8+ebuw+r1dRHNLyTcbtN66FLLjFl+Var1ueco/XcuY3vLrxeUxRlsZiWT2vWBDbm1qqt1fr003V95fvf/qZ1eXm77JpgFx8FaukuSSEyMvKo1neErvg9dgtut7lIBUNda5jZs1vezuvVOjfXNB994QVTxj9jhta33mrKwzuiZVBDBw5offnlJvbsbK3fe88UW6WkmHXx8VrfcIPW//u/JoHUJa6bbjLxTpli1l188ZFbEHU0j8ck1//5HxNjXJz5vvfubdNuJSl0cpIUuokvvjAXqGO1fr3WAwaYMvilS9svrtZ4+21d3xqmq3rvvYOJICzMVBbPm9f4rsDj0frjj00CqLuzCQszZfiBbM3UHr7+2rRcUsrE/OCDx7wrSQod6K677tJPP/10/es//OEP+pFHHtHl5eX61FNP1SNHjtTDhg3T7733Xv02R0oKPp9P33HHHXro0KF62LBh+s0339Raa7137149adIknZWVpYcOHaqXLFmiPR6PvvLKK+u3ffzxx4/pPIL9PXY5jzxi/gsNH35sFajvv691VJRp856RcbAzVEd01Fq9WuuICPNrtLUVyZ1VYaFJDq1JzsXFpvPY2rWBj6s9bdli7nLef/+Yd9HapFDX8qfLGDNmjF6+fHmjdRs3bmTw4MHmxa23mi7p7Sk7G55ofqC9H374gVtvvZUvvvgCgCFDhrBw4ULS0tKoqqoiJiaGwsJCxo8fz5YtW1BKERUVRUVFxWH7qlv/zjvv8Oyzz/Lxxx9TWFjI2LFj+e6773j99ddxuVz87ne/w+v1UlVVxebNm5k1axaffvopYCb9OZaJexp9j6Jl//d/ZnjkU04xQyRnZ8OiRaay9ki0hgcegHvuMePmzJsHsbEwa5YZ8iAzE557Dk47rW0x5ufDF1/A9u2mArjhsnq1qVBevtyM/y+6PaXUCq31EUfn63ajpAbDyJEjyc/PZ+/evRQUFBAfH09GRgZut5u7776bJUuWYLFY2LNnD/v37yc1NfWI+/zqq6+45JJLsFqt9OjRg5NOOolly5YxduxYrrnmGtxuN9OmTSM7O5t+/fqxfft2fvWrX3H22WczefLkDjjrEPbUUyYhXHSRmVRl/nwzjv7UqbBgAYSHN//ZykrTwuXf/4bLLoPZsw9u/8wzprXPtdfCT38KP/853HWXae3TmtY7JSWwZAl89plZ1q49+J7dblrhxMWZx/HjzVhDkhDEIbpfUmjhF30gTZ8+nblz57Jv3z5mzpwJwGuvvUZBQQErVqzAbrfTt2/fJofMPhonnngiS5YsYf78+Vx11VXcdtttXHHFFaxevZqFCxfy7LPP8vbbb/Piiy+2x2mJQ/397/DrX8P558Prr5smg+edB3PmmIv8RReZX/5hYY0/pzWsWGEu+OvWmWaHt912+MX+xBPNAGp/+AM89pgZsrlvX5MkTj8dTj3VjNVfXW1+7S9fbva7YgWsXw8+n0kyJ5xgmlqeeqoZfjoiou3NQkVoaE0ZU2daOmOdgtZar1u3Tk+YMEEPGDBA7/W3EnjiiSf0zTffrLXW+rPPPtOA3rFjh9b6yHUK77zzjp48ebL2eDw6Pz9f9+7dW+fl5emdO3dqj7/H41NPPaVvueUWXVBQoEtLS7XWWq9du1ZnZWUd0zl0hu+xU6sbbmHq1KbL4f/5T/P+9OkHW+Ps2qX1X/5ihjCoa0ny8cetO962bWZ8oGnTtI6JMZ9XyjRVtFp1ffPQ5GTTmubee03roPbs2CW6DTpB57WQMnToUMrLy0lPTyfNf0t+6aWXcu655zJ8+HDGjBlzVJPanH/++XzzzTdkZWWhlOLhhx8mNTWVl19+mUceeQS73U5UVBRz5sxhz549XH311fh8PgD++te/BuQcQ9q//mU6F519tplY5dA7ATAzbpWXwx13gMsFZWWmTB/ML/dnnzWdwFrqTNVQv35mXP4bbwSPx9wVLFpk7hB+9jMz9PKYMaajk9wFiHbS/SqaxTELqe+xutrUBZx7rukl25Jly8xcuyefbCZFOdL2991nJmYZMAAuvxwuvdRc4IUIIqloFqI5u3ebOoGVK025+6uvmgldmlJSYn7dp6XBm28eOSGASQo//zmkp8sveNHlBHLmNSE6ny++MEUuW7fClVea1kN33930tlrDNddAbi689RYkJLT+OFKkI7oouVMQoUFr0+TzN78xg7q99x4cf7xplfPQQ9CnD/zyl40/89RTpiXRY4+ZJpxChABJCqL7c7lMZe2//mX6ErzyiplDF+DJJyEnB26+2RT3TJ1q1i9bZiqMzz3XJBIhQkTIFB9p7cHjqUBrX7BDER3pm29My59//cu0/Z8372BCANPP4M03TUueiy82E6o3rEd46SUpBhIhJWSSgsdTSnX1Jny+mmCHIjrC1q2mI9n//A/s2WOKi+67r+kK5chI06ooNRXOOcckhGOpRxCiGwiZpKCUaTWidfsnhZKSEv7+978f02fPOussSkpK2jmiEFZYCLfcAoMHw8cfm0SwZYvpddySHj3go4/A64VPPzX1DFKPIEJQyNQpWCwmKfh8te2+77qkcOONNx72nsfjwdbC7EkLFixo93i6Ja3NWD4ff2yW9etNJXF09MElMtJ07qqoME1Cj3Zsn4EDzecXLzYDKwoRgkLoTsEGqIAUH82aNYtt27aRnZ3NnXfeyeLFi5k0aRJTp05lyJAhAEybNo3Ro0czdOhQZs+eXf/Zvn37UlhYyM6dOxk8eDDXXXcdQ4cOZfLkyVRXVx92rA8//JCf/OQnjBw5kp/+9Kfs378fgIqKCq6++mqGDx/OiBEjeOeddwD4+OOPGTVqFFlZWZzW1lE3O5rPB3PnmgHk0tMhK8sMEFdUZCqATzjBDBYXHm5G/ty40YwsumYN/POfxzbY28iRpmJZ6hFEiOp2dwrNj5yt8HoHoZSl2X5KzTnCyNk8+OCDrFu3jlX+Ay9evJiVK1eybt06MjMzAXjxxRdJSEigurqasWPHcuGFF5KYmNhoP1u2bOGNN97gueeeY8aMGbzzzjtcdtlljbY54YQT+Pbbb1FK8fzzz/Pwww/z2GOPcf/99xMbG8ta/8iYxcXFFBQUcN1117FkyRIyMzM5cODA0Z14IBQXQ22tKa5pSUGBGWDuk0/MsBCTJ8OUKeaxZ8+OiVWIENTtkkJLlFId1vpo3Lhx9QkB4Mknn2TevHkA5OTksGXLlsOSQmZmJtnZ2QCMHj2anTt3Hrbf3NxcZs6cSV5eHrW1tfXHWLRoEW+++Wb9dvHx8Xz44YeceOKJ9dskBLvS9NtvTU/ikhK4/XYzf0BU1OHbffmlaQlUVGR+8V97LVitHR+vECGo2yWFln7Ru1wFuN0HiI4eGfA4IiMj658vXryYRYsW8c033xAREcHJJ5/c5BDajgZDKFit1iaLj371q19x2223MXXqVBYvXsx9990XkPjb3csvmwHj0tPhpJPMJDMvvGAer7zSXPR9PnjkEfjd78xEM/Pnm9s0IUSHCZk6BahrgeRFa0+77jc6Opry8vJm3y8tLSU+Pp6IiAg2bdrEt99+e8zHKi0tJT09HYCXX365fv3pp5/OM888U/+6uLiY8ePHs2TJEnbs2AEQnOIjj8fMG3DVVaYOYNky0y/gm2/MPAHXXmuGnfjPf0zHsVmz4IILzPwAkhCE6HAhlRQsFjPccXu3QEpMTGTixIkMGzaMO++887D3p0yZgsfjYfDgwcyaNYvxbWjqeN999zF9+nRGjx5NUlJS/frf//73FBcXM2zYMLKysvj8889JTk5m9uzZXHDBBWRlZdVP/tNhiovhrLPM1JW/+pVpNVRXZDZ+PHz9tZmopq7i+JNPzNASb73VuIOZEKLDhNTQ2V5vJVVVG3E6+2O3H/0cxt1duw6d/fXXplho1y74xz/MHUFzqqtNj+Px42HUqPY5vhCiERk6uwlKmTuFQHRgE35Ll5r+AYsWmR7Cn39u5iJoSXi4GZtICBF0IVV8ZPoqWGSoi0D46iszj/AJJ5h+Ao8+aoaaOFJCEEJ0KiF2p6CwWBwB6dUcklwu+OAD02z0s88gJcUkgxtuML2LhRBdTkglBTBFSFJ81AZam/4GL79sKoRLSkwz08ceM8kgIiLYEQoh2iDkkoLF4sDtLkdrjZKhDI7O88+bfgSbN5t6gAsuMJXJp54qncuE6CZCMimAD629/joG0Srr1sF118HYsfDii3DhhdJsVIhuKGAVzUqpDKXU50qpDUqp9UqpW5rYRimlnlRKbVVKrVFKBbw9YmdpgRTV1PAOndmf/2xGIv34YzNAnSQEIbqlQLY+8gC3a62HAOOBm5RSQw7Z5kxggH+5HvhHAOMBGg6hLfUKrbZxI7z9tumAFuzxk4QQARWwpKC1ztNar/Q/Lwc2AumHbHYeMEcb3wJxSqljGO+49eruFNqzBdKsWbMaDTFx33338eijj1JRUcFpp53GqFGjGD58OO+///4R99XcENtNDYHd3HDZ7e6BB0wFssxVLES31yGF6kqpvsBI4LtD3koHchq8zvWvyzvk89dj7iTo3bt3i8e69eNbWbWvybGz63m9FShlw2JxHjl4IDs1myemND/S3syZM7n11lu56aabAHj77bdZuHAhTqeTefPmERMTQ2FhIePHj2fq1KktVnA3NcS2z+drcgjspobLbndbtsAbb5hRTRsMqyGE6J4CnhSUUlHAO8CtWuuyY9mH1no2MBvMMBdtj8oCtN/wHiNHjiQ/P5+9e/dSUFBAfHw8GRkZuN1u7r77bpYsWYLFYmHPnj3s37+f1NTUZvfV1BDbBQUFTQ6B3dRw2e3uL38Bh8MkBSFEtxfQpKCUsmMSwmta63eb2GQPkNHgdS//umPW0i/6OtXVW/H5XERGDmvLoRqZPn06c+fOZd++ffUDz7322msUFBSwYsUK7HY7ffv2bXLI7DqtHWK7w2zfDq+8Ar/+9ZEnxRFCdAuBbH2kgBeAjVrrx5vZ7APgCn8rpPFAqdY6r5lt2zE206u5PQcDnDlzJm+++SZz585l+vTpgBnmOiUlBbvdzueff86uXbta3EdzQ2w3NwR2U8Nlt6u//hVsNmhi5FchRPcUyNZHE4HLgVOVUqv8y1lKqRuUUjf4t1kAbAe2As8BHTIqmhlC29eu8yoMHTqU8vJy0tPTSfPPDXzppZeyfPlyhg8fzpw5cxg0aFCL+2huiO3mhsBuarjsdrNrF7z0kpkY51jmOhZCdEkhNXR2Hbe7BJdrKxERg7Bau1h/gfaktZntzN8budH3+Mtfmk5q27ZBr15BDFII0R5k6OwWHOyrUBvaozPk50NODoSFmQHsysrMjGjJyWaqzGuvlYQgRIgJ0aRQ11chhDuweTywd6/pf+BwQGWlmSntzDPN+zabmRpTCBFSuk1SOJoB7pSyopQNrUN4CO28PPB6zTzJERGm0t1igXnzzCioxx8PffoEO0ohRAfrFknB6XRSVFREYmJiy4lBa/C/b1ogheidQk2NKTpKTKxPCEVFRTgjI2HaNLMIIUJSt0gKvXr1Ijc3l4KCguY3qqoyE8T37AlWK253AT5fLQ6Ht+MC7SwKC833ERZmxjXCJNZeUn8gRMjrFknBbrfX9/Zt1g8/wBlnmMlhrriCbdteIjf3CU48sRqlQmhW0h9+gJNOgrvuMv0QhBCigdC5GmZlmekiP/kEAKczE61rqa0NeF+5zuWuu8xIp1KJLIRoQugkBYsFTj8dPv0UfD6czr4AVFfvCG5cHemTT8z533MPxMYGOxohRCcUOkkBYPJkU8G6ejXh4aa4yeXaGdyYOorXC//7v9Cvn+mYJoQQTQitpHD66ebxk09wOExzS5crRO4UXnsNVq82o56GhQU7GiFEJxVaSSEtDUaMgE8+wWp1EhaWFhp3CgUF8Pvfw5gx4B+sTwghmhJaSQFMEdJXX0FlJU5nZve/U/jqKxg50hSbPfGEqVsRQohmhN4VYvJkqK2FL77A6ezbfe8UfD54+GE4+WQIDze9lCdODHZUQohOLvSSwqRJ4HTCJ5/47xR24/O13xDanUJREUydapqfXnABrFgB2dnBjkoI0QWEXlJwOk3nrYUL/c1SvdTWtmmyt85Da1i8GEaNMs1Pn3oK3noLYmKCHZkQoosIvaQApghp0yYiiiKALt5XobQU3nnHDHOdng6nnGLqDZYuhZtvrh/rSQghWiM0k8IZZwAQ8ZWZHrNLVjYvWmQSQFISXHSRSQyTJpnZ0lavhrFjgx2hEKIL6hZjHx21IUOgZ0/sn62AwZauV9m8dSucf75JCHfcAWedBRMmmDkQhBCiDULzKqIUTJ6Mev99HLf07Fp3CrW1cPHFYLfDkiWQkRHsiIQQ3UhoFh+BKUIqLiZhR1LXulP47W9Na6IXX5SEIIRod6GbFH76U1CKhGVQXb012NG0zoIF8PjjcNNNMhGOECIgQjcpJCXBqFHEfFtGbW1e52+BtHcvXHmlGabj0UeDHY0QopsK3aQAMHkyYSt3Ya2EkpLPgx1N87xeuOwyM1vaW2+ZvhZCCBEAoZ0UzjgD5fWStCa2cyeFBx+Ezz83ndEGDQp2NEKIbiy0k8KECRAZSY/VSRQXf47WOtgRHW7JEvjDH+CSS+Dqq4MdjRCimwvtpBAWBqecQszSYmpdezpfhfOWLaY/Qv/+8Oyz0jtZCBFwoZ0UAH72M2y5B0j4vpPVKxQVmU5pFgvMny/jFwkhOoQkhQsvRKelkTEvrPMkhZoa0+Q0Jwfeew+OOy7YEQkhQoQkhbAw1I03Ev99La4fPg1+vYLWZnC7r74y4xjJHAhCiA4UsKSglHpRKZWvlFrXzPsnK6VKlVKr/Mu9gYrliH7xC7TDRo+3i6iq2hi0MAD44x/NfMp//rMZzkIIITpQIO8UXgKmHGGbL7XW2f7lTwGMpWXJyXhnTCP1EyjdOT9oYfDKKyYpXHUV3H138OIQQoSsgCUFrfUS4ECg9t/erLf9DqsLLC/O6fiD19TAfffBNdeY4bD/+U9paSSECIpg1ylMUEqtVkp9pJQaGsxAVHY2lWN7EPfaBrS7tuMOvHQpjBxp7hCmT4d33zVNZYUQIgiCmRRWAn201lnAU8B7zW2olLpeKbVcKbW8oKAgYAHV3jAD534frrefDtgx6pWVwY03wgknQGWlGezu9dchLi7wxxZCiGYELSlorcu01hX+5wsAu1IqqZltZ2utx2itxyQnJwcspvCZv6E6FSxPPhOwYwDw0Udmop9nn4Vbb4X16+HMMwN7TCGEaIWgJQWlVKpSpuBcKTXOH0tRsOIBcEZmkj89Acf32+GHHwJzkA8/hHPPhYQE+PZb+L//g6iowBxLCCGOUiCbpL4BfAMMVErlKqWuVUrdoJS6wb/JRcA6pdRq4EngYh30TgJQc9lZeMNB/+2J9t/5V1/BjBmmDmHpUhg3rv2PIYQQbaA6wXX4qIwZM0YvX748YPvfv/81PL+4jJ4f2VG7c6BHj/bZ8dq1cOKJkJJikkMAi8GEEOJQSqkVWusxR9quVXcKSqlblFIxynhBKbVSKTW57WF2PnFxp5B7AahaN9x7L7jdR/6Q1rB/f/Pv79xppv+MiIBPPpGEIITotFpbfHSN1roMmAzEA5cDDwYsqiByOHrCwIEUzuwDs2fDT34Cq1Y1/4GlS2H8eEhNNbOiPfywGbOoTn4+TJ4M1dWwcCH06RP4kxBCiGPU2qRQ15PqLOAVrfX6Buu6nfj4U9h40wF8c/9tpsEcOxbuucd0MquzbZtSeEnoAAAgAElEQVTpV3DCCZCbC7//vakwvusuc+E/9VR4/nkz0mlODvznPzBsWPBOSgghWqG1SWGFUuoTTFJYqJSKBnyBCyu44uJOwestp+L0DNiwAS691IxFNGoUfPop3H47DB5s+hb88Y+weTPcfz98/TVs3Wp6J+fmwnXXmbuMf/9bBrYTQnQJrapoVkpZgGxgu9a6RCmVAPTSWq8JdICHCnRFM0BtbT5ff92DzMy/0qfPLLPyo4/g+uvNxV4pMyTF/fdDWlrTO9Eali0z8ytPmBDQeIUQ4khaW9Fsa+X+JgCrtNaVSqnLgFHA39oSYGcWFpZCZGQWhYXvHUwKZ55pOpnNng2nnw5ZWS3vRClpciqE6HJaW3z0D6BKKZUF3A5sA4IwclzHSU29ivLy76ioaDDyd0wM3HHHkROCEEJ0Ua1NCh5/x7LzgKe11s8A0YELK/h69LgMpcLIy3s+2KEIIUSHaW1SKFdK/RbTFHW+v47BHriwgi8sLImkpPPZv/8VvF5XsMMRQogO0dqkMBOowfRX2Af0Ah4JWFSdRM+e1+HxHKCwcF6wQxFCiA7RqqTgTwSvAbFKqXMAl9a6W9cpgGma6nRmShGSECJktHaYixnA98B0YAbwnVLqokAG1hkoZSEt7eeUlHxGdfW2YIcjhBAB19rio98BY7XWV2qtrwDGAfcELqzOIzX1KsBCXt4LwQ5FCCECrrVJwaK1zm/wuugoPtulORw9SUw8m337/oXP14rB8YQQogtr7YX9Y6XUQqXUVUqpq4D5wILAhdW5pKVdR23tPg4cCJlTFkKEqNZWNN8JzAZG+JfZWuu7AhlYZ5KQcCZhYWns3ftcsEMRQoiAau0wF2it3wHeCWAsnZbFYiM19Wp2734QlysXp7NXsEMSQoiAaPFOQSlVrpQqa2IpV0qVdVSQnUFa2rWAj337Xgp2KEIIETAtJgWtdbTWOqaJJVprHdNRQXYG4eH9iIs7jX37XkDrbjtquBAixIVEC6L20rPndbhcOyku/jTYoQghREBIUjgKSUnTCAtLJSfn8WCHIoQQASFJ4ShYLA7S02+huPgTyst/CHY4QgjR7iQpHKWePW/Aao0mJ+fhYIcihBDtTpLCUbLb4+jZ8wby89+munp7sMMRQoh2JUnhGPTqdQtKWcnJeSzYoQghRLuSpHAMHI50evS4nH37XqS2tiDY4QghRLuRpHCMMjLuxOerYc+ep4IdihBCtBtJCscoMnIQSUnnsWfP03g8FcEORwgh2oUkhTbIyLgLj6dYZmYTQnQbkhTaIDZ2PLGxk8jNfVzmWhBCdAsBSwpKqReVUvlKqXXNvK+UUk8qpbYqpdYopUYFKpZA6t37LmpqcsjPfyPYoQghRJsF8k7hJWBKC++fCQzwL9cD/whgLAGTkHAWkZHD2L37YRkoTwjR5QUsKWitlwAHWtjkPGCONr4F4pRSaYGKJ1CUUmRk3EVV1XoKC+cFOxwhhGiTVk+yEwDpQE6D17n+dXmHbqiUuh5zN0Hv3r07JLijkZJyMbt3P8COHfeQlDQNpazBDkmITsntBpcLqqvN4nKZdUqBxWIe654DaG2Wuudw8P2Gi9ZQVWWWysqDj243WK2Nt7VawecDrxc8HvNYt9Qdr+Fx4eDnGi7Q9D7cbqitNUvdc7cbbDYICzu4OBxmXd3n6mLy+QscGh7LZjOPI0bAmDGB/TcKZlJoNa31bMx0oIwZM0YfYfMOZ7HY6Nv3fjZsmM7+/a+RmnpFsEMS7czjMRcal+vgRa3ued1/ZK0bPx56wfB4zFJ3QazbR3W1+YzNdvhSXQ0VFY2XysrGF6xD1V1Y65a6Y7vdZqmLQ6mDF5u6R6XM/svLDx6vvBxqag7ff0PNxVO3nVLmO/GFaAmrzWa+87a6667unRT2ABkNXvfyr+uSkpMvICpqFDt33kdKysVYLGHBDqlb8fmgtBSKisxSWmouVLW1Bx/rfpE1/NVWt1RWQllZ46Wi4uCvzrpfk1ar2b683CxlZeaxujpw51YXg9fb9PtWK0RFQXS0eYyIOPhL+lCH/tLV2nzebjcXJrsdnE6zTuvGycrlMuuioiAlpfExHQ4T56G/3Bsmh+YSRcNf+E6nWcLDDy42W+N465JHw4TS8HnDbRommogIiIw0j3XP7fbG29X9PVgsBxNhXVKsu5NoeMyGx2v491SX/A/dR9133fCOoC7Z1n3fDf9ePZ7GdyF1z+u2bbh4PObfI9CCmRQ+AG5WSr0J/AQo1VofVnTUVShlITPzz6xdexZ5eS+Qnv7LYIcUdNXVUFJiLuClpeYCW1p68FdoZaVZ6p43vPWvWyoq4MABs7TlV6bVCjExjZe4uIO/pOsuGnX/SdPTzTbR0QcfIyLMRazuwla3NCyeaFgM0vCCUXfRsNkaXxCdTnPhaHjRqPtV7/GYbeouyKJrq/ubsNlMwuqsApYUlFJvACcDSUqpXOAPgB1Aa/0ssAA4C9gKVAFXByqWjpKQMIXY2BPYtet+UlOvxGqNCHZIAeHxQH4+5OUdXPbsgdxcyMkxj7m5JgkciVLmP0jDpe6XXlqaeZ2QAImJB5ekJIiNPXhBdTgal9EeWvZrsRy88HZmDS8aTmewoxGhKmBJQWt9yRHe18BNgTp+MCilyMz8C6tWnciePX+nd+87gh3SMSkrg+3bYedO2LXr4OOuXebiX1Bw+K92pSA1FXr1goED4bTTzEU9Ls5cwBsuMTEHE4DT2fkv1kKEki5R0dyVxMVNIj7+DHbv/is9e16PzRYT7JCapLW52K9eDZs3N17272+8bUQE9OljllGjzMW+qcVuD8qpCCHakSSFAOjX7wFWrBhDTs7jZGbeF+xw0Nr8yl+xApYvN48rVphy+jopKXD88XDOOebxuOOgb1+TCBIT5de8EKFCkkIAREePJinpQnJzHyc9/WbCwpI69Ph795qL/7Jl5nH5cigsNO/ZbDBsGFxwAYweDSNHmuKeuLgODVEI0UlJUgiQzMw/UVj4Lrt3P0j//o8G9FilpfDf/8LHH8PChbB7t1lvscDQoTB1qmnbPGYMDB8ulZhCiOZJUgiQyMgh9OhxBXv2PEXPntcRETGw3fatNaxbBx9+aBLB11+bpozR0fDTn8JvfgNjx5q7gIju2QBKCBEgkhQCqF+/ByksfI/Nm39JVtZ/UW0smN+0Cd56yywbN5p1o0aZXo5nnAETJkhlrxCibSQpBJDDkcpxxz3E5s03sH//K8c0/MWuXfD66yYRrF5tKnwnTYKbbzb1AqmpAQhcCBGyJCkEWFradezb9zLbtt1OYuLZ2O2JR/xMeTm88w68/DIsXmzWTZgATzwB06dDz56BjVkIEbpk5rUAU8rC8cf/E4+nhG3b7mp2O68XPv0ULr/c/Pq/+mrTK/hPf4IdO0y9wS23SEIQQgSW3Cl0gKio4fTqdRs5OQ+TmnolcXGT6t/bvNncEcyZY5JAbKxJDFdcYe4OpH+AEKIjSVLoIH373ktBwdts3vwLBgxYxdy5Ybz0krkDsFhMRfGjj8J550mTUSFE8EhS6CBWayRO5ws88MBqFiwwI4AOGQIPPwyXXirFQkKIzkGSQgf44Qd45BF4++1TUepETjnlbX7/+0lMmpQhxUNCiE5FkkIAffUV3Hef6W0cHQ233go33FBIXt4viYoaCXyG1PULIToTuSIFQGEhXHON6U+wcaMpIsrJMXUG/fun0r//E5SWfkFOzuPBDlUIIRqRpNCOtIaXXoJBg+CVV0xP4y1b4M47TauiOqmpV5GUdAE7dtxNRcXqoMUrhBCHkqTQTjZuhJNPNv0LBg0y9QgPPtj02ENKKY4//p/Y7Uls2HApXq+rw+MVQoimSFJoI5cL7r0XsrJg7Vp47jlYssQMT92SsLAkBg36F1VV69mx47cdE6wQQhyBJIU2+PJLyM6G+++HmTPNgHU//7npd9AaCQlnkJ7+K3Jzn+DAgU8DG6wQQrSCJIVjUFoKN9wAJ54INTVm+OpXXjGzlx2tfv0eIiJiMJs2XYXbfeDIHxBCiACSpHCU3nsPBg82xUS33WbmNTjjjGPfn9UazuDBr+F2F7B58w1ordsvWCGEOErST6GV3G7TiuhvfzNFRh98YGYyaw/R0SPJzLyf7dtnkZd3Oj17Xtc+OxYiiLTWlNWUcaD6AAeqD+DyuDg+8XiSI5PbZf+lrlI2Fm5kff56cstyiXZEE+eMa7TEOGKItEcSGRZJpD0Sq8UKQLW7mi0HtrCxYCMbC82yo3gH8eHxZMRkmCXWPKZFpxFpjyTCHkG4PZwIewQ2S9sunV6flxpvDeU15RRUFbC/Yj/5lfnkV+azv3I/xdXFVLgrqKhtvFydfTW3TbitPb6+ZklSaIX8fJgxA774wsxq9tBD7T+ZTUbGHRQXf86WLTcRGTmU2Nj/ad8DiA6RW5bLhz9+yNKcpUTaI0mMSCQxPJGkiCQSIxKJCovC7XXj9rmp9dZS663F7XVT7ammyl1FlbuKytrK+uc2iw2nzdlosVlslNeWU+IqodRVSmlNKSWuEmq8NTisDhw2Bw6rA6fNicPqwKM9lNeUU15bTnlNORW1FVS6K4l1xJIaldpoSYpIwqqsh52XRVnq99vwsdRVyu7S3eSU5dQ/5pTmUFhVyIHqA3i197B9pUSmMCxlGMOShzE0ZSj94vsRHRZNVFhUo6WitoK8ijz2VewjrzyPvIo89pbvZWPhRjYUbCC3LPeo/32cNicR9giKq4vRmLtyhaJvXF+OSziOA9UHWLN/Dfsq9rW4H5vFRpwzjvTodNJj0s2j/3mNp4Z9FfvMUrmv/oJf5a7C5XHh8rhw+9xH3Hd0WDTRDvO9xDhi6Bndkx6RPY76nI+W6mrFFWPGjNHLly/vsOMtX24msykoMEVGl10WuGO53cWsXDkOr7eC0aOX43CkB+5gLcivzKewqpB+8f1w2o5+dD6tNZXuSspqygi3hRMZFondYm8081yVu4o9ZXvYU76H3LJc9pbvpbi6mPJac9Gqu4C5PC56RvekX3w/+sX3IzMuk37x/YhxxLD1wFY2F23mx6If2Vy0mc1Fmyl2FTcZU0J4QqP/uL1iepEckUx5bTmFVYWNlhJXCR6f57AlzhnHoKRBDEoaxOCkwQxKGkR6TDpr9q/hgx8/4IMfP2BF3goAekb3xOPzUFRV1OSFsSUKRWRYJOG2cLzai8vjotpdXX8RqxNuCyfWGUusI5Y4ZxwOm4Naby01nhpcHhc13hpqPDXYLDaiHdGNLjKR9khKXCUHL14V+1q8ULVGalQqvWN70yumFykRKSSEJ5AYkWgewxOxWWz8WPQj6/LX1S+V7sqjOkakPZKBSQMZkjyEoclDGZI8hCHJQ+gT24cqdxUlrpJGS1lNGZXuSiprK+uTYWVtJUkRSQxOHszgpMEcn3g84fbwRsep9dayp2wPOWU57KvYR7X7YNKuS+AHqg+wp3xP/d9xfmV+/ectykJKZEp9sk2JTCHKHnVYgo+wR5ASmUJKZAo9onqQEplCnDMOi2r/kn2l1Aqt9RHLNyQptGDOHLj+eujRA+bNM1NfHo2K2gryK/PpG9e31f/IlZXrWblyPBERg8nOXoLV2rYhUwurClm9bzWbizaTEZtBVo8sesX0Omxq0O3F25m3cR7v/fgeS3cvRaNRKDJiM+if0J8BCQMYkDAAh81R/0u20m0eK2orKKwqpKCqgPzKfAoqC6j2VDfav1VZiQwzt+Auj4sSV8lhsdostvoLV90vR4fNwZ6yPewq3YXH52nyHK3KSmZ8pimaiEg+7Ny01hRWFdb/By6oKjhsHwpFYoT5RR/riMVutWO32LFZbNgsNqwWK4VVhWws2EhpTWn95+wWO26fG4VifK/xnDfwPKYOnMqgpEEopeqLUIqqiyiqKqKitgK71U6YNQy7xf9otRNuM8USkWGROKyOJs/B4/Pg8rio9dYS7YgmzBrW8j/+UdBaU+IqoaCqoMl6La/2UuOpqU80dY/Rjmh6x/YmPTodh81xVMf0aR+7SnaRU5ZTf9GuW8pry4mwR5AWlUZadBqpUamkRaUR7Yhur1Nud3V3CE6b09xxWQ6/4womSQptdNddZniKU04xU2EmH0Ux6Lr8dfxj2T+Ys2YOFbUVRIdFk5WaRXaPbEamjWRk6kgSwhPqixDcXvPo8rjYXbqbdXvm88OuNyj0ppBXY6OspoyT+pzE2QPO5qwBZ9Enrs9hx/T6vGw5sIXV+1azer9ZVu1bxd7yvYdtG+eMY0SPEYxIGUG0I5r5W+azZv8aAEb0GMH5g86nf0J/th3YxtbirWwp2sLWA1spqi5qtJ8Ie0R9WWtyZDLJEcmkRKbUP0Y7onF5XIcVidit9ka/2NOj0+kZ3ZOosKhm57H2+DzsKdvD9uLt7CjZQYmrhP4J/Tk+8Xj6xfc7qgtkjaeGvIo8CioLiHHEkBSRRJwzrlX/ibXW5Ffms6lwE5sKN7H1wFYGJQ3inOPPoUdU4G/thThWkhTa4Pnn4brr4Be/gKefhhpfJd/v+Z6lOUtZkbeC5Ijk+uKDwcmD6R3bG4/Pw3ub3uOZZc+wZNcSHFYHFw+7mAm9JrA2fy2r9q1i1b5Vrb5dTo2IJsVezsCUcSTEjOTT7Z+yvXg7AEOSh3D2gLPJiMlgzf41rN6/mnX56+p/ndssNoYkDyGrR5ZZUrMYmDiQ3aW767dfs38Na/avocpdxQm9T2DaoGlMGzSNfvH9mo2puLoYr/YSaY/EaXM2ewEXQnQ+khSO0fLlMPEEH0PO/YQTr1nIN7lL+WHfD/VFFwMSBnCg+kCjX83htnCcNifFrmIy4zL55ZhfcvXIq0mKSGq0b5/2sfXAVlbtW2WKERoUH4RZw3BYHfSK6UVmfCYOaxjr119IYeGHZGUtJC7uVDYXbWb+lvks2LKAJbuW4Pa5SQxPJCs1q1ECGJw0uFW38j7to9pdTWRYZPt+iUKITkeSwjHYmVfOqGteonzwU3hit+C0OflJ+k+YmDGRib0nMqHXBOLD4wHqy5c3Fm5kY8FGDrgOMHPoTKb0n9JulUQeTzkrV06gtjaPkSOXEhk5qP69utYkaVFp8otdCHFEnSIpKKWmAH8DrMDzWusHD3n/KuARYI9/1dNa6+db2mcgksL24u387dun+PvXL+KxlTEsbjy/O+0WLhh8QbtW5h2L6uptrFw5EYvFzsiRS3E6ewc1HiFE19TapBCwHs1KKSvwDHAmMAS4RCk1pIlN39JaZ/uXFhNCIDy89GH6P9mfp797Gs+Gc/ht0nesveUbLh52cdATAkB4+HFkZS3E4yln9erJ1NYe3nJGCCHaSyCHuRgHbNVab9da1wJvAucF8HhHbdW+Vfzus98xLvZcfI/v4pq413jgxnHBDuswUVFZDB/+H2pqdrNmzRQ8nrJghySE6KYCmRTSgZwGr3P96w51oVJqjVJqrlIqI4DxNOLxebj2g2uJDUtgw4MvMmpAT55+mk47Z3Jc3AkMHTqXyso1rFt3nszBIIQIiGAPiPch0FdrPQL4FHi5qY2UUtcrpZYrpZYXFLRP8cljXz/GyryVDNj8DBZXInPnQnj4kT8XTImJZzFo0MuUlHzBhg0z8TXTmUsIIY5VIJPCHqDhL/9eHKxQBkBrXaS1rvG/fB4Y3dSOtNaztdZjtNZjko+mF1kzNhdt5g+L/8DZ/c5nxasXctVVkJnZ5t12iB49fsaAAU9RVPQBP/54tSQGIUS7CmRSWAYMUEplKqXCgIuBDxpuoJRKa/ByKrAxgPEApm3+zz/4OeH2cCaVPYO7VnHFFYE+avtKT7+JzMwH2L//Vf8dQ82RPySEEK0QsKSgtfYANwMLMRf7t7XW65VSf1JKTfVv9mul1Hql1Grg18BVgYqnzrPLn+XL3V/y+OTHef+1NIYNg5EjA33U9tenz9307/8EhYXvsnbtuXg8FcEOSQjRDYRU57XdpbsZ+vehTOg1gafGLWTQIMXDD5t5ErqqvLyX+PHHa4mJGcfw4Quw2+ODHZIQohMKej+FzkZrzQ3/MTObzT53Nq++qrBY4NJLgx1Z26SlXcXQof+mvHwlq1adRE1Ny+PACyFES0ImKbyx7g0+2voRfzntL/SO6csrr8Dpp0PPnsGOrO2Sky9g+PD5VFdv54cfTqC6enuwQxJCdFEhkxTOOO4M/nTyn7hp7E0sWQK7dtHlKphbkpDwU7KyFuHxHGD58mzy8l6S+Z6FEEctZJJCYkQi95x0D1aLlTlzIDoapk0LdlTtKzZ2PKNHryAqaiQ//ng169dfQG1t/pE/KIQQfiGTFOpUVcG//w3Tp0NERLCjaX/h4ZlkZ3/Occc9SlHRApYtG0ZBwXvBDksI0UWEXFKYNw8qKrpX0dGhlLKQkXE7Y8asxOHoxfr157Nx41W43YdPgSmEEA2FXFKYMwf69IFJk4IdSeBFRg5l1Khv6dPnHvbvf5VlywaTn/+21DUIIZoVUklhzx5YtMjcJVhC5MwtljAyM//E6NHfExaWzoYNM1m79hyqq3cGOzQhRCcUIpdG4/XXweeDyy8PdiQdLzp6FKNGfctxx/0fJSVfsGzZUHJyHpOxk4QQjYRMUtAaXn4ZJkyAAQOCHU1wWCw2MjJuZdy4DcTHn8a2bXewYsUYCgs/lCIlIQQQQknhhx9g/Xq48spgRxJ8Tmdvhg17n6FD5+L1lrNu3VR/cnhfkoMQIS5kkkJxMWRnw4wZwY6kc1BKkZx8IePGbWLgwH/h8ZSybt00li8fSUHBu2jtC3aIQoggCKkB8UTzfD4P+fmvs2vXn6mu3kJ4+ABSUmaSnDydyMjhqM46JZ0QolVaOyCeJAXRiM/noaDgLfLyXqSkZDHgIzz8eFJSZkiCEKILk6Qg2qy2Np+CgncpKPh3gwQxkB49LiEl5WIiIgYGO0QhRCtJUhDtqrY2n8LCeeTnv0lJyReAJioqm5SUS0hOnkF4eN9ghyiEaIEkBREwNTV7KSj4N/v3v0F5+XcAhIcPIDb2BP8yifDw/lLMJEQnIklBdIjq6h0UFr5LScmXlJZ+hcdTBIDdnkJs7ERiYn5CdPQ4oqPHYLNFBzlaIUKXJAXR4bT2UVX1I6WlJkGUli7F5aqb8EcRETGEmJhxREYOx+HIwOnsjcORQVhYD5QKmdbRQgSFJAXRKdTWFlJevpzy8u8pK/ue8vLvcLsLG22jlB2Hoxfh4ccRHj6QiIi6ZRAORy9JGEK0g9YmBVtHBCNCV1hYEomJU0hMnAKYubI9nmJqanJwuXY3eNxNdfUW9u+fg9dbXv95iyWCqKhsYmLGER09lujosVJfIUQASVIQHUophd2egN2eQFRU1mHva62prd1HVdWPVFf/SGXlBsrLV7B37z/x+Z4AwGaLIyJiMErZgLrkoFBKYbMlEBk5hIiIIUREDCYiYiBWa3jHnaAQXZwkBdGpKKVwONJwONKIjz+5fr3P56Gqaj1lZcsoL19GdfVWwAzFYYpANVr7qKxcT2Hh+4C3bo84nf0ID++P09kHp7Ovf+mDw9ELsKC1B609gBetPSjlwOnsg8Vi79BzF6IzkKQgugSLxUZUVJb/7uLnLW7r89VQVbWFqqoNVFZuoKpqIy7XdgoLV+J2F7TqeErZCA/v36COYxBOZ29stkTsdrNYLOFSjCW6HUkKotuxWBxERQ0jKmrYYe95vZW4XLtxuXZSU7MHMAlAKav/0YbXW0l19WaqqjZRVfUjBw4sQGv3YftSyuFPDk7/563+Ii0rFosdqzUaqzUGmy2m/tFmS6i/WwkPz8RmSzgssWit8XrL8HjK6j8ryUd0FEkKIqRYrZFERg4mMnJwqz/j83lwuXZSW7sHt7uofvF4DuB2F+Hz1WCKnuoWD1q78XorcLl21l/gvd6yw5KL1RqF05mJUmF4PCV4PMV4PCXUFY0BWCzhhIWlEhaW5l96YLcnYrOZupm6R4vFiddbiddb0WixWJyEhaVgt6fUP1qtUYDG6y33H7cUj6cUn68GpzMDp7MvFoujfb500aVIUhDiCCwWGxER/YmI6N+m/dTdAbhcO3G5dlJdvcP/fAda1xIRcTw2Wzw2Wzx2ezxWayxebym1tfuoqcmjtjaPqqqNlJR8jsdTDBx7c3KlwvwJqrl9KByODMLDj8Pp7IfDkVZ/F6SUBaWs/udWf5Phhs8taO3G56vxLy60rkFr7W9kkNRosVqjqWsoYEbzN8+19uLz1aJ1rf/Rjda19fE1bGRgsThwOHpJB8l2IElBiA5iWkfFNqgbOXZa+/y/7g/gdh/A4zmAz+fCao1qtFgskfh8LtzufGpr8xs8FmCxOLDZ4rDZYrFaY7HZ4rBY7Lhcu6iu3o7LtY3q6m0UFX2I253fxnM3LcWaKoZrTzZbHA5Hb3/HyN7YbLH4fK7DFqXCsNli/ece438e44+zLjFZ/M99/juqcrzeMv/zMv/xGn6+bknAbk/2J714fwI1vF4Xbvf++kTv8ZRgsTixWiOwWMLrH822Ff47P3P35/NVEhWVTWzsxMB+hwHduxAiIJSyYLebO4rw8OOOuL3T2avNx9Ta55986WBRGfiaeO7DYrGjlAOLxSxKWdBa4/NV4XYX4nYXUltbgNtdiNdbgblj0f79m+emjifMv68wLJYwlKprEab9MZltfT4XNTW51NTsru/3Ulr6NR5PKVZrOBaLs9Hi89X4i/RK8flcR/U9mIt4DABeb9kRPm+aSdtscXg8B/x3eMcuI+POrp0UlFJTgL8BVuB5rfWDh7zvAOYAo4EiYKbWemcgYxJCHBtTbGThWC8bSims1kis1kiczj7tG1wb+Hy1Dep86pKbSU5a+/xxR/uXqMOaKpvPl/rrjkr9dU6FjRaPpxibLYGwsFQcjjR/HVEqNlucv4itGq+3qv4ROOSuLxKrNQqbLSbg30fAkoIy90zPAKSB5lIAAAaaSURBVKcDucAypdQHWusNDTa7FijWWvdXSl0MPATMDFRMQghxKIsljLCwJCCpDZ9PBpLbNa5gCeSgMuOArVrr7drUDr0JnHfINucBL/ufzwVOU9L2TgghgiaQSSEdyGnwOte/rslttOlSWgokBjAmIYQQLegSw08qpa5XSi1XSi0vKGhdj1QhhBBHL5BJYQ+Q0eB1L/+6JrdRpi1YLKbCuRGt9Wyt9Rit9Zjk5O5RbieEEJ1RIJPCMmCAUipTKRUGXAx8cMg2HwBX+p9fBHymu9oED0II0Y0ErPWR1tqjlLoZWIhpkvqi1nq9UupPwHKt9QfAC8ArSqmtwAFM4hBCCBEkAe2noLVeACw4ZN29DZ67gOmBjEEIIUTrdYmKZiGEEB2jy83RrJQqAHYd48eTgMIjbtX1hcJ5hsI5QmicZyicIwT/PPtorY/YUqfLJYW2UEotb83E1V1dKJxnKJwjhMZ5hsI5Qtc5Tyk+EkIIUU+SghBCiHqhlhRmBzuADhIK5xkK5wihcZ6hcI7QRc4zpOoUhBBCtCzU7hSEEEK0IGSSglJqilLqR6XUVqXUrGDH016UUi8qpfKVUusarEtQSn2qlNrif4wPZoxtpZTKUEp9rpTaoJRar5S6xb++25ynUsqplPpeKbXaf45/9K/PVEp95/+7fcs/ZEyXppSyKqV+UEr9x/+6O57jTqXUWqXUKqXUcv+6LvH3GhJJocGEP2cCQ4BLlFJDghtVu3kJmHLIulnAf7XWA4D/+l93ZR7gdq31EGA8cJP/3687nWcNcKrWOgvIBqYopcZjJp76P611f6AYMzFVV3cLsLHB6+54jgCnaK2zGzRD7RJ/ryGRFGjdhD9dktZ6CWbcqIYaTl70MjCtQ4NqZ1rrPK31Sv/zcswFJZ1udJ7aqPC/tPsXDZyKmYAKuvg5AiilegFnA8/7Xyu62Tm2oEv8vYZKUmjNhD/dSQ+tdZ7/+T6gRzCDaU9Kqb7ASOA7utl5+otVVgH5wKfANqDEPwEVdI+/2yeA/wV8/teJdL9zBJPQP1FKrVBKXe9f1yX+XgM6IJ4IPq21Vkp1iyZmSqko4B3gVq11WcOZW7vDeWoza3y2UioOmAcMCnJI7UopdQ6Qr7VeoZQ6OdjxBNgJWus9SqkU4FOl1KaGb3bmv9dQuVNozYQ/3cl+pVQagP8xP8jxtJlSyo5JCK9prd/1r+525wmgtS4BPgcmAHH+Caig6//dTgSm/n979xNiVRnGcfz7K0FsRoxiVkrJ2CaEQRFmYQmi2CJatKiEVMS1mxZCjCjBgFulheAsWhiO4h8a3TfF0CyixKQiXUWLcaEbCRSKmH4u3veerjOCw6Rz5975fTZ37nsPh/PAOfOc876c55H0B2UKdxfwOb0VIwC279TPe5QEP0yXnK8rJSkspOFPL2lvXnQQuNbBY/nf6rzzF8At2yfbfuqZOCUN1CcEJK0B9lDWTr6lNKCCLo/R9ojtDbY3Uq7Bb2zvo4diBJDUJ2lt62/gHeBXuuR8XTEvr0l6lzKf2Wr4c6LDh/RMSLoA7KRUYLwLfAZcBS4Br1Eqyn5ke+5idNeQ9DbwHfAL/81FH6WsK/REnJKGKIuPL1Ju1i7ZHpU0SLmrfgX4Cdhv++/OHemzUaePjth+r9dirPFM1K+rgPO2T0h6lS44X1dMUoiIiKdbKdNHERGxAEkKERHRSFKIiIhGkkJERDSSFCIiopGkELGEJO1sVQeNWI6SFCIiopGkEPEEkvbX/gY3JY3VYnUPJJ2q/Q4mJQ3UbbdI+l7Sz5ImWnXyJb0h6evaI+GGpE119/2Srki6LWlc7UWcIjosSSFiDklvAnuBt2xvAWaBfUAfcN32ZmCK8vY4wJfAp7aHKG9dt8bHgdO1R8J2oFUhcyvwCaW3xyClJlDEspAqqRHz7Qa2AT/Wm/g1lOJl/wIX6zbngK8krQNetj1Vx88Cl2vtm/W2JwBs/wVQ9/eD7Zn6/SawEZh+/mFFPF2SQsR8As7aHnlsUDo+Z7vF1ohpr+szS67DWEYyfRQx3yTwQa2F3+qt+zrlemlV8/wYmLb9J3Bf0o46fgCYqh3iZiS9X/exWtJLSxpFxCLkDiViDtu/STpG6Zz1AvAPcBh4CAzX3+5R1h2glEE+U//p/w4cquMHgDFJo3UfHy5hGBGLkiqpEQsk6YHt/k4fR8TzlOmjiIho5EkhIiIaeVKIiIhGkkJERDSSFCIiopGkEBERjSSFiIhoJClERETjEepOpsMztKaIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 859us/sample - loss: 1.4290 - acc: 0.5626\n",
      "Loss: 1.4289896430008633 Accuracy: 0.5626168\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1544 - acc: 0.3033\n",
      "Epoch 00001: val_loss improved from inf to 1.62908, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/001-1.6291.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 2.1543 - acc: 0.3033 - val_loss: 1.6291 - val_acc: 0.4754\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4514 - acc: 0.5414\n",
      "Epoch 00002: val_loss improved from 1.62908 to 1.26991, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/002-1.2699.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.4514 - acc: 0.5414 - val_loss: 1.2699 - val_acc: 0.6147\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2212 - acc: 0.6229\n",
      "Epoch 00003: val_loss improved from 1.26991 to 1.20942, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/003-1.2094.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.2211 - acc: 0.6229 - val_loss: 1.2094 - val_acc: 0.6238\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0717 - acc: 0.6714\n",
      "Epoch 00004: val_loss improved from 1.20942 to 1.08847, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/004-1.0885.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.0716 - acc: 0.6714 - val_loss: 1.0885 - val_acc: 0.6601\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9434 - acc: 0.7113\n",
      "Epoch 00005: val_loss improved from 1.08847 to 1.01836, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/005-1.0184.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.9434 - acc: 0.7113 - val_loss: 1.0184 - val_acc: 0.6925\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8413 - acc: 0.7450\n",
      "Epoch 00006: val_loss improved from 1.01836 to 0.98150, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/006-0.9815.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.8413 - acc: 0.7450 - val_loss: 0.9815 - val_acc: 0.7044\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7365 - acc: 0.7755\n",
      "Epoch 00007: val_loss did not improve from 0.98150\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.7364 - acc: 0.7755 - val_loss: 0.9967 - val_acc: 0.6983\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6505 - acc: 0.7988\n",
      "Epoch 00008: val_loss improved from 0.98150 to 0.97701, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/008-0.9770.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.6505 - acc: 0.7988 - val_loss: 0.9770 - val_acc: 0.7077\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5736 - acc: 0.8218\n",
      "Epoch 00009: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5735 - acc: 0.8218 - val_loss: 1.1013 - val_acc: 0.6942\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5055 - acc: 0.8420\n",
      "Epoch 00010: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5055 - acc: 0.8419 - val_loss: 1.0116 - val_acc: 0.7065\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4515 - acc: 0.8598\n",
      "Epoch 00011: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4515 - acc: 0.8598 - val_loss: 0.9783 - val_acc: 0.7193\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3975 - acc: 0.8748\n",
      "Epoch 00012: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3975 - acc: 0.8749 - val_loss: 1.0541 - val_acc: 0.7207\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3528 - acc: 0.8874\n",
      "Epoch 00013: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3528 - acc: 0.8874 - val_loss: 1.0739 - val_acc: 0.7300\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3214 - acc: 0.8979\n",
      "Epoch 00014: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3214 - acc: 0.8978 - val_loss: 1.1663 - val_acc: 0.7147\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2972 - acc: 0.9059\n",
      "Epoch 00015: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2972 - acc: 0.9059 - val_loss: 1.1027 - val_acc: 0.7147\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2674 - acc: 0.9142\n",
      "Epoch 00016: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2674 - acc: 0.9142 - val_loss: 1.1086 - val_acc: 0.7317\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2478 - acc: 0.9201\n",
      "Epoch 00017: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2478 - acc: 0.9201 - val_loss: 1.1266 - val_acc: 0.7317\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9267\n",
      "Epoch 00018: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2241 - acc: 0.9267 - val_loss: 1.2380 - val_acc: 0.7345\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2139 - acc: 0.9308\n",
      "Epoch 00019: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2140 - acc: 0.9308 - val_loss: 1.1835 - val_acc: 0.7377\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9356\n",
      "Epoch 00020: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1977 - acc: 0.9356 - val_loss: 1.2217 - val_acc: 0.7298\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1899 - acc: 0.9388\n",
      "Epoch 00021: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1899 - acc: 0.9388 - val_loss: 1.2106 - val_acc: 0.7410\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9418\n",
      "Epoch 00022: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1792 - acc: 0.9418 - val_loss: 1.2177 - val_acc: 0.7445\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9442\n",
      "Epoch 00023: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1739 - acc: 0.9442 - val_loss: 1.2132 - val_acc: 0.7440\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1632 - acc: 0.9467\n",
      "Epoch 00024: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1632 - acc: 0.9467 - val_loss: 1.2237 - val_acc: 0.7393\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9523\n",
      "Epoch 00025: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1506 - acc: 0.9523 - val_loss: 1.2297 - val_acc: 0.7503\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9490\n",
      "Epoch 00026: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1550 - acc: 0.9491 - val_loss: 1.3101 - val_acc: 0.7428\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9545\n",
      "Epoch 00027: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1432 - acc: 0.9545 - val_loss: 1.2528 - val_acc: 0.7491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9565\n",
      "Epoch 00028: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1376 - acc: 0.9566 - val_loss: 1.2277 - val_acc: 0.7543\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9587\n",
      "Epoch 00029: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1328 - acc: 0.9587 - val_loss: 1.2834 - val_acc: 0.7463\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9594\n",
      "Epoch 00030: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1254 - acc: 0.9594 - val_loss: 1.2573 - val_acc: 0.7512\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9601\n",
      "Epoch 00031: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1272 - acc: 0.9601 - val_loss: 1.3088 - val_acc: 0.7563\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9635\n",
      "Epoch 00032: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1166 - acc: 0.9635 - val_loss: 1.3402 - val_acc: 0.7519\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9621\n",
      "Epoch 00033: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1178 - acc: 0.9622 - val_loss: 1.2699 - val_acc: 0.7526\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9651\n",
      "Epoch 00034: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1108 - acc: 0.9651 - val_loss: 1.4132 - val_acc: 0.7484\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9651\n",
      "Epoch 00035: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1102 - acc: 0.9651 - val_loss: 1.3315 - val_acc: 0.7519\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9651\n",
      "Epoch 00036: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1135 - acc: 0.9651 - val_loss: 1.3034 - val_acc: 0.7589\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9673\n",
      "Epoch 00037: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1065 - acc: 0.9673 - val_loss: 1.2891 - val_acc: 0.7573\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9679\n",
      "Epoch 00038: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1050 - acc: 0.9679 - val_loss: 1.3043 - val_acc: 0.7566\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9676\n",
      "Epoch 00039: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1026 - acc: 0.9676 - val_loss: 1.3648 - val_acc: 0.7515\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9707\n",
      "Epoch 00040: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0962 - acc: 0.9707 - val_loss: 1.2815 - val_acc: 0.7584\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9684\n",
      "Epoch 00041: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1014 - acc: 0.9684 - val_loss: 1.2798 - val_acc: 0.7626\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9721\n",
      "Epoch 00042: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0930 - acc: 0.9721 - val_loss: 1.3323 - val_acc: 0.7636\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9712\n",
      "Epoch 00043: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0933 - acc: 0.9711 - val_loss: 1.3948 - val_acc: 0.7508\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9677\n",
      "Epoch 00044: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1017 - acc: 0.9677 - val_loss: 1.3555 - val_acc: 0.7570\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9718\n",
      "Epoch 00045: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0898 - acc: 0.9719 - val_loss: 1.4100 - val_acc: 0.7589\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9744\n",
      "Epoch 00046: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0847 - acc: 0.9744 - val_loss: 1.3008 - val_acc: 0.7598\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9749\n",
      "Epoch 00047: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0830 - acc: 0.9749 - val_loss: 1.4419 - val_acc: 0.7363\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9705\n",
      "Epoch 00048: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0953 - acc: 0.9705 - val_loss: 1.3805 - val_acc: 0.7631\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9757\n",
      "Epoch 00049: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0806 - acc: 0.9757 - val_loss: 1.3711 - val_acc: 0.7584\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9750\n",
      "Epoch 00050: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0844 - acc: 0.9749 - val_loss: 1.3315 - val_acc: 0.7626\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9748\n",
      "Epoch 00051: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0840 - acc: 0.9748 - val_loss: 1.3670 - val_acc: 0.7654\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9757\n",
      "Epoch 00052: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0788 - acc: 0.9757 - val_loss: 1.4042 - val_acc: 0.7519\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9755\n",
      "Epoch 00053: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0815 - acc: 0.9755 - val_loss: 1.3700 - val_acc: 0.7601\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9773\n",
      "Epoch 00054: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0755 - acc: 0.9773 - val_loss: 1.4054 - val_acc: 0.7596\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9754\n",
      "Epoch 00055: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0819 - acc: 0.9754 - val_loss: 1.3717 - val_acc: 0.7643\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9774\n",
      "Epoch 00056: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0742 - acc: 0.9774 - val_loss: 1.3874 - val_acc: 0.7710\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9768\n",
      "Epoch 00057: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0775 - acc: 0.9768 - val_loss: 1.3407 - val_acc: 0.7710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9769\n",
      "Epoch 00058: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0742 - acc: 0.9769 - val_loss: 1.3651 - val_acc: 0.7624\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd8W9X5+PHPkSxL3nsksRM7eziJs0ggJECBsErKDnyhjLZQKFD40lLSMkoHZY9CoZBCymhZhbK+UFLgl+AwQhYJZJHhDNuJ916a5/fHsR078YotRR7P+/W6L9nS1blHinOfe9ZzldYaIYQQAsAS7AoIIYToOyQoCCGEaCFBQQghRAsJCkIIIVpIUBBCCNFCgoIQQogWEhSEEEK0kKAghBCihQQFIYQQLUKCXYEjlZiYqDMyMoJdDSGE6FfWrVtXqrVO6mq/fhcUMjIyWLt2bbCrIYQQ/YpSam939pPuIyGEEC0kKAghhGghQUEIIUSLfjem0B63201+fj6NjY3Brkq/5XA4SEtLw2azBbsqQoggGhBBIT8/n6ioKDIyMlBKBbs6/Y7WmrKyMvLz88nMzAx2dYQQQTQguo8aGxtJSEiQgNBDSikSEhKkpSWEGBhBAZCA0Evy/QkhYAAFha54vfU4nQX4fJ5gV0UIIfqsQRMUfD4nLtcBtHb5vezKykqeeuqpHr33zDPPpLKystv733333Tz00EM9OpYQQnRl0AQFpcyYutb+byl0FhQ8ns6P98EHHxAbG+v3OgkhRE8MwqDg9nvZixcvZteuXWRnZ3PrrbeyYsUK5s2bx8KFC5k4cSIA55xzDjNmzGDSpEksWbKk5b0ZGRmUlpayZ88eJkyYwNVXX82kSZNYsGABDQ0NnR53w4YNzJkzhylTpnDuuedSUVEBwOOPP87EiROZMmUKF198MQCffvop2dnZZGdnM23aNGpqavz+PQgh+r8BMSW1tR07bqa2dkM7r2i83losFjtKhR5RmZGR2YwZ81iHr993331s2rSJDRvMcVesWMH69evZtGlTyxTPpUuXEh8fT0NDA7NmzeL8888nISHhkLrv4JVXXuFvf/sbF110EW+++SaXXXZZh8e9/PLLeeKJJzjhhBO46667+N3vfsdjjz3Gfffdx+7du7Hb7S1dUw899BBPPvkkc+fOpba2FofDcUTfgRBicBg0LQVonl2jj8rRjjnmmDZz/h9//HGmTp3KnDlzyMvLY8eOHYe9JzMzk+zsbABmzJjBnj17Oiy/qqqKyspKTjjhBACuuOIKcnJyAJgyZQqXXnop//jHPwgJMXF/7ty53HLLLTz++ONUVla2PC+EEK0NuDNDZ1f0tbUbCAmJw+EYEfB6REREtPy8YsUKPv74Y7788kvCw8M58cQT210TYLfbW362Wq1ddh915P333ycnJ4f33nuPe+65h2+//ZbFixdz1lln8cEHHzB37lyWLVvG+PHje1S+EGLgGkQtBTOuEIiB5qioqE776KuqqoiLiyM8PJxt27axatWqXh8zJiaGuLg4Vq5cCcBLL73ECSecgM/nIy8vj5NOOon777+fqqoqamtr2bVrF5MnT+a2225j1qxZbNu2rdd1EEIMPAOupdCZQAWFhIQE5s6dS1ZWFmeccQZnnXVWm9dPP/10nn76aSZMmMC4ceOYM2eOX477wgsvcO2111JfX8/IkSP5+9//jtfr5bLLLqOqqgqtNT//+c+JjY3lzjvvZPny5VgsFiZNmsQZZ5zhlzoIIQYWpfXR6WP3l5kzZ+pDb7KzdetWJkyY0OV7Gxp24vM5iYiYFKjq9Wvd/R6FEP2PUmqd1npmV/sNsu4jW0CmpAohxEAxyIKC6T7qb60jIYQ4WgIWFJRS6Uqp5UqpLUqpzUqpm9rZRymlHldK7VRKfaOUmh6o+pjjNS9g8wbyMEII0W8FcqDZA/xCa71eKRUFrFNKfaS13tJqnzOAMU3bbOCvTY8B0TbVxaAaYxdCiG4JWEtBa31Aa72+6ecaYCsw7JDdfgC8qI1VQKxSakig6hTI/EdCCDEQHJUxBaVUBjAN+OqQl4YBea1+z+fwwOHHekhQEEKIzgQ8KCilIoE3gZu11tU9LOMapdRapdTakpKSXtQlcEnxjlRkZOQRPS+EEEdDQIOCUsqGCQj/1Fr/u51dCoD0Vr+nNT3XhtZ6idZ6ptZ6ZlJSUi/qIy0FIYToTCBnHyngOWCr1vqRDnZ7F7i8aRbSHKBKa30gcHWyAha/B4XFixfz5JNPtvzefCOc2tpaTj75ZKZPn87kyZN55513ul2m1ppbb72VrKwsJk+ezGuvvQbAgQMHmD9/PtnZ2WRlZbFy5Uq8Xi9XXnlly76PPvqoXz+fEGLwCOQUnLnAD4FvlVLNuax/AwwH0Fo/DXwAnAnsBOqBq3p91Jtvhg3tpc42wr11oKxgOYLU0dnZ8FjHifYWLVrEzTffzPXXXw/A66+/zrJly3A4HLz11ltER0dTWlrKnDlzWLhwYbfuh/zvf/+bDRs2sHHjRkpLS5k1axbz58/n5Zdf5rTTTuP222/H6/VSX1/Phg0bKCgoYNOmTQBHdCc3IYRoLWBBQWv9GQfzVXe0jwauD1Qd2qfwd/rsadOmUVxczP79+ykpKSEuLo709HTcbje/+c1vyMnJwWKxUFBQQFFREampqV2W+dlnn3HJJZdgtVpJSUnhhBNOYM2aNcyaNYsf/ehHuN1uzjnnHLKzsxk5ciS5ubnceOONnHXWWSxYsMCvn08IMXgMvMn6nVzRAzjrt6O1l4gI/+b4ufDCC3njjTcoLCxk0aJFAPzzn/+kpKSEdevWYbPZyMjIaDdl9pGYP38+OTk5vP/++1x55ZXccsstXH755WzcuJFly5bx9NNP8/rrr7N06VJ/fCwhxCAzqNJcQOAypS5atIhXX32VN954gwsvvBAwKbOTk5Ox2WwsX76cvXv3dru8efPm8dprr+H1eikpKSEnJ4djjjmGvXv3kpKSwtVXX81PfvIT1q9fT2lpKT6fj/PPP58//vGPrF+/3u+fTwgxOAy8lkIXApUUb9KkSdTU1DBs2DCGDDHr7y699FLOPvtsJk+ezMyZM4/opjbnnnsuX375JVOnTkUpxQMPPEBqaiovvPACDz74IDabjcjISF588UUKCgq46qqr8Pl8ANx7771+/3xCiMFhUKXOBnA6D+ByFRAZOR2lBl1DqVOSOluIgUtSZ3dA1ioIIUTHJCgIIYRoIUFBCCFEi0EcFIKf/0gIIfqaQRwUpKUghBCHkqAghBCixSAMCsrvC9gqKyt56qmnevTeM888U3IVCSH6jEEXFMD/q5o7CwoeT+fH+eCDD4iNjfVbXYQQojckKPjB4sWL2bVrF9nZ2dx6662sWLGCefPmsXDhQiZOnAjAOeecw4wZM5g0aRJLlixpeW9GRgalpaXs2bOHCRMmcPXVVzNp0iQWLFhAQ0PDYcd67733mD17NtOmTeOUU06hqKgIgNraWq666iomT57MlClTePPNNwH48MMPmT59OlOnTuXkk0/222cWQgxMAy7NRReZswHw+UagtQ+rtXtldpE5m/vuu49NmzaxoenAK1asYP369WzatInMzEwAli5dSnx8PA0NDcyaNYvzzz+fhISENuXs2LGDV155hb/97W9cdNFFvPnmm1x22WVt9jn++ONZtWoVSimeffZZHnjgAR5++GH+8Ic/EBMTw7fffgtARUUFJSUlXH311eTk5JCZmUl5eXn3PrAQYtAacEGhe/yfPvtQxxxzTEtAAHj88cd56623AMjLy2PHjh2HBYXMzEyys7MBmDFjBnv27Dms3Pz8fBYtWsSBAwdwuVwtx/j444959dVXW/aLi4vjvffeY/78+S37xMfH+/UzCiEGngEXFLrInA2A01mGy3WAyMgZ3brhTU9ERES0/LxixQo+/vhjvvzyS8LDwznxxBPbTaFtt9tbfrZare12H914443ccsstLFy4kBUrVnD33XcHpP5CiMFp0I4pAGjt9Ut5UVFR1NTUdPh6VVUVcXFxhIeHs23bNlatWtXjY1VVVTFs2DAAXnjhhZbnTz311Da3BK2oqGDOnDnk5OSwe/duAOk+EkJ0aZAHBf8MNickJDB37lyysrK49dZbD3v99NNPx+PxMGHCBBYvXsycOXN6fKy7776bCy+8kBkzZpCYmNjy/B133EFFRQVZWVlMnTqV5cuXk5SUxJIlSzjvvPOYOnVqy81/hBCiI4MudTaAx1NFQ8MOwsLGExIS6e8q9luSOluIgUtSZ3dCVjULIUT7BnlQkKR4QgjR2iAPCtJSEEKI1gZpULACFgkKQghxiEEZFMD/qS6EEGIgkKAghBCihQSFIImMlKmwQoi+R4KCEEKIFoM4KNj8NiV18eLFbVJM3H333Tz00EPU1tZy8sknM336dCZPnsw777zTZVkdpdhuLwV2R+myhRCipwZcQrybP7yZDYVd5M4GfD4XWjuxWqO63Dc7NZvHTu84096iRYu4+eabuf766wF4/fXXWbZsGQ6Hg7feeovo6GhKS0uZM2cOCxcu7DQJX3sptn0+X7spsNtLly2EEL0x4IJCh7xecLvBbgelUEphMnxoTCrtnps2bRrFxcXs37+fkpIS4uLiSE9Px+1285vf/IacnBwsFgsFBQUUFRWRmpraYVntpdguKSlpNwV2e+myhRCiNwZcUOjwir6qCnbsgPHjITISt7uCxsZdhIdPxGoN7/VxL7zwQt544w0KCwtbEs/985//pKSkhHXr1mGz2cjIyGg3ZXaz7qbYFkKIQBk8YwoOh3lsukeBv1c1L1q0iFdffZU33niDCy+8EDBprpOTk7HZbCxfvpy9e/d2WkZHKbY7SoHdXrpsIYTojcETFEJDQSlouvL2d/6jSZMmUVNTw7BhwxgyZAgAl156KWvXrmXy5Mm8+OKLjB8/vtMyOkqx3VEK7PbSZQshRG8MrtTZmzeb4DBmDD6fm7q6jdjt6YSGpgSotv2LpM4WYuCS1NntcTjaaSnIWgUhhGg2+IKC0wk+H0opWcAmhBCHGDBBoVvdYM2DzU4nIKuaW+tv3YhCiMAYEEHB4XBQVlbW9YmtOSi06kKSoGACQllZGY7m70cIMWgNiHUKaWlp5OfnU1JS0vmOPh+UloLHAzExuFwlaO3GbvcdnYr2YQ6Hg7S0tGBXQwgRZAELCkqppcD3gWKtdVY7r58IvAPsbnrq31rr3/fkWDabrWW1b5fOPBPmz4eXXuK77x6jtPQdsrMLe3JYIYQYcALZUnge+AvwYif7rNRafz+AdTjc+PGwbRsANlsibncpWutO8xEJIcRgEbAxBa11DlAeqPJ7rDkoaI3NlgR48Xgqg10rIYToE4I90HysUmqjUuo/SqlJHe2klLpGKbVWKbW2y3GDrowfD7W1sH8/NlsiAG53ae/KFEKIASKYQWE9MEJrPRV4Ani7ox211ku01jO11jOTkpJ6d9TmVBNbtxIaaspyu3sZaIQQYoAIWlDQWldrrWubfv4AsCmlEgN+4OagsG2btBSEEOIQQQsKSqlU1TS6q5Q6pqkuZQE/cGoqREcfEhSkpSCEEBDYKamvACcCiUqpfOC3gA1Aa/00cAFwnVLKAzQAF+ujsaxWqZbBZjPQDC6XBAUhhIAABgWt9SVdvP4XzJTVo2/8ePjkE6zWcGy2FOrqNgWlGkKIXnrqKdizB+67DyzBnjczMAyIFc1HbPx4ePFFqKkhNnY+VVWfyloFIfqb2lpYvBhqaszNsx5/3PQEiF4ZnKG1ebD5u++IjT0BpzOfxsY9Qa2SEF3ySJ6uNl57zQSEM8+Ev/wF7rkn2DUaEAZ3UNi2jZiY+QBUVeUEsUJCdGHfPoiLg2eeCXZNAu///T+4/HLTEujMkiUwcSK89x5ccQXceWdgv5/du1uSaXaqoQE++QS83sDVJYAGZ1AYNQqsVti2jYiISYSExFNZ+WmwayVEx557zpwk//d/Yfv2YNemZ776CqqrO9/ngw/Mlf9LL5nuoI5s2ACrV8M115ixhL/9Db7/fbjuOnjjDf/Wu77efO+jRsGkSaaOHfnoI8jKglNOgZkz4Ysv/FuXo2BwBoXQUPMPvG0bSlmIiZlHZaW0FEQf5fXC0qUwezaEhZmr6P7WlfTMMzBnDkyZAjkd/F97+20455yDJ9UHH4TKDlLQ/O1vYLfDD39ofrfZTHfSccfBpZea1oY/5OTA1Knw2GOmNRIaCmedBeedZ1pvzUpKTF0WLDAXnA89ZDIyz50LV10FxcVty/V6TVD74x/hySdNBue+Qmvdr7YZM2Zov1i4UOtJk7TWWu/b94hevhzd2Jjvn7KF8Kf339catH7jDa1fe838/Mc/BrtW3ffWW1pbLFqfdJLWo0drrZTWt92mtdN5cJ/XXtM6JETrOXO0rqjQ+uuvzee8667Dy6ur0zo6WuvLLjv8tfJyrbOytA4N1XrGDK0vv1zr++7T+r33tN69W2ufr3t1rq3V+sYbTR0yM7Vevtw873Rqfe+9WoeFaR0ebsp+7jmt4+O1ttm0vvNOrRsazL41NeZz2mxax8Ro/dhjWi9dqvWiRWZ/OLidc47ZP4CAtbob59ign+SPdPNbUPjVr8wfjtutq6vX6uXL0YWFL/unbCH86dxztU5KOngSveQScwJdvz4wxyss1PrVV7t/Au3MypVaOxxaz55tTrQ1NVpffbU59WRna715s9YvvWSCxrx5WldXH3zvBRdoHRWldUlJ2zL//nfz/pyc9o954IDWv/iF1qeeqvXQoW1Pvt//vtZFRZ3X+eOPtR450uz/85+beh9qzx6tf/CDg+Uef7z5LO3ZulXrU045uG9KiglWL7+sdXGx1n/+s/n8U6aYcttTXq71gw9q/emnnde9ExIUurJ0qfn4O3Zon8+jc3Ki9LZtP/VP2UL4y4EDJgD88pcHnysrMye7SZMOXpX6S0mJ1hMmmP8bzz7bu7I2bdI6NlbrsWMPP7G//bbWiYla2+2m5fC97x1+8t282bz2q1+1ff7YY7UeP777QauiQuvPPzetK7td6+Rk03I4VEmJOVmDadF05wT8n/9o/Y9/aO31dr6fz2eC2Ndft7/vhx+a1kRysqlrs61btb7uOtMqAa0XL+66Th2QoNCVL74wH7/pj2PjxjP0V19N8E/ZQnRXXZ3WjY0dv37ffebvdNu2ts9/+KF5vnWw6K3qaq1nzjQnzilTzFV6R1euXcnL0zotTevUVNNt054DB7Q+/3ytL7xQ6/r69ve57DLTVXPggPn9m2/M537kkZ7Va9MmradONWVcd535/n0+rV94QeuEBBOAb7+94/oE0tatWo8aZXow/vAHrU87zdTTbtf6qqtMQOkFCQpdKSszH//BB7XWWu/de59evhztdHbRtBTCHxobtX74YXMlPWtW+ychn89csc6b134Z111nrqQ/+aT39WloMH3+VqvW776rdW6u1pGRWp988pF3I5WXm1ZMdLTWGzb0rl47dpg63XST+f3GG81Js7S052U2NppgqpTW48aZzwimBfLtt72rb2+Vlpp/B9B6yBATHIqL/VK0BIXuSE7W+sc/1lprXVn5hV6+HF1c/Ib/yhfiUD6f1v/618E+6+OOM49XXHH4yXfFCvPaiy+2X1ZtrdZjxpj+6MsuO7w10V1utxnoBNO/3+zpp81zTz3V/bIKC00rIzTUP8FKa61/8hNT3nffmSD6P//jn3I/+cS0ZqKjzWfsqgvoaHG5TNdV64F4P5Cg0B3z52s9d67WWmuv16k//TRMb99+o//KF31ffr65sj0aVq0yf29gZsgsW2ae/+1vzXNPPNF2/0svNf3MdXUdl1lcrPWtt5o+Z4vFvOdIgoPXq/WVV5rjP/5429d8PjNYGxGh9a5dXZe1Z49p2YSHa/3f/3a/Dt0p12Yzs4DABEt/qa09ev/+QSZBoTuuucZMDWu6Qvv665P16tVT/Ve+6NsKCsy/f0ZGz/vOu+vJJ013RUqK1kuWaO3xHHzN69X67LNNf3bz4GZ5uelL/tnPuld+UVHb4HDBBVo//7zWe/e2v/+BA6ZVsHChOQ387nft77dvn7mSnj+/8yvpLVu0HjbMXMm3Hij1l+uvN/UcO9Y/s6IGIQkK3fHII+YraOqz2737d3r5cqVdrsFx5TCoeb1aL1hgTqIxMaY7Jy/P/8fx+Q62BBYubDvlsrXKStO/nZRkTsRPPGHec6SDi83BITFRt0yBHDnSdJM++6zWt9yi9eTJB19LSND67rs7P9E2z9R77LH2X1+71hwvJUXrjRuPrL7dVVBgAs6TTwam/EGgu0FBmX37j5kzZ+q1a9f6p7D//Mcsqc/JgXnzqKz8lA0bTiQr610SE8/2zzFE3/TEE/Dzn8Nf/wrTp8Opp0JyMnz6KQwd2r0yvF644w5wu+GmmyA9ve3rPp85xpNPwpVXmlW4IZ0kJt62DY45BsaNMzl27Hbo6d+6zwebNsHy5Wb79FOzOjg0FI4/3nzeU0+FadO6TjmtNZx9tsnnc8MNZlW1w2E2nw9+/3uIjzcpHsaM6Vl9u8PpNPWXTKg9opRap7We2eWO3YkcfWnza0shN9dcAT3zjNZaa4+nXq9YEap37PiF/44h+p7Nm82CqrPOOniF/MUXZrbN2LEHpz92xuM5OKfdYjFdP5dffnD2itNpVq6CuXLvbpfH228fvIp/+umefb6O6rt1a+fjE50pKDDjIGFhphus9YKwiRMD08oSfoV0H3WD12sWAY0Y0fJHvX79PL127Sz/HUP0LU6n1tOmme6OQ0/+K1eaQdUJEzpf9erxmNk+oPXvf2/GI2666eACo7POOjjN8YEHjryOf/qTGbCtrDzy9x4NPp/5HquqzGyj1uMjos+SoNBda9eaRToTJmhdUqJ37bpdL19u1W53B32/on/79a/Nn/1bb7X/+ooV5mp49GgzEOtytX3d7TZTItvLP1RaagZsExPN3PqlS3teTxlMFX7W3aAwOLOktjZjhsnHnpsLZ55JrHUW4KW6uv+lvO0zCgtN/3Nf89lncP/98KMfmWyc7TnhBDPWFBJisl5mZsIDD5j+eI/HPPfyy/CnP8Htt7d9b0IC3HUX7N0LO3aY7Jg9Jf3mIkgG90Bza++9B+eei2/+8Xy2eCVpo29j5Mg/+f84g8H3vmcGN++/H371q6N/fJ8PDhyAggLIzzePBQXmZG6zmVz8UVFdl/Hhh/DIIybARUSYG7qsWRO8zyVEL3R3oHlw3qO5PWefDc8/j+WHP2SyjmP3/cthZLAr1Q99+qkJCKNGwW23mVk0d97Z/pXv9u1m1k5VlZkBNH26ablNnGhO3h6POanv2WO2/fshMhKSkiAx0TwmJEBREWzcaE72GzaYn2tq2h4rNNRc9b/wQtcBAcyMnDPPNNuGDfDoo/D66yZP/i9+4Y9vSog+SVoKh2qaqliwEOJf3U1YWEbgjjUQnXiiOdlv326mL77wAvzmN+ZmIs2Bwecz99RdvNhMa8zKMife5hO53W6mh+7ff2S3NIyMNDdEyc42d8hKT4dhw8yWmNj11Muu+Hy9L0OIIJGWQk/deCOe775m6FN/p+CLR0g7uZNbAoq2mufDP/64OUEvXWqu0P/0J9NieOgh099+1VWwYoW5g9WSJWZdgM8HO3fCunWwfr25+h8xAjIyDm7DhplbUpaWmq2kxDzGxZn59pmZgT1pS0AQg4C0FNpTXIxv+BBKTgsn+e0qlJKTQZe0NoO0ubnm5O5wHHz+pptMC+yss0zQUMrc3vCqq2RAVYijpLsthW6d7ZRSNymlopXxnFJqvVJqQe+r2UclJ9N48Ykk/aeW6u/eCXZt+odPPoGVK+HXvz4YEMCc9P/8Z/jlL+H992HWLPj2WzMDSAKCEH1Ody+Bf6S1rgYWAHHAD4H7AlarPsB++59RXvA8dFewqxJYS5bA55/3rgyt4be/hbQ0+MlPDn9dKTOtc+tW+Phj0y0khOiTuhsUmi/pzgRe0lpvbvXcgGQdk0XNaZnEvLoJT1lBsKsTGB99BD/9KSxY0PMcO83lfPGFGVC229vfRykYP1765YXo47r7P3SdUuq/mKCwTCkVBfgCV62+QS2+g5A6aHj0f4NdFf9zOuH6683U0eRk09+fm3vk5TS3EtLTTZeQEKJf625Q+DGwGJilta4HbEAvlmv2D5HzrqLymDAcz7xjTqIDyYMPmlW3Tz1lFml5PHD66WY2z5FYtgxWrTKreztqJQgh+o3uBoVjge+01pVKqcuAO4CqwFWrb1BK0fjzRdhKXbieezTY1fGf3bvhnnvgwgtN19G4cfDuu7BvHyxcCPX1XZeRmwsPPwzXXWfGCHqT0kEI0Wd0Nyj8FahXSk0FfgHsAl4MWK36kNjz7qZmDGaO/ZEspOqrtIYbbzS5fR5tFejmzjVpIFatgksvPfyzNjSYlcJ/+INZEzBqlJlRFBcHzz1n1iMIIfq97gYFT1OWvR8Af9FaPwl0I1dA/+cIG0HZTyYTursM/fZbR+egBQXw5ZeBKfvdd83U0N/9ziwGa+2888z00bffhlNOMd1JkyebG6iEh5uVwr/9rckD9PDDprWwfj2cfHJg6iqEOOq6tXhNKfUp8CHwI2AeUAxs1FpPDmz1DndUFq8domj/S0TPuhxb6nhC1m4J/Pz6444zs4G+/tqka/CXujqTVyg62pzMbbb29/v9783Vf0rKwTQRw4aZweRTToHUVP/VSQhxVHR38Vp3g0Iq8D/AGq31SqXUcOBErfVR70IKRlDweuvJvS2BMQ83mtQNgew//+IL05UD5raJn37qv2mcv/413HefWWR2/PH+KVMI0S/4dUWz1roQ+CcQo5T6PtAYjIAQLFZrOL6rLqVihgV93XWwenXgDvbQQ6a75oknTP7/557rXXlam7GA224zZV95pQQEIUSHupvm4iJgNXAhcBHwlVLqgkBWrK8Zkn41W+704U2ONH3vhYX+P8iOHaY//7rrzBqCE04wefuLio68rN27TSK6rCwzFvDIIyYN9IMP+r/eQogBo7v9Erdj1ihcobW+HDgGuDNw1ep7oqNn40ibzdY/RaDKL2FaAAAgAElEQVTLy810TpfLvwd59FHTz3/DDWbc4umnzfTQW245snJ+8xsYOdKsHYiLM2sRDhyAd94xKaSFEKID3Q0KFq11cavfy47gvQNGWtrNlKXto/bPN5iunf/140rn0lJ4/nlzu8fmgdzx4804wMsvw3//271y3nkH7r0XLrvMtBY++8y0PCQYCCG6obsn9g+VUsuUUlcqpa4E3gc+6OwNSqmlSqlipdSmDl5XSqnHlVI7lVLfKKWmH1nVj76kpPMJDR1G7jFfmzn6Tz1lBp794a9/NWsBDm0VLF4MY8eaE3tXi8r27TOD4NOnw7PPmnsQCCHEEejuQPOtwBJgStO2RGt9Wxdvex44vZPXzwDGNG3XYBbI9WkWi41hw26gouJjam//HzM987rrTObP3mhsNAPLZ55ppoy25nCYbqTcXHP3so643XDJJSZdxWuvScoJIUSPdLsLSGv9ptb6lqaty1VcWuscoLyTXX4AvKiNVUCsUmpId+sTLEOHXo3FEkZ+4ZPw6qvmbl+nnmrGAWpre1boSy+Zu4j98pftv37SSWbW0IMPmruaeTyH73PXXWY665IlMHp0z+ohhBj0Og0KSqkapVR1O1uNUqq6l8ceBuS1+j2/6bk+zWZLICXlcoqK/oErymduH3nTTaYrKSur/VZDQ4MZE3jkETM9tPXaEJ/PrA6eNs3c37gjDz8M3/ueOda0aeZ2ls2WLTPrD66+Gi6+2F8fVQgxCHUaFLTWUVrr6Ha2KK119NGqpFLqGqXUWqXU2pKSkqN12A6lpd2E1k7273/GpHx47DGzIMzhMK2Gn/zE5BB64AHze1wcnHYa/OIXZnpoVpZJSJebCx98AN99Z1oJna2Ujo832Uzfesvc4P6kk0wAWLPGDE5nZZl6CCFELwT0Hs1KqQzg/7TWWe289gywQmv9StPv32FWSR/orMxgrGhuzzffnEFt7QbmzNmLxdKUDK6x0eQUeuAB0wIAc7I+9VSTjXTSJJN36OWXTRABc4P7uDjYtavjtBOHamiA++83W2OjyUu0Zs3h4xFC+JHHA1Zrx9cuWptMKhUVpifVajV/0iEh5tFmM3/unQ13eb3m/c1ltN7q6kwdfL62m91uJte13iIizIS+wsKDW1GRKT8kxNSt+dFiMZ+peWtdF4+n7dZ8umzeTymzX2Nj283tNvVyOCAszGwOhymjocFs9fXm0e029WjeLBbz2Pydtn486ywzG74nuruiOaRnxfvFu8ANSqlXgdlAVVcBoS9JS7uZb745neLi10lNvcw86XCY6aCXXAKbN5vFZ0OHtn3jtdeabd8+Mybx9tvws591PyCA+Qu7+2644gqTtfTssyUg9GFamxOH220aeVVVbTev1ySZbb0pZfatqYHqavNYW9v9RL0+nznp1Nebk2nzzx6PKcPnM4/N5VksB0+OFot5vbr64FZVdfCWIuHh5qTb/OjxmJN4ZaX5jF1xOCA21mwxMeb7KSszW2Vlz77jYGs+6TdvISFmGVNzAGhoODgUGBZmvrvmYGGzHfy3aP3v0jrwND+OHx/4zxKwloJS6hXgRCARKAJ+i7k5D1rrp5VSCvgLZoZSPXCV1rrLJkBfaSlorVmzZhIWSxgzZqxFyU3o+ySfz5xsDhyA4mLzHzYm5uAWFWWu7A4caLuVlR28kmu9NZ9cm7eGBnOybP6P3Lw1n3yb/6MHQ+uTd/PWfHXc3hVp85W31uYEFB19cIuJMVf5bnfbQFNXZ8qIizMn+bg4s0VFmbI8HvOe5seaGnPir6oyjxUV5lgJCW235jIiI81naH602Q4GsOatocH8e5WWHtxqaswNBVNTzZaSYn5vPgE3//s0tzy0PvyqPCSk7XZoK6n1qbM7//27amkFWtBbClrrS7p4XQPXB+r4gaaUIi3tJrZvv5aqqs+IjZ0X7CoNKM0nkNZXq81Xy80no0O35i6Gujpzwtm/33QbdOfqtT3NV3Ktr+qaT64xMQeft9vbNv9bn3gP/Tkqqm1Qiok5eFXpdptHl8ucqKKizBYdffAEGdLN/7HNJ/bBIj29+/s2n+R760i/X38c82joJ9Xsm1JSfsju3XewZ8/vmDr1I2kttMPlOtg1UFZmZt4WFx98LC42V4vNXRTNjw0N3T9G8xVx6y0mxtxQbuhQsw0ZYq4UGxsP774JCzOvt94SEvyXnDYY5E9R9JQEhV6wWsMZMeJOdu68ifLyD0lIOCPYVTpqfD7TTC8ogLw8M0TSetu/3wSBzpZuxMdDUtLBLoORI83JvHW3RfPWfNXc3I3QvIWH9++TtxB9jQSFXho69Fry8x8nN/dXxMcvQClrsKvkF82Df9u3H9x27oT8fBMIDhw4vFvGbofhw802f/7h/cTx8eZqPTnZ/H4kY+tCiKNDgkIvWSyhjBx5L1u2XERh4fMMGfLjYFfpiFRWmmUSO3eazN3Njzt2mG6dZiEhZvF2erqZVDVsmOmWab4h2/Dh5mQv3RZC9G8SFPwgKekCoqPnsHv3nSQnX4zVGhHsKh1Ga9izBzZsMNvGjeZx796D+yhlTu5jxsCiRaZPfuxYs40YIVf2QgwGEhT8QCnFqFEP8fXXx5OX9wgZGcG/1UR9vbnN85dfHtyKm5KfWyzmRH/ssWbJxMSJJhBkZpopm0KIwUuCgp/ExMwlMfFc8vIeYOjQawgNTTmqx3e54Kuv4KOPTPqlNWsOLpYZMwbOOAPmzDFZtbOyzACtEEIcSoKCH40ceR+rV7/Lnj2/Y+zYpwJ+vH37zD11li0z+fHq6kwrYNYsuPVWOO44Ewjk/jpCiO6SoOBH4eFjGTr0p+zf/wzDhv2ciAj/r0nfutXkxPv3v02CVjCZsi+/3KRYOukks7JUCCF6QoKCn2Vk/JaiopfIzV3M5Mlv+6XMXbvgn/+EV16BbdvMc7Nnm2zZ555rxgeEEMIfJCj4WWhoMsOH38bu3XdQVfU5MTFze1ROSQm8/jr84x8mC7dSZiroDTfAOeeYqaBCCOFvshY0ANLSbiY0NJXc3MUcScJBn8/ci+e888wagBtuMLOI7r/fTB1dvhyuv14CghAicKSlEABWawQjRtzFjh0/o6zsfRITv9/p/qWl8Pzz5lbMu3aZgeGbbzb3zpky5ejUWQghQFoKATNkyE8ICxvN7t2/RuvDk+BrbbqFLr8c0tLMbKGhQ839d/Lzze2YJSAIIY42CQoBYrHYyMy8h7q6TRQV/aPl+bo6ePZZmDHDLB57+21z985vv4WcHHN/ns7uTCWEEIEk3UcBlJR0AZGRM9i9+y6czkU8+qiD55836ZonTzbdRZdeajJ/CiEGH6/PS5277rDnQywhhNuCs8JUgkIAKWUhIeEh7rjjS958MwSfDy64wNx9c+5cSR4n+ievz0tFYwVl9WWUNZRR56rD4/Pg8Xlw+9x4fB5CraHMGjqLYdFHf1ZEnauOz/M+J9oeTXJEMknhSUSGRrbc78SnfVQ0VFDWUEZZfRmVjZXUuGqoddVS46yhxlWDT/uYNXQWx6UfR4wjpsNjaa3xai9WZW1zPxWtNVXOKorriimpK6GkvoTiumLyqvLYW7WXvVV72Ve1j/zqfDw+T7tlp0SkMD5xPOMSxjEucRzjEsaRnZod8O9UgkKAOJ3w5JNwzz0nUl5+Iqee+i+efPI0xoyJDnbVBq0aZw0RoRFYVNe9pl6fl5L6EopqiyisLaSorojyhnJSI1MZHT+a0fGjiXUcvkrQ6XFSXFdMUV0RRbVFLY+FtYWUNZQRGRpJYngiSeFJJIYnkhieiD3Ejtfnxau9LY8WZSE+LJ6EsAQSwhOIdcS21NvpcVLZWNmy7a/Zz57KPeyt2sueyj3sqdxDSX0JodZQ7FY79hA7jhAHdqudEEsIVosVq7K2PEbZo0iNSCUlMoXUyFRSIlKICI0gryqvpbw9VXvYW7mXkvoSKhoq0HRvVt2ImBEcl34cx6Ufx5y0Obi8LvKq8sirziO/Op+86jzKG8pp9DTS4G4wj54GnB5nS4Dx+Dy4vW40mpMyTuKGY27grDFnYbW0TVNf0VDBX1b/hT9/9WfKGsravGa32kkMT6TB03BE9bcoC1NTpjJ/xHzmps+l0dPIjvIdZiszj9XO6jb7W5SlJVi0V96wqGGMiB3B3PS5DI8ZTkJYwmE36Gr0NLKzfCfflX3HG1vfoLyhHIBfHvtLHlzwYLfq3lMBu0dzoPSVezR3RGt47TVYvNhMI12wAO68cysez0RGjLiDzMw/BLuKfV5ZfRnby7a3nPSqnFVUNlZS7axGa41FWbBarC3/ASNDI1uuCJMikkgKT8KnfWwo3MD6A+v5uvBr1h9YT0FNAY4QB5mxmWTGZTIydiQj40bi0742J6n86nwKawvx6c5vrpwQlsDo+NGEWEIoriumuK6YKmdVu/tGhUaRGJ5InbuO0vrSLss+lEVZiLHH0OAxJ872RNgiyIzLJCM2g+TwZDzaQ6OnEafHidPrpNHTiMfnaROAPD4P1c5qiuqKqHfXt1tuUngSGbEZjIgdQXJ4MonhiSSEJ7QErMjQSGwWGyGWkJatxlXDV/lf8Xne53ye9zn7a/YfVm5kaCTp0ekkhCcQFhJGmC0MR4iDsJAw7FY7Nqsps7lsp9fJ65tfp6CmgBExI7h25rX8eNqP8Wovj375KE+tfYpaVy1njz2b62Zeh0/7KKkvablSL60vJSwkrE3d48PiiXPEEWWPIio0iih7FJGhkbi9blblr2LlvpXk7M1hVf4qGjwNLf8WI2JGMCZhDGPjx5IckYxP+1o2r/aiUCb4N/09JkckkxSRREpECjbrkacbLq0v5bvS70gMT2Rc4rgjfj90/x7NEhT8aMsWs7Zg+XLIzjYziE45xby2efPFlJW9x+zZO7Dbhx71ujk9TgprC0mPSe/WlfKhKhsr+SLvC1xeV5vntdY0ehqpcdW0NL2bH6ucVVQ1VlHtrKbKWUW9u5606DRzpR1nrrZHxY+itL6UdfvXse7AOtYfWM/eqr3t1iHEEoJFWfD6vPi0r1tXexZlYXzieKYPmc7ExImUN5STW5lLbkUuu8p3UeOqAQ6eoNKi00iPTmdo1FCGRA0hJaLp6jkyhfiwePbX7Gdn+U52lO1gZ/lOdlbsRGtNckRyy5YSkWIeW115h9nCWurk0z4qGysprS+lpK4El9fV5uo9xBKC1+elvKGcsoYySutLW7o5wmxhxDpi22zJEclkxmYSHxbfq1vC1rpqTauotohaVy3pMemMiBlBRGjvUsFrrcmrzmNNwRrCbeGkx5jvOcYec8T19fg8vLPtHZ5c8yTL9yzHbjWzMtw+NxdNuohfH/9rpqT4f9qey+vim6JviLBFMDJuJPaQ/jcbRILCUVRTA7//PTz2mLll5J/+BFdfbW7W3qyhIZc1ayYRF7eArKy3/XY/55I6cwXk9DpxeV04PeaxpL6EzcWb2VK6hS0lW9hRtgOv9pIckcypI09lwagFnDryVIZEDemw7F3lu3j3u3d5b/t7rNy3ssO+z0NF2CKIskcRY48hxhFDtD2aGHsMYbYw9lXtY2f5znavHEfHj2bGkBnMGDKDiUkTiQ+Lb3Pyc4Q4Duu39WkfNa6aw/pufdpHdmo2U1KmdDhgp7WmvKGcEEsI0fZoucd2P7OlZAvPrH0Gr/Zy0+ybGJMwJthV6tMkKBwl//qXWWi2f7+ZWnrvvR1nJc3Le5hdu37JhAmvkJJyMWCuGhWqWyckr8/L5pLNfJH3BZ/nfc4XeV+QW5Hb4f4WZWF0/GgmJU1iYtJEhkQO4Yv8L/ho10eU1JcAMDl5MiNiRxz23l3lu9hauhWASUmTOHvs2Zw++vR2B90cIY6WpneELeKwvt721LnqzNV6xS5i7DFMHzK90wE9IUTvSFAIsMpKk3Li5ZfNPQr+/ISbyJGb+Sr/K1YXrKa8sZyhkUNJi05jWPSwpuZyFB+tu4TtFfupsp/CtrJdbC/bTmpkKvOGz2P+iPnMGz6PCUkTsCgLZfVlfFXwFV/mfcmqglWsLljdMqiVEpHC3OFzOTbtWNKj082gYoidUGsoodZQ4hxxjE0Y224z16d9bCzcyH93/ZePd3/cMojVWmJ4ImeOPpOzx53NyLiRAf8+hRCBJUEhgFauhMsug/zSSubf9giuYf+PrwvXtwxEJYQlkBqZyv6a/VQ0Vhz2fgWkR0YybdjJjEsYx96qveTszeFA7YGW98eFxbGzfCdgrvinpExhzrA5zB0+l+PSjyMzNlO6O4QQ3dbdoCBTUo+A2w133w333u8l4dRniZ53B5+6yzhWHcu1M6/lmGHHcMywY9qcsOvd9RRUF5BfnU95Qzmj4kfhqP03hfl/ICvrKhITfwCY/u3cilxy9uaQsy+HqsYqfjztx8xJm8PMoTOJDJUVbkKIwJOWQjft3QsXXghrSpYT9z83UxH6DfNHzOex0x5j2pBpR1SWz+dm3bpZuN3FzJq1GZstLkC1FkIIo7stBcl91A1r1sDM7+Xx9djz4crvEZ1Uxb8u/BcrrlhxxAEBTF6k8eOX4nIVs2vXLwJQYyGE6BkJCl14620fc29+irJLJmIb/yF/POmPbL1+KxdMvKBXffpRUdMZPvxWCgv/Tnn5Mj/WWAghek6CQge0ht88/B3nvXsi7gXXMy9jDpuv38Tt829vsxCpN0aM+C3h4RPYtu1KXK5iv5QphBC9IUGhHY0uN8fddi/3Vk7FNuxbnj7j76z48X/JjMv063GsVgcTJ76K213Btm1Xoo8w9YEQQvjboJ99VFBdwOd5n7O1ZCtbS7eypWQLW4q2441wMtZ9Act/9QRDo1MDdvzIyCmMHv0wO3bcQH7+n0lP/9+AHUsIIboyqINCeUM5k56aRJWzCoUiMy6TOM8EvF+cxkWzTua1e04/KvUYOvRnVFR8TG7ubcTGzicqasZROa4QQhxqUAeFFze+SJWziv+75P84KfMkqsvCycqCGRnwj7uPXj2UUowb9xxr105ly5aLmTFjPSEhUUevAkII0WTQjilorXlm3TPMHjabs8aeRVhIOFdfDbW18NJLYDvy7La9YrPFM2HCP2loyGXHjuuP7sGFEKLJoA0KOXtz2Fa6jZ/O+CkAS5fC//0f3HcfTJgQnDrFxs5nxIg7KSp6icLCl4JTCSHEoDZog8Iz654hxh7DoqxF5OaaTKcnnQQ//3lw6zVixB3ExMxn+/ZrqanZENzKCCEGnUEZFErrS3lz65tcPvVy7JZwrrwSLBZ4/nnzGEwWSwgTJ76GzRbPpk0LcbmKglshIcSgMiiDwvMbnsfldfHTGT/lkUdM1tMnnoDhw4NdM8NuTyUr6x3c7lI2bToPn88Z7CoJIQaJQRcUfNrHM+ue4fjhx5MZOYm77oIf/AB++MNg16ytqKjpjB//AtXVX7B9+3X0t8SFQoj+KaBBQSl1ulLqO6XUTqXU4nZev1IpVaKU2tC0/SSQ9QFYvns5O8t38tMZP2X1amhsNHdM64u3JkhOvpARI+6isPDv5Oc/GuzqCCEGgYAFBaWUFXgSOAOYCFyilJrYzq6vaa2zm7ZnA1WfZs+se4b4sHgumHgBn31mnps7N9BH7bmMjN+SmHg+u3bdSlnZf4JdHSHEABfIlsIxwE6tda7W2gW8CvwggMfrUmFtIW9te4srp16JI8TBypWQlQVxffh2BkpZmDDhBSIjp7Bly8XU1KwPdpWEEANYIIPCMCCv1e/5Tc8d6nyl1DdKqTeUUuntFaSUukYptVYptbakpKTHFfr713/H4/NwzYxr8Hjgiy/g+ON7XNxRY7VGkJX1DiEhcWzY8D2qqr4MdpWEEANUsAea3wMytNZTgI+AF9rbSWu9RGs9U2s9MykpqUcH8mkfS9Yv4cSMExmXOI5vvzWrl+fN63nljyaHYzjTpuUQGprExo2nUlGxIthVEkIMQIEMCgVA6yv/tKbnWmity7TWzfMtnwUClgnuv7v+y57KPVw741rATEOF/tFSaOZwDCc7OweHYwTffnuG3JxHCOF3gQwKa4AxSqlMpVQocDHwbusdlFJDWv26ENgaqMqkR6dz3czrOHfCuQB89plZl9BX1iZ0l90+hOzsFYSFjePbbxdSWvpu128SQohuClhQ0Fp7gBuAZZiT/eta681Kqd8rpRY27fZzpdRmpdRG4OfAlYGqz6TkSTx11lOEWkPR2rQU+lMrobXQ0CSys5cTGZnN5s3nU1z8erCrJIQYIAKaOltr/QHwwSHP3dXq518Dvw5kHdqTmwuFhf1nPKE9NlscU6d+xLfffp8tWy7B52sgNfWKYFdLCNHPBXugOSia1yf015ZCs5CQaKZM+Q9xcd9j27YrKSh4OthVEkL0c4MyKKxcadYmTGxvKV0/Y6arvkd8/Fns2HEdeXmPBbtKQoh+bFAGhc8+M6uYg50R1V+sVgdZWf8mKekCdu36X/bu/VOwqySE6KcG3e04i4vhu+/gqquCXRP/slhCmTDhFSwWB7t3347XW0Nm5j0oNUAinxDiqBh0QeHzz81jfx5k7ojFEsL48S9gsUSwb9991NVtYcKEFwkJiQl21YQQ/cSgu4z87DOw22FGwJbJBZdSFsaO/SujRz9OWdn7rFs3m7q6gC3/EEIMMIMuKKxcCbNnm8AwUCmlSEu7kezsT/B4Kli//hhKSt4KdrWEEP3AoAoKdXWwfn3/n4raXbGxJzBjxjrCwyeyefN55Obegc/nDna1hBB92KAKCqtWgdc7eIICgMORRnb2p6Sm/ph9++5hzZrJlJa+J3dyE0K0a1AFhc8+M3dYO+64YNfk6LJaHYwb9zeyst4BNJs2LWTjxpPl3gxCiMMMuqAwZQrEDMLJOEopEhMXMmvWJkaPfoLa2m9Yt24mW7deQUPDnmBXTwjRRwyaoODxwJdfDsypqEfCYrGRlnYDc+bsIj39VoqLX+Wrr0axadN5VFSskG4lIQa5QRMUNmwwA82DaTyhMyEhMYwadT+zZ+9i+PDbqKzMYePGk1i7dir79z+L19sQ7CoKIYJg0ASF/HyIj5egcCiHI42RI//EscfmMW7cc4Bi+/arWbUqg/z8J/D5nF2WIYQYOFR/6y6YOXOmXrt2bY/e6/MNnHxHgaK1pqoqhz17fkdl5XIcjgwyMn5PSsr/oJQ12NUTQvSQUmqd1npmV/sNqlOkBISuKaWIjT2BqVM/YcqUZYSExLNt2+WsXZtNaem7aO0LdhWFEAEkp0nRLqUU8fELmDFjDRMnvobP52TTph/w5ZfD2bnzF9TUrJNBaSEGoEHVfSR6zudzU1LyJsXFL1Ne/iFauwkLG0Ny8iWkpl5OWNioYFdRCNGJ7nYfSVAQR8ztLqek5N8UF79CZeVyAOLjz2DYsBuIjz9N0nUL0QdJUBBHhdNZwP79f+PAgWdwuQoJCxvN0KE/IzX1Cmy2+GBXTwjRRIKCOKp8PhclJW9SUPAk1dXmphUOxygiI6cQETGFyMipREZOxeHIRCkV5NoKMfh0NygMupvsiMCwWEJJSbmElJRLqKn5mrKy96ir+5ba2m8oLX0bMBcfDkcG8fFnkpBwJrGxJ2G1hge34kKINiQoCL+LippGVNS0lt+93nrq6jZTU7OW8vIPKSx8nv37n8JicRAbeyLR0XNwOEYRFjaasLBR2GyJ0poQIkgkKIiAs1rDiY6eRXT0LIYNuw6fz0llZQ7l5f+hrOwDysuX0dySMPtHEx4+lsjIbCIjpzVtU7BaI4L3IYQYJGRMQQSd19tIY+MeGhp20ti4i4aGndTVbaW29ms8nvKmvRRhYWNwOIYTGppKaGgqNlsKoaGphIePISJiClZrWFA/hxB9mYwpiH7DanUQETGeiIjxbZ7XWuN05lNb+3XT9i0u136qqj7H5TqAz9fYam8L4eHjiYqaTmTkNKKiZhAVNVNaF0IcIQkKos9SSuFwpONwpJOYuLDNa1prvN5qnM4D1NdvbQkcFRXLKSr6R9NeViIjpxAdfSzR0ccSFTUTrd243aVtNpstiejoWURETMZiCT36H1SIPkS6j8SA43IVU1OzlurqL6mq+oKamtV4vbVdvk8pO5GR2URHH0NkZDZ2+zBCQ4cSGjoEmy1BBr9FvybdR2LQCg1NJiHBTHsF0NpLXd0mams3YLGEY7MlttoScDr3U1OzmpqaNVRXr+bAgaX4fHVtylQqtGksIwWbLZnQ0GRstiRCQ5Ox29NwODJxOEZK8BD9ngQFMeApZW1ZPNeesLAMwsIySE6+CDBBpLFxD07nAVyu/bhcB5p+PoDbXYzLdYC6um9wuYrQ2tWmLKs1Cocjk9DQVLR24fM1ttrchIWNJjIym6ioaURGZhMWNlpSkos+RYKCEIdQykpY2Kguk/w1j2s0NubR2LibxsZcGhpyaWzMxeUqxmKxY7VGYbMlY7E4UMpCff028vMfQWs3ABZLBDZbIlq70NqNz+dqes2CwzEchyMDh2MEDkcGdvtwLJYwlLI2BRILSlnx+Zx4vVV4PAc3rd3Y7elN7zebzRYb+C9P9HsSFIToIaUUISExREbGEBmZ1e33+Xwu6uq2UFu7oWnabRUWSyhK2VoetXbT2LiPxsY9VFevxuMpO4J6hTYFi7a3VLVao7Fao7BYQrFY7Chlx2KxY7E4sFojsVojsFojsFgiCAmJwW5Pawos6djtwwkJiUVrD253CS5XYcumVCjh4WMJCxvbrcCjtcbtLqWhYTv19d+hVAhRUccQHj5Wkin2ARIUhDjKLJZQoqKyiYrKBq7s1ns8nhqczjx8PidaewEfWnvR2ovFYickJIaQkBis1hisVgdaazyechob97Ta9uL11jWV4cLnczZtDbhcRfh8dXi9ZvN4qgDvIfUOa5oG3PHkFJstibCwsTgcI1DK0nTPDbOZbrm9NDR8h8dTedh7rdZooqJmER09m8jIaU0D/WYtSiDq2vcAAAiySURBVFfpULzeBmpq1lFdvYrq6lU0Nu4hOno2cXEnExt7EjZbXLe+ZyGzj4QQ7dDai8tVhNOZR2PjPpzOPJzOAqzWqJbFg80D7z6fs+mqf3vL1b/TmddUkgJU0+C7Bbs9jfDwcYSFjSU8fBzh4WPx+Rqprl5NTc1qqqtXU1f3DVp72tTHao3EZkvBao3EYnG0tHAsFgcu135qaze0vMfhGInDMYLq6tVNEwYUkZHTiYv7HhZLGB5POW53BR5POR5PBV5vQ1OXnAXTJWdBqdCmiQSpLYEpNDS5qcuwBq+3tmVTKgS7fSh2exqhocOw24cREhKDy1Xc9L01b/mEhMQRFjaqKa3LqDbBSmuNz1ePx1OF11uH1RpJSEhMU5dh7ycvSJZUIUS/5PU2UF+/tal7qqjl0e0uwuutbxq0d7YM4Nts8URHz2naZhMamgKYbrrq6tVUVn5CRcUnVFevQmtPU6sqjpCQeGy2OCyWMJpbMuZ2sz58PmdLN5nHU9GDT6E4tEWllB2tnW2eCwmJJyQktikQVB0WDM37bC2twGHDfkZ6+i09qI9MSRVC9FNWaxhRUdN7XY7FEkps7PHExh5PRsZv8flcrQbpu8/nc+FyFeN2FwHWpvGXSEJCorBYwtDa3TQ7rQCnMx+nswC3u5zQ0FQcjuHY7enY7enYbAn4fPU0NOTS0LCrJa2Lx1PT0v1ntlgslnC83tqWYOHxVOLxVBEamtrr76UrEhSEEINCT1erWyyhOBxpOBxp7b6ulL1lWnNXrNYIIiMnExk5uUd1ORpkqF8IIUSLgAYFpdTpSqnvlFI7lVKL23ndrpR6ren1r5RSGYGsjxBCiM4FLCgo03H3JHAGMBG4RCk18ZDdfgxUaK1HA48C9weqPkIIIboWyJbCMcBOrXWuNrkAXgV+cMg+PwBeaPr5DeBkJYljhBAiaAIZFIYBea1+z296rt19tJmLVQUkBLBOQgghOtEvBpqVUtcopdYqpdaWlJQEuzpCCDFgBTIoFADprX5Pa3qu3X2UUiFADHBYkhet9RKt9Uyt9cykpKQAVVcIIUQgg8IaYIxSKlMpFQpcDLx7yD7vAlc0/XwB8P90f1tiLYQQA0hA01wopc4EHgOswFKt9T1Kqd8Da7XW7yqlHMBLwDSgHLhYa53bRZklwN4eVikRKO3he/uygfi5BuJngoH5ueQz9Q8jtNZddrX0u9xHvaGUWtud3B/9zUD8XAPxM8HA/FzymQaWfjHQLIQQ4uiQoCCEEKLFYAsKS4JdgQAZiJ9rIH4mGJifSz7TADKoxhSEEEJ0brC1FIQQQnRi0ASFrjK29hdKqaVKqWKl1KZWz8UrpT5SSu1oeuxXN6RVSqUrpZYrpbYopTYrpW5qer7ffi6llEMptVoptbHpM/2u6fnMpozAO5syBPcsyX8QKaWsSqmvlVL/1/T7QPhMe5RS3yqlNiil1jY912///npjUASFbmZs7S+eB04/5LnFwCda6zHAJ02/9yce4Bda64nAHOD6pn+f/vy5nMD3tNZTgWzgdKXUHEwm4EebMgNXYDIF9zc3AVtb/T4QPhPASVrr7FZTUfvz31+PDYqgQPcytvYLWusczEK/1lpnm30BOOeoVqqXtP7/7d3Pi1VlHMfx96eSMCeSxCSUEmtRBDISCKXBYNQmiRb9gFSiTZs2LqIwisA/oB+LIKEWRlNk5dQ2Mxly0S9tqCg3RQvFnE1WExQxflo8zz1OM5Izd3LuHO/nBcO957mXw/OF59zvOc+Z83180vbR+v53yg/Oalocl4uJurmk/hnYQqkIDC2LCUDSGuAe4NW6LVoe039o7fibj35JCrOp2Npmq2yfrO9/Blb1sjPzURda2gB8RsvjqtMsY8A4cAD4ATjts6uzt3Ecvgg8CZyp2ytof0xQEvaHko5Ieqy2tXr8dStrNF9kbFtSK/+lTNIA8B6w0/ZvU5fWaGNctieBQUnLgRHgph53aV4kbQXGbR+RNNTr/vzPNts+Ieka4ICkY1M/bOP461a/XCnMpmJrm52SdC1AfR3vcX/mTNISSkIYtr2/Nrc+LgDbp4FDwG3A8loRGNo3DjcB90r6iTIFuwV4iXbHBIDtE/V1nJLAN3KRjL+56pekMJuKrW02tdrsI8AHPezLnNV56deA720/P+Wj1sYlaWW9QkDSUuAuyr2SQ5SKwNCymGzvsr3G9lrKMfSx7W20OCYAScskXdl5D9wNfEuLx9989M3Da+eq2NrjLnVF0lvAEKWK4yngOeB9YB9wHaWC7IO2p9+MXrQkbQY+Ab7h7Fz105T7Cq2MS9J6ys3JSyknX/ts75a0jnKWfTXwFbDd9l+962l36vTRE7a3tj2m2v+RunkZ8Gat6LyClo6/+eibpBAREefXL9NHERExC0kKERHRSFKIiIhGkkJERDSSFCIiopGkELGAJA11qotGLEZJChER0UhSiDgHSdvreghjkvbU4nYTkl6o6yMclLSyfndQ0qeSvpY00qm7L+lGSR/VNRWOSrqh7n5A0ruSjkka1tQiTxE9lqQQMY2km4GHgE22B4FJYBuwDPjS9i3AKOVpcoDXgadsr6c8ld1pHwZermsq3A50Km5uAHZS1vZYR6kpFLEopEpqxEx3ArcCX9ST+KWUYmhngLfrd94A9ku6Clhue7S27wXeqbV0VtseAbD9J0Dd3+e2j9ftMWAtcPjChxVxfkkKETMJ2Gt7178apWenfa/bGjFT6wJNkuMwFpFMH0XMdBC4v9bW76zVez3leOlUA30YOGz7V+AXSXfU9h3AaF1B7rik++o+Lpd0xYJGEdGFnKFETGP7O0nPUFbiugT4G3gc+APYWD8bp9x3gFJW+ZX6o/8j8Ght3wHskbS77uOBBQwjoiupkhoxS5ImbA/0uh8RF1KmjyIiopErhYiIaORKISIiGkkKERHRSFKIiIhGkkJERDSSFCIiopGkEBERjX8A/9iQOMafRGoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 890us/sample - loss: 1.0904 - acc: 0.6719\n",
      "Loss: 1.0903628553928244 Accuracy: 0.6718588\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1243 - acc: 0.3067\n",
      "Epoch 00001: val_loss improved from inf to 1.55428, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/001-1.5543.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 2.1242 - acc: 0.3067 - val_loss: 1.5543 - val_acc: 0.4997\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4237 - acc: 0.5414\n",
      "Epoch 00002: val_loss improved from 1.55428 to 1.27438, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/002-1.2744.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.4237 - acc: 0.5413 - val_loss: 1.2744 - val_acc: 0.5954\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2156 - acc: 0.6175\n",
      "Epoch 00003: val_loss improved from 1.27438 to 1.10489, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/003-1.1049.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.2155 - acc: 0.6175 - val_loss: 1.1049 - val_acc: 0.6560\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0650 - acc: 0.6675\n",
      "Epoch 00004: val_loss improved from 1.10489 to 1.01711, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/004-1.0171.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.0650 - acc: 0.6675 - val_loss: 1.0171 - val_acc: 0.6795\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9360 - acc: 0.7130\n",
      "Epoch 00005: val_loss did not improve from 1.01711\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.9360 - acc: 0.7129 - val_loss: 1.1054 - val_acc: 0.6508\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8312 - acc: 0.7451\n",
      "Epoch 00006: val_loss improved from 1.01711 to 0.83001, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/006-0.8300.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.8314 - acc: 0.7450 - val_loss: 0.8300 - val_acc: 0.7501\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7405 - acc: 0.7761\n",
      "Epoch 00007: val_loss improved from 0.83001 to 0.79698, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/007-0.7970.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.7404 - acc: 0.7761 - val_loss: 0.7970 - val_acc: 0.7692\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6745 - acc: 0.7940\n",
      "Epoch 00008: val_loss improved from 0.79698 to 0.78419, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/008-0.7842.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6745 - acc: 0.7940 - val_loss: 0.7842 - val_acc: 0.7717\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.8152\n",
      "Epoch 00009: val_loss did not improve from 0.78419\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6022 - acc: 0.8153 - val_loss: 0.8549 - val_acc: 0.7494\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5464 - acc: 0.8327\n",
      "Epoch 00010: val_loss improved from 0.78419 to 0.74132, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/010-0.7413.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5464 - acc: 0.8327 - val_loss: 0.7413 - val_acc: 0.7838\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5000 - acc: 0.8471\n",
      "Epoch 00011: val_loss did not improve from 0.74132\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5000 - acc: 0.8471 - val_loss: 0.7642 - val_acc: 0.7822\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4524 - acc: 0.8587\n",
      "Epoch 00012: val_loss improved from 0.74132 to 0.73630, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/012-0.7363.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4524 - acc: 0.8588 - val_loss: 0.7363 - val_acc: 0.7927\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4090 - acc: 0.8731\n",
      "Epoch 00013: val_loss did not improve from 0.73630\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4089 - acc: 0.8731 - val_loss: 0.7863 - val_acc: 0.7920\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3709 - acc: 0.8840\n",
      "Epoch 00014: val_loss did not improve from 0.73630\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3710 - acc: 0.8840 - val_loss: 0.7791 - val_acc: 0.7873\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3446 - acc: 0.8916\n",
      "Epoch 00015: val_loss improved from 0.73630 to 0.73621, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/015-0.7362.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3447 - acc: 0.8916 - val_loss: 0.7362 - val_acc: 0.8015\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3100 - acc: 0.9017\n",
      "Epoch 00016: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3101 - acc: 0.9017 - val_loss: 0.7578 - val_acc: 0.8020\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2849 - acc: 0.9089\n",
      "Epoch 00017: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2849 - acc: 0.9089 - val_loss: 0.8109 - val_acc: 0.8036\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2545 - acc: 0.9181\n",
      "Epoch 00018: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2545 - acc: 0.9181 - val_loss: 0.8054 - val_acc: 0.7948\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9244\n",
      "Epoch 00019: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2362 - acc: 0.9244 - val_loss: 0.8351 - val_acc: 0.7997\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2240 - acc: 0.9283\n",
      "Epoch 00020: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2240 - acc: 0.9283 - val_loss: 0.8424 - val_acc: 0.7927\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2067 - acc: 0.9327\n",
      "Epoch 00021: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2067 - acc: 0.9328 - val_loss: 0.8392 - val_acc: 0.7983\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9398\n",
      "Epoch 00022: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1885 - acc: 0.9398 - val_loss: 0.8675 - val_acc: 0.7990\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9410\n",
      "Epoch 00023: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1820 - acc: 0.9410 - val_loss: 0.8880 - val_acc: 0.7948\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9443\n",
      "Epoch 00024: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1720 - acc: 0.9444 - val_loss: 0.8663 - val_acc: 0.8083\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9473\n",
      "Epoch 00025: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1653 - acc: 0.9473 - val_loss: 0.8060 - val_acc: 0.8213\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9507\n",
      "Epoch 00026: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1556 - acc: 0.9507 - val_loss: 0.8698 - val_acc: 0.8111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9517\n",
      "Epoch 00027: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1489 - acc: 0.9517 - val_loss: 0.8396 - val_acc: 0.8171\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9524\n",
      "Epoch 00028: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1439 - acc: 0.9524 - val_loss: 0.8545 - val_acc: 0.8116\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9550\n",
      "Epoch 00029: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1403 - acc: 0.9550 - val_loss: 0.9271 - val_acc: 0.8039\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9588\n",
      "Epoch 00030: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1310 - acc: 0.9588 - val_loss: 0.8583 - val_acc: 0.8150\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9611\n",
      "Epoch 00031: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1257 - acc: 0.9611 - val_loss: 0.9097 - val_acc: 0.8134\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9604\n",
      "Epoch 00032: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1263 - acc: 0.9604 - val_loss: 0.9035 - val_acc: 0.8085\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9617\n",
      "Epoch 00033: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1187 - acc: 0.9617 - val_loss: 0.8536 - val_acc: 0.8202\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9635\n",
      "Epoch 00034: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1152 - acc: 0.9634 - val_loss: 0.9029 - val_acc: 0.8218\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9656\n",
      "Epoch 00035: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1117 - acc: 0.9656 - val_loss: 0.8380 - val_acc: 0.8286\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9647\n",
      "Epoch 00036: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1142 - acc: 0.9647 - val_loss: 0.9272 - val_acc: 0.8227\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9679\n",
      "Epoch 00037: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1051 - acc: 0.9679 - val_loss: 0.9669 - val_acc: 0.8137\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9664\n",
      "Epoch 00038: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1079 - acc: 0.9664 - val_loss: 0.8660 - val_acc: 0.8279\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9705\n",
      "Epoch 00039: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0954 - acc: 0.9705 - val_loss: 0.9144 - val_acc: 0.8185\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9705\n",
      "Epoch 00040: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0982 - acc: 0.9705 - val_loss: 0.8667 - val_acc: 0.8239\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9712\n",
      "Epoch 00041: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0924 - acc: 0.9712 - val_loss: 0.8941 - val_acc: 0.8248\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9714\n",
      "Epoch 00042: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0935 - acc: 0.9714 - val_loss: 0.8730 - val_acc: 0.8237\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9719\n",
      "Epoch 00043: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0897 - acc: 0.9719 - val_loss: 0.9020 - val_acc: 0.8341\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9737\n",
      "Epoch 00044: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0860 - acc: 0.9737 - val_loss: 0.8842 - val_acc: 0.8248\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9734\n",
      "Epoch 00045: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0877 - acc: 0.9734 - val_loss: 0.8877 - val_acc: 0.8295\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9736\n",
      "Epoch 00046: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0842 - acc: 0.9736 - val_loss: 0.9266 - val_acc: 0.8197\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9735\n",
      "Epoch 00047: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0872 - acc: 0.9735 - val_loss: 0.8879 - val_acc: 0.8265\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9750\n",
      "Epoch 00048: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0820 - acc: 0.9750 - val_loss: 0.9098 - val_acc: 0.8162\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9751\n",
      "Epoch 00049: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0812 - acc: 0.9751 - val_loss: 0.8764 - val_acc: 0.8290\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9753\n",
      "Epoch 00050: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0803 - acc: 0.9753 - val_loss: 0.8870 - val_acc: 0.8328\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9764\n",
      "Epoch 00051: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0774 - acc: 0.9764 - val_loss: 0.9019 - val_acc: 0.8302\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9751\n",
      "Epoch 00052: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0800 - acc: 0.9751 - val_loss: 0.8904 - val_acc: 0.8288\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9770\n",
      "Epoch 00053: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0747 - acc: 0.9770 - val_loss: 0.9035 - val_acc: 0.8265\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9779\n",
      "Epoch 00054: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0752 - acc: 0.9779 - val_loss: 0.9213 - val_acc: 0.8344\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9781\n",
      "Epoch 00055: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0754 - acc: 0.9781 - val_loss: 0.8901 - val_acc: 0.8309\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9786\n",
      "Epoch 00056: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0689 - acc: 0.9786 - val_loss: 0.9131 - val_acc: 0.8290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9794\n",
      "Epoch 00057: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0685 - acc: 0.9794 - val_loss: 0.9247 - val_acc: 0.8337\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9796\n",
      "Epoch 00058: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0680 - acc: 0.9796 - val_loss: 0.9255 - val_acc: 0.8344\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9792\n",
      "Epoch 00059: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0690 - acc: 0.9792 - val_loss: 0.9196 - val_acc: 0.8307\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9788\n",
      "Epoch 00060: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0715 - acc: 0.9788 - val_loss: 0.9302 - val_acc: 0.8376\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9787\n",
      "Epoch 00061: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0711 - acc: 0.9788 - val_loss: 0.9167 - val_acc: 0.8253\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9814\n",
      "Epoch 00062: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0642 - acc: 0.9814 - val_loss: 0.8507 - val_acc: 0.8404\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9795\n",
      "Epoch 00063: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0688 - acc: 0.9795 - val_loss: 0.9381 - val_acc: 0.8316\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9810\n",
      "Epoch 00064: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0646 - acc: 0.9810 - val_loss: 0.9057 - val_acc: 0.8428\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9806\n",
      "Epoch 00065: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0657 - acc: 0.9805 - val_loss: 0.9376 - val_acc: 0.8302\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 945us/sample - loss: 0.8833 - acc: 0.7666\n",
      "Loss: 0.883316714778496 Accuracy: 0.7665628\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4018 - acc: 0.2090\n",
      "Epoch 00001: val_loss improved from inf to 1.67515, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/001-1.6752.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 2.4017 - acc: 0.2090 - val_loss: 1.6752 - val_acc: 0.4663\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5659 - acc: 0.4914\n",
      "Epoch 00002: val_loss improved from 1.67515 to 1.34717, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/002-1.3472.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.5657 - acc: 0.4914 - val_loss: 1.3472 - val_acc: 0.5840\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3392 - acc: 0.5676\n",
      "Epoch 00003: val_loss improved from 1.34717 to 1.20077, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/003-1.2008.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.3392 - acc: 0.5676 - val_loss: 1.2008 - val_acc: 0.6084\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2186 - acc: 0.6087\n",
      "Epoch 00004: val_loss improved from 1.20077 to 1.07433, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/004-1.0743.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.2186 - acc: 0.6088 - val_loss: 1.0743 - val_acc: 0.6730\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1096 - acc: 0.6462\n",
      "Epoch 00005: val_loss improved from 1.07433 to 0.97878, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/005-0.9788.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.1095 - acc: 0.6462 - val_loss: 0.9788 - val_acc: 0.7067\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9998 - acc: 0.6863\n",
      "Epoch 00006: val_loss improved from 0.97878 to 0.90228, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/006-0.9023.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.9997 - acc: 0.6863 - val_loss: 0.9023 - val_acc: 0.7303\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8967 - acc: 0.7213\n",
      "Epoch 00007: val_loss improved from 0.90228 to 0.75282, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/007-0.7528.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8969 - acc: 0.7213 - val_loss: 0.7528 - val_acc: 0.7813\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8122 - acc: 0.7486\n",
      "Epoch 00008: val_loss improved from 0.75282 to 0.67530, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/008-0.6753.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8121 - acc: 0.7486 - val_loss: 0.6753 - val_acc: 0.8055\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7303 - acc: 0.7766\n",
      "Epoch 00009: val_loss improved from 0.67530 to 0.61138, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/009-0.6114.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7302 - acc: 0.7766 - val_loss: 0.6114 - val_acc: 0.8283\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6572 - acc: 0.7998\n",
      "Epoch 00010: val_loss improved from 0.61138 to 0.58938, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/010-0.5894.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6572 - acc: 0.7998 - val_loss: 0.5894 - val_acc: 0.8314\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5928 - acc: 0.8207\n",
      "Epoch 00011: val_loss improved from 0.58938 to 0.56331, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/011-0.5633.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5927 - acc: 0.8208 - val_loss: 0.5633 - val_acc: 0.8397\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5548 - acc: 0.8290\n",
      "Epoch 00012: val_loss improved from 0.56331 to 0.49751, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/012-0.4975.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5547 - acc: 0.8290 - val_loss: 0.4975 - val_acc: 0.8591\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5151 - acc: 0.8419\n",
      "Epoch 00013: val_loss did not improve from 0.49751\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5151 - acc: 0.8419 - val_loss: 0.5345 - val_acc: 0.8526\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4735 - acc: 0.8566\n",
      "Epoch 00014: val_loss did not improve from 0.49751\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4735 - acc: 0.8565 - val_loss: 0.5197 - val_acc: 0.8551\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4500 - acc: 0.8650\n",
      "Epoch 00015: val_loss improved from 0.49751 to 0.45783, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/015-0.4578.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4499 - acc: 0.8650 - val_loss: 0.4578 - val_acc: 0.8691\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4157 - acc: 0.8744\n",
      "Epoch 00016: val_loss did not improve from 0.45783\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4157 - acc: 0.8744 - val_loss: 0.4581 - val_acc: 0.8703\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3902 - acc: 0.8835\n",
      "Epoch 00017: val_loss improved from 0.45783 to 0.45472, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/017-0.4547.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3902 - acc: 0.8835 - val_loss: 0.4547 - val_acc: 0.8754\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3711 - acc: 0.8863\n",
      "Epoch 00018: val_loss improved from 0.45472 to 0.43325, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/018-0.4332.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3711 - acc: 0.8863 - val_loss: 0.4332 - val_acc: 0.8798\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3529 - acc: 0.8923\n",
      "Epoch 00019: val_loss improved from 0.43325 to 0.39886, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/019-0.3989.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3530 - acc: 0.8923 - val_loss: 0.3989 - val_acc: 0.8912\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3342 - acc: 0.8973\n",
      "Epoch 00020: val_loss improved from 0.39886 to 0.38753, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/020-0.3875.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3342 - acc: 0.8973 - val_loss: 0.3875 - val_acc: 0.8961\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3054 - acc: 0.9054\n",
      "Epoch 00021: val_loss did not improve from 0.38753\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3053 - acc: 0.9054 - val_loss: 0.3962 - val_acc: 0.8889\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2957 - acc: 0.9101\n",
      "Epoch 00022: val_loss did not improve from 0.38753\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2958 - acc: 0.9100 - val_loss: 0.3953 - val_acc: 0.8975\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2865 - acc: 0.9120\n",
      "Epoch 00023: val_loss did not improve from 0.38753\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2866 - acc: 0.9119 - val_loss: 0.4049 - val_acc: 0.8952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2694 - acc: 0.9154\n",
      "Epoch 00024: val_loss improved from 0.38753 to 0.36484, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/024-0.3648.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2694 - acc: 0.9154 - val_loss: 0.3648 - val_acc: 0.9059\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.9205\n",
      "Epoch 00025: val_loss did not improve from 0.36484\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2552 - acc: 0.9205 - val_loss: 0.3684 - val_acc: 0.9061\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2361 - acc: 0.9248\n",
      "Epoch 00026: val_loss improved from 0.36484 to 0.36309, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/026-0.3631.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2361 - acc: 0.9248 - val_loss: 0.3631 - val_acc: 0.9059\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9275\n",
      "Epoch 00027: val_loss did not improve from 0.36309\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2299 - acc: 0.9274 - val_loss: 0.3798 - val_acc: 0.9068\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2234 - acc: 0.9293\n",
      "Epoch 00028: val_loss improved from 0.36309 to 0.36234, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/028-0.3623.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2234 - acc: 0.9293 - val_loss: 0.3623 - val_acc: 0.9026\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9340\n",
      "Epoch 00029: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2078 - acc: 0.9340 - val_loss: 0.3760 - val_acc: 0.9119\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9359\n",
      "Epoch 00030: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1986 - acc: 0.9359 - val_loss: 0.4064 - val_acc: 0.8966\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1894 - acc: 0.9395\n",
      "Epoch 00031: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1893 - acc: 0.9395 - val_loss: 0.4091 - val_acc: 0.8984\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9418\n",
      "Epoch 00032: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1828 - acc: 0.9418 - val_loss: 0.3846 - val_acc: 0.9015\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9427\n",
      "Epoch 00033: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1801 - acc: 0.9427 - val_loss: 0.4071 - val_acc: 0.9075\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1648 - acc: 0.9471\n",
      "Epoch 00034: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1648 - acc: 0.9471 - val_loss: 0.3913 - val_acc: 0.9122\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9442\n",
      "Epoch 00035: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1674 - acc: 0.9442 - val_loss: 0.3915 - val_acc: 0.9147\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1545 - acc: 0.9489\n",
      "Epoch 00036: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1544 - acc: 0.9489 - val_loss: 0.4010 - val_acc: 0.9071\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9515\n",
      "Epoch 00037: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1508 - acc: 0.9515 - val_loss: 0.3681 - val_acc: 0.9180\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9531\n",
      "Epoch 00038: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1456 - acc: 0.9531 - val_loss: 0.3964 - val_acc: 0.9080\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9545\n",
      "Epoch 00039: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1410 - acc: 0.9545 - val_loss: 0.4005 - val_acc: 0.9045\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9563\n",
      "Epoch 00040: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1352 - acc: 0.9563 - val_loss: 0.4063 - val_acc: 0.9126\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9570\n",
      "Epoch 00041: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1307 - acc: 0.9570 - val_loss: 0.3728 - val_acc: 0.9166\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9567\n",
      "Epoch 00042: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1328 - acc: 0.9567 - val_loss: 0.4009 - val_acc: 0.9164\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9601\n",
      "Epoch 00043: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1247 - acc: 0.9601 - val_loss: 0.4229 - val_acc: 0.9133\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9591\n",
      "Epoch 00044: val_loss improved from 0.36234 to 0.36054, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/044-0.3605.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1246 - acc: 0.9591 - val_loss: 0.3605 - val_acc: 0.9220\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9628\n",
      "Epoch 00045: val_loss improved from 0.36054 to 0.35622, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/045-0.3562.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1105 - acc: 0.9627 - val_loss: 0.3562 - val_acc: 0.9227\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9620\n",
      "Epoch 00046: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1134 - acc: 0.9620 - val_loss: 0.3747 - val_acc: 0.9217\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9626\n",
      "Epoch 00047: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1120 - acc: 0.9626 - val_loss: 0.3807 - val_acc: 0.9157\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9635\n",
      "Epoch 00048: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1083 - acc: 0.9635 - val_loss: 0.3928 - val_acc: 0.9152\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9651\n",
      "Epoch 00049: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1040 - acc: 0.9651 - val_loss: 0.4237 - val_acc: 0.9150\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9658\n",
      "Epoch 00050: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1042 - acc: 0.9657 - val_loss: 0.4074 - val_acc: 0.9182\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9670\n",
      "Epoch 00051: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1021 - acc: 0.9670 - val_loss: 0.4040 - val_acc: 0.9157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9694\n",
      "Epoch 00052: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0942 - acc: 0.9694 - val_loss: 0.4090 - val_acc: 0.9231\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9667\n",
      "Epoch 00053: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1004 - acc: 0.9667 - val_loss: 0.4178 - val_acc: 0.9208\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9683\n",
      "Epoch 00054: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0944 - acc: 0.9683 - val_loss: 0.3780 - val_acc: 0.9213\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9720\n",
      "Epoch 00055: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0860 - acc: 0.9720 - val_loss: 0.4317 - val_acc: 0.9143\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9714\n",
      "Epoch 00056: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0869 - acc: 0.9714 - val_loss: 0.4315 - val_acc: 0.9180\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9710\n",
      "Epoch 00057: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0885 - acc: 0.9710 - val_loss: 0.4095 - val_acc: 0.9182\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9713\n",
      "Epoch 00058: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0867 - acc: 0.9713 - val_loss: 0.4331 - val_acc: 0.9201\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9730\n",
      "Epoch 00059: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0829 - acc: 0.9730 - val_loss: 0.3983 - val_acc: 0.9196\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9732\n",
      "Epoch 00060: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0832 - acc: 0.9732 - val_loss: 0.4100 - val_acc: 0.9187\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9722\n",
      "Epoch 00061: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0833 - acc: 0.9722 - val_loss: 0.4045 - val_acc: 0.9231\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9733\n",
      "Epoch 00062: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0808 - acc: 0.9733 - val_loss: 0.4311 - val_acc: 0.9215\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9730\n",
      "Epoch 00063: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0800 - acc: 0.9730 - val_loss: 0.4199 - val_acc: 0.9250\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9778\n",
      "Epoch 00064: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0702 - acc: 0.9778 - val_loss: 0.4208 - val_acc: 0.9180\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9756\n",
      "Epoch 00065: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0751 - acc: 0.9756 - val_loss: 0.4280 - val_acc: 0.9171\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9748\n",
      "Epoch 00066: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0767 - acc: 0.9748 - val_loss: 0.4315 - val_acc: 0.9210\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9764\n",
      "Epoch 00067: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0723 - acc: 0.9764 - val_loss: 0.4540 - val_acc: 0.9185\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9775\n",
      "Epoch 00068: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0679 - acc: 0.9775 - val_loss: 0.4024 - val_acc: 0.9210\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9769\n",
      "Epoch 00069: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0718 - acc: 0.9769 - val_loss: 0.4177 - val_acc: 0.9236\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9777\n",
      "Epoch 00070: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0694 - acc: 0.9777 - val_loss: 0.4301 - val_acc: 0.9231\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9778\n",
      "Epoch 00071: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0663 - acc: 0.9777 - val_loss: 0.4098 - val_acc: 0.9243\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9781\n",
      "Epoch 00072: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0692 - acc: 0.9781 - val_loss: 0.4099 - val_acc: 0.9269\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9788\n",
      "Epoch 00073: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0659 - acc: 0.9788 - val_loss: 0.4144 - val_acc: 0.9224\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9800\n",
      "Epoch 00074: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0625 - acc: 0.9800 - val_loss: 0.4164 - val_acc: 0.9266\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9783\n",
      "Epoch 00075: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0658 - acc: 0.9783 - val_loss: 0.4008 - val_acc: 0.9262\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9792\n",
      "Epoch 00076: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0638 - acc: 0.9792 - val_loss: 0.4024 - val_acc: 0.9248\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9799\n",
      "Epoch 00077: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0613 - acc: 0.9799 - val_loss: 0.4175 - val_acc: 0.9220\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9798\n",
      "Epoch 00078: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0608 - acc: 0.9798 - val_loss: 0.4188 - val_acc: 0.9203\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9818\n",
      "Epoch 00079: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0566 - acc: 0.9818 - val_loss: 0.4287 - val_acc: 0.9259\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9789\n",
      "Epoch 00080: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0667 - acc: 0.9789 - val_loss: 0.4161 - val_acc: 0.9222\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9818\n",
      "Epoch 00081: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0588 - acc: 0.9818 - val_loss: 0.4386 - val_acc: 0.9187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9826\n",
      "Epoch 00082: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0548 - acc: 0.9826 - val_loss: 0.4204 - val_acc: 0.9206\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9821\n",
      "Epoch 00083: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0546 - acc: 0.9821 - val_loss: 0.4875 - val_acc: 0.9154\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9806\n",
      "Epoch 00084: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0591 - acc: 0.9806 - val_loss: 0.4242 - val_acc: 0.9248\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9821\n",
      "Epoch 00085: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0563 - acc: 0.9821 - val_loss: 0.4311 - val_acc: 0.9203\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9827\n",
      "Epoch 00086: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0547 - acc: 0.9827 - val_loss: 0.4451 - val_acc: 0.9243\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9825\n",
      "Epoch 00087: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0543 - acc: 0.9825 - val_loss: 0.4325 - val_acc: 0.9222\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9827\n",
      "Epoch 00088: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0533 - acc: 0.9827 - val_loss: 0.4176 - val_acc: 0.9248\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9824\n",
      "Epoch 00089: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0533 - acc: 0.9824 - val_loss: 0.4247 - val_acc: 0.9264\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9841\n",
      "Epoch 00090: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0494 - acc: 0.9841 - val_loss: 0.4201 - val_acc: 0.9273\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9835\n",
      "Epoch 00091: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0540 - acc: 0.9835 - val_loss: 0.4246 - val_acc: 0.9231\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9846\n",
      "Epoch 00092: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0474 - acc: 0.9846 - val_loss: 0.4136 - val_acc: 0.9290\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9845\n",
      "Epoch 00093: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0500 - acc: 0.9845 - val_loss: 0.3928 - val_acc: 0.9304\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9862\n",
      "Epoch 00094: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0461 - acc: 0.9862 - val_loss: 0.4322 - val_acc: 0.9290\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9851\n",
      "Epoch 00095: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0458 - acc: 0.9851 - val_loss: 0.4486 - val_acc: 0.9271\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 970us/sample - loss: 0.4131 - acc: 0.9018\n",
      "Loss: 0.41305809186255077 Accuracy: 0.9017653\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5060 - acc: 0.1717\n",
      "Epoch 00001: val_loss improved from inf to 1.94137, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/001-1.9414.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 2.5060 - acc: 0.1717 - val_loss: 1.9414 - val_acc: 0.3638\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6701 - acc: 0.4447\n",
      "Epoch 00002: val_loss improved from 1.94137 to 1.24963, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/002-1.2496.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.6702 - acc: 0.4446 - val_loss: 1.2496 - val_acc: 0.6052\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3199 - acc: 0.5615\n",
      "Epoch 00003: val_loss improved from 1.24963 to 1.05219, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/003-1.0522.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.3199 - acc: 0.5616 - val_loss: 1.0522 - val_acc: 0.6804\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1089 - acc: 0.6401\n",
      "Epoch 00004: val_loss improved from 1.05219 to 0.89823, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/004-0.8982.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.1088 - acc: 0.6401 - val_loss: 0.8982 - val_acc: 0.7144\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9484 - acc: 0.6968\n",
      "Epoch 00005: val_loss improved from 0.89823 to 0.76811, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/005-0.7681.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9484 - acc: 0.6968 - val_loss: 0.7681 - val_acc: 0.7619\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8319 - acc: 0.7352\n",
      "Epoch 00006: val_loss improved from 0.76811 to 0.61852, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/006-0.6185.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8319 - acc: 0.7352 - val_loss: 0.6185 - val_acc: 0.8123\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7317 - acc: 0.7667\n",
      "Epoch 00007: val_loss improved from 0.61852 to 0.58055, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/007-0.5805.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7316 - acc: 0.7667 - val_loss: 0.5805 - val_acc: 0.8274\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6345 - acc: 0.7991\n",
      "Epoch 00008: val_loss improved from 0.58055 to 0.49445, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/008-0.4944.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6345 - acc: 0.7991 - val_loss: 0.4944 - val_acc: 0.8558\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5627 - acc: 0.8237\n",
      "Epoch 00009: val_loss improved from 0.49445 to 0.43004, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/009-0.4300.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5627 - acc: 0.8237 - val_loss: 0.4300 - val_acc: 0.8754\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4979 - acc: 0.8442\n",
      "Epoch 00010: val_loss improved from 0.43004 to 0.37113, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/010-0.3711.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4978 - acc: 0.8442 - val_loss: 0.3711 - val_acc: 0.8903\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4500 - acc: 0.8589\n",
      "Epoch 00011: val_loss improved from 0.37113 to 0.33107, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/011-0.3311.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4502 - acc: 0.8589 - val_loss: 0.3311 - val_acc: 0.9050\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4130 - acc: 0.8711\n",
      "Epoch 00012: val_loss improved from 0.33107 to 0.31315, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/012-0.3131.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4130 - acc: 0.8711 - val_loss: 0.3131 - val_acc: 0.9117\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3801 - acc: 0.8809\n",
      "Epoch 00013: val_loss improved from 0.31315 to 0.27041, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/013-0.2704.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3801 - acc: 0.8809 - val_loss: 0.2704 - val_acc: 0.9243\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3501 - acc: 0.8893\n",
      "Epoch 00014: val_loss improved from 0.27041 to 0.25189, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/014-0.2519.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3505 - acc: 0.8893 - val_loss: 0.2519 - val_acc: 0.9269\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3327 - acc: 0.8946\n",
      "Epoch 00015: val_loss did not improve from 0.25189\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3326 - acc: 0.8946 - val_loss: 0.2736 - val_acc: 0.9259\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3113 - acc: 0.9023\n",
      "Epoch 00016: val_loss did not improve from 0.25189\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3113 - acc: 0.9023 - val_loss: 0.2635 - val_acc: 0.9280\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2928 - acc: 0.9089\n",
      "Epoch 00017: val_loss did not improve from 0.25189\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2928 - acc: 0.9089 - val_loss: 0.2765 - val_acc: 0.9222\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2751 - acc: 0.9135\n",
      "Epoch 00018: val_loss improved from 0.25189 to 0.22053, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/018-0.2205.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2751 - acc: 0.9135 - val_loss: 0.2205 - val_acc: 0.9380\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2626 - acc: 0.9172\n",
      "Epoch 00019: val_loss did not improve from 0.22053\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2625 - acc: 0.9172 - val_loss: 0.2541 - val_acc: 0.9271\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2541 - acc: 0.9202\n",
      "Epoch 00020: val_loss improved from 0.22053 to 0.18887, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/020-0.1889.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2541 - acc: 0.9202 - val_loss: 0.1889 - val_acc: 0.9439\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2397 - acc: 0.9249\n",
      "Epoch 00021: val_loss did not improve from 0.18887\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2397 - acc: 0.9249 - val_loss: 0.2191 - val_acc: 0.9387\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2285 - acc: 0.9277\n",
      "Epoch 00022: val_loss did not improve from 0.18887\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2284 - acc: 0.9277 - val_loss: 0.1967 - val_acc: 0.9413\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2199 - acc: 0.9304\n",
      "Epoch 00023: val_loss did not improve from 0.18887\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2200 - acc: 0.9304 - val_loss: 0.1978 - val_acc: 0.9425\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2121 - acc: 0.9333\n",
      "Epoch 00024: val_loss did not improve from 0.18887\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2122 - acc: 0.9333 - val_loss: 0.2142 - val_acc: 0.9436\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9341\n",
      "Epoch 00025: val_loss did not improve from 0.18887\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2036 - acc: 0.9341 - val_loss: 0.2062 - val_acc: 0.9425\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1938 - acc: 0.9374\n",
      "Epoch 00026: val_loss improved from 0.18887 to 0.18481, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/026-0.1848.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1938 - acc: 0.9374 - val_loss: 0.1848 - val_acc: 0.9488\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9414\n",
      "Epoch 00027: val_loss did not improve from 0.18481\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1867 - acc: 0.9414 - val_loss: 0.2157 - val_acc: 0.9385\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9420\n",
      "Epoch 00028: val_loss improved from 0.18481 to 0.18194, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/028-0.1819.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1819 - acc: 0.9420 - val_loss: 0.1819 - val_acc: 0.9497\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9438\n",
      "Epoch 00029: val_loss improved from 0.18194 to 0.17784, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/029-0.1778.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1723 - acc: 0.9438 - val_loss: 0.1778 - val_acc: 0.9490\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9465\n",
      "Epoch 00030: val_loss improved from 0.17784 to 0.17586, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/030-0.1759.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1703 - acc: 0.9466 - val_loss: 0.1759 - val_acc: 0.9497\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9452\n",
      "Epoch 00031: val_loss improved from 0.17586 to 0.16324, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/031-0.1632.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1626 - acc: 0.9452 - val_loss: 0.1632 - val_acc: 0.9506\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1518 - acc: 0.9517\n",
      "Epoch 00032: val_loss did not improve from 0.16324\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1518 - acc: 0.9517 - val_loss: 0.1710 - val_acc: 0.9483\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9504\n",
      "Epoch 00033: val_loss did not improve from 0.16324\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1538 - acc: 0.9504 - val_loss: 0.1777 - val_acc: 0.9522\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9520\n",
      "Epoch 00034: val_loss did not improve from 0.16324\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1506 - acc: 0.9520 - val_loss: 0.1710 - val_acc: 0.9502\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1423 - acc: 0.9531\n",
      "Epoch 00035: val_loss did not improve from 0.16324\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1423 - acc: 0.9531 - val_loss: 0.1826 - val_acc: 0.9488\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9544\n",
      "Epoch 00036: val_loss did not improve from 0.16324\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1400 - acc: 0.9544 - val_loss: 0.1704 - val_acc: 0.9574\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9569\n",
      "Epoch 00037: val_loss improved from 0.16324 to 0.15672, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/037-0.1567.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1320 - acc: 0.9569 - val_loss: 0.1567 - val_acc: 0.9581\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9564\n",
      "Epoch 00038: val_loss did not improve from 0.15672\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1310 - acc: 0.9564 - val_loss: 0.1803 - val_acc: 0.9481\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9570\n",
      "Epoch 00039: val_loss did not improve from 0.15672\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1317 - acc: 0.9570 - val_loss: 0.1757 - val_acc: 0.9532\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9596\n",
      "Epoch 00040: val_loss improved from 0.15672 to 0.15373, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/040-0.1537.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1223 - acc: 0.9596 - val_loss: 0.1537 - val_acc: 0.9574\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9620\n",
      "Epoch 00041: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1160 - acc: 0.9620 - val_loss: 0.1736 - val_acc: 0.9513\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9622\n",
      "Epoch 00042: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1148 - acc: 0.9622 - val_loss: 0.1603 - val_acc: 0.9564\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9629\n",
      "Epoch 00043: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1104 - acc: 0.9629 - val_loss: 0.1615 - val_acc: 0.9576\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9633\n",
      "Epoch 00044: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1137 - acc: 0.9633 - val_loss: 0.1873 - val_acc: 0.9513\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9661\n",
      "Epoch 00045: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1067 - acc: 0.9661 - val_loss: 0.1759 - val_acc: 0.9574\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9643\n",
      "Epoch 00046: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1070 - acc: 0.9643 - val_loss: 0.1738 - val_acc: 0.9529\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9658\n",
      "Epoch 00047: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1034 - acc: 0.9658 - val_loss: 0.1677 - val_acc: 0.9520\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9661\n",
      "Epoch 00048: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1022 - acc: 0.9661 - val_loss: 0.1746 - val_acc: 0.9550\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9665\n",
      "Epoch 00049: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0987 - acc: 0.9665 - val_loss: 0.1683 - val_acc: 0.9553\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9654\n",
      "Epoch 00050: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1047 - acc: 0.9654 - val_loss: 0.1578 - val_acc: 0.9571\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9694\n",
      "Epoch 00051: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0930 - acc: 0.9694 - val_loss: 0.1642 - val_acc: 0.9550\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9691\n",
      "Epoch 00052: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0915 - acc: 0.9691 - val_loss: 0.1667 - val_acc: 0.9583\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9708\n",
      "Epoch 00053: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0877 - acc: 0.9708 - val_loss: 0.1721 - val_acc: 0.9550\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9696\n",
      "Epoch 00054: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0907 - acc: 0.9696 - val_loss: 0.1765 - val_acc: 0.9527\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9708\n",
      "Epoch 00055: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0862 - acc: 0.9707 - val_loss: 0.1905 - val_acc: 0.9555\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9710\n",
      "Epoch 00056: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0875 - acc: 0.9710 - val_loss: 0.1747 - val_acc: 0.9604\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9722\n",
      "Epoch 00057: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0797 - acc: 0.9722 - val_loss: 0.1682 - val_acc: 0.9588\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9732\n",
      "Epoch 00058: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0804 - acc: 0.9732 - val_loss: 0.1588 - val_acc: 0.9562\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9745\n",
      "Epoch 00059: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0742 - acc: 0.9745 - val_loss: 0.1666 - val_acc: 0.9609\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9733\n",
      "Epoch 00060: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0774 - acc: 0.9733 - val_loss: 0.1798 - val_acc: 0.9541\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9744\n",
      "Epoch 00061: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0740 - acc: 0.9744 - val_loss: 0.1761 - val_acc: 0.9571\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9747\n",
      "Epoch 00062: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0739 - acc: 0.9747 - val_loss: 0.1608 - val_acc: 0.9606\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9754\n",
      "Epoch 00063: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0716 - acc: 0.9754 - val_loss: 0.1931 - val_acc: 0.9571\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9737\n",
      "Epoch 00064: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0770 - acc: 0.9738 - val_loss: 0.1752 - val_acc: 0.9595\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9773\n",
      "Epoch 00065: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0679 - acc: 0.9773 - val_loss: 0.1637 - val_acc: 0.9627\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9798\n",
      "Epoch 00066: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0595 - acc: 0.9798 - val_loss: 0.1831 - val_acc: 0.9609\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9769\n",
      "Epoch 00067: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0694 - acc: 0.9769 - val_loss: 0.1550 - val_acc: 0.9599\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9787\n",
      "Epoch 00068: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0616 - acc: 0.9787 - val_loss: 0.1768 - val_acc: 0.9571\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9765\n",
      "Epoch 00069: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0679 - acc: 0.9765 - val_loss: 0.1903 - val_acc: 0.9569\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9783\n",
      "Epoch 00070: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0621 - acc: 0.9783 - val_loss: 0.1782 - val_acc: 0.9602\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9798\n",
      "Epoch 00071: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0600 - acc: 0.9798 - val_loss: 0.1900 - val_acc: 0.9583\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9778\n",
      "Epoch 00072: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0642 - acc: 0.9778 - val_loss: 0.1598 - val_acc: 0.9609\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9792\n",
      "Epoch 00073: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0605 - acc: 0.9792 - val_loss: 0.1845 - val_acc: 0.9581\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9795\n",
      "Epoch 00074: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0604 - acc: 0.9795 - val_loss: 0.1852 - val_acc: 0.9534\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9807\n",
      "Epoch 00075: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0568 - acc: 0.9807 - val_loss: 0.1883 - val_acc: 0.9590\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9806\n",
      "Epoch 00076: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0577 - acc: 0.9806 - val_loss: 0.1781 - val_acc: 0.9592\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9819\n",
      "Epoch 00077: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0539 - acc: 0.9819 - val_loss: 0.1830 - val_acc: 0.9536\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9784\n",
      "Epoch 00078: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0670 - acc: 0.9784 - val_loss: 0.1948 - val_acc: 0.9597\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9821\n",
      "Epoch 00079: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0527 - acc: 0.9821 - val_loss: 0.1881 - val_acc: 0.9585\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9829\n",
      "Epoch 00080: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0526 - acc: 0.9829 - val_loss: 0.1660 - val_acc: 0.9627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9820\n",
      "Epoch 00081: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0550 - acc: 0.9820 - val_loss: 0.1749 - val_acc: 0.9611\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9834\n",
      "Epoch 00082: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0503 - acc: 0.9834 - val_loss: 0.1996 - val_acc: 0.9616\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9814\n",
      "Epoch 00083: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0526 - acc: 0.9814 - val_loss: 0.1830 - val_acc: 0.9592\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9823\n",
      "Epoch 00084: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0516 - acc: 0.9823 - val_loss: 0.1750 - val_acc: 0.9611\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9821\n",
      "Epoch 00085: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0507 - acc: 0.9821 - val_loss: 0.1897 - val_acc: 0.9611\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9814\n",
      "Epoch 00086: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0522 - acc: 0.9814 - val_loss: 0.1732 - val_acc: 0.9599\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9839\n",
      "Epoch 00087: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0477 - acc: 0.9839 - val_loss: 0.1788 - val_acc: 0.9609\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9843\n",
      "Epoch 00088: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0465 - acc: 0.9843 - val_loss: 0.2147 - val_acc: 0.9606\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9840\n",
      "Epoch 00089: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0464 - acc: 0.9840 - val_loss: 0.1944 - val_acc: 0.9625\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9847\n",
      "Epoch 00090: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0477 - acc: 0.9847 - val_loss: 0.1837 - val_acc: 0.9611\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2009 - acc: 0.9427\n",
      "Loss: 0.20089558003352315 Accuracy: 0.9426791\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5030 - acc: 0.1666\n",
      "Epoch 00001: val_loss improved from inf to 1.77017, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/001-1.7702.hdf5\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 2.5029 - acc: 0.1667 - val_loss: 1.7702 - val_acc: 0.4377\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5336 - acc: 0.4921\n",
      "Epoch 00002: val_loss improved from 1.77017 to 1.02237, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/002-1.0224.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.5335 - acc: 0.4921 - val_loss: 1.0224 - val_acc: 0.6776\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1249 - acc: 0.6308\n",
      "Epoch 00003: val_loss improved from 1.02237 to 0.81245, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/003-0.8125.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.1249 - acc: 0.6308 - val_loss: 0.8125 - val_acc: 0.7477\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9261 - acc: 0.6983\n",
      "Epoch 00004: val_loss improved from 0.81245 to 0.66076, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/004-0.6608.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.9263 - acc: 0.6982 - val_loss: 0.6608 - val_acc: 0.8022\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7937 - acc: 0.7420\n",
      "Epoch 00005: val_loss improved from 0.66076 to 0.60150, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/005-0.6015.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.7937 - acc: 0.7420 - val_loss: 0.6015 - val_acc: 0.8074\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6864 - acc: 0.7756\n",
      "Epoch 00006: val_loss improved from 0.60150 to 0.47397, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/006-0.4740.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6863 - acc: 0.7756 - val_loss: 0.4740 - val_acc: 0.8509\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5950 - acc: 0.8085\n",
      "Epoch 00007: val_loss improved from 0.47397 to 0.39878, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/007-0.3988.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5950 - acc: 0.8085 - val_loss: 0.3988 - val_acc: 0.8749\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5115 - acc: 0.8357\n",
      "Epoch 00008: val_loss improved from 0.39878 to 0.33302, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/008-0.3330.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5114 - acc: 0.8357 - val_loss: 0.3330 - val_acc: 0.9005\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4549 - acc: 0.8548\n",
      "Epoch 00009: val_loss improved from 0.33302 to 0.31605, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/009-0.3160.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4548 - acc: 0.8548 - val_loss: 0.3160 - val_acc: 0.9031\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4147 - acc: 0.8668\n",
      "Epoch 00010: val_loss improved from 0.31605 to 0.28011, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/010-0.2801.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4147 - acc: 0.8668 - val_loss: 0.2801 - val_acc: 0.9217\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3804 - acc: 0.8804\n",
      "Epoch 00011: val_loss improved from 0.28011 to 0.25815, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/011-0.2581.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3804 - acc: 0.8804 - val_loss: 0.2581 - val_acc: 0.9245\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3425 - acc: 0.8915\n",
      "Epoch 00012: val_loss improved from 0.25815 to 0.22267, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/012-0.2227.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3425 - acc: 0.8915 - val_loss: 0.2227 - val_acc: 0.9364\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3146 - acc: 0.8997\n",
      "Epoch 00013: val_loss did not improve from 0.22267\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3146 - acc: 0.8997 - val_loss: 0.2308 - val_acc: 0.9324\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3000 - acc: 0.9046\n",
      "Epoch 00014: val_loss improved from 0.22267 to 0.21192, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/014-0.2119.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2999 - acc: 0.9046 - val_loss: 0.2119 - val_acc: 0.9359\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2791 - acc: 0.9123\n",
      "Epoch 00015: val_loss improved from 0.21192 to 0.18893, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/015-0.1889.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2791 - acc: 0.9123 - val_loss: 0.1889 - val_acc: 0.9455\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2580 - acc: 0.9197\n",
      "Epoch 00016: val_loss improved from 0.18893 to 0.18810, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/016-0.1881.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2580 - acc: 0.9197 - val_loss: 0.1881 - val_acc: 0.9443\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2507 - acc: 0.9205\n",
      "Epoch 00017: val_loss improved from 0.18810 to 0.18106, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/017-0.1811.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2507 - acc: 0.9205 - val_loss: 0.1811 - val_acc: 0.9464\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2290 - acc: 0.9279\n",
      "Epoch 00018: val_loss improved from 0.18106 to 0.15562, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/018-0.1556.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2290 - acc: 0.9279 - val_loss: 0.1556 - val_acc: 0.9522\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9317\n",
      "Epoch 00019: val_loss did not improve from 0.15562\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2134 - acc: 0.9317 - val_loss: 0.1599 - val_acc: 0.9555\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9323\n",
      "Epoch 00020: val_loss improved from 0.15562 to 0.15507, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/020-0.1551.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2078 - acc: 0.9323 - val_loss: 0.1551 - val_acc: 0.9529\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1950 - acc: 0.9376\n",
      "Epoch 00021: val_loss improved from 0.15507 to 0.14213, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/021-0.1421.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1950 - acc: 0.9376 - val_loss: 0.1421 - val_acc: 0.9620\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1863 - acc: 0.9405\n",
      "Epoch 00022: val_loss did not improve from 0.14213\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1863 - acc: 0.9405 - val_loss: 0.1510 - val_acc: 0.9548\n",
      "Epoch 23/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9423\n",
      "Epoch 00023: val_loss improved from 0.14213 to 0.13079, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/023-0.1308.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1801 - acc: 0.9423 - val_loss: 0.1308 - val_acc: 0.9606\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9438\n",
      "Epoch 00024: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1702 - acc: 0.9438 - val_loss: 0.1422 - val_acc: 0.9562\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9480\n",
      "Epoch 00025: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1627 - acc: 0.9480 - val_loss: 0.1373 - val_acc: 0.9597\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9489\n",
      "Epoch 00026: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1572 - acc: 0.9489 - val_loss: 0.1454 - val_acc: 0.9567\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9511\n",
      "Epoch 00027: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1516 - acc: 0.9511 - val_loss: 0.1315 - val_acc: 0.9637\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9523\n",
      "Epoch 00028: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1436 - acc: 0.9523 - val_loss: 0.1357 - val_acc: 0.9578\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9555\n",
      "Epoch 00029: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1388 - acc: 0.9555 - val_loss: 0.1324 - val_acc: 0.9599\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9564\n",
      "Epoch 00030: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1325 - acc: 0.9564 - val_loss: 0.1322 - val_acc: 0.9627\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9556\n",
      "Epoch 00031: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1324 - acc: 0.9556 - val_loss: 0.1314 - val_acc: 0.9616\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9580\n",
      "Epoch 00032: val_loss improved from 0.13079 to 0.11777, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/032-0.1178.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1259 - acc: 0.9580 - val_loss: 0.1178 - val_acc: 0.9658\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9597\n",
      "Epoch 00033: val_loss did not improve from 0.11777\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1230 - acc: 0.9597 - val_loss: 0.1321 - val_acc: 0.9616\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9611\n",
      "Epoch 00034: val_loss did not improve from 0.11777\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1183 - acc: 0.9610 - val_loss: 0.1266 - val_acc: 0.9634\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9619\n",
      "Epoch 00035: val_loss did not improve from 0.11777\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1125 - acc: 0.9619 - val_loss: 0.1235 - val_acc: 0.9653\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9638\n",
      "Epoch 00036: val_loss did not improve from 0.11777\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1096 - acc: 0.9638 - val_loss: 0.1353 - val_acc: 0.9618\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9645\n",
      "Epoch 00037: val_loss improved from 0.11777 to 0.11737, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/037-0.1174.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1065 - acc: 0.9645 - val_loss: 0.1174 - val_acc: 0.9655\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9666\n",
      "Epoch 00038: val_loss did not improve from 0.11737\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1022 - acc: 0.9666 - val_loss: 0.1299 - val_acc: 0.9627\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9688\n",
      "Epoch 00039: val_loss improved from 0.11737 to 0.11534, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/039-0.1153.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0943 - acc: 0.9688 - val_loss: 0.1153 - val_acc: 0.9686\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9679\n",
      "Epoch 00040: val_loss did not improve from 0.11534\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0954 - acc: 0.9679 - val_loss: 0.1242 - val_acc: 0.9604\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9696\n",
      "Epoch 00041: val_loss did not improve from 0.11534\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0904 - acc: 0.9696 - val_loss: 0.1342 - val_acc: 0.9606\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9686\n",
      "Epoch 00042: val_loss improved from 0.11534 to 0.11337, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/042-0.1134.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0929 - acc: 0.9686 - val_loss: 0.1134 - val_acc: 0.9660\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9696\n",
      "Epoch 00043: val_loss did not improve from 0.11337\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0895 - acc: 0.9696 - val_loss: 0.1276 - val_acc: 0.9620\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9721\n",
      "Epoch 00044: val_loss did not improve from 0.11337\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0868 - acc: 0.9721 - val_loss: 0.1187 - val_acc: 0.9690\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9724\n",
      "Epoch 00045: val_loss improved from 0.11337 to 0.11122, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/045-0.1112.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0833 - acc: 0.9724 - val_loss: 0.1112 - val_acc: 0.9697\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9744\n",
      "Epoch 00046: val_loss did not improve from 0.11122\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0789 - acc: 0.9744 - val_loss: 0.1236 - val_acc: 0.9662\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9732\n",
      "Epoch 00047: val_loss improved from 0.11122 to 0.10720, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/047-0.1072.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0798 - acc: 0.9732 - val_loss: 0.1072 - val_acc: 0.9695\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9747\n",
      "Epoch 00048: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0760 - acc: 0.9747 - val_loss: 0.1161 - val_acc: 0.9660\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9752\n",
      "Epoch 00049: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0734 - acc: 0.9752 - val_loss: 0.1292 - val_acc: 0.9641\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9754\n",
      "Epoch 00050: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0718 - acc: 0.9753 - val_loss: 0.1090 - val_acc: 0.9695\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9755\n",
      "Epoch 00051: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0728 - acc: 0.9755 - val_loss: 0.1210 - val_acc: 0.9690\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9774\n",
      "Epoch 00052: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0670 - acc: 0.9774 - val_loss: 0.1252 - val_acc: 0.9651\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9780\n",
      "Epoch 00053: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0656 - acc: 0.9780 - val_loss: 0.1301 - val_acc: 0.9630\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9780\n",
      "Epoch 00054: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0663 - acc: 0.9780 - val_loss: 0.1285 - val_acc: 0.9618\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9787\n",
      "Epoch 00055: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0650 - acc: 0.9787 - val_loss: 0.1260 - val_acc: 0.9686\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9778\n",
      "Epoch 00056: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0661 - acc: 0.9777 - val_loss: 0.1275 - val_acc: 0.9658\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9797\n",
      "Epoch 00057: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0591 - acc: 0.9796 - val_loss: 0.1290 - val_acc: 0.9667\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9790\n",
      "Epoch 00058: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0623 - acc: 0.9790 - val_loss: 0.1314 - val_acc: 0.9674\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9789\n",
      "Epoch 00059: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0595 - acc: 0.9789 - val_loss: 0.1259 - val_acc: 0.9676\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9790\n",
      "Epoch 00060: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0630 - acc: 0.9790 - val_loss: 0.1094 - val_acc: 0.9695\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9821\n",
      "Epoch 00061: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0548 - acc: 0.9821 - val_loss: 0.1302 - val_acc: 0.9679\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9820\n",
      "Epoch 00062: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0555 - acc: 0.9820 - val_loss: 0.1188 - val_acc: 0.9672\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9822\n",
      "Epoch 00063: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0520 - acc: 0.9822 - val_loss: 0.1318 - val_acc: 0.9674\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9826\n",
      "Epoch 00064: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0516 - acc: 0.9826 - val_loss: 0.1196 - val_acc: 0.9709\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9818\n",
      "Epoch 00065: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0549 - acc: 0.9818 - val_loss: 0.1449 - val_acc: 0.9693\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9830\n",
      "Epoch 00066: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0502 - acc: 0.9830 - val_loss: 0.1297 - val_acc: 0.9648\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9839\n",
      "Epoch 00067: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0486 - acc: 0.9839 - val_loss: 0.1137 - val_acc: 0.9713\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9843\n",
      "Epoch 00068: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0476 - acc: 0.9843 - val_loss: 0.1406 - val_acc: 0.9690\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9824\n",
      "Epoch 00069: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0549 - acc: 0.9824 - val_loss: 0.1395 - val_acc: 0.9681\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9846\n",
      "Epoch 00070: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0449 - acc: 0.9846 - val_loss: 0.1263 - val_acc: 0.9686\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9831\n",
      "Epoch 00071: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0488 - acc: 0.9831 - val_loss: 0.1252 - val_acc: 0.9725\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9854\n",
      "Epoch 00072: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0450 - acc: 0.9853 - val_loss: 0.1543 - val_acc: 0.9637\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9835\n",
      "Epoch 00073: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0477 - acc: 0.9835 - val_loss: 0.1233 - val_acc: 0.9706\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9860\n",
      "Epoch 00074: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0414 - acc: 0.9860 - val_loss: 0.1218 - val_acc: 0.9697\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9848\n",
      "Epoch 00075: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0430 - acc: 0.9847 - val_loss: 0.1429 - val_acc: 0.9641\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9841\n",
      "Epoch 00076: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0471 - acc: 0.9841 - val_loss: 0.1196 - val_acc: 0.9718\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9850\n",
      "Epoch 00077: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0438 - acc: 0.9850 - val_loss: 0.1292 - val_acc: 0.9702\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9874\n",
      "Epoch 00078: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0382 - acc: 0.9874 - val_loss: 0.1358 - val_acc: 0.9688\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9863\n",
      "Epoch 00079: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0414 - acc: 0.9863 - val_loss: 0.1172 - val_acc: 0.9674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9870\n",
      "Epoch 00080: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0371 - acc: 0.9870 - val_loss: 0.1406 - val_acc: 0.9681\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9860\n",
      "Epoch 00081: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0416 - acc: 0.9860 - val_loss: 0.1220 - val_acc: 0.9702\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9878\n",
      "Epoch 00082: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0376 - acc: 0.9878 - val_loss: 0.1387 - val_acc: 0.9686\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9871\n",
      "Epoch 00083: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0382 - acc: 0.9871 - val_loss: 0.1362 - val_acc: 0.9674\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9869\n",
      "Epoch 00084: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0395 - acc: 0.9869 - val_loss: 0.1403 - val_acc: 0.9706\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9879\n",
      "Epoch 00085: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0356 - acc: 0.9878 - val_loss: 0.1271 - val_acc: 0.9702\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9875\n",
      "Epoch 00086: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0385 - acc: 0.9875 - val_loss: 0.1385 - val_acc: 0.9690\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9883\n",
      "Epoch 00087: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0353 - acc: 0.9883 - val_loss: 0.1231 - val_acc: 0.9686\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9892\n",
      "Epoch 00088: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0338 - acc: 0.9891 - val_loss: 0.1417 - val_acc: 0.9674\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9872\n",
      "Epoch 00089: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0378 - acc: 0.9872 - val_loss: 0.1656 - val_acc: 0.9690\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9893\n",
      "Epoch 00090: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0321 - acc: 0.9893 - val_loss: 0.1633 - val_acc: 0.9683\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9892\n",
      "Epoch 00091: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0318 - acc: 0.9892 - val_loss: 0.1343 - val_acc: 0.9695\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9889\n",
      "Epoch 00092: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0330 - acc: 0.9888 - val_loss: 0.1343 - val_acc: 0.9695\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9875\n",
      "Epoch 00093: val_loss improved from 0.10720 to 0.10587, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/093-0.1059.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0387 - acc: 0.9875 - val_loss: 0.1059 - val_acc: 0.9734\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9887\n",
      "Epoch 00094: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0318 - acc: 0.9888 - val_loss: 0.1410 - val_acc: 0.9679\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9899\n",
      "Epoch 00095: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0301 - acc: 0.9899 - val_loss: 0.1385 - val_acc: 0.9704\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9885\n",
      "Epoch 00096: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0344 - acc: 0.9885 - val_loss: 0.1546 - val_acc: 0.9681\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9897\n",
      "Epoch 00097: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0314 - acc: 0.9897 - val_loss: 0.1385 - val_acc: 0.9697\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9897\n",
      "Epoch 00098: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0302 - acc: 0.9897 - val_loss: 0.1502 - val_acc: 0.9676\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9916\n",
      "Epoch 00099: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0257 - acc: 0.9916 - val_loss: 0.1740 - val_acc: 0.9637\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9899\n",
      "Epoch 00100: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0308 - acc: 0.9899 - val_loss: 0.1368 - val_acc: 0.9709\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9901\n",
      "Epoch 00101: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0293 - acc: 0.9901 - val_loss: 0.1331 - val_acc: 0.9683\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9912\n",
      "Epoch 00102: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0269 - acc: 0.9912 - val_loss: 0.1498 - val_acc: 0.9697\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9905\n",
      "Epoch 00103: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0286 - acc: 0.9905 - val_loss: 0.1774 - val_acc: 0.9676\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9911\n",
      "Epoch 00104: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0283 - acc: 0.9911 - val_loss: 0.1269 - val_acc: 0.9700\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9909\n",
      "Epoch 00105: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0273 - acc: 0.9909 - val_loss: 0.1934 - val_acc: 0.9651\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9914\n",
      "Epoch 00106: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0273 - acc: 0.9914 - val_loss: 0.1728 - val_acc: 0.9700\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9902\n",
      "Epoch 00107: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0303 - acc: 0.9902 - val_loss: 0.1383 - val_acc: 0.9700\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9908\n",
      "Epoch 00108: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0273 - acc: 0.9908 - val_loss: 0.1288 - val_acc: 0.9725\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9914\n",
      "Epoch 00109: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0264 - acc: 0.9914 - val_loss: 0.1539 - val_acc: 0.9706\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 00110: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0242 - acc: 0.9917 - val_loss: 0.1478 - val_acc: 0.9709\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9921\n",
      "Epoch 00111: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0236 - acc: 0.9921 - val_loss: 0.1598 - val_acc: 0.9660\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9914\n",
      "Epoch 00112: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0258 - acc: 0.9914 - val_loss: 0.1685 - val_acc: 0.9676\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9920\n",
      "Epoch 00113: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0235 - acc: 0.9920 - val_loss: 0.1577 - val_acc: 0.9681\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9921\n",
      "Epoch 00114: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0242 - acc: 0.9921 - val_loss: 0.1439 - val_acc: 0.9709\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9899\n",
      "Epoch 00115: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0297 - acc: 0.9899 - val_loss: 0.1259 - val_acc: 0.9713\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9927\n",
      "Epoch 00116: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0218 - acc: 0.9927 - val_loss: 0.1457 - val_acc: 0.9674\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9898\n",
      "Epoch 00117: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0313 - acc: 0.9898 - val_loss: 0.1431 - val_acc: 0.9695\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9931\n",
      "Epoch 00118: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0201 - acc: 0.9931 - val_loss: 0.1269 - val_acc: 0.9725\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9932\n",
      "Epoch 00119: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0211 - acc: 0.9932 - val_loss: 0.1261 - val_acc: 0.9711\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9926\n",
      "Epoch 00120: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0239 - acc: 0.9926 - val_loss: 0.1356 - val_acc: 0.9690\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9931\n",
      "Epoch 00121: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0218 - acc: 0.9931 - val_loss: 0.1516 - val_acc: 0.9697\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9941\n",
      "Epoch 00122: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0185 - acc: 0.9941 - val_loss: 0.1515 - val_acc: 0.9700\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9919\n",
      "Epoch 00123: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0236 - acc: 0.9919 - val_loss: 0.1514 - val_acc: 0.9690\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9926\n",
      "Epoch 00124: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0234 - acc: 0.9926 - val_loss: 0.1527 - val_acc: 0.9723\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9929\n",
      "Epoch 00125: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0218 - acc: 0.9929 - val_loss: 0.1524 - val_acc: 0.9700\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9929\n",
      "Epoch 00126: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0212 - acc: 0.9929 - val_loss: 0.1700 - val_acc: 0.9681\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9926\n",
      "Epoch 00127: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0215 - acc: 0.9926 - val_loss: 0.1371 - val_acc: 0.9704\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9942\n",
      "Epoch 00128: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0190 - acc: 0.9942 - val_loss: 0.1631 - val_acc: 0.9690\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9934\n",
      "Epoch 00129: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0203 - acc: 0.9934 - val_loss: 0.1528 - val_acc: 0.9723\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9935\n",
      "Epoch 00130: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0200 - acc: 0.9935 - val_loss: 0.1474 - val_acc: 0.9693\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9936\n",
      "Epoch 00131: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0200 - acc: 0.9936 - val_loss: 0.1487 - val_acc: 0.9709\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9939\n",
      "Epoch 00132: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0184 - acc: 0.9939 - val_loss: 0.1606 - val_acc: 0.9667\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9937\n",
      "Epoch 00133: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0210 - acc: 0.9937 - val_loss: 0.1733 - val_acc: 0.9688\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9934\n",
      "Epoch 00134: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0198 - acc: 0.9934 - val_loss: 0.1564 - val_acc: 0.9702\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9940\n",
      "Epoch 00135: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0194 - acc: 0.9940 - val_loss: 0.1489 - val_acc: 0.9706\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9932\n",
      "Epoch 00136: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0206 - acc: 0.9932 - val_loss: 0.1445 - val_acc: 0.9713\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9946\n",
      "Epoch 00137: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0169 - acc: 0.9946 - val_loss: 0.1459 - val_acc: 0.9727\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9936\n",
      "Epoch 00138: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0193 - acc: 0.9936 - val_loss: 0.1578 - val_acc: 0.9704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9934\n",
      "Epoch 00139: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0205 - acc: 0.9934 - val_loss: 0.1362 - val_acc: 0.9720\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9937\n",
      "Epoch 00140: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0207 - acc: 0.9937 - val_loss: 0.1383 - val_acc: 0.9709\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9951\n",
      "Epoch 00141: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0153 - acc: 0.9951 - val_loss: 0.1399 - val_acc: 0.9711\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9941\n",
      "Epoch 00142: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0190 - acc: 0.9941 - val_loss: 0.1624 - val_acc: 0.9688\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9945\n",
      "Epoch 00143: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0165 - acc: 0.9945 - val_loss: 0.1732 - val_acc: 0.9681\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1829 - acc: 0.9630\n",
      "Loss: 0.18293105663304596 Accuracy: 0.9630322\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2604 - acc: 0.2589\n",
      "Epoch 00001: val_loss improved from inf to 1.45279, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/001-1.4528.hdf5\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 2.2604 - acc: 0.2589 - val_loss: 1.4528 - val_acc: 0.5316\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2838 - acc: 0.5808\n",
      "Epoch 00002: val_loss improved from 1.45279 to 0.93213, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/002-0.9321.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.2837 - acc: 0.5808 - val_loss: 0.9321 - val_acc: 0.7009\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8632 - acc: 0.7179\n",
      "Epoch 00003: val_loss improved from 0.93213 to 0.63588, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/003-0.6359.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.8632 - acc: 0.7179 - val_loss: 0.6359 - val_acc: 0.7936\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6488 - acc: 0.7901\n",
      "Epoch 00004: val_loss improved from 0.63588 to 0.59140, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/004-0.5914.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6488 - acc: 0.7901 - val_loss: 0.5914 - val_acc: 0.8178\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5368 - acc: 0.8268\n",
      "Epoch 00005: val_loss improved from 0.59140 to 0.47067, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/005-0.4707.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5369 - acc: 0.8267 - val_loss: 0.4707 - val_acc: 0.8528\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4689 - acc: 0.8490\n",
      "Epoch 00006: val_loss improved from 0.47067 to 0.32111, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/006-0.3211.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4689 - acc: 0.8490 - val_loss: 0.3211 - val_acc: 0.8959\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4123 - acc: 0.8689\n",
      "Epoch 00007: val_loss did not improve from 0.32111\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4124 - acc: 0.8688 - val_loss: 0.3538 - val_acc: 0.8896\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3639 - acc: 0.8827\n",
      "Epoch 00008: val_loss improved from 0.32111 to 0.28435, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/008-0.2843.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3639 - acc: 0.8827 - val_loss: 0.2843 - val_acc: 0.9092\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3215 - acc: 0.8956\n",
      "Epoch 00009: val_loss improved from 0.28435 to 0.26217, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/009-0.2622.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3214 - acc: 0.8956 - val_loss: 0.2622 - val_acc: 0.9166\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.9048\n",
      "Epoch 00010: val_loss improved from 0.26217 to 0.25965, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/010-0.2597.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2970 - acc: 0.9047 - val_loss: 0.2597 - val_acc: 0.9187\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9131\n",
      "Epoch 00011: val_loss improved from 0.25965 to 0.22228, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/011-0.2223.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2708 - acc: 0.9131 - val_loss: 0.2223 - val_acc: 0.9329\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2529 - acc: 0.9181\n",
      "Epoch 00012: val_loss improved from 0.22228 to 0.20242, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/012-0.2024.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2529 - acc: 0.9181 - val_loss: 0.2024 - val_acc: 0.9357\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2287 - acc: 0.9254\n",
      "Epoch 00013: val_loss improved from 0.20242 to 0.20198, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/013-0.2020.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2287 - acc: 0.9254 - val_loss: 0.2020 - val_acc: 0.9369\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2101 - acc: 0.9317\n",
      "Epoch 00014: val_loss improved from 0.20198 to 0.19779, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/014-0.1978.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2101 - acc: 0.9317 - val_loss: 0.1978 - val_acc: 0.9357\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1985 - acc: 0.9348\n",
      "Epoch 00015: val_loss did not improve from 0.19779\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1985 - acc: 0.9348 - val_loss: 0.2298 - val_acc: 0.9264\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9401\n",
      "Epoch 00016: val_loss improved from 0.19779 to 0.16430, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/016-0.1643.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1831 - acc: 0.9401 - val_loss: 0.1643 - val_acc: 0.9469\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1749 - acc: 0.9427\n",
      "Epoch 00017: val_loss did not improve from 0.16430\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1750 - acc: 0.9427 - val_loss: 0.1700 - val_acc: 0.9495\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9489\n",
      "Epoch 00018: val_loss did not improve from 0.16430\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1569 - acc: 0.9489 - val_loss: 0.1908 - val_acc: 0.9399\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9510\n",
      "Epoch 00019: val_loss did not improve from 0.16430\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1491 - acc: 0.9510 - val_loss: 0.1780 - val_acc: 0.9464\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9528\n",
      "Epoch 00020: val_loss did not improve from 0.16430\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1402 - acc: 0.9528 - val_loss: 0.1766 - val_acc: 0.9432\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9555\n",
      "Epoch 00021: val_loss did not improve from 0.16430\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1344 - acc: 0.9555 - val_loss: 0.1685 - val_acc: 0.9434\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9573\n",
      "Epoch 00022: val_loss improved from 0.16430 to 0.16262, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/022-0.1626.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1291 - acc: 0.9573 - val_loss: 0.1626 - val_acc: 0.9515\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9584\n",
      "Epoch 00023: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1265 - acc: 0.9584 - val_loss: 0.1639 - val_acc: 0.9539\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9626\n",
      "Epoch 00024: val_loss improved from 0.16262 to 0.16232, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/024-0.1623.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1124 - acc: 0.9626 - val_loss: 0.1623 - val_acc: 0.9553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9652\n",
      "Epoch 00025: val_loss improved from 0.16232 to 0.14835, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/025-0.1484.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1054 - acc: 0.9652 - val_loss: 0.1484 - val_acc: 0.9539\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9655\n",
      "Epoch 00026: val_loss did not improve from 0.14835\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1038 - acc: 0.9655 - val_loss: 0.1747 - val_acc: 0.9515\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9673\n",
      "Epoch 00027: val_loss improved from 0.14835 to 0.14019, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/027-0.1402.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0965 - acc: 0.9673 - val_loss: 0.1402 - val_acc: 0.9567\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9689\n",
      "Epoch 00028: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0901 - acc: 0.9689 - val_loss: 0.1557 - val_acc: 0.9546\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9718\n",
      "Epoch 00029: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0839 - acc: 0.9718 - val_loss: 0.1608 - val_acc: 0.9574\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9704\n",
      "Epoch 00030: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0893 - acc: 0.9704 - val_loss: 0.1684 - val_acc: 0.9562\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9725\n",
      "Epoch 00031: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0787 - acc: 0.9725 - val_loss: 0.1536 - val_acc: 0.9595\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9758\n",
      "Epoch 00032: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0721 - acc: 0.9758 - val_loss: 0.1444 - val_acc: 0.9630\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9756\n",
      "Epoch 00033: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0712 - acc: 0.9756 - val_loss: 0.1492 - val_acc: 0.9595\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9763\n",
      "Epoch 00034: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0720 - acc: 0.9763 - val_loss: 0.1529 - val_acc: 0.9583\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9776\n",
      "Epoch 00035: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0659 - acc: 0.9776 - val_loss: 0.1591 - val_acc: 0.9553\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9789\n",
      "Epoch 00036: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0621 - acc: 0.9789 - val_loss: 0.1823 - val_acc: 0.9590\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9798\n",
      "Epoch 00037: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0595 - acc: 0.9798 - val_loss: 0.1453 - val_acc: 0.9585\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9809\n",
      "Epoch 00038: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0566 - acc: 0.9809 - val_loss: 0.1669 - val_acc: 0.9571\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9807\n",
      "Epoch 00039: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0586 - acc: 0.9807 - val_loss: 0.1619 - val_acc: 0.9597\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9820\n",
      "Epoch 00040: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0531 - acc: 0.9820 - val_loss: 0.1597 - val_acc: 0.9597\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9822\n",
      "Epoch 00041: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0510 - acc: 0.9822 - val_loss: 0.1574 - val_acc: 0.9620\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9839\n",
      "Epoch 00042: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0483 - acc: 0.9839 - val_loss: 0.1568 - val_acc: 0.9646\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9841\n",
      "Epoch 00043: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0484 - acc: 0.9841 - val_loss: 0.1726 - val_acc: 0.9611\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9829\n",
      "Epoch 00044: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0529 - acc: 0.9829 - val_loss: 0.1600 - val_acc: 0.9602\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9842\n",
      "Epoch 00045: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0477 - acc: 0.9842 - val_loss: 0.1610 - val_acc: 0.9609\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9845\n",
      "Epoch 00046: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0458 - acc: 0.9845 - val_loss: 0.1731 - val_acc: 0.9597\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9865\n",
      "Epoch 00047: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0424 - acc: 0.9865 - val_loss: 0.1576 - val_acc: 0.9627\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9877\n",
      "Epoch 00048: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0366 - acc: 0.9877 - val_loss: 0.1653 - val_acc: 0.9620\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9862\n",
      "Epoch 00049: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0409 - acc: 0.9862 - val_loss: 0.1968 - val_acc: 0.9606\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9861\n",
      "Epoch 00050: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0420 - acc: 0.9861 - val_loss: 0.1892 - val_acc: 0.9532\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9874\n",
      "Epoch 00051: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0383 - acc: 0.9874 - val_loss: 0.1772 - val_acc: 0.9609\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9871\n",
      "Epoch 00052: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0389 - acc: 0.9871 - val_loss: 0.1847 - val_acc: 0.9609\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9885\n",
      "Epoch 00053: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0338 - acc: 0.9885 - val_loss: 0.1901 - val_acc: 0.9606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9881\n",
      "Epoch 00054: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0349 - acc: 0.9881 - val_loss: 0.1763 - val_acc: 0.9606\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9874\n",
      "Epoch 00055: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0379 - acc: 0.9874 - val_loss: 0.1862 - val_acc: 0.9576\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9899\n",
      "Epoch 00056: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0320 - acc: 0.9899 - val_loss: 0.1476 - val_acc: 0.9630\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9894\n",
      "Epoch 00057: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0322 - acc: 0.9894 - val_loss: 0.1549 - val_acc: 0.9634\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9885\n",
      "Epoch 00058: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0357 - acc: 0.9885 - val_loss: 0.2162 - val_acc: 0.9546\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9896\n",
      "Epoch 00059: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0312 - acc: 0.9896 - val_loss: 0.1700 - val_acc: 0.9676\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9898\n",
      "Epoch 00060: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0311 - acc: 0.9898 - val_loss: 0.1761 - val_acc: 0.9637\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9892\n",
      "Epoch 00061: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0339 - acc: 0.9892 - val_loss: 0.1822 - val_acc: 0.9641\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9907\n",
      "Epoch 00062: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0285 - acc: 0.9907 - val_loss: 0.1775 - val_acc: 0.9658\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9915\n",
      "Epoch 00063: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0254 - acc: 0.9915 - val_loss: 0.1910 - val_acc: 0.9627\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9913\n",
      "Epoch 00064: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0269 - acc: 0.9913 - val_loss: 0.1732 - val_acc: 0.9634\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9905\n",
      "Epoch 00065: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0286 - acc: 0.9905 - val_loss: 0.1748 - val_acc: 0.9627\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9912\n",
      "Epoch 00066: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0274 - acc: 0.9913 - val_loss: 0.1731 - val_acc: 0.9613\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9915\n",
      "Epoch 00067: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0264 - acc: 0.9916 - val_loss: 0.1931 - val_acc: 0.9651\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9916\n",
      "Epoch 00068: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0260 - acc: 0.9916 - val_loss: 0.2012 - val_acc: 0.9611\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9910\n",
      "Epoch 00069: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0281 - acc: 0.9910 - val_loss: 0.1744 - val_acc: 0.9660\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9908\n",
      "Epoch 00070: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0282 - acc: 0.9908 - val_loss: 0.1630 - val_acc: 0.9665\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9918\n",
      "Epoch 00071: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0250 - acc: 0.9918 - val_loss: 0.1772 - val_acc: 0.9683\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9924\n",
      "Epoch 00072: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0252 - acc: 0.9924 - val_loss: 0.1842 - val_acc: 0.9618\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9921\n",
      "Epoch 00073: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0247 - acc: 0.9921 - val_loss: 0.1915 - val_acc: 0.9611\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9929\n",
      "Epoch 00074: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0228 - acc: 0.9929 - val_loss: 0.1726 - val_acc: 0.9630\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9937\n",
      "Epoch 00075: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0206 - acc: 0.9937 - val_loss: 0.2027 - val_acc: 0.9653\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9923\n",
      "Epoch 00076: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0254 - acc: 0.9923 - val_loss: 0.2188 - val_acc: 0.9583\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9928\n",
      "Epoch 00077: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0216 - acc: 0.9928 - val_loss: 0.1828 - val_acc: 0.9648\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2276 - acc: 0.9350\n",
      "Loss: 0.2276410343955239 Accuracy: 0.9349948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_custom_conv_3_VGG_DO_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 556us/sample - loss: 1.9917 - acc: 0.3877\n",
      "Loss: 1.9917109709043492 Accuracy: 0.38774663\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,498,320\n",
      "Trainable params: 5,498,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 882us/sample - loss: 1.7163 - acc: 0.4752\n",
      "Loss: 1.7163452906276826 Accuracy: 0.47518173\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.4290 - acc: 0.5626\n",
      "Loss: 1.4289896430008633 Accuracy: 0.5626168\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.0904 - acc: 0.6719\n",
      "Loss: 1.0903628553928244 Accuracy: 0.6718588\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.8833 - acc: 0.7666\n",
      "Loss: 0.883316714778496 Accuracy: 0.7665628\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.4131 - acc: 0.9018\n",
      "Loss: 0.41305809186255077 Accuracy: 0.9017653\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2009 - acc: 0.9427\n",
      "Loss: 0.20089558003352315 Accuracy: 0.9426791\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1829 - acc: 0.9630\n",
      "Loss: 0.18293105663304596 Accuracy: 0.9630322\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2276 - acc: 0.9350\n",
      "Loss: 0.2276410343955239 Accuracy: 0.9349948\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
