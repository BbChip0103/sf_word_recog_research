{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                      activation='relu', input_shape=input_shape)) \n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                  activation='relu')) \n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))         \n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,498,320\n",
      "Trainable params: 5,498,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3342 - acc: 0.2681\n",
      "Epoch 00001: val_loss improved from inf to 2.11902, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_1_conv_checkpoint/001-2.1190.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 2.3342 - acc: 0.2680 - val_loss: 2.1190 - val_acc: 0.3361\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8677 - acc: 0.4412\n",
      "Epoch 00002: val_loss improved from 2.11902 to 1.97704, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_1_conv_checkpoint/002-1.9770.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.8677 - acc: 0.4411 - val_loss: 1.9770 - val_acc: 0.3946\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4978 - acc: 0.5650\n",
      "Epoch 00003: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.4979 - acc: 0.5650 - val_loss: 1.9807 - val_acc: 0.4018\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1864 - acc: 0.6626\n",
      "Epoch 00004: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.1863 - acc: 0.6626 - val_loss: 2.0509 - val_acc: 0.3755\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9279 - acc: 0.7422\n",
      "Epoch 00005: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.9279 - acc: 0.7422 - val_loss: 2.1401 - val_acc: 0.3755\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7272 - acc: 0.8094\n",
      "Epoch 00006: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.7272 - acc: 0.8094 - val_loss: 2.2356 - val_acc: 0.3876\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5647 - acc: 0.8575\n",
      "Epoch 00007: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.5647 - acc: 0.8575 - val_loss: 2.4169 - val_acc: 0.3736\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4370 - acc: 0.8951\n",
      "Epoch 00008: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4370 - acc: 0.8951 - val_loss: 2.5836 - val_acc: 0.3671\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3378 - acc: 0.9243\n",
      "Epoch 00009: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3378 - acc: 0.9244 - val_loss: 2.7661 - val_acc: 0.3648\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2655 - acc: 0.9439\n",
      "Epoch 00010: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2656 - acc: 0.9438 - val_loss: 2.8919 - val_acc: 0.3655\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9610\n",
      "Epoch 00011: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2040 - acc: 0.9609 - val_loss: 3.1045 - val_acc: 0.3648\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1660 - acc: 0.9704\n",
      "Epoch 00012: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1660 - acc: 0.9704 - val_loss: 3.2424 - val_acc: 0.3580\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9777\n",
      "Epoch 00013: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1342 - acc: 0.9777 - val_loss: 3.4207 - val_acc: 0.3608\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9831\n",
      "Epoch 00014: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1126 - acc: 0.9831 - val_loss: 3.4965 - val_acc: 0.3692\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9863\n",
      "Epoch 00015: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0970 - acc: 0.9863 - val_loss: 3.6642 - val_acc: 0.3552\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9901\n",
      "Epoch 00016: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0794 - acc: 0.9901 - val_loss: 3.8058 - val_acc: 0.3662\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9913\n",
      "Epoch 00017: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0717 - acc: 0.9913 - val_loss: 3.9215 - val_acc: 0.3587\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9919\n",
      "Epoch 00018: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0673 - acc: 0.9919 - val_loss: 4.0192 - val_acc: 0.3485\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9924\n",
      "Epoch 00019: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0633 - acc: 0.9924 - val_loss: 4.0036 - val_acc: 0.3676\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9937\n",
      "Epoch 00020: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0532 - acc: 0.9937 - val_loss: 4.1217 - val_acc: 0.3636\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9949\n",
      "Epoch 00021: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0472 - acc: 0.9949 - val_loss: 4.2238 - val_acc: 0.3594\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9946\n",
      "Epoch 00022: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0508 - acc: 0.9946 - val_loss: 4.2844 - val_acc: 0.3620\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9953\n",
      "Epoch 00023: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0421 - acc: 0.9953 - val_loss: 4.3568 - val_acc: 0.3631\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9951\n",
      "Epoch 00024: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0397 - acc: 0.9951 - val_loss: 4.4896 - val_acc: 0.3550\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9960\n",
      "Epoch 00025: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0368 - acc: 0.9960 - val_loss: 4.5489 - val_acc: 0.3566\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9956\n",
      "Epoch 00026: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0387 - acc: 0.9956 - val_loss: 4.6514 - val_acc: 0.3576\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9941\n",
      "Epoch 00027: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0437 - acc: 0.9941 - val_loss: 4.6112 - val_acc: 0.3538\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9954\n",
      "Epoch 00028: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0367 - acc: 0.9954 - val_loss: 4.5717 - val_acc: 0.3664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9967\n",
      "Epoch 00029: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0339 - acc: 0.9967 - val_loss: 4.6855 - val_acc: 0.3627\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9958\n",
      "Epoch 00030: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0350 - acc: 0.9958 - val_loss: 4.6992 - val_acc: 0.3657\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9970\n",
      "Epoch 00031: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0310 - acc: 0.9970 - val_loss: 4.7316 - val_acc: 0.3604\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9963\n",
      "Epoch 00032: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0310 - acc: 0.9963 - val_loss: 4.8478 - val_acc: 0.3683\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9961\n",
      "Epoch 00033: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0326 - acc: 0.9961 - val_loss: 4.8750 - val_acc: 0.3627\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9975\n",
      "Epoch 00034: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0267 - acc: 0.9975 - val_loss: 4.8643 - val_acc: 0.3634\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9971\n",
      "Epoch 00035: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0257 - acc: 0.9971 - val_loss: 4.9156 - val_acc: 0.3641\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9968\n",
      "Epoch 00036: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0271 - acc: 0.9968 - val_loss: 4.9692 - val_acc: 0.3683\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9969\n",
      "Epoch 00037: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0279 - acc: 0.9969 - val_loss: 5.0658 - val_acc: 0.3645\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9985\n",
      "Epoch 00038: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0219 - acc: 0.9985 - val_loss: 5.0794 - val_acc: 0.3552\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9981\n",
      "Epoch 00039: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0232 - acc: 0.9981 - val_loss: 5.1830 - val_acc: 0.3566\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9966\n",
      "Epoch 00040: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0271 - acc: 0.9966 - val_loss: 5.1424 - val_acc: 0.3611\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9961\n",
      "Epoch 00041: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0295 - acc: 0.9961 - val_loss: 5.1795 - val_acc: 0.3594\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9973\n",
      "Epoch 00042: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0257 - acc: 0.9973 - val_loss: 5.2156 - val_acc: 0.3638\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9970\n",
      "Epoch 00043: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0261 - acc: 0.9970 - val_loss: 5.2150 - val_acc: 0.3634\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9977\n",
      "Epoch 00044: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0239 - acc: 0.9977 - val_loss: 5.1809 - val_acc: 0.3680\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9976\n",
      "Epoch 00045: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0242 - acc: 0.9976 - val_loss: 5.2029 - val_acc: 0.3604\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9985\n",
      "Epoch 00046: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0206 - acc: 0.9985 - val_loss: 5.2594 - val_acc: 0.3636\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9974\n",
      "Epoch 00047: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0246 - acc: 0.9974 - val_loss: 5.2570 - val_acc: 0.3613\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9972\n",
      "Epoch 00048: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0237 - acc: 0.9972 - val_loss: 5.3461 - val_acc: 0.3510\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9978\n",
      "Epoch 00049: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0231 - acc: 0.9978 - val_loss: 5.2409 - val_acc: 0.3599\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9978\n",
      "Epoch 00050: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0211 - acc: 0.9978 - val_loss: 5.3052 - val_acc: 0.3590\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9984\n",
      "Epoch 00051: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0206 - acc: 0.9984 - val_loss: 5.3588 - val_acc: 0.3615\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9974\n",
      "Epoch 00052: val_loss did not improve from 1.97704\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0234 - acc: 0.9974 - val_loss: 5.4649 - val_acc: 0.3594\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 465us/sample - loss: 1.9917 - acc: 0.3877\n",
      "Loss: 1.9917109709043492 Accuracy: 0.38774663\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2231 - acc: 0.3038\n",
      "Epoch 00001: val_loss improved from inf to 1.88607, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_2_conv_checkpoint/001-1.8861.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 2.2230 - acc: 0.3039 - val_loss: 1.8861 - val_acc: 0.4386\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7233 - acc: 0.4796\n",
      "Epoch 00002: val_loss improved from 1.88607 to 1.68747, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_2_conv_checkpoint/002-1.6875.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.7232 - acc: 0.4797 - val_loss: 1.6875 - val_acc: 0.4908\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4425 - acc: 0.5717\n",
      "Epoch 00003: val_loss improved from 1.68747 to 1.64934, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_2_conv_checkpoint/003-1.6493.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.4424 - acc: 0.5717 - val_loss: 1.6493 - val_acc: 0.4901\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1851 - acc: 0.6544\n",
      "Epoch 00004: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.1851 - acc: 0.6544 - val_loss: 1.6799 - val_acc: 0.4976\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9444 - acc: 0.7265\n",
      "Epoch 00005: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.9444 - acc: 0.7265 - val_loss: 1.7603 - val_acc: 0.4878\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7388 - acc: 0.7870\n",
      "Epoch 00006: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.7387 - acc: 0.7870 - val_loss: 1.8669 - val_acc: 0.4850\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5634 - acc: 0.8388\n",
      "Epoch 00007: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.5633 - acc: 0.8387 - val_loss: 2.0537 - val_acc: 0.4803\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4304 - acc: 0.8756\n",
      "Epoch 00008: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.4304 - acc: 0.8756 - val_loss: 2.1998 - val_acc: 0.4754\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3319 - acc: 0.9072\n",
      "Epoch 00009: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3319 - acc: 0.9072 - val_loss: 2.3268 - val_acc: 0.4771\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.9301\n",
      "Epoch 00010: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2609 - acc: 0.9301 - val_loss: 2.5561 - val_acc: 0.4801\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9445\n",
      "Epoch 00011: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2032 - acc: 0.9445 - val_loss: 2.7347 - val_acc: 0.4768\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9543\n",
      "Epoch 00012: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1691 - acc: 0.9543 - val_loss: 2.9239 - val_acc: 0.4624\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9599\n",
      "Epoch 00013: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1507 - acc: 0.9598 - val_loss: 3.0228 - val_acc: 0.4612\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9650\n",
      "Epoch 00014: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1335 - acc: 0.9650 - val_loss: 3.0994 - val_acc: 0.4628\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9690\n",
      "Epoch 00015: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1171 - acc: 0.9690 - val_loss: 3.1822 - val_acc: 0.4766\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9738\n",
      "Epoch 00016: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1056 - acc: 0.9738 - val_loss: 3.3066 - val_acc: 0.4684\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9760\n",
      "Epoch 00017: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0952 - acc: 0.9760 - val_loss: 3.4309 - val_acc: 0.4703\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9767\n",
      "Epoch 00018: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0939 - acc: 0.9767 - val_loss: 3.4582 - val_acc: 0.4631\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9785\n",
      "Epoch 00019: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0850 - acc: 0.9785 - val_loss: 3.4582 - val_acc: 0.4722\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9769\n",
      "Epoch 00020: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0909 - acc: 0.9769 - val_loss: 3.5330 - val_acc: 0.4570\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9814\n",
      "Epoch 00021: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0753 - acc: 0.9814 - val_loss: 3.5833 - val_acc: 0.4724\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9834\n",
      "Epoch 00022: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0690 - acc: 0.9834 - val_loss: 3.6398 - val_acc: 0.4731\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9848\n",
      "Epoch 00023: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0647 - acc: 0.9848 - val_loss: 3.6943 - val_acc: 0.4864\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9826\n",
      "Epoch 00024: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0718 - acc: 0.9826 - val_loss: 3.7163 - val_acc: 0.4715\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9817\n",
      "Epoch 00025: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0724 - acc: 0.9817 - val_loss: 3.6584 - val_acc: 0.4785\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9860\n",
      "Epoch 00026: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0605 - acc: 0.9860 - val_loss: 3.7579 - val_acc: 0.4715\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9871\n",
      "Epoch 00027: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0606 - acc: 0.9871 - val_loss: 3.8602 - val_acc: 0.4582\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9856\n",
      "Epoch 00028: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0607 - acc: 0.9856 - val_loss: 3.8860 - val_acc: 0.4733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9839\n",
      "Epoch 00029: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0650 - acc: 0.9839 - val_loss: 3.8565 - val_acc: 0.4857\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9885\n",
      "Epoch 00030: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0517 - acc: 0.9885 - val_loss: 3.9517 - val_acc: 0.4845\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9870\n",
      "Epoch 00031: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0583 - acc: 0.9870 - val_loss: 3.8449 - val_acc: 0.4819\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9884\n",
      "Epoch 00032: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0525 - acc: 0.9884 - val_loss: 3.8503 - val_acc: 0.4836\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9870\n",
      "Epoch 00033: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0552 - acc: 0.9870 - val_loss: 3.8762 - val_acc: 0.4815\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9893\n",
      "Epoch 00034: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0476 - acc: 0.9893 - val_loss: 3.8535 - val_acc: 0.4850\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9903\n",
      "Epoch 00035: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0478 - acc: 0.9903 - val_loss: 3.8204 - val_acc: 0.4878\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9893\n",
      "Epoch 00036: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0476 - acc: 0.9893 - val_loss: 4.0205 - val_acc: 0.4733\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9883\n",
      "Epoch 00037: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0528 - acc: 0.9883 - val_loss: 3.8648 - val_acc: 0.4801\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9896\n",
      "Epoch 00038: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0504 - acc: 0.9896 - val_loss: 3.9693 - val_acc: 0.4789\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9896\n",
      "Epoch 00039: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0469 - acc: 0.9896 - val_loss: 3.9250 - val_acc: 0.4908\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9897\n",
      "Epoch 00040: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0471 - acc: 0.9897 - val_loss: 4.0918 - val_acc: 0.4694\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9906\n",
      "Epoch 00041: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0448 - acc: 0.9906 - val_loss: 4.0546 - val_acc: 0.4794\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9924\n",
      "Epoch 00042: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0392 - acc: 0.9924 - val_loss: 4.1617 - val_acc: 0.4768\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9907\n",
      "Epoch 00043: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0447 - acc: 0.9907 - val_loss: 4.0562 - val_acc: 0.4894\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9915\n",
      "Epoch 00044: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0439 - acc: 0.9916 - val_loss: 3.9701 - val_acc: 0.4901\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9914\n",
      "Epoch 00045: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0417 - acc: 0.9914 - val_loss: 3.9810 - val_acc: 0.4964\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9922\n",
      "Epoch 00046: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0391 - acc: 0.9922 - val_loss: 4.2705 - val_acc: 0.4752\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9911\n",
      "Epoch 00047: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0416 - acc: 0.9911 - val_loss: 4.1379 - val_acc: 0.4812\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9920\n",
      "Epoch 00048: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0399 - acc: 0.9920 - val_loss: 4.0835 - val_acc: 0.4817\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9907\n",
      "Epoch 00049: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0440 - acc: 0.9907 - val_loss: 4.1667 - val_acc: 0.4745\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9924\n",
      "Epoch 00050: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0389 - acc: 0.9924 - val_loss: 4.1195 - val_acc: 0.4824\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9927\n",
      "Epoch 00051: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0395 - acc: 0.9927 - val_loss: 4.1374 - val_acc: 0.4896\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9920\n",
      "Epoch 00052: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0397 - acc: 0.9920 - val_loss: 4.1176 - val_acc: 0.4852\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9918\n",
      "Epoch 00053: val_loss did not improve from 1.64934\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0406 - acc: 0.9918 - val_loss: 4.1606 - val_acc: 0.4887\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 769us/sample - loss: 1.7163 - acc: 0.4752\n",
      "Loss: 1.7163452906276826 Accuracy: 0.47518173\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2427 - acc: 0.2877\n",
      "Epoch 00001: val_loss improved from inf to 1.86165, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/001-1.8617.hdf5\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 2.2427 - acc: 0.2876 - val_loss: 1.8617 - val_acc: 0.4088\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6555 - acc: 0.4901\n",
      "Epoch 00002: val_loss improved from 1.86165 to 1.58989, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/002-1.5899.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.6555 - acc: 0.4901 - val_loss: 1.5899 - val_acc: 0.5236\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3620 - acc: 0.5856\n",
      "Epoch 00003: val_loss improved from 1.58989 to 1.41779, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/003-1.4178.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.3621 - acc: 0.5856 - val_loss: 1.4178 - val_acc: 0.5560\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1719 - acc: 0.6452\n",
      "Epoch 00004: val_loss improved from 1.41779 to 1.36893, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/004-1.3689.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.1718 - acc: 0.6452 - val_loss: 1.3689 - val_acc: 0.5733\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0111 - acc: 0.6928\n",
      "Epoch 00005: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.0111 - acc: 0.6929 - val_loss: 1.4107 - val_acc: 0.5614\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8679 - acc: 0.7391\n",
      "Epoch 00006: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.8681 - acc: 0.7391 - val_loss: 1.3838 - val_acc: 0.5924\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7480 - acc: 0.7732\n",
      "Epoch 00007: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.7483 - acc: 0.7731 - val_loss: 1.4656 - val_acc: 0.5782\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6420 - acc: 0.8010\n",
      "Epoch 00008: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.6420 - acc: 0.8011 - val_loss: 1.5133 - val_acc: 0.5798\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5498 - acc: 0.8286\n",
      "Epoch 00009: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.5498 - acc: 0.8286 - val_loss: 1.6002 - val_acc: 0.5898\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4692 - acc: 0.8540\n",
      "Epoch 00010: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.4692 - acc: 0.8540 - val_loss: 1.7021 - val_acc: 0.5681\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3995 - acc: 0.8750\n",
      "Epoch 00011: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3995 - acc: 0.8750 - val_loss: 1.7236 - val_acc: 0.5819\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3482 - acc: 0.8903\n",
      "Epoch 00012: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3482 - acc: 0.8903 - val_loss: 1.7801 - val_acc: 0.5956\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3013 - acc: 0.9052\n",
      "Epoch 00013: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3012 - acc: 0.9053 - val_loss: 1.9166 - val_acc: 0.5821\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2642 - acc: 0.9164\n",
      "Epoch 00014: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2642 - acc: 0.9163 - val_loss: 1.9004 - val_acc: 0.6056\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2394 - acc: 0.9255\n",
      "Epoch 00015: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2394 - acc: 0.9255 - val_loss: 2.0522 - val_acc: 0.5949\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2137 - acc: 0.9327\n",
      "Epoch 00016: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2137 - acc: 0.9327 - val_loss: 2.0799 - val_acc: 0.5980\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9409\n",
      "Epoch 00017: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1961 - acc: 0.9409 - val_loss: 2.1171 - val_acc: 0.6042\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1802 - acc: 0.9453\n",
      "Epoch 00018: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1803 - acc: 0.9453 - val_loss: 2.1780 - val_acc: 0.6012\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1718 - acc: 0.9486\n",
      "Epoch 00019: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1718 - acc: 0.9486 - val_loss: 2.1357 - val_acc: 0.6091\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9515\n",
      "Epoch 00020: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1603 - acc: 0.9516 - val_loss: 2.1922 - val_acc: 0.6129\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9571\n",
      "Epoch 00021: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1449 - acc: 0.9571 - val_loss: 2.2131 - val_acc: 0.6031\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9590\n",
      "Epoch 00022: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1447 - acc: 0.9590 - val_loss: 2.2093 - val_acc: 0.6143\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9599\n",
      "Epoch 00023: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1325 - acc: 0.9598 - val_loss: 2.2505 - val_acc: 0.6143\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9639\n",
      "Epoch 00024: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1233 - acc: 0.9639 - val_loss: 2.3105 - val_acc: 0.6063\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9632\n",
      "Epoch 00025: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1243 - acc: 0.9632 - val_loss: 2.2257 - val_acc: 0.6122\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9671\n",
      "Epoch 00026: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1129 - acc: 0.9671 - val_loss: 2.3252 - val_acc: 0.6133\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9695\n",
      "Epoch 00027: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1074 - acc: 0.9695 - val_loss: 2.4009 - val_acc: 0.6017\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9699\n",
      "Epoch 00028: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1064 - acc: 0.9699 - val_loss: 2.3222 - val_acc: 0.6245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9709\n",
      "Epoch 00029: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1023 - acc: 0.9709 - val_loss: 2.3492 - val_acc: 0.6189\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9735\n",
      "Epoch 00030: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0929 - acc: 0.9734 - val_loss: 2.4099 - val_acc: 0.6205\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9722\n",
      "Epoch 00031: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0977 - acc: 0.9722 - val_loss: 2.3612 - val_acc: 0.6236\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9758\n",
      "Epoch 00032: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0906 - acc: 0.9758 - val_loss: 2.3412 - val_acc: 0.6212\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9758\n",
      "Epoch 00033: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0853 - acc: 0.9758 - val_loss: 2.3562 - val_acc: 0.6257\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9756\n",
      "Epoch 00034: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0888 - acc: 0.9756 - val_loss: 2.3754 - val_acc: 0.6236\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9770\n",
      "Epoch 00035: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0824 - acc: 0.9770 - val_loss: 2.3804 - val_acc: 0.6273\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9759\n",
      "Epoch 00036: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0868 - acc: 0.9759 - val_loss: 2.4734 - val_acc: 0.6203\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9795\n",
      "Epoch 00037: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0767 - acc: 0.9795 - val_loss: 2.4426 - val_acc: 0.6203\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9794\n",
      "Epoch 00038: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0758 - acc: 0.9794 - val_loss: 2.4322 - val_acc: 0.6182\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9795\n",
      "Epoch 00039: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0751 - acc: 0.9795 - val_loss: 2.4554 - val_acc: 0.6268\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9793\n",
      "Epoch 00040: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0772 - acc: 0.9794 - val_loss: 2.4758 - val_acc: 0.6322\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9819\n",
      "Epoch 00041: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0713 - acc: 0.9819 - val_loss: 2.4982 - val_acc: 0.6194\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9815\n",
      "Epoch 00042: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0710 - acc: 0.9815 - val_loss: 2.5451 - val_acc: 0.6159\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9817\n",
      "Epoch 00043: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0727 - acc: 0.9817 - val_loss: 2.4605 - val_acc: 0.6231\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9811\n",
      "Epoch 00044: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0724 - acc: 0.9811 - val_loss: 2.4102 - val_acc: 0.6355\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9841\n",
      "Epoch 00045: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0636 - acc: 0.9841 - val_loss: 2.4372 - val_acc: 0.6308\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9835\n",
      "Epoch 00046: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0660 - acc: 0.9835 - val_loss: 2.4093 - val_acc: 0.6275\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9844\n",
      "Epoch 00047: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0617 - acc: 0.9844 - val_loss: 2.4658 - val_acc: 0.6394\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9847\n",
      "Epoch 00048: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0612 - acc: 0.9847 - val_loss: 2.5588 - val_acc: 0.6310\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9838\n",
      "Epoch 00049: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0651 - acc: 0.9838 - val_loss: 2.5034 - val_acc: 0.6282\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9848\n",
      "Epoch 00050: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0608 - acc: 0.9848 - val_loss: 2.6234 - val_acc: 0.6203\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9865\n",
      "Epoch 00051: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0549 - acc: 0.9865 - val_loss: 2.4700 - val_acc: 0.6273\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9847\n",
      "Epoch 00052: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0620 - acc: 0.9847 - val_loss: 2.5316 - val_acc: 0.6296\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9855\n",
      "Epoch 00053: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0593 - acc: 0.9855 - val_loss: 2.4410 - val_acc: 0.6362\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9845\n",
      "Epoch 00054: val_loss did not improve from 1.36893\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0626 - acc: 0.9845 - val_loss: 2.4072 - val_acc: 0.6396\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 859us/sample - loss: 1.4290 - acc: 0.5626\n",
      "Loss: 1.4289896430008633 Accuracy: 0.5626168\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1544 - acc: 0.3033\n",
      "Epoch 00001: val_loss improved from inf to 1.62908, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/001-1.6291.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 2.1543 - acc: 0.3033 - val_loss: 1.6291 - val_acc: 0.4754\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4514 - acc: 0.5414\n",
      "Epoch 00002: val_loss improved from 1.62908 to 1.26991, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/002-1.2699.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.4514 - acc: 0.5414 - val_loss: 1.2699 - val_acc: 0.6147\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2212 - acc: 0.6229\n",
      "Epoch 00003: val_loss improved from 1.26991 to 1.20942, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/003-1.2094.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.2211 - acc: 0.6229 - val_loss: 1.2094 - val_acc: 0.6238\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0717 - acc: 0.6714\n",
      "Epoch 00004: val_loss improved from 1.20942 to 1.08847, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/004-1.0885.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.0716 - acc: 0.6714 - val_loss: 1.0885 - val_acc: 0.6601\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9434 - acc: 0.7113\n",
      "Epoch 00005: val_loss improved from 1.08847 to 1.01836, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/005-1.0184.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.9434 - acc: 0.7113 - val_loss: 1.0184 - val_acc: 0.6925\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8413 - acc: 0.7450\n",
      "Epoch 00006: val_loss improved from 1.01836 to 0.98150, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/006-0.9815.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.8413 - acc: 0.7450 - val_loss: 0.9815 - val_acc: 0.7044\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7365 - acc: 0.7755\n",
      "Epoch 00007: val_loss did not improve from 0.98150\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.7364 - acc: 0.7755 - val_loss: 0.9967 - val_acc: 0.6983\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6505 - acc: 0.7988\n",
      "Epoch 00008: val_loss improved from 0.98150 to 0.97701, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/008-0.9770.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.6505 - acc: 0.7988 - val_loss: 0.9770 - val_acc: 0.7077\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5736 - acc: 0.8218\n",
      "Epoch 00009: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5735 - acc: 0.8218 - val_loss: 1.1013 - val_acc: 0.6942\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5055 - acc: 0.8420\n",
      "Epoch 00010: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5055 - acc: 0.8419 - val_loss: 1.0116 - val_acc: 0.7065\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4515 - acc: 0.8598\n",
      "Epoch 00011: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4515 - acc: 0.8598 - val_loss: 0.9783 - val_acc: 0.7193\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3975 - acc: 0.8748\n",
      "Epoch 00012: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3975 - acc: 0.8749 - val_loss: 1.0541 - val_acc: 0.7207\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3528 - acc: 0.8874\n",
      "Epoch 00013: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3528 - acc: 0.8874 - val_loss: 1.0739 - val_acc: 0.7300\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3214 - acc: 0.8979\n",
      "Epoch 00014: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3214 - acc: 0.8978 - val_loss: 1.1663 - val_acc: 0.7147\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2972 - acc: 0.9059\n",
      "Epoch 00015: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2972 - acc: 0.9059 - val_loss: 1.1027 - val_acc: 0.7147\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2674 - acc: 0.9142\n",
      "Epoch 00016: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2674 - acc: 0.9142 - val_loss: 1.1086 - val_acc: 0.7317\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2478 - acc: 0.9201\n",
      "Epoch 00017: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2478 - acc: 0.9201 - val_loss: 1.1266 - val_acc: 0.7317\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9267\n",
      "Epoch 00018: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2241 - acc: 0.9267 - val_loss: 1.2380 - val_acc: 0.7345\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2139 - acc: 0.9308\n",
      "Epoch 00019: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2140 - acc: 0.9308 - val_loss: 1.1835 - val_acc: 0.7377\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9356\n",
      "Epoch 00020: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1977 - acc: 0.9356 - val_loss: 1.2217 - val_acc: 0.7298\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1899 - acc: 0.9388\n",
      "Epoch 00021: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1899 - acc: 0.9388 - val_loss: 1.2106 - val_acc: 0.7410\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9418\n",
      "Epoch 00022: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1792 - acc: 0.9418 - val_loss: 1.2177 - val_acc: 0.7445\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9442\n",
      "Epoch 00023: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1739 - acc: 0.9442 - val_loss: 1.2132 - val_acc: 0.7440\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1632 - acc: 0.9467\n",
      "Epoch 00024: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1632 - acc: 0.9467 - val_loss: 1.2237 - val_acc: 0.7393\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9523\n",
      "Epoch 00025: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1506 - acc: 0.9523 - val_loss: 1.2297 - val_acc: 0.7503\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9490\n",
      "Epoch 00026: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1550 - acc: 0.9491 - val_loss: 1.3101 - val_acc: 0.7428\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9545\n",
      "Epoch 00027: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1432 - acc: 0.9545 - val_loss: 1.2528 - val_acc: 0.7491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9565\n",
      "Epoch 00028: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1376 - acc: 0.9566 - val_loss: 1.2277 - val_acc: 0.7543\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9587\n",
      "Epoch 00029: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1328 - acc: 0.9587 - val_loss: 1.2834 - val_acc: 0.7463\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9594\n",
      "Epoch 00030: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1254 - acc: 0.9594 - val_loss: 1.2573 - val_acc: 0.7512\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9601\n",
      "Epoch 00031: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1272 - acc: 0.9601 - val_loss: 1.3088 - val_acc: 0.7563\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9635\n",
      "Epoch 00032: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1166 - acc: 0.9635 - val_loss: 1.3402 - val_acc: 0.7519\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9621\n",
      "Epoch 00033: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1178 - acc: 0.9622 - val_loss: 1.2699 - val_acc: 0.7526\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9651\n",
      "Epoch 00034: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1108 - acc: 0.9651 - val_loss: 1.4132 - val_acc: 0.7484\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9651\n",
      "Epoch 00035: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1102 - acc: 0.9651 - val_loss: 1.3315 - val_acc: 0.7519\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9651\n",
      "Epoch 00036: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1135 - acc: 0.9651 - val_loss: 1.3034 - val_acc: 0.7589\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9673\n",
      "Epoch 00037: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1065 - acc: 0.9673 - val_loss: 1.2891 - val_acc: 0.7573\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9679\n",
      "Epoch 00038: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1050 - acc: 0.9679 - val_loss: 1.3043 - val_acc: 0.7566\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9676\n",
      "Epoch 00039: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1026 - acc: 0.9676 - val_loss: 1.3648 - val_acc: 0.7515\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9707\n",
      "Epoch 00040: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0962 - acc: 0.9707 - val_loss: 1.2815 - val_acc: 0.7584\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9684\n",
      "Epoch 00041: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1014 - acc: 0.9684 - val_loss: 1.2798 - val_acc: 0.7626\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9721\n",
      "Epoch 00042: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0930 - acc: 0.9721 - val_loss: 1.3323 - val_acc: 0.7636\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9712\n",
      "Epoch 00043: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0933 - acc: 0.9711 - val_loss: 1.3948 - val_acc: 0.7508\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9677\n",
      "Epoch 00044: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1017 - acc: 0.9677 - val_loss: 1.3555 - val_acc: 0.7570\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9718\n",
      "Epoch 00045: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0898 - acc: 0.9719 - val_loss: 1.4100 - val_acc: 0.7589\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9744\n",
      "Epoch 00046: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0847 - acc: 0.9744 - val_loss: 1.3008 - val_acc: 0.7598\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9749\n",
      "Epoch 00047: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0830 - acc: 0.9749 - val_loss: 1.4419 - val_acc: 0.7363\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9705\n",
      "Epoch 00048: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0953 - acc: 0.9705 - val_loss: 1.3805 - val_acc: 0.7631\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9757\n",
      "Epoch 00049: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0806 - acc: 0.9757 - val_loss: 1.3711 - val_acc: 0.7584\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9750\n",
      "Epoch 00050: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0844 - acc: 0.9749 - val_loss: 1.3315 - val_acc: 0.7626\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9748\n",
      "Epoch 00051: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0840 - acc: 0.9748 - val_loss: 1.3670 - val_acc: 0.7654\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9757\n",
      "Epoch 00052: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0788 - acc: 0.9757 - val_loss: 1.4042 - val_acc: 0.7519\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9755\n",
      "Epoch 00053: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0815 - acc: 0.9755 - val_loss: 1.3700 - val_acc: 0.7601\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9773\n",
      "Epoch 00054: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0755 - acc: 0.9773 - val_loss: 1.4054 - val_acc: 0.7596\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9754\n",
      "Epoch 00055: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0819 - acc: 0.9754 - val_loss: 1.3717 - val_acc: 0.7643\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9774\n",
      "Epoch 00056: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0742 - acc: 0.9774 - val_loss: 1.3874 - val_acc: 0.7710\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9768\n",
      "Epoch 00057: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0775 - acc: 0.9768 - val_loss: 1.3407 - val_acc: 0.7710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9769\n",
      "Epoch 00058: val_loss did not improve from 0.97701\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0742 - acc: 0.9769 - val_loss: 1.3651 - val_acc: 0.7624\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd8W9X5+PHPkSxL3nsksRM7eziJs0ggJECBsErKDnyhjLZQKFD40lLSMkoHZY9CoZBCymhZhbK+UFLgl+AwQhYJZJHhDNuJ916a5/fHsR078YotRR7P+/W6L9nS1blHinOfe9ZzldYaIYQQAsAS7AoIIYToOyQoCCGEaCFBQQghRAsJCkIIIVpIUBBCCNFCgoIQQogWEhSEEEK0kKAghBCihQQFIYQQLUKCXYEjlZiYqDMyMoJdDSGE6FfWrVtXqrVO6mq/fhcUMjIyWLt2bbCrIYQQ/YpSam939pPuIyGEEC0kKAghhGghQUEIIUSLfjem0B63201+fj6NjY3Brkq/5XA4SEtLw2azBbsqQoggGhBBIT8/n6ioKDIyMlBKBbs6/Y7WmrKyMvLz88nMzAx2dYQQQTQguo8aGxtJSEiQgNBDSikSEhKkpSWEGBhBAZCA0Evy/QkhYAAFha54vfU4nQX4fJ5gV0UIIfqsQRMUfD4nLtcBtHb5vezKykqeeuqpHr33zDPPpLKystv733333Tz00EM9OpYQQnRl0AQFpcyYutb+byl0FhQ8ns6P98EHHxAbG+v3OgkhRE8MwqDg9nvZixcvZteuXWRnZ3PrrbeyYsUK5s2bx8KFC5k4cSIA55xzDjNmzGDSpEksWbKk5b0ZGRmUlpayZ88eJkyYwNVXX82kSZNYsGABDQ0NnR53w4YNzJkzhylTpnDuuedSUVEBwOOPP87EiROZMmUKF198MQCffvop2dnZZGdnM23aNGpqavz+PQgh+r8BMSW1tR07bqa2dkM7r2i83losFjtKhR5RmZGR2YwZ81iHr993331s2rSJDRvMcVesWMH69evZtGlTyxTPpUuXEh8fT0NDA7NmzeL8888nISHhkLrv4JVXXuFvf/sbF110EW+++SaXXXZZh8e9/PLLeeKJJzjhhBO46667+N3vfsdjjz3Gfffdx+7du7Hb7S1dUw899BBPPvkkc+fOpba2FofDcUTfgRBicBg0LQVonl2jj8rRjjnmmDZz/h9//HGmTp3KnDlzyMvLY8eOHYe9JzMzk+zsbABmzJjBnj17Oiy/qqqKyspKTjjhBACuuOIKcnJyAJgyZQqXXnop//jHPwgJMXF/7ty53HLLLTz++ONUVla2PC+EEK0NuDNDZ1f0tbUbCAmJw+EYEfB6REREtPy8YsUKPv74Y7788kvCw8M58cQT210TYLfbW362Wq1ddh915P333ycnJ4f33nuPe+65h2+//ZbFixdz1lln8cEHHzB37lyWLVvG+PHje1S+EGLgGkQtBTOuEIiB5qioqE776KuqqoiLiyM8PJxt27axatWqXh8zJiaGuLg4Vq5cCcBLL73ECSecgM/nIy8vj5NOOon777+fqqoqamtr2bVrF5MnT+a2225j1qxZbNu2rdd1EEIMPAOupdCZQAWFhIQE5s6dS1ZWFmeccQZnnXVWm9dPP/10nn76aSZMmMC4ceOYM2eOX477wgsvcO2111JfX8/IkSP5+9//jtfr5bLLLqOqqgqtNT//+c+JjY3lzjvvZPny5VgsFiZNmsQZZ5zhlzoIIQYWpfXR6WP3l5kzZ+pDb7KzdetWJkyY0OV7Gxp24vM5iYiYFKjq9Wvd/R6FEP2PUmqd1npmV/sNsu4jW0CmpAohxEAxyIKC6T7qb60jIYQ4WgIWFJRS6Uqp5UqpLUqpzUqpm9rZRymlHldK7VRKfaOUmh6o+pjjNS9g8wbyMEII0W8FcqDZA/xCa71eKRUFrFNKfaS13tJqnzOAMU3bbOCvTY8B0TbVxaAaYxdCiG4JWEtBa31Aa72+6ecaYCsw7JDdfgC8qI1VQKxSakig6hTI/EdCCDEQHJUxBaVUBjAN+OqQl4YBea1+z+fwwOHHekhQEEKIzgQ8KCilIoE3gZu11tU9LOMapdRapdTakpKSXtQlcEnxjlRkZOQRPS+EEEdDQIOCUsqGCQj/1Fr/u51dCoD0Vr+nNT3XhtZ6idZ6ptZ6ZlJSUi/qIy0FIYToTCBnHyngOWCr1vqRDnZ7F7i8aRbSHKBKa30gcHWyAha/B4XFixfz5JNPtvzefCOc2tpaTj75ZKZPn87kyZN55513ul2m1ppbb72VrKwsJk+ezGuvvQbAgQMHmD9/PtnZ2WRlZbFy5Uq8Xi9XXnlly76PPvqoXz+fEGLwCOQUnLnAD4FvlVLNuax/AwwH0Fo/DXwAnAnsBOqBq3p91Jtvhg3tpc42wr11oKxgOYLU0dnZ8FjHifYWLVrEzTffzPXXXw/A66+/zrJly3A4HLz11ltER0dTWlrKnDlzWLhwYbfuh/zvf/+bDRs2sHHjRkpLS5k1axbz58/n5Zdf5rTTTuP222/H6/VSX1/Phg0bKCgoYNOmTQBHdCc3IYRoLWBBQWv9GQfzVXe0jwauD1Qd2qfwd/rsadOmUVxczP79+ykpKSEuLo709HTcbje/+c1vyMnJwWKxUFBQQFFREampqV2W+dlnn3HJJZdgtVpJSUnhhBNOYM2aNcyaNYsf/ehHuN1uzjnnHLKzsxk5ciS5ubnceOONnHXWWSxYsMCvn08IMXgMvMn6nVzRAzjrt6O1l4gI/+b4ufDCC3njjTcoLCxk0aJFAPzzn/+kpKSEdevWYbPZyMjIaDdl9pGYP38+OTk5vP/++1x55ZXccsstXH755WzcuJFly5bx9NNP8/rrr7N06VJ/fCwhxCAzqNJcQOAypS5atIhXX32VN954gwsvvBAwKbOTk5Ox2WwsX76cvXv3dru8efPm8dprr+H1eikpKSEnJ4djjjmGvXv3kpKSwtVXX81PfvIT1q9fT2lpKT6fj/PPP58//vGPrF+/3u+fTwgxOAy8lkIXApUUb9KkSdTU1DBs2DCGDDHr7y699FLOPvtsJk+ezMyZM4/opjbnnnsuX375JVOnTkUpxQMPPEBqaiovvPACDz74IDabjcjISF588UUKCgq46qqr8Pl8ANx7771+/3xCiMFhUKXOBnA6D+ByFRAZOR2lBl1DqVOSOluIgUtSZ3dA1ioIIUTHJCgIIYRoIUFBCCFEi0EcFIKf/0gIIfqaQRwUpKUghBCHkqAghBCixSAMCsrvC9gqKyt56qmnevTeM888U3IVCSH6jEEXFMD/q5o7CwoeT+fH+eCDD4iNjfVbXYQQojckKPjB4sWL2bVrF9nZ2dx6662sWLGCefPmsXDhQiZOnAjAOeecw4wZM5g0aRJLlixpeW9GRgalpaXs2bOHCRMmcPXVVzNp0iQWLFhAQ0PDYcd67733mD17NtOmTeOUU06hqKgIgNraWq666iomT57MlClTePPNNwH48MMPmT59OlOnTuXkk0/222cWQgxMAy7NRReZswHw+UagtQ+rtXtldpE5m/vuu49NmzaxoenAK1asYP369WzatInMzEwAli5dSnx8PA0NDcyaNYvzzz+fhISENuXs2LGDV155hb/97W9cdNFFvPnmm1x22WVt9jn++ONZtWoVSimeffZZHnjgAR5++GH+8Ic/EBMTw7fffgtARUUFJSUlXH311eTk5JCZmUl5eXn3PrAQYtAacEGhe/yfPvtQxxxzTEtAAHj88cd56623AMjLy2PHjh2HBYXMzEyys7MBmDFjBnv27Dms3Pz8fBYtWsSBAwdwuVwtx/j444959dVXW/aLi4vjvffeY/78+S37xMfH+/UzCiEGngEXFLrInA2A01mGy3WAyMgZ3brhTU9ERES0/LxixQo+/vhjvvzyS8LDwznxxBPbTaFtt9tbfrZare12H914443ccsstLFy4kBUrVnD33XcHpP5CiMFp0I4pAGjt9Ut5UVFR1NTUdPh6VVUVcXFxhIeHs23bNlatWtXjY1VVVTFs2DAAXnjhhZbnTz311Da3BK2oqGDOnDnk5OSwe/duAOk+EkJ0aZAHBf8MNickJDB37lyysrK49dZbD3v99NNPx+PxMGHCBBYvXsycOXN6fKy7776bCy+8kBkzZpCYmNjy/B133EFFRQVZWVlMnTqV5cuXk5SUxJIlSzjvvPOYOnVqy81/hBCiI4MudTaAx1NFQ8MOwsLGExIS6e8q9luSOluIgUtSZ3dCVjULIUT7BnlQkKR4QgjR2iAPCtJSEEKI1gZpULACFgkKQghxiEEZFMD/qS6EEGIgkKAghBCihQSFIImMlKmwQoi+R4KCEEKIFoM4KNj8NiV18eLFbVJM3H333Tz00EPU1tZy8sknM336dCZPnsw777zTZVkdpdhuLwV2R+myhRCipwZcQrybP7yZDYVd5M4GfD4XWjuxWqO63Dc7NZvHTu84096iRYu4+eabuf766wF4/fXXWbZsGQ6Hg7feeovo6GhKS0uZM2cOCxcu7DQJX3sptn0+X7spsNtLly2EEL0x4IJCh7xecLvBbgelUEphMnxoTCrtnps2bRrFxcXs37+fkpIS4uLiSE9Px+1285vf/IacnBwsFgsFBQUUFRWRmpraYVntpdguKSlpNwV2e+myhRCiNwZcUOjwir6qCnbsgPHjITISt7uCxsZdhIdPxGoN7/VxL7zwQt544w0KCwtbEs/985//pKSkhHXr1mGz2cjIyGg3ZXaz7qbYFkKIQBk8YwoOh3lsukeBv1c1L1q0iFdffZU33niDCy+8EDBprpOTk7HZbCxfvpy9e/d2WkZHKbY7SoHdXrpsIYTojcETFEJDQSlouvL2d/6jSZMmUVNTw7BhwxgyZAgAl156KWvXrmXy5Mm8+OKLjB8/vtMyOkqx3VEK7PbSZQshRG8MrtTZmzeb4DBmDD6fm7q6jdjt6YSGpgSotv2LpM4WYuCS1NntcTjaaSnIWgUhhGg2+IKC0wk+H0opWcAmhBCHGDBBoVvdYM2DzU4nIKuaW+tv3YhCiMAYEEHB4XBQVlbW9YmtOSi06kKSoGACQllZGY7m70cIMWgNiHUKaWlp5OfnU1JS0vmOPh+UloLHAzExuFwlaO3GbvcdnYr2YQ6Hg7S0tGBXQwgRZAELCkqppcD3gWKtdVY7r58IvAPsbnrq31rr3/fkWDabrWW1b5fOPBPmz4eXXuK77x6jtPQdsrMLe3JYIYQYcALZUnge+AvwYif7rNRafz+AdTjc+PGwbRsANlsibncpWutO8xEJIcRgEbAxBa11DlAeqPJ7rDkoaI3NlgR48Xgqg10rIYToE4I90HysUmqjUuo/SqlJHe2klLpGKbVWKbW2y3GDrowfD7W1sH8/NlsiAG53ae/KFEKIASKYQWE9MEJrPRV4Ani7ox211ku01jO11jOTkpJ6d9TmVBNbtxIaaspyu3sZaIQQYoAIWlDQWldrrWubfv4AsCmlEgN+4OagsG2btBSEEOIQQQsKSqlU1TS6q5Q6pqkuZQE/cGoqREcfEhSkpSCEEBDYKamvACcCiUqpfOC3gA1Aa/00cAFwnVLKAzQAF+ujsaxWqZbBZjPQDC6XBAUhhIAABgWt9SVdvP4XzJTVo2/8ePjkE6zWcGy2FOrqNgWlGkKIXnrqKdizB+67DyzBnjczMAyIFc1HbPx4ePFFqKkhNnY+VVWfyloFIfqb2lpYvBhqaszNsx5/3PQEiF4ZnKG1ebD5u++IjT0BpzOfxsY9Qa2SEF3ySJ6uNl57zQSEM8+Ev/wF7rkn2DUaEAZ3UNi2jZiY+QBUVeUEsUJCdGHfPoiLg2eeCXZNAu///T+4/HLTEujMkiUwcSK89x5ccQXceWdgv5/du1uSaXaqoQE++QS83sDVJYAGZ1AYNQqsVti2jYiISYSExFNZ+WmwayVEx557zpwk//d/Yfv2YNemZ776CqqrO9/ngw/Mlf9LL5nuoI5s2ACrV8M115ixhL/9Db7/fbjuOnjjDf/Wu77efO+jRsGkSaaOHfnoI8jKglNOgZkz4Ysv/FuXo2BwBoXQUPMPvG0bSlmIiZlHZaW0FEQf5fXC0qUwezaEhZmr6P7WlfTMMzBnDkyZAjkd/F97+20455yDJ9UHH4TKDlLQ/O1vYLfDD39ofrfZTHfSccfBpZea1oY/5OTA1Knw2GOmNRIaCmedBeedZ1pvzUpKTF0WLDAXnA89ZDIyz50LV10FxcVty/V6TVD74x/hySdNBue+Qmvdr7YZM2Zov1i4UOtJk7TWWu/b94hevhzd2Jjvn7KF8Kf339catH7jDa1fe838/Mc/BrtW3ffWW1pbLFqfdJLWo0drrZTWt92mtdN5cJ/XXtM6JETrOXO0rqjQ+uuvzee8667Dy6ur0zo6WuvLLjv8tfJyrbOytA4N1XrGDK0vv1zr++7T+r33tN69W2ufr3t1rq3V+sYbTR0yM7Vevtw873Rqfe+9WoeFaR0ebsp+7jmt4+O1ttm0vvNOrRsazL41NeZz2mxax8Ro/dhjWi9dqvWiRWZ/OLidc47ZP4CAtbob59ign+SPdPNbUPjVr8wfjtutq6vX6uXL0YWFL/unbCH86dxztU5KOngSveQScwJdvz4wxyss1PrVV7t/Au3MypVaOxxaz55tTrQ1NVpffbU59WRna715s9YvvWSCxrx5WldXH3zvBRdoHRWldUlJ2zL//nfz/pyc9o954IDWv/iF1qeeqvXQoW1Pvt//vtZFRZ3X+eOPtR450uz/85+beh9qzx6tf/CDg+Uef7z5LO3ZulXrU045uG9KiglWL7+sdXGx1n/+s/n8U6aYcttTXq71gw9q/emnnde9ExIUurJ0qfn4O3Zon8+jc3Ki9LZtP/VP2UL4y4EDJgD88pcHnysrMye7SZMOXpX6S0mJ1hMmmP8bzz7bu7I2bdI6NlbrsWMPP7G//bbWiYla2+2m5fC97x1+8t282bz2q1+1ff7YY7UeP777QauiQuvPPzetK7td6+Rk03I4VEmJOVmDadF05wT8n/9o/Y9/aO31dr6fz2eC2Ndft7/vhx+a1kRysqlrs61btb7uOtMqAa0XL+66Th2QoNCVL74wH7/pj2PjxjP0V19N8E/ZQnRXXZ3WjY0dv37ffebvdNu2ts9/+KF5vnWw6K3qaq1nzjQnzilTzFV6R1euXcnL0zotTevUVNNt054DB7Q+/3ytL7xQ6/r69ve57DLTVXPggPn9m2/M537kkZ7Va9MmradONWVcd535/n0+rV94QeuEBBOAb7+94/oE0tatWo8aZXow/vAHrU87zdTTbtf6qqtMQOkFCQpdKSszH//BB7XWWu/de59evhztdHbRtBTCHxobtX74YXMlPWtW+ychn89csc6b134Z111nrqQ/+aT39WloMH3+VqvW776rdW6u1pGRWp988pF3I5WXm1ZMdLTWGzb0rl47dpg63XST+f3GG81Js7S052U2NppgqpTW48aZzwimBfLtt72rb2+Vlpp/B9B6yBATHIqL/VK0BIXuSE7W+sc/1lprXVn5hV6+HF1c/Ib/yhfiUD6f1v/618E+6+OOM49XXHH4yXfFCvPaiy+2X1ZtrdZjxpj+6MsuO7w10V1utxnoBNO/3+zpp81zTz3V/bIKC00rIzTUP8FKa61/8hNT3nffmSD6P//jn3I/+cS0ZqKjzWfsqgvoaHG5TNdV64F4P5Cg0B3z52s9d67WWmuv16k//TRMb99+o//KF31ffr65sj0aVq0yf29gZsgsW2ae/+1vzXNPPNF2/0svNf3MdXUdl1lcrPWtt5o+Z4vFvOdIgoPXq/WVV5rjP/5429d8PjNYGxGh9a5dXZe1Z49p2YSHa/3f/3a/Dt0p12Yzs4DABEt/qa09ev/+QSZBoTuuucZMDWu6Qvv665P16tVT/Ve+6NsKCsy/f0ZGz/vOu+vJJ013RUqK1kuWaO3xHHzN69X67LNNf3bz4GZ5uelL/tnPuld+UVHb4HDBBVo//7zWe/e2v/+BA6ZVsHChOQ387nft77dvn7mSnj+/8yvpLVu0HjbMXMm3Hij1l+uvN/UcO9Y/s6IGIQkK3fHII+YraOqz2737d3r5cqVdrsFx5TCoeb1aL1hgTqIxMaY7Jy/P/8fx+Q62BBYubDvlsrXKStO/nZRkTsRPPGHec6SDi83BITFRt0yBHDnSdJM++6zWt9yi9eTJB19LSND67rs7P9E2z9R77LH2X1+71hwvJUXrjRuPrL7dVVBgAs6TTwam/EGgu0FBmX37j5kzZ+q1a9f6p7D//Mcsqc/JgXnzqKz8lA0bTiQr610SE8/2zzFE3/TEE/Dzn8Nf/wrTp8Opp0JyMnz6KQwd2r0yvF644w5wu+GmmyA9ve3rPp85xpNPwpVXmlW4IZ0kJt62DY45BsaNMzl27Hbo6d+6zwebNsHy5Wb79FOzOjg0FI4/3nzeU0+FadO6TjmtNZx9tsnnc8MNZlW1w2E2nw9+/3uIjzcpHsaM6Vl9u8PpNPWXTKg9opRap7We2eWO3YkcfWnza0shN9dcAT3zjNZaa4+nXq9YEap37PiF/44h+p7Nm82CqrPOOniF/MUXZrbN2LEHpz92xuM5OKfdYjFdP5dffnD2itNpVq6CuXLvbpfH228fvIp/+umefb6O6rt1a+fjE50pKDDjIGFhphus9YKwiRMD08oSfoV0H3WD12sWAY0Y0fJHvX79PL127Sz/HUP0LU6n1tOmme6OQ0/+K1eaQdUJEzpf9erxmNk+oPXvf2/GI2666eACo7POOjjN8YEHjryOf/qTGbCtrDzy9x4NPp/5HquqzGyj1uMjos+SoNBda9eaRToTJmhdUqJ37bpdL19u1W53B32/on/79a/Nn/1bb7X/+ooV5mp49GgzEOtytX3d7TZTItvLP1RaagZsExPN3PqlS3teTxlMFX7W3aAwOLOktjZjhsnHnpsLZ55JrHUW4KW6uv+lvO0zCgtN/3Nf89lncP/98KMfmWyc7TnhBDPWFBJisl5mZsIDD5j+eI/HPPfyy/CnP8Htt7d9b0IC3HUX7N0LO3aY7Jg9Jf3mIkgG90Bza++9B+eei2/+8Xy2eCVpo29j5Mg/+f84g8H3vmcGN++/H371q6N/fJ8PDhyAggLIzzePBQXmZG6zmVz8UVFdl/Hhh/DIIybARUSYG7qsWRO8zyVEL3R3oHlw3qO5PWefDc8/j+WHP2SyjmP3/cthZLAr1Q99+qkJCKNGwW23mVk0d97Z/pXv9u1m1k5VlZkBNH26ablNnGhO3h6POanv2WO2/fshMhKSkiAx0TwmJEBREWzcaE72GzaYn2tq2h4rNNRc9b/wQtcBAcyMnDPPNNuGDfDoo/D66yZP/i9+4Y9vSog+SVoKh2qaqliwEOJf3U1YWEbgjjUQnXiiOdlv326mL77wAvzmN+ZmIs2Bwecz99RdvNhMa8zKMife5hO53W6mh+7ff2S3NIyMNDdEyc42d8hKT4dhw8yWmNj11Muu+Hy9L0OIIJGWQk/deCOe775m6FN/p+CLR0g7uZNbAoq2mufDP/64OUEvXWqu0P/0J9NieOgh099+1VWwYoW5g9WSJWZdgM8HO3fCunWwfr25+h8xAjIyDm7DhplbUpaWmq2kxDzGxZn59pmZgT1pS0AQg4C0FNpTXIxv+BBKTgsn+e0qlJKTQZe0NoO0ubnm5O5wHHz+pptMC+yss0zQUMrc3vCqq2RAVYijpLsthW6d7ZRSNymlopXxnFJqvVJqQe+r2UclJ9N48Ykk/aeW6u/eCXZt+odPPoGVK+HXvz4YEMCc9P/8Z/jlL+H992HWLPj2WzMDSAKCEH1Ody+Bf6S1rgYWAHHAD4H7AlarPsB++59RXvA8dFewqxJYS5bA55/3rgyt4be/hbQ0+MlPDn9dKTOtc+tW+Phj0y0khOiTuhsUmi/pzgRe0lpvbvXcgGQdk0XNaZnEvLoJT1lBsKsTGB99BD/9KSxY0PMcO83lfPGFGVC229vfRykYP1765YXo47r7P3SdUuq/mKCwTCkVBfgCV62+QS2+g5A6aHj0f4NdFf9zOuH6683U0eRk09+fm3vk5TS3EtLTTZeQEKJf625Q+DGwGJilta4HbEAvlmv2D5HzrqLymDAcz7xjTqIDyYMPmlW3Tz1lFml5PHD66WY2z5FYtgxWrTKreztqJQgh+o3uBoVjge+01pVKqcuAO4CqwFWrb1BK0fjzRdhKXbieezTY1fGf3bvhnnvgwgtN19G4cfDuu7BvHyxcCPX1XZeRmwsPPwzXXWfGCHqT0kEI0Wd0Nyj8FahXSk0FfgHsAl4MWK36kNjz7qZmDGaO/ZEspOqrtIYbbzS5fR5tFejmzjVpIFatgksvPfyzNjSYlcJ/+INZEzBqlJlRFBcHzz1n1iMIIfq97gYFT1OWvR8Af9FaPwl0I1dA/+cIG0HZTyYTursM/fZbR+egBQXw5ZeBKfvdd83U0N/9ziwGa+2888z00bffhlNOMd1JkyebG6iEh5uVwr/9rckD9PDDprWwfj2cfHJg6iqEOOq6tXhNKfUp8CHwI2AeUAxs1FpPDmz1DndUFq8domj/S0TPuhxb6nhC1m4J/Pz6444zs4G+/tqka/CXujqTVyg62pzMbbb29/v9783Vf0rKwTQRw4aZweRTToHUVP/VSQhxVHR38Vp3g0Iq8D/AGq31SqXUcOBErfVR70IKRlDweuvJvS2BMQ83mtQNgew//+IL05UD5raJn37qv2mcv/413HefWWR2/PH+KVMI0S/4dUWz1roQ+CcQo5T6PtAYjIAQLFZrOL6rLqVihgV93XWwenXgDvbQQ6a75oknTP7/557rXXlam7GA224zZV95pQQEIUSHupvm4iJgNXAhcBHwlVLqgkBWrK8Zkn41W+704U2ONH3vhYX+P8iOHaY//7rrzBqCE04wefuLio68rN27TSK6rCwzFvDIIyYN9IMP+r/eQogBo7v9Erdj1ihcobW+HDgGuDNw1ep7oqNn40ibzdY/RaDKL2FaAAAgAElEQVTLy810TpfLvwd59FHTz3/DDWbc4umnzfTQW245snJ+8xsYOdKsHYiLM2sRDhyAd94xKaSFEKID3Q0KFq11cavfy47gvQNGWtrNlKXto/bPN5iunf/140rn0lJ4/nlzu8fmgdzx4804wMsvw3//271y3nkH7r0XLrvMtBY++8y0PCQYCCG6obsn9g+VUsuUUlcqpa4E3gc+6OwNSqmlSqlipdSmDl5XSqnHlVI7lVLfKKWmH1nVj76kpPMJDR1G7jFfmzn6Tz1lBp794a9/NWsBDm0VLF4MY8eaE3tXi8r27TOD4NOnw7PPmnsQCCHEEejuQPOtwBJgStO2RGt9Wxdvex44vZPXzwDGNG3XYBbI9WkWi41hw26gouJjam//HzM987rrTObP3mhsNAPLZ55ppoy25nCYbqTcXHP3so643XDJJSZdxWuvScoJIUSPdLsLSGv9ptb6lqaty1VcWuscoLyTXX4AvKiNVUCsUmpId+sTLEOHXo3FEkZ+4ZPw6qvmbl+nnmrGAWpre1boSy+Zu4j98pftv37SSWbW0IMPmruaeTyH73PXXWY665IlMHp0z+ohhBj0Og0KSqkapVR1O1uNUqq6l8ceBuS1+j2/6bk+zWZLICXlcoqK/oErymduH3nTTaYrKSur/VZDQ4MZE3jkETM9tPXaEJ/PrA6eNs3c37gjDz8M3/ueOda0aeZ2ls2WLTPrD66+Gi6+2F8fVQgxCHUaFLTWUVrr6Ha2KK119NGqpFLqGqXUWqXU2pKSkqN12A6lpd2E1k7273/GpHx47DGzIMzhMK2Gn/zE5BB64AHze1wcnHYa/OIXZnpoVpZJSJebCx98AN99Z1oJna2Ujo832Uzfesvc4P6kk0wAWLPGDE5nZZl6CCFELwT0Hs1KqQzg/7TWWe289gywQmv9StPv32FWSR/orMxgrGhuzzffnEFt7QbmzNmLxdKUDK6x0eQUeuAB0wIAc7I+9VSTjXTSJJN36OWXTRABc4P7uDjYtavjtBOHamiA++83W2OjyUu0Zs3h4xFC+JHHA1Zrx9cuWptMKhUVpifVajV/0iEh5tFmM3/unQ13eb3m/c1ltN7q6kwdfL62m91uJte13iIizIS+wsKDW1GRKT8kxNSt+dFiMZ+peWtdF4+n7dZ8umzeTymzX2Nj283tNvVyOCAszGwOhymjocFs9fXm0e029WjeLBbz2Pydtn486ywzG74nuruiOaRnxfvFu8ANSqlXgdlAVVcBoS9JS7uZb745neLi10lNvcw86XCY6aCXXAKbN5vFZ0OHtn3jtdeabd8+Mybx9tvws591PyCA+Qu7+2644gqTtfTssyUg9GFamxOH220aeVVVbTev1ySZbb0pZfatqYHqavNYW9v9RL0+nznp1Nebk2nzzx6PKcPnM4/N5VksB0+OFot5vbr64FZVdfCWIuHh5qTb/OjxmJN4ZaX5jF1xOCA21mwxMeb7KSszW2Vlz77jYGs+6TdvISFmGVNzAGhoODgUGBZmvrvmYGGzHfy3aP3v0jrwND+OHx/4zxKwloJS6hXgRCARKAJ+i7k5D1rrp5VSCvgLZoZSPXCV1rrLJkBfaSlorVmzZhIWSxgzZqxFyU3o+ySfz5xsDhyA4mLzHzYm5uAWFWWu7A4caLuVlR28kmu9NZ9cm7eGBnOybP6P3Lw1n3yb/6MHQ+uTd/PWfHXc3hVp85W31uYEFB19cIuJMVf5bnfbQFNXZ8qIizMn+bg4s0VFmbI8HvOe5seaGnPir6oyjxUV5lgJCW235jIiI81naH602Q4GsOatocH8e5WWHtxqaswNBVNTzZaSYn5vPgE3//s0tzy0PvyqPCSk7XZoK6n1qbM7//27amkFWtBbClrrS7p4XQPXB+r4gaaUIi3tJrZvv5aqqs+IjZ0X7CoNKM0nkNZXq81Xy80no0O35i6Gujpzwtm/33QbdOfqtT3NV3Ktr+qaT64xMQeft9vbNv9bn3gP/Tkqqm1Qiok5eFXpdptHl8ucqKKizBYdffAEGdLN/7HNJ/bBIj29+/s2n+R760i/X38c82joJ9Xsm1JSfsju3XewZ8/vmDr1I2kttMPlOtg1UFZmZt4WFx98LC42V4vNXRTNjw0N3T9G8xVx6y0mxtxQbuhQsw0ZYq4UGxsP774JCzOvt94SEvyXnDYY5E9R9JQEhV6wWsMZMeJOdu68ifLyD0lIOCPYVTpqfD7TTC8ogLw8M0TSetu/3wSBzpZuxMdDUtLBLoORI83JvHW3RfPWfNXc3I3QvIWH9++TtxB9jQSFXho69Fry8x8nN/dXxMcvQClrsKvkF82Df9u3H9x27oT8fBMIDhw4vFvGbofhw802f/7h/cTx8eZqPTnZ/H4kY+tCiKNDgkIvWSyhjBx5L1u2XERh4fMMGfLjYFfpiFRWmmUSO3eazN3Njzt2mG6dZiEhZvF2erqZVDVsmOmWab4h2/Dh5mQv3RZC9G8SFPwgKekCoqPnsHv3nSQnX4zVGhHsKh1Ga9izBzZsMNvGjeZx796D+yhlTu5jxsCiRaZPfuxYs40YIVf2QgwGEhT8QCnFqFEP8fXXx5OX9wgZGcG/1UR9vbnN85dfHtyKm5KfWyzmRH/ssWbJxMSJJhBkZpopm0KIwUuCgp/ExMwlMfFc8vIeYOjQawgNTTmqx3e54Kuv4KOPTPqlNWsOLpYZMwbOOAPmzDFZtbOyzACtEEIcSoKCH40ceR+rV7/Lnj2/Y+zYpwJ+vH37zD11li0z+fHq6kwrYNYsuPVWOO44Ewjk/jpCiO6SoOBH4eFjGTr0p+zf/wzDhv2ciAj/r0nfutXkxPv3v02CVjCZsi+/3KRYOukks7JUCCF6QoKCn2Vk/JaiopfIzV3M5Mlv+6XMXbvgn/+EV16BbdvMc7Nnm2zZ555rxgeEEMIfJCj4WWhoMsOH38bu3XdQVfU5MTFze1ROSQm8/jr84x8mC7dSZiroDTfAOeeYqaBCCOFvshY0ANLSbiY0NJXc3MUcScJBn8/ci+e888wagBtuMLOI7r/fTB1dvhyuv14CghAicKSlEABWawQjRtzFjh0/o6zsfRITv9/p/qWl8Pzz5lbMu3aZgeGbbzb3zpky5ejUWQghQFoKATNkyE8ICxvN7t2/RuvDk+BrbbqFLr8c0tLMbKGhQ839d/Lzze2YJSAIIY42CQoBYrHYyMy8h7q6TRQV/aPl+bo6ePZZmDHDLB57+21z985vv4WcHHN/ns7uTCWEEIEk3UcBlJR0AZGRM9i9+y6czkU8+qiD55836ZonTzbdRZdeajJ/CiEGH6/PS5277rDnQywhhNuCs8JUgkIAKWUhIeEh7rjjS958MwSfDy64wNx9c+5cSR4n+ievz0tFYwVl9WWUNZRR56rD4/Pg8Xlw+9x4fB5CraHMGjqLYdFHf1ZEnauOz/M+J9oeTXJEMknhSUSGRrbc78SnfVQ0VFDWUEZZfRmVjZXUuGqoddVS46yhxlWDT/uYNXQWx6UfR4wjpsNjaa3xai9WZW1zPxWtNVXOKorriimpK6GkvoTiumLyqvLYW7WXvVV72Ve1j/zqfDw+T7tlp0SkMD5xPOMSxjEucRzjEsaRnZod8O9UgkKAOJ3w5JNwzz0nUl5+Iqee+i+efPI0xoyJDnbVBq0aZw0RoRFYVNe9pl6fl5L6EopqiyisLaSorojyhnJSI1MZHT+a0fGjiXUcvkrQ6XFSXFdMUV0RRbVFLY+FtYWUNZQRGRpJYngiSeFJJIYnkhieiD3Ejtfnxau9LY8WZSE+LJ6EsAQSwhOIdcS21NvpcVLZWNmy7a/Zz57KPeyt2sueyj3sqdxDSX0JodZQ7FY79hA7jhAHdqudEEsIVosVq7K2PEbZo0iNSCUlMoXUyFRSIlKICI0gryqvpbw9VXvYW7mXkvoSKhoq0HRvVt2ImBEcl34cx6Ufx5y0Obi8LvKq8sirziO/Op+86jzKG8pp9DTS4G4wj54GnB5nS4Dx+Dy4vW40mpMyTuKGY27grDFnYbW0TVNf0VDBX1b/hT9/9WfKGsravGa32kkMT6TB03BE9bcoC1NTpjJ/xHzmps+l0dPIjvIdZiszj9XO6jb7W5SlJVi0V96wqGGMiB3B3PS5DI8ZTkJYwmE36Gr0NLKzfCfflX3HG1vfoLyhHIBfHvtLHlzwYLfq3lMBu0dzoPSVezR3RGt47TVYvNhMI12wAO68cysez0RGjLiDzMw/BLuKfV5ZfRnby7a3nPSqnFVUNlZS7axGa41FWbBarC3/ASNDI1uuCJMikkgKT8KnfWwo3MD6A+v5uvBr1h9YT0FNAY4QB5mxmWTGZTIydiQj40bi0742J6n86nwKawvx6c5vrpwQlsDo+NGEWEIoriumuK6YKmdVu/tGhUaRGJ5InbuO0vrSLss+lEVZiLHH0OAxJ872RNgiyIzLJCM2g+TwZDzaQ6OnEafHidPrpNHTiMfnaROAPD4P1c5qiuqKqHfXt1tuUngSGbEZjIgdQXJ4MonhiSSEJ7QErMjQSGwWGyGWkJatxlXDV/lf8Xne53ye9zn7a/YfVm5kaCTp0ekkhCcQFhJGmC0MR4iDsJAw7FY7Nqsps7lsp9fJ65tfp6CmgBExI7h25rX8eNqP8Wovj375KE+tfYpaVy1njz2b62Zeh0/7KKkvablSL60vJSwkrE3d48PiiXPEEWWPIio0iih7FJGhkbi9blblr2LlvpXk7M1hVf4qGjwNLf8WI2JGMCZhDGPjx5IckYxP+1o2r/aiUCb4N/09JkckkxSRREpECjbrkacbLq0v5bvS70gMT2Rc4rgjfj90/x7NEhT8aMsWs7Zg+XLIzjYziE45xby2efPFlJW9x+zZO7Dbhx71ujk9TgprC0mPSe/WlfKhKhsr+SLvC1xeV5vntdY0ehqpcdW0NL2bH6ucVVQ1VlHtrKbKWUW9u5606DRzpR1nrrZHxY+itL6UdfvXse7AOtYfWM/eqr3t1iHEEoJFWfD6vPi0r1tXexZlYXzieKYPmc7ExImUN5STW5lLbkUuu8p3UeOqAQ6eoNKi00iPTmdo1FCGRA0hJaLp6jkyhfiwePbX7Gdn+U52lO1gZ/lOdlbsRGtNckRyy5YSkWIeW115h9nCWurk0z4qGysprS+lpK4El9fV5uo9xBKC1+elvKGcsoYySutLW7o5wmxhxDpi22zJEclkxmYSHxbfq1vC1rpqTauotohaVy3pMemMiBlBRGjvUsFrrcmrzmNNwRrCbeGkx5jvOcYec8T19fg8vLPtHZ5c8yTL9yzHbjWzMtw+NxdNuohfH/9rpqT4f9qey+vim6JviLBFMDJuJPaQ/jcbRILCUVRTA7//PTz2mLll5J/+BFdfbW7W3qyhIZc1ayYRF7eArKy3/XY/55I6cwXk9DpxeV04PeaxpL6EzcWb2VK6hS0lW9hRtgOv9pIckcypI09lwagFnDryVIZEDemw7F3lu3j3u3d5b/t7rNy3ssO+z0NF2CKIskcRY48hxhFDtD2aGHsMYbYw9lXtY2f5znavHEfHj2bGkBnMGDKDiUkTiQ+Lb3Pyc4Q4Duu39WkfNa6aw/pufdpHdmo2U1KmdDhgp7WmvKGcEEsI0fZoucd2P7OlZAvPrH0Gr/Zy0+ybGJMwJthV6tMkKBwl//qXWWi2f7+ZWnrvvR1nJc3Le5hdu37JhAmvkJJyMWCuGhWqWyckr8/L5pLNfJH3BZ/nfc4XeV+QW5Hb4f4WZWF0/GgmJU1iYtJEhkQO4Yv8L/ho10eU1JcAMDl5MiNiRxz23l3lu9hauhWASUmTOHvs2Zw++vR2B90cIY6WpneELeKwvt721LnqzNV6xS5i7DFMHzK90wE9IUTvSFAIsMpKk3Li5ZfNPQr+/ISbyJGb+Sr/K1YXrKa8sZyhkUNJi05jWPSwpuZyFB+tu4TtFfupsp/CtrJdbC/bTmpkKvOGz2P+iPnMGz6PCUkTsCgLZfVlfFXwFV/mfcmqglWsLljdMqiVEpHC3OFzOTbtWNKj082gYoidUGsoodZQ4hxxjE0Y224z16d9bCzcyH93/ZePd3/cMojVWmJ4ImeOPpOzx53NyLiRAf8+hRCBJUEhgFauhMsug/zSSubf9giuYf+PrwvXtwxEJYQlkBqZyv6a/VQ0Vhz2fgWkR0YybdjJjEsYx96qveTszeFA7YGW98eFxbGzfCdgrvinpExhzrA5zB0+l+PSjyMzNlO6O4QQ3dbdoCBTUo+A2w133w333u8l4dRniZ53B5+6yzhWHcu1M6/lmGHHcMywY9qcsOvd9RRUF5BfnU95Qzmj4kfhqP03hfl/ICvrKhITfwCY/u3cilxy9uaQsy+HqsYqfjztx8xJm8PMoTOJDJUVbkKIwJOWQjft3QsXXghrSpYT9z83UxH6DfNHzOex0x5j2pBpR1SWz+dm3bpZuN3FzJq1GZstLkC1FkIIo7stBcl91A1r1sDM7+Xx9djz4crvEZ1Uxb8u/BcrrlhxxAEBTF6k8eOX4nIVs2vXLwJQYyGE6BkJCl14620fc29+irJLJmIb/yF/POmPbL1+KxdMvKBXffpRUdMZPvxWCgv/Tnn5Mj/WWAghek6CQge0ht88/B3nvXsi7gXXMy9jDpuv38Tt829vsxCpN0aM+C3h4RPYtu1KXK5iv5QphBC9IUGhHY0uN8fddi/3Vk7FNuxbnj7j76z48X/JjMv063GsVgcTJ76K213Btm1Xoo8w9YEQQvjboJ99VFBdwOd5n7O1ZCtbS7eypWQLW4q2441wMtZ9Act/9QRDo1MDdvzIyCmMHv0wO3bcQH7+n0lP/9+AHUsIIboyqINCeUM5k56aRJWzCoUiMy6TOM8EvF+cxkWzTua1e04/KvUYOvRnVFR8TG7ubcTGzicqasZROa4QQhxqUAeFFze+SJWziv+75P84KfMkqsvCycqCGRnwj7uPXj2UUowb9xxr105ly5aLmTFjPSEhUUevAkII0WTQjilorXlm3TPMHjabs8aeRVhIOFdfDbW18NJLYDvy7La9YrPFM2HCP2loyGXHjuuP7sGFEKLJoA0KOXtz2Fa6jZ/O+CkAS5fC//0f3HcfTJgQnDrFxs5nxIg7KSp6icLCl4JTCSHEoDZog8Iz654hxh7DoqxF5OaaTKcnnQQ//3lw6zVixB3ExMxn+/ZrqanZENzKCCEGnUEZFErrS3lz65tcPvVy7JZwrrwSLBZ4/nnzGEwWSwgTJ76GzRbPpk0LcbmKglshIcSgMiiDwvMbnsfldfHTGT/lkUdM1tMnnoDhw4NdM8NuTyUr6x3c7lI2bToPn88Z7CoJIQaJQRcUfNrHM+ue4fjhx5MZOYm77oIf/AB++MNg16ytqKjpjB//AtXVX7B9+3X0t8SFQoj+KaBBQSl1ulLqO6XUTqXU4nZev1IpVaKU2tC0/SSQ9QFYvns5O8t38tMZP2X1amhsNHdM64u3JkhOvpARI+6isPDv5Oc/GuzqCCEGgYAFBaWUFXgSOAOYCFyilJrYzq6vaa2zm7ZnA1WfZs+se4b4sHgumHgBn31mnps7N9BH7bmMjN+SmHg+u3bdSlnZf4JdHSHEABfIlsIxwE6tda7W2gW8CvwggMfrUmFtIW9te4srp16JI8TBypWQlQVxffh2BkpZmDDhBSIjp7Bly8XU1KwPdpWEEANYIIPCMCCv1e/5Tc8d6nyl1DdKqTeUUuntFaSUukYptVYptbakpKTHFfr713/H4/NwzYxr8Hjgiy/g+ON7XNxRY7VGkJX1DiEhcWzY8D2qqr4MdpWEEANUsAea3wMytNZTgI+AF9rbSWu9RGs9U2s9MykpqUcH8mkfS9Yv4cSMExmXOI5vvzWrl+fN63nljyaHYzjTpuUQGprExo2nUlGxIthVEkIMQIEMCgVA6yv/tKbnWmity7TWzfMtnwUClgnuv7v+y57KPVw741rATEOF/tFSaOZwDCc7OweHYwTffnuG3JxHCOF3gQwKa4AxSqlMpVQocDHwbusdlFJDWv26ENgaqMqkR6dz3czrOHfCuQB89plZl9BX1iZ0l90+hOzsFYSFjePbbxdSWvpu128SQohuClhQ0Fp7gBuAZZiT/eta681Kqd8rpRY27fZzpdRmpdRG4OfAlYGqz6TkSTx11lOEWkPR2rQU+lMrobXQ0CSys5cTGZnN5s3nU1z8erCrJIQYIAKaOltr/QHwwSHP3dXq518Dvw5kHdqTmwuFhf1nPKE9NlscU6d+xLfffp8tWy7B52sgNfWKYFdLCNHPBXugOSia1yf015ZCs5CQaKZM+Q9xcd9j27YrKSh4OthVEkL0c4MyKKxcadYmTGxvKV0/Y6arvkd8/Fns2HEdeXmPBbtKQoh+bFAGhc8+M6uYg50R1V+sVgdZWf8mKekCdu36X/bu/VOwqySE6KcG3e04i4vhu+/gqquCXRP/slhCmTDhFSwWB7t3347XW0Nm5j0oNUAinxDiqBh0QeHzz81jfx5k7ojFEsL48S9gsUSwb9991NVtYcKEFwkJiQl21YQQ/cSgu4z87DOw22FGwJbJBZdSFsaO/SujRz9OWdn7rFs3m7q6gC3/EEIMMIMuKKxcCbNnm8AwUCmlSEu7kezsT/B4Kli//hhKSt4KdrWEEP3AoAoKdXWwfn3/n4raXbGxJzBjxjrCwyeyefN55Obegc/nDna1hBB92KAKCqtWgdc7eIICgMORRnb2p6Sm/ph9++5hzZrJlJa+J3dyE0K0a1AFhc8+M3dYO+64YNfk6LJaHYwb9zeyst4BNJs2LWTjxpPl3gxCiMMMuqAwZQrEDMLJOEopEhMXMmvWJkaPfoLa2m9Yt24mW7deQUPDnmBXTwjRRwyaoODxwJdfDsypqEfCYrGRlnYDc+bsIj39VoqLX+Wrr0axadN5VFSskG4lIQa5QRMUNmwwA82DaTyhMyEhMYwadT+zZ+9i+PDbqKzMYePGk1i7dir79z+L19sQ7CoKIYJg0ASF/HyIj5egcCiHI42RI//EscfmMW7cc4Bi+/arWbUqg/z8J/D5nF2WIYQYOFR/6y6YOXOmXrt2bY/e6/MNnHxHgaK1pqoqhz17fkdl5XIcjgwyMn5PSsr/oJQ12NUTQvSQUmqd1npmV/sNqlOkBISuKaWIjT2BqVM/YcqUZYSExLNt2+WsXZtNaem7aO0LdhWFEAEkp0nRLqUU8fELmDFjDRMnvobP52TTph/w5ZfD2bnzF9TUrJNBaSEGoEHVfSR6zudzU1LyJsXFL1Ne/iFauwkLG0Ny8iWkpl5OWNioYFdRCNGJ7nYfSVAQR8ztLqek5N8UF79CZeVyAOLjz2DYsBuIjz9N0nUL0QdJUBBHhdNZwP79f+PAgWdwuQoJCxvN0KE/IzX1Cmy2+GBXTwjRRIKCOKp8PhclJW9SUPAk1dXmphUOxygiI6cQETGFyMipREZOxeHIRCkV5NoKMfh0NygMupvsiMCwWEJJSbmElJRLqKn5mrKy96ir+5ba2m8oLX0bMBcfDkcG8fFnkpBwJrGxJ2G1hge34kKINiQoCL+LippGVNS0lt+93nrq6jZTU7OW8vIPKSx8nv37n8JicRAbeyLR0XNwOEYRFjaasLBR2GyJ0poQIkgkKIiAs1rDiY6eRXT0LIYNuw6fz0llZQ7l5f+hrOwDysuX0dySMPtHEx4+lsjIbCIjpzVtU7BaI4L3IYQYJGRMQQSd19tIY+MeGhp20ti4i4aGndTVbaW29ms8nvKmvRRhYWNwOIYTGppKaGgqNlsKoaGphIePISJiClZrWFA/hxB9mYwpiH7DanUQETGeiIjxbZ7XWuN05lNb+3XT9i0u136qqj7H5TqAz9fYam8L4eHjiYqaTmTkNKKiZhAVNVNaF0IcIQkKos9SSuFwpONwpJOYuLDNa1prvN5qnM4D1NdvbQkcFRXLKSr6R9NeViIjpxAdfSzR0ccSFTUTrd243aVtNpstiejoWURETMZiCT36H1SIPkS6j8SA43IVU1OzlurqL6mq+oKamtV4vbVdvk8pO5GR2URHH0NkZDZ2+zBCQ4cSGjoEmy1BBr9FvybdR2LQCg1NJiHBTHsF0NpLXd0mams3YLGEY7MlttoScDr3U1OzmpqaNVRXr+bAgaX4fHVtylQqtGksIwWbLZnQ0GRstiRCQ5Ox29NwODJxOEZK8BD9ngQFMeApZW1ZPNeesLAMwsIySE6+CDBBpLFxD07nAVyu/bhcB5p+PoDbXYzLdYC6um9wuYrQ2tWmLKs1Cocjk9DQVLR24fM1ttrchIWNJjIym6ioaURGZhMWNlpSkos+RYKCEIdQykpY2Kguk/w1j2s0NubR2LibxsZcGhpyaWzMxeUqxmKxY7VGYbMlY7E4UMpCff028vMfQWs3ABZLBDZbIlq70NqNz+dqes2CwzEchyMDh2MEDkcGdvtwLJYwlLI2BRILSlnx+Zx4vVV4PAc3rd3Y7elN7zebzRYb+C9P9HsSFIToIaUUISExREbGEBmZ1e33+Xwu6uq2UFu7oWnabRUWSyhK2VoetXbT2LiPxsY9VFevxuMpO4J6hTYFi7a3VLVao7Fao7BYQrFY7Chlx2KxY7E4sFojsVojsFojsFgiCAmJwW5Pawos6djtwwkJiUVrD253CS5XYcumVCjh4WMJCxvbrcCjtcbtLqWhYTv19d+hVAhRUccQHj5Wkin2ARIUhDjKLJZQoqKyiYrKBq7s1ns8nhqczjx8PidaewEfWnvR2ovFYickJIaQkBis1hisVgdaazyechob97Ta9uL11jWV4cLnczZtDbhcRfh8dXi9ZvN4qgDvIfUOa5oG3PHkFJstibCwsTgcI1DK0nTPDbOZbrm9NDR8h8dTedh7rdZooqJmER09m8jIaU0D/WYtSiDq2vcAAAiySURBVFfpULzeBmpq1lFdvYrq6lU0Nu4hOno2cXEnExt7EjZbXLe+ZyGzj4QQ7dDai8tVhNOZR2PjPpzOPJzOAqzWqJbFg80D7z6fs+mqf3vL1b/TmddUkgJU0+C7Bbs9jfDwcYSFjSU8fBzh4WPx+Rqprl5NTc1qqqtXU1f3DVp72tTHao3EZkvBao3EYnG0tHAsFgcu135qaze0vMfhGInDMYLq6tVNEwYUkZHTiYv7HhZLGB5POW53BR5POR5PBV5vQ1OXnAXTJWdBqdCmiQSpLYEpNDS5qcuwBq+3tmVTKgS7fSh2exqhocOw24cREhKDy1Xc9L01b/mEhMQRFjaqKa3LqDbBSmuNz1ePx1OF11uH1RpJSEhMU5dh7ycvSJZUIUS/5PU2UF+/tal7qqjl0e0uwuutbxq0d7YM4Nts8URHz2naZhMamgKYbrrq6tVUVn5CRcUnVFevQmtPU6sqjpCQeGy2OCyWMJpbMuZ2sz58PmdLN5nHU9GDT6E4tEWllB2tnW2eCwmJJyQktikQVB0WDM37bC2twGHDfkZ6+i09qI9MSRVC9FNWaxhRUdN7XY7FEkps7PHExh5PRsZv8flcrQbpu8/nc+FyFeN2FwHWpvGXSEJCorBYwtDa3TQ7rQCnMx+nswC3u5zQ0FQcjuHY7enY7enYbAn4fPU0NOTS0LCrJa2Lx1PT0v1ntlgslnC83tqWYOHxVOLxVBEamtrr76UrEhSEEINCT1erWyyhOBxpOBxp7b6ulL1lWnNXrNYIIiMnExk5uUd1ORpkqF8IIUSLgAYFpdTpSqnvlFI7lVKL23ndrpR6ren1r5RSGYGsjxBCiM4FLCgo03H3JHAGMBG4RCk18ZDdfgxUaK1HA48C9weqPkIIIboWyJbCMcBOrXWuNrkAXgV+cMg+PwBeaPr5DeBkJYljhBAiaAIZFIYBea1+z296rt19tJmLVQUkBLBOQgghOtEvBpqVUtcopdYqpdaWlJQEuzpCCDFgBTIoFADprX5Pa3qu3X2UUiFADHBYkhet9RKt9Uyt9cykpKQAVVcIIUQgg8IaYIxSKlMpFQpcDLx7yD7vAlc0/XwB8P90f1tiLYQQA0hA01wopc4EHgOswFKt9T1Kqd8Da7XW7yqlHMBLwDSgHLhYa53bRZklwN4eVikRKO3he/uygfi5BuJngoH5ueQz9Q8jtNZddrX0u9xHvaGUWtud3B/9zUD8XAPxM8HA/FzymQaWfjHQLIQQ4uiQoCCEEKLFYAsKS4JdgQAZiJ9rIH4mGJifSz7TADKoxhSEEEJ0brC1FIQQQnRi0ASFrjK29hdKqaVKqWKl1KZWz8UrpT5SSu1oeuxXN6RVSqUrpZYrpbYopTYrpW5qer7ffi6llEMptVoptbHpM/2u6fnMpozAO5syBPcsyX8QKaWsSqmvlVL/1/T7QPhMe5RS3yqlNiil1jY912///npjUASFbmZs7S+eB04/5LnFwCda6zHAJ02/9yce4Bda64nAHOD6pn+f/vy5nMD3tNZTgWzgdKXUHEwm4EebMgNXYDIF9zc3AVtb/T4QPhPASVrr7FZTUfvz31+PDYqgQPcytvYLWusczEK/1lpnm30BOOeoVqqXtP7/7d3Pi1VlHMfx96eSMCeSxCSUEmtRBDISCKXBYNQmiRb9gFSiTZs2LqIwisA/oB+LIKEWRlNk5dQ2Mxly0S9tqCg3RQvFnE1WExQxflo8zz1OM5Izd3LuHO/nBcO957mXw/OF59zvOc+Z83180vbR+v53yg/Oalocl4uJurmk/hnYQqkIDC2LCUDSGuAe4NW6LVoe039o7fibj35JCrOp2Npmq2yfrO9/Blb1sjPzURda2gB8RsvjqtMsY8A4cAD4ATjts6uzt3Ecvgg8CZyp2ytof0xQEvaHko5Ieqy2tXr8dStrNF9kbFtSK/+lTNIA8B6w0/ZvU5fWaGNctieBQUnLgRHgph53aV4kbQXGbR+RNNTr/vzPNts+Ieka4ICkY1M/bOP461a/XCnMpmJrm52SdC1AfR3vcX/mTNISSkIYtr2/Nrc+LgDbp4FDwG3A8loRGNo3DjcB90r6iTIFuwV4iXbHBIDtE/V1nJLAN3KRjL+56pekMJuKrW02tdrsI8AHPezLnNV56deA720/P+Wj1sYlaWW9QkDSUuAuyr2SQ5SKwNCymGzvsr3G9lrKMfSx7W20OCYAScskXdl5D9wNfEuLx9989M3Da+eq2NrjLnVF0lvAEKWK4yngOeB9YB9wHaWC7IO2p9+MXrQkbQY+Ab7h7Fz105T7Cq2MS9J6ys3JSyknX/ts75a0jnKWfTXwFbDd9l+962l36vTRE7a3tj2m2v+RunkZ8Gat6LyClo6/+eibpBAREefXL9NHERExC0kKERHRSFKIiIhGkkJERDSSFCIiopGkELGAJA11qotGLEZJChER0UhSiDgHSdvreghjkvbU4nYTkl6o6yMclLSyfndQ0qeSvpY00qm7L+lGSR/VNRWOSrqh7n5A0ruSjkka1tQiTxE9lqQQMY2km4GHgE22B4FJYBuwDPjS9i3AKOVpcoDXgadsr6c8ld1pHwZermsq3A50Km5uAHZS1vZYR6kpFLEopEpqxEx3ArcCX9ST+KWUYmhngLfrd94A9ku6Clhue7S27wXeqbV0VtseAbD9J0Dd3+e2j9ftMWAtcPjChxVxfkkKETMJ2Gt7178apWenfa/bGjFT6wJNkuMwFpFMH0XMdBC4v9bW76zVez3leOlUA30YOGz7V+AXSXfU9h3AaF1B7rik++o+Lpd0xYJGEdGFnKFETGP7O0nPUFbiugT4G3gc+APYWD8bp9x3gFJW+ZX6o/8j8Ght3wHskbS77uOBBQwjoiupkhoxS5ImbA/0uh8RF1KmjyIiopErhYiIaORKISIiGkkKERHRSFKIiIhGkkJERDSSFCIiopGkEBERjX8A/9iQOMafRGoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 890us/sample - loss: 1.0904 - acc: 0.6719\n",
      "Loss: 1.0903628553928244 Accuracy: 0.6718588\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1243 - acc: 0.3067\n",
      "Epoch 00001: val_loss improved from inf to 1.55428, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/001-1.5543.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 2.1242 - acc: 0.3067 - val_loss: 1.5543 - val_acc: 0.4997\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4237 - acc: 0.5414\n",
      "Epoch 00002: val_loss improved from 1.55428 to 1.27438, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/002-1.2744.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.4237 - acc: 0.5413 - val_loss: 1.2744 - val_acc: 0.5954\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2156 - acc: 0.6175\n",
      "Epoch 00003: val_loss improved from 1.27438 to 1.10489, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/003-1.1049.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.2155 - acc: 0.6175 - val_loss: 1.1049 - val_acc: 0.6560\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0650 - acc: 0.6675\n",
      "Epoch 00004: val_loss improved from 1.10489 to 1.01711, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/004-1.0171.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.0650 - acc: 0.6675 - val_loss: 1.0171 - val_acc: 0.6795\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9360 - acc: 0.7130\n",
      "Epoch 00005: val_loss did not improve from 1.01711\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.9360 - acc: 0.7129 - val_loss: 1.1054 - val_acc: 0.6508\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8312 - acc: 0.7451\n",
      "Epoch 00006: val_loss improved from 1.01711 to 0.83001, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/006-0.8300.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.8314 - acc: 0.7450 - val_loss: 0.8300 - val_acc: 0.7501\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7405 - acc: 0.7761\n",
      "Epoch 00007: val_loss improved from 0.83001 to 0.79698, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/007-0.7970.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.7404 - acc: 0.7761 - val_loss: 0.7970 - val_acc: 0.7692\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6745 - acc: 0.7940\n",
      "Epoch 00008: val_loss improved from 0.79698 to 0.78419, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/008-0.7842.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6745 - acc: 0.7940 - val_loss: 0.7842 - val_acc: 0.7717\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.8152\n",
      "Epoch 00009: val_loss did not improve from 0.78419\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6022 - acc: 0.8153 - val_loss: 0.8549 - val_acc: 0.7494\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5464 - acc: 0.8327\n",
      "Epoch 00010: val_loss improved from 0.78419 to 0.74132, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/010-0.7413.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5464 - acc: 0.8327 - val_loss: 0.7413 - val_acc: 0.7838\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5000 - acc: 0.8471\n",
      "Epoch 00011: val_loss did not improve from 0.74132\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5000 - acc: 0.8471 - val_loss: 0.7642 - val_acc: 0.7822\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4524 - acc: 0.8587\n",
      "Epoch 00012: val_loss improved from 0.74132 to 0.73630, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/012-0.7363.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4524 - acc: 0.8588 - val_loss: 0.7363 - val_acc: 0.7927\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4090 - acc: 0.8731\n",
      "Epoch 00013: val_loss did not improve from 0.73630\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4089 - acc: 0.8731 - val_loss: 0.7863 - val_acc: 0.7920\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3709 - acc: 0.8840\n",
      "Epoch 00014: val_loss did not improve from 0.73630\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3710 - acc: 0.8840 - val_loss: 0.7791 - val_acc: 0.7873\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3446 - acc: 0.8916\n",
      "Epoch 00015: val_loss improved from 0.73630 to 0.73621, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/015-0.7362.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3447 - acc: 0.8916 - val_loss: 0.7362 - val_acc: 0.8015\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3100 - acc: 0.9017\n",
      "Epoch 00016: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3101 - acc: 0.9017 - val_loss: 0.7578 - val_acc: 0.8020\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2849 - acc: 0.9089\n",
      "Epoch 00017: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2849 - acc: 0.9089 - val_loss: 0.8109 - val_acc: 0.8036\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2545 - acc: 0.9181\n",
      "Epoch 00018: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2545 - acc: 0.9181 - val_loss: 0.8054 - val_acc: 0.7948\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9244\n",
      "Epoch 00019: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2362 - acc: 0.9244 - val_loss: 0.8351 - val_acc: 0.7997\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2240 - acc: 0.9283\n",
      "Epoch 00020: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2240 - acc: 0.9283 - val_loss: 0.8424 - val_acc: 0.7927\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2067 - acc: 0.9327\n",
      "Epoch 00021: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2067 - acc: 0.9328 - val_loss: 0.8392 - val_acc: 0.7983\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9398\n",
      "Epoch 00022: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1885 - acc: 0.9398 - val_loss: 0.8675 - val_acc: 0.7990\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9410\n",
      "Epoch 00023: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1820 - acc: 0.9410 - val_loss: 0.8880 - val_acc: 0.7948\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9443\n",
      "Epoch 00024: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1720 - acc: 0.9444 - val_loss: 0.8663 - val_acc: 0.8083\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9473\n",
      "Epoch 00025: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1653 - acc: 0.9473 - val_loss: 0.8060 - val_acc: 0.8213\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9507\n",
      "Epoch 00026: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1556 - acc: 0.9507 - val_loss: 0.8698 - val_acc: 0.8111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9517\n",
      "Epoch 00027: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1489 - acc: 0.9517 - val_loss: 0.8396 - val_acc: 0.8171\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9524\n",
      "Epoch 00028: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1439 - acc: 0.9524 - val_loss: 0.8545 - val_acc: 0.8116\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9550\n",
      "Epoch 00029: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1403 - acc: 0.9550 - val_loss: 0.9271 - val_acc: 0.8039\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9588\n",
      "Epoch 00030: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1310 - acc: 0.9588 - val_loss: 0.8583 - val_acc: 0.8150\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9611\n",
      "Epoch 00031: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1257 - acc: 0.9611 - val_loss: 0.9097 - val_acc: 0.8134\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9604\n",
      "Epoch 00032: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1263 - acc: 0.9604 - val_loss: 0.9035 - val_acc: 0.8085\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9617\n",
      "Epoch 00033: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1187 - acc: 0.9617 - val_loss: 0.8536 - val_acc: 0.8202\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9635\n",
      "Epoch 00034: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1152 - acc: 0.9634 - val_loss: 0.9029 - val_acc: 0.8218\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9656\n",
      "Epoch 00035: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1117 - acc: 0.9656 - val_loss: 0.8380 - val_acc: 0.8286\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9647\n",
      "Epoch 00036: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1142 - acc: 0.9647 - val_loss: 0.9272 - val_acc: 0.8227\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9679\n",
      "Epoch 00037: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1051 - acc: 0.9679 - val_loss: 0.9669 - val_acc: 0.8137\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9664\n",
      "Epoch 00038: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1079 - acc: 0.9664 - val_loss: 0.8660 - val_acc: 0.8279\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9705\n",
      "Epoch 00039: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0954 - acc: 0.9705 - val_loss: 0.9144 - val_acc: 0.8185\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9705\n",
      "Epoch 00040: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0982 - acc: 0.9705 - val_loss: 0.8667 - val_acc: 0.8239\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9712\n",
      "Epoch 00041: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0924 - acc: 0.9712 - val_loss: 0.8941 - val_acc: 0.8248\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9714\n",
      "Epoch 00042: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0935 - acc: 0.9714 - val_loss: 0.8730 - val_acc: 0.8237\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9719\n",
      "Epoch 00043: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0897 - acc: 0.9719 - val_loss: 0.9020 - val_acc: 0.8341\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9737\n",
      "Epoch 00044: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0860 - acc: 0.9737 - val_loss: 0.8842 - val_acc: 0.8248\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9734\n",
      "Epoch 00045: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0877 - acc: 0.9734 - val_loss: 0.8877 - val_acc: 0.8295\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9736\n",
      "Epoch 00046: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0842 - acc: 0.9736 - val_loss: 0.9266 - val_acc: 0.8197\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9735\n",
      "Epoch 00047: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0872 - acc: 0.9735 - val_loss: 0.8879 - val_acc: 0.8265\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9750\n",
      "Epoch 00048: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0820 - acc: 0.9750 - val_loss: 0.9098 - val_acc: 0.8162\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9751\n",
      "Epoch 00049: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0812 - acc: 0.9751 - val_loss: 0.8764 - val_acc: 0.8290\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9753\n",
      "Epoch 00050: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0803 - acc: 0.9753 - val_loss: 0.8870 - val_acc: 0.8328\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9764\n",
      "Epoch 00051: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0774 - acc: 0.9764 - val_loss: 0.9019 - val_acc: 0.8302\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9751\n",
      "Epoch 00052: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0800 - acc: 0.9751 - val_loss: 0.8904 - val_acc: 0.8288\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9770\n",
      "Epoch 00053: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0747 - acc: 0.9770 - val_loss: 0.9035 - val_acc: 0.8265\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9779\n",
      "Epoch 00054: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0752 - acc: 0.9779 - val_loss: 0.9213 - val_acc: 0.8344\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9781\n",
      "Epoch 00055: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0754 - acc: 0.9781 - val_loss: 0.8901 - val_acc: 0.8309\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9786\n",
      "Epoch 00056: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0689 - acc: 0.9786 - val_loss: 0.9131 - val_acc: 0.8290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9794\n",
      "Epoch 00057: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0685 - acc: 0.9794 - val_loss: 0.9247 - val_acc: 0.8337\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9796\n",
      "Epoch 00058: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0680 - acc: 0.9796 - val_loss: 0.9255 - val_acc: 0.8344\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9792\n",
      "Epoch 00059: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0690 - acc: 0.9792 - val_loss: 0.9196 - val_acc: 0.8307\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9788\n",
      "Epoch 00060: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0715 - acc: 0.9788 - val_loss: 0.9302 - val_acc: 0.8376\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9787\n",
      "Epoch 00061: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0711 - acc: 0.9788 - val_loss: 0.9167 - val_acc: 0.8253\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9814\n",
      "Epoch 00062: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0642 - acc: 0.9814 - val_loss: 0.8507 - val_acc: 0.8404\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9795\n",
      "Epoch 00063: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0688 - acc: 0.9795 - val_loss: 0.9381 - val_acc: 0.8316\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9810\n",
      "Epoch 00064: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0646 - acc: 0.9810 - val_loss: 0.9057 - val_acc: 0.8428\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9806\n",
      "Epoch 00065: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0657 - acc: 0.9805 - val_loss: 0.9376 - val_acc: 0.8302\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 945us/sample - loss: 0.8833 - acc: 0.7666\n",
      "Loss: 0.883316714778496 Accuracy: 0.7665628\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4018 - acc: 0.2090\n",
      "Epoch 00001: val_loss improved from inf to 1.67515, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/001-1.6752.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 2.4017 - acc: 0.2090 - val_loss: 1.6752 - val_acc: 0.4663\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5659 - acc: 0.4914\n",
      "Epoch 00002: val_loss improved from 1.67515 to 1.34717, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/002-1.3472.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.5657 - acc: 0.4914 - val_loss: 1.3472 - val_acc: 0.5840\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3392 - acc: 0.5676\n",
      "Epoch 00003: val_loss improved from 1.34717 to 1.20077, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/003-1.2008.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.3392 - acc: 0.5676 - val_loss: 1.2008 - val_acc: 0.6084\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2186 - acc: 0.6087\n",
      "Epoch 00004: val_loss improved from 1.20077 to 1.07433, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/004-1.0743.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.2186 - acc: 0.6088 - val_loss: 1.0743 - val_acc: 0.6730\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1096 - acc: 0.6462\n",
      "Epoch 00005: val_loss improved from 1.07433 to 0.97878, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/005-0.9788.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.1095 - acc: 0.6462 - val_loss: 0.9788 - val_acc: 0.7067\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9998 - acc: 0.6863\n",
      "Epoch 00006: val_loss improved from 0.97878 to 0.90228, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/006-0.9023.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.9997 - acc: 0.6863 - val_loss: 0.9023 - val_acc: 0.7303\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8967 - acc: 0.7213\n",
      "Epoch 00007: val_loss improved from 0.90228 to 0.75282, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/007-0.7528.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8969 - acc: 0.7213 - val_loss: 0.7528 - val_acc: 0.7813\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8122 - acc: 0.7486\n",
      "Epoch 00008: val_loss improved from 0.75282 to 0.67530, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/008-0.6753.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8121 - acc: 0.7486 - val_loss: 0.6753 - val_acc: 0.8055\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7303 - acc: 0.7766\n",
      "Epoch 00009: val_loss improved from 0.67530 to 0.61138, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/009-0.6114.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7302 - acc: 0.7766 - val_loss: 0.6114 - val_acc: 0.8283\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6572 - acc: 0.7998\n",
      "Epoch 00010: val_loss improved from 0.61138 to 0.58938, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/010-0.5894.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6572 - acc: 0.7998 - val_loss: 0.5894 - val_acc: 0.8314\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5928 - acc: 0.8207\n",
      "Epoch 00011: val_loss improved from 0.58938 to 0.56331, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/011-0.5633.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5927 - acc: 0.8208 - val_loss: 0.5633 - val_acc: 0.8397\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5548 - acc: 0.8290\n",
      "Epoch 00012: val_loss improved from 0.56331 to 0.49751, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/012-0.4975.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5547 - acc: 0.8290 - val_loss: 0.4975 - val_acc: 0.8591\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5151 - acc: 0.8419\n",
      "Epoch 00013: val_loss did not improve from 0.49751\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5151 - acc: 0.8419 - val_loss: 0.5345 - val_acc: 0.8526\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4735 - acc: 0.8566\n",
      "Epoch 00014: val_loss did not improve from 0.49751\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4735 - acc: 0.8565 - val_loss: 0.5197 - val_acc: 0.8551\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4500 - acc: 0.8650\n",
      "Epoch 00015: val_loss improved from 0.49751 to 0.45783, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/015-0.4578.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4499 - acc: 0.8650 - val_loss: 0.4578 - val_acc: 0.8691\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4157 - acc: 0.8744\n",
      "Epoch 00016: val_loss did not improve from 0.45783\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4157 - acc: 0.8744 - val_loss: 0.4581 - val_acc: 0.8703\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3902 - acc: 0.8835\n",
      "Epoch 00017: val_loss improved from 0.45783 to 0.45472, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/017-0.4547.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3902 - acc: 0.8835 - val_loss: 0.4547 - val_acc: 0.8754\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3711 - acc: 0.8863\n",
      "Epoch 00018: val_loss improved from 0.45472 to 0.43325, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/018-0.4332.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3711 - acc: 0.8863 - val_loss: 0.4332 - val_acc: 0.8798\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3529 - acc: 0.8923\n",
      "Epoch 00019: val_loss improved from 0.43325 to 0.39886, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/019-0.3989.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3530 - acc: 0.8923 - val_loss: 0.3989 - val_acc: 0.8912\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3342 - acc: 0.8973\n",
      "Epoch 00020: val_loss improved from 0.39886 to 0.38753, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/020-0.3875.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3342 - acc: 0.8973 - val_loss: 0.3875 - val_acc: 0.8961\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3054 - acc: 0.9054\n",
      "Epoch 00021: val_loss did not improve from 0.38753\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3053 - acc: 0.9054 - val_loss: 0.3962 - val_acc: 0.8889\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2957 - acc: 0.9101\n",
      "Epoch 00022: val_loss did not improve from 0.38753\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2958 - acc: 0.9100 - val_loss: 0.3953 - val_acc: 0.8975\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2865 - acc: 0.9120\n",
      "Epoch 00023: val_loss did not improve from 0.38753\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2866 - acc: 0.9119 - val_loss: 0.4049 - val_acc: 0.8952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2694 - acc: 0.9154\n",
      "Epoch 00024: val_loss improved from 0.38753 to 0.36484, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/024-0.3648.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2694 - acc: 0.9154 - val_loss: 0.3648 - val_acc: 0.9059\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.9205\n",
      "Epoch 00025: val_loss did not improve from 0.36484\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2552 - acc: 0.9205 - val_loss: 0.3684 - val_acc: 0.9061\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2361 - acc: 0.9248\n",
      "Epoch 00026: val_loss improved from 0.36484 to 0.36309, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/026-0.3631.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2361 - acc: 0.9248 - val_loss: 0.3631 - val_acc: 0.9059\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9275\n",
      "Epoch 00027: val_loss did not improve from 0.36309\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2299 - acc: 0.9274 - val_loss: 0.3798 - val_acc: 0.9068\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2234 - acc: 0.9293\n",
      "Epoch 00028: val_loss improved from 0.36309 to 0.36234, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/028-0.3623.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2234 - acc: 0.9293 - val_loss: 0.3623 - val_acc: 0.9026\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9340\n",
      "Epoch 00029: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2078 - acc: 0.9340 - val_loss: 0.3760 - val_acc: 0.9119\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9359\n",
      "Epoch 00030: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1986 - acc: 0.9359 - val_loss: 0.4064 - val_acc: 0.8966\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1894 - acc: 0.9395\n",
      "Epoch 00031: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1893 - acc: 0.9395 - val_loss: 0.4091 - val_acc: 0.8984\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9418\n",
      "Epoch 00032: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1828 - acc: 0.9418 - val_loss: 0.3846 - val_acc: 0.9015\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9427\n",
      "Epoch 00033: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1801 - acc: 0.9427 - val_loss: 0.4071 - val_acc: 0.9075\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1648 - acc: 0.9471\n",
      "Epoch 00034: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1648 - acc: 0.9471 - val_loss: 0.3913 - val_acc: 0.9122\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9442\n",
      "Epoch 00035: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1674 - acc: 0.9442 - val_loss: 0.3915 - val_acc: 0.9147\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1545 - acc: 0.9489\n",
      "Epoch 00036: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1544 - acc: 0.9489 - val_loss: 0.4010 - val_acc: 0.9071\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9515\n",
      "Epoch 00037: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1508 - acc: 0.9515 - val_loss: 0.3681 - val_acc: 0.9180\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9531\n",
      "Epoch 00038: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1456 - acc: 0.9531 - val_loss: 0.3964 - val_acc: 0.9080\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9545\n",
      "Epoch 00039: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1410 - acc: 0.9545 - val_loss: 0.4005 - val_acc: 0.9045\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9563\n",
      "Epoch 00040: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1352 - acc: 0.9563 - val_loss: 0.4063 - val_acc: 0.9126\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9570\n",
      "Epoch 00041: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1307 - acc: 0.9570 - val_loss: 0.3728 - val_acc: 0.9166\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9567\n",
      "Epoch 00042: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1328 - acc: 0.9567 - val_loss: 0.4009 - val_acc: 0.9164\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9601\n",
      "Epoch 00043: val_loss did not improve from 0.36234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1247 - acc: 0.9601 - val_loss: 0.4229 - val_acc: 0.9133\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9591\n",
      "Epoch 00044: val_loss improved from 0.36234 to 0.36054, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/044-0.3605.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1246 - acc: 0.9591 - val_loss: 0.3605 - val_acc: 0.9220\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9628\n",
      "Epoch 00045: val_loss improved from 0.36054 to 0.35622, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/045-0.3562.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1105 - acc: 0.9627 - val_loss: 0.3562 - val_acc: 0.9227\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9620\n",
      "Epoch 00046: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1134 - acc: 0.9620 - val_loss: 0.3747 - val_acc: 0.9217\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9626\n",
      "Epoch 00047: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1120 - acc: 0.9626 - val_loss: 0.3807 - val_acc: 0.9157\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9635\n",
      "Epoch 00048: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1083 - acc: 0.9635 - val_loss: 0.3928 - val_acc: 0.9152\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9651\n",
      "Epoch 00049: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1040 - acc: 0.9651 - val_loss: 0.4237 - val_acc: 0.9150\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9658\n",
      "Epoch 00050: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1042 - acc: 0.9657 - val_loss: 0.4074 - val_acc: 0.9182\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9670\n",
      "Epoch 00051: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1021 - acc: 0.9670 - val_loss: 0.4040 - val_acc: 0.9157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9694\n",
      "Epoch 00052: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0942 - acc: 0.9694 - val_loss: 0.4090 - val_acc: 0.9231\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9667\n",
      "Epoch 00053: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1004 - acc: 0.9667 - val_loss: 0.4178 - val_acc: 0.9208\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9683\n",
      "Epoch 00054: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0944 - acc: 0.9683 - val_loss: 0.3780 - val_acc: 0.9213\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9720\n",
      "Epoch 00055: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0860 - acc: 0.9720 - val_loss: 0.4317 - val_acc: 0.9143\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9714\n",
      "Epoch 00056: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0869 - acc: 0.9714 - val_loss: 0.4315 - val_acc: 0.9180\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9710\n",
      "Epoch 00057: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0885 - acc: 0.9710 - val_loss: 0.4095 - val_acc: 0.9182\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9713\n",
      "Epoch 00058: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0867 - acc: 0.9713 - val_loss: 0.4331 - val_acc: 0.9201\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9730\n",
      "Epoch 00059: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0829 - acc: 0.9730 - val_loss: 0.3983 - val_acc: 0.9196\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9732\n",
      "Epoch 00060: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0832 - acc: 0.9732 - val_loss: 0.4100 - val_acc: 0.9187\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9722\n",
      "Epoch 00061: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0833 - acc: 0.9722 - val_loss: 0.4045 - val_acc: 0.9231\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9733\n",
      "Epoch 00062: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0808 - acc: 0.9733 - val_loss: 0.4311 - val_acc: 0.9215\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9730\n",
      "Epoch 00063: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0800 - acc: 0.9730 - val_loss: 0.4199 - val_acc: 0.9250\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9778\n",
      "Epoch 00064: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0702 - acc: 0.9778 - val_loss: 0.4208 - val_acc: 0.9180\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9756\n",
      "Epoch 00065: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0751 - acc: 0.9756 - val_loss: 0.4280 - val_acc: 0.9171\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9748\n",
      "Epoch 00066: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0767 - acc: 0.9748 - val_loss: 0.4315 - val_acc: 0.9210\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9764\n",
      "Epoch 00067: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0723 - acc: 0.9764 - val_loss: 0.4540 - val_acc: 0.9185\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9775\n",
      "Epoch 00068: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0679 - acc: 0.9775 - val_loss: 0.4024 - val_acc: 0.9210\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9769\n",
      "Epoch 00069: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0718 - acc: 0.9769 - val_loss: 0.4177 - val_acc: 0.9236\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9777\n",
      "Epoch 00070: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0694 - acc: 0.9777 - val_loss: 0.4301 - val_acc: 0.9231\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9778\n",
      "Epoch 00071: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0663 - acc: 0.9777 - val_loss: 0.4098 - val_acc: 0.9243\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9781\n",
      "Epoch 00072: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0692 - acc: 0.9781 - val_loss: 0.4099 - val_acc: 0.9269\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9788\n",
      "Epoch 00073: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0659 - acc: 0.9788 - val_loss: 0.4144 - val_acc: 0.9224\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9800\n",
      "Epoch 00074: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0625 - acc: 0.9800 - val_loss: 0.4164 - val_acc: 0.9266\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9783\n",
      "Epoch 00075: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0658 - acc: 0.9783 - val_loss: 0.4008 - val_acc: 0.9262\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9792\n",
      "Epoch 00076: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0638 - acc: 0.9792 - val_loss: 0.4024 - val_acc: 0.9248\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9799\n",
      "Epoch 00077: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0613 - acc: 0.9799 - val_loss: 0.4175 - val_acc: 0.9220\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9798\n",
      "Epoch 00078: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0608 - acc: 0.9798 - val_loss: 0.4188 - val_acc: 0.9203\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9818\n",
      "Epoch 00079: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0566 - acc: 0.9818 - val_loss: 0.4287 - val_acc: 0.9259\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9789\n",
      "Epoch 00080: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0667 - acc: 0.9789 - val_loss: 0.4161 - val_acc: 0.9222\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9818\n",
      "Epoch 00081: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0588 - acc: 0.9818 - val_loss: 0.4386 - val_acc: 0.9187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9826\n",
      "Epoch 00082: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0548 - acc: 0.9826 - val_loss: 0.4204 - val_acc: 0.9206\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9821\n",
      "Epoch 00083: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0546 - acc: 0.9821 - val_loss: 0.4875 - val_acc: 0.9154\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9806\n",
      "Epoch 00084: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0591 - acc: 0.9806 - val_loss: 0.4242 - val_acc: 0.9248\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9821\n",
      "Epoch 00085: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0563 - acc: 0.9821 - val_loss: 0.4311 - val_acc: 0.9203\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9827\n",
      "Epoch 00086: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0547 - acc: 0.9827 - val_loss: 0.4451 - val_acc: 0.9243\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9825\n",
      "Epoch 00087: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0543 - acc: 0.9825 - val_loss: 0.4325 - val_acc: 0.9222\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9827\n",
      "Epoch 00088: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0533 - acc: 0.9827 - val_loss: 0.4176 - val_acc: 0.9248\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9824\n",
      "Epoch 00089: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0533 - acc: 0.9824 - val_loss: 0.4247 - val_acc: 0.9264\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9841\n",
      "Epoch 00090: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0494 - acc: 0.9841 - val_loss: 0.4201 - val_acc: 0.9273\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9835\n",
      "Epoch 00091: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0540 - acc: 0.9835 - val_loss: 0.4246 - val_acc: 0.9231\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9846\n",
      "Epoch 00092: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0474 - acc: 0.9846 - val_loss: 0.4136 - val_acc: 0.9290\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9845\n",
      "Epoch 00093: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0500 - acc: 0.9845 - val_loss: 0.3928 - val_acc: 0.9304\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9862\n",
      "Epoch 00094: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0461 - acc: 0.9862 - val_loss: 0.4322 - val_acc: 0.9290\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9851\n",
      "Epoch 00095: val_loss did not improve from 0.35622\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0458 - acc: 0.9851 - val_loss: 0.4486 - val_acc: 0.9271\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 970us/sample - loss: 0.4131 - acc: 0.9018\n",
      "Loss: 0.41305809186255077 Accuracy: 0.9017653\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5060 - acc: 0.1717\n",
      "Epoch 00001: val_loss improved from inf to 1.94137, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/001-1.9414.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 2.5060 - acc: 0.1717 - val_loss: 1.9414 - val_acc: 0.3638\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6701 - acc: 0.4447\n",
      "Epoch 00002: val_loss improved from 1.94137 to 1.24963, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/002-1.2496.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.6702 - acc: 0.4446 - val_loss: 1.2496 - val_acc: 0.6052\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3199 - acc: 0.5615\n",
      "Epoch 00003: val_loss improved from 1.24963 to 1.05219, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/003-1.0522.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.3199 - acc: 0.5616 - val_loss: 1.0522 - val_acc: 0.6804\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1089 - acc: 0.6401\n",
      "Epoch 00004: val_loss improved from 1.05219 to 0.89823, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/004-0.8982.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.1088 - acc: 0.6401 - val_loss: 0.8982 - val_acc: 0.7144\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9484 - acc: 0.6968\n",
      "Epoch 00005: val_loss improved from 0.89823 to 0.76811, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/005-0.7681.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9484 - acc: 0.6968 - val_loss: 0.7681 - val_acc: 0.7619\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8319 - acc: 0.7352\n",
      "Epoch 00006: val_loss improved from 0.76811 to 0.61852, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/006-0.6185.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8319 - acc: 0.7352 - val_loss: 0.6185 - val_acc: 0.8123\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7317 - acc: 0.7667\n",
      "Epoch 00007: val_loss improved from 0.61852 to 0.58055, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/007-0.5805.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7316 - acc: 0.7667 - val_loss: 0.5805 - val_acc: 0.8274\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6345 - acc: 0.7991\n",
      "Epoch 00008: val_loss improved from 0.58055 to 0.49445, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/008-0.4944.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6345 - acc: 0.7991 - val_loss: 0.4944 - val_acc: 0.8558\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5627 - acc: 0.8237\n",
      "Epoch 00009: val_loss improved from 0.49445 to 0.43004, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/009-0.4300.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5627 - acc: 0.8237 - val_loss: 0.4300 - val_acc: 0.8754\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4979 - acc: 0.8442\n",
      "Epoch 00010: val_loss improved from 0.43004 to 0.37113, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/010-0.3711.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4978 - acc: 0.8442 - val_loss: 0.3711 - val_acc: 0.8903\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4500 - acc: 0.8589\n",
      "Epoch 00011: val_loss improved from 0.37113 to 0.33107, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/011-0.3311.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4502 - acc: 0.8589 - val_loss: 0.3311 - val_acc: 0.9050\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4130 - acc: 0.8711\n",
      "Epoch 00012: val_loss improved from 0.33107 to 0.31315, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/012-0.3131.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4130 - acc: 0.8711 - val_loss: 0.3131 - val_acc: 0.9117\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3801 - acc: 0.8809\n",
      "Epoch 00013: val_loss improved from 0.31315 to 0.27041, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/013-0.2704.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3801 - acc: 0.8809 - val_loss: 0.2704 - val_acc: 0.9243\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3501 - acc: 0.8893\n",
      "Epoch 00014: val_loss improved from 0.27041 to 0.25189, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/014-0.2519.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3505 - acc: 0.8893 - val_loss: 0.2519 - val_acc: 0.9269\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3327 - acc: 0.8946\n",
      "Epoch 00015: val_loss did not improve from 0.25189\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3326 - acc: 0.8946 - val_loss: 0.2736 - val_acc: 0.9259\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3113 - acc: 0.9023\n",
      "Epoch 00016: val_loss did not improve from 0.25189\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3113 - acc: 0.9023 - val_loss: 0.2635 - val_acc: 0.9280\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2928 - acc: 0.9089\n",
      "Epoch 00017: val_loss did not improve from 0.25189\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2928 - acc: 0.9089 - val_loss: 0.2765 - val_acc: 0.9222\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2751 - acc: 0.9135\n",
      "Epoch 00018: val_loss improved from 0.25189 to 0.22053, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/018-0.2205.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2751 - acc: 0.9135 - val_loss: 0.2205 - val_acc: 0.9380\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2626 - acc: 0.9172\n",
      "Epoch 00019: val_loss did not improve from 0.22053\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2625 - acc: 0.9172 - val_loss: 0.2541 - val_acc: 0.9271\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2541 - acc: 0.9202\n",
      "Epoch 00020: val_loss improved from 0.22053 to 0.18887, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/020-0.1889.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2541 - acc: 0.9202 - val_loss: 0.1889 - val_acc: 0.9439\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2397 - acc: 0.9249\n",
      "Epoch 00021: val_loss did not improve from 0.18887\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2397 - acc: 0.9249 - val_loss: 0.2191 - val_acc: 0.9387\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2285 - acc: 0.9277\n",
      "Epoch 00022: val_loss did not improve from 0.18887\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2284 - acc: 0.9277 - val_loss: 0.1967 - val_acc: 0.9413\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2199 - acc: 0.9304\n",
      "Epoch 00023: val_loss did not improve from 0.18887\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2200 - acc: 0.9304 - val_loss: 0.1978 - val_acc: 0.9425\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2121 - acc: 0.9333\n",
      "Epoch 00024: val_loss did not improve from 0.18887\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2122 - acc: 0.9333 - val_loss: 0.2142 - val_acc: 0.9436\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9341\n",
      "Epoch 00025: val_loss did not improve from 0.18887\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2036 - acc: 0.9341 - val_loss: 0.2062 - val_acc: 0.9425\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1938 - acc: 0.9374\n",
      "Epoch 00026: val_loss improved from 0.18887 to 0.18481, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/026-0.1848.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1938 - acc: 0.9374 - val_loss: 0.1848 - val_acc: 0.9488\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9414\n",
      "Epoch 00027: val_loss did not improve from 0.18481\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1867 - acc: 0.9414 - val_loss: 0.2157 - val_acc: 0.9385\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9420\n",
      "Epoch 00028: val_loss improved from 0.18481 to 0.18194, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/028-0.1819.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1819 - acc: 0.9420 - val_loss: 0.1819 - val_acc: 0.9497\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9438\n",
      "Epoch 00029: val_loss improved from 0.18194 to 0.17784, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/029-0.1778.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1723 - acc: 0.9438 - val_loss: 0.1778 - val_acc: 0.9490\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9465\n",
      "Epoch 00030: val_loss improved from 0.17784 to 0.17586, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/030-0.1759.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1703 - acc: 0.9466 - val_loss: 0.1759 - val_acc: 0.9497\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9452\n",
      "Epoch 00031: val_loss improved from 0.17586 to 0.16324, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/031-0.1632.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1626 - acc: 0.9452 - val_loss: 0.1632 - val_acc: 0.9506\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1518 - acc: 0.9517\n",
      "Epoch 00032: val_loss did not improve from 0.16324\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1518 - acc: 0.9517 - val_loss: 0.1710 - val_acc: 0.9483\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9504\n",
      "Epoch 00033: val_loss did not improve from 0.16324\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1538 - acc: 0.9504 - val_loss: 0.1777 - val_acc: 0.9522\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9520\n",
      "Epoch 00034: val_loss did not improve from 0.16324\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1506 - acc: 0.9520 - val_loss: 0.1710 - val_acc: 0.9502\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1423 - acc: 0.9531\n",
      "Epoch 00035: val_loss did not improve from 0.16324\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1423 - acc: 0.9531 - val_loss: 0.1826 - val_acc: 0.9488\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9544\n",
      "Epoch 00036: val_loss did not improve from 0.16324\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1400 - acc: 0.9544 - val_loss: 0.1704 - val_acc: 0.9574\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9569\n",
      "Epoch 00037: val_loss improved from 0.16324 to 0.15672, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/037-0.1567.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1320 - acc: 0.9569 - val_loss: 0.1567 - val_acc: 0.9581\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9564\n",
      "Epoch 00038: val_loss did not improve from 0.15672\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1310 - acc: 0.9564 - val_loss: 0.1803 - val_acc: 0.9481\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9570\n",
      "Epoch 00039: val_loss did not improve from 0.15672\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1317 - acc: 0.9570 - val_loss: 0.1757 - val_acc: 0.9532\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9596\n",
      "Epoch 00040: val_loss improved from 0.15672 to 0.15373, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/040-0.1537.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1223 - acc: 0.9596 - val_loss: 0.1537 - val_acc: 0.9574\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9620\n",
      "Epoch 00041: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1160 - acc: 0.9620 - val_loss: 0.1736 - val_acc: 0.9513\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9622\n",
      "Epoch 00042: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1148 - acc: 0.9622 - val_loss: 0.1603 - val_acc: 0.9564\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9629\n",
      "Epoch 00043: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1104 - acc: 0.9629 - val_loss: 0.1615 - val_acc: 0.9576\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9633\n",
      "Epoch 00044: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1137 - acc: 0.9633 - val_loss: 0.1873 - val_acc: 0.9513\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9661\n",
      "Epoch 00045: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1067 - acc: 0.9661 - val_loss: 0.1759 - val_acc: 0.9574\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9643\n",
      "Epoch 00046: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1070 - acc: 0.9643 - val_loss: 0.1738 - val_acc: 0.9529\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9658\n",
      "Epoch 00047: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1034 - acc: 0.9658 - val_loss: 0.1677 - val_acc: 0.9520\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9661\n",
      "Epoch 00048: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1022 - acc: 0.9661 - val_loss: 0.1746 - val_acc: 0.9550\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9665\n",
      "Epoch 00049: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0987 - acc: 0.9665 - val_loss: 0.1683 - val_acc: 0.9553\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9654\n",
      "Epoch 00050: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1047 - acc: 0.9654 - val_loss: 0.1578 - val_acc: 0.9571\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9694\n",
      "Epoch 00051: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0930 - acc: 0.9694 - val_loss: 0.1642 - val_acc: 0.9550\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9691\n",
      "Epoch 00052: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0915 - acc: 0.9691 - val_loss: 0.1667 - val_acc: 0.9583\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9708\n",
      "Epoch 00053: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0877 - acc: 0.9708 - val_loss: 0.1721 - val_acc: 0.9550\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9696\n",
      "Epoch 00054: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0907 - acc: 0.9696 - val_loss: 0.1765 - val_acc: 0.9527\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9708\n",
      "Epoch 00055: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0862 - acc: 0.9707 - val_loss: 0.1905 - val_acc: 0.9555\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9710\n",
      "Epoch 00056: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0875 - acc: 0.9710 - val_loss: 0.1747 - val_acc: 0.9604\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9722\n",
      "Epoch 00057: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0797 - acc: 0.9722 - val_loss: 0.1682 - val_acc: 0.9588\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9732\n",
      "Epoch 00058: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0804 - acc: 0.9732 - val_loss: 0.1588 - val_acc: 0.9562\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9745\n",
      "Epoch 00059: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0742 - acc: 0.9745 - val_loss: 0.1666 - val_acc: 0.9609\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9733\n",
      "Epoch 00060: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0774 - acc: 0.9733 - val_loss: 0.1798 - val_acc: 0.9541\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9744\n",
      "Epoch 00061: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0740 - acc: 0.9744 - val_loss: 0.1761 - val_acc: 0.9571\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9747\n",
      "Epoch 00062: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0739 - acc: 0.9747 - val_loss: 0.1608 - val_acc: 0.9606\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9754\n",
      "Epoch 00063: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0716 - acc: 0.9754 - val_loss: 0.1931 - val_acc: 0.9571\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9737\n",
      "Epoch 00064: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0770 - acc: 0.9738 - val_loss: 0.1752 - val_acc: 0.9595\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9773\n",
      "Epoch 00065: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0679 - acc: 0.9773 - val_loss: 0.1637 - val_acc: 0.9627\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9798\n",
      "Epoch 00066: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0595 - acc: 0.9798 - val_loss: 0.1831 - val_acc: 0.9609\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9769\n",
      "Epoch 00067: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0694 - acc: 0.9769 - val_loss: 0.1550 - val_acc: 0.9599\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9787\n",
      "Epoch 00068: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0616 - acc: 0.9787 - val_loss: 0.1768 - val_acc: 0.9571\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9765\n",
      "Epoch 00069: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0679 - acc: 0.9765 - val_loss: 0.1903 - val_acc: 0.9569\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9783\n",
      "Epoch 00070: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0621 - acc: 0.9783 - val_loss: 0.1782 - val_acc: 0.9602\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9798\n",
      "Epoch 00071: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0600 - acc: 0.9798 - val_loss: 0.1900 - val_acc: 0.9583\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9778\n",
      "Epoch 00072: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0642 - acc: 0.9778 - val_loss: 0.1598 - val_acc: 0.9609\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9792\n",
      "Epoch 00073: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0605 - acc: 0.9792 - val_loss: 0.1845 - val_acc: 0.9581\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9795\n",
      "Epoch 00074: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0604 - acc: 0.9795 - val_loss: 0.1852 - val_acc: 0.9534\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9807\n",
      "Epoch 00075: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0568 - acc: 0.9807 - val_loss: 0.1883 - val_acc: 0.9590\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9806\n",
      "Epoch 00076: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0577 - acc: 0.9806 - val_loss: 0.1781 - val_acc: 0.9592\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9819\n",
      "Epoch 00077: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0539 - acc: 0.9819 - val_loss: 0.1830 - val_acc: 0.9536\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9784\n",
      "Epoch 00078: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0670 - acc: 0.9784 - val_loss: 0.1948 - val_acc: 0.9597\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9821\n",
      "Epoch 00079: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0527 - acc: 0.9821 - val_loss: 0.1881 - val_acc: 0.9585\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9829\n",
      "Epoch 00080: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0526 - acc: 0.9829 - val_loss: 0.1660 - val_acc: 0.9627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9820\n",
      "Epoch 00081: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0550 - acc: 0.9820 - val_loss: 0.1749 - val_acc: 0.9611\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9834\n",
      "Epoch 00082: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0503 - acc: 0.9834 - val_loss: 0.1996 - val_acc: 0.9616\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9814\n",
      "Epoch 00083: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0526 - acc: 0.9814 - val_loss: 0.1830 - val_acc: 0.9592\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9823\n",
      "Epoch 00084: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0516 - acc: 0.9823 - val_loss: 0.1750 - val_acc: 0.9611\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9821\n",
      "Epoch 00085: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0507 - acc: 0.9821 - val_loss: 0.1897 - val_acc: 0.9611\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9814\n",
      "Epoch 00086: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0522 - acc: 0.9814 - val_loss: 0.1732 - val_acc: 0.9599\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9839\n",
      "Epoch 00087: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0477 - acc: 0.9839 - val_loss: 0.1788 - val_acc: 0.9609\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9843\n",
      "Epoch 00088: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0465 - acc: 0.9843 - val_loss: 0.2147 - val_acc: 0.9606\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9840\n",
      "Epoch 00089: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0464 - acc: 0.9840 - val_loss: 0.1944 - val_acc: 0.9625\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9847\n",
      "Epoch 00090: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0477 - acc: 0.9847 - val_loss: 0.1837 - val_acc: 0.9611\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2009 - acc: 0.9427\n",
      "Loss: 0.20089558003352315 Accuracy: 0.9426791\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5030 - acc: 0.1666\n",
      "Epoch 00001: val_loss improved from inf to 1.77017, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/001-1.7702.hdf5\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 2.5029 - acc: 0.1667 - val_loss: 1.7702 - val_acc: 0.4377\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5336 - acc: 0.4921\n",
      "Epoch 00002: val_loss improved from 1.77017 to 1.02237, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/002-1.0224.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.5335 - acc: 0.4921 - val_loss: 1.0224 - val_acc: 0.6776\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1249 - acc: 0.6308\n",
      "Epoch 00003: val_loss improved from 1.02237 to 0.81245, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/003-0.8125.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.1249 - acc: 0.6308 - val_loss: 0.8125 - val_acc: 0.7477\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9261 - acc: 0.6983\n",
      "Epoch 00004: val_loss improved from 0.81245 to 0.66076, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/004-0.6608.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.9263 - acc: 0.6982 - val_loss: 0.6608 - val_acc: 0.8022\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7937 - acc: 0.7420\n",
      "Epoch 00005: val_loss improved from 0.66076 to 0.60150, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/005-0.6015.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.7937 - acc: 0.7420 - val_loss: 0.6015 - val_acc: 0.8074\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6864 - acc: 0.7756\n",
      "Epoch 00006: val_loss improved from 0.60150 to 0.47397, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/006-0.4740.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6863 - acc: 0.7756 - val_loss: 0.4740 - val_acc: 0.8509\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5950 - acc: 0.8085\n",
      "Epoch 00007: val_loss improved from 0.47397 to 0.39878, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/007-0.3988.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5950 - acc: 0.8085 - val_loss: 0.3988 - val_acc: 0.8749\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5115 - acc: 0.8357\n",
      "Epoch 00008: val_loss improved from 0.39878 to 0.33302, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/008-0.3330.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5114 - acc: 0.8357 - val_loss: 0.3330 - val_acc: 0.9005\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4549 - acc: 0.8548\n",
      "Epoch 00009: val_loss improved from 0.33302 to 0.31605, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/009-0.3160.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4548 - acc: 0.8548 - val_loss: 0.3160 - val_acc: 0.9031\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4147 - acc: 0.8668\n",
      "Epoch 00010: val_loss improved from 0.31605 to 0.28011, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/010-0.2801.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4147 - acc: 0.8668 - val_loss: 0.2801 - val_acc: 0.9217\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3804 - acc: 0.8804\n",
      "Epoch 00011: val_loss improved from 0.28011 to 0.25815, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/011-0.2581.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3804 - acc: 0.8804 - val_loss: 0.2581 - val_acc: 0.9245\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3425 - acc: 0.8915\n",
      "Epoch 00012: val_loss improved from 0.25815 to 0.22267, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/012-0.2227.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3425 - acc: 0.8915 - val_loss: 0.2227 - val_acc: 0.9364\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3146 - acc: 0.8997\n",
      "Epoch 00013: val_loss did not improve from 0.22267\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3146 - acc: 0.8997 - val_loss: 0.2308 - val_acc: 0.9324\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3000 - acc: 0.9046\n",
      "Epoch 00014: val_loss improved from 0.22267 to 0.21192, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/014-0.2119.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2999 - acc: 0.9046 - val_loss: 0.2119 - val_acc: 0.9359\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2791 - acc: 0.9123\n",
      "Epoch 00015: val_loss improved from 0.21192 to 0.18893, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/015-0.1889.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2791 - acc: 0.9123 - val_loss: 0.1889 - val_acc: 0.9455\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2580 - acc: 0.9197\n",
      "Epoch 00016: val_loss improved from 0.18893 to 0.18810, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/016-0.1881.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2580 - acc: 0.9197 - val_loss: 0.1881 - val_acc: 0.9443\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2507 - acc: 0.9205\n",
      "Epoch 00017: val_loss improved from 0.18810 to 0.18106, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/017-0.1811.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2507 - acc: 0.9205 - val_loss: 0.1811 - val_acc: 0.9464\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2290 - acc: 0.9279\n",
      "Epoch 00018: val_loss improved from 0.18106 to 0.15562, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/018-0.1556.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2290 - acc: 0.9279 - val_loss: 0.1556 - val_acc: 0.9522\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9317\n",
      "Epoch 00019: val_loss did not improve from 0.15562\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2134 - acc: 0.9317 - val_loss: 0.1599 - val_acc: 0.9555\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9323\n",
      "Epoch 00020: val_loss improved from 0.15562 to 0.15507, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/020-0.1551.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2078 - acc: 0.9323 - val_loss: 0.1551 - val_acc: 0.9529\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1950 - acc: 0.9376\n",
      "Epoch 00021: val_loss improved from 0.15507 to 0.14213, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/021-0.1421.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1950 - acc: 0.9376 - val_loss: 0.1421 - val_acc: 0.9620\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1863 - acc: 0.9405\n",
      "Epoch 00022: val_loss did not improve from 0.14213\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1863 - acc: 0.9405 - val_loss: 0.1510 - val_acc: 0.9548\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9423\n",
      "Epoch 00023: val_loss improved from 0.14213 to 0.13079, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/023-0.1308.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1801 - acc: 0.9423 - val_loss: 0.1308 - val_acc: 0.9606\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9438\n",
      "Epoch 00024: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1702 - acc: 0.9438 - val_loss: 0.1422 - val_acc: 0.9562\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9480\n",
      "Epoch 00025: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1627 - acc: 0.9480 - val_loss: 0.1373 - val_acc: 0.9597\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9489\n",
      "Epoch 00026: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1572 - acc: 0.9489 - val_loss: 0.1454 - val_acc: 0.9567\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9511\n",
      "Epoch 00027: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1516 - acc: 0.9511 - val_loss: 0.1315 - val_acc: 0.9637\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9523\n",
      "Epoch 00028: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1436 - acc: 0.9523 - val_loss: 0.1357 - val_acc: 0.9578\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9555\n",
      "Epoch 00029: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1388 - acc: 0.9555 - val_loss: 0.1324 - val_acc: 0.9599\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9564\n",
      "Epoch 00030: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1325 - acc: 0.9564 - val_loss: 0.1322 - val_acc: 0.9627\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9556\n",
      "Epoch 00031: val_loss did not improve from 0.13079\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1324 - acc: 0.9556 - val_loss: 0.1314 - val_acc: 0.9616\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9580\n",
      "Epoch 00032: val_loss improved from 0.13079 to 0.11777, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/032-0.1178.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1259 - acc: 0.9580 - val_loss: 0.1178 - val_acc: 0.9658\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9597\n",
      "Epoch 00033: val_loss did not improve from 0.11777\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1230 - acc: 0.9597 - val_loss: 0.1321 - val_acc: 0.9616\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9611\n",
      "Epoch 00034: val_loss did not improve from 0.11777\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1183 - acc: 0.9610 - val_loss: 0.1266 - val_acc: 0.9634\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9619\n",
      "Epoch 00035: val_loss did not improve from 0.11777\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1125 - acc: 0.9619 - val_loss: 0.1235 - val_acc: 0.9653\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9638\n",
      "Epoch 00036: val_loss did not improve from 0.11777\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1096 - acc: 0.9638 - val_loss: 0.1353 - val_acc: 0.9618\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9645\n",
      "Epoch 00037: val_loss improved from 0.11777 to 0.11737, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/037-0.1174.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1065 - acc: 0.9645 - val_loss: 0.1174 - val_acc: 0.9655\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9666\n",
      "Epoch 00038: val_loss did not improve from 0.11737\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1022 - acc: 0.9666 - val_loss: 0.1299 - val_acc: 0.9627\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9688\n",
      "Epoch 00039: val_loss improved from 0.11737 to 0.11534, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/039-0.1153.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0943 - acc: 0.9688 - val_loss: 0.1153 - val_acc: 0.9686\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9679\n",
      "Epoch 00040: val_loss did not improve from 0.11534\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0954 - acc: 0.9679 - val_loss: 0.1242 - val_acc: 0.9604\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9696\n",
      "Epoch 00041: val_loss did not improve from 0.11534\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0904 - acc: 0.9696 - val_loss: 0.1342 - val_acc: 0.9606\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9686\n",
      "Epoch 00042: val_loss improved from 0.11534 to 0.11337, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/042-0.1134.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0929 - acc: 0.9686 - val_loss: 0.1134 - val_acc: 0.9660\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9696\n",
      "Epoch 00043: val_loss did not improve from 0.11337\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0895 - acc: 0.9696 - val_loss: 0.1276 - val_acc: 0.9620\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9721\n",
      "Epoch 00044: val_loss did not improve from 0.11337\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0868 - acc: 0.9721 - val_loss: 0.1187 - val_acc: 0.9690\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9724\n",
      "Epoch 00045: val_loss improved from 0.11337 to 0.11122, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/045-0.1112.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0833 - acc: 0.9724 - val_loss: 0.1112 - val_acc: 0.9697\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9744\n",
      "Epoch 00046: val_loss did not improve from 0.11122\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0789 - acc: 0.9744 - val_loss: 0.1236 - val_acc: 0.9662\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9732\n",
      "Epoch 00047: val_loss improved from 0.11122 to 0.10720, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/047-0.1072.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0798 - acc: 0.9732 - val_loss: 0.1072 - val_acc: 0.9695\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9747\n",
      "Epoch 00048: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0760 - acc: 0.9747 - val_loss: 0.1161 - val_acc: 0.9660\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9752\n",
      "Epoch 00049: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0734 - acc: 0.9752 - val_loss: 0.1292 - val_acc: 0.9641\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9754\n",
      "Epoch 00050: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0718 - acc: 0.9753 - val_loss: 0.1090 - val_acc: 0.9695\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9755\n",
      "Epoch 00051: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0728 - acc: 0.9755 - val_loss: 0.1210 - val_acc: 0.9690\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9774\n",
      "Epoch 00052: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0670 - acc: 0.9774 - val_loss: 0.1252 - val_acc: 0.9651\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9780\n",
      "Epoch 00053: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0656 - acc: 0.9780 - val_loss: 0.1301 - val_acc: 0.9630\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9780\n",
      "Epoch 00054: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0663 - acc: 0.9780 - val_loss: 0.1285 - val_acc: 0.9618\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9787\n",
      "Epoch 00055: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0650 - acc: 0.9787 - val_loss: 0.1260 - val_acc: 0.9686\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9778\n",
      "Epoch 00056: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0661 - acc: 0.9777 - val_loss: 0.1275 - val_acc: 0.9658\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9797\n",
      "Epoch 00057: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0591 - acc: 0.9796 - val_loss: 0.1290 - val_acc: 0.9667\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9790\n",
      "Epoch 00058: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0623 - acc: 0.9790 - val_loss: 0.1314 - val_acc: 0.9674\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9789\n",
      "Epoch 00059: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0595 - acc: 0.9789 - val_loss: 0.1259 - val_acc: 0.9676\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9790\n",
      "Epoch 00060: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0630 - acc: 0.9790 - val_loss: 0.1094 - val_acc: 0.9695\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9821\n",
      "Epoch 00061: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0548 - acc: 0.9821 - val_loss: 0.1302 - val_acc: 0.9679\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9820\n",
      "Epoch 00062: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0555 - acc: 0.9820 - val_loss: 0.1188 - val_acc: 0.9672\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9822\n",
      "Epoch 00063: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0520 - acc: 0.9822 - val_loss: 0.1318 - val_acc: 0.9674\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9826\n",
      "Epoch 00064: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0516 - acc: 0.9826 - val_loss: 0.1196 - val_acc: 0.9709\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9818\n",
      "Epoch 00065: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0549 - acc: 0.9818 - val_loss: 0.1449 - val_acc: 0.9693\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9830\n",
      "Epoch 00066: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0502 - acc: 0.9830 - val_loss: 0.1297 - val_acc: 0.9648\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9839\n",
      "Epoch 00067: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0486 - acc: 0.9839 - val_loss: 0.1137 - val_acc: 0.9713\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9843\n",
      "Epoch 00068: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0476 - acc: 0.9843 - val_loss: 0.1406 - val_acc: 0.9690\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9824\n",
      "Epoch 00069: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0549 - acc: 0.9824 - val_loss: 0.1395 - val_acc: 0.9681\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9846\n",
      "Epoch 00070: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0449 - acc: 0.9846 - val_loss: 0.1263 - val_acc: 0.9686\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9831\n",
      "Epoch 00071: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0488 - acc: 0.9831 - val_loss: 0.1252 - val_acc: 0.9725\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9854\n",
      "Epoch 00072: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0450 - acc: 0.9853 - val_loss: 0.1543 - val_acc: 0.9637\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9835\n",
      "Epoch 00073: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0477 - acc: 0.9835 - val_loss: 0.1233 - val_acc: 0.9706\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9860\n",
      "Epoch 00074: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0414 - acc: 0.9860 - val_loss: 0.1218 - val_acc: 0.9697\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9848\n",
      "Epoch 00075: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0430 - acc: 0.9847 - val_loss: 0.1429 - val_acc: 0.9641\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9841\n",
      "Epoch 00076: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0471 - acc: 0.9841 - val_loss: 0.1196 - val_acc: 0.9718\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9850\n",
      "Epoch 00077: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0438 - acc: 0.9850 - val_loss: 0.1292 - val_acc: 0.9702\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9874\n",
      "Epoch 00078: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0382 - acc: 0.9874 - val_loss: 0.1358 - val_acc: 0.9688\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9863\n",
      "Epoch 00079: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0414 - acc: 0.9863 - val_loss: 0.1172 - val_acc: 0.9674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9870\n",
      "Epoch 00080: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0371 - acc: 0.9870 - val_loss: 0.1406 - val_acc: 0.9681\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9860\n",
      "Epoch 00081: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0416 - acc: 0.9860 - val_loss: 0.1220 - val_acc: 0.9702\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9878\n",
      "Epoch 00082: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0376 - acc: 0.9878 - val_loss: 0.1387 - val_acc: 0.9686\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9871\n",
      "Epoch 00083: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0382 - acc: 0.9871 - val_loss: 0.1362 - val_acc: 0.9674\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9869\n",
      "Epoch 00084: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0395 - acc: 0.9869 - val_loss: 0.1403 - val_acc: 0.9706\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9879\n",
      "Epoch 00085: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0356 - acc: 0.9878 - val_loss: 0.1271 - val_acc: 0.9702\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9875\n",
      "Epoch 00086: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0385 - acc: 0.9875 - val_loss: 0.1385 - val_acc: 0.9690\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9883\n",
      "Epoch 00087: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0353 - acc: 0.9883 - val_loss: 0.1231 - val_acc: 0.9686\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9892\n",
      "Epoch 00088: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0338 - acc: 0.9891 - val_loss: 0.1417 - val_acc: 0.9674\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9872\n",
      "Epoch 00089: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0378 - acc: 0.9872 - val_loss: 0.1656 - val_acc: 0.9690\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9893\n",
      "Epoch 00090: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0321 - acc: 0.9893 - val_loss: 0.1633 - val_acc: 0.9683\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9892\n",
      "Epoch 00091: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0318 - acc: 0.9892 - val_loss: 0.1343 - val_acc: 0.9695\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9889\n",
      "Epoch 00092: val_loss did not improve from 0.10720\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0330 - acc: 0.9888 - val_loss: 0.1343 - val_acc: 0.9695\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9875\n",
      "Epoch 00093: val_loss improved from 0.10720 to 0.10587, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/093-0.1059.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0387 - acc: 0.9875 - val_loss: 0.1059 - val_acc: 0.9734\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9887\n",
      "Epoch 00094: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0318 - acc: 0.9888 - val_loss: 0.1410 - val_acc: 0.9679\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9899\n",
      "Epoch 00095: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0301 - acc: 0.9899 - val_loss: 0.1385 - val_acc: 0.9704\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9885\n",
      "Epoch 00096: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0344 - acc: 0.9885 - val_loss: 0.1546 - val_acc: 0.9681\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9897\n",
      "Epoch 00097: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0314 - acc: 0.9897 - val_loss: 0.1385 - val_acc: 0.9697\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9897\n",
      "Epoch 00098: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0302 - acc: 0.9897 - val_loss: 0.1502 - val_acc: 0.9676\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9916\n",
      "Epoch 00099: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0257 - acc: 0.9916 - val_loss: 0.1740 - val_acc: 0.9637\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9899\n",
      "Epoch 00100: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0308 - acc: 0.9899 - val_loss: 0.1368 - val_acc: 0.9709\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9901\n",
      "Epoch 00101: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0293 - acc: 0.9901 - val_loss: 0.1331 - val_acc: 0.9683\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9912\n",
      "Epoch 00102: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0269 - acc: 0.9912 - val_loss: 0.1498 - val_acc: 0.9697\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9905\n",
      "Epoch 00103: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0286 - acc: 0.9905 - val_loss: 0.1774 - val_acc: 0.9676\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9911\n",
      "Epoch 00104: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0283 - acc: 0.9911 - val_loss: 0.1269 - val_acc: 0.9700\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9909\n",
      "Epoch 00105: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0273 - acc: 0.9909 - val_loss: 0.1934 - val_acc: 0.9651\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9914\n",
      "Epoch 00106: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0273 - acc: 0.9914 - val_loss: 0.1728 - val_acc: 0.9700\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9902\n",
      "Epoch 00107: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0303 - acc: 0.9902 - val_loss: 0.1383 - val_acc: 0.9700\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9908\n",
      "Epoch 00108: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0273 - acc: 0.9908 - val_loss: 0.1288 - val_acc: 0.9725\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9914\n",
      "Epoch 00109: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0264 - acc: 0.9914 - val_loss: 0.1539 - val_acc: 0.9706\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 00110: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0242 - acc: 0.9917 - val_loss: 0.1478 - val_acc: 0.9709\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9921\n",
      "Epoch 00111: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0236 - acc: 0.9921 - val_loss: 0.1598 - val_acc: 0.9660\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9914\n",
      "Epoch 00112: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0258 - acc: 0.9914 - val_loss: 0.1685 - val_acc: 0.9676\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9920\n",
      "Epoch 00113: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0235 - acc: 0.9920 - val_loss: 0.1577 - val_acc: 0.9681\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9921\n",
      "Epoch 00114: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0242 - acc: 0.9921 - val_loss: 0.1439 - val_acc: 0.9709\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9899\n",
      "Epoch 00115: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0297 - acc: 0.9899 - val_loss: 0.1259 - val_acc: 0.9713\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9927\n",
      "Epoch 00116: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0218 - acc: 0.9927 - val_loss: 0.1457 - val_acc: 0.9674\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9898\n",
      "Epoch 00117: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0313 - acc: 0.9898 - val_loss: 0.1431 - val_acc: 0.9695\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9931\n",
      "Epoch 00118: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0201 - acc: 0.9931 - val_loss: 0.1269 - val_acc: 0.9725\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9932\n",
      "Epoch 00119: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0211 - acc: 0.9932 - val_loss: 0.1261 - val_acc: 0.9711\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9926\n",
      "Epoch 00120: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0239 - acc: 0.9926 - val_loss: 0.1356 - val_acc: 0.9690\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9931\n",
      "Epoch 00121: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0218 - acc: 0.9931 - val_loss: 0.1516 - val_acc: 0.9697\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9941\n",
      "Epoch 00122: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0185 - acc: 0.9941 - val_loss: 0.1515 - val_acc: 0.9700\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9919\n",
      "Epoch 00123: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0236 - acc: 0.9919 - val_loss: 0.1514 - val_acc: 0.9690\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9926\n",
      "Epoch 00124: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0234 - acc: 0.9926 - val_loss: 0.1527 - val_acc: 0.9723\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9929\n",
      "Epoch 00125: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0218 - acc: 0.9929 - val_loss: 0.1524 - val_acc: 0.9700\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9929\n",
      "Epoch 00126: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0212 - acc: 0.9929 - val_loss: 0.1700 - val_acc: 0.9681\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9926\n",
      "Epoch 00127: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0215 - acc: 0.9926 - val_loss: 0.1371 - val_acc: 0.9704\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9942\n",
      "Epoch 00128: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0190 - acc: 0.9942 - val_loss: 0.1631 - val_acc: 0.9690\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9934\n",
      "Epoch 00129: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0203 - acc: 0.9934 - val_loss: 0.1528 - val_acc: 0.9723\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9935\n",
      "Epoch 00130: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0200 - acc: 0.9935 - val_loss: 0.1474 - val_acc: 0.9693\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9936\n",
      "Epoch 00131: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0200 - acc: 0.9936 - val_loss: 0.1487 - val_acc: 0.9709\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9939\n",
      "Epoch 00132: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0184 - acc: 0.9939 - val_loss: 0.1606 - val_acc: 0.9667\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9937\n",
      "Epoch 00133: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0210 - acc: 0.9937 - val_loss: 0.1733 - val_acc: 0.9688\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9934\n",
      "Epoch 00134: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0198 - acc: 0.9934 - val_loss: 0.1564 - val_acc: 0.9702\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9940\n",
      "Epoch 00135: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0194 - acc: 0.9940 - val_loss: 0.1489 - val_acc: 0.9706\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9932\n",
      "Epoch 00136: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0206 - acc: 0.9932 - val_loss: 0.1445 - val_acc: 0.9713\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9946\n",
      "Epoch 00137: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0169 - acc: 0.9946 - val_loss: 0.1459 - val_acc: 0.9727\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9936\n",
      "Epoch 00138: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0193 - acc: 0.9936 - val_loss: 0.1578 - val_acc: 0.9704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9934\n",
      "Epoch 00139: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0205 - acc: 0.9934 - val_loss: 0.1362 - val_acc: 0.9720\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9937\n",
      "Epoch 00140: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0207 - acc: 0.9937 - val_loss: 0.1383 - val_acc: 0.9709\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9951\n",
      "Epoch 00141: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0153 - acc: 0.9951 - val_loss: 0.1399 - val_acc: 0.9711\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9941\n",
      "Epoch 00142: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0190 - acc: 0.9941 - val_loss: 0.1624 - val_acc: 0.9688\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9945\n",
      "Epoch 00143: val_loss did not improve from 0.10587\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0165 - acc: 0.9945 - val_loss: 0.1732 - val_acc: 0.9681\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1829 - acc: 0.9630\n",
      "Loss: 0.18293105663304596 Accuracy: 0.9630322\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2604 - acc: 0.2589\n",
      "Epoch 00001: val_loss improved from inf to 1.45279, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/001-1.4528.hdf5\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 2.2604 - acc: 0.2589 - val_loss: 1.4528 - val_acc: 0.5316\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2838 - acc: 0.5808\n",
      "Epoch 00002: val_loss improved from 1.45279 to 0.93213, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/002-0.9321.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.2837 - acc: 0.5808 - val_loss: 0.9321 - val_acc: 0.7009\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8632 - acc: 0.7179\n",
      "Epoch 00003: val_loss improved from 0.93213 to 0.63588, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/003-0.6359.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.8632 - acc: 0.7179 - val_loss: 0.6359 - val_acc: 0.7936\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6488 - acc: 0.7901\n",
      "Epoch 00004: val_loss improved from 0.63588 to 0.59140, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/004-0.5914.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6488 - acc: 0.7901 - val_loss: 0.5914 - val_acc: 0.8178\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5368 - acc: 0.8268\n",
      "Epoch 00005: val_loss improved from 0.59140 to 0.47067, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/005-0.4707.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5369 - acc: 0.8267 - val_loss: 0.4707 - val_acc: 0.8528\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4689 - acc: 0.8490\n",
      "Epoch 00006: val_loss improved from 0.47067 to 0.32111, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/006-0.3211.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4689 - acc: 0.8490 - val_loss: 0.3211 - val_acc: 0.8959\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4123 - acc: 0.8689\n",
      "Epoch 00007: val_loss did not improve from 0.32111\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4124 - acc: 0.8688 - val_loss: 0.3538 - val_acc: 0.8896\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3639 - acc: 0.8827\n",
      "Epoch 00008: val_loss improved from 0.32111 to 0.28435, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/008-0.2843.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3639 - acc: 0.8827 - val_loss: 0.2843 - val_acc: 0.9092\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3215 - acc: 0.8956\n",
      "Epoch 00009: val_loss improved from 0.28435 to 0.26217, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/009-0.2622.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3214 - acc: 0.8956 - val_loss: 0.2622 - val_acc: 0.9166\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.9048\n",
      "Epoch 00010: val_loss improved from 0.26217 to 0.25965, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/010-0.2597.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2970 - acc: 0.9047 - val_loss: 0.2597 - val_acc: 0.9187\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9131\n",
      "Epoch 00011: val_loss improved from 0.25965 to 0.22228, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/011-0.2223.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2708 - acc: 0.9131 - val_loss: 0.2223 - val_acc: 0.9329\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2529 - acc: 0.9181\n",
      "Epoch 00012: val_loss improved from 0.22228 to 0.20242, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/012-0.2024.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2529 - acc: 0.9181 - val_loss: 0.2024 - val_acc: 0.9357\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2287 - acc: 0.9254\n",
      "Epoch 00013: val_loss improved from 0.20242 to 0.20198, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/013-0.2020.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2287 - acc: 0.9254 - val_loss: 0.2020 - val_acc: 0.9369\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2101 - acc: 0.9317\n",
      "Epoch 00014: val_loss improved from 0.20198 to 0.19779, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/014-0.1978.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2101 - acc: 0.9317 - val_loss: 0.1978 - val_acc: 0.9357\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1985 - acc: 0.9348\n",
      "Epoch 00015: val_loss did not improve from 0.19779\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1985 - acc: 0.9348 - val_loss: 0.2298 - val_acc: 0.9264\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9401\n",
      "Epoch 00016: val_loss improved from 0.19779 to 0.16430, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/016-0.1643.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1831 - acc: 0.9401 - val_loss: 0.1643 - val_acc: 0.9469\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1749 - acc: 0.9427\n",
      "Epoch 00017: val_loss did not improve from 0.16430\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1750 - acc: 0.9427 - val_loss: 0.1700 - val_acc: 0.9495\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9489\n",
      "Epoch 00018: val_loss did not improve from 0.16430\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1569 - acc: 0.9489 - val_loss: 0.1908 - val_acc: 0.9399\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9510\n",
      "Epoch 00019: val_loss did not improve from 0.16430\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1491 - acc: 0.9510 - val_loss: 0.1780 - val_acc: 0.9464\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9528\n",
      "Epoch 00020: val_loss did not improve from 0.16430\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1402 - acc: 0.9528 - val_loss: 0.1766 - val_acc: 0.9432\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9555\n",
      "Epoch 00021: val_loss did not improve from 0.16430\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1344 - acc: 0.9555 - val_loss: 0.1685 - val_acc: 0.9434\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9573\n",
      "Epoch 00022: val_loss improved from 0.16430 to 0.16262, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/022-0.1626.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1291 - acc: 0.9573 - val_loss: 0.1626 - val_acc: 0.9515\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9584\n",
      "Epoch 00023: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1265 - acc: 0.9584 - val_loss: 0.1639 - val_acc: 0.9539\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9626\n",
      "Epoch 00024: val_loss improved from 0.16262 to 0.16232, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/024-0.1623.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1124 - acc: 0.9626 - val_loss: 0.1623 - val_acc: 0.9553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9652\n",
      "Epoch 00025: val_loss improved from 0.16232 to 0.14835, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/025-0.1484.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1054 - acc: 0.9652 - val_loss: 0.1484 - val_acc: 0.9539\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9655\n",
      "Epoch 00026: val_loss did not improve from 0.14835\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1038 - acc: 0.9655 - val_loss: 0.1747 - val_acc: 0.9515\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9673\n",
      "Epoch 00027: val_loss improved from 0.14835 to 0.14019, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/027-0.1402.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0965 - acc: 0.9673 - val_loss: 0.1402 - val_acc: 0.9567\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9689\n",
      "Epoch 00028: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0901 - acc: 0.9689 - val_loss: 0.1557 - val_acc: 0.9546\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9718\n",
      "Epoch 00029: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0839 - acc: 0.9718 - val_loss: 0.1608 - val_acc: 0.9574\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9704\n",
      "Epoch 00030: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0893 - acc: 0.9704 - val_loss: 0.1684 - val_acc: 0.9562\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9725\n",
      "Epoch 00031: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0787 - acc: 0.9725 - val_loss: 0.1536 - val_acc: 0.9595\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9758\n",
      "Epoch 00032: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0721 - acc: 0.9758 - val_loss: 0.1444 - val_acc: 0.9630\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9756\n",
      "Epoch 00033: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0712 - acc: 0.9756 - val_loss: 0.1492 - val_acc: 0.9595\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9763\n",
      "Epoch 00034: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0720 - acc: 0.9763 - val_loss: 0.1529 - val_acc: 0.9583\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9776\n",
      "Epoch 00035: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0659 - acc: 0.9776 - val_loss: 0.1591 - val_acc: 0.9553\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9789\n",
      "Epoch 00036: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0621 - acc: 0.9789 - val_loss: 0.1823 - val_acc: 0.9590\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9798\n",
      "Epoch 00037: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0595 - acc: 0.9798 - val_loss: 0.1453 - val_acc: 0.9585\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9809\n",
      "Epoch 00038: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0566 - acc: 0.9809 - val_loss: 0.1669 - val_acc: 0.9571\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9807\n",
      "Epoch 00039: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0586 - acc: 0.9807 - val_loss: 0.1619 - val_acc: 0.9597\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9820\n",
      "Epoch 00040: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0531 - acc: 0.9820 - val_loss: 0.1597 - val_acc: 0.9597\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9822\n",
      "Epoch 00041: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0510 - acc: 0.9822 - val_loss: 0.1574 - val_acc: 0.9620\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9839\n",
      "Epoch 00042: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0483 - acc: 0.9839 - val_loss: 0.1568 - val_acc: 0.9646\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9841\n",
      "Epoch 00043: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0484 - acc: 0.9841 - val_loss: 0.1726 - val_acc: 0.9611\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9829\n",
      "Epoch 00044: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0529 - acc: 0.9829 - val_loss: 0.1600 - val_acc: 0.9602\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9842\n",
      "Epoch 00045: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0477 - acc: 0.9842 - val_loss: 0.1610 - val_acc: 0.9609\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9845\n",
      "Epoch 00046: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0458 - acc: 0.9845 - val_loss: 0.1731 - val_acc: 0.9597\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9865\n",
      "Epoch 00047: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0424 - acc: 0.9865 - val_loss: 0.1576 - val_acc: 0.9627\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9877\n",
      "Epoch 00048: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0366 - acc: 0.9877 - val_loss: 0.1653 - val_acc: 0.9620\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9862\n",
      "Epoch 00049: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0409 - acc: 0.9862 - val_loss: 0.1968 - val_acc: 0.9606\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9861\n",
      "Epoch 00050: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0420 - acc: 0.9861 - val_loss: 0.1892 - val_acc: 0.9532\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9874\n",
      "Epoch 00051: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0383 - acc: 0.9874 - val_loss: 0.1772 - val_acc: 0.9609\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9871\n",
      "Epoch 00052: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0389 - acc: 0.9871 - val_loss: 0.1847 - val_acc: 0.9609\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9885\n",
      "Epoch 00053: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0338 - acc: 0.9885 - val_loss: 0.1901 - val_acc: 0.9606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9881\n",
      "Epoch 00054: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0349 - acc: 0.9881 - val_loss: 0.1763 - val_acc: 0.9606\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9874\n",
      "Epoch 00055: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0379 - acc: 0.9874 - val_loss: 0.1862 - val_acc: 0.9576\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9899\n",
      "Epoch 00056: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0320 - acc: 0.9899 - val_loss: 0.1476 - val_acc: 0.9630\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9894\n",
      "Epoch 00057: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0322 - acc: 0.9894 - val_loss: 0.1549 - val_acc: 0.9634\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9885\n",
      "Epoch 00058: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0357 - acc: 0.9885 - val_loss: 0.2162 - val_acc: 0.9546\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9896\n",
      "Epoch 00059: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0312 - acc: 0.9896 - val_loss: 0.1700 - val_acc: 0.9676\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9898\n",
      "Epoch 00060: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0311 - acc: 0.9898 - val_loss: 0.1761 - val_acc: 0.9637\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9892\n",
      "Epoch 00061: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0339 - acc: 0.9892 - val_loss: 0.1822 - val_acc: 0.9641\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9907\n",
      "Epoch 00062: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0285 - acc: 0.9907 - val_loss: 0.1775 - val_acc: 0.9658\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9915\n",
      "Epoch 00063: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0254 - acc: 0.9915 - val_loss: 0.1910 - val_acc: 0.9627\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9913\n",
      "Epoch 00064: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0269 - acc: 0.9913 - val_loss: 0.1732 - val_acc: 0.9634\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9905\n",
      "Epoch 00065: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0286 - acc: 0.9905 - val_loss: 0.1748 - val_acc: 0.9627\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9912\n",
      "Epoch 00066: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0274 - acc: 0.9913 - val_loss: 0.1731 - val_acc: 0.9613\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9915\n",
      "Epoch 00067: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0264 - acc: 0.9916 - val_loss: 0.1931 - val_acc: 0.9651\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9916\n",
      "Epoch 00068: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0260 - acc: 0.9916 - val_loss: 0.2012 - val_acc: 0.9611\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9910\n",
      "Epoch 00069: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0281 - acc: 0.9910 - val_loss: 0.1744 - val_acc: 0.9660\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9908\n",
      "Epoch 00070: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0282 - acc: 0.9908 - val_loss: 0.1630 - val_acc: 0.9665\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9918\n",
      "Epoch 00071: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0250 - acc: 0.9918 - val_loss: 0.1772 - val_acc: 0.9683\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9924\n",
      "Epoch 00072: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0252 - acc: 0.9924 - val_loss: 0.1842 - val_acc: 0.9618\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9921\n",
      "Epoch 00073: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0247 - acc: 0.9921 - val_loss: 0.1915 - val_acc: 0.9611\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9929\n",
      "Epoch 00074: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0228 - acc: 0.9929 - val_loss: 0.1726 - val_acc: 0.9630\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9937\n",
      "Epoch 00075: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0206 - acc: 0.9937 - val_loss: 0.2027 - val_acc: 0.9653\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9923\n",
      "Epoch 00076: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0254 - acc: 0.9923 - val_loss: 0.2188 - val_acc: 0.9583\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9928\n",
      "Epoch 00077: val_loss did not improve from 0.14019\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0216 - acc: 0.9928 - val_loss: 0.1828 - val_acc: 0.9648\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2276 - acc: 0.9350\n",
      "Loss: 0.2276410343955239 Accuracy: 0.9349948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_custom_conv_3_VGG_DO_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 556us/sample - loss: 1.9917 - acc: 0.3877\n",
      "Loss: 1.9917109709043492 Accuracy: 0.38774663\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,498,320\n",
      "Trainable params: 5,498,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 882us/sample - loss: 1.7163 - acc: 0.4752\n",
      "Loss: 1.7163452906276826 Accuracy: 0.47518173\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.4290 - acc: 0.5626\n",
      "Loss: 1.4289896430008633 Accuracy: 0.5626168\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.0904 - acc: 0.6719\n",
      "Loss: 1.0903628553928244 Accuracy: 0.6718588\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.8833 - acc: 0.7666\n",
      "Loss: 0.883316714778496 Accuracy: 0.7665628\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.4131 - acc: 0.9018\n",
      "Loss: 0.41305809186255077 Accuracy: 0.9017653\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2009 - acc: 0.9427\n",
      "Loss: 0.20089558003352315 Accuracy: 0.9426791\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1829 - acc: 0.9630\n",
      "Loss: 0.18293105663304596 Accuracy: 0.9630322\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2276 - acc: 0.9350\n",
      "Loss: 0.2276410343955239 Accuracy: 0.9349948\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3300 - acc: 0.2712\n",
      "Epoch 00001: val_loss improved from inf to 2.12591, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_1_conv_checkpoint/001-2.1259.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 2.3300 - acc: 0.2712 - val_loss: 2.1259 - val_acc: 0.3629\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8783 - acc: 0.4381\n",
      "Epoch 00002: val_loss improved from 2.12591 to 1.97895, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_1_conv_checkpoint/002-1.9789.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.8783 - acc: 0.4381 - val_loss: 1.9789 - val_acc: 0.4093\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5242 - acc: 0.5536\n",
      "Epoch 00003: val_loss improved from 1.97895 to 1.96684, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_1_conv_checkpoint/003-1.9668.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.5242 - acc: 0.5536 - val_loss: 1.9668 - val_acc: 0.3923\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2126 - acc: 0.6523\n",
      "Epoch 00004: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.2126 - acc: 0.6523 - val_loss: 2.0496 - val_acc: 0.3857\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9591 - acc: 0.7336\n",
      "Epoch 00005: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.9590 - acc: 0.7336 - val_loss: 2.1410 - val_acc: 0.3697\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7464 - acc: 0.8001\n",
      "Epoch 00006: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.7463 - acc: 0.8001 - val_loss: 2.2736 - val_acc: 0.3666\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5856 - acc: 0.8480\n",
      "Epoch 00007: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.5856 - acc: 0.8480 - val_loss: 2.4395 - val_acc: 0.3757\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4513 - acc: 0.8888\n",
      "Epoch 00008: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4513 - acc: 0.8887 - val_loss: 2.6642 - val_acc: 0.3629\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3551 - acc: 0.9170\n",
      "Epoch 00009: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3555 - acc: 0.9169 - val_loss: 2.7774 - val_acc: 0.3590\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2828 - acc: 0.9376\n",
      "Epoch 00010: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2829 - acc: 0.9376 - val_loss: 2.9830 - val_acc: 0.3599\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9561\n",
      "Epoch 00011: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2201 - acc: 0.9561 - val_loss: 3.1157 - val_acc: 0.3641\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1763 - acc: 0.9659\n",
      "Epoch 00012: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1763 - acc: 0.9659 - val_loss: 3.3003 - val_acc: 0.3594\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9720\n",
      "Epoch 00013: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1496 - acc: 0.9720 - val_loss: 3.4533 - val_acc: 0.3510\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9801\n",
      "Epoch 00014: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1202 - acc: 0.9801 - val_loss: 3.5891 - val_acc: 0.3557\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9845\n",
      "Epoch 00015: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1027 - acc: 0.9845 - val_loss: 3.7164 - val_acc: 0.3592\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9881\n",
      "Epoch 00016: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0840 - acc: 0.9881 - val_loss: 3.8563 - val_acc: 0.3545\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9899\n",
      "Epoch 00017: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0747 - acc: 0.9899 - val_loss: 4.0169 - val_acc: 0.3508\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9917\n",
      "Epoch 00018: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0648 - acc: 0.9917 - val_loss: 4.0856 - val_acc: 0.3517\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9920\n",
      "Epoch 00019: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0638 - acc: 0.9920 - val_loss: 4.1614 - val_acc: 0.3592\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9923\n",
      "Epoch 00020: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0570 - acc: 0.9923 - val_loss: 4.3172 - val_acc: 0.3538\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9933\n",
      "Epoch 00021: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0567 - acc: 0.9933 - val_loss: 4.3105 - val_acc: 0.3604\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9940\n",
      "Epoch 00022: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0483 - acc: 0.9940 - val_loss: 4.4278 - val_acc: 0.3566\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9945\n",
      "Epoch 00023: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0474 - acc: 0.9945 - val_loss: 4.4085 - val_acc: 0.3608\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9939\n",
      "Epoch 00024: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0459 - acc: 0.9939 - val_loss: 4.5423 - val_acc: 0.3559\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9957\n",
      "Epoch 00025: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0395 - acc: 0.9957 - val_loss: 4.5487 - val_acc: 0.3529\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9958\n",
      "Epoch 00026: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0375 - acc: 0.9958 - val_loss: 4.6325 - val_acc: 0.3550\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9964\n",
      "Epoch 00027: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0325 - acc: 0.9964 - val_loss: 4.7920 - val_acc: 0.3489\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9968\n",
      "Epoch 00028: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0321 - acc: 0.9968 - val_loss: 4.7774 - val_acc: 0.3590\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9956\n",
      "Epoch 00029: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0357 - acc: 0.9956 - val_loss: 4.9086 - val_acc: 0.3615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9952\n",
      "Epoch 00030: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0361 - acc: 0.9952 - val_loss: 4.9427 - val_acc: 0.3427\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9958\n",
      "Epoch 00031: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0351 - acc: 0.9958 - val_loss: 4.8433 - val_acc: 0.3590\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9967\n",
      "Epoch 00032: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0292 - acc: 0.9967 - val_loss: 4.9068 - val_acc: 0.3573\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9966\n",
      "Epoch 00033: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0296 - acc: 0.9966 - val_loss: 5.0071 - val_acc: 0.3482\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9960\n",
      "Epoch 00034: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0321 - acc: 0.9960 - val_loss: 4.9567 - val_acc: 0.3627\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9969\n",
      "Epoch 00035: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0291 - acc: 0.9969 - val_loss: 5.0686 - val_acc: 0.3513\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9955\n",
      "Epoch 00036: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0319 - acc: 0.9955 - val_loss: 5.0095 - val_acc: 0.3655\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9976\n",
      "Epoch 00037: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0235 - acc: 0.9976 - val_loss: 5.0483 - val_acc: 0.3559\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9966\n",
      "Epoch 00038: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0266 - acc: 0.9966 - val_loss: 5.0865 - val_acc: 0.3629\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9973\n",
      "Epoch 00039: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0247 - acc: 0.9973 - val_loss: 5.2332 - val_acc: 0.3552\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9976\n",
      "Epoch 00040: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0225 - acc: 0.9976 - val_loss: 5.3115 - val_acc: 0.3538\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9964\n",
      "Epoch 00041: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0299 - acc: 0.9964 - val_loss: 5.1748 - val_acc: 0.3615\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9968\n",
      "Epoch 00042: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0264 - acc: 0.9968 - val_loss: 5.2449 - val_acc: 0.3562\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9979\n",
      "Epoch 00043: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0223 - acc: 0.9979 - val_loss: 5.2743 - val_acc: 0.3580\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9983\n",
      "Epoch 00044: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0201 - acc: 0.9983 - val_loss: 5.2996 - val_acc: 0.3601\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9976\n",
      "Epoch 00045: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0233 - acc: 0.9976 - val_loss: 5.3638 - val_acc: 0.3520\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9963\n",
      "Epoch 00046: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0283 - acc: 0.9963 - val_loss: 5.4133 - val_acc: 0.3461\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9961\n",
      "Epoch 00047: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0279 - acc: 0.9961 - val_loss: 5.4250 - val_acc: 0.3524\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9973\n",
      "Epoch 00048: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0231 - acc: 0.9973 - val_loss: 5.3360 - val_acc: 0.3585\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9972\n",
      "Epoch 00049: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0238 - acc: 0.9972 - val_loss: 5.4523 - val_acc: 0.3557\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9969\n",
      "Epoch 00050: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0254 - acc: 0.9969 - val_loss: 5.3636 - val_acc: 0.3625\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9974\n",
      "Epoch 00051: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0232 - acc: 0.9973 - val_loss: 5.3652 - val_acc: 0.3562\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9971\n",
      "Epoch 00052: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0241 - acc: 0.9971 - val_loss: 5.5032 - val_acc: 0.3541\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9975\n",
      "Epoch 00053: val_loss did not improve from 1.96684\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0234 - acc: 0.9975 - val_loss: 5.4972 - val_acc: 0.3527\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 780us/sample - loss: 1.9976 - acc: 0.3909\n",
      "Loss: 1.9976032813885254 Accuracy: 0.3908619\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2719 - acc: 0.2813\n",
      "Epoch 00001: val_loss improved from inf to 1.98344, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_2_conv_checkpoint/001-1.9834.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 2.2717 - acc: 0.2814 - val_loss: 1.9834 - val_acc: 0.4195\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7807 - acc: 0.4614\n",
      "Epoch 00002: val_loss improved from 1.98344 to 1.70794, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_2_conv_checkpoint/002-1.7079.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.7807 - acc: 0.4614 - val_loss: 1.7079 - val_acc: 0.4792\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4781 - acc: 0.5582\n",
      "Epoch 00003: val_loss improved from 1.70794 to 1.63943, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_2_conv_checkpoint/003-1.6394.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.4781 - acc: 0.5582 - val_loss: 1.6394 - val_acc: 0.5043\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2244 - acc: 0.6387\n",
      "Epoch 00004: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.2243 - acc: 0.6387 - val_loss: 1.6957 - val_acc: 0.4812\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9927 - acc: 0.7090\n",
      "Epoch 00005: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.9926 - acc: 0.7091 - val_loss: 1.7437 - val_acc: 0.4922\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7883 - acc: 0.7727\n",
      "Epoch 00006: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.7884 - acc: 0.7727 - val_loss: 1.8716 - val_acc: 0.4796\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6161 - acc: 0.8237\n",
      "Epoch 00007: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.6160 - acc: 0.8237 - val_loss: 1.9757 - val_acc: 0.4787\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4762 - acc: 0.8641\n",
      "Epoch 00008: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.4761 - acc: 0.8641 - val_loss: 2.1123 - val_acc: 0.4771\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3703 - acc: 0.8946\n",
      "Epoch 00009: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3704 - acc: 0.8946 - val_loss: 2.3043 - val_acc: 0.4733\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3006 - acc: 0.9159\n",
      "Epoch 00010: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3006 - acc: 0.9159 - val_loss: 2.5514 - val_acc: 0.4608\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2355 - acc: 0.9355\n",
      "Epoch 00011: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2355 - acc: 0.9355 - val_loss: 2.5846 - val_acc: 0.4838\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1957 - acc: 0.9470\n",
      "Epoch 00012: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1957 - acc: 0.9470 - val_loss: 2.7373 - val_acc: 0.4773\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1629 - acc: 0.9551\n",
      "Epoch 00013: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1629 - acc: 0.9551 - val_loss: 2.9386 - val_acc: 0.4787\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9607\n",
      "Epoch 00014: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1483 - acc: 0.9607 - val_loss: 2.9511 - val_acc: 0.4752\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9657\n",
      "Epoch 00015: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1303 - acc: 0.9657 - val_loss: 3.1450 - val_acc: 0.4824\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9694\n",
      "Epoch 00016: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1192 - acc: 0.9694 - val_loss: 3.2128 - val_acc: 0.4833\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9719\n",
      "Epoch 00017: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1077 - acc: 0.9719 - val_loss: 3.2647 - val_acc: 0.4726\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9760\n",
      "Epoch 00018: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0977 - acc: 0.9760 - val_loss: 3.3667 - val_acc: 0.4747\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9777\n",
      "Epoch 00019: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0900 - acc: 0.9777 - val_loss: 3.4399 - val_acc: 0.4787\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9796\n",
      "Epoch 00020: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0853 - acc: 0.9796 - val_loss: 3.5177 - val_acc: 0.4754\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9798\n",
      "Epoch 00021: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0822 - acc: 0.9798 - val_loss: 3.4876 - val_acc: 0.4829\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9832\n",
      "Epoch 00022: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0745 - acc: 0.9832 - val_loss: 3.5337 - val_acc: 0.4852\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9815\n",
      "Epoch 00023: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0767 - acc: 0.9815 - val_loss: 3.5827 - val_acc: 0.4857\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9821\n",
      "Epoch 00024: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0763 - acc: 0.9821 - val_loss: 3.6137 - val_acc: 0.4913\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9845\n",
      "Epoch 00025: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0665 - acc: 0.9844 - val_loss: 3.7620 - val_acc: 0.4726\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9836\n",
      "Epoch 00026: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0716 - acc: 0.9836 - val_loss: 3.7096 - val_acc: 0.4771\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9848\n",
      "Epoch 00027: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0648 - acc: 0.9848 - val_loss: 3.7397 - val_acc: 0.4799\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9871\n",
      "Epoch 00028: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0608 - acc: 0.9871 - val_loss: 3.7322 - val_acc: 0.4901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9864\n",
      "Epoch 00029: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0625 - acc: 0.9864 - val_loss: 3.8548 - val_acc: 0.4680\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9890\n",
      "Epoch 00030: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0519 - acc: 0.9890 - val_loss: 3.8559 - val_acc: 0.4775\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9871\n",
      "Epoch 00031: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0584 - acc: 0.9871 - val_loss: 3.7798 - val_acc: 0.4878\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9878\n",
      "Epoch 00032: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0559 - acc: 0.9878 - val_loss: 3.8672 - val_acc: 0.4805\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9891\n",
      "Epoch 00033: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0514 - acc: 0.9891 - val_loss: 3.9687 - val_acc: 0.4927\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9884\n",
      "Epoch 00034: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0544 - acc: 0.9884 - val_loss: 3.8581 - val_acc: 0.4794\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9884\n",
      "Epoch 00035: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0518 - acc: 0.9884 - val_loss: 3.8834 - val_acc: 0.4787\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9902\n",
      "Epoch 00036: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0459 - acc: 0.9902 - val_loss: 3.9049 - val_acc: 0.4838\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9886\n",
      "Epoch 00037: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0520 - acc: 0.9886 - val_loss: 3.9026 - val_acc: 0.4875\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9895\n",
      "Epoch 00038: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0492 - acc: 0.9895 - val_loss: 3.9662 - val_acc: 0.4868\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9902\n",
      "Epoch 00039: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0468 - acc: 0.9902 - val_loss: 4.0400 - val_acc: 0.4875\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9897\n",
      "Epoch 00040: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0475 - acc: 0.9897 - val_loss: 4.0514 - val_acc: 0.4817\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9884\n",
      "Epoch 00041: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0497 - acc: 0.9884 - val_loss: 3.9745 - val_acc: 0.4794\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9931\n",
      "Epoch 00042: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0388 - acc: 0.9931 - val_loss: 4.0346 - val_acc: 0.4847\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9923\n",
      "Epoch 00043: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0399 - acc: 0.9923 - val_loss: 4.0894 - val_acc: 0.4962\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9899\n",
      "Epoch 00044: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0492 - acc: 0.9899 - val_loss: 3.9999 - val_acc: 0.4845\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9915\n",
      "Epoch 00045: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0411 - acc: 0.9916 - val_loss: 4.0270 - val_acc: 0.4808\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9930\n",
      "Epoch 00046: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0395 - acc: 0.9930 - val_loss: 4.1196 - val_acc: 0.4859\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9920\n",
      "Epoch 00047: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0411 - acc: 0.9920 - val_loss: 4.0309 - val_acc: 0.4936\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9921\n",
      "Epoch 00048: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0401 - acc: 0.9921 - val_loss: 4.0827 - val_acc: 0.4817\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9929\n",
      "Epoch 00049: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0366 - acc: 0.9929 - val_loss: 4.0790 - val_acc: 0.4864\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9925\n",
      "Epoch 00050: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0404 - acc: 0.9925 - val_loss: 4.1136 - val_acc: 0.4852\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9928\n",
      "Epoch 00051: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0381 - acc: 0.9928 - val_loss: 4.1955 - val_acc: 0.4871\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9918\n",
      "Epoch 00052: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0405 - acc: 0.9918 - val_loss: 4.1961 - val_acc: 0.4861\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9919\n",
      "Epoch 00053: val_loss did not improve from 1.63943\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0412 - acc: 0.9919 - val_loss: 4.1157 - val_acc: 0.4957\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.7659 - acc: 0.4573\n",
      "Loss: 1.7659185970807496 Accuracy: 0.45732087\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2593 - acc: 0.2804\n",
      "Epoch 00001: val_loss improved from inf to 1.84776, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/001-1.8478.hdf5\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 2.2592 - acc: 0.2803 - val_loss: 1.8478 - val_acc: 0.4326\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6434 - acc: 0.4955\n",
      "Epoch 00002: val_loss improved from 1.84776 to 1.48839, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/002-1.4884.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.6433 - acc: 0.4955 - val_loss: 1.4884 - val_acc: 0.5532\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3383 - acc: 0.5932\n",
      "Epoch 00003: val_loss improved from 1.48839 to 1.37734, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/003-1.3773.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.3384 - acc: 0.5932 - val_loss: 1.3773 - val_acc: 0.5663\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1217 - acc: 0.6585\n",
      "Epoch 00004: val_loss improved from 1.37734 to 1.35713, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/004-1.3571.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.1217 - acc: 0.6586 - val_loss: 1.3571 - val_acc: 0.5795\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9464 - acc: 0.7144\n",
      "Epoch 00005: val_loss improved from 1.35713 to 1.34323, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_3_conv_checkpoint/005-1.3432.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.9465 - acc: 0.7144 - val_loss: 1.3432 - val_acc: 0.5833\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8008 - acc: 0.7567\n",
      "Epoch 00006: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.8008 - acc: 0.7567 - val_loss: 1.3709 - val_acc: 0.5980\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6726 - acc: 0.7954\n",
      "Epoch 00007: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.6725 - acc: 0.7954 - val_loss: 1.4024 - val_acc: 0.5993\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5655 - acc: 0.8274\n",
      "Epoch 00008: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.5655 - acc: 0.8274 - val_loss: 1.4854 - val_acc: 0.5947\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4855 - acc: 0.8501\n",
      "Epoch 00009: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.4856 - acc: 0.8501 - val_loss: 1.6215 - val_acc: 0.5805\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4122 - acc: 0.8722\n",
      "Epoch 00010: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.4121 - acc: 0.8722 - val_loss: 1.6634 - val_acc: 0.5928\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3460 - acc: 0.8937\n",
      "Epoch 00011: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.3460 - acc: 0.8937 - val_loss: 1.6713 - val_acc: 0.6119\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3044 - acc: 0.9061\n",
      "Epoch 00012: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.3044 - acc: 0.9062 - val_loss: 1.8112 - val_acc: 0.6019\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2653 - acc: 0.9186\n",
      "Epoch 00013: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2653 - acc: 0.9186 - val_loss: 1.8527 - val_acc: 0.6087\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.9258\n",
      "Epoch 00014: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2401 - acc: 0.9258 - val_loss: 1.8972 - val_acc: 0.6173\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2134 - acc: 0.9338\n",
      "Epoch 00015: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2134 - acc: 0.9338 - val_loss: 1.9530 - val_acc: 0.6175\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9392\n",
      "Epoch 00016: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1994 - acc: 0.9392 - val_loss: 2.0145 - val_acc: 0.6103\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1871 - acc: 0.9421\n",
      "Epoch 00017: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1872 - acc: 0.9421 - val_loss: 2.0110 - val_acc: 0.6254\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9527\n",
      "Epoch 00018: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1599 - acc: 0.9527 - val_loss: 2.0769 - val_acc: 0.6240\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9548\n",
      "Epoch 00019: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1518 - acc: 0.9547 - val_loss: 2.0794 - val_acc: 0.6215\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9573\n",
      "Epoch 00020: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1474 - acc: 0.9573 - val_loss: 2.1337 - val_acc: 0.6231\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9618\n",
      "Epoch 00021: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1298 - acc: 0.9618 - val_loss: 2.2326 - val_acc: 0.6191\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9627\n",
      "Epoch 00022: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1278 - acc: 0.9627 - val_loss: 2.1521 - val_acc: 0.6250\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9647\n",
      "Epoch 00023: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1236 - acc: 0.9647 - val_loss: 2.2552 - val_acc: 0.6171\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9649\n",
      "Epoch 00024: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1244 - acc: 0.9648 - val_loss: 2.1277 - val_acc: 0.6315\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9695\n",
      "Epoch 00025: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1099 - acc: 0.9695 - val_loss: 2.1764 - val_acc: 0.6389\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9688\n",
      "Epoch 00026: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1119 - acc: 0.9688 - val_loss: 2.1951 - val_acc: 0.6313\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9704\n",
      "Epoch 00027: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1059 - acc: 0.9704 - val_loss: 2.2688 - val_acc: 0.6392\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9728\n",
      "Epoch 00028: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.0980 - acc: 0.9728 - val_loss: 2.2685 - val_acc: 0.6299\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9727\n",
      "Epoch 00029: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.0994 - acc: 0.9727 - val_loss: 2.3323 - val_acc: 0.6306\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9727\n",
      "Epoch 00030: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1001 - acc: 0.9727 - val_loss: 2.2387 - val_acc: 0.6380\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0903 - acc: 0.9753\n",
      "Epoch 00031: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.0903 - acc: 0.9753 - val_loss: 2.2655 - val_acc: 0.6387\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9738\n",
      "Epoch 00032: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.0934 - acc: 0.9738 - val_loss: 2.2829 - val_acc: 0.6352\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9756\n",
      "Epoch 00033: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0935 - acc: 0.9756 - val_loss: 2.2754 - val_acc: 0.6327\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9789\n",
      "Epoch 00034: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0813 - acc: 0.9789 - val_loss: 2.3246 - val_acc: 0.6462\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9788\n",
      "Epoch 00035: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0813 - acc: 0.9788 - val_loss: 2.2845 - val_acc: 0.6403\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9796\n",
      "Epoch 00036: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0774 - acc: 0.9796 - val_loss: 2.3795 - val_acc: 0.6422\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9811\n",
      "Epoch 00037: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0758 - acc: 0.9811 - val_loss: 2.4350 - val_acc: 0.6355\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9799\n",
      "Epoch 00038: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0768 - acc: 0.9799 - val_loss: 2.3331 - val_acc: 0.6473\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9812\n",
      "Epoch 00039: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0749 - acc: 0.9812 - val_loss: 2.3600 - val_acc: 0.6445\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9819\n",
      "Epoch 00040: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0744 - acc: 0.9819 - val_loss: 2.3503 - val_acc: 0.6504\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9826\n",
      "Epoch 00041: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0703 - acc: 0.9826 - val_loss: 2.3882 - val_acc: 0.6485\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9829\n",
      "Epoch 00042: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0688 - acc: 0.9829 - val_loss: 2.4675 - val_acc: 0.6396\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9816\n",
      "Epoch 00043: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0717 - acc: 0.9816 - val_loss: 2.3492 - val_acc: 0.6573\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9839\n",
      "Epoch 00044: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0651 - acc: 0.9839 - val_loss: 2.4153 - val_acc: 0.6518\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9819\n",
      "Epoch 00045: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0713 - acc: 0.9819 - val_loss: 2.3661 - val_acc: 0.6487\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9848\n",
      "Epoch 00046: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0629 - acc: 0.9848 - val_loss: 2.4336 - val_acc: 0.6513\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9836\n",
      "Epoch 00047: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0664 - acc: 0.9836 - val_loss: 2.4262 - val_acc: 0.6536\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9842\n",
      "Epoch 00048: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0654 - acc: 0.9842 - val_loss: 2.3737 - val_acc: 0.6445\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9848\n",
      "Epoch 00049: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0627 - acc: 0.9848 - val_loss: 2.4012 - val_acc: 0.6443\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9862\n",
      "Epoch 00050: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0593 - acc: 0.9862 - val_loss: 2.4073 - val_acc: 0.6476\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9857\n",
      "Epoch 00051: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0594 - acc: 0.9857 - val_loss: 2.4277 - val_acc: 0.6401\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9864\n",
      "Epoch 00052: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0570 - acc: 0.9864 - val_loss: 2.4549 - val_acc: 0.6518\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9868\n",
      "Epoch 00053: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0569 - acc: 0.9868 - val_loss: 2.4694 - val_acc: 0.6403\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9875\n",
      "Epoch 00054: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0540 - acc: 0.9875 - val_loss: 2.3929 - val_acc: 0.6518\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9857\n",
      "Epoch 00055: val_loss did not improve from 1.34323\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0602 - acc: 0.9857 - val_loss: 2.4714 - val_acc: 0.6504\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.4214 - acc: 0.5601\n",
      "Loss: 1.4213561559639492 Accuracy: 0.56012464\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2021 - acc: 0.2880\n",
      "Epoch 00001: val_loss improved from inf to 1.66184, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/001-1.6618.hdf5\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 2.2020 - acc: 0.2880 - val_loss: 1.6618 - val_acc: 0.4587\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5305 - acc: 0.5098\n",
      "Epoch 00002: val_loss improved from 1.66184 to 1.40126, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/002-1.4013.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.5305 - acc: 0.5098 - val_loss: 1.4013 - val_acc: 0.5458\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2942 - acc: 0.5967\n",
      "Epoch 00003: val_loss improved from 1.40126 to 1.26357, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/003-1.2636.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.2941 - acc: 0.5967 - val_loss: 1.2636 - val_acc: 0.6019\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1248 - acc: 0.6551\n",
      "Epoch 00004: val_loss improved from 1.26357 to 1.12616, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/004-1.1262.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.1248 - acc: 0.6551 - val_loss: 1.1262 - val_acc: 0.6466\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9861 - acc: 0.6970\n",
      "Epoch 00005: val_loss improved from 1.12616 to 1.07897, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/005-1.0790.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.9861 - acc: 0.6970 - val_loss: 1.0790 - val_acc: 0.6625\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8702 - acc: 0.7342\n",
      "Epoch 00006: val_loss improved from 1.07897 to 1.03327, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/006-1.0333.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.8702 - acc: 0.7342 - val_loss: 1.0333 - val_acc: 0.6823\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7679 - acc: 0.7656\n",
      "Epoch 00007: val_loss improved from 1.03327 to 1.02571, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_4_conv_checkpoint/007-1.0257.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.7678 - acc: 0.7656 - val_loss: 1.0257 - val_acc: 0.6888\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6774 - acc: 0.7905\n",
      "Epoch 00008: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6776 - acc: 0.7905 - val_loss: 1.1307 - val_acc: 0.6527\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.8124\n",
      "Epoch 00009: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6031 - acc: 0.8123 - val_loss: 1.1546 - val_acc: 0.6711\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5304 - acc: 0.8358\n",
      "Epoch 00010: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5304 - acc: 0.8358 - val_loss: 1.0526 - val_acc: 0.6874\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8553\n",
      "Epoch 00011: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4590 - acc: 0.8553 - val_loss: 1.0723 - val_acc: 0.7065\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4147 - acc: 0.8686\n",
      "Epoch 00012: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4147 - acc: 0.8686 - val_loss: 1.0642 - val_acc: 0.7081\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3749 - acc: 0.8783\n",
      "Epoch 00013: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3749 - acc: 0.8783 - val_loss: 1.0883 - val_acc: 0.7123\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3283 - acc: 0.8943\n",
      "Epoch 00014: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3283 - acc: 0.8943 - val_loss: 1.1626 - val_acc: 0.7070\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3010 - acc: 0.9036\n",
      "Epoch 00015: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3010 - acc: 0.9036 - val_loss: 1.3173 - val_acc: 0.6709\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2800 - acc: 0.9092\n",
      "Epoch 00016: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2800 - acc: 0.9091 - val_loss: 1.1780 - val_acc: 0.7109\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2542 - acc: 0.9182\n",
      "Epoch 00017: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2543 - acc: 0.9182 - val_loss: 1.1326 - val_acc: 0.7256\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2415 - acc: 0.9200\n",
      "Epoch 00018: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2415 - acc: 0.9200 - val_loss: 1.2814 - val_acc: 0.7123\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2205 - acc: 0.9275\n",
      "Epoch 00019: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2204 - acc: 0.9275 - val_loss: 1.2101 - val_acc: 0.7240\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9310\n",
      "Epoch 00020: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2061 - acc: 0.9310 - val_loss: 1.2792 - val_acc: 0.7270\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1955 - acc: 0.9351\n",
      "Epoch 00021: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1956 - acc: 0.9350 - val_loss: 1.2348 - val_acc: 0.7221\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1878 - acc: 0.9388\n",
      "Epoch 00022: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1878 - acc: 0.9388 - val_loss: 1.2494 - val_acc: 0.7256\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1745 - acc: 0.9431\n",
      "Epoch 00023: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1745 - acc: 0.9431 - val_loss: 1.3156 - val_acc: 0.7156\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1697 - acc: 0.9443\n",
      "Epoch 00024: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1697 - acc: 0.9443 - val_loss: 1.3292 - val_acc: 0.7214\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1553 - acc: 0.9509\n",
      "Epoch 00025: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1553 - acc: 0.9509 - val_loss: 1.3597 - val_acc: 0.7284\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9516\n",
      "Epoch 00026: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1509 - acc: 0.9516 - val_loss: 1.3432 - val_acc: 0.7237\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9527\n",
      "Epoch 00027: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1454 - acc: 0.9528 - val_loss: 1.3346 - val_acc: 0.7286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9533\n",
      "Epoch 00028: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1453 - acc: 0.9533 - val_loss: 1.3294 - val_acc: 0.7407\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9556\n",
      "Epoch 00029: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1386 - acc: 0.9556 - val_loss: 1.2950 - val_acc: 0.7386\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9569\n",
      "Epoch 00030: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1341 - acc: 0.9569 - val_loss: 1.2648 - val_acc: 0.7317\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9587\n",
      "Epoch 00031: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1271 - acc: 0.9587 - val_loss: 1.4012 - val_acc: 0.7345\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9589\n",
      "Epoch 00032: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1266 - acc: 0.9589 - val_loss: 1.3627 - val_acc: 0.7326\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9616\n",
      "Epoch 00033: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1187 - acc: 0.9616 - val_loss: 1.3582 - val_acc: 0.7331\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9631\n",
      "Epoch 00034: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1175 - acc: 0.9631 - val_loss: 1.3848 - val_acc: 0.7358\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9624\n",
      "Epoch 00035: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1186 - acc: 0.9624 - val_loss: 1.3155 - val_acc: 0.7421\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9662\n",
      "Epoch 00036: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1085 - acc: 0.9662 - val_loss: 1.4454 - val_acc: 0.7361\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9627\n",
      "Epoch 00037: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1148 - acc: 0.9627 - val_loss: 1.3080 - val_acc: 0.7496\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9672\n",
      "Epoch 00038: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1084 - acc: 0.9672 - val_loss: 1.3789 - val_acc: 0.7461\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9660\n",
      "Epoch 00039: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1098 - acc: 0.9660 - val_loss: 1.3974 - val_acc: 0.7349\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9678\n",
      "Epoch 00040: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1044 - acc: 0.9678 - val_loss: 1.3619 - val_acc: 0.7377\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9687\n",
      "Epoch 00041: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0988 - acc: 0.9687 - val_loss: 1.3855 - val_acc: 0.7468\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9707\n",
      "Epoch 00042: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0956 - acc: 0.9707 - val_loss: 1.4152 - val_acc: 0.7414\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9708\n",
      "Epoch 00043: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0961 - acc: 0.9708 - val_loss: 1.3119 - val_acc: 0.7494\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9694\n",
      "Epoch 00044: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0969 - acc: 0.9694 - val_loss: 1.4430 - val_acc: 0.7454\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9710\n",
      "Epoch 00045: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0898 - acc: 0.9710 - val_loss: 1.4389 - val_acc: 0.7424\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9698\n",
      "Epoch 00046: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0926 - acc: 0.9698 - val_loss: 1.3114 - val_acc: 0.7582\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9728\n",
      "Epoch 00047: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0882 - acc: 0.9728 - val_loss: 1.3669 - val_acc: 0.7575\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9733\n",
      "Epoch 00048: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0872 - acc: 0.9733 - val_loss: 1.4060 - val_acc: 0.7519\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9741\n",
      "Epoch 00049: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0837 - acc: 0.9741 - val_loss: 1.3734 - val_acc: 0.7533\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9742\n",
      "Epoch 00050: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0828 - acc: 0.9742 - val_loss: 1.4686 - val_acc: 0.7519\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9744\n",
      "Epoch 00051: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0873 - acc: 0.9744 - val_loss: 1.4073 - val_acc: 0.7536\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9747\n",
      "Epoch 00052: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0807 - acc: 0.9747 - val_loss: 1.3895 - val_acc: 0.7636\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9752\n",
      "Epoch 00053: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0784 - acc: 0.9752 - val_loss: 1.4002 - val_acc: 0.7536\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9761\n",
      "Epoch 00054: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0770 - acc: 0.9761 - val_loss: 1.4265 - val_acc: 0.7643\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9754\n",
      "Epoch 00055: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0797 - acc: 0.9754 - val_loss: 1.4066 - val_acc: 0.7552\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9758\n",
      "Epoch 00056: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0806 - acc: 0.9758 - val_loss: 1.3826 - val_acc: 0.7503\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9750\n",
      "Epoch 00057: val_loss did not improve from 1.02571\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0794 - acc: 0.9750 - val_loss: 1.3401 - val_acc: 0.7540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.0469 - acc: 0.6789\n",
      "Loss: 1.0469354746745259 Accuracy: 0.67892003\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1671 - acc: 0.2973\n",
      "Epoch 00001: val_loss improved from inf to 1.50455, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/001-1.5046.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 2.1670 - acc: 0.2974 - val_loss: 1.5046 - val_acc: 0.5178\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4633 - acc: 0.5282\n",
      "Epoch 00002: val_loss improved from 1.50455 to 1.26951, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/002-1.2695.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.4632 - acc: 0.5282 - val_loss: 1.2695 - val_acc: 0.5996\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2802 - acc: 0.5952\n",
      "Epoch 00003: val_loss improved from 1.26951 to 1.17523, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/003-1.1752.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.2801 - acc: 0.5953 - val_loss: 1.1752 - val_acc: 0.6373\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1417 - acc: 0.6468\n",
      "Epoch 00004: val_loss improved from 1.17523 to 1.06349, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/004-1.0635.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.1417 - acc: 0.6468 - val_loss: 1.0635 - val_acc: 0.6723\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0145 - acc: 0.6887\n",
      "Epoch 00005: val_loss did not improve from 1.06349\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.0146 - acc: 0.6887 - val_loss: 1.0844 - val_acc: 0.6564\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9222 - acc: 0.7173\n",
      "Epoch 00006: val_loss improved from 1.06349 to 0.89751, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/006-0.8975.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.9222 - acc: 0.7173 - val_loss: 0.8975 - val_acc: 0.7235\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8288 - acc: 0.7456\n",
      "Epoch 00007: val_loss improved from 0.89751 to 0.86133, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/007-0.8613.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.8288 - acc: 0.7456 - val_loss: 0.8613 - val_acc: 0.7449\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7505 - acc: 0.7715\n",
      "Epoch 00008: val_loss improved from 0.86133 to 0.79196, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/008-0.7920.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.7507 - acc: 0.7714 - val_loss: 0.7920 - val_acc: 0.7633\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6814 - acc: 0.7936\n",
      "Epoch 00009: val_loss did not improve from 0.79196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6813 - acc: 0.7936 - val_loss: 0.7926 - val_acc: 0.7680\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6198 - acc: 0.8102\n",
      "Epoch 00010: val_loss improved from 0.79196 to 0.75932, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/010-0.7593.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6197 - acc: 0.8102 - val_loss: 0.7593 - val_acc: 0.7792\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5667 - acc: 0.8274\n",
      "Epoch 00011: val_loss improved from 0.75932 to 0.74783, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/011-0.7478.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5666 - acc: 0.8274 - val_loss: 0.7478 - val_acc: 0.7743\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5249 - acc: 0.8386\n",
      "Epoch 00012: val_loss did not improve from 0.74783\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5250 - acc: 0.8386 - val_loss: 0.7506 - val_acc: 0.7815\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4816 - acc: 0.8513\n",
      "Epoch 00013: val_loss improved from 0.74783 to 0.71345, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/013-0.7134.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4815 - acc: 0.8513 - val_loss: 0.7134 - val_acc: 0.7934\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4367 - acc: 0.8661\n",
      "Epoch 00014: val_loss improved from 0.71345 to 0.70585, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_5_conv_checkpoint/014-0.7058.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4366 - acc: 0.8661 - val_loss: 0.7058 - val_acc: 0.8062\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3972 - acc: 0.8768\n",
      "Epoch 00015: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3972 - acc: 0.8768 - val_loss: 0.7378 - val_acc: 0.7922\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3680 - acc: 0.8851\n",
      "Epoch 00016: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3679 - acc: 0.8851 - val_loss: 0.7851 - val_acc: 0.7869\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3357 - acc: 0.8944\n",
      "Epoch 00017: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3358 - acc: 0.8944 - val_loss: 0.8267 - val_acc: 0.7857\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3147 - acc: 0.8998\n",
      "Epoch 00018: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3147 - acc: 0.8998 - val_loss: 0.7502 - val_acc: 0.8004\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2842 - acc: 0.9092\n",
      "Epoch 00019: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2842 - acc: 0.9092 - val_loss: 0.8014 - val_acc: 0.7883\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2588 - acc: 0.9168\n",
      "Epoch 00020: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2588 - acc: 0.9168 - val_loss: 0.7546 - val_acc: 0.8083\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2405 - acc: 0.9226\n",
      "Epoch 00021: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2405 - acc: 0.9226 - val_loss: 0.8278 - val_acc: 0.7978\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2319 - acc: 0.9241\n",
      "Epoch 00022: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2319 - acc: 0.9241 - val_loss: 0.7631 - val_acc: 0.8076\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9329\n",
      "Epoch 00023: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2110 - acc: 0.9328 - val_loss: 0.8590 - val_acc: 0.8006\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9324\n",
      "Epoch 00024: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2073 - acc: 0.9323 - val_loss: 0.8059 - val_acc: 0.7985\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1909 - acc: 0.9373\n",
      "Epoch 00025: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1908 - acc: 0.9373 - val_loss: 0.8146 - val_acc: 0.8036\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1771 - acc: 0.9426\n",
      "Epoch 00026: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1771 - acc: 0.9425 - val_loss: 0.8823 - val_acc: 0.8069\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1685 - acc: 0.9462\n",
      "Epoch 00027: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1685 - acc: 0.9462 - val_loss: 0.8759 - val_acc: 0.8057\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9457\n",
      "Epoch 00028: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1700 - acc: 0.9457 - val_loss: 0.9629 - val_acc: 0.7997\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1824 - acc: 0.9440\n",
      "Epoch 00029: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1824 - acc: 0.9440 - val_loss: 0.8256 - val_acc: 0.8113\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1446 - acc: 0.9532\n",
      "Epoch 00030: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1446 - acc: 0.9532 - val_loss: 0.9097 - val_acc: 0.8120\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9542\n",
      "Epoch 00031: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1431 - acc: 0.9542 - val_loss: 0.8190 - val_acc: 0.8213\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9547\n",
      "Epoch 00032: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1444 - acc: 0.9547 - val_loss: 0.8870 - val_acc: 0.8183\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9593\n",
      "Epoch 00033: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1270 - acc: 0.9592 - val_loss: 0.9276 - val_acc: 0.8088\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9567\n",
      "Epoch 00034: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1357 - acc: 0.9567 - val_loss: 0.8730 - val_acc: 0.8125\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9616\n",
      "Epoch 00035: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1214 - acc: 0.9616 - val_loss: 0.9898 - val_acc: 0.8067\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9602\n",
      "Epoch 00036: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1251 - acc: 0.9602 - val_loss: 0.9145 - val_acc: 0.8162\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9609\n",
      "Epoch 00037: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1229 - acc: 0.9609 - val_loss: 0.8972 - val_acc: 0.8185\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9630\n",
      "Epoch 00038: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1152 - acc: 0.9630 - val_loss: 0.9456 - val_acc: 0.8195\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9631\n",
      "Epoch 00039: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1167 - acc: 0.9631 - val_loss: 0.8822 - val_acc: 0.8272\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9652\n",
      "Epoch 00040: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1104 - acc: 0.9652 - val_loss: 0.9274 - val_acc: 0.8225\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9676\n",
      "Epoch 00041: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1034 - acc: 0.9676 - val_loss: 0.9298 - val_acc: 0.8209\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9677\n",
      "Epoch 00042: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1049 - acc: 0.9676 - val_loss: 0.8636 - val_acc: 0.8260\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9677\n",
      "Epoch 00043: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1053 - acc: 0.9677 - val_loss: 0.8513 - val_acc: 0.8274\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9700\n",
      "Epoch 00044: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0976 - acc: 0.9700 - val_loss: 0.8567 - val_acc: 0.8253\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9678\n",
      "Epoch 00045: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1018 - acc: 0.9678 - val_loss: 0.8967 - val_acc: 0.8157\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9689\n",
      "Epoch 00046: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1015 - acc: 0.9689 - val_loss: 0.8981 - val_acc: 0.8204\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9725\n",
      "Epoch 00047: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0931 - acc: 0.9725 - val_loss: 0.8632 - val_acc: 0.8288\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9724\n",
      "Epoch 00048: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0890 - acc: 0.9724 - val_loss: 0.9415 - val_acc: 0.8220\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9730\n",
      "Epoch 00049: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0915 - acc: 0.9730 - val_loss: 0.8418 - val_acc: 0.8279\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9721\n",
      "Epoch 00050: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0876 - acc: 0.9722 - val_loss: 0.9715 - val_acc: 0.8237\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9726\n",
      "Epoch 00051: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0901 - acc: 0.9726 - val_loss: 0.8682 - val_acc: 0.8316\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9742\n",
      "Epoch 00052: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0844 - acc: 0.9742 - val_loss: 0.9373 - val_acc: 0.8286\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9755\n",
      "Epoch 00053: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0811 - acc: 0.9755 - val_loss: 0.9176 - val_acc: 0.8216\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9748\n",
      "Epoch 00054: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0808 - acc: 0.9748 - val_loss: 0.9344 - val_acc: 0.8311\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9746\n",
      "Epoch 00055: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0834 - acc: 0.9746 - val_loss: 0.9250 - val_acc: 0.8351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9767\n",
      "Epoch 00056: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0775 - acc: 0.9767 - val_loss: 0.9391 - val_acc: 0.8220\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9760\n",
      "Epoch 00057: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0772 - acc: 0.9760 - val_loss: 0.8722 - val_acc: 0.8290\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9779\n",
      "Epoch 00058: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0769 - acc: 0.9779 - val_loss: 0.9288 - val_acc: 0.8358\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9766\n",
      "Epoch 00059: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0788 - acc: 0.9766 - val_loss: 0.9523 - val_acc: 0.8176\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9787\n",
      "Epoch 00060: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0729 - acc: 0.9787 - val_loss: 0.9452 - val_acc: 0.8362\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9773\n",
      "Epoch 00061: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0766 - acc: 0.9773 - val_loss: 0.9360 - val_acc: 0.8307\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9776\n",
      "Epoch 00062: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0760 - acc: 0.9776 - val_loss: 0.9665 - val_acc: 0.8185\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9804\n",
      "Epoch 00063: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0682 - acc: 0.9804 - val_loss: 0.9344 - val_acc: 0.8400\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9790\n",
      "Epoch 00064: val_loss did not improve from 0.70585\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0726 - acc: 0.9791 - val_loss: 0.8913 - val_acc: 0.8328\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.8236 - acc: 0.7593\n",
      "Loss: 0.8235816266554044 Accuracy: 0.75929385\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3342 - acc: 0.2342\n",
      "Epoch 00001: val_loss improved from inf to 1.55340, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/001-1.5534.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 2.3342 - acc: 0.2342 - val_loss: 1.5534 - val_acc: 0.5045\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5459 - acc: 0.4944\n",
      "Epoch 00002: val_loss improved from 1.55340 to 1.31026, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/002-1.3103.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.5457 - acc: 0.4945 - val_loss: 1.3103 - val_acc: 0.5865\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3462 - acc: 0.5657\n",
      "Epoch 00003: val_loss improved from 1.31026 to 1.18550, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/003-1.1855.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.3461 - acc: 0.5658 - val_loss: 1.1855 - val_acc: 0.6441\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2260 - acc: 0.6070\n",
      "Epoch 00004: val_loss improved from 1.18550 to 1.12420, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/004-1.1242.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.2259 - acc: 0.6071 - val_loss: 1.1242 - val_acc: 0.6485\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1167 - acc: 0.6435\n",
      "Epoch 00005: val_loss improved from 1.12420 to 0.97052, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/005-0.9705.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.1167 - acc: 0.6436 - val_loss: 0.9705 - val_acc: 0.7014\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0074 - acc: 0.6835\n",
      "Epoch 00006: val_loss improved from 0.97052 to 0.86283, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/006-0.8628.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.0074 - acc: 0.6834 - val_loss: 0.8628 - val_acc: 0.7440\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9163 - acc: 0.7158\n",
      "Epoch 00007: val_loss improved from 0.86283 to 0.77015, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/007-0.7702.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9162 - acc: 0.7159 - val_loss: 0.7702 - val_acc: 0.7761\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8226 - acc: 0.7463\n",
      "Epoch 00008: val_loss improved from 0.77015 to 0.73292, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/008-0.7329.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8225 - acc: 0.7463 - val_loss: 0.7329 - val_acc: 0.7922\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7313 - acc: 0.7779\n",
      "Epoch 00009: val_loss improved from 0.73292 to 0.70283, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/009-0.7028.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7313 - acc: 0.7779 - val_loss: 0.7028 - val_acc: 0.7876\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6721 - acc: 0.7957\n",
      "Epoch 00010: val_loss improved from 0.70283 to 0.58742, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/010-0.5874.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6721 - acc: 0.7957 - val_loss: 0.5874 - val_acc: 0.8325\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6075 - acc: 0.8152\n",
      "Epoch 00011: val_loss improved from 0.58742 to 0.55406, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/011-0.5541.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6074 - acc: 0.8152 - val_loss: 0.5541 - val_acc: 0.8411\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5555 - acc: 0.8310\n",
      "Epoch 00012: val_loss improved from 0.55406 to 0.51696, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/012-0.5170.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5555 - acc: 0.8310 - val_loss: 0.5170 - val_acc: 0.8521\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5198 - acc: 0.8435\n",
      "Epoch 00013: val_loss improved from 0.51696 to 0.47366, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/013-0.4737.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5198 - acc: 0.8434 - val_loss: 0.4737 - val_acc: 0.8633\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4847 - acc: 0.8543\n",
      "Epoch 00014: val_loss did not improve from 0.47366\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4846 - acc: 0.8543 - val_loss: 0.4877 - val_acc: 0.8591\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4503 - acc: 0.8630\n",
      "Epoch 00015: val_loss improved from 0.47366 to 0.44400, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/015-0.4440.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4503 - acc: 0.8631 - val_loss: 0.4440 - val_acc: 0.8740\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4214 - acc: 0.8718\n",
      "Epoch 00016: val_loss improved from 0.44400 to 0.42352, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/016-0.4235.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4214 - acc: 0.8718 - val_loss: 0.4235 - val_acc: 0.8777\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3917 - acc: 0.8829\n",
      "Epoch 00017: val_loss improved from 0.42352 to 0.42068, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/017-0.4207.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3917 - acc: 0.8829 - val_loss: 0.4207 - val_acc: 0.8779\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3668 - acc: 0.8883\n",
      "Epoch 00018: val_loss improved from 0.42068 to 0.39280, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/018-0.3928.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3668 - acc: 0.8883 - val_loss: 0.3928 - val_acc: 0.8903\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3499 - acc: 0.8932\n",
      "Epoch 00019: val_loss did not improve from 0.39280\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3499 - acc: 0.8932 - val_loss: 0.3932 - val_acc: 0.8933\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3329 - acc: 0.8981\n",
      "Epoch 00020: val_loss improved from 0.39280 to 0.39133, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/020-0.3913.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3329 - acc: 0.8981 - val_loss: 0.3913 - val_acc: 0.8854\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3121 - acc: 0.9039\n",
      "Epoch 00021: val_loss improved from 0.39133 to 0.37165, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/021-0.3717.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3121 - acc: 0.9040 - val_loss: 0.3717 - val_acc: 0.8952\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2998 - acc: 0.9080\n",
      "Epoch 00022: val_loss did not improve from 0.37165\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2998 - acc: 0.9081 - val_loss: 0.3829 - val_acc: 0.8947\n",
      "Epoch 23/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2860 - acc: 0.9124\n",
      "Epoch 00023: val_loss improved from 0.37165 to 0.36082, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/023-0.3608.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2860 - acc: 0.9124 - val_loss: 0.3608 - val_acc: 0.9031\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2668 - acc: 0.9176\n",
      "Epoch 00024: val_loss did not improve from 0.36082\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2668 - acc: 0.9176 - val_loss: 0.3887 - val_acc: 0.8905\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2631 - acc: 0.9188\n",
      "Epoch 00025: val_loss improved from 0.36082 to 0.35653, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/025-0.3565.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2630 - acc: 0.9188 - val_loss: 0.3565 - val_acc: 0.9033\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.9224\n",
      "Epoch 00026: val_loss did not improve from 0.35653\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2470 - acc: 0.9224 - val_loss: 0.3625 - val_acc: 0.9068\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9263\n",
      "Epoch 00027: val_loss did not improve from 0.35653\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2362 - acc: 0.9263 - val_loss: 0.3638 - val_acc: 0.9054\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9286\n",
      "Epoch 00028: val_loss improved from 0.35653 to 0.35346, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/028-0.3535.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2252 - acc: 0.9285 - val_loss: 0.3535 - val_acc: 0.9015\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2219 - acc: 0.9299\n",
      "Epoch 00029: val_loss did not improve from 0.35346\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2219 - acc: 0.9298 - val_loss: 0.3638 - val_acc: 0.9082\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2070 - acc: 0.9352\n",
      "Epoch 00030: val_loss improved from 0.35346 to 0.34606, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/030-0.3461.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2069 - acc: 0.9352 - val_loss: 0.3461 - val_acc: 0.9066\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9372\n",
      "Epoch 00031: val_loss improved from 0.34606 to 0.34222, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/031-0.3422.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1919 - acc: 0.9372 - val_loss: 0.3422 - val_acc: 0.9150\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1938 - acc: 0.9383\n",
      "Epoch 00032: val_loss did not improve from 0.34222\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1938 - acc: 0.9383 - val_loss: 0.3475 - val_acc: 0.9124\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9423\n",
      "Epoch 00033: val_loss improved from 0.34222 to 0.33190, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/033-0.3319.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1829 - acc: 0.9423 - val_loss: 0.3319 - val_acc: 0.9122\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1784 - acc: 0.9427\n",
      "Epoch 00034: val_loss did not improve from 0.33190\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1784 - acc: 0.9427 - val_loss: 0.3512 - val_acc: 0.9106\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9427\n",
      "Epoch 00035: val_loss did not improve from 0.33190\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1756 - acc: 0.9427 - val_loss: 0.3604 - val_acc: 0.9115\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9476\n",
      "Epoch 00036: val_loss did not improve from 0.33190\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1607 - acc: 0.9476 - val_loss: 0.3604 - val_acc: 0.9157\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9507\n",
      "Epoch 00037: val_loss did not improve from 0.33190\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1517 - acc: 0.9507 - val_loss: 0.3669 - val_acc: 0.9145\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.9518\n",
      "Epoch 00038: val_loss did not improve from 0.33190\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1493 - acc: 0.9518 - val_loss: 0.4008 - val_acc: 0.9124\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9534\n",
      "Epoch 00039: val_loss did not improve from 0.33190\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1444 - acc: 0.9534 - val_loss: 0.3749 - val_acc: 0.9147\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9538\n",
      "Epoch 00040: val_loss did not improve from 0.33190\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1414 - acc: 0.9538 - val_loss: 0.3393 - val_acc: 0.9159\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9552\n",
      "Epoch 00041: val_loss improved from 0.33190 to 0.32392, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_6_conv_checkpoint/041-0.3239.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1371 - acc: 0.9552 - val_loss: 0.3239 - val_acc: 0.9185\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9561\n",
      "Epoch 00042: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1331 - acc: 0.9560 - val_loss: 0.3623 - val_acc: 0.9161\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9580\n",
      "Epoch 00043: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1290 - acc: 0.9580 - val_loss: 0.3468 - val_acc: 0.9154\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9589\n",
      "Epoch 00044: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1236 - acc: 0.9589 - val_loss: 0.3574 - val_acc: 0.9175\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9589\n",
      "Epoch 00045: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1263 - acc: 0.9589 - val_loss: 0.3418 - val_acc: 0.9154\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9629\n",
      "Epoch 00046: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1163 - acc: 0.9629 - val_loss: 0.3578 - val_acc: 0.9182\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9608\n",
      "Epoch 00047: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1200 - acc: 0.9608 - val_loss: 0.3609 - val_acc: 0.9057\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9639\n",
      "Epoch 00048: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1107 - acc: 0.9639 - val_loss: 0.3748 - val_acc: 0.9217\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9638\n",
      "Epoch 00049: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1117 - acc: 0.9638 - val_loss: 0.3738 - val_acc: 0.9222\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9668\n",
      "Epoch 00050: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1025 - acc: 0.9668 - val_loss: 0.3345 - val_acc: 0.9194\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9642\n",
      "Epoch 00051: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1064 - acc: 0.9642 - val_loss: 0.3431 - val_acc: 0.9259\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9680\n",
      "Epoch 00052: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0974 - acc: 0.9680 - val_loss: 0.3646 - val_acc: 0.9131\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9660\n",
      "Epoch 00053: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1051 - acc: 0.9660 - val_loss: 0.3349 - val_acc: 0.9210\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9692\n",
      "Epoch 00054: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0936 - acc: 0.9692 - val_loss: 0.3655 - val_acc: 0.9257\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9687\n",
      "Epoch 00055: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0922 - acc: 0.9687 - val_loss: 0.3702 - val_acc: 0.9147\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9694\n",
      "Epoch 00056: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0911 - acc: 0.9694 - val_loss: 0.3914 - val_acc: 0.9145\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9706\n",
      "Epoch 00057: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0911 - acc: 0.9706 - val_loss: 0.3431 - val_acc: 0.9199\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9700\n",
      "Epoch 00058: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0886 - acc: 0.9700 - val_loss: 0.3414 - val_acc: 0.9252\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9726\n",
      "Epoch 00059: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0831 - acc: 0.9726 - val_loss: 0.4191 - val_acc: 0.9175\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9719\n",
      "Epoch 00060: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0866 - acc: 0.9719 - val_loss: 0.3652 - val_acc: 0.9252\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9739\n",
      "Epoch 00061: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0829 - acc: 0.9739 - val_loss: 0.3895 - val_acc: 0.9131\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9726\n",
      "Epoch 00062: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0840 - acc: 0.9726 - val_loss: 0.3750 - val_acc: 0.9255\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9736\n",
      "Epoch 00063: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0813 - acc: 0.9736 - val_loss: 0.3642 - val_acc: 0.9243\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9748\n",
      "Epoch 00064: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0770 - acc: 0.9748 - val_loss: 0.4075 - val_acc: 0.9229\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9740\n",
      "Epoch 00065: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0798 - acc: 0.9740 - val_loss: 0.3708 - val_acc: 0.9220\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9735\n",
      "Epoch 00066: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0816 - acc: 0.9735 - val_loss: 0.3697 - val_acc: 0.9248\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9765\n",
      "Epoch 00067: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0707 - acc: 0.9765 - val_loss: 0.3943 - val_acc: 0.9213\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9765\n",
      "Epoch 00068: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0725 - acc: 0.9765 - val_loss: 0.3649 - val_acc: 0.9255\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9765\n",
      "Epoch 00069: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0725 - acc: 0.9765 - val_loss: 0.3893 - val_acc: 0.9210\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9791\n",
      "Epoch 00070: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0658 - acc: 0.9791 - val_loss: 0.3482 - val_acc: 0.9308\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9770\n",
      "Epoch 00071: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0692 - acc: 0.9770 - val_loss: 0.3665 - val_acc: 0.9297\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9747\n",
      "Epoch 00072: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0776 - acc: 0.9747 - val_loss: 0.3760 - val_acc: 0.9285\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9786\n",
      "Epoch 00073: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0661 - acc: 0.9786 - val_loss: 0.3982 - val_acc: 0.9241\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9775\n",
      "Epoch 00074: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0697 - acc: 0.9775 - val_loss: 0.3917 - val_acc: 0.9250\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9764\n",
      "Epoch 00075: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0716 - acc: 0.9764 - val_loss: 0.3590 - val_acc: 0.9220\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9787\n",
      "Epoch 00076: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0639 - acc: 0.9787 - val_loss: 0.3913 - val_acc: 0.9266\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9810\n",
      "Epoch 00077: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0593 - acc: 0.9809 - val_loss: 0.3677 - val_acc: 0.9234\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9792\n",
      "Epoch 00078: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0641 - acc: 0.9792 - val_loss: 0.3840 - val_acc: 0.9290\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9804\n",
      "Epoch 00079: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0614 - acc: 0.9804 - val_loss: 0.3826 - val_acc: 0.9297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9795\n",
      "Epoch 00080: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0641 - acc: 0.9795 - val_loss: 0.3833 - val_acc: 0.9234\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9799\n",
      "Epoch 00081: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0620 - acc: 0.9799 - val_loss: 0.3828 - val_acc: 0.9220\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9813\n",
      "Epoch 00082: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0585 - acc: 0.9813 - val_loss: 0.3678 - val_acc: 0.9308\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9809\n",
      "Epoch 00083: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0577 - acc: 0.9809 - val_loss: 0.3936 - val_acc: 0.9292\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9809\n",
      "Epoch 00084: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0594 - acc: 0.9809 - val_loss: 0.4065 - val_acc: 0.9250\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9817\n",
      "Epoch 00085: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0570 - acc: 0.9817 - val_loss: 0.3854 - val_acc: 0.9248\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9829\n",
      "Epoch 00086: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0518 - acc: 0.9829 - val_loss: 0.3842 - val_acc: 0.9280\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9809\n",
      "Epoch 00087: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0603 - acc: 0.9809 - val_loss: 0.3788 - val_acc: 0.9168\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9836\n",
      "Epoch 00088: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0542 - acc: 0.9836 - val_loss: 0.3798 - val_acc: 0.9236\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9827\n",
      "Epoch 00089: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0535 - acc: 0.9827 - val_loss: 0.3950 - val_acc: 0.9245\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9818\n",
      "Epoch 00090: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0565 - acc: 0.9818 - val_loss: 0.4376 - val_acc: 0.9201\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9830\n",
      "Epoch 00091: val_loss did not improve from 0.32392\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0521 - acc: 0.9830 - val_loss: 0.3946 - val_acc: 0.9311\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.3925 - acc: 0.8960\n",
      "Loss: 0.39251999248472946 Accuracy: 0.89595014\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5489 - acc: 0.1522\n",
      "Epoch 00001: val_loss improved from inf to 1.85002, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/001-1.8500.hdf5\n",
      "36805/36805 [==============================] - 129s 4ms/sample - loss: 2.5488 - acc: 0.1523 - val_loss: 1.8500 - val_acc: 0.3927\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6768 - acc: 0.4371\n",
      "Epoch 00002: val_loss improved from 1.85002 to 1.29071, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/002-1.2907.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.6769 - acc: 0.4371 - val_loss: 1.2907 - val_acc: 0.5959\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3252 - acc: 0.5616\n",
      "Epoch 00003: val_loss improved from 1.29071 to 1.15569, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/003-1.1557.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.3252 - acc: 0.5616 - val_loss: 1.1557 - val_acc: 0.6396\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1364 - acc: 0.6335\n",
      "Epoch 00004: val_loss improved from 1.15569 to 0.88521, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/004-0.8852.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.1363 - acc: 0.6335 - val_loss: 0.8852 - val_acc: 0.7310\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9631 - acc: 0.6912\n",
      "Epoch 00005: val_loss improved from 0.88521 to 0.77369, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/005-0.7737.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9630 - acc: 0.6912 - val_loss: 0.7737 - val_acc: 0.7568\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8399 - acc: 0.7340\n",
      "Epoch 00006: val_loss improved from 0.77369 to 0.69116, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/006-0.6912.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8399 - acc: 0.7340 - val_loss: 0.6912 - val_acc: 0.7934\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7435 - acc: 0.7646\n",
      "Epoch 00007: val_loss improved from 0.69116 to 0.55225, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/007-0.5523.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7434 - acc: 0.7646 - val_loss: 0.5523 - val_acc: 0.8409\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6532 - acc: 0.7950\n",
      "Epoch 00008: val_loss improved from 0.55225 to 0.49625, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/008-0.4962.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6531 - acc: 0.7950 - val_loss: 0.4962 - val_acc: 0.8598\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5884 - acc: 0.8140\n",
      "Epoch 00009: val_loss improved from 0.49625 to 0.43368, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/009-0.4337.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5884 - acc: 0.8140 - val_loss: 0.4337 - val_acc: 0.8693\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5364 - acc: 0.8314\n",
      "Epoch 00010: val_loss improved from 0.43368 to 0.42949, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/010-0.4295.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5364 - acc: 0.8314 - val_loss: 0.4295 - val_acc: 0.8689\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4915 - acc: 0.8474\n",
      "Epoch 00011: val_loss improved from 0.42949 to 0.36078, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/011-0.3608.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4914 - acc: 0.8474 - val_loss: 0.3608 - val_acc: 0.8896\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4518 - acc: 0.8593\n",
      "Epoch 00012: val_loss improved from 0.36078 to 0.33328, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/012-0.3333.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4518 - acc: 0.8593 - val_loss: 0.3333 - val_acc: 0.9036\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4148 - acc: 0.8710\n",
      "Epoch 00013: val_loss did not improve from 0.33328\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4149 - acc: 0.8709 - val_loss: 0.3434 - val_acc: 0.9031\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3877 - acc: 0.8792\n",
      "Epoch 00014: val_loss improved from 0.33328 to 0.30613, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/014-0.3061.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3877 - acc: 0.8792 - val_loss: 0.3061 - val_acc: 0.9143\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.8883\n",
      "Epoch 00015: val_loss did not improve from 0.30613\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3574 - acc: 0.8883 - val_loss: 0.3634 - val_acc: 0.8959\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3392 - acc: 0.8933\n",
      "Epoch 00016: val_loss improved from 0.30613 to 0.25553, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/016-0.2555.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3392 - acc: 0.8933 - val_loss: 0.2555 - val_acc: 0.9334\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3206 - acc: 0.8998\n",
      "Epoch 00017: val_loss improved from 0.25553 to 0.25225, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/017-0.2523.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3206 - acc: 0.8998 - val_loss: 0.2523 - val_acc: 0.9259\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2963 - acc: 0.9058\n",
      "Epoch 00018: val_loss improved from 0.25225 to 0.22698, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/018-0.2270.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2964 - acc: 0.9058 - val_loss: 0.2270 - val_acc: 0.9345\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2798 - acc: 0.9123\n",
      "Epoch 00019: val_loss did not improve from 0.22698\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2797 - acc: 0.9123 - val_loss: 0.2482 - val_acc: 0.9322\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2693 - acc: 0.9144\n",
      "Epoch 00020: val_loss improved from 0.22698 to 0.22326, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/020-0.2233.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2693 - acc: 0.9144 - val_loss: 0.2233 - val_acc: 0.9378\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.9212\n",
      "Epoch 00021: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2470 - acc: 0.9212 - val_loss: 0.2633 - val_acc: 0.9241\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2420 - acc: 0.9242\n",
      "Epoch 00022: val_loss improved from 0.22326 to 0.20020, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/022-0.2002.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2420 - acc: 0.9242 - val_loss: 0.2002 - val_acc: 0.9436\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2311 - acc: 0.9265\n",
      "Epoch 00023: val_loss did not improve from 0.20020\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2312 - acc: 0.9265 - val_loss: 0.2135 - val_acc: 0.9371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2258 - acc: 0.9294\n",
      "Epoch 00024: val_loss did not improve from 0.20020\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2257 - acc: 0.9294 - val_loss: 0.2070 - val_acc: 0.9462\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9346\n",
      "Epoch 00025: val_loss improved from 0.20020 to 0.20003, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/025-0.2000.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2077 - acc: 0.9345 - val_loss: 0.2000 - val_acc: 0.9413\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2089 - acc: 0.9339\n",
      "Epoch 00026: val_loss improved from 0.20003 to 0.18642, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/026-0.1864.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2089 - acc: 0.9339 - val_loss: 0.1864 - val_acc: 0.9471\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1943 - acc: 0.9384\n",
      "Epoch 00027: val_loss did not improve from 0.18642\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1943 - acc: 0.9384 - val_loss: 0.2018 - val_acc: 0.9455\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1904 - acc: 0.9400\n",
      "Epoch 00028: val_loss improved from 0.18642 to 0.18020, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/028-0.1802.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1904 - acc: 0.9400 - val_loss: 0.1802 - val_acc: 0.9448\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1814 - acc: 0.9423\n",
      "Epoch 00029: val_loss did not improve from 0.18020\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1813 - acc: 0.9423 - val_loss: 0.2054 - val_acc: 0.9429\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1777 - acc: 0.9426\n",
      "Epoch 00030: val_loss improved from 0.18020 to 0.17817, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/030-0.1782.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1777 - acc: 0.9426 - val_loss: 0.1782 - val_acc: 0.9504\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9443\n",
      "Epoch 00031: val_loss improved from 0.17817 to 0.17761, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/031-0.1776.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1694 - acc: 0.9443 - val_loss: 0.1776 - val_acc: 0.9504\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9466\n",
      "Epoch 00032: val_loss did not improve from 0.17761\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1682 - acc: 0.9466 - val_loss: 0.1889 - val_acc: 0.9478\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9504\n",
      "Epoch 00033: val_loss did not improve from 0.17761\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1548 - acc: 0.9504 - val_loss: 0.1781 - val_acc: 0.9511\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1531 - acc: 0.9501\n",
      "Epoch 00034: val_loss improved from 0.17761 to 0.17220, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/034-0.1722.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1530 - acc: 0.9501 - val_loss: 0.1722 - val_acc: 0.9485\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9509\n",
      "Epoch 00035: val_loss improved from 0.17220 to 0.16929, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/035-0.1693.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1508 - acc: 0.9509 - val_loss: 0.1693 - val_acc: 0.9562\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9509\n",
      "Epoch 00036: val_loss did not improve from 0.16929\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1473 - acc: 0.9509 - val_loss: 0.1735 - val_acc: 0.9522\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9543\n",
      "Epoch 00037: val_loss did not improve from 0.16929\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1381 - acc: 0.9544 - val_loss: 0.1769 - val_acc: 0.9499\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9547\n",
      "Epoch 00038: val_loss improved from 0.16929 to 0.15976, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/038-0.1598.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1376 - acc: 0.9547 - val_loss: 0.1598 - val_acc: 0.9560\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9563\n",
      "Epoch 00039: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1341 - acc: 0.9563 - val_loss: 0.1796 - val_acc: 0.9502\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9574\n",
      "Epoch 00040: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1309 - acc: 0.9575 - val_loss: 0.1774 - val_acc: 0.9488\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9592\n",
      "Epoch 00041: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1230 - acc: 0.9592 - val_loss: 0.1709 - val_acc: 0.9536\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9595\n",
      "Epoch 00042: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1210 - acc: 0.9594 - val_loss: 0.1734 - val_acc: 0.9515\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9601\n",
      "Epoch 00043: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1221 - acc: 0.9601 - val_loss: 0.2151 - val_acc: 0.9378\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9611\n",
      "Epoch 00044: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1156 - acc: 0.9611 - val_loss: 0.1823 - val_acc: 0.9518\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9627\n",
      "Epoch 00045: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1124 - acc: 0.9627 - val_loss: 0.1685 - val_acc: 0.9532\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9646\n",
      "Epoch 00046: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1070 - acc: 0.9646 - val_loss: 0.1809 - val_acc: 0.9532\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9626\n",
      "Epoch 00047: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1102 - acc: 0.9626 - val_loss: 0.1756 - val_acc: 0.9553\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9661\n",
      "Epoch 00048: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1020 - acc: 0.9661 - val_loss: 0.2073 - val_acc: 0.9511\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9658\n",
      "Epoch 00049: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1013 - acc: 0.9658 - val_loss: 0.1759 - val_acc: 0.9532\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9679\n",
      "Epoch 00050: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0963 - acc: 0.9679 - val_loss: 0.1894 - val_acc: 0.9543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9683\n",
      "Epoch 00051: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0953 - acc: 0.9683 - val_loss: 0.1749 - val_acc: 0.9578\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9685\n",
      "Epoch 00052: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0960 - acc: 0.9685 - val_loss: 0.2084 - val_acc: 0.9457\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9702\n",
      "Epoch 00053: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0897 - acc: 0.9702 - val_loss: 0.1708 - val_acc: 0.9590\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9706\n",
      "Epoch 00054: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0896 - acc: 0.9706 - val_loss: 0.1664 - val_acc: 0.9569\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9717\n",
      "Epoch 00055: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0841 - acc: 0.9717 - val_loss: 0.1915 - val_acc: 0.9557\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9708\n",
      "Epoch 00056: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0868 - acc: 0.9708 - val_loss: 0.1665 - val_acc: 0.9606\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9731\n",
      "Epoch 00057: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0799 - acc: 0.9731 - val_loss: 0.1826 - val_acc: 0.9557\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9720\n",
      "Epoch 00058: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0799 - acc: 0.9720 - val_loss: 0.1790 - val_acc: 0.9583\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9725\n",
      "Epoch 00059: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0814 - acc: 0.9725 - val_loss: 0.1634 - val_acc: 0.9562\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9746\n",
      "Epoch 00060: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0745 - acc: 0.9747 - val_loss: 0.1946 - val_acc: 0.9571\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9731\n",
      "Epoch 00061: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0781 - acc: 0.9731 - val_loss: 0.1717 - val_acc: 0.9564\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9750\n",
      "Epoch 00062: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0741 - acc: 0.9750 - val_loss: 0.1864 - val_acc: 0.9543\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9762\n",
      "Epoch 00063: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0721 - acc: 0.9762 - val_loss: 0.1846 - val_acc: 0.9592\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9760\n",
      "Epoch 00064: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0739 - acc: 0.9760 - val_loss: 0.1761 - val_acc: 0.9599\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9762\n",
      "Epoch 00065: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0685 - acc: 0.9763 - val_loss: 0.2006 - val_acc: 0.9557\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9766\n",
      "Epoch 00066: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0689 - acc: 0.9766 - val_loss: 0.1738 - val_acc: 0.9606\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9757\n",
      "Epoch 00067: val_loss did not improve from 0.15976\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0689 - acc: 0.9757 - val_loss: 0.1894 - val_acc: 0.9585\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9767\n",
      "Epoch 00068: val_loss improved from 0.15976 to 0.15847, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_7_conv_checkpoint/068-0.1585.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0683 - acc: 0.9767 - val_loss: 0.1585 - val_acc: 0.9630\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9769\n",
      "Epoch 00069: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0688 - acc: 0.9769 - val_loss: 0.1809 - val_acc: 0.9609\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9767\n",
      "Epoch 00070: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0695 - acc: 0.9767 - val_loss: 0.1928 - val_acc: 0.9560\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9794\n",
      "Epoch 00071: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0636 - acc: 0.9794 - val_loss: 0.1815 - val_acc: 0.9604\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9790\n",
      "Epoch 00072: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0601 - acc: 0.9791 - val_loss: 0.1896 - val_acc: 0.9583\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9788\n",
      "Epoch 00073: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0616 - acc: 0.9788 - val_loss: 0.1864 - val_acc: 0.9627\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9789\n",
      "Epoch 00074: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0611 - acc: 0.9789 - val_loss: 0.1827 - val_acc: 0.9609\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9802\n",
      "Epoch 00075: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0596 - acc: 0.9802 - val_loss: 0.1915 - val_acc: 0.9513\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9804\n",
      "Epoch 00076: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0580 - acc: 0.9804 - val_loss: 0.1645 - val_acc: 0.9602\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9808\n",
      "Epoch 00077: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0569 - acc: 0.9808 - val_loss: 0.2052 - val_acc: 0.9539\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9814\n",
      "Epoch 00078: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0542 - acc: 0.9814 - val_loss: 0.1928 - val_acc: 0.9611\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9805\n",
      "Epoch 00079: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0563 - acc: 0.9805 - val_loss: 0.1952 - val_acc: 0.9606\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9824\n",
      "Epoch 00080: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0522 - acc: 0.9824 - val_loss: 0.1921 - val_acc: 0.9576\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9810\n",
      "Epoch 00081: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0544 - acc: 0.9810 - val_loss: 0.1839 - val_acc: 0.9639\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9827\n",
      "Epoch 00082: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0509 - acc: 0.9827 - val_loss: 0.1743 - val_acc: 0.9604\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9830\n",
      "Epoch 00083: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0494 - acc: 0.9830 - val_loss: 0.2013 - val_acc: 0.9583\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9822\n",
      "Epoch 00084: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0524 - acc: 0.9822 - val_loss: 0.1841 - val_acc: 0.9609\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9826\n",
      "Epoch 00085: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0511 - acc: 0.9826 - val_loss: 0.1978 - val_acc: 0.9550\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9841\n",
      "Epoch 00086: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0475 - acc: 0.9841 - val_loss: 0.2039 - val_acc: 0.9576\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9828\n",
      "Epoch 00087: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0497 - acc: 0.9828 - val_loss: 0.1672 - val_acc: 0.9627\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9837\n",
      "Epoch 00088: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0497 - acc: 0.9837 - val_loss: 0.1910 - val_acc: 0.9590\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9846\n",
      "Epoch 00089: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0468 - acc: 0.9846 - val_loss: 0.1827 - val_acc: 0.9627\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9843\n",
      "Epoch 00090: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0472 - acc: 0.9843 - val_loss: 0.2070 - val_acc: 0.9611\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9843\n",
      "Epoch 00091: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0452 - acc: 0.9843 - val_loss: 0.1754 - val_acc: 0.9597\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9856\n",
      "Epoch 00092: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0420 - acc: 0.9856 - val_loss: 0.1982 - val_acc: 0.9599\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9858\n",
      "Epoch 00093: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0444 - acc: 0.9858 - val_loss: 0.1853 - val_acc: 0.9630\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9863\n",
      "Epoch 00094: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0411 - acc: 0.9863 - val_loss: 0.1934 - val_acc: 0.9627\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9849\n",
      "Epoch 00095: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0456 - acc: 0.9849 - val_loss: 0.2052 - val_acc: 0.9632\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9857\n",
      "Epoch 00096: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0424 - acc: 0.9857 - val_loss: 0.1836 - val_acc: 0.9609\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9869\n",
      "Epoch 00097: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0394 - acc: 0.9869 - val_loss: 0.1955 - val_acc: 0.9578\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9867\n",
      "Epoch 00098: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0381 - acc: 0.9867 - val_loss: 0.2217 - val_acc: 0.9599\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9851\n",
      "Epoch 00099: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0451 - acc: 0.9851 - val_loss: 0.1871 - val_acc: 0.9623\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9873\n",
      "Epoch 00100: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0386 - acc: 0.9873 - val_loss: 0.2036 - val_acc: 0.9625\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9866\n",
      "Epoch 00101: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0398 - acc: 0.9866 - val_loss: 0.1983 - val_acc: 0.9595\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9860\n",
      "Epoch 00102: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0405 - acc: 0.9860 - val_loss: 0.1850 - val_acc: 0.9625\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9873\n",
      "Epoch 00103: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0373 - acc: 0.9873 - val_loss: 0.1948 - val_acc: 0.9623\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9861\n",
      "Epoch 00104: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0401 - acc: 0.9861 - val_loss: 0.2206 - val_acc: 0.9609\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9881\n",
      "Epoch 00105: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0377 - acc: 0.9880 - val_loss: 0.2011 - val_acc: 0.9585\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9882\n",
      "Epoch 00106: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0355 - acc: 0.9882 - val_loss: 0.1935 - val_acc: 0.9660\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9877\n",
      "Epoch 00107: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0382 - acc: 0.9877 - val_loss: 0.1874 - val_acc: 0.9611\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9892\n",
      "Epoch 00108: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0336 - acc: 0.9892 - val_loss: 0.2154 - val_acc: 0.9602\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9881\n",
      "Epoch 00109: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0364 - acc: 0.9881 - val_loss: 0.2199 - val_acc: 0.9581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9883\n",
      "Epoch 00110: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0356 - acc: 0.9883 - val_loss: 0.2132 - val_acc: 0.9578\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9890\n",
      "Epoch 00111: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0348 - acc: 0.9890 - val_loss: 0.2076 - val_acc: 0.9625\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9885\n",
      "Epoch 00112: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0349 - acc: 0.9885 - val_loss: 0.2034 - val_acc: 0.9604\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9882\n",
      "Epoch 00113: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0361 - acc: 0.9882 - val_loss: 0.1994 - val_acc: 0.9604\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9895\n",
      "Epoch 00114: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0327 - acc: 0.9895 - val_loss: 0.1915 - val_acc: 0.9623\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9899\n",
      "Epoch 00115: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0309 - acc: 0.9899 - val_loss: 0.1972 - val_acc: 0.9625\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9889\n",
      "Epoch 00116: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0326 - acc: 0.9889 - val_loss: 0.2001 - val_acc: 0.9599\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9887\n",
      "Epoch 00117: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0340 - acc: 0.9887 - val_loss: 0.2115 - val_acc: 0.9602\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9896\n",
      "Epoch 00118: val_loss did not improve from 0.15847\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0306 - acc: 0.9896 - val_loss: 0.2288 - val_acc: 0.9585\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.1780 - acc: 0.9529\n",
      "Loss: 0.17800962907317272 Accuracy: 0.95285565\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5655 - acc: 0.1547\n",
      "Epoch 00001: val_loss improved from inf to 2.07901, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/001-2.0790.hdf5\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 2.5654 - acc: 0.1547 - val_loss: 2.0790 - val_acc: 0.3322\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7322 - acc: 0.4385\n",
      "Epoch 00002: val_loss improved from 2.07901 to 1.28755, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/002-1.2876.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 1.7322 - acc: 0.4385 - val_loss: 1.2876 - val_acc: 0.5861\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1998 - acc: 0.6044\n",
      "Epoch 00003: val_loss improved from 1.28755 to 0.90353, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/003-0.9035.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 1.1998 - acc: 0.6044 - val_loss: 0.9035 - val_acc: 0.7086\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9433 - acc: 0.6898\n",
      "Epoch 00004: val_loss improved from 0.90353 to 0.62859, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/004-0.6286.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.9432 - acc: 0.6898 - val_loss: 0.6286 - val_acc: 0.7973\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7944 - acc: 0.7415\n",
      "Epoch 00005: val_loss improved from 0.62859 to 0.52346, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/005-0.5235.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.7944 - acc: 0.7416 - val_loss: 0.5235 - val_acc: 0.8362\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6685 - acc: 0.7847\n",
      "Epoch 00006: val_loss improved from 0.52346 to 0.45878, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/006-0.4588.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.6684 - acc: 0.7848 - val_loss: 0.4588 - val_acc: 0.8549\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5788 - acc: 0.8128\n",
      "Epoch 00007: val_loss improved from 0.45878 to 0.36519, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/007-0.3652.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.5787 - acc: 0.8129 - val_loss: 0.3652 - val_acc: 0.8898\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5174 - acc: 0.8368\n",
      "Epoch 00008: val_loss improved from 0.36519 to 0.35995, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/008-0.3600.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.5174 - acc: 0.8368 - val_loss: 0.3600 - val_acc: 0.8870\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4584 - acc: 0.8532\n",
      "Epoch 00009: val_loss improved from 0.35995 to 0.30626, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/009-0.3063.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4584 - acc: 0.8531 - val_loss: 0.3063 - val_acc: 0.9094\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4217 - acc: 0.8669\n",
      "Epoch 00010: val_loss improved from 0.30626 to 0.29043, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/010-0.2904.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4216 - acc: 0.8669 - val_loss: 0.2904 - val_acc: 0.9103\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3854 - acc: 0.8763\n",
      "Epoch 00011: val_loss improved from 0.29043 to 0.25561, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/011-0.2556.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3854 - acc: 0.8763 - val_loss: 0.2556 - val_acc: 0.9243\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3518 - acc: 0.8892\n",
      "Epoch 00012: val_loss improved from 0.25561 to 0.24493, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/012-0.2449.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3518 - acc: 0.8892 - val_loss: 0.2449 - val_acc: 0.9273\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3264 - acc: 0.8960\n",
      "Epoch 00013: val_loss improved from 0.24493 to 0.22053, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/013-0.2205.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3264 - acc: 0.8960 - val_loss: 0.2205 - val_acc: 0.9362\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3092 - acc: 0.9014\n",
      "Epoch 00014: val_loss did not improve from 0.22053\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3093 - acc: 0.9014 - val_loss: 0.2386 - val_acc: 0.9301\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2940 - acc: 0.9064\n",
      "Epoch 00015: val_loss improved from 0.22053 to 0.20129, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/015-0.2013.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2940 - acc: 0.9064 - val_loss: 0.2013 - val_acc: 0.9411\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2770 - acc: 0.9098\n",
      "Epoch 00016: val_loss improved from 0.20129 to 0.18364, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/016-0.1836.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2770 - acc: 0.9098 - val_loss: 0.1836 - val_acc: 0.9443\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2542 - acc: 0.9190\n",
      "Epoch 00017: val_loss did not improve from 0.18364\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2542 - acc: 0.9191 - val_loss: 0.1966 - val_acc: 0.9439\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2413 - acc: 0.9219\n",
      "Epoch 00018: val_loss did not improve from 0.18364\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2412 - acc: 0.9219 - val_loss: 0.1905 - val_acc: 0.9460\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2354 - acc: 0.9241\n",
      "Epoch 00019: val_loss improved from 0.18364 to 0.16272, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/019-0.1627.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2354 - acc: 0.9241 - val_loss: 0.1627 - val_acc: 0.9511\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9303\n",
      "Epoch 00020: val_loss did not improve from 0.16272\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2211 - acc: 0.9303 - val_loss: 0.1810 - val_acc: 0.9464\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9307\n",
      "Epoch 00021: val_loss did not improve from 0.16272\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2135 - acc: 0.9307 - val_loss: 0.1869 - val_acc: 0.9492\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2000 - acc: 0.9344\n",
      "Epoch 00022: val_loss improved from 0.16272 to 0.15486, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/022-0.1549.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1999 - acc: 0.9344 - val_loss: 0.1549 - val_acc: 0.9567\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9383\n",
      "Epoch 00023: val_loss did not improve from 0.15486\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1932 - acc: 0.9384 - val_loss: 0.1876 - val_acc: 0.9432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1806 - acc: 0.9411\n",
      "Epoch 00024: val_loss did not improve from 0.15486\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1807 - acc: 0.9410 - val_loss: 0.1552 - val_acc: 0.9555\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1746 - acc: 0.9436\n",
      "Epoch 00025: val_loss improved from 0.15486 to 0.14509, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/025-0.1451.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1746 - acc: 0.9436 - val_loss: 0.1451 - val_acc: 0.9557\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1667 - acc: 0.9464\n",
      "Epoch 00026: val_loss improved from 0.14509 to 0.14409, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/026-0.1441.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1667 - acc: 0.9464 - val_loss: 0.1441 - val_acc: 0.9599\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9482\n",
      "Epoch 00027: val_loss did not improve from 0.14409\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1603 - acc: 0.9482 - val_loss: 0.1526 - val_acc: 0.9567\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9489\n",
      "Epoch 00028: val_loss improved from 0.14409 to 0.14153, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/028-0.1415.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1572 - acc: 0.9489 - val_loss: 0.1415 - val_acc: 0.9611\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.9505\n",
      "Epoch 00029: val_loss did not improve from 0.14153\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1493 - acc: 0.9505 - val_loss: 0.1500 - val_acc: 0.9576\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1436 - acc: 0.9532\n",
      "Epoch 00030: val_loss did not improve from 0.14153\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1436 - acc: 0.9532 - val_loss: 0.1420 - val_acc: 0.9564\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9548\n",
      "Epoch 00031: val_loss did not improve from 0.14153\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1397 - acc: 0.9548 - val_loss: 0.1549 - val_acc: 0.9569\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9556\n",
      "Epoch 00032: val_loss did not improve from 0.14153\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1351 - acc: 0.9556 - val_loss: 0.1566 - val_acc: 0.9527\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9578\n",
      "Epoch 00033: val_loss improved from 0.14153 to 0.13167, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/033-0.1317.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1314 - acc: 0.9578 - val_loss: 0.1317 - val_acc: 0.9655\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9588\n",
      "Epoch 00034: val_loss improved from 0.13167 to 0.12246, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/034-0.1225.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1243 - acc: 0.9588 - val_loss: 0.1225 - val_acc: 0.9637\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9611\n",
      "Epoch 00035: val_loss did not improve from 0.12246\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1209 - acc: 0.9611 - val_loss: 0.1251 - val_acc: 0.9637\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9608\n",
      "Epoch 00036: val_loss did not improve from 0.12246\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1181 - acc: 0.9608 - val_loss: 0.1290 - val_acc: 0.9648\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9599\n",
      "Epoch 00037: val_loss improved from 0.12246 to 0.12090, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/037-0.1209.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1198 - acc: 0.9599 - val_loss: 0.1209 - val_acc: 0.9665\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9643\n",
      "Epoch 00038: val_loss did not improve from 0.12090\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1096 - acc: 0.9643 - val_loss: 0.1610 - val_acc: 0.9546\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9660\n",
      "Epoch 00039: val_loss did not improve from 0.12090\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1041 - acc: 0.9659 - val_loss: 0.1270 - val_acc: 0.9651\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9668\n",
      "Epoch 00040: val_loss did not improve from 0.12090\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0987 - acc: 0.9668 - val_loss: 0.1296 - val_acc: 0.9625\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9659\n",
      "Epoch 00041: val_loss did not improve from 0.12090\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1006 - acc: 0.9659 - val_loss: 0.1320 - val_acc: 0.9665\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9659\n",
      "Epoch 00042: val_loss did not improve from 0.12090\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1031 - acc: 0.9659 - val_loss: 0.1240 - val_acc: 0.9648\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9676\n",
      "Epoch 00043: val_loss did not improve from 0.12090\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0936 - acc: 0.9676 - val_loss: 0.1370 - val_acc: 0.9606\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9699\n",
      "Epoch 00044: val_loss did not improve from 0.12090\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0891 - acc: 0.9699 - val_loss: 0.1286 - val_acc: 0.9620\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9698\n",
      "Epoch 00045: val_loss improved from 0.12090 to 0.11652, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_8_conv_checkpoint/045-0.1165.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0910 - acc: 0.9698 - val_loss: 0.1165 - val_acc: 0.9648\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9713\n",
      "Epoch 00046: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0851 - acc: 0.9713 - val_loss: 0.1266 - val_acc: 0.9620\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9728\n",
      "Epoch 00047: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0832 - acc: 0.9728 - val_loss: 0.1362 - val_acc: 0.9644\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9729\n",
      "Epoch 00048: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0811 - acc: 0.9729 - val_loss: 0.1441 - val_acc: 0.9620\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9720\n",
      "Epoch 00049: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0813 - acc: 0.9720 - val_loss: 0.1315 - val_acc: 0.9672\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9739\n",
      "Epoch 00050: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0762 - acc: 0.9739 - val_loss: 0.1456 - val_acc: 0.9618\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9748\n",
      "Epoch 00051: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0756 - acc: 0.9747 - val_loss: 0.1471 - val_acc: 0.9611\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9752\n",
      "Epoch 00052: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0751 - acc: 0.9752 - val_loss: 0.1397 - val_acc: 0.9641\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9749\n",
      "Epoch 00053: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0741 - acc: 0.9749 - val_loss: 0.1282 - val_acc: 0.9644\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9768\n",
      "Epoch 00054: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0685 - acc: 0.9768 - val_loss: 0.1299 - val_acc: 0.9665\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9762\n",
      "Epoch 00055: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0710 - acc: 0.9762 - val_loss: 0.1458 - val_acc: 0.9602\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9769\n",
      "Epoch 00056: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0686 - acc: 0.9769 - val_loss: 0.1349 - val_acc: 0.9681\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9793\n",
      "Epoch 00057: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0636 - acc: 0.9793 - val_loss: 0.1282 - val_acc: 0.9655\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9793\n",
      "Epoch 00058: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0641 - acc: 0.9793 - val_loss: 0.1463 - val_acc: 0.9655\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9792\n",
      "Epoch 00059: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0637 - acc: 0.9792 - val_loss: 0.1233 - val_acc: 0.9674\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9798\n",
      "Epoch 00060: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0597 - acc: 0.9797 - val_loss: 0.1460 - val_acc: 0.9665\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9782\n",
      "Epoch 00061: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0650 - acc: 0.9782 - val_loss: 0.1315 - val_acc: 0.9658\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9794\n",
      "Epoch 00062: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0601 - acc: 0.9794 - val_loss: 0.1331 - val_acc: 0.9662\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9816\n",
      "Epoch 00063: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0550 - acc: 0.9816 - val_loss: 0.1373 - val_acc: 0.9665\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9822\n",
      "Epoch 00064: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0560 - acc: 0.9822 - val_loss: 0.1389 - val_acc: 0.9655\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9827\n",
      "Epoch 00065: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0512 - acc: 0.9827 - val_loss: 0.1372 - val_acc: 0.9658\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9812\n",
      "Epoch 00066: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0551 - acc: 0.9812 - val_loss: 0.1371 - val_acc: 0.9693\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9811\n",
      "Epoch 00067: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0538 - acc: 0.9811 - val_loss: 0.1537 - val_acc: 0.9667\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9824\n",
      "Epoch 00068: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0523 - acc: 0.9824 - val_loss: 0.1310 - val_acc: 0.9665\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9834\n",
      "Epoch 00069: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0482 - acc: 0.9834 - val_loss: 0.1234 - val_acc: 0.9676\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9830\n",
      "Epoch 00070: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0492 - acc: 0.9830 - val_loss: 0.1217 - val_acc: 0.9695\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9835\n",
      "Epoch 00071: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0491 - acc: 0.9835 - val_loss: 0.1198 - val_acc: 0.9709\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9840\n",
      "Epoch 00072: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0469 - acc: 0.9840 - val_loss: 0.1460 - val_acc: 0.9672\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9840\n",
      "Epoch 00073: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0472 - acc: 0.9840 - val_loss: 0.1539 - val_acc: 0.9665\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9846\n",
      "Epoch 00074: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0470 - acc: 0.9846 - val_loss: 0.1425 - val_acc: 0.9679\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9842\n",
      "Epoch 00075: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0445 - acc: 0.9842 - val_loss: 0.1479 - val_acc: 0.9662\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9857\n",
      "Epoch 00076: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0452 - acc: 0.9857 - val_loss: 0.1287 - val_acc: 0.9679\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9854\n",
      "Epoch 00077: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0433 - acc: 0.9854 - val_loss: 0.1251 - val_acc: 0.9713\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9854\n",
      "Epoch 00078: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0438 - acc: 0.9854 - val_loss: 0.1380 - val_acc: 0.9681\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9848\n",
      "Epoch 00079: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0430 - acc: 0.9848 - val_loss: 0.1367 - val_acc: 0.9662\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9848\n",
      "Epoch 00080: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0454 - acc: 0.9848 - val_loss: 0.1319 - val_acc: 0.9681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9862\n",
      "Epoch 00081: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0414 - acc: 0.9862 - val_loss: 0.2248 - val_acc: 0.9578\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9870\n",
      "Epoch 00082: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0394 - acc: 0.9870 - val_loss: 0.1529 - val_acc: 0.9630\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9861\n",
      "Epoch 00083: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0425 - acc: 0.9861 - val_loss: 0.1348 - val_acc: 0.9672\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9876\n",
      "Epoch 00084: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0356 - acc: 0.9876 - val_loss: 0.1464 - val_acc: 0.9674\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9846\n",
      "Epoch 00085: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0453 - acc: 0.9846 - val_loss: 0.1491 - val_acc: 0.9688\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9875\n",
      "Epoch 00086: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0360 - acc: 0.9875 - val_loss: 0.1370 - val_acc: 0.9686\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9870\n",
      "Epoch 00087: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0375 - acc: 0.9870 - val_loss: 0.1491 - val_acc: 0.9697\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9878\n",
      "Epoch 00088: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0378 - acc: 0.9878 - val_loss: 0.1166 - val_acc: 0.9697\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9884\n",
      "Epoch 00089: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0356 - acc: 0.9884 - val_loss: 0.1349 - val_acc: 0.9706\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9886\n",
      "Epoch 00090: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0338 - acc: 0.9886 - val_loss: 0.1568 - val_acc: 0.9662\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9875\n",
      "Epoch 00091: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0372 - acc: 0.9875 - val_loss: 0.1586 - val_acc: 0.9686\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9891\n",
      "Epoch 00092: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0329 - acc: 0.9891 - val_loss: 0.1463 - val_acc: 0.9693\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9881\n",
      "Epoch 00093: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0361 - acc: 0.9881 - val_loss: 0.1458 - val_acc: 0.9669\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9892\n",
      "Epoch 00094: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0320 - acc: 0.9892 - val_loss: 0.1555 - val_acc: 0.9674\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9884\n",
      "Epoch 00095: val_loss did not improve from 0.11652\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0345 - acc: 0.9884 - val_loss: 0.1661 - val_acc: 0.9646\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.1703 - acc: 0.9487\n",
      "Loss: 0.17028206680144106 Accuracy: 0.948702\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3002 - acc: 0.2503\n",
      "Epoch 00001: val_loss improved from inf to 1.56512, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/001-1.5651.hdf5\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 2.3002 - acc: 0.2504 - val_loss: 1.5651 - val_acc: 0.4997\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3636 - acc: 0.5498\n",
      "Epoch 00002: val_loss improved from 1.56512 to 0.91549, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/002-0.9155.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.3635 - acc: 0.5498 - val_loss: 0.9155 - val_acc: 0.7081\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9114 - acc: 0.7030\n",
      "Epoch 00003: val_loss improved from 0.91549 to 0.70311, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/003-0.7031.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.9116 - acc: 0.7029 - val_loss: 0.7031 - val_acc: 0.7757\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6695 - acc: 0.7813\n",
      "Epoch 00004: val_loss improved from 0.70311 to 0.49105, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/004-0.4910.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6694 - acc: 0.7813 - val_loss: 0.4910 - val_acc: 0.8341\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5464 - acc: 0.8226\n",
      "Epoch 00005: val_loss improved from 0.49105 to 0.40258, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/005-0.4026.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5464 - acc: 0.8226 - val_loss: 0.4026 - val_acc: 0.8721\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4677 - acc: 0.8464\n",
      "Epoch 00006: val_loss improved from 0.40258 to 0.32437, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/006-0.3244.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4677 - acc: 0.8464 - val_loss: 0.3244 - val_acc: 0.8977\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4016 - acc: 0.8716\n",
      "Epoch 00007: val_loss did not improve from 0.32437\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4015 - acc: 0.8716 - val_loss: 0.3391 - val_acc: 0.8940\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3552 - acc: 0.8851\n",
      "Epoch 00008: val_loss improved from 0.32437 to 0.24268, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/008-0.2427.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3552 - acc: 0.8851 - val_loss: 0.2427 - val_acc: 0.9234\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3183 - acc: 0.8991\n",
      "Epoch 00009: val_loss did not improve from 0.24268\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3182 - acc: 0.8991 - val_loss: 0.2564 - val_acc: 0.9185\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2888 - acc: 0.9050\n",
      "Epoch 00010: val_loss improved from 0.24268 to 0.19886, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/010-0.1989.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2889 - acc: 0.9050 - val_loss: 0.1989 - val_acc: 0.9373\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2590 - acc: 0.9157\n",
      "Epoch 00011: val_loss did not improve from 0.19886\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2590 - acc: 0.9156 - val_loss: 0.1994 - val_acc: 0.9390\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2421 - acc: 0.9225\n",
      "Epoch 00012: val_loss improved from 0.19886 to 0.18887, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/012-0.1889.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2421 - acc: 0.9225 - val_loss: 0.1889 - val_acc: 0.9413\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2164 - acc: 0.9304\n",
      "Epoch 00013: val_loss improved from 0.18887 to 0.17972, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/013-0.1797.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2164 - acc: 0.9304 - val_loss: 0.1797 - val_acc: 0.9418\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2029 - acc: 0.9351\n",
      "Epoch 00014: val_loss improved from 0.17972 to 0.17871, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/014-0.1787.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2029 - acc: 0.9351 - val_loss: 0.1787 - val_acc: 0.9432\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1889 - acc: 0.9392\n",
      "Epoch 00015: val_loss improved from 0.17871 to 0.16797, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/015-0.1680.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1889 - acc: 0.9392 - val_loss: 0.1680 - val_acc: 0.9497\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.9437\n",
      "Epoch 00016: val_loss improved from 0.16797 to 0.16630, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/016-0.1663.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1764 - acc: 0.9437 - val_loss: 0.1663 - val_acc: 0.9457\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9464\n",
      "Epoch 00017: val_loss did not improve from 0.16630\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1620 - acc: 0.9464 - val_loss: 0.1985 - val_acc: 0.9404\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9499\n",
      "Epoch 00018: val_loss improved from 0.16630 to 0.16055, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/018-0.1605.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1506 - acc: 0.9498 - val_loss: 0.1605 - val_acc: 0.9483\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9508\n",
      "Epoch 00019: val_loss improved from 0.16055 to 0.15303, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/019-0.1530.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1487 - acc: 0.9508 - val_loss: 0.1530 - val_acc: 0.9550\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9556\n",
      "Epoch 00020: val_loss improved from 0.15303 to 0.14434, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/020-0.1443.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1367 - acc: 0.9556 - val_loss: 0.1443 - val_acc: 0.9585\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9576\n",
      "Epoch 00021: val_loss did not improve from 0.14434\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1262 - acc: 0.9576 - val_loss: 0.1494 - val_acc: 0.9562\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9589\n",
      "Epoch 00022: val_loss did not improve from 0.14434\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1195 - acc: 0.9589 - val_loss: 0.1472 - val_acc: 0.9555\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9621\n",
      "Epoch 00023: val_loss did not improve from 0.14434\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1141 - acc: 0.9620 - val_loss: 0.1570 - val_acc: 0.9583\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9630\n",
      "Epoch 00024: val_loss improved from 0.14434 to 0.13225, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/024-0.1322.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1100 - acc: 0.9630 - val_loss: 0.1322 - val_acc: 0.9546\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9678\n",
      "Epoch 00025: val_loss did not improve from 0.13225\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0981 - acc: 0.9678 - val_loss: 0.1460 - val_acc: 0.9578\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9671\n",
      "Epoch 00026: val_loss did not improve from 0.13225\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0974 - acc: 0.9671 - val_loss: 0.1440 - val_acc: 0.9567\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9699\n",
      "Epoch 00027: val_loss did not improve from 0.13225\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0893 - acc: 0.9699 - val_loss: 0.1451 - val_acc: 0.9555\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9714\n",
      "Epoch 00028: val_loss did not improve from 0.13225\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0841 - acc: 0.9714 - val_loss: 0.1469 - val_acc: 0.9606\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9733\n",
      "Epoch 00029: val_loss improved from 0.13225 to 0.12961, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_9_conv_checkpoint/029-0.1296.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0785 - acc: 0.9733 - val_loss: 0.1296 - val_acc: 0.9627\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9741\n",
      "Epoch 00030: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0805 - acc: 0.9741 - val_loss: 0.1515 - val_acc: 0.9592\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9755\n",
      "Epoch 00031: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0725 - acc: 0.9755 - val_loss: 0.1437 - val_acc: 0.9588\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9732\n",
      "Epoch 00032: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0777 - acc: 0.9732 - val_loss: 0.1724 - val_acc: 0.9564\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9776\n",
      "Epoch 00033: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0670 - acc: 0.9775 - val_loss: 0.1592 - val_acc: 0.9599\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9770\n",
      "Epoch 00034: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0662 - acc: 0.9770 - val_loss: 0.1574 - val_acc: 0.9620\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9795\n",
      "Epoch 00035: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0621 - acc: 0.9795 - val_loss: 0.1594 - val_acc: 0.9583\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9817\n",
      "Epoch 00036: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0540 - acc: 0.9817 - val_loss: 0.1451 - val_acc: 0.9655\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9796\n",
      "Epoch 00037: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0588 - acc: 0.9796 - val_loss: 0.1493 - val_acc: 0.9630\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9807\n",
      "Epoch 00038: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0583 - acc: 0.9807 - val_loss: 0.1703 - val_acc: 0.9576\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9810\n",
      "Epoch 00039: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0560 - acc: 0.9810 - val_loss: 0.1708 - val_acc: 0.9599\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9835\n",
      "Epoch 00040: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0483 - acc: 0.9835 - val_loss: 0.1572 - val_acc: 0.9606\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9826\n",
      "Epoch 00041: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0524 - acc: 0.9826 - val_loss: 0.2378 - val_acc: 0.9460\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9826\n",
      "Epoch 00042: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0522 - acc: 0.9826 - val_loss: 0.1734 - val_acc: 0.9602\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9846\n",
      "Epoch 00043: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0463 - acc: 0.9846 - val_loss: 0.1815 - val_acc: 0.9585\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9852\n",
      "Epoch 00044: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0441 - acc: 0.9852 - val_loss: 0.1769 - val_acc: 0.9599\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9844\n",
      "Epoch 00045: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0468 - acc: 0.9844 - val_loss: 0.1747 - val_acc: 0.9576\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9849\n",
      "Epoch 00046: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0442 - acc: 0.9849 - val_loss: 0.1789 - val_acc: 0.9639\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9860\n",
      "Epoch 00047: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0410 - acc: 0.9860 - val_loss: 0.1737 - val_acc: 0.9590\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9868\n",
      "Epoch 00048: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0398 - acc: 0.9868 - val_loss: 0.1701 - val_acc: 0.9611\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9876\n",
      "Epoch 00049: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0383 - acc: 0.9876 - val_loss: 0.1572 - val_acc: 0.9627\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9879\n",
      "Epoch 00050: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0369 - acc: 0.9879 - val_loss: 0.1966 - val_acc: 0.9620\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9881\n",
      "Epoch 00051: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0377 - acc: 0.9881 - val_loss: 0.1693 - val_acc: 0.9634\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9875\n",
      "Epoch 00052: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0383 - acc: 0.9875 - val_loss: 0.1741 - val_acc: 0.9651\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9865\n",
      "Epoch 00053: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0417 - acc: 0.9865 - val_loss: 0.1491 - val_acc: 0.9655\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9897\n",
      "Epoch 00054: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0330 - acc: 0.9897 - val_loss: 0.1798 - val_acc: 0.9606\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9890\n",
      "Epoch 00055: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0336 - acc: 0.9890 - val_loss: 0.1643 - val_acc: 0.9658\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9892\n",
      "Epoch 00056: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0317 - acc: 0.9892 - val_loss: 0.1683 - val_acc: 0.9651\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9890\n",
      "Epoch 00057: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0351 - acc: 0.9891 - val_loss: 0.1765 - val_acc: 0.9599\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9893\n",
      "Epoch 00058: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0322 - acc: 0.9893 - val_loss: 0.1986 - val_acc: 0.9618\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9882\n",
      "Epoch 00059: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0355 - acc: 0.9882 - val_loss: 0.1589 - val_acc: 0.9625\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9911\n",
      "Epoch 00060: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0276 - acc: 0.9911 - val_loss: 0.2148 - val_acc: 0.9602\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9898\n",
      "Epoch 00061: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0317 - acc: 0.9898 - val_loss: 0.1767 - val_acc: 0.9627\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9901\n",
      "Epoch 00062: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0290 - acc: 0.9901 - val_loss: 0.1670 - val_acc: 0.9665\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9904\n",
      "Epoch 00063: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0295 - acc: 0.9904 - val_loss: 0.2047 - val_acc: 0.9618\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9928\n",
      "Epoch 00064: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0237 - acc: 0.9928 - val_loss: 0.2049 - val_acc: 0.9585\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9900\n",
      "Epoch 00065: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0317 - acc: 0.9900 - val_loss: 0.1943 - val_acc: 0.9590\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9915\n",
      "Epoch 00066: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0265 - acc: 0.9915 - val_loss: 0.1646 - val_acc: 0.9634\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9915\n",
      "Epoch 00067: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0259 - acc: 0.9915 - val_loss: 0.1833 - val_acc: 0.9620\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 00068: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0251 - acc: 0.9917 - val_loss: 0.2032 - val_acc: 0.9602\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9918\n",
      "Epoch 00069: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0261 - acc: 0.9918 - val_loss: 0.2000 - val_acc: 0.9641\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9916\n",
      "Epoch 00070: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0258 - acc: 0.9916 - val_loss: 0.1818 - val_acc: 0.9592\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9907\n",
      "Epoch 00071: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0285 - acc: 0.9907 - val_loss: 0.1946 - val_acc: 0.9648\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9921\n",
      "Epoch 00072: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0249 - acc: 0.9921 - val_loss: 0.1911 - val_acc: 0.9646\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9926\n",
      "Epoch 00073: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0229 - acc: 0.9926 - val_loss: 0.1796 - val_acc: 0.9644\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9927\n",
      "Epoch 00074: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0226 - acc: 0.9927 - val_loss: 0.2272 - val_acc: 0.9599\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9933\n",
      "Epoch 00075: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0201 - acc: 0.9933 - val_loss: 0.2116 - val_acc: 0.9632\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9915\n",
      "Epoch 00076: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0271 - acc: 0.9915 - val_loss: 0.1724 - val_acc: 0.9644\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9942\n",
      "Epoch 00077: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0187 - acc: 0.9942 - val_loss: 0.1760 - val_acc: 0.9679\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9933\n",
      "Epoch 00078: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0213 - acc: 0.9933 - val_loss: 0.2102 - val_acc: 0.9634\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9935\n",
      "Epoch 00079: val_loss did not improve from 0.12961\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0210 - acc: 0.9935 - val_loss: 0.1875 - val_acc: 0.9632\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.1918 - acc: 0.9483\n",
      "Loss: 0.1917828597236707 Accuracy: 0.9482866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    base = '1D_CNN_custom_conv_3_VGG_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.9976 - acc: 0.3909\n",
      "Loss: 1.9976032813885254 Accuracy: 0.3908619\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,498,320\n",
      "Trainable params: 5,498,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.7659 - acc: 0.4573\n",
      "Loss: 1.7659185970807496 Accuracy: 0.45732087\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.4214 - acc: 0.5601\n",
      "Loss: 1.4213561559639492 Accuracy: 0.56012464\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 1.0469 - acc: 0.6789\n",
      "Loss: 1.0469354746745259 Accuracy: 0.67892003\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.8236 - acc: 0.7593\n",
      "Loss: 0.8235816266554044 Accuracy: 0.75929385\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.3925 - acc: 0.8960\n",
      "Loss: 0.39251999248472946 Accuracy: 0.89595014\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.1780 - acc: 0.9529\n",
      "Loss: 0.17800962907317272 Accuracy: 0.95285565\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.1703 - acc: 0.9487\n",
      "Loss: 0.17028206680144106 Accuracy: 0.948702\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.1918 - acc: 0.9483\n",
      "Loss: 0.1917828597236707 Accuracy: 0.9482866\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_DO'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 5.7123 - acc: 0.3238\n",
      "Loss: 5.712339253390937 Accuracy: 0.32377985\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,498,320\n",
      "Trainable params: 5,498,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 4.4435 - acc: 0.4530\n",
      "Loss: 4.443544545178597 Accuracy: 0.4529595\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 2.6758 - acc: 0.6087\n",
      "Loss: 2.675766536181837 Accuracy: 0.60872275\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 1.5002 - acc: 0.7244\n",
      "Loss: 1.5001820875229246 Accuracy: 0.7244029\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.0908 - acc: 0.7952\n",
      "Loss: 1.0908317271546535 Accuracy: 0.79522324\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.4645 - acc: 0.9092\n",
      "Loss: 0.4645488865712226 Accuracy: 0.909242\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2319 - acc: 0.9506\n",
      "Loss: 0.23194159156950395 Accuracy: 0.9505711\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2112 - acc: 0.9502\n",
      "Loss: 0.21121647467345842 Accuracy: 0.95015574\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2628 - acc: 0.9508\n",
      "Loss: 0.2628163867620333 Accuracy: 0.95077884\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
