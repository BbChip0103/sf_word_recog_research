{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                      activation='relu', input_shape=input_shape)) \n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))\n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,272\n",
      "Trainable params: 16,384,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,473,616\n",
      "Trainable params: 5,473,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,844,624\n",
      "Trainable params: 1,844,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 643,536\n",
      "Trainable params: 643,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 465,488\n",
      "Trainable params: 465,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 244,432\n",
      "Trainable params: 244,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 203,600\n",
      "Trainable params: 203,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 224,208\n",
      "Trainable params: 224,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 316,624\n",
      "Trainable params: 316,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4958 - acc: 0.2085\n",
      "Epoch 00001: val_loss improved from inf to 2.39163, saving model to model/checkpoint/1D_CNN_1_conv_custom_conv_3_DO_checkpoint/001-2.3916.hdf5\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 2.4958 - acc: 0.2085 - val_loss: 2.3916 - val_acc: 0.2262\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.1419 - acc: 0.3522\n",
      "Epoch 00002: val_loss improved from 2.39163 to 2.32499, saving model to model/checkpoint/1D_CNN_1_conv_custom_conv_3_DO_checkpoint/002-2.3250.hdf5\n",
      "36805/36805 [==============================] - 27s 730us/sample - loss: 2.1420 - acc: 0.3522 - val_loss: 2.3250 - val_acc: 0.2630\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8910 - acc: 0.4411\n",
      "Epoch 00003: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 726us/sample - loss: 1.8910 - acc: 0.4411 - val_loss: 2.3428 - val_acc: 0.2707\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6825 - acc: 0.5104\n",
      "Epoch 00004: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 1.6825 - acc: 0.5104 - val_loss: 2.3786 - val_acc: 0.2662\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5103 - acc: 0.5652\n",
      "Epoch 00005: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 1.5103 - acc: 0.5651 - val_loss: 2.4350 - val_acc: 0.2709\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3659 - acc: 0.6098\n",
      "Epoch 00006: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 1.3659 - acc: 0.6099 - val_loss: 2.4755 - val_acc: 0.2674\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2376 - acc: 0.6529\n",
      "Epoch 00007: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 1.2375 - acc: 0.6529 - val_loss: 2.5354 - val_acc: 0.2700\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1251 - acc: 0.6903\n",
      "Epoch 00008: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 1.1251 - acc: 0.6903 - val_loss: 2.6063 - val_acc: 0.2623\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0258 - acc: 0.7189\n",
      "Epoch 00009: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 1.0257 - acc: 0.7189 - val_loss: 2.6460 - val_acc: 0.2697\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9404 - acc: 0.7468\n",
      "Epoch 00010: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.9403 - acc: 0.7468 - val_loss: 2.7413 - val_acc: 0.2660\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8581 - acc: 0.7739\n",
      "Epoch 00011: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.8582 - acc: 0.7739 - val_loss: 2.7738 - val_acc: 0.2690\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7886 - acc: 0.7972\n",
      "Epoch 00012: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 724us/sample - loss: 0.7888 - acc: 0.7971 - val_loss: 2.8696 - val_acc: 0.2672\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7270 - acc: 0.8129\n",
      "Epoch 00013: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 26s 715us/sample - loss: 0.7271 - acc: 0.8128 - val_loss: 2.9174 - val_acc: 0.2611\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6687 - acc: 0.8313\n",
      "Epoch 00014: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 26s 715us/sample - loss: 0.6687 - acc: 0.8313 - val_loss: 3.0035 - val_acc: 0.2667\n",
      "Epoch 15/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6175 - acc: 0.8473\n",
      "Epoch 00015: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 729us/sample - loss: 0.6175 - acc: 0.8473 - val_loss: 3.0855 - val_acc: 0.2665\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5673 - acc: 0.8621\n",
      "Epoch 00016: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.5673 - acc: 0.8621 - val_loss: 3.1456 - val_acc: 0.2618\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5258 - acc: 0.8727\n",
      "Epoch 00017: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.5258 - acc: 0.8727 - val_loss: 3.2265 - val_acc: 0.2586\n",
      "Epoch 18/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4818 - acc: 0.8872\n",
      "Epoch 00018: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 726us/sample - loss: 0.4821 - acc: 0.8873 - val_loss: 3.2996 - val_acc: 0.2679\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4489 - acc: 0.8971\n",
      "Epoch 00019: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.4489 - acc: 0.8971 - val_loss: 3.3858 - val_acc: 0.2520\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4150 - acc: 0.9048\n",
      "Epoch 00020: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.4150 - acc: 0.9048 - val_loss: 3.4040 - val_acc: 0.2630\n",
      "Epoch 21/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3878 - acc: 0.9138\n",
      "Epoch 00021: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.3880 - acc: 0.9136 - val_loss: 3.5256 - val_acc: 0.2611\n",
      "Epoch 22/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3632 - acc: 0.9205\n",
      "Epoch 00022: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 726us/sample - loss: 0.3635 - acc: 0.9204 - val_loss: 3.5900 - val_acc: 0.2604\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3406 - acc: 0.9270\n",
      "Epoch 00023: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.3407 - acc: 0.9269 - val_loss: 3.7035 - val_acc: 0.2593\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3147 - acc: 0.9325\n",
      "Epoch 00024: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 721us/sample - loss: 0.3147 - acc: 0.9325 - val_loss: 3.7638 - val_acc: 0.2548\n",
      "Epoch 25/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2925 - acc: 0.9400\n",
      "Epoch 00025: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.2927 - acc: 0.9400 - val_loss: 3.8549 - val_acc: 0.2618\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2743 - acc: 0.9445\n",
      "Epoch 00026: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.2743 - acc: 0.9445 - val_loss: 3.8768 - val_acc: 0.2574\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2544 - acc: 0.9503\n",
      "Epoch 00027: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 26s 706us/sample - loss: 0.2545 - acc: 0.9503 - val_loss: 3.9152 - val_acc: 0.2595\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2359 - acc: 0.9539\n",
      "Epoch 00028: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 26s 702us/sample - loss: 0.2359 - acc: 0.9539 - val_loss: 4.0272 - val_acc: 0.2425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2331 - acc: 0.9545\n",
      "Epoch 00029: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 26s 704us/sample - loss: 0.2331 - acc: 0.9545 - val_loss: 4.0689 - val_acc: 0.2527\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9598\n",
      "Epoch 00030: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 26s 703us/sample - loss: 0.2135 - acc: 0.9598 - val_loss: 4.1307 - val_acc: 0.2642\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2027 - acc: 0.9621\n",
      "Epoch 00031: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 26s 707us/sample - loss: 0.2028 - acc: 0.9621 - val_loss: 4.2280 - val_acc: 0.2548\n",
      "Epoch 32/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1859 - acc: 0.9676\n",
      "Epoch 00032: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 26s 702us/sample - loss: 0.1859 - acc: 0.9676 - val_loss: 4.2520 - val_acc: 0.2569\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1730 - acc: 0.9710\n",
      "Epoch 00033: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 26s 720us/sample - loss: 0.1730 - acc: 0.9710 - val_loss: 4.2947 - val_acc: 0.2628\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9735\n",
      "Epoch 00034: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 724us/sample - loss: 0.1624 - acc: 0.9735 - val_loss: 4.3588 - val_acc: 0.2537\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1573 - acc: 0.9741\n",
      "Epoch 00035: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 26s 718us/sample - loss: 0.1573 - acc: 0.9741 - val_loss: 4.4271 - val_acc: 0.2572\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1498 - acc: 0.9748\n",
      "Epoch 00036: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 26s 711us/sample - loss: 0.1498 - acc: 0.9748 - val_loss: 4.4693 - val_acc: 0.2600\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9762\n",
      "Epoch 00037: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.1414 - acc: 0.9762 - val_loss: 4.5722 - val_acc: 0.2534\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9778\n",
      "Epoch 00038: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.1371 - acc: 0.9778 - val_loss: 4.5953 - val_acc: 0.2614\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9803\n",
      "Epoch 00039: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.1269 - acc: 0.9803 - val_loss: 4.6563 - val_acc: 0.2530\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9807\n",
      "Epoch 00040: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.1241 - acc: 0.9807 - val_loss: 4.7171 - val_acc: 0.2539\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9818\n",
      "Epoch 00041: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 721us/sample - loss: 0.1178 - acc: 0.9818 - val_loss: 4.8059 - val_acc: 0.2590\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9842\n",
      "Epoch 00042: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 734us/sample - loss: 0.1079 - acc: 0.9842 - val_loss: 4.7983 - val_acc: 0.2544\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9839\n",
      "Epoch 00043: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.1068 - acc: 0.9839 - val_loss: 4.8216 - val_acc: 0.2551\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9843\n",
      "Epoch 00044: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 726us/sample - loss: 0.1035 - acc: 0.9843 - val_loss: 4.8726 - val_acc: 0.2593\n",
      "Epoch 45/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9851\n",
      "Epoch 00045: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.0996 - acc: 0.9851 - val_loss: 4.9131 - val_acc: 0.2537\n",
      "Epoch 46/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9873\n",
      "Epoch 00046: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.0908 - acc: 0.9873 - val_loss: 4.9459 - val_acc: 0.2607\n",
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9880\n",
      "Epoch 00047: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.0907 - acc: 0.9880 - val_loss: 5.0117 - val_acc: 0.2593\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9884\n",
      "Epoch 00048: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.0866 - acc: 0.9884 - val_loss: 5.0541 - val_acc: 0.2567\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9878\n",
      "Epoch 00049: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.0871 - acc: 0.9878 - val_loss: 5.1184 - val_acc: 0.2600\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9889\n",
      "Epoch 00050: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.0812 - acc: 0.9889 - val_loss: 5.1350 - val_acc: 0.2572\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9871\n",
      "Epoch 00051: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.0850 - acc: 0.9871 - val_loss: 5.1392 - val_acc: 0.2579\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9911\n",
      "Epoch 00052: val_loss did not improve from 2.32499\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.0718 - acc: 0.9911 - val_loss: 5.1564 - val_acc: 0.2644\n",
      "\n",
      "1D_CNN_1_conv_custom_conv_3_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 329us/sample - loss: 2.3283 - acc: 0.2569\n",
      "Loss: 2.328297340337609 Accuracy: 0.2569055\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3579 - acc: 0.2581\n",
      "Epoch 00001: val_loss improved from inf to 2.13599, saving model to model/checkpoint/1D_CNN_2_conv_custom_conv_3_DO_checkpoint/001-2.1360.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 2.3579 - acc: 0.2580 - val_loss: 2.1360 - val_acc: 0.3403\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9674 - acc: 0.4044\n",
      "Epoch 00002: val_loss improved from 2.13599 to 1.99470, saving model to model/checkpoint/1D_CNN_2_conv_custom_conv_3_DO_checkpoint/002-1.9947.hdf5\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 1.9674 - acc: 0.4044 - val_loss: 1.9947 - val_acc: 0.3927\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7000 - acc: 0.4947\n",
      "Epoch 00003: val_loss improved from 1.99470 to 1.92433, saving model to model/checkpoint/1D_CNN_2_conv_custom_conv_3_DO_checkpoint/003-1.9243.hdf5\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 1.7000 - acc: 0.4947 - val_loss: 1.9243 - val_acc: 0.4083\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4918 - acc: 0.5600\n",
      "Epoch 00004: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 1.4918 - acc: 0.5600 - val_loss: 1.9358 - val_acc: 0.4069\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3243 - acc: 0.6084\n",
      "Epoch 00005: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 1.3244 - acc: 0.6083 - val_loss: 1.9574 - val_acc: 0.4067\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1852 - acc: 0.6492\n",
      "Epoch 00006: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 1.1853 - acc: 0.6492 - val_loss: 2.0192 - val_acc: 0.4023\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0636 - acc: 0.6873\n",
      "Epoch 00007: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 1.0635 - acc: 0.6874 - val_loss: 2.0674 - val_acc: 0.4053\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9519 - acc: 0.7203\n",
      "Epoch 00008: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.9519 - acc: 0.7202 - val_loss: 2.1164 - val_acc: 0.4011\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8569 - acc: 0.7511\n",
      "Epoch 00009: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.8569 - acc: 0.7511 - val_loss: 2.2715 - val_acc: 0.3979\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7699 - acc: 0.7779\n",
      "Epoch 00010: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.7700 - acc: 0.7778 - val_loss: 2.2593 - val_acc: 0.3927\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6878 - acc: 0.8060\n",
      "Epoch 00011: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.6877 - acc: 0.8060 - val_loss: 2.3014 - val_acc: 0.3948\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6166 - acc: 0.8273\n",
      "Epoch 00012: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.6166 - acc: 0.8273 - val_loss: 2.3968 - val_acc: 0.3923\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5540 - acc: 0.8457\n",
      "Epoch 00013: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.5540 - acc: 0.8457 - val_loss: 2.4884 - val_acc: 0.3825\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4967 - acc: 0.8641\n",
      "Epoch 00014: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.4966 - acc: 0.8641 - val_loss: 2.5488 - val_acc: 0.3899\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4445 - acc: 0.8802\n",
      "Epoch 00015: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.4445 - acc: 0.8802 - val_loss: 2.5926 - val_acc: 0.3983\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4004 - acc: 0.8936\n",
      "Epoch 00016: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.4005 - acc: 0.8936 - val_loss: 2.6878 - val_acc: 0.4018\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3578 - acc: 0.9049\n",
      "Epoch 00017: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.3578 - acc: 0.9050 - val_loss: 2.7576 - val_acc: 0.3923\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3249 - acc: 0.9148\n",
      "Epoch 00018: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.3249 - acc: 0.9148 - val_loss: 2.8423 - val_acc: 0.3962\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2971 - acc: 0.9240\n",
      "Epoch 00019: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.2970 - acc: 0.9240 - val_loss: 2.9007 - val_acc: 0.3962\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2682 - acc: 0.9307\n",
      "Epoch 00020: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.2681 - acc: 0.9307 - val_loss: 2.9783 - val_acc: 0.4014\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2434 - acc: 0.9398\n",
      "Epoch 00021: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.2434 - acc: 0.9398 - val_loss: 3.0380 - val_acc: 0.3965\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9460\n",
      "Epoch 00022: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.2208 - acc: 0.9460 - val_loss: 3.1492 - val_acc: 0.3934\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2052 - acc: 0.9499\n",
      "Epoch 00023: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.2052 - acc: 0.9499 - val_loss: 3.2159 - val_acc: 0.3960\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1927 - acc: 0.9535\n",
      "Epoch 00024: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1926 - acc: 0.9535 - val_loss: 3.2658 - val_acc: 0.3946\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1775 - acc: 0.9564\n",
      "Epoch 00025: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1775 - acc: 0.9564 - val_loss: 3.3456 - val_acc: 0.3895\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9635\n",
      "Epoch 00026: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1600 - acc: 0.9635 - val_loss: 3.4202 - val_acc: 0.3962\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9630\n",
      "Epoch 00027: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1546 - acc: 0.9630 - val_loss: 3.4549 - val_acc: 0.4034\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1467 - acc: 0.9659\n",
      "Epoch 00028: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1467 - acc: 0.9659 - val_loss: 3.4765 - val_acc: 0.3965\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9696\n",
      "Epoch 00029: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1377 - acc: 0.9697 - val_loss: 3.5233 - val_acc: 0.4027\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9719\n",
      "Epoch 00030: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1262 - acc: 0.9719 - val_loss: 3.5844 - val_acc: 0.4030\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9729\n",
      "Epoch 00031: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1238 - acc: 0.9729 - val_loss: 3.6415 - val_acc: 0.4011\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9756\n",
      "Epoch 00032: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1117 - acc: 0.9756 - val_loss: 3.6799 - val_acc: 0.4097\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9750\n",
      "Epoch 00033: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1144 - acc: 0.9750 - val_loss: 3.7842 - val_acc: 0.3899\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9793\n",
      "Epoch 00034: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1001 - acc: 0.9793 - val_loss: 3.7927 - val_acc: 0.3972\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9778\n",
      "Epoch 00035: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0996 - acc: 0.9778 - val_loss: 3.8213 - val_acc: 0.4030\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9780\n",
      "Epoch 00036: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1010 - acc: 0.9780 - val_loss: 3.8634 - val_acc: 0.4016\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9810\n",
      "Epoch 00037: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0926 - acc: 0.9810 - val_loss: 3.9623 - val_acc: 0.3932\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.9816\n",
      "Epoch 00038: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0879 - acc: 0.9816 - val_loss: 3.9118 - val_acc: 0.4023\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9821\n",
      "Epoch 00039: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0859 - acc: 0.9821 - val_loss: 3.9784 - val_acc: 0.4011\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9832\n",
      "Epoch 00040: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0839 - acc: 0.9832 - val_loss: 3.9592 - val_acc: 0.3976\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9829\n",
      "Epoch 00041: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0813 - acc: 0.9829 - val_loss: 4.0833 - val_acc: 0.3944\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9847\n",
      "Epoch 00042: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0769 - acc: 0.9847 - val_loss: 4.1171 - val_acc: 0.4014\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9847\n",
      "Epoch 00043: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0741 - acc: 0.9847 - val_loss: 4.0870 - val_acc: 0.4046\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9854\n",
      "Epoch 00044: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0761 - acc: 0.9854 - val_loss: 4.1431 - val_acc: 0.4002\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9848\n",
      "Epoch 00045: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0737 - acc: 0.9848 - val_loss: 4.0774 - val_acc: 0.4079\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9866\n",
      "Epoch 00046: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0683 - acc: 0.9866 - val_loss: 4.1547 - val_acc: 0.4060\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9868\n",
      "Epoch 00047: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0661 - acc: 0.9868 - val_loss: 4.1855 - val_acc: 0.4104\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9869\n",
      "Epoch 00048: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0661 - acc: 0.9869 - val_loss: 4.2050 - val_acc: 0.4104\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9877\n",
      "Epoch 00049: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0637 - acc: 0.9877 - val_loss: 4.2496 - val_acc: 0.4081\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9867\n",
      "Epoch 00050: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0652 - acc: 0.9867 - val_loss: 4.2303 - val_acc: 0.4074\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9885\n",
      "Epoch 00051: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0587 - acc: 0.9885 - val_loss: 4.2934 - val_acc: 0.4074\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9870\n",
      "Epoch 00052: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0630 - acc: 0.9870 - val_loss: 4.2957 - val_acc: 0.4088\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9866\n",
      "Epoch 00053: val_loss did not improve from 1.92433\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0628 - acc: 0.9866 - val_loss: 4.2962 - val_acc: 0.4104\n",
      "\n",
      "1D_CNN_2_conv_custom_conv_3_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4VNX5wPHvmS2TfWNfA4LIEgirYARxo4iKiCIq7ha0WpWq+ENRi1uLVau1pSoqilZcCiJarVotiwuogFh2IxogrAlkJcts5/fHmckCIQTIZJKZ9/M897k3M3fuPXcy894z5577HqW1RgghRPizhLoAQgghGocEfCGEiBAS8IUQIkJIwBdCiAghAV8IISKEBHwhhIgQEvCFECJCSMAXQogIIQFfCCEihC3UBaiuRYsWOi0tLdTFEEKIZmP16tV5WuuW9Vm3SQX8tLQ0Vq1aFepiCCFEs6GU2lbfdaVJRwghIoQEfCGEiBAS8IUQIkI0qTb82rjdbnJycigvLw91UZolp9NJhw4dsNvtoS6KECLEmnzAz8nJIT4+nrS0NJRSoS5Os6K1Zv/+/eTk5NClS5dQF0cIEWJNvkmnvLyc1NRUCfbHQSlFamqq/DoSQgDNIOADEuxPgLx3QoiAJt+kI4QQzUphIXz4IRw8CG53zcnjAa0Pn+Li4J57gl40CfhHUVBQwPz587nllluO+bVjxoxh/vz5JCUl1Wv9mTNnEhcXx913333M+xJChFhRETz7LDz1FBQUHNtr27RplIDfLJp0QqmgoIC///3vtT7n8XjqfO1HH31U72AvhGii3G7473/h66/hwIHDny8uhsceg7Q0eOABGD4cvvoKduyAPXtg/35zMigrq6rle73g81XV8HfvbpRDkYB/FNOnT2fr1q1kZGQwbdo0li5dyvDhwxk7diy9evUCYNy4cQwcOJDevXszZ86cytempaWRl5dHdnY2PXv2ZPLkyfTu3ZtRo0ZRVlZW537Xrl3L0KFD6du3LxdffDH5+fkAPPvss/Tq1Yu+ffty+eWXA7Bs2TIyMjLIyMigf//+FBcXB+ndECJCaG2C9i23QNu2cPbZkJkJqanQsiWcfjr8+tdw990m0N9/v3n+u+/g/ffhtNOgQwdo3RpSUiA+HpxOsNnAagWLBUJwfa1ZNelkZU2lpGRtg24zLi6D7t2fOeLzs2bNYv369axda/a7dOlS1qxZw/r16yu7Os6dO5eUlBTKysoYPHgwl1xyCampqYeUPYs333yTF198kcsuu4yFCxdy1VVXHXG/11xzDX/9618544wzePDBB3nooYd45plnmDVrFr/88gtRUVEU+H82Pvnkk8yePZvMzExKSkpwOp0n+rYIEXlKSmDjRhOw58+HX34xQXrsWLjiChOst2wx0+bN8MEHsG8fjBkDM2fC4MGhPoKjalYBv6kYMmRIjX7tzz77LIsWLQJgx44dZGVlHRbwu3TpQkZGBgADBw4kOzv7iNsvLCykoKCAM844A4Brr72WCRMmANC3b18mTZrEuHHjGDduHACZmZnceeedTJo0ifHjx9OhQ4cGO1Yhwk5FBaxaBd9/bwJ3YNq50zxvscA555ggfvHFpnYecMEFh28rKqrRin6imlXAr6sm3phiY2Mrl5cuXcpnn33GihUriImJYeTIkbX2e4+q9qGwWq1HbdI5kg8//JDly5fzwQcf8Nhjj7Fu3TqmT5/O+eefz0cffURmZiaffPIJp5xyynFtX4iwU1YGK1fC8uWwbBmsWAGB72hCApxyimmy6dHDLJ92mrmIWh/NKNhDMwv4oRAfH19nm3hhYSHJycnExMSwefNmVq5cecL7TExMJDk5mS+++ILhw4fz+uuvc8YZZ+Dz+dixYwdnnnkmp59+Om+99RYlJSXs37+f9PR00tPT+e6779i8ebMEfBGeCgvhm2/MhdHo6LrXzcuD//s/+Mc/wOUybeYZGXDzzTBiBJx6qmmfj6B7VSTgH0VqaiqZmZn06dOH8847j/PPP7/G86NHj+b555+nZ8+e9OjRg6FDhzbIfufNm8fNN99MaWkpXbt25ZVXXsHr9XLVVVdRWFiI1prbb7+dpKQkHnjgAZYsWYLFYqF3796cd955DVIGIRpFbm7VRc0j2bbNdHl88UXTK6ZdO9Mj5sYb4dA8UT4fvPKK6eZYVARTpsB555kLrZHea05r3WSmgQMH6kNt3LjxsMfEsZH3UDQpRUVaf/CB1rffrnXPnqZjYlSU1sOHaz1jhtYff2zW0Vrrb77ReuJEra1WM115pdZvvql1ZqZ5XdeuWr/+utYej1n/f//T+rTTzHOnn671+vWhO85GAqzS9YyxUsMXQjSOV16BuXNNe7rHY5pkRoyAa681tfwvvoBZs0yfdosFOnc2PWUSEuDOO+G226BjR7OtiRPh3/+GGTPg6qvN64YPN78AkpLMfq691mxHVAp6wFdKWYFVwE6t9QVHW18IEYYefdQ0waSnm77r555rLo4e2oxTUlJ1gfX77+H2202zTfWeMmDa3ceMgdGjYcECs+3nnzfrPv646S8vDtMYNfw7gE1AQiPsSwjR1Dz0kOniePXVppZvtR553bg40yXynHPqt22LBS67DMaPh/x8c1OUOKKg/t5RSnUAzgdeCuZ+hBBNkNbw+9+bYH/ttUcP9ifCZpNgXw/BbuB6BrgH8AV5P0KIpkRrePBBePhhuP56ePnl4AV7UW9Ba9JRSl0A7NNar1ZKjaxjvSnAFIBOnToFqzhCiIbkdpsLo19/DV27Vt20dPLJ5mLsjBnwxz+afDMvvCAXT5uIYLbhZwJjlVJjACeQoJT6h9a6RgIZrfUcYA7AoEGDdBDL02ji4uIoKSmp9+NCNAlvvgl/+IPpr37TTeYmpUP5fPDOOyZZ2Nat0KqV6WGjq31127QxWSKnTIHnnpNg34QE7T+htb5Xa91Ba50GXA7899BgL4RoAtxu0+3xyivN8quvQv/+5k7UuXPNQB5aw8cfw8CBJpFYTAz8618msB88CD/8YE4EjzxiLrg+9pgE+yZI/htHMX36dGbPnl3598yZM3nyyScpKSnh7LPPZsCAAaSnp7N48eJ6b1NrzbRp0+jTpw/p6em8/fbbAOzevZsRI0aQkZFBnz59+OKLL/B6vVx33XWV6z799NMNfowigu3da7pIPv206QK5bp1JIvbMM+aO1htvNHe1Dh5s7lYtLDSpCtauhfPPN90jo6Ohb1+YMMHU/F9/He67T4J9E9QoN15prZcCS094Q1Onmg9aQ8rIMB/uI5g4cSJTp07l1ltvBeCdd97hk08+wel0smjRIhISEsjLy2Po0KGMHTu2XmPIvvvuu6xdu5YffviBvLw8Bg8ezIgRI5g/fz6/+tWvmDFjBl6vl9LSUtauXcvOnTtZv349QGVKZCFO2MqVcOmlZlCP11+HQLrulBS44w5zAvjiC5gzx/SJ/9vfYPJkcDhCW25x3ORO26Po378/+/btY9euXeTm5pKcnEzHjh1xu93cd999LF++HIvFws6dO9m7dy9t6pFl78svv+SKK67AarXSunVrzjjjDL777jsGDx7MDTfcgNvtZty4cWRkZNC1a1d+/vlnbrvtNs4//3xGjRrVCEctwlp5Obz0kmnG6dDBZI/s1+/w9ZQyd8KOGNH4ZRRB0bwCfh018WCaMGECCxYsYM+ePUycOBGAN954g9zcXFavXo3dbictLa3WtMjHYsSIESxfvpwPP/yQ6667jjvvvJNrrrmGH374gU8++YTnn3+ed955h7lz5zbEYYlIUlEBn35q2tkXLzbNNaNHwxtvmBq9iAjNK+CHyMSJE5k8eTJ5eXksW7YMMGmRW7Vqhd1uZ8mSJWzbtq3e2xs+fDgvvPAC1157LQcOHGD58uU88cQTbNu2jQ4dOjB58mQqKipYs2YNY8aMweFwcMkll9CjR486R8kSoobcXDNM36JF8N57JnNkcrK5M3XCBNN2L+3sEUUCfj307t2b4uJi2rdvT9u2bQGYNGkSF154Ienp6QwaNOiY8s9ffPHFrFixgn79+qGU4k9/+hNt2rRh3rx5PPHEE9jtduLi4njttdfYuXMn119/PT6fuXftj3/8Y1COUTRzPp8Ztemrr0zf+K+/hh9/NM8lJprUA5ddZgb6kDb4iKW0bjpd3wcNGqRXrVpV47FNmzbRs2fPEJUoPMh7GEYWLDBTfr6ZDhww84ICE/QBWrQwickC05AhzW5kJlF/SqnVWutB9VlXavhCNAc+n+nq+Pjj0L69mVJToVs300yTnAwnnQSZmdC9e0SN4iTqTwK+EE1dSYnpMrl4sbkD9q9/PXyUJyHqQQK+EE3Ztm0wdiysX2+G+Pvtb6X2Lo6bBHwhmqqvvoKLLzYDcP/73yD3YIgTJH2yhGhK3G74/HNzl+tZZ5nh+r75RoK9aBBSwxci1AoLTWKyxYvho4/M306n6Uo5e7bcGCUajNTwj6KgoIC///3vx/XaMWPGSO4bcWQ//ADXXGNGarr8cvjsM7jkEnOTVF6eSVcswV40IAn4R1FXwPd4PHW+9qOPPiIpKSkYxRLNldYmxcGoUSZx36JF8JvfmPb63bvNyFAXXQSxsaEuqQhDEvCPYvr06WzdupWMjAymTZvG0qVLGT58OGPHjqVXr14AjBs3joEDB9K7d2/mzJlT+dq0tDTy8vLIzs6mZ8+eTJ48md69ezNq1CjKysoO29cHH3zAqaeeSv/+/TnnnHPYu3cvACUlJVx//fWkp6fTt29fFi5cCMDHH3/MgAED6NevH2effXYjvBviuLndJiNlRgb86lem180f/wjbt8Nf/mJukJIhAEWQNas2/BBkR2bWrFmsX7+etf4dL126lDVr1rB+/Xq6dOkCwNy5c0lJSaGsrIzBgwdzySWXkJqaWmM7WVlZvPnmm7z44otcdtllLFy48LC8OKeffjorV65EKcVLL73En/70J5566ikeeeQREhMTWbduHQD5+fnk5uYyefJkli9fTpcuXThw4EADviuiwVRUwLx5MGsW/PIL9OplBhW58kq5+1U0umYV8JuKIUOGVAZ7gGeffZZFixYBsGPHDrKysg4L+F26dCHDP2TcwIEDyc7OPmy7OTk5TJw4kd27d+NyuSr38dlnn/HWW29VrpecnMwHH3zAiBEjKtdJkbbepqWszDTPPP445OSYAUSeeQYuuEASlomQaVYBP0TZkQ8TW619denSpXz22WesWLGCmJgYRo4cWWua5KhqtTmr1Vprk85tt93GnXfeydixY1m6dCkzZ84MSvlFEOXmmhr9U0+Z4f8yM03u+VGj5IYpEXJS1TiK+Ph4iouLj/h8YWEhycnJxMTEsHnzZlauXHnc+yosLKR9+/YAzJs3r/Lxc889t8Ywi/n5+QwdOpTly5fzyy+/AEiTTii5XObi67hxZjjAadNM082SJWbEqF/9SoK9aBIk4B9FamoqmZmZ9OnTh2nTph32/OjRo/F4PPTs2ZPp06czdOjQ497XzJkzmTBhAgMHDqRFixaVj99///3k5+fTp08f+vXrx5IlS2jZsiVz5sxh/Pjx9OvXr3JgFtFIiopMML/9dhPkx483N0hNnWrGhf38cxg5UgK9aFIkPXIEkPfwBGgNW7bAqlWmZ826dWa+fbt5PirKdKO89lrTbGNrVq2kIgxIemQhTkR+vqmhf/KJmXbsMI/b7dCzJ5x+OvTpA717w/DhJjWxEM2ABHwhALxeeOUV07Pm229N/vmEBDNC1IwZJsiffLKkJRbNmgR8Ib75xqQdXrXK3Jhx//2meebUU6WJRoQV+TSLyJWbC9Onmxuh2rWD+fNNThu50CrClPTSEZHH44G//c000bz2mulGuXkzXHGFBHsR1qSGLyLL99/D5MmwejWcc44ZLvCUU0JdKiEahdTwgyAuLi7URRCHKi01NfnBg02qg7ffNlkrJdiLCCI1fBH+Pv0Ubr7ZJC+bPNnkt5GulCICSQ3/KKZPn14jrcHMmTN58sknKSkp4eyzz2bAgAGkp6ezePHio27rSGmUa0tzfKSUyOIY/PQTXH21SW3gcMCyZTBnjgR7EbGaVQ1/6sdTWbunYfMjZ7TJ4JnRR87KNnHiRKZOncqtt94KwDvvvMMnn3yC0+lk0aJFJCQkkJeXx9ChQxk7diyqjot+taVR9vl8taY5ri0lsqiHigozYtSLL5qbp+x2eOABuO8+M2ygEBGsWQX8UOjfvz/79u1j165d5ObmkpycTMeOHXG73dx3330sX74ci8XCzp072bt3L23atDnitmpLo5ybm1trmuPaUiKLOmRlmdr7q6+a4QE7d4ZHH4XrrzddLoUQzSvg11UTD6YJEyawYMEC9uzZU5mk7I033iA3N5fVq1djt9tJS0urNS1yQH3TKItj9NNP8OCDZvxXm83ktZkyxfTAkbzzQtQg34h6mDhxIm+99RYLFixgwoQJgEll3KpVK+x2O0uWLGHbtm11buNIaZSPlOa4tpTIoprdu+GWW0xum8WL4d57Tc6bBQvMXbIS7IU4jHwr6qF3794UFxfTvn172rZtC8CkSZNYtWoV6enpvPbaa5xylO59R0qjfKQ0x7WlRBZAQYFpjz/pJNNOP2WKqeX/4Q9QR3OaEELSI0eEsHkPV6wwTTa5uWZM2IcfNoFfiAgm6ZFF+Fm82OS56dDBpCzu3z/UJRKi2ZEmHdH0PfecGVGqb1/4+msJ9kIcp2YR8JtSs1Nz06zfO63NxdhbboExY+C//4WWLUNdKiGaraAFfKWUUyn1rVLqB6XUBqXUQ8ezHafTyf79+5t34AoRrTX79+/H2RxvOHK5zLCBs2aZC7OLFkFsbKhLJUSzFsw2/ArgLK11iVLKDnyplPq31nrlsWykQ4cO5OTkkJubG5xShjmn00mHDh1CXYz609qkQJgxwzTfPPKIWZa0xUKcsKAFfG2q5CX+P+3+6Zir6Xa7vfIuVBHGtIYPPzTdK1esgNat4fXX4aqrQl0yIcJGUNvwlVJWpdRaYB/wH631N8Hcn2iGPB5zl2xGBlx4IezaBbNnm8yWEuyFaFBBDfhaa6/WOgPoAAxRSvU5dB2l1BSl1Cql1CpptokwX3xhAv2VV5o2+3nzTE6cW26B6OhQl06IsNMovXS01gXAEmB0Lc/N0VoP0loPaik9MCJDXh7ceCOMGAHFxfDOO7BhA1xzjcluKYQIimD20mmplEryL0cD5wKbg7U/0QxoDa+8YkaZeu01uOce2LgRJkyQ3DdCNIJg9tJpC8xTSlkxJ5Z3tNb/CuL+RFP2/fdwxx2mGScz09xMlZ4e6lIJEVGC2Uvnf4DcEhnJtIYlS8yQgp9+Cikp8NJLJke91OiFaHTyrRMNz+uFhQvh1FPh7LPhhx9Md8utW03bvQR7IUJCkqeJhvX++3D33aa3zUknwfPPmztmm+PdvkKEGalqiYaRn2962Vx0kRkw/O23YcsWuOkmCfZCNBFSwxcn7uOPTVPN3r1mwPD77zdBXwjRpEgNXxy/oiKYPBnOOw+SkmDlSjMoiQR7IZokCfji2Gltslf27Qtz55r+9KtXw6B6DbojhAgRadIRx+bbb+Guu+DLL6FXLzMfNizUpRJC1IPU8EX9ZGfDFVeYrpY//ggvvGC6W0qwF6LZkBq+qFtZGcycCc88A1aruSB7zz0QHx/qkgkhjpEEfHFkWVkmz80PP5i+9I8+agYRF0I0SxLwRe0WLIAbbjDZKz/80IwpK4Ro1qQNX9TkcpkkZxMmmIuy338vwV6IMCEBX1TZvt3kqH/2WZg6FZYvh06dQl0qIUQDkSadSOdymUyW8+fD4sVgs5nmnEsuCXXJhBANTAJ+JPJ6Te39zTdNcM/PN6mLr74apk0zSc+EEGFHAn4kKS83I049/jhs2waxsTBunBlT9txzZXhBIcKcBPxIUFJibpR66inYvRuGDjVB/8ILISYm1KUTQjQSCfjhrLAQ/vpXc9PU/v1w1lnwj3/AmWeCUqEunRCikUnAD1dLl8JVV8HOnXDBBTBjhqnZCyEilnTLDDceDzz4oKnNx8bCN9/ABx9IsBdCSA0/rGzfDpMmmQyW111nmnPi4kJdKiFEEyEBP1wsWmRGnfJ44I03TM8bIYSoRpp0mruKCvjtb2H8eNN//vvvJdgLIWoVFgHf7S7A5coNdTEa3y+/wOmnw+zZcOed8NVXctOUEOKImn3A93pLWbGiPTk5fw51URrX++/DgAEmhfGiRaaPvYwlK4SoQ7MP+FZrDImJmeTmLkRrHeriBJ/bbQYguegi6NoV1qwxd8sKIcRR1CvgK6XuUEolKONlpdQapdSoYBeuvlq2vISysixKSzeGuijBozWsXGm6Wz7xBPzmN6YJp2vXUJdMCNFM1LeGf4PWuggYBSQDVwOzglaqY5SaehGgyM1dGOqiHDuPxwTz2mhtBg2/+25ISzPjx65da3rh/P3v4HQ2alGFEM1bfbtlBu7DHwO8rrXeoFTTuTc/KqqNv1nnXdLSHgx1cepv5Uo47zwoLYU2baBt26q5zWZumNq2zSQ1GzUKHnkExo6FpKRQl1wI0QzVN+CvVkp9CnQB7lVKxQO+4BXr2LVoMZ6tW++krGwr0dHNoKfKrl2mK2VyMkyZAnv2mMRmW7eaG6eKi+Gcc+Chh0x7vQR5IcQJqm/AvxHIAH7WWpcqpVKA64NXrGPXosXFbN16J7m5i+jU6e5QF6du5eUm2BcVmcFH+vQ5fB2tJcGZEKJB1bcNfxiwRWtdoJS6CrgfKAxesY5ddHQacXEDyct7N9RFqZvWcMstJsfNa6/VHuxBgr0QosHVN+A/B5QqpfoBdwFbgdeCVqrj1LLleIqKVlBRsTPURTmyv/3NDELy4IOmli+EEI2kvgHfo00n94uAv2mtZwPxwSvWMfL3cmnRwgTQvLz3QlmaI1uyBH73O9Mm//vfh7o0QogIU9+AX6yUuhfTHfNDpZQFaBrj4ZWUmHzvb71FbOwpxMT0JDe3CTbrZGfDhAlw8smmKcfS7O95E0I0M/WNOhOBCkx//D1AB+CJoJXqWNhsJuhfcw0sWULLlpdQULAMlysv1CUzSkpg7lzTrdLrhcWLISEh1KUSQkSgegV8f5B/A0hUSl0AlGutm0YbvtMJ770H3bvDuHG02psOeNm///3QlSlww9SUKaZP/Y03mhPTokWmnEIIEQL1Ta1wGfAtMAG4DPhGKXVpMAt2TJKT4eOPIS6OmEvvJKGwQ2iadfLy4C9/gX794NRTzR2xEyaYFAgbNsDIkY1fJiGE8Ktvk84MYLDW+lqt9TXAEOCBul6glOqolFqilNqolNqglLrjRAtbp44d4d//RhUX03taGUXbP8XjKQrqLgHTTPPxxyawt2sHU6dCVBS88IK5kWruXDjtNOlmKYQIufreeGXRWu+r9vd+jn6y8AB3aa3X+O/MXa2U+o/WOngZzvr2hffew/GrUfS538P+9Pdo3fma4Oxr2zZ46SV49VXIyYHUVLj1VrjhBkhPD84+hRDiBNS3hv+xUuoTpdR1SqnrgA+Bj+p6gdZ6t9Z6jX+5GNgEtD+RwtbLmWfCq6+S9AM4b5oBvgbOAPHzz/DrX0O3bvCHP5jg/s9/ws6d8PTTEuyFEE1WfS/aTgPmAH390xyt9f/VdydKqTSgP/BNLc9NUUqtUkqtys1tmFGr1JWTyL1nGImf5KAzTzNJyk5UVpYZGPzkk+Ef/4CbbzYjTn30EVx6qWnGEUKIJkwFe9AQpVQcsAx4TGtd55XUQYMG6VWrVjXIfg/s/w/7nhhF91eSsO4rgIkTYdYsk2a4Pnw+2L4d1q+Ht9+G+fNNUL/5Zpg2zfS+EUKIEFNKrdZaD6rPunW24SulioHazggK0FrrOjuUK6XswELgjaMF+4aWlHwmWy7qzPoL29Hv03PNoCHvvWcuqt57r+kLX1ICe/eaTJV798KOHaY3zbp1Zl5SYjYWEwN33WWm1q0b8zCEEKLBBK2G78+XPw84oLWeWp/XNGQNHyAn52/89NNtZGR8QVJJGsyYYe5yjY01feVLSw9/UYsWph2+Tx8zpaebKS6uwcolhBAN5Vhq+MEM+KcDXwDrqMqdf5/W+ogXexs64Hu9paxc2ZmEhKGkp39gHlyzBl580dTa27QxNfbAvF07aNmywfYvhBDB1mBNOidCa/0lVSNlhYTVGkP79neQnf0AJSXriItLhwED4LnnQlksIYQIibDP4NW+/a1YrXFs3/54qIsihBAhFfYB325Ppm3bm9i37y3Kyn4JdXGEECJkwj7gA3Ts+DuUsrBjx1OhLooQQoRMRAT8qKj2tG59DXv2vIzLte/oLxBCiDAUEQEfoFOnafh8FeTkPBvqogghREhETMCPielBixbj2bVrduNk0RRCiCYmYgI+QKdO0/F4Cti1a06oiyKEEI0uogJ+QsIgkpPPISfnz/h8FaEujhBCNKqICvgAnTrdi8u1m5ycv4S6KEII0agiLuAnJ59FaupYsrMfprx8R6iLI4QQjSbiAj5At25/Abxs3XpXqIsihBCNJiIDfnR0Gp06zSA3958cOPBpqIsjhBCNIiIDPkDHjncTHd2NrKzb5AKuECIiRGzAt1qddOv2V8rKfmTHjj+HujhCCBF0ERvwAVJTR9OixXi2bXuE8vJtoS6OEEIEVUQHfIBu3Z4GFD/99LtQF0UIIYIq4gO+09mJzp0fIC9vEfv3/zvUxRFCiKCJ+IAP0LHjnURH9yAr6za83lrGuRVCiDAgAR+wWBycfPJzlJf/TFbWbaEujhBCBIUEfL/k5DPp3HkGe/bMZc+e10JdHCGEaHAS8Kvp3Pn3JCaewY8//oaDBzeFujhCCNGgJOBXY7HY6NVrPlZrLBs2TJD2fCFEWJGAf4ioqHb07PkPSks3kpV1e6iLI4QQDUYCfi1SUkb52/NfZs+e10NdHCGEaBAS8I/AtOeP4Mcfb5b2fCFEWJCAfwSmPf9Nf3v+pbjdBaEukhBCnBAJ+HWIimpHr15vUVaWxfr14/B6y0NdJCGEOG4S8I8iOfksTjllHoWFy9i06Sq09oa6SEIIcVwk4NdD69ZXcNJJfyZ21egcAAAa50lEQVQvbyFZWbejtQ51kYQQ4pjZQl2A5qJjx9/hcu1mx44ncDjakpZ2f6iLJIQQx0QC/jHo2nUWLtcesrMfwOFoQ7t2vw51kYQQot4k4B8DpSz06PEybncuP/54Ew5HK1q0GBvqYgkhRL1IG/4xsljs9Or1T+LjB7FhwwTy8t4PdZGEEKJeJOAfB5stjr59PyYurh8bNlzCvn0LQl0kIYQ4Kgn4x8luT6Zfv8+Ijz+VjRsvZ+/e+aEukhBC1EkC/gmw2RLo2/djkpKGs2nTVeze/UqoiySEEEckAf8E2WxxpKd/SHLyuWzZcgO7dr0Q6iIJIUStghbwlVJzlVL7lFLrg7WPpsJqjaFPn8Wkpl7Ajz/ezI4dfw51kYQQ4jDBrOG/CowO4vabFKvVSe/eC2nZ8lK2br2Ln366G619oS6WEEJUClrA11ovBw4Ea/tNkcXioFevt2jf/rfk5DzFpk2T8PkqQl0sIYQA5MarBqeUlW7dniUqqiM///x/uFx76N17EXZ7UqiLJkSTojV4veDx1L2O1uDzVS0HUlkpVXMCs73ANj2eqr+rb+/Q5UMfO3SfgblSYLEcPh26v8DcYgGrtWqy2cxjh5ZZKfNchw4n/p4eTcgDvlJqCjAFoFOnTiEuTcNQStGp0z1ERbVn8+brWbt2OOnp/8bpbIT/qDhuXi9U+H+QBb6QgS+o1wsuF7jdZh6YKiqgvLxqHlh2ucwX3+2uOfd6TQAJTIGA5HZXbTsw93oPD2pKmdeVlZl9VZ/7fCawHBpoAoHl0MB26LEEpkDZjhRsqwfKwPOHHlf1fVUPbj5f7YE40rVuDXv2BH8/IQ/4Wus5wByAQYMGhVUaytatJ2G3t2bDhvF8//0w0tM/JC6ub6iL1ay43VBSAsXFZl5SUhXkapsODbyB4BuYAkGurAyKiqCwsGp+8GBoj9XhALu9am61mscPDbgWC0RHm8nprJpbLFXBt6Ki9qAaCLyB/TkcEBdXtRzY76EnvNqmwPaqn2QCtd7qJ5nqJ4jqtd3AVP2kVF31WvWh5Tn0BBTYR/VtH1qrru09qH4c1R8LvKb6vgP/i0OnwH6q77v6/6L6r47q/8vq74/TWb/PyIkKecAPdykp55CRsZx1685nzZpT6d7977Rte32oi9VoPB7Iz4f9+6GgwATX4mIzDywHnj9woOa8qKiqxn2sbDaIiqqaAoE0MEVFQWIidOxo5gkJZh744h36095qrfn6QHB0Os22nM6qKSrKPG+zmXUC8+oBqPp0aE1ciGAJWsBXSr0JjARaKKVygN9rrV8O1v6asvj4DAYNWsPGjVeyZcsNFBYup3v32VitMaEu2jErKYG9e83Pz337IC8PcnPNvPpyIGgXFh59mzExkJoKKSlm3qePWU5KMrXP+HgzBZYDNdpDg2z15UDtWAhRJWgBX2t9RbC23Rw5HK3p1+9TsrMfZtu2RyguXkWvXv8kNvaUUBcNME0dOTmwYwfs3GmWd+6smvbsMYG+tLT218fFQYsWZkpNhZNPrhnEU1IgOdnUpKtP8fGm9iuECD5p0mlESlnp0uUhEhMz2bRpEmvWDObkk+fQunXjnBvz8yEry0xbt8Ivv0B2tpnv2GGaLqqLi4P27c102mnmwlJgatMGWrWCli1NkG+sNkghxPGTgB8CKSmjGDRoLRs3Xs6mTVeSn/8funV7Bpst4YS3ffAg/PQT/PijmbKyquZ5eTXXbdcOunSB4cPNPC0NOnWqCvIJJ14cIUQTIgE/RKKi2tOv33/Jzn6I7dv/SEHBEk45ZR5JSSPq9fr9+2HDBli/3sw3bTKBfefOmuu1a2eaV8aPh+7dzXL37ibAS61ciMgiAT+ELBY7Xbs+Smrq+WzadDVr146kY8e76NLlUSyWqMr1cnNh5Ur4+mtYtcoE+ep9dhMToWdPOOecqqB+8snQrRvExobgwIQQTZIE/CYgMXEYgwatZevWu8nOfpoVK7axf/+fWbOmA19/bZpowHTp69cPRo82PVl69zbz9u2lS58Q4ugk4IeQ1rB9u6m9f/ttHN988zxr1symrMz0KUxNLSEzM4bJky0MGwaDBpkuiUIIcTwk4DcirU1tfdmyqmnHDvNcVBQMGAA33WRlwIAiWra8n6iovxIfn0GPHnOJj+8f2sILIZo9CfhBlp0Nn39upqVLYfdu83irVjBiBNxzDwwbBn37Vu+PngA8S27uWWRl/YbVqwfTqdP/0bnzA1itcqVVCHF8JOA3sLy8qgD/+efw88/m8TZt4Mwz4YwzzNSjx9Hb3Vu2HEdS0hls3Xon27f/gby8RfTo8TKJicOCfyBCiLCjtG46+coGDRqkV61aFepiHBOtYcsWeP99M339tXksMRFGjoSzzzZTz54ndmH1wIFP2LJlMhUVObRufQ1du/6BqKh2DXYcQojmSSm1Wms9qF7rSsA/dl6vCezvvQcffGBuagLTBn/hhXDeeTBwoOlV05A8nmK2bXuUnJxnUMpGp07T6djxrmaZk0cI0TAk4AeBx2Musi5cCO++a/LKOBxw1lkwdixccIHJvNgYysp+ZuvWe8jLW0hUVAe6dp1Fq1ZXoJSMSS9EpDmWgC9t+HXw+UyQnz8fFi0yd7fGxMCYMXDppWYeH9/45YqO7kqfPgsoKFjOTz/9jk2briIn5y+kpT1ESspolHTKF0LUQgJ+LXJy4NVX4ZVXzEXX+HhTg7/0UnPTU0wTaUFJShrBwIHfsWfPa2Rnz2TdujHExw8hLe33pKScJ4FfCFGDNOn4ud2weDG8/DJ8+qmp3Z91Ftxwg8lD09RvePL5XOzZM49t2x6jomIb8fGDSUubKYFfiDB3LE06Ed/o6/OZJptevWDCBJOnZsYMkz74889h0qSmH+wBLBYH7dpN5tRTf+Tkk1/E7c5l3brzWb16EHv3voXPV8dI0UKIiBCxAV9rU6PPyDBBPSbGtNNnZ8PDD0PXrqEu4fExgf/XDBnyIz16vIzXW8KmTVfw7bfdycl5Fq83xAO3CiFCJiID/mefwdChMG6cGez6zTfh++/N3+EyNJ7FYqdt2xsYMmQTffq8h8PRnp9+uoMVKzry88/3U1Gx5+gbEUKElYgK+MXFcN11cO65JsXByy/Dxo1w+eVmMOlwpJSFFi0uYsCAL+nf/2uSkkayffsfWLmyExs3XkFBwRc0pes4QojgiZheOt9+C1deaYbze+AB004fFXX014WTxMRhJCa+S2lpFrt2PceePa+wb99bxMam067dLbRufRU2W1yoiymECJIwrddW8Xph1izIzASXyyQwe/jhyAv21cXEdKdbtz8zbNhOevR4CaVsZGX9hhUr2rFly2Ty85egtTfUxRRCNLCw7pa5cydcfTUsWQKXXQbPPw/R8eXsLt6NRmNVVizKgtVirVwOdGFU+OdKYVVWou3R2C32sOziqLWmqOgbdu16nry8hXi9JTgcbWnV6nJatbqS+PiBYXncTVGFp4L88nzyy/Lxai8nJZ9EtL0ZdBMLIY/PQ2F5IQfdB7EqKzaLDavFzG0WG1pryjxllLnLKPOUUe4pp8xdhucIPdcsyoLdasdmsWG3+OdWOxZlMTECVbWsVGWsqE6j8fq8eLX3iHOPz1O5bFVWhnU8vqSIcqct8N3/ijjr1kVUxG1myJ+y2Z6cTa+52ewpOf6LlRZlIdoWTbQ9mmhbNFaLFZfXRYWnApfXVTlZlIVoezROm5Nom39ujybKGkWULQqH1VFjOcYeQ6w9tsbcaXPi0z48Pg9unxuPz4PH58GnfdgsNhxWB3aLHbvVjt1iJ8YeQ4uYFjWmhKgElFJUeCoorCiksLyQgvICCivM/EDZAfLL8isDTH55KQddp1NSvpOS8l2UVTyDy/c0PuUgOboVreJPok1CF1KjU2kR04LEqETcPjflnvIak8vrqvX9c3vdlHpKKXWXctB1kFK3WdboyuOuPkVZ/e+V/30KHLNP+3D73Li8LtxeN26fG7fXfdjJO/Clr/H+OszcZrFRXFFMsauYooqiGlPgvQrMiyqKAEh0JpIQlVA1ORLwaA8lrpLKbRVXFFPiKsHr/4V0aIWqeiAKBCeNpqC8gPyyfA66a/aiUii6JHehZ4uenNLiFHq26ElqTKopZ7UyFlYUUuwq5qDrICWuksrpoPsgPu3DqqxYLf73xb/f+Kh4kp3JJEcnk+JMITk6mXhHPEUVRewv28+BsgOV86KKospAV307Vou18rPstDkrlyv/d4d85l1el3mfXUWV721RRRFlnrLK71KFt+r75LA6anznou3ROKwOiiuKKz/LJa6S4/5ONxWtY1uz5+7gd6QIuxr+hn0beHL5bOatfR1tL8FusdMpsRNpSWmkJaXRObEzHRI6YFEWfNpX44zr0z6g6kuqMXOPz1NZO6ice8rw+ryHBaVAQCr3lFeuF6hRVHgrKk8OgeUKbwVl7jIOuk0ALPeUn9ibWE0gqFR4K+pcz26xkxydTLIz2QTawBfWYgHvAbzuXRSU5VLkgSKPjUI3VHgPrx3ZLXacNid2q73WWo/VYiXWHlsZdANBGKDMU1Z5AgicEKp/8Y90ErFb7DisDmwWW43/Z2A58D+tjxh7DAlRCSRGJVYG98SoRBKjEgEOC1KFFYUmcDriiY+Kr5zHOeKwqaq6VODXkdYaH77Kk7fXZ2p5Gm0CrzOZlGgTeFOiU9Bas2X/FjbnbWZT3ia25G2p9X/ptDlJjDLljXXEEueIq5xi7bFYlKXyvaheuyyqKKpxwi8oL0CjsSgLyc5kUmNSSYlOITU6lYSoBIAa2wlUSAKf5XJPeY3PdW0B3GaxVZY1ISqBRGci8Y74ys+dw+Ko/PzZrXZcXleN71yZ25wY4qPiSYpKItGZSJIziSRnErH22MoyVZ+AGieMwNxusR/2XgaO0ePz4Pa6Kytcbq8bn/ah0fi0zyxrXefnK1D5ONI88EvEqqw4bU6Gdx5e789qdRFXw3d73by3+T1mfzebZduWobxRWDZfzks33cLVZw/Eamk+fS192kepu5Qyd1llTTDwk9KqrCil8Pq8lR/CQE33oOsg+8v2k1eaVznlHszFq70kOZMqg1hgHqjZBYL80ZpsXK695OYuYN++tyks/JJyL2hHT1qmnkPr1HNolTKSKHtC0N4XrXXlsVqUBYfVUfl+1MWnfTVOqIFfFm6fu0ZtPc4Rh83StL8OXp+XbYXbKCgvqHFSclgdDbJ9n/Zx0HWQWIc5STS0QEVKmgdDp9nX8Isriuk5uyc7i3eSlpRGwpbf8L95N7Dw9RaMHx+kgka4ioqd7Nv3T/LyFlFUtAKt3SjlIDHxNJKSziY5+Szi4gbI6FxCNIKIS4/84JIHGdJ+CF++eh6P/9HKE0/A3XcHoYDiMF7vQQoKvqCg4HPy8z+npGQtoFHKQVxcfxITh5GQMJSEhGFERXWU2p0QDSziAj7A3Llw440wZYrpjSNxJTTc7v0UFHxBUdEKiopWUFz8HT6fuS7hcLQjMTGTxMRMEhIyiYvLwNLEm1GEaOoiLuB//rlJW3zWWfCvf1UfDFyEms/npqTkh8oTQGHhl1RU7ADAYokhIeFUEhKGEh8/kLi4gTidneVXgBDHIKIC/v790K0btG8PX31lxpIVTVt5+Q4KC7+iqOgrCgu/4uDBdWhtelPYbCnExw8gLm4AcXH9iYvrS3T0yfJLQIgjiKheOqmp8NxzMGyYBPvmwunsiNN5Oa1bXw6A11vOwYPrKClZQ3HxaoqL15CT8wxam66YSkURG9uL2Ni+xMWlEx3dHaczDaczDZsteD2DhAg3zb6GL8KTz+eitHQzJSX/4+DB/1XOXa7dNdaz2ZL9wb8zDkd7oqLa4XC0IyqqrX/eDpstRZqJRNiKqBq+CE8Wi4O4uL7ExfWt8bjLlUd5+S+Ul2dXm7ZRWppFQcEyPJ78WrYVi9PZCaezM1FRnf3LaURHdyM6uht2e0pjHZYQISUBXzQrDkcLHI4WJCQMrvV5r7cMl2sPLtcuKip2U1GRQ0XFdsrLt1Fevo3i4lW43Xk1XmOzJVUGf4ejPVZrbOVksZi5zZaAzZaEzZbsnydhsTTMDU9CNBYJ+CKsWK3RREd3ITq6yxHX8XoPUl6eTVnZVsrKfvJPWykq+haXazc+X1m99mWxRGOzpWC3p1TO7fZUbLYUHI5WOBxtsNtb43C0weFojd2eigrCHaxC1JcEfBFxrNZYYmN7Exvbu9bntfbh9Zbi8x3E6w1MRXg8BTUmtzsfjycfj+cAbvd+Skt/rFwOXHCuyYLF4kApu3+yoZQdqzUau70VDkdbHI42/usPbbDZktHag8/nQms3Wrvx+VxYLE6czo5ERZnJZosP7hsmwoYEfCEOoZTFPxDM8Q0Go7XG6y3yNy3trZy73fvw+Sr8wduDzxcI4mW4XHspLd1IQcHneDwFx7Q/qzURp7MTNlugm5qqnJRSaO3zj2/gRWuvf1ljtcZhsyX7f6EkV06mKSsaqzUGiyXGP3dWO0lVn2p7zIaqR54j0fgk4AvRwJRS2GyJ2GyJxMT0OObXm+sQe/F4CrBY7ChlfhUEfh34fKWUl++gomKH//qEWfZ6SwANaH+iMo3WPswviyh/ELYCJhh7PMWUl2dTUvI9bvcBfL6GHeC+6pdMVdktligslmj/CSXav+z0l89R7ReQA4vF7j9ZeapNbrT2Vp5szPtTtQ9zzSWmxvUXs4+av6rMZIFasroqZTmk7GZu3k9P5UnTnDh9WCwx2GzxWCx1JyHU2ovPV/2XX9WYG6Aa5ZpQUAO+Umo08BfACryktZ4VzP0JEQ7MdYi0OtdxOjs3+H59PhceT4G/OasMn68Ur9fMfb7yWgKv+ZVifjkEfrFUf95doznK/F2Bz1dWuQ+vtxiXax9au6qt6/Jvy+U/SdX89QDWGvsw23WjdUXlDXyhYcFqjcNqjcdqja08Vp+vHJ+vDK3dR3yl3d6azMzg58MPWsBXpioxGzgXyAG+U0q9r7XeGKx9CiGOn8XiwOFoFepinBCfz43Xe7DG9RcTbGuepMyJofZhPE3t3V3Z5BaYwHLIrySbSVfuLcXrLcbjKcLrLfZPB2v9NWN+ralqA+OYudUa0xhvT1Br+EOAn7TWPwMopd4CLgIk4AshgsJisWOxJAFJoS5KkxTMPmLtgR3V/s7xPyaEECIEQt4pWCk1RSm1Sim1Kjc3N9TFEUKIsBXMgL8T6Fjt7w7+x2rQWs/RWg/SWg9q2bJlEIsjhBCRLZgB/zugu1Kqi1LKAVwOvB/E/QkhhKhD0C7aaq09SqnfAp9gumXO1VpvCNb+hBBC1C2o/fC11h8BHwVzH0IIIeon5BdthRBCNA4J+EIIESGa1IhXSqlcYNtxvrwFkHfUtZq/SDlOiJxjjZTjhMg51sY8zs5a63p1cWxSAf9EKKVW1XeYr+YsUo4TIudYI+U4IXKOtakepzTpCCFEhJCAL4QQESKcAv6cUBegkUTKcULkHGukHCdEzrE2yeMMmzZ8IYQQdQunGr4QQog6NPuAr5QarZTaopT6SSk1PdTlaUhKqblKqX1KqfXVHktRSv1HKZXlnyeHsowNQSnVUSm1RCm1USm1QSl1h//xcDxWp1LqW6XUD/5jfcj/eBel1Df+z/Hb/vxTzZ5SyqqU+l4p9S//3+F6nNlKqXVKqbVKqVX+x5rc57dZB/xqo2qdB/QCrlBK9QptqRrUq8DoQx6bDnyute4OfO7/u7nzAHdprXsBQ4Fb/f/HcDzWCuAsrXU/IAMYrZQaCjwOPK217gbkAzeGsIwN6Q5gU7W/w/U4Ac7UWmdU647Z5D6/zTrgU21ULa21CwiMqhUWtNbLgQOHPHwRMM+/PA8Y16iFCgKt9W6t9Rr/cjEmQLQnPI9Va61L/H/a/ZMGzgIW+B8Pi2NVSnUAzgde8v+tCMPjrEOT+/w294AfiaNqtdZa7/Yv7wFah7IwDU0plQb0B74hTI/V38yxFtgH/AfYChToqhG4w+Vz/AxwD+Dz/51KeB4nmJP2p0qp1UqpKf7HmtznN6jZMkVwaa21UipsulkppeKAhcBUrXWRqRAa4XSsWmsvkKGUSgIWAaeEuEgNTil1AbBPa71aKTUy1OVpBKdrrXcqpVoB/1FKba7+ZFP5/Db3Gn69RtUKM3uVUm0B/PN9IS5Pg1BK2THB/g2t9bv+h8PyWAO01gXAEmAYkKSUClTAwuFznAmMVUplY5pazwL+QvgdJwBa653++T7MSXwITfDz29wDfiSOqvU+cK1/+VpgcQjL0iD8bbsvA5u01n+u9lQ4HmtLf80epVQ0cC7mmsUS4FL/as3+WLXW92qtO2it0zDfy/9qrScRZscJoJSKVUrFB5aBUcB6muDnt9nfeKWUGoNpKwyMqvVYiIvUYJRSbwIjMZn39gK/B94D3gE6YTKLXqa1PvTCbrOilDod+AJYR1V7732YdvxwO9a+mAt4VkyF6x2t9cNKqa6YmnAK8D1wlda6InQlbTj+Jp27tdYXhONx+o9pkf9PGzBfa/2YUiqVJvb5bfYBXwghRP009yYdIYQQ9SQBXwghIoQEfCGEiBAS8IUQIkJIwBdCiAghAV+IBqCUGhnICClEUyUBXwghIoQEfBFRlFJX+fPRr1VKveBPZFailHran5/+c6VUS/+6GUqplUqp/ymlFgXymSuluimlPvPntF+jlDrJv/k4pdQCpdRmpdQbqnoyICGaAAn4ImIopXoCE4FMrXUG4AUmAbHAKq11b2AZ5o5mgNeA/9Na98XcBRx4/A1gtj+n/WlAICNif2AqZmyGrph8MkI0GZItU0SSs4GBwHf+ync0JqGVD3jbv84/gHeVUolAktZ6mf/xecA//TlT2mutFwForcsB/Nv7Vmud4/97LZAGfBn8wxKifiTgi0iigHla63trPKjUA4esd7z5RqrnhPEi3y/RxEiTjogknwOX+nOWB8Yc7Yz5HgQyOF4JfKm1LgTylVLD/Y9fDSzzj8iVo5Qa599GlFIqplGPQojjJDUQETG01huVUvdjRiayAG7gVuAgMMT/3D5MOz+YlLbP+wP6z8D1/sevBl5QSj3s38aERjwMIY6bZMsUEU8pVaK1jgt1OYQINmnSEUKICCE1fCGEiBBSwxdCiAghAV8IISKEBHwhhIgQEvCFECJCSMAXQogIIQFfCCEixP8Drpb20CgjklUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 480us/sample - loss: 1.9484 - acc: 0.3961\n",
      "Loss: 1.9483548640214519 Accuracy: 0.396054\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2864 - acc: 0.2793\n",
      "Epoch 00001: val_loss improved from inf to 1.96475, saving model to model/checkpoint/1D_CNN_3_conv_custom_conv_3_DO_checkpoint/001-1.9647.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 2.2864 - acc: 0.2793 - val_loss: 1.9647 - val_acc: 0.4118\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8070 - acc: 0.4499\n",
      "Epoch 00002: val_loss improved from 1.96475 to 1.73310, saving model to model/checkpoint/1D_CNN_3_conv_custom_conv_3_DO_checkpoint/002-1.7331.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.8069 - acc: 0.4499 - val_loss: 1.7331 - val_acc: 0.4715\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5986 - acc: 0.5164\n",
      "Epoch 00003: val_loss improved from 1.73310 to 1.68981, saving model to model/checkpoint/1D_CNN_3_conv_custom_conv_3_DO_checkpoint/003-1.6898.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.5987 - acc: 0.5164 - val_loss: 1.6898 - val_acc: 0.4738\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4546 - acc: 0.5578\n",
      "Epoch 00004: val_loss improved from 1.68981 to 1.64330, saving model to model/checkpoint/1D_CNN_3_conv_custom_conv_3_DO_checkpoint/004-1.6433.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.4546 - acc: 0.5578 - val_loss: 1.6433 - val_acc: 0.4880\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3361 - acc: 0.5925\n",
      "Epoch 00005: val_loss improved from 1.64330 to 1.62902, saving model to model/checkpoint/1D_CNN_3_conv_custom_conv_3_DO_checkpoint/005-1.6290.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.3361 - acc: 0.5925 - val_loss: 1.6290 - val_acc: 0.4941\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2430 - acc: 0.6251\n",
      "Epoch 00006: val_loss did not improve from 1.62902\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.2430 - acc: 0.6251 - val_loss: 1.6561 - val_acc: 0.4962\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1558 - acc: 0.6478\n",
      "Epoch 00007: val_loss improved from 1.62902 to 1.61623, saving model to model/checkpoint/1D_CNN_3_conv_custom_conv_3_DO_checkpoint/007-1.6162.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.1558 - acc: 0.6478 - val_loss: 1.6162 - val_acc: 0.5059\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0834 - acc: 0.6685\n",
      "Epoch 00008: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.0835 - acc: 0.6685 - val_loss: 1.6275 - val_acc: 0.5076\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0103 - acc: 0.6908\n",
      "Epoch 00009: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.0102 - acc: 0.6908 - val_loss: 1.6646 - val_acc: 0.5036\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9479 - acc: 0.7111\n",
      "Epoch 00010: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.9478 - acc: 0.7112 - val_loss: 1.6706 - val_acc: 0.5048\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8888 - acc: 0.7275\n",
      "Epoch 00011: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.8889 - acc: 0.7275 - val_loss: 1.6689 - val_acc: 0.5087\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8281 - acc: 0.7477\n",
      "Epoch 00012: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.8281 - acc: 0.7478 - val_loss: 1.6758 - val_acc: 0.5055\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7808 - acc: 0.7614\n",
      "Epoch 00013: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.7809 - acc: 0.7614 - val_loss: 1.7002 - val_acc: 0.5208\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7282 - acc: 0.7772\n",
      "Epoch 00014: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.7282 - acc: 0.7771 - val_loss: 1.7147 - val_acc: 0.5222\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6788 - acc: 0.7911\n",
      "Epoch 00015: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.6788 - acc: 0.7911 - val_loss: 1.7060 - val_acc: 0.5260\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6362 - acc: 0.8046\n",
      "Epoch 00016: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.6361 - acc: 0.8046 - val_loss: 1.7713 - val_acc: 0.5274\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5895 - acc: 0.8192\n",
      "Epoch 00017: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.5895 - acc: 0.8192 - val_loss: 1.7611 - val_acc: 0.5241\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5532 - acc: 0.8298\n",
      "Epoch 00018: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.5532 - acc: 0.8298 - val_loss: 1.7988 - val_acc: 0.5262\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5124 - acc: 0.8421\n",
      "Epoch 00019: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.5125 - acc: 0.8421 - val_loss: 1.8235 - val_acc: 0.5367\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4818 - acc: 0.8519\n",
      "Epoch 00020: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4818 - acc: 0.8519 - val_loss: 1.8551 - val_acc: 0.5297\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4554 - acc: 0.8572\n",
      "Epoch 00021: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4554 - acc: 0.8572 - val_loss: 1.8407 - val_acc: 0.5418\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4185 - acc: 0.8730\n",
      "Epoch 00022: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4184 - acc: 0.8731 - val_loss: 1.9056 - val_acc: 0.5411\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3941 - acc: 0.8783\n",
      "Epoch 00023: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3940 - acc: 0.8784 - val_loss: 1.9212 - val_acc: 0.5369\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3799 - acc: 0.8813\n",
      "Epoch 00024: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3799 - acc: 0.8813 - val_loss: 1.9879 - val_acc: 0.5367\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3550 - acc: 0.8903\n",
      "Epoch 00025: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3550 - acc: 0.8903 - val_loss: 1.9842 - val_acc: 0.5406\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3303 - acc: 0.8977\n",
      "Epoch 00026: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3303 - acc: 0.8977 - val_loss: 2.0385 - val_acc: 0.5369\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3134 - acc: 0.9045\n",
      "Epoch 00027: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.3134 - acc: 0.9045 - val_loss: 2.0378 - val_acc: 0.5483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2985 - acc: 0.9067\n",
      "Epoch 00028: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2985 - acc: 0.9067 - val_loss: 2.0463 - val_acc: 0.5476\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2812 - acc: 0.9120\n",
      "Epoch 00029: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2812 - acc: 0.9121 - val_loss: 2.0578 - val_acc: 0.5560\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2725 - acc: 0.9145\n",
      "Epoch 00030: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2725 - acc: 0.9145 - val_loss: 2.1180 - val_acc: 0.5504\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2536 - acc: 0.9224\n",
      "Epoch 00031: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2536 - acc: 0.9224 - val_loss: 2.1134 - val_acc: 0.5511\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2397 - acc: 0.9268\n",
      "Epoch 00032: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2397 - acc: 0.9268 - val_loss: 2.1505 - val_acc: 0.5539\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2376 - acc: 0.9264\n",
      "Epoch 00033: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2376 - acc: 0.9265 - val_loss: 2.1920 - val_acc: 0.5460\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2201 - acc: 0.9327\n",
      "Epoch 00034: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2201 - acc: 0.9326 - val_loss: 2.2318 - val_acc: 0.5509\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9361\n",
      "Epoch 00035: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2073 - acc: 0.9361 - val_loss: 2.2399 - val_acc: 0.5490\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2017 - acc: 0.9381\n",
      "Epoch 00036: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2018 - acc: 0.9381 - val_loss: 2.2718 - val_acc: 0.5518\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1929 - acc: 0.9422\n",
      "Epoch 00037: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1929 - acc: 0.9422 - val_loss: 2.2765 - val_acc: 0.5597\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9408\n",
      "Epoch 00038: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1926 - acc: 0.9408 - val_loss: 2.3158 - val_acc: 0.5472\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9451\n",
      "Epoch 00039: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1810 - acc: 0.9451 - val_loss: 2.3518 - val_acc: 0.5523\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1699 - acc: 0.9499\n",
      "Epoch 00040: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1699 - acc: 0.9499 - val_loss: 2.3746 - val_acc: 0.5574\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9507\n",
      "Epoch 00041: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1679 - acc: 0.9507 - val_loss: 2.3542 - val_acc: 0.5593\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9483\n",
      "Epoch 00042: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1692 - acc: 0.9483 - val_loss: 2.4835 - val_acc: 0.5530\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9520\n",
      "Epoch 00043: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1589 - acc: 0.9520 - val_loss: 2.3967 - val_acc: 0.5546\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9570\n",
      "Epoch 00044: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1455 - acc: 0.9570 - val_loss: 2.4535 - val_acc: 0.5586\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1470 - acc: 0.9564\n",
      "Epoch 00045: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1470 - acc: 0.9564 - val_loss: 2.4704 - val_acc: 0.5572\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1436 - acc: 0.9579\n",
      "Epoch 00046: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1436 - acc: 0.9579 - val_loss: 2.4632 - val_acc: 0.5504\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9569\n",
      "Epoch 00047: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1396 - acc: 0.9569 - val_loss: 2.5028 - val_acc: 0.5528\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9606\n",
      "Epoch 00048: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1352 - acc: 0.9605 - val_loss: 2.5319 - val_acc: 0.5563\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1347 - acc: 0.9599\n",
      "Epoch 00049: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1346 - acc: 0.9599 - val_loss: 2.4988 - val_acc: 0.5593\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9619\n",
      "Epoch 00050: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1299 - acc: 0.9619 - val_loss: 2.5351 - val_acc: 0.5586\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.9652\n",
      "Epoch 00051: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1185 - acc: 0.9652 - val_loss: 2.5402 - val_acc: 0.5637\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9640\n",
      "Epoch 00052: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1196 - acc: 0.9640 - val_loss: 2.5397 - val_acc: 0.5616\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9667\n",
      "Epoch 00053: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1147 - acc: 0.9667 - val_loss: 2.5265 - val_acc: 0.5679\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9675\n",
      "Epoch 00054: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1133 - acc: 0.9675 - val_loss: 2.6093 - val_acc: 0.5577\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9661\n",
      "Epoch 00055: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1164 - acc: 0.9661 - val_loss: 2.6187 - val_acc: 0.5614\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9684\n",
      "Epoch 00056: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1105 - acc: 0.9684 - val_loss: 2.5838 - val_acc: 0.5663\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9677\n",
      "Epoch 00057: val_loss did not improve from 1.61623\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1104 - acc: 0.9677 - val_loss: 2.6085 - val_acc: 0.5637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_3_conv_custom_conv_3_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 525us/sample - loss: 1.6956 - acc: 0.4795\n",
      "Loss: 1.6955603861734503 Accuracy: 0.4795431\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2507 - acc: 0.2878\n",
      "Epoch 00001: val_loss improved from inf to 1.85787, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/001-1.8579.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 2.2507 - acc: 0.2878 - val_loss: 1.8579 - val_acc: 0.4370\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6831 - acc: 0.4723\n",
      "Epoch 00002: val_loss improved from 1.85787 to 1.54766, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/002-1.5477.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 1.6831 - acc: 0.4723 - val_loss: 1.5477 - val_acc: 0.5204\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4670 - acc: 0.5419\n",
      "Epoch 00003: val_loss improved from 1.54766 to 1.41502, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/003-1.4150.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 1.4669 - acc: 0.5419 - val_loss: 1.4150 - val_acc: 0.5560\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3387 - acc: 0.5803\n",
      "Epoch 00004: val_loss improved from 1.41502 to 1.39177, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/004-1.3918.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 1.3387 - acc: 0.5803 - val_loss: 1.3918 - val_acc: 0.5495\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2486 - acc: 0.6115\n",
      "Epoch 00005: val_loss improved from 1.39177 to 1.29572, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/005-1.2957.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 1.2486 - acc: 0.6115 - val_loss: 1.2957 - val_acc: 0.5865\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1638 - acc: 0.6398\n",
      "Epoch 00006: val_loss improved from 1.29572 to 1.25731, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/006-1.2573.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 1.1638 - acc: 0.6399 - val_loss: 1.2573 - val_acc: 0.6010\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0915 - acc: 0.6629\n",
      "Epoch 00007: val_loss improved from 1.25731 to 1.22534, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/007-1.2253.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 1.0914 - acc: 0.6629 - val_loss: 1.2253 - val_acc: 0.6077\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0274 - acc: 0.6840\n",
      "Epoch 00008: val_loss improved from 1.22534 to 1.19662, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/008-1.1966.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 1.0273 - acc: 0.6840 - val_loss: 1.1966 - val_acc: 0.6110\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9701 - acc: 0.7036\n",
      "Epoch 00009: val_loss improved from 1.19662 to 1.18321, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/009-1.1832.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.9702 - acc: 0.7036 - val_loss: 1.1832 - val_acc: 0.6240\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9127 - acc: 0.7188\n",
      "Epoch 00010: val_loss improved from 1.18321 to 1.16049, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/010-1.1605.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.9127 - acc: 0.7188 - val_loss: 1.1605 - val_acc: 0.6334\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8661 - acc: 0.7336\n",
      "Epoch 00011: val_loss improved from 1.16049 to 1.15529, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/011-1.1553.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.8661 - acc: 0.7336 - val_loss: 1.1553 - val_acc: 0.6369\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8161 - acc: 0.7495\n",
      "Epoch 00012: val_loss improved from 1.15529 to 1.14279, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/012-1.1428.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.8160 - acc: 0.7495 - val_loss: 1.1428 - val_acc: 0.6424\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7657 - acc: 0.7634\n",
      "Epoch 00013: val_loss did not improve from 1.14279\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.7657 - acc: 0.7634 - val_loss: 1.1707 - val_acc: 0.6408\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7296 - acc: 0.7742\n",
      "Epoch 00014: val_loss did not improve from 1.14279\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.7295 - acc: 0.7742 - val_loss: 1.1619 - val_acc: 0.6438\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6842 - acc: 0.7878\n",
      "Epoch 00015: val_loss improved from 1.14279 to 1.13483, saving model to model/checkpoint/1D_CNN_4_conv_custom_conv_3_DO_checkpoint/015-1.1348.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.6841 - acc: 0.7879 - val_loss: 1.1348 - val_acc: 0.6578\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6469 - acc: 0.7983\n",
      "Epoch 00016: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.6469 - acc: 0.7983 - val_loss: 1.1571 - val_acc: 0.6490\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6086 - acc: 0.8109\n",
      "Epoch 00017: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.6087 - acc: 0.8109 - val_loss: 1.1555 - val_acc: 0.6557\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5782 - acc: 0.8198\n",
      "Epoch 00018: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.5782 - acc: 0.8198 - val_loss: 1.1708 - val_acc: 0.6590\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5406 - acc: 0.8307\n",
      "Epoch 00019: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.5405 - acc: 0.8307 - val_loss: 1.1836 - val_acc: 0.6585\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5183 - acc: 0.8368\n",
      "Epoch 00020: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.5184 - acc: 0.8368 - val_loss: 1.1681 - val_acc: 0.6718\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4855 - acc: 0.8492\n",
      "Epoch 00021: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.4855 - acc: 0.8493 - val_loss: 1.1843 - val_acc: 0.6683\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4629 - acc: 0.8511\n",
      "Epoch 00022: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.4628 - acc: 0.8511 - val_loss: 1.2070 - val_acc: 0.6622\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4371 - acc: 0.8625\n",
      "Epoch 00023: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.4371 - acc: 0.8625 - val_loss: 1.2232 - val_acc: 0.6641\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4195 - acc: 0.8669\n",
      "Epoch 00024: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.4195 - acc: 0.8669 - val_loss: 1.2174 - val_acc: 0.6716\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3960 - acc: 0.8748\n",
      "Epoch 00025: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.3961 - acc: 0.8748 - val_loss: 1.2357 - val_acc: 0.6692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3736 - acc: 0.8817\n",
      "Epoch 00026: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.3736 - acc: 0.8817 - val_loss: 1.2432 - val_acc: 0.6678\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3650 - acc: 0.8828\n",
      "Epoch 00027: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.3651 - acc: 0.8828 - val_loss: 1.2474 - val_acc: 0.6746\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3479 - acc: 0.8873\n",
      "Epoch 00028: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.3479 - acc: 0.8873 - val_loss: 1.2573 - val_acc: 0.6737\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3262 - acc: 0.8942\n",
      "Epoch 00029: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.3263 - acc: 0.8942 - val_loss: 1.2503 - val_acc: 0.6795\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3098 - acc: 0.8998\n",
      "Epoch 00030: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.3098 - acc: 0.8998 - val_loss: 1.2833 - val_acc: 0.6790\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3018 - acc: 0.9042\n",
      "Epoch 00031: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.3018 - acc: 0.9042 - val_loss: 1.2727 - val_acc: 0.6799\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2862 - acc: 0.9082\n",
      "Epoch 00032: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2862 - acc: 0.9082 - val_loss: 1.2636 - val_acc: 0.6883\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2729 - acc: 0.9116\n",
      "Epoch 00033: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2729 - acc: 0.9116 - val_loss: 1.3189 - val_acc: 0.6804\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2700 - acc: 0.9121\n",
      "Epoch 00034: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2700 - acc: 0.9121 - val_loss: 1.3048 - val_acc: 0.6858\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2564 - acc: 0.9177\n",
      "Epoch 00035: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2564 - acc: 0.9177 - val_loss: 1.3077 - val_acc: 0.6969\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2449 - acc: 0.9202\n",
      "Epoch 00036: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2449 - acc: 0.9202 - val_loss: 1.3335 - val_acc: 0.6902\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2367 - acc: 0.9221\n",
      "Epoch 00037: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2368 - acc: 0.9221 - val_loss: 1.3237 - val_acc: 0.6876\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2314 - acc: 0.9244\n",
      "Epoch 00038: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2315 - acc: 0.9243 - val_loss: 1.3240 - val_acc: 0.6860\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2258 - acc: 0.9265\n",
      "Epoch 00039: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2258 - acc: 0.9265 - val_loss: 1.3325 - val_acc: 0.6944\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2143 - acc: 0.9308\n",
      "Epoch 00040: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2143 - acc: 0.9308 - val_loss: 1.3823 - val_acc: 0.6897\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2125 - acc: 0.9311\n",
      "Epoch 00041: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2125 - acc: 0.9311 - val_loss: 1.3800 - val_acc: 0.6958\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2046 - acc: 0.9343\n",
      "Epoch 00042: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2046 - acc: 0.9343 - val_loss: 1.3730 - val_acc: 0.6923\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9360\n",
      "Epoch 00043: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.2021 - acc: 0.9360 - val_loss: 1.3809 - val_acc: 0.6953\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1890 - acc: 0.9385\n",
      "Epoch 00044: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1890 - acc: 0.9385 - val_loss: 1.3883 - val_acc: 0.7014\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1899 - acc: 0.9386\n",
      "Epoch 00045: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1899 - acc: 0.9386 - val_loss: 1.3908 - val_acc: 0.6995\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1870 - acc: 0.9388\n",
      "Epoch 00046: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1870 - acc: 0.9388 - val_loss: 1.4071 - val_acc: 0.7016\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9454\n",
      "Epoch 00047: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1722 - acc: 0.9454 - val_loss: 1.4970 - val_acc: 0.6918\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9436\n",
      "Epoch 00048: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1747 - acc: 0.9436 - val_loss: 1.4671 - val_acc: 0.6962\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9452\n",
      "Epoch 00049: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1689 - acc: 0.9452 - val_loss: 1.4213 - val_acc: 0.7046\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1683 - acc: 0.9456\n",
      "Epoch 00050: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1682 - acc: 0.9456 - val_loss: 1.4538 - val_acc: 0.6979\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1555 - acc: 0.9510\n",
      "Epoch 00051: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1554 - acc: 0.9510 - val_loss: 1.4501 - val_acc: 0.7035\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1575 - acc: 0.9488\n",
      "Epoch 00052: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1574 - acc: 0.9488 - val_loss: 1.4468 - val_acc: 0.7023\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9514\n",
      "Epoch 00053: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1533 - acc: 0.9514 - val_loss: 1.4327 - val_acc: 0.7039\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9506\n",
      "Epoch 00054: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1537 - acc: 0.9506 - val_loss: 1.5054 - val_acc: 0.6997\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9529\n",
      "Epoch 00055: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1488 - acc: 0.9528 - val_loss: 1.4773 - val_acc: 0.7065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9537\n",
      "Epoch 00056: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1460 - acc: 0.9537 - val_loss: 1.4637 - val_acc: 0.7079\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9536\n",
      "Epoch 00057: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1476 - acc: 0.9536 - val_loss: 1.4548 - val_acc: 0.7000\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9565\n",
      "Epoch 00058: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1382 - acc: 0.9566 - val_loss: 1.5130 - val_acc: 0.7032\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9580\n",
      "Epoch 00059: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1324 - acc: 0.9580 - val_loss: 1.5337 - val_acc: 0.6981\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9567\n",
      "Epoch 00060: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1376 - acc: 0.9567 - val_loss: 1.5004 - val_acc: 0.7079\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9604\n",
      "Epoch 00061: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1290 - acc: 0.9604 - val_loss: 1.4639 - val_acc: 0.7109\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9601\n",
      "Epoch 00062: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1276 - acc: 0.9601 - val_loss: 1.5201 - val_acc: 0.7077\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9591\n",
      "Epoch 00063: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1296 - acc: 0.9591 - val_loss: 1.5195 - val_acc: 0.7063\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9585\n",
      "Epoch 00064: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1310 - acc: 0.9585 - val_loss: 1.5116 - val_acc: 0.7105\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9613\n",
      "Epoch 00065: val_loss did not improve from 1.13483\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1225 - acc: 0.9613 - val_loss: 1.5054 - val_acc: 0.7123\n",
      "\n",
      "1D_CNN_4_conv_custom_conv_3_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 516us/sample - loss: 1.2561 - acc: 0.6278\n",
      "Loss: 1.2561477027082988 Accuracy: 0.6278297\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2041 - acc: 0.2888\n",
      "Epoch 00001: val_loss improved from inf to 1.76188, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/001-1.7619.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 2.2040 - acc: 0.2888 - val_loss: 1.7619 - val_acc: 0.4337\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5996 - acc: 0.4917\n",
      "Epoch 00002: val_loss improved from 1.76188 to 1.42912, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/002-1.4291.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.5996 - acc: 0.4916 - val_loss: 1.4291 - val_acc: 0.5637\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4130 - acc: 0.5540\n",
      "Epoch 00003: val_loss improved from 1.42912 to 1.30336, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/003-1.3034.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.4129 - acc: 0.5541 - val_loss: 1.3034 - val_acc: 0.5984\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2807 - acc: 0.6031\n",
      "Epoch 00004: val_loss improved from 1.30336 to 1.23830, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/004-1.2383.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.2806 - acc: 0.6031 - val_loss: 1.2383 - val_acc: 0.6198\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1785 - acc: 0.6355\n",
      "Epoch 00005: val_loss improved from 1.23830 to 1.15264, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/005-1.1526.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.1785 - acc: 0.6355 - val_loss: 1.1526 - val_acc: 0.6406\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0979 - acc: 0.6603\n",
      "Epoch 00006: val_loss improved from 1.15264 to 1.09816, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/006-1.0982.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.0979 - acc: 0.6603 - val_loss: 1.0982 - val_acc: 0.6576\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0275 - acc: 0.6835\n",
      "Epoch 00007: val_loss improved from 1.09816 to 1.06922, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/007-1.0692.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 1.0275 - acc: 0.6834 - val_loss: 1.0692 - val_acc: 0.6783\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9648 - acc: 0.7065\n",
      "Epoch 00008: val_loss improved from 1.06922 to 1.02138, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/008-1.0214.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.9647 - acc: 0.7065 - val_loss: 1.0214 - val_acc: 0.6846\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9088 - acc: 0.7217\n",
      "Epoch 00009: val_loss improved from 1.02138 to 0.98041, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/009-0.9804.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.9088 - acc: 0.7217 - val_loss: 0.9804 - val_acc: 0.6914\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8547 - acc: 0.7362\n",
      "Epoch 00010: val_loss improved from 0.98041 to 0.96641, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/010-0.9664.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.8547 - acc: 0.7362 - val_loss: 0.9664 - val_acc: 0.7063\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8089 - acc: 0.7527\n",
      "Epoch 00011: val_loss improved from 0.96641 to 0.94191, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/011-0.9419.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.8088 - acc: 0.7527 - val_loss: 0.9419 - val_acc: 0.7095\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7569 - acc: 0.7690\n",
      "Epoch 00012: val_loss did not improve from 0.94191\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.7569 - acc: 0.7690 - val_loss: 0.9609 - val_acc: 0.7140\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7194 - acc: 0.7812\n",
      "Epoch 00013: val_loss did not improve from 0.94191\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.7193 - acc: 0.7812 - val_loss: 0.9512 - val_acc: 0.7105\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6689 - acc: 0.7934\n",
      "Epoch 00014: val_loss did not improve from 0.94191\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.6689 - acc: 0.7934 - val_loss: 0.9520 - val_acc: 0.7133\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6356 - acc: 0.8025\n",
      "Epoch 00015: val_loss improved from 0.94191 to 0.92101, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/015-0.9210.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.6356 - acc: 0.8025 - val_loss: 0.9210 - val_acc: 0.7242\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.8148\n",
      "Epoch 00016: val_loss improved from 0.92101 to 0.91016, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/016-0.9102.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.6020 - acc: 0.8148 - val_loss: 0.9102 - val_acc: 0.7300\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5673 - acc: 0.8237\n",
      "Epoch 00017: val_loss did not improve from 0.91016\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.5673 - acc: 0.8237 - val_loss: 0.9105 - val_acc: 0.7389\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5341 - acc: 0.8346\n",
      "Epoch 00018: val_loss improved from 0.91016 to 0.90783, saving model to model/checkpoint/1D_CNN_5_conv_custom_conv_3_DO_checkpoint/018-0.9078.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.5341 - acc: 0.8347 - val_loss: 0.9078 - val_acc: 0.7354\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5059 - acc: 0.8430\n",
      "Epoch 00019: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.5060 - acc: 0.8430 - val_loss: 0.9351 - val_acc: 0.7347\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4821 - acc: 0.8499\n",
      "Epoch 00020: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4821 - acc: 0.8499 - val_loss: 0.9302 - val_acc: 0.7286\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4547 - acc: 0.8577\n",
      "Epoch 00021: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4546 - acc: 0.8578 - val_loss: 0.9661 - val_acc: 0.7365\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4335 - acc: 0.8644\n",
      "Epoch 00022: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4335 - acc: 0.8644 - val_loss: 0.9185 - val_acc: 0.7405\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4011 - acc: 0.8717\n",
      "Epoch 00023: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4011 - acc: 0.8717 - val_loss: 0.9566 - val_acc: 0.7358\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3799 - acc: 0.8789\n",
      "Epoch 00024: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3799 - acc: 0.8788 - val_loss: 1.0064 - val_acc: 0.7291\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3711 - acc: 0.8802\n",
      "Epoch 00025: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3711 - acc: 0.8802 - val_loss: 0.9634 - val_acc: 0.7438\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3538 - acc: 0.8885\n",
      "Epoch 00026: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3538 - acc: 0.8885 - val_loss: 0.9761 - val_acc: 0.7433\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3408 - acc: 0.8904\n",
      "Epoch 00027: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3408 - acc: 0.8904 - val_loss: 0.9676 - val_acc: 0.7405\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3198 - acc: 0.8955\n",
      "Epoch 00028: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3197 - acc: 0.8955 - val_loss: 1.0098 - val_acc: 0.7389\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3132 - acc: 0.8986\n",
      "Epoch 00029: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3132 - acc: 0.8986 - val_loss: 1.1110 - val_acc: 0.7242\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2940 - acc: 0.9055\n",
      "Epoch 00030: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2939 - acc: 0.9055 - val_loss: 0.9907 - val_acc: 0.7470\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2770 - acc: 0.9099\n",
      "Epoch 00031: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2770 - acc: 0.9099 - val_loss: 1.0803 - val_acc: 0.7328\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2721 - acc: 0.9118\n",
      "Epoch 00032: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2722 - acc: 0.9118 - val_loss: 1.0105 - val_acc: 0.7473\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2705 - acc: 0.9104\n",
      "Epoch 00033: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2705 - acc: 0.9104 - val_loss: 1.0164 - val_acc: 0.7459\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2547 - acc: 0.9172\n",
      "Epoch 00034: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2547 - acc: 0.9172 - val_loss: 1.0249 - val_acc: 0.7545\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2460 - acc: 0.9184\n",
      "Epoch 00035: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2460 - acc: 0.9184 - val_loss: 1.0412 - val_acc: 0.7524\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2393 - acc: 0.9226\n",
      "Epoch 00036: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2393 - acc: 0.9226 - val_loss: 1.0531 - val_acc: 0.7468\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.9219\n",
      "Epoch 00037: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2346 - acc: 0.9219 - val_loss: 1.0767 - val_acc: 0.7470\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9285\n",
      "Epoch 00038: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2230 - acc: 0.9285 - val_loss: 1.0803 - val_acc: 0.7456\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2149 - acc: 0.9294\n",
      "Epoch 00039: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2150 - acc: 0.9294 - val_loss: 1.1199 - val_acc: 0.7445\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2119 - acc: 0.9302\n",
      "Epoch 00040: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2119 - acc: 0.9302 - val_loss: 1.0646 - val_acc: 0.7563\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2075 - acc: 0.9322\n",
      "Epoch 00041: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2075 - acc: 0.9322 - val_loss: 1.0710 - val_acc: 0.7577\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1987 - acc: 0.9359\n",
      "Epoch 00042: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1987 - acc: 0.9359 - val_loss: 1.0610 - val_acc: 0.7624\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1924 - acc: 0.9383\n",
      "Epoch 00043: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1924 - acc: 0.9383 - val_loss: 1.1088 - val_acc: 0.7498\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1883 - acc: 0.9377\n",
      "Epoch 00044: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1882 - acc: 0.9377 - val_loss: 1.0933 - val_acc: 0.7591\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9413\n",
      "Epoch 00045: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1820 - acc: 0.9413 - val_loss: 1.1207 - val_acc: 0.7566\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1789 - acc: 0.9422\n",
      "Epoch 00046: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1789 - acc: 0.9422 - val_loss: 1.1035 - val_acc: 0.7556\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1743 - acc: 0.9422\n",
      "Epoch 00047: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1743 - acc: 0.9422 - val_loss: 1.0976 - val_acc: 0.7547\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9445\n",
      "Epoch 00048: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1712 - acc: 0.9445 - val_loss: 1.1033 - val_acc: 0.7643\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9453\n",
      "Epoch 00049: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1691 - acc: 0.9453 - val_loss: 1.1196 - val_acc: 0.7589\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1648 - acc: 0.9455\n",
      "Epoch 00050: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1648 - acc: 0.9455 - val_loss: 1.1143 - val_acc: 0.7610\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1588 - acc: 0.9480\n",
      "Epoch 00051: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1588 - acc: 0.9479 - val_loss: 1.1270 - val_acc: 0.7612\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9504\n",
      "Epoch 00052: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1548 - acc: 0.9504 - val_loss: 1.1123 - val_acc: 0.7626\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9490\n",
      "Epoch 00053: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1543 - acc: 0.9490 - val_loss: 1.1152 - val_acc: 0.7701\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1498 - acc: 0.9508\n",
      "Epoch 00054: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1498 - acc: 0.9508 - val_loss: 1.1287 - val_acc: 0.7612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9538\n",
      "Epoch 00055: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1451 - acc: 0.9538 - val_loss: 1.1143 - val_acc: 0.7619\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9534\n",
      "Epoch 00056: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1438 - acc: 0.9534 - val_loss: 1.1646 - val_acc: 0.7612\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1436 - acc: 0.9527\n",
      "Epoch 00057: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1436 - acc: 0.9527 - val_loss: 1.1362 - val_acc: 0.7661\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9545\n",
      "Epoch 00058: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1392 - acc: 0.9544 - val_loss: 1.1513 - val_acc: 0.7668\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9540\n",
      "Epoch 00059: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1441 - acc: 0.9541 - val_loss: 1.1085 - val_acc: 0.7694\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9533\n",
      "Epoch 00060: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1424 - acc: 0.9533 - val_loss: 1.1300 - val_acc: 0.7696\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9555\n",
      "Epoch 00061: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1362 - acc: 0.9555 - val_loss: 1.1352 - val_acc: 0.7736\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9554\n",
      "Epoch 00062: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1400 - acc: 0.9554 - val_loss: 1.1124 - val_acc: 0.7696\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9586\n",
      "Epoch 00063: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1295 - acc: 0.9586 - val_loss: 1.2188 - val_acc: 0.7580\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9595\n",
      "Epoch 00064: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1272 - acc: 0.9595 - val_loss: 1.1488 - val_acc: 0.7671\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9589\n",
      "Epoch 00065: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1301 - acc: 0.9589 - val_loss: 1.1137 - val_acc: 0.7738\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9610\n",
      "Epoch 00066: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1211 - acc: 0.9610 - val_loss: 1.1928 - val_acc: 0.7687\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9589\n",
      "Epoch 00067: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1269 - acc: 0.9589 - val_loss: 1.1807 - val_acc: 0.7692\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9610\n",
      "Epoch 00068: val_loss did not improve from 0.90783\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1202 - acc: 0.9610 - val_loss: 1.1454 - val_acc: 0.7731\n",
      "\n",
      "1D_CNN_5_conv_custom_conv_3_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 545us/sample - loss: 1.0106 - acc: 0.6941\n",
      "Loss: 1.0106030552434278 Accuracy: 0.694081\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3496 - acc: 0.2289\n",
      "Epoch 00001: val_loss improved from inf to 1.77711, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/001-1.7771.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 2.3495 - acc: 0.2289 - val_loss: 1.7771 - val_acc: 0.4300\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6689 - acc: 0.4556\n",
      "Epoch 00002: val_loss improved from 1.77711 to 1.46854, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/002-1.4685.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.6688 - acc: 0.4556 - val_loss: 1.4685 - val_acc: 0.5416\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4302 - acc: 0.5420\n",
      "Epoch 00003: val_loss improved from 1.46854 to 1.24704, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/003-1.2470.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.4301 - acc: 0.5420 - val_loss: 1.2470 - val_acc: 0.6240\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3121 - acc: 0.5860\n",
      "Epoch 00004: val_loss improved from 1.24704 to 1.15418, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/004-1.1542.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.3120 - acc: 0.5860 - val_loss: 1.1542 - val_acc: 0.6580\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2085 - acc: 0.6237\n",
      "Epoch 00005: val_loss improved from 1.15418 to 1.14998, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/005-1.1500.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.2086 - acc: 0.6236 - val_loss: 1.1500 - val_acc: 0.6243\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1251 - acc: 0.6504\n",
      "Epoch 00006: val_loss improved from 1.14998 to 1.03804, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/006-1.0380.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.1251 - acc: 0.6504 - val_loss: 1.0380 - val_acc: 0.6888\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0501 - acc: 0.6769\n",
      "Epoch 00007: val_loss improved from 1.03804 to 0.96350, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/007-0.9635.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.0501 - acc: 0.6769 - val_loss: 0.9635 - val_acc: 0.6997\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9820 - acc: 0.6993\n",
      "Epoch 00008: val_loss improved from 0.96350 to 0.92227, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/008-0.9223.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.9821 - acc: 0.6992 - val_loss: 0.9223 - val_acc: 0.7284\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9267 - acc: 0.7144\n",
      "Epoch 00009: val_loss improved from 0.92227 to 0.87717, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/009-0.8772.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.9266 - acc: 0.7144 - val_loss: 0.8772 - val_acc: 0.7356\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8860 - acc: 0.7289\n",
      "Epoch 00010: val_loss improved from 0.87717 to 0.83612, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/010-0.8361.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.8861 - acc: 0.7289 - val_loss: 0.8361 - val_acc: 0.7538\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8388 - acc: 0.7460\n",
      "Epoch 00011: val_loss improved from 0.83612 to 0.80367, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/011-0.8037.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.8387 - acc: 0.7460 - val_loss: 0.8037 - val_acc: 0.7645\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8001 - acc: 0.7571\n",
      "Epoch 00012: val_loss did not improve from 0.80367\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.8000 - acc: 0.7572 - val_loss: 0.8191 - val_acc: 0.7636\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7592 - acc: 0.7698\n",
      "Epoch 00013: val_loss improved from 0.80367 to 0.73542, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/013-0.7354.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.7591 - acc: 0.7698 - val_loss: 0.7354 - val_acc: 0.7892\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7251 - acc: 0.7799\n",
      "Epoch 00014: val_loss improved from 0.73542 to 0.70705, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/014-0.7071.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.7251 - acc: 0.7799 - val_loss: 0.7071 - val_acc: 0.7899\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7024 - acc: 0.7877\n",
      "Epoch 00015: val_loss improved from 0.70705 to 0.69394, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/015-0.6939.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.7024 - acc: 0.7877 - val_loss: 0.6939 - val_acc: 0.8020\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6652 - acc: 0.7988\n",
      "Epoch 00016: val_loss did not improve from 0.69394\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.6653 - acc: 0.7987 - val_loss: 0.7350 - val_acc: 0.7757\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6478 - acc: 0.8043\n",
      "Epoch 00017: val_loss improved from 0.69394 to 0.64742, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/017-0.6474.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.6478 - acc: 0.8043 - val_loss: 0.6474 - val_acc: 0.8192\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6206 - acc: 0.8133\n",
      "Epoch 00018: val_loss did not improve from 0.64742\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.6206 - acc: 0.8133 - val_loss: 0.6479 - val_acc: 0.8130\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5990 - acc: 0.8205\n",
      "Epoch 00019: val_loss improved from 0.64742 to 0.63535, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/019-0.6353.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5990 - acc: 0.8205 - val_loss: 0.6353 - val_acc: 0.8199\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5739 - acc: 0.8279\n",
      "Epoch 00020: val_loss did not improve from 0.63535\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5739 - acc: 0.8279 - val_loss: 0.6759 - val_acc: 0.8057\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5577 - acc: 0.8324\n",
      "Epoch 00021: val_loss improved from 0.63535 to 0.61788, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/021-0.6179.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5577 - acc: 0.8324 - val_loss: 0.6179 - val_acc: 0.8267\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5384 - acc: 0.8385\n",
      "Epoch 00022: val_loss did not improve from 0.61788\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5384 - acc: 0.8386 - val_loss: 0.6237 - val_acc: 0.8199\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5187 - acc: 0.8437\n",
      "Epoch 00023: val_loss improved from 0.61788 to 0.61592, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/023-0.6159.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5187 - acc: 0.8437 - val_loss: 0.6159 - val_acc: 0.8276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5017 - acc: 0.8472\n",
      "Epoch 00024: val_loss improved from 0.61592 to 0.59190, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/024-0.5919.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5018 - acc: 0.8472 - val_loss: 0.5919 - val_acc: 0.8362\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4852 - acc: 0.8532\n",
      "Epoch 00025: val_loss improved from 0.59190 to 0.56742, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/025-0.5674.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4852 - acc: 0.8532 - val_loss: 0.5674 - val_acc: 0.8404\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8592\n",
      "Epoch 00026: val_loss did not improve from 0.56742\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4675 - acc: 0.8591 - val_loss: 0.6404 - val_acc: 0.8239\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4570 - acc: 0.8632\n",
      "Epoch 00027: val_loss did not improve from 0.56742\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4570 - acc: 0.8632 - val_loss: 0.5969 - val_acc: 0.8337\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4420 - acc: 0.8658\n",
      "Epoch 00028: val_loss improved from 0.56742 to 0.55967, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/028-0.5597.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4421 - acc: 0.8658 - val_loss: 0.5597 - val_acc: 0.8430\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4286 - acc: 0.8692\n",
      "Epoch 00029: val_loss did not improve from 0.55967\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4286 - acc: 0.8692 - val_loss: 0.7071 - val_acc: 0.8013\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4236 - acc: 0.8702\n",
      "Epoch 00030: val_loss did not improve from 0.55967\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4236 - acc: 0.8702 - val_loss: 0.5851 - val_acc: 0.8395\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4082 - acc: 0.8746\n",
      "Epoch 00031: val_loss improved from 0.55967 to 0.55483, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/031-0.5548.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4083 - acc: 0.8746 - val_loss: 0.5548 - val_acc: 0.8474\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3934 - acc: 0.8789\n",
      "Epoch 00032: val_loss did not improve from 0.55483\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3934 - acc: 0.8789 - val_loss: 0.5846 - val_acc: 0.8400\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3809 - acc: 0.8840\n",
      "Epoch 00033: val_loss improved from 0.55483 to 0.53244, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/033-0.5324.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3809 - acc: 0.8841 - val_loss: 0.5324 - val_acc: 0.8572\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3691 - acc: 0.8874\n",
      "Epoch 00034: val_loss did not improve from 0.53244\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3691 - acc: 0.8874 - val_loss: 0.5930 - val_acc: 0.8388\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3625 - acc: 0.8885\n",
      "Epoch 00035: val_loss improved from 0.53244 to 0.52912, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/035-0.5291.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3625 - acc: 0.8885 - val_loss: 0.5291 - val_acc: 0.8544\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3511 - acc: 0.8917\n",
      "Epoch 00036: val_loss did not improve from 0.52912\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3511 - acc: 0.8917 - val_loss: 0.5379 - val_acc: 0.8546\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3389 - acc: 0.8939\n",
      "Epoch 00037: val_loss did not improve from 0.52912\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3389 - acc: 0.8939 - val_loss: 0.5330 - val_acc: 0.8546\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3367 - acc: 0.8953\n",
      "Epoch 00038: val_loss improved from 0.52912 to 0.52672, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/038-0.5267.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3367 - acc: 0.8953 - val_loss: 0.5267 - val_acc: 0.8574\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3199 - acc: 0.8986\n",
      "Epoch 00039: val_loss did not improve from 0.52672\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3203 - acc: 0.8986 - val_loss: 0.5574 - val_acc: 0.8505\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3086 - acc: 0.9033\n",
      "Epoch 00040: val_loss did not improve from 0.52672\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3087 - acc: 0.9032 - val_loss: 0.5388 - val_acc: 0.8553\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3114 - acc: 0.9025\n",
      "Epoch 00041: val_loss did not improve from 0.52672\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3114 - acc: 0.9025 - val_loss: 0.5461 - val_acc: 0.8500\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2973 - acc: 0.9067\n",
      "Epoch 00042: val_loss did not improve from 0.52672\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2974 - acc: 0.9066 - val_loss: 0.5365 - val_acc: 0.8528\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2908 - acc: 0.9079\n",
      "Epoch 00043: val_loss did not improve from 0.52672\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2908 - acc: 0.9079 - val_loss: 0.5534 - val_acc: 0.8495\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2856 - acc: 0.9100\n",
      "Epoch 00044: val_loss did not improve from 0.52672\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2856 - acc: 0.9100 - val_loss: 0.5440 - val_acc: 0.8593\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2771 - acc: 0.9141\n",
      "Epoch 00045: val_loss did not improve from 0.52672\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2771 - acc: 0.9141 - val_loss: 0.5362 - val_acc: 0.8642\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2709 - acc: 0.9129\n",
      "Epoch 00046: val_loss improved from 0.52672 to 0.51618, saving model to model/checkpoint/1D_CNN_6_conv_custom_conv_3_DO_checkpoint/046-0.5162.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2709 - acc: 0.9129 - val_loss: 0.5162 - val_acc: 0.8623\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2623 - acc: 0.9167\n",
      "Epoch 00047: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2624 - acc: 0.9167 - val_loss: 0.5432 - val_acc: 0.8549\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2603 - acc: 0.9174\n",
      "Epoch 00048: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2603 - acc: 0.9174 - val_loss: 0.5521 - val_acc: 0.8593\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2611 - acc: 0.9157\n",
      "Epoch 00049: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2611 - acc: 0.9157 - val_loss: 0.5553 - val_acc: 0.8591\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2505 - acc: 0.9195\n",
      "Epoch 00050: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2506 - acc: 0.9195 - val_loss: 0.5341 - val_acc: 0.8633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2372 - acc: 0.9244\n",
      "Epoch 00051: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2372 - acc: 0.9244 - val_loss: 0.5493 - val_acc: 0.8614\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2419 - acc: 0.9235\n",
      "Epoch 00052: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2419 - acc: 0.9235 - val_loss: 0.5784 - val_acc: 0.8544\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2402 - acc: 0.9224\n",
      "Epoch 00053: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2402 - acc: 0.9224 - val_loss: 0.5673 - val_acc: 0.8605\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2276 - acc: 0.9260\n",
      "Epoch 00054: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2276 - acc: 0.9260 - val_loss: 0.5717 - val_acc: 0.8512\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2296 - acc: 0.9257\n",
      "Epoch 00055: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2296 - acc: 0.9257 - val_loss: 0.5314 - val_acc: 0.8621\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2216 - acc: 0.9272\n",
      "Epoch 00056: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2216 - acc: 0.9272 - val_loss: 0.5456 - val_acc: 0.8700\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2192 - acc: 0.9289\n",
      "Epoch 00057: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2192 - acc: 0.9289 - val_loss: 0.5476 - val_acc: 0.8644\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2143 - acc: 0.9303\n",
      "Epoch 00058: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2142 - acc: 0.9303 - val_loss: 0.5987 - val_acc: 0.8519\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9325\n",
      "Epoch 00059: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2073 - acc: 0.9325 - val_loss: 0.5575 - val_acc: 0.8682\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9337\n",
      "Epoch 00060: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2024 - acc: 0.9337 - val_loss: 0.5633 - val_acc: 0.8595\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9358\n",
      "Epoch 00061: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1982 - acc: 0.9359 - val_loss: 0.5849 - val_acc: 0.8570\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1952 - acc: 0.9368\n",
      "Epoch 00062: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1952 - acc: 0.9368 - val_loss: 0.5593 - val_acc: 0.8633\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1931 - acc: 0.9360\n",
      "Epoch 00063: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1931 - acc: 0.9360 - val_loss: 0.5560 - val_acc: 0.8628\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9367\n",
      "Epoch 00064: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1947 - acc: 0.9367 - val_loss: 0.6000 - val_acc: 0.8595\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1884 - acc: 0.9392\n",
      "Epoch 00065: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1884 - acc: 0.9392 - val_loss: 0.5747 - val_acc: 0.8609\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9380\n",
      "Epoch 00066: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1875 - acc: 0.9380 - val_loss: 0.5340 - val_acc: 0.8700\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1858 - acc: 0.9389\n",
      "Epoch 00067: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1859 - acc: 0.9389 - val_loss: 0.5438 - val_acc: 0.8670\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9386\n",
      "Epoch 00068: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1834 - acc: 0.9385 - val_loss: 0.5394 - val_acc: 0.8717\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1738 - acc: 0.9437\n",
      "Epoch 00069: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1737 - acc: 0.9437 - val_loss: 0.5558 - val_acc: 0.8691\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1783 - acc: 0.9400\n",
      "Epoch 00070: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1784 - acc: 0.9400 - val_loss: 0.5594 - val_acc: 0.8717\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9409\n",
      "Epoch 00071: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1800 - acc: 0.9409 - val_loss: 0.5535 - val_acc: 0.8633\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1699 - acc: 0.9440\n",
      "Epoch 00072: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1699 - acc: 0.9440 - val_loss: 0.5622 - val_acc: 0.8693\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9455\n",
      "Epoch 00073: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1656 - acc: 0.9455 - val_loss: 0.5454 - val_acc: 0.8696\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1638 - acc: 0.9451\n",
      "Epoch 00074: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1638 - acc: 0.9451 - val_loss: 0.5706 - val_acc: 0.8733\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9467\n",
      "Epoch 00075: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1624 - acc: 0.9467 - val_loss: 0.5694 - val_acc: 0.8705\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9486\n",
      "Epoch 00076: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1591 - acc: 0.9486 - val_loss: 0.5693 - val_acc: 0.8758\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1561 - acc: 0.9482\n",
      "Epoch 00077: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1560 - acc: 0.9482 - val_loss: 0.5673 - val_acc: 0.8728\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1563 - acc: 0.9477\n",
      "Epoch 00078: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1564 - acc: 0.9477 - val_loss: 0.5638 - val_acc: 0.8696\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1561 - acc: 0.9482\n",
      "Epoch 00079: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1561 - acc: 0.9482 - val_loss: 0.5730 - val_acc: 0.8658\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9502\n",
      "Epoch 00080: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1507 - acc: 0.9502 - val_loss: 0.5562 - val_acc: 0.8733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9473\n",
      "Epoch 00081: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1582 - acc: 0.9473 - val_loss: 0.5936 - val_acc: 0.8616\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1498 - acc: 0.9492\n",
      "Epoch 00082: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1498 - acc: 0.9492 - val_loss: 0.5865 - val_acc: 0.8663\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9521\n",
      "Epoch 00083: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1448 - acc: 0.9521 - val_loss: 0.5384 - val_acc: 0.8775\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9532\n",
      "Epoch 00084: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1409 - acc: 0.9532 - val_loss: 0.5952 - val_acc: 0.8707\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9522\n",
      "Epoch 00085: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1416 - acc: 0.9522 - val_loss: 0.5580 - val_acc: 0.8710\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9530\n",
      "Epoch 00086: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1426 - acc: 0.9530 - val_loss: 0.6137 - val_acc: 0.8675\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9549\n",
      "Epoch 00087: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1341 - acc: 0.9549 - val_loss: 0.5897 - val_acc: 0.8700\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9556\n",
      "Epoch 00088: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1333 - acc: 0.9555 - val_loss: 0.6116 - val_acc: 0.8703\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9549\n",
      "Epoch 00089: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1380 - acc: 0.9549 - val_loss: 0.6198 - val_acc: 0.8649\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9546\n",
      "Epoch 00090: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1375 - acc: 0.9547 - val_loss: 0.5681 - val_acc: 0.8819\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9552\n",
      "Epoch 00091: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1311 - acc: 0.9553 - val_loss: 0.5717 - val_acc: 0.8730\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9560\n",
      "Epoch 00092: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1316 - acc: 0.9560 - val_loss: 0.5463 - val_acc: 0.8807\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9573\n",
      "Epoch 00093: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1280 - acc: 0.9573 - val_loss: 0.5533 - val_acc: 0.8793\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9590\n",
      "Epoch 00094: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1270 - acc: 0.9589 - val_loss: 0.5981 - val_acc: 0.8658\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9573\n",
      "Epoch 00095: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1290 - acc: 0.9573 - val_loss: 0.5688 - val_acc: 0.8763\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9589\n",
      "Epoch 00096: val_loss did not improve from 0.51618\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1273 - acc: 0.9589 - val_loss: 0.5701 - val_acc: 0.8775\n",
      "\n",
      "1D_CNN_6_conv_custom_conv_3_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 565us/sample - loss: 0.6294 - acc: 0.8299\n",
      "Loss: 0.6293874348435446 Accuracy: 0.8299065\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4603 - acc: 0.1934\n",
      "Epoch 00001: val_loss improved from inf to 1.85230, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/001-1.8523.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 2.4601 - acc: 0.1934 - val_loss: 1.8523 - val_acc: 0.4232\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7148 - acc: 0.4364\n",
      "Epoch 00002: val_loss improved from 1.85230 to 1.40246, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/002-1.4025.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.7149 - acc: 0.4363 - val_loss: 1.4025 - val_acc: 0.5642\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4760 - acc: 0.5157\n",
      "Epoch 00003: val_loss improved from 1.40246 to 1.24869, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/003-1.2487.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.4761 - acc: 0.5157 - val_loss: 1.2487 - val_acc: 0.6252\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3339 - acc: 0.5721\n",
      "Epoch 00004: val_loss improved from 1.24869 to 1.13495, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/004-1.1349.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.3339 - acc: 0.5721 - val_loss: 1.1349 - val_acc: 0.6594\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1893 - acc: 0.6218\n",
      "Epoch 00005: val_loss improved from 1.13495 to 0.98112, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/005-0.9811.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.1893 - acc: 0.6218 - val_loss: 0.9811 - val_acc: 0.7142\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0671 - acc: 0.6677\n",
      "Epoch 00006: val_loss improved from 0.98112 to 0.86659, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/006-0.8666.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.0671 - acc: 0.6677 - val_loss: 0.8666 - val_acc: 0.7512\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9757 - acc: 0.7002\n",
      "Epoch 00007: val_loss improved from 0.86659 to 0.80444, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/007-0.8044.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.9756 - acc: 0.7002 - val_loss: 0.8044 - val_acc: 0.7747\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9011 - acc: 0.7243\n",
      "Epoch 00008: val_loss improved from 0.80444 to 0.75511, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/008-0.7551.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.9012 - acc: 0.7243 - val_loss: 0.7551 - val_acc: 0.7724\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8380 - acc: 0.7458\n",
      "Epoch 00009: val_loss improved from 0.75511 to 0.67950, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/009-0.6795.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.8380 - acc: 0.7458 - val_loss: 0.6795 - val_acc: 0.8078\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7843 - acc: 0.7618\n",
      "Epoch 00010: val_loss improved from 0.67950 to 0.64743, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/010-0.6474.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.7843 - acc: 0.7619 - val_loss: 0.6474 - val_acc: 0.8169\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7383 - acc: 0.7765\n",
      "Epoch 00011: val_loss improved from 0.64743 to 0.63063, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/011-0.6306.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.7382 - acc: 0.7764 - val_loss: 0.6306 - val_acc: 0.8202\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6949 - acc: 0.7903\n",
      "Epoch 00012: val_loss improved from 0.63063 to 0.58180, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/012-0.5818.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.6949 - acc: 0.7904 - val_loss: 0.5818 - val_acc: 0.8316\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6623 - acc: 0.7999\n",
      "Epoch 00013: val_loss improved from 0.58180 to 0.55470, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/013-0.5547.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.6623 - acc: 0.7999 - val_loss: 0.5547 - val_acc: 0.8467\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6255 - acc: 0.8114\n",
      "Epoch 00014: val_loss improved from 0.55470 to 0.54274, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/014-0.5427.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.6255 - acc: 0.8115 - val_loss: 0.5427 - val_acc: 0.8535\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6002 - acc: 0.8173\n",
      "Epoch 00015: val_loss improved from 0.54274 to 0.52473, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/015-0.5247.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.6002 - acc: 0.8173 - val_loss: 0.5247 - val_acc: 0.8556\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5722 - acc: 0.8288\n",
      "Epoch 00016: val_loss improved from 0.52473 to 0.48214, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/016-0.4821.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5722 - acc: 0.8287 - val_loss: 0.4821 - val_acc: 0.8661\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5436 - acc: 0.8343\n",
      "Epoch 00017: val_loss did not improve from 0.48214\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5435 - acc: 0.8343 - val_loss: 0.4900 - val_acc: 0.8647\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5234 - acc: 0.8405\n",
      "Epoch 00018: val_loss improved from 0.48214 to 0.44381, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/018-0.4438.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5234 - acc: 0.8405 - val_loss: 0.4438 - val_acc: 0.8740\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5023 - acc: 0.8478\n",
      "Epoch 00019: val_loss improved from 0.44381 to 0.44161, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/019-0.4416.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5024 - acc: 0.8478 - val_loss: 0.4416 - val_acc: 0.8768\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4874 - acc: 0.8507\n",
      "Epoch 00020: val_loss improved from 0.44161 to 0.40834, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/020-0.4083.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4874 - acc: 0.8507 - val_loss: 0.4083 - val_acc: 0.8898\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4706 - acc: 0.8567\n",
      "Epoch 00021: val_loss did not improve from 0.40834\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4706 - acc: 0.8566 - val_loss: 0.4199 - val_acc: 0.8835\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8593\n",
      "Epoch 00022: val_loss improved from 0.40834 to 0.39652, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/022-0.3965.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4591 - acc: 0.8594 - val_loss: 0.3965 - val_acc: 0.8917\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4355 - acc: 0.8666\n",
      "Epoch 00023: val_loss did not improve from 0.39652\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4356 - acc: 0.8666 - val_loss: 0.4136 - val_acc: 0.8861\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4302 - acc: 0.8692\n",
      "Epoch 00024: val_loss improved from 0.39652 to 0.37953, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/024-0.3795.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4302 - acc: 0.8692 - val_loss: 0.3795 - val_acc: 0.8947\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4152 - acc: 0.8724\n",
      "Epoch 00025: val_loss did not improve from 0.37953\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4151 - acc: 0.8724 - val_loss: 0.3827 - val_acc: 0.8947\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3978 - acc: 0.8772\n",
      "Epoch 00026: val_loss improved from 0.37953 to 0.35752, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/026-0.3575.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3978 - acc: 0.8772 - val_loss: 0.3575 - val_acc: 0.8994\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3881 - acc: 0.8824\n",
      "Epoch 00027: val_loss did not improve from 0.35752\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3881 - acc: 0.8824 - val_loss: 0.3782 - val_acc: 0.8968\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3805 - acc: 0.8815\n",
      "Epoch 00028: val_loss improved from 0.35752 to 0.35582, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/028-0.3558.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3805 - acc: 0.8815 - val_loss: 0.3558 - val_acc: 0.9026\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3730 - acc: 0.8837\n",
      "Epoch 00029: val_loss did not improve from 0.35582\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3730 - acc: 0.8837 - val_loss: 0.3656 - val_acc: 0.8996\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3583 - acc: 0.8897\n",
      "Epoch 00030: val_loss did not improve from 0.35582\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3584 - acc: 0.8897 - val_loss: 0.3855 - val_acc: 0.8961\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3588 - acc: 0.8885\n",
      "Epoch 00031: val_loss improved from 0.35582 to 0.32360, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/031-0.3236.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3588 - acc: 0.8885 - val_loss: 0.3236 - val_acc: 0.9115\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3413 - acc: 0.8933\n",
      "Epoch 00032: val_loss did not improve from 0.32360\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3412 - acc: 0.8933 - val_loss: 0.3276 - val_acc: 0.9110\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3292 - acc: 0.8975\n",
      "Epoch 00033: val_loss did not improve from 0.32360\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3292 - acc: 0.8975 - val_loss: 0.3280 - val_acc: 0.9087\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3310 - acc: 0.8965\n",
      "Epoch 00034: val_loss did not improve from 0.32360\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3310 - acc: 0.8966 - val_loss: 0.3494 - val_acc: 0.9073\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.8981\n",
      "Epoch 00035: val_loss improved from 0.32360 to 0.30946, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/035-0.3095.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3237 - acc: 0.8981 - val_loss: 0.3095 - val_acc: 0.9147\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3126 - acc: 0.9015\n",
      "Epoch 00036: val_loss improved from 0.30946 to 0.30217, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/036-0.3022.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3126 - acc: 0.9015 - val_loss: 0.3022 - val_acc: 0.9173\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3094 - acc: 0.9036\n",
      "Epoch 00037: val_loss improved from 0.30217 to 0.29847, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/037-0.2985.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3094 - acc: 0.9036 - val_loss: 0.2985 - val_acc: 0.9189\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2970 - acc: 0.9066\n",
      "Epoch 00038: val_loss improved from 0.29847 to 0.29440, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/038-0.2944.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2969 - acc: 0.9066 - val_loss: 0.2944 - val_acc: 0.9208\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2925 - acc: 0.9072\n",
      "Epoch 00039: val_loss improved from 0.29440 to 0.29256, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/039-0.2926.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2925 - acc: 0.9072 - val_loss: 0.2926 - val_acc: 0.9168\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2898 - acc: 0.9082\n",
      "Epoch 00040: val_loss improved from 0.29256 to 0.28877, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/040-0.2888.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2898 - acc: 0.9082 - val_loss: 0.2888 - val_acc: 0.9222\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2868 - acc: 0.9099\n",
      "Epoch 00041: val_loss did not improve from 0.28877\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2868 - acc: 0.9099 - val_loss: 0.2961 - val_acc: 0.9180\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2812 - acc: 0.9107\n",
      "Epoch 00042: val_loss improved from 0.28877 to 0.28507, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/042-0.2851.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2813 - acc: 0.9107 - val_loss: 0.2851 - val_acc: 0.9238\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2715 - acc: 0.9139\n",
      "Epoch 00043: val_loss did not improve from 0.28507\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2715 - acc: 0.9139 - val_loss: 0.3040 - val_acc: 0.9161\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2748 - acc: 0.9123\n",
      "Epoch 00044: val_loss improved from 0.28507 to 0.28301, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/044-0.2830.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2748 - acc: 0.9123 - val_loss: 0.2830 - val_acc: 0.9248\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2574 - acc: 0.9187\n",
      "Epoch 00045: val_loss did not improve from 0.28301\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2574 - acc: 0.9187 - val_loss: 0.2925 - val_acc: 0.9215\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2596 - acc: 0.9174\n",
      "Epoch 00046: val_loss did not improve from 0.28301\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2596 - acc: 0.9175 - val_loss: 0.3227 - val_acc: 0.9168\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2506 - acc: 0.9186\n",
      "Epoch 00047: val_loss did not improve from 0.28301\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2506 - acc: 0.9186 - val_loss: 0.2879 - val_acc: 0.9210\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2556 - acc: 0.9192\n",
      "Epoch 00048: val_loss improved from 0.28301 to 0.27943, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/048-0.2794.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2555 - acc: 0.9192 - val_loss: 0.2794 - val_acc: 0.9294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2384 - acc: 0.9231\n",
      "Epoch 00049: val_loss improved from 0.27943 to 0.27730, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/049-0.2773.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2384 - acc: 0.9231 - val_loss: 0.2773 - val_acc: 0.9224\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2377 - acc: 0.9251\n",
      "Epoch 00050: val_loss improved from 0.27730 to 0.27613, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/050-0.2761.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2377 - acc: 0.9251 - val_loss: 0.2761 - val_acc: 0.9278\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2347 - acc: 0.9260\n",
      "Epoch 00051: val_loss did not improve from 0.27613\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2347 - acc: 0.9260 - val_loss: 0.2812 - val_acc: 0.9241\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2314 - acc: 0.9250\n",
      "Epoch 00052: val_loss improved from 0.27613 to 0.26443, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/052-0.2644.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2314 - acc: 0.9250 - val_loss: 0.2644 - val_acc: 0.9280\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2269 - acc: 0.9260\n",
      "Epoch 00053: val_loss improved from 0.26443 to 0.25997, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/053-0.2600.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2269 - acc: 0.9260 - val_loss: 0.2600 - val_acc: 0.9264\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2271 - acc: 0.9280\n",
      "Epoch 00054: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2271 - acc: 0.9280 - val_loss: 0.2731 - val_acc: 0.9304\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9296\n",
      "Epoch 00055: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2175 - acc: 0.9295 - val_loss: 0.3313 - val_acc: 0.9129\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2215 - acc: 0.9300\n",
      "Epoch 00056: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2215 - acc: 0.9300 - val_loss: 0.2604 - val_acc: 0.9269\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2118 - acc: 0.9306\n",
      "Epoch 00057: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2118 - acc: 0.9306 - val_loss: 0.2821 - val_acc: 0.9257\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2134 - acc: 0.9309\n",
      "Epoch 00058: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2135 - acc: 0.9309 - val_loss: 0.2686 - val_acc: 0.9338\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2072 - acc: 0.9328\n",
      "Epoch 00059: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2072 - acc: 0.9328 - val_loss: 0.2633 - val_acc: 0.9336\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2002 - acc: 0.9352\n",
      "Epoch 00060: val_loss did not improve from 0.25997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2002 - acc: 0.9352 - val_loss: 0.2632 - val_acc: 0.9317\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2031 - acc: 0.9335\n",
      "Epoch 00061: val_loss improved from 0.25997 to 0.25398, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/061-0.2540.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2031 - acc: 0.9335 - val_loss: 0.2540 - val_acc: 0.9315\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9357\n",
      "Epoch 00062: val_loss did not improve from 0.25398\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1995 - acc: 0.9357 - val_loss: 0.2878 - val_acc: 0.9255\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1988 - acc: 0.9362\n",
      "Epoch 00063: val_loss improved from 0.25398 to 0.25130, saving model to model/checkpoint/1D_CNN_7_conv_custom_conv_3_DO_checkpoint/063-0.2513.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1990 - acc: 0.9362 - val_loss: 0.2513 - val_acc: 0.9304\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1954 - acc: 0.9363\n",
      "Epoch 00064: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1954 - acc: 0.9363 - val_loss: 0.2611 - val_acc: 0.9308\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9369\n",
      "Epoch 00065: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1923 - acc: 0.9369 - val_loss: 0.2649 - val_acc: 0.9317\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1888 - acc: 0.9374\n",
      "Epoch 00066: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1888 - acc: 0.9374 - val_loss: 0.2591 - val_acc: 0.9338\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1832 - acc: 0.9396\n",
      "Epoch 00067: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1832 - acc: 0.9396 - val_loss: 0.2699 - val_acc: 0.9327\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1797 - acc: 0.9404\n",
      "Epoch 00068: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1797 - acc: 0.9404 - val_loss: 0.2625 - val_acc: 0.9343\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9405\n",
      "Epoch 00069: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1834 - acc: 0.9406 - val_loss: 0.2689 - val_acc: 0.9329\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9423\n",
      "Epoch 00070: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1771 - acc: 0.9423 - val_loss: 0.2555 - val_acc: 0.9352\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1734 - acc: 0.9430\n",
      "Epoch 00071: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1734 - acc: 0.9430 - val_loss: 0.2646 - val_acc: 0.9322\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9421\n",
      "Epoch 00072: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1735 - acc: 0.9421 - val_loss: 0.2725 - val_acc: 0.9343\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1707 - acc: 0.9442\n",
      "Epoch 00073: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1707 - acc: 0.9442 - val_loss: 0.2631 - val_acc: 0.9373\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9434\n",
      "Epoch 00074: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1698 - acc: 0.9434 - val_loss: 0.2676 - val_acc: 0.9320\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1642 - acc: 0.9446\n",
      "Epoch 00075: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1641 - acc: 0.9446 - val_loss: 0.2725 - val_acc: 0.9357\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1646 - acc: 0.9461\n",
      "Epoch 00076: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1646 - acc: 0.9461 - val_loss: 0.2643 - val_acc: 0.9364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9462\n",
      "Epoch 00077: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1599 - acc: 0.9462 - val_loss: 0.2630 - val_acc: 0.9355\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1559 - acc: 0.9495\n",
      "Epoch 00078: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1560 - acc: 0.9494 - val_loss: 0.2711 - val_acc: 0.9343\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9462\n",
      "Epoch 00079: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1606 - acc: 0.9461 - val_loss: 0.2726 - val_acc: 0.9306\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9485\n",
      "Epoch 00080: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1554 - acc: 0.9485 - val_loss: 0.2623 - val_acc: 0.9343\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1519 - acc: 0.9497\n",
      "Epoch 00081: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1519 - acc: 0.9497 - val_loss: 0.2704 - val_acc: 0.9369\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9491\n",
      "Epoch 00082: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1533 - acc: 0.9491 - val_loss: 0.2773 - val_acc: 0.9334\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9490\n",
      "Epoch 00083: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1538 - acc: 0.9490 - val_loss: 0.2686 - val_acc: 0.9345\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1519 - acc: 0.9488\n",
      "Epoch 00084: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1519 - acc: 0.9488 - val_loss: 0.2581 - val_acc: 0.9324\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9489\n",
      "Epoch 00085: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1526 - acc: 0.9489 - val_loss: 0.2782 - val_acc: 0.9359\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1484 - acc: 0.9504\n",
      "Epoch 00086: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1484 - acc: 0.9504 - val_loss: 0.2859 - val_acc: 0.9320\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9523\n",
      "Epoch 00087: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1432 - acc: 0.9523 - val_loss: 0.2700 - val_acc: 0.9336\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9512\n",
      "Epoch 00088: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1424 - acc: 0.9512 - val_loss: 0.2697 - val_acc: 0.9362\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9527\n",
      "Epoch 00089: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1415 - acc: 0.9528 - val_loss: 0.2592 - val_acc: 0.9376\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9520\n",
      "Epoch 00090: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1421 - acc: 0.9520 - val_loss: 0.2618 - val_acc: 0.9362\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9535\n",
      "Epoch 00091: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1372 - acc: 0.9535 - val_loss: 0.2820 - val_acc: 0.9362\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9549\n",
      "Epoch 00092: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1345 - acc: 0.9549 - val_loss: 0.2768 - val_acc: 0.9350\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9543\n",
      "Epoch 00093: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1342 - acc: 0.9544 - val_loss: 0.2801 - val_acc: 0.9371\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9539\n",
      "Epoch 00094: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1357 - acc: 0.9539 - val_loss: 0.2685 - val_acc: 0.9373\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9565\n",
      "Epoch 00095: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1312 - acc: 0.9565 - val_loss: 0.2695 - val_acc: 0.9401\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9566\n",
      "Epoch 00096: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1289 - acc: 0.9566 - val_loss: 0.2715 - val_acc: 0.9387\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9552\n",
      "Epoch 00097: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1332 - acc: 0.9552 - val_loss: 0.2684 - val_acc: 0.9359\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9575\n",
      "Epoch 00098: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1294 - acc: 0.9575 - val_loss: 0.2753 - val_acc: 0.9308\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9588\n",
      "Epoch 00099: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1198 - acc: 0.9588 - val_loss: 0.2699 - val_acc: 0.9399\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9574\n",
      "Epoch 00100: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1239 - acc: 0.9574 - val_loss: 0.2901 - val_acc: 0.9336\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9594\n",
      "Epoch 00101: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1213 - acc: 0.9594 - val_loss: 0.2758 - val_acc: 0.9345\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9580\n",
      "Epoch 00102: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1242 - acc: 0.9580 - val_loss: 0.2704 - val_acc: 0.9397\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9595\n",
      "Epoch 00103: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1244 - acc: 0.9595 - val_loss: 0.2578 - val_acc: 0.9399\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9576\n",
      "Epoch 00104: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1237 - acc: 0.9576 - val_loss: 0.2817 - val_acc: 0.9364\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9592\n",
      "Epoch 00105: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1184 - acc: 0.9592 - val_loss: 0.2798 - val_acc: 0.9352\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9614\n",
      "Epoch 00106: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1164 - acc: 0.9614 - val_loss: 0.3009 - val_acc: 0.9371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9609\n",
      "Epoch 00107: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1168 - acc: 0.9609 - val_loss: 0.2827 - val_acc: 0.9352\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9598\n",
      "Epoch 00108: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1175 - acc: 0.9598 - val_loss: 0.2688 - val_acc: 0.9425\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9630\n",
      "Epoch 00109: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1122 - acc: 0.9630 - val_loss: 0.2933 - val_acc: 0.9336\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9618\n",
      "Epoch 00110: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1145 - acc: 0.9619 - val_loss: 0.2786 - val_acc: 0.9378\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9630\n",
      "Epoch 00111: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1119 - acc: 0.9630 - val_loss: 0.2753 - val_acc: 0.9357\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9632\n",
      "Epoch 00112: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1097 - acc: 0.9631 - val_loss: 0.2790 - val_acc: 0.9383\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9635\n",
      "Epoch 00113: val_loss did not improve from 0.25130\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1104 - acc: 0.9635 - val_loss: 0.2730 - val_acc: 0.9341\n",
      "\n",
      "1D_CNN_7_conv_custom_conv_3_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 604us/sample - loss: 0.2910 - acc: 0.9153\n",
      "Loss: 0.2909540087882108 Accuracy: 0.9152648\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4746 - acc: 0.1887\n",
      "Epoch 00001: val_loss improved from inf to 1.71182, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/001-1.7118.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 2.4746 - acc: 0.1887 - val_loss: 1.7118 - val_acc: 0.4836\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6293 - acc: 0.4653\n",
      "Epoch 00002: val_loss improved from 1.71182 to 1.19726, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/002-1.1973.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.6294 - acc: 0.4653 - val_loss: 1.1973 - val_acc: 0.6285\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3154 - acc: 0.5683\n",
      "Epoch 00003: val_loss improved from 1.19726 to 1.00500, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/003-1.0050.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.3153 - acc: 0.5684 - val_loss: 1.0050 - val_acc: 0.6962\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1334 - acc: 0.6337\n",
      "Epoch 00004: val_loss improved from 1.00500 to 0.84590, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/004-0.8459.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.1335 - acc: 0.6337 - val_loss: 0.8459 - val_acc: 0.7470\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9996 - acc: 0.6777\n",
      "Epoch 00005: val_loss improved from 0.84590 to 0.72010, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/005-0.7201.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.9997 - acc: 0.6777 - val_loss: 0.7201 - val_acc: 0.7831\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8930 - acc: 0.7122\n",
      "Epoch 00006: val_loss improved from 0.72010 to 0.63703, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/006-0.6370.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.8931 - acc: 0.7122 - val_loss: 0.6370 - val_acc: 0.8039\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8078 - acc: 0.7442\n",
      "Epoch 00007: val_loss improved from 0.63703 to 0.59315, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/007-0.5932.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.8078 - acc: 0.7442 - val_loss: 0.5932 - val_acc: 0.8330\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7348 - acc: 0.7686\n",
      "Epoch 00008: val_loss improved from 0.59315 to 0.50519, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/008-0.5052.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.7348 - acc: 0.7686 - val_loss: 0.5052 - val_acc: 0.8560\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6746 - acc: 0.7872\n",
      "Epoch 00009: val_loss improved from 0.50519 to 0.45231, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/009-0.4523.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.6745 - acc: 0.7873 - val_loss: 0.4523 - val_acc: 0.8749\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6272 - acc: 0.8035\n",
      "Epoch 00010: val_loss improved from 0.45231 to 0.43044, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/010-0.4304.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.6271 - acc: 0.8036 - val_loss: 0.4304 - val_acc: 0.8793\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5830 - acc: 0.8155\n",
      "Epoch 00011: val_loss improved from 0.43044 to 0.39522, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/011-0.3952.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5831 - acc: 0.8155 - val_loss: 0.3952 - val_acc: 0.8842\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5503 - acc: 0.8268\n",
      "Epoch 00012: val_loss improved from 0.39522 to 0.36479, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/012-0.3648.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5502 - acc: 0.8269 - val_loss: 0.3648 - val_acc: 0.8947\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5062 - acc: 0.8384\n",
      "Epoch 00013: val_loss improved from 0.36479 to 0.34632, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/013-0.3463.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5061 - acc: 0.8384 - val_loss: 0.3463 - val_acc: 0.8935\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4927 - acc: 0.8434\n",
      "Epoch 00014: val_loss improved from 0.34632 to 0.32722, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/014-0.3272.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4927 - acc: 0.8434 - val_loss: 0.3272 - val_acc: 0.9017\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4679 - acc: 0.8538\n",
      "Epoch 00015: val_loss improved from 0.32722 to 0.31338, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/015-0.3134.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4679 - acc: 0.8538 - val_loss: 0.3134 - val_acc: 0.9106\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4401 - acc: 0.8584\n",
      "Epoch 00016: val_loss did not improve from 0.31338\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4401 - acc: 0.8584 - val_loss: 0.3162 - val_acc: 0.9017\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4252 - acc: 0.8644\n",
      "Epoch 00017: val_loss improved from 0.31338 to 0.28371, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/017-0.2837.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4251 - acc: 0.8644 - val_loss: 0.2837 - val_acc: 0.9166\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4081 - acc: 0.8700\n",
      "Epoch 00018: val_loss improved from 0.28371 to 0.27590, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/018-0.2759.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4081 - acc: 0.8700 - val_loss: 0.2759 - val_acc: 0.9192\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3975 - acc: 0.8751\n",
      "Epoch 00019: val_loss did not improve from 0.27590\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3974 - acc: 0.8751 - val_loss: 0.2865 - val_acc: 0.9117\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3791 - acc: 0.8798\n",
      "Epoch 00020: val_loss improved from 0.27590 to 0.25794, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/020-0.2579.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3790 - acc: 0.8798 - val_loss: 0.2579 - val_acc: 0.9264\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3649 - acc: 0.8823\n",
      "Epoch 00021: val_loss did not improve from 0.25794\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3649 - acc: 0.8823 - val_loss: 0.3668 - val_acc: 0.8887\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3551 - acc: 0.8851\n",
      "Epoch 00022: val_loss did not improve from 0.25794\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3551 - acc: 0.8851 - val_loss: 0.2616 - val_acc: 0.9245\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3484 - acc: 0.8887\n",
      "Epoch 00023: val_loss did not improve from 0.25794\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3484 - acc: 0.8887 - val_loss: 0.2831 - val_acc: 0.9168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3415 - acc: 0.8927\n",
      "Epoch 00024: val_loss improved from 0.25794 to 0.23135, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/024-0.2314.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3414 - acc: 0.8927 - val_loss: 0.2314 - val_acc: 0.9327\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3210 - acc: 0.8974\n",
      "Epoch 00025: val_loss improved from 0.23135 to 0.22763, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/025-0.2276.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3210 - acc: 0.8974 - val_loss: 0.2276 - val_acc: 0.9315\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3131 - acc: 0.8991\n",
      "Epoch 00026: val_loss improved from 0.22763 to 0.21640, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/026-0.2164.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3131 - acc: 0.8991 - val_loss: 0.2164 - val_acc: 0.9355\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3041 - acc: 0.9023\n",
      "Epoch 00027: val_loss did not improve from 0.21640\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3041 - acc: 0.9022 - val_loss: 0.2222 - val_acc: 0.9373\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2958 - acc: 0.9053\n",
      "Epoch 00028: val_loss improved from 0.21640 to 0.20597, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/028-0.2060.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2958 - acc: 0.9053 - val_loss: 0.2060 - val_acc: 0.9415\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2931 - acc: 0.9062\n",
      "Epoch 00029: val_loss did not improve from 0.20597\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2931 - acc: 0.9063 - val_loss: 0.2273 - val_acc: 0.9362\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2804 - acc: 0.9092\n",
      "Epoch 00030: val_loss did not improve from 0.20597\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2804 - acc: 0.9092 - val_loss: 0.2133 - val_acc: 0.9373\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2838 - acc: 0.9095\n",
      "Epoch 00031: val_loss improved from 0.20597 to 0.20302, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/031-0.2030.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2838 - acc: 0.9096 - val_loss: 0.2030 - val_acc: 0.9411\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2700 - acc: 0.9146\n",
      "Epoch 00032: val_loss improved from 0.20302 to 0.20293, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/032-0.2029.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2700 - acc: 0.9146 - val_loss: 0.2029 - val_acc: 0.9415\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2617 - acc: 0.9162\n",
      "Epoch 00033: val_loss improved from 0.20293 to 0.20280, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/033-0.2028.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2616 - acc: 0.9162 - val_loss: 0.2028 - val_acc: 0.9401\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2525 - acc: 0.9195\n",
      "Epoch 00034: val_loss improved from 0.20280 to 0.19391, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/034-0.1939.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2525 - acc: 0.9195 - val_loss: 0.1939 - val_acc: 0.9404\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2512 - acc: 0.9201\n",
      "Epoch 00035: val_loss improved from 0.19391 to 0.19205, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/035-0.1921.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2511 - acc: 0.9201 - val_loss: 0.1921 - val_acc: 0.9406\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2448 - acc: 0.9204\n",
      "Epoch 00036: val_loss did not improve from 0.19205\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2449 - acc: 0.9204 - val_loss: 0.2086 - val_acc: 0.9385\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2447 - acc: 0.9201\n",
      "Epoch 00037: val_loss did not improve from 0.19205\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2447 - acc: 0.9201 - val_loss: 0.2314 - val_acc: 0.9304\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2337 - acc: 0.9242\n",
      "Epoch 00038: val_loss did not improve from 0.19205\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2337 - acc: 0.9242 - val_loss: 0.2264 - val_acc: 0.9308\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2334 - acc: 0.9250\n",
      "Epoch 00039: val_loss did not improve from 0.19205\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2334 - acc: 0.9250 - val_loss: 0.2072 - val_acc: 0.9390\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2267 - acc: 0.9263\n",
      "Epoch 00040: val_loss improved from 0.19205 to 0.18130, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/040-0.1813.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2267 - acc: 0.9263 - val_loss: 0.1813 - val_acc: 0.9467\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2270 - acc: 0.9253\n",
      "Epoch 00041: val_loss did not improve from 0.18130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2270 - acc: 0.9253 - val_loss: 0.1976 - val_acc: 0.9373\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2213 - acc: 0.9271\n",
      "Epoch 00042: val_loss did not improve from 0.18130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2213 - acc: 0.9272 - val_loss: 0.1902 - val_acc: 0.9411\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2121 - acc: 0.9314\n",
      "Epoch 00043: val_loss did not improve from 0.18130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2120 - acc: 0.9314 - val_loss: 0.2041 - val_acc: 0.9385\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2079 - acc: 0.9325\n",
      "Epoch 00044: val_loss did not improve from 0.18130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2080 - acc: 0.9325 - val_loss: 0.1818 - val_acc: 0.9462\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2087 - acc: 0.9315\n",
      "Epoch 00045: val_loss did not improve from 0.18130\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2089 - acc: 0.9314 - val_loss: 0.1830 - val_acc: 0.9460\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9347\n",
      "Epoch 00046: val_loss improved from 0.18130 to 0.17881, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/046-0.1788.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2021 - acc: 0.9347 - val_loss: 0.1788 - val_acc: 0.9453\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1974 - acc: 0.9346\n",
      "Epoch 00047: val_loss did not improve from 0.17881\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1974 - acc: 0.9346 - val_loss: 0.1820 - val_acc: 0.9481\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9358\n",
      "Epoch 00048: val_loss did not improve from 0.17881\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1980 - acc: 0.9358 - val_loss: 0.1859 - val_acc: 0.9457\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1892 - acc: 0.9384\n",
      "Epoch 00049: val_loss improved from 0.17881 to 0.17605, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/049-0.1760.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1892 - acc: 0.9384 - val_loss: 0.1760 - val_acc: 0.9481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9367\n",
      "Epoch 00050: val_loss improved from 0.17605 to 0.17587, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/050-0.1759.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1926 - acc: 0.9367 - val_loss: 0.1759 - val_acc: 0.9462\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9378\n",
      "Epoch 00051: val_loss did not improve from 0.17587\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1874 - acc: 0.9378 - val_loss: 0.1847 - val_acc: 0.9462\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1851 - acc: 0.9395\n",
      "Epoch 00052: val_loss did not improve from 0.17587\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1851 - acc: 0.9395 - val_loss: 0.1934 - val_acc: 0.9415\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9405\n",
      "Epoch 00053: val_loss did not improve from 0.17587\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1793 - acc: 0.9406 - val_loss: 0.1891 - val_acc: 0.9422\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9428\n",
      "Epoch 00054: val_loss improved from 0.17587 to 0.15928, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/054-0.1593.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1722 - acc: 0.9428 - val_loss: 0.1593 - val_acc: 0.9504\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9435\n",
      "Epoch 00055: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1722 - acc: 0.9435 - val_loss: 0.1735 - val_acc: 0.9504\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1673 - acc: 0.9454\n",
      "Epoch 00056: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1673 - acc: 0.9454 - val_loss: 0.1728 - val_acc: 0.9478\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9448\n",
      "Epoch 00057: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1672 - acc: 0.9448 - val_loss: 0.1737 - val_acc: 0.9520\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1646 - acc: 0.9456\n",
      "Epoch 00058: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1647 - acc: 0.9456 - val_loss: 0.1679 - val_acc: 0.9529\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9484\n",
      "Epoch 00059: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1574 - acc: 0.9484 - val_loss: 0.1725 - val_acc: 0.9488\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9468\n",
      "Epoch 00060: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1616 - acc: 0.9469 - val_loss: 0.1670 - val_acc: 0.9513\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9471\n",
      "Epoch 00061: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1557 - acc: 0.9471 - val_loss: 0.1693 - val_acc: 0.9515\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9503\n",
      "Epoch 00062: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1491 - acc: 0.9503 - val_loss: 0.1687 - val_acc: 0.9506\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9496\n",
      "Epoch 00063: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1478 - acc: 0.9495 - val_loss: 0.1659 - val_acc: 0.9518\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9505\n",
      "Epoch 00064: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1466 - acc: 0.9505 - val_loss: 0.1721 - val_acc: 0.9495\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9522\n",
      "Epoch 00065: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1439 - acc: 0.9522 - val_loss: 0.1768 - val_acc: 0.9504\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9500\n",
      "Epoch 00066: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1492 - acc: 0.9500 - val_loss: 0.1735 - val_acc: 0.9532\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1461 - acc: 0.9508\n",
      "Epoch 00067: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1461 - acc: 0.9508 - val_loss: 0.1658 - val_acc: 0.9499\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9527\n",
      "Epoch 00068: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1382 - acc: 0.9528 - val_loss: 0.1771 - val_acc: 0.9492\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9530\n",
      "Epoch 00069: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1393 - acc: 0.9530 - val_loss: 0.1613 - val_acc: 0.9550\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9532\n",
      "Epoch 00070: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1354 - acc: 0.9532 - val_loss: 0.1608 - val_acc: 0.9562\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9574\n",
      "Epoch 00071: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1286 - acc: 0.9574 - val_loss: 0.1828 - val_acc: 0.9478\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9549\n",
      "Epoch 00072: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1326 - acc: 0.9549 - val_loss: 0.1676 - val_acc: 0.9527\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9567\n",
      "Epoch 00073: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1284 - acc: 0.9567 - val_loss: 0.1672 - val_acc: 0.9553\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9565\n",
      "Epoch 00074: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1283 - acc: 0.9565 - val_loss: 0.1656 - val_acc: 0.9555\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9599\n",
      "Epoch 00075: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1212 - acc: 0.9599 - val_loss: 0.1803 - val_acc: 0.9495\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9573\n",
      "Epoch 00076: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1253 - acc: 0.9573 - val_loss: 0.1687 - val_acc: 0.9562\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9571\n",
      "Epoch 00077: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1247 - acc: 0.9572 - val_loss: 0.1838 - val_acc: 0.9506\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9605\n",
      "Epoch 00078: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1183 - acc: 0.9605 - val_loss: 0.1629 - val_acc: 0.9553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9590\n",
      "Epoch 00079: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1229 - acc: 0.9590 - val_loss: 0.1721 - val_acc: 0.9515\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9599\n",
      "Epoch 00080: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1188 - acc: 0.9599 - val_loss: 0.1791 - val_acc: 0.9518\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9620\n",
      "Epoch 00081: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1138 - acc: 0.9620 - val_loss: 0.1662 - val_acc: 0.9532\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9604\n",
      "Epoch 00082: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1188 - acc: 0.9604 - val_loss: 0.1667 - val_acc: 0.9539\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9623\n",
      "Epoch 00083: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1093 - acc: 0.9623 - val_loss: 0.1712 - val_acc: 0.9522\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9615\n",
      "Epoch 00084: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1113 - acc: 0.9615 - val_loss: 0.1601 - val_acc: 0.9527\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9623\n",
      "Epoch 00085: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1104 - acc: 0.9623 - val_loss: 0.1617 - val_acc: 0.9539\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9641\n",
      "Epoch 00086: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1081 - acc: 0.9641 - val_loss: 0.1711 - val_acc: 0.9520\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9621\n",
      "Epoch 00087: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1097 - acc: 0.9621 - val_loss: 0.1791 - val_acc: 0.9504\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9635\n",
      "Epoch 00088: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1041 - acc: 0.9635 - val_loss: 0.1734 - val_acc: 0.9557\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9642\n",
      "Epoch 00089: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1039 - acc: 0.9642 - val_loss: 0.1661 - val_acc: 0.9543\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9658\n",
      "Epoch 00090: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0993 - acc: 0.9658 - val_loss: 0.1751 - val_acc: 0.9541\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9667\n",
      "Epoch 00091: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0962 - acc: 0.9667 - val_loss: 0.1736 - val_acc: 0.9548\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9652\n",
      "Epoch 00092: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0998 - acc: 0.9652 - val_loss: 0.1771 - val_acc: 0.9539\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9645\n",
      "Epoch 00093: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1033 - acc: 0.9645 - val_loss: 0.1668 - val_acc: 0.9541\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9667\n",
      "Epoch 00094: val_loss did not improve from 0.15928\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0959 - acc: 0.9667 - val_loss: 0.1736 - val_acc: 0.9569\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9648\n",
      "Epoch 00095: val_loss improved from 0.15928 to 0.15633, saving model to model/checkpoint/1D_CNN_8_conv_custom_conv_3_DO_checkpoint/095-0.1563.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0999 - acc: 0.9648 - val_loss: 0.1563 - val_acc: 0.9567\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9694\n",
      "Epoch 00096: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0924 - acc: 0.9694 - val_loss: 0.1722 - val_acc: 0.9543\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9689\n",
      "Epoch 00097: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0907 - acc: 0.9689 - val_loss: 0.1756 - val_acc: 0.9588\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9682\n",
      "Epoch 00098: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0945 - acc: 0.9682 - val_loss: 0.1791 - val_acc: 0.9567\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9699\n",
      "Epoch 00099: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0908 - acc: 0.9699 - val_loss: 0.1834 - val_acc: 0.9511\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9694\n",
      "Epoch 00100: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0909 - acc: 0.9694 - val_loss: 0.1655 - val_acc: 0.9567\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9696\n",
      "Epoch 00101: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0864 - acc: 0.9696 - val_loss: 0.1722 - val_acc: 0.9539\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9696\n",
      "Epoch 00102: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0867 - acc: 0.9696 - val_loss: 0.1631 - val_acc: 0.9578\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9695\n",
      "Epoch 00103: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0890 - acc: 0.9695 - val_loss: 0.1783 - val_acc: 0.9541\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9712\n",
      "Epoch 00104: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0839 - acc: 0.9713 - val_loss: 0.1836 - val_acc: 0.9578\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9700\n",
      "Epoch 00105: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0866 - acc: 0.9700 - val_loss: 0.1775 - val_acc: 0.9553\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9713\n",
      "Epoch 00106: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0862 - acc: 0.9713 - val_loss: 0.1766 - val_acc: 0.9539\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9742\n",
      "Epoch 00107: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0796 - acc: 0.9742 - val_loss: 0.1808 - val_acc: 0.9564\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9706\n",
      "Epoch 00108: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0870 - acc: 0.9706 - val_loss: 0.1732 - val_acc: 0.9532\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9722\n",
      "Epoch 00109: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0809 - acc: 0.9722 - val_loss: 0.1845 - val_acc: 0.9488\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9726\n",
      "Epoch 00110: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0796 - acc: 0.9726 - val_loss: 0.1818 - val_acc: 0.9539\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9724\n",
      "Epoch 00111: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0801 - acc: 0.9724 - val_loss: 0.1826 - val_acc: 0.9553\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9748\n",
      "Epoch 00112: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0747 - acc: 0.9748 - val_loss: 0.1906 - val_acc: 0.9506\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9738\n",
      "Epoch 00113: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0773 - acc: 0.9738 - val_loss: 0.1763 - val_acc: 0.9527\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9741\n",
      "Epoch 00114: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0797 - acc: 0.9741 - val_loss: 0.1969 - val_acc: 0.9536\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9742\n",
      "Epoch 00115: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0753 - acc: 0.9742 - val_loss: 0.1806 - val_acc: 0.9550\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9745\n",
      "Epoch 00116: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0741 - acc: 0.9745 - val_loss: 0.1707 - val_acc: 0.9567\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9752\n",
      "Epoch 00117: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0726 - acc: 0.9752 - val_loss: 0.1765 - val_acc: 0.9592\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9740\n",
      "Epoch 00118: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0739 - acc: 0.9740 - val_loss: 0.1980 - val_acc: 0.9553\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9760\n",
      "Epoch 00119: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0700 - acc: 0.9760 - val_loss: 0.1677 - val_acc: 0.9553\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9781\n",
      "Epoch 00120: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0672 - acc: 0.9781 - val_loss: 0.1957 - val_acc: 0.9555\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9754\n",
      "Epoch 00121: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0728 - acc: 0.9754 - val_loss: 0.1789 - val_acc: 0.9581\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9757\n",
      "Epoch 00122: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0721 - acc: 0.9757 - val_loss: 0.1718 - val_acc: 0.9562\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9758\n",
      "Epoch 00123: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0700 - acc: 0.9758 - val_loss: 0.1921 - val_acc: 0.9539\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9767\n",
      "Epoch 00124: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0688 - acc: 0.9767 - val_loss: 0.1711 - val_acc: 0.9576\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9768\n",
      "Epoch 00125: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0665 - acc: 0.9769 - val_loss: 0.1802 - val_acc: 0.9574\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9760\n",
      "Epoch 00126: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0703 - acc: 0.9759 - val_loss: 0.1663 - val_acc: 0.9574\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9765\n",
      "Epoch 00127: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0681 - acc: 0.9765 - val_loss: 0.1604 - val_acc: 0.9602\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9785\n",
      "Epoch 00128: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0631 - acc: 0.9785 - val_loss: 0.1899 - val_acc: 0.9539\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9781\n",
      "Epoch 00129: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0645 - acc: 0.9781 - val_loss: 0.1765 - val_acc: 0.9588\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9785\n",
      "Epoch 00130: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0625 - acc: 0.9785 - val_loss: 0.1961 - val_acc: 0.9539\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9778\n",
      "Epoch 00131: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0659 - acc: 0.9778 - val_loss: 0.1706 - val_acc: 0.9623\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9782\n",
      "Epoch 00132: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0630 - acc: 0.9782 - val_loss: 0.1838 - val_acc: 0.9571\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9795\n",
      "Epoch 00133: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0608 - acc: 0.9795 - val_loss: 0.1936 - val_acc: 0.9553\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9792\n",
      "Epoch 00134: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0624 - acc: 0.9792 - val_loss: 0.1766 - val_acc: 0.9555\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9785\n",
      "Epoch 00135: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0641 - acc: 0.9785 - val_loss: 0.2069 - val_acc: 0.9555\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9795\n",
      "Epoch 00136: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0598 - acc: 0.9795 - val_loss: 0.1825 - val_acc: 0.9562\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9789\n",
      "Epoch 00137: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0606 - acc: 0.9789 - val_loss: 0.1986 - val_acc: 0.9557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9797\n",
      "Epoch 00138: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0586 - acc: 0.9797 - val_loss: 0.1890 - val_acc: 0.9543\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9795\n",
      "Epoch 00139: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0612 - acc: 0.9795 - val_loss: 0.1957 - val_acc: 0.9560\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9804\n",
      "Epoch 00140: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0591 - acc: 0.9804 - val_loss: 0.1899 - val_acc: 0.9574\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9799\n",
      "Epoch 00141: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0601 - acc: 0.9799 - val_loss: 0.1732 - val_acc: 0.9571\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9812\n",
      "Epoch 00142: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0551 - acc: 0.9813 - val_loss: 0.1935 - val_acc: 0.9564\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9801\n",
      "Epoch 00143: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0609 - acc: 0.9801 - val_loss: 0.1818 - val_acc: 0.9571\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9804\n",
      "Epoch 00144: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0566 - acc: 0.9804 - val_loss: 0.1840 - val_acc: 0.9555\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9800\n",
      "Epoch 00145: val_loss did not improve from 0.15633\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0572 - acc: 0.9800 - val_loss: 0.1896 - val_acc: 0.9571\n",
      "\n",
      "1D_CNN_8_conv_custom_conv_3_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 545us/sample - loss: 0.1899 - acc: 0.9443\n",
      "Loss: 0.18985166766933192 Accuracy: 0.9443406\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2601 - acc: 0.2634\n",
      "Epoch 00001: val_loss improved from inf to 1.43353, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/001-1.4335.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 2.2600 - acc: 0.2635 - val_loss: 1.4335 - val_acc: 0.5563\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3645 - acc: 0.5537\n",
      "Epoch 00002: val_loss improved from 1.43353 to 0.93191, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/002-0.9319.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 1.3646 - acc: 0.5536 - val_loss: 0.9319 - val_acc: 0.7205\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0144 - acc: 0.6708\n",
      "Epoch 00003: val_loss improved from 0.93191 to 0.70810, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/003-0.7081.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.0144 - acc: 0.6708 - val_loss: 0.7081 - val_acc: 0.7780\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8364 - acc: 0.7298\n",
      "Epoch 00004: val_loss improved from 0.70810 to 0.60942, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/004-0.6094.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.8365 - acc: 0.7297 - val_loss: 0.6094 - val_acc: 0.8083\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7257 - acc: 0.7667\n",
      "Epoch 00005: val_loss improved from 0.60942 to 0.50124, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/005-0.5012.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.7258 - acc: 0.7667 - val_loss: 0.5012 - val_acc: 0.8470\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6396 - acc: 0.7935\n",
      "Epoch 00006: val_loss improved from 0.50124 to 0.46069, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/006-0.4607.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.6395 - acc: 0.7935 - val_loss: 0.4607 - val_acc: 0.8579\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5690 - acc: 0.8177\n",
      "Epoch 00007: val_loss improved from 0.46069 to 0.41163, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/007-0.4116.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.5690 - acc: 0.8176 - val_loss: 0.4116 - val_acc: 0.8726\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5258 - acc: 0.8304\n",
      "Epoch 00008: val_loss improved from 0.41163 to 0.35986, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/008-0.3599.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5257 - acc: 0.8304 - val_loss: 0.3599 - val_acc: 0.8928\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4765 - acc: 0.8466\n",
      "Epoch 00009: val_loss improved from 0.35986 to 0.34912, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/009-0.3491.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4765 - acc: 0.8466 - val_loss: 0.3491 - val_acc: 0.8919\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4357 - acc: 0.8598\n",
      "Epoch 00010: val_loss improved from 0.34912 to 0.34117, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/010-0.3412.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4357 - acc: 0.8598 - val_loss: 0.3412 - val_acc: 0.8915\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4110 - acc: 0.8699\n",
      "Epoch 00011: val_loss improved from 0.34117 to 0.28881, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/011-0.2888.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4110 - acc: 0.8699 - val_loss: 0.2888 - val_acc: 0.9131\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3741 - acc: 0.8792\n",
      "Epoch 00012: val_loss improved from 0.28881 to 0.28211, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/012-0.2821.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3742 - acc: 0.8792 - val_loss: 0.2821 - val_acc: 0.9140\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3538 - acc: 0.8863\n",
      "Epoch 00013: val_loss improved from 0.28211 to 0.25046, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/013-0.2505.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3538 - acc: 0.8863 - val_loss: 0.2505 - val_acc: 0.9220\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3308 - acc: 0.8944\n",
      "Epoch 00014: val_loss did not improve from 0.25046\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3311 - acc: 0.8943 - val_loss: 0.2645 - val_acc: 0.9168\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3267 - acc: 0.8970\n",
      "Epoch 00015: val_loss improved from 0.25046 to 0.24713, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/015-0.2471.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3267 - acc: 0.8970 - val_loss: 0.2471 - val_acc: 0.9229\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.9054\n",
      "Epoch 00016: val_loss improved from 0.24713 to 0.23940, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/016-0.2394.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2969 - acc: 0.9054 - val_loss: 0.2394 - val_acc: 0.9234\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2837 - acc: 0.9091\n",
      "Epoch 00017: val_loss did not improve from 0.23940\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2837 - acc: 0.9091 - val_loss: 0.2398 - val_acc: 0.9238\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2711 - acc: 0.9133\n",
      "Epoch 00018: val_loss improved from 0.23940 to 0.23560, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/018-0.2356.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2711 - acc: 0.9133 - val_loss: 0.2356 - val_acc: 0.9262\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2587 - acc: 0.9162\n",
      "Epoch 00019: val_loss improved from 0.23560 to 0.23012, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/019-0.2301.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2587 - acc: 0.9162 - val_loss: 0.2301 - val_acc: 0.9283\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2517 - acc: 0.9183\n",
      "Epoch 00020: val_loss improved from 0.23012 to 0.20122, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/020-0.2012.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2517 - acc: 0.9183 - val_loss: 0.2012 - val_acc: 0.9369\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2392 - acc: 0.9214\n",
      "Epoch 00021: val_loss did not improve from 0.20122\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2392 - acc: 0.9214 - val_loss: 0.2050 - val_acc: 0.9324\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2292 - acc: 0.9241\n",
      "Epoch 00022: val_loss improved from 0.20122 to 0.19252, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/022-0.1925.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2292 - acc: 0.9241 - val_loss: 0.1925 - val_acc: 0.9397\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2217 - acc: 0.9283\n",
      "Epoch 00023: val_loss did not improve from 0.19252\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2217 - acc: 0.9282 - val_loss: 0.2154 - val_acc: 0.9343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2146 - acc: 0.9305\n",
      "Epoch 00024: val_loss improved from 0.19252 to 0.19247, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/024-0.1925.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2147 - acc: 0.9305 - val_loss: 0.1925 - val_acc: 0.9404\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2084 - acc: 0.9319\n",
      "Epoch 00025: val_loss improved from 0.19247 to 0.17917, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/025-0.1792.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2083 - acc: 0.9319 - val_loss: 0.1792 - val_acc: 0.9446\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9361\n",
      "Epoch 00026: val_loss improved from 0.17917 to 0.17511, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/026-0.1751.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1980 - acc: 0.9361 - val_loss: 0.1751 - val_acc: 0.9432\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1901 - acc: 0.9383\n",
      "Epoch 00027: val_loss did not improve from 0.17511\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1901 - acc: 0.9383 - val_loss: 0.1796 - val_acc: 0.9462\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1845 - acc: 0.9396\n",
      "Epoch 00028: val_loss did not improve from 0.17511\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1845 - acc: 0.9396 - val_loss: 0.1984 - val_acc: 0.9399\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9413\n",
      "Epoch 00029: val_loss did not improve from 0.17511\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1790 - acc: 0.9413 - val_loss: 0.1865 - val_acc: 0.9397\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9421\n",
      "Epoch 00030: val_loss did not improve from 0.17511\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1735 - acc: 0.9421 - val_loss: 0.1820 - val_acc: 0.9450\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9444\n",
      "Epoch 00031: val_loss improved from 0.17511 to 0.17125, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/031-0.1712.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1710 - acc: 0.9444 - val_loss: 0.1712 - val_acc: 0.9488\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9462\n",
      "Epoch 00032: val_loss improved from 0.17125 to 0.16544, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/032-0.1654.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1619 - acc: 0.9462 - val_loss: 0.1654 - val_acc: 0.9504\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9479\n",
      "Epoch 00033: val_loss did not improve from 0.16544\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1579 - acc: 0.9479 - val_loss: 0.1673 - val_acc: 0.9499\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9500\n",
      "Epoch 00034: val_loss did not improve from 0.16544\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1522 - acc: 0.9500 - val_loss: 0.1742 - val_acc: 0.9488\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9519\n",
      "Epoch 00035: val_loss did not improve from 0.16544\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1476 - acc: 0.9519 - val_loss: 0.1708 - val_acc: 0.9467\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9509\n",
      "Epoch 00036: val_loss did not improve from 0.16544\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1499 - acc: 0.9509 - val_loss: 0.2300 - val_acc: 0.9322\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9529\n",
      "Epoch 00037: val_loss did not improve from 0.16544\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1448 - acc: 0.9529 - val_loss: 0.1827 - val_acc: 0.9490\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9559\n",
      "Epoch 00038: val_loss did not improve from 0.16544\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1344 - acc: 0.9559 - val_loss: 0.1753 - val_acc: 0.9506\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9577\n",
      "Epoch 00039: val_loss improved from 0.16544 to 0.16506, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/039-0.1651.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1299 - acc: 0.9577 - val_loss: 0.1651 - val_acc: 0.9513\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9571\n",
      "Epoch 00040: val_loss improved from 0.16506 to 0.16473, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/040-0.1647.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1269 - acc: 0.9571 - val_loss: 0.1647 - val_acc: 0.9513\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9579\n",
      "Epoch 00041: val_loss improved from 0.16473 to 0.16412, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/041-0.1641.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1261 - acc: 0.9579 - val_loss: 0.1641 - val_acc: 0.9532\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9599\n",
      "Epoch 00042: val_loss improved from 0.16412 to 0.16071, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/042-0.1607.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1189 - acc: 0.9599 - val_loss: 0.1607 - val_acc: 0.9520\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9613\n",
      "Epoch 00043: val_loss did not improve from 0.16071\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1142 - acc: 0.9613 - val_loss: 0.1616 - val_acc: 0.9525\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9609\n",
      "Epoch 00044: val_loss did not improve from 0.16071\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1160 - acc: 0.9609 - val_loss: 0.1759 - val_acc: 0.9490\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9598\n",
      "Epoch 00045: val_loss improved from 0.16071 to 0.15605, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/045-0.1560.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1161 - acc: 0.9598 - val_loss: 0.1560 - val_acc: 0.9562\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9633\n",
      "Epoch 00046: val_loss did not improve from 0.15605\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1064 - acc: 0.9633 - val_loss: 0.1797 - val_acc: 0.9499\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9645\n",
      "Epoch 00047: val_loss improved from 0.15605 to 0.15192, saving model to model/checkpoint/1D_CNN_9_conv_custom_conv_3_DO_checkpoint/047-0.1519.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1070 - acc: 0.9645 - val_loss: 0.1519 - val_acc: 0.9557\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9652\n",
      "Epoch 00048: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1037 - acc: 0.9652 - val_loss: 0.1594 - val_acc: 0.9560\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9661\n",
      "Epoch 00049: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0995 - acc: 0.9661 - val_loss: 0.1604 - val_acc: 0.9541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9656\n",
      "Epoch 00050: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1010 - acc: 0.9656 - val_loss: 0.1719 - val_acc: 0.9536\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9677\n",
      "Epoch 00051: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0944 - acc: 0.9677 - val_loss: 0.1719 - val_acc: 0.9504\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9662\n",
      "Epoch 00052: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0985 - acc: 0.9662 - val_loss: 0.1682 - val_acc: 0.9539\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9691\n",
      "Epoch 00053: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0884 - acc: 0.9691 - val_loss: 0.1673 - val_acc: 0.9562\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9692\n",
      "Epoch 00054: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0900 - acc: 0.9692 - val_loss: 0.1563 - val_acc: 0.9567\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9699\n",
      "Epoch 00055: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0856 - acc: 0.9699 - val_loss: 0.1643 - val_acc: 0.9555\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9704\n",
      "Epoch 00056: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0863 - acc: 0.9704 - val_loss: 0.1639 - val_acc: 0.9534\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9714\n",
      "Epoch 00057: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0821 - acc: 0.9714 - val_loss: 0.1649 - val_acc: 0.9557\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9723\n",
      "Epoch 00058: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0822 - acc: 0.9723 - val_loss: 0.1739 - val_acc: 0.9529\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9743\n",
      "Epoch 00059: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0758 - acc: 0.9743 - val_loss: 0.1614 - val_acc: 0.9553\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9735\n",
      "Epoch 00060: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0790 - acc: 0.9735 - val_loss: 0.1604 - val_acc: 0.9564\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9738\n",
      "Epoch 00061: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0758 - acc: 0.9738 - val_loss: 0.1827 - val_acc: 0.9546\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9735\n",
      "Epoch 00062: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0751 - acc: 0.9735 - val_loss: 0.1873 - val_acc: 0.9529\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9748\n",
      "Epoch 00063: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0755 - acc: 0.9748 - val_loss: 0.1731 - val_acc: 0.9509\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9762\n",
      "Epoch 00064: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0685 - acc: 0.9762 - val_loss: 0.1707 - val_acc: 0.9557\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9755\n",
      "Epoch 00065: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0701 - acc: 0.9755 - val_loss: 0.1651 - val_acc: 0.9576\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9769\n",
      "Epoch 00066: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0665 - acc: 0.9769 - val_loss: 0.1768 - val_acc: 0.9557\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9761\n",
      "Epoch 00067: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0688 - acc: 0.9761 - val_loss: 0.1954 - val_acc: 0.9520\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9773\n",
      "Epoch 00068: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0664 - acc: 0.9773 - val_loss: 0.1916 - val_acc: 0.9511\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9763\n",
      "Epoch 00069: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0662 - acc: 0.9763 - val_loss: 0.1751 - val_acc: 0.9560\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9782\n",
      "Epoch 00070: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0643 - acc: 0.9782 - val_loss: 0.1745 - val_acc: 0.9562\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9782\n",
      "Epoch 00071: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0637 - acc: 0.9782 - val_loss: 0.1844 - val_acc: 0.9522\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9793\n",
      "Epoch 00072: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0615 - acc: 0.9793 - val_loss: 0.1752 - val_acc: 0.9571\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9786\n",
      "Epoch 00073: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0622 - acc: 0.9786 - val_loss: 0.2007 - val_acc: 0.9511\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9815\n",
      "Epoch 00074: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0547 - acc: 0.9815 - val_loss: 0.1961 - val_acc: 0.9536\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9805\n",
      "Epoch 00075: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0564 - acc: 0.9805 - val_loss: 0.1759 - val_acc: 0.9583\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9806\n",
      "Epoch 00076: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0554 - acc: 0.9806 - val_loss: 0.1884 - val_acc: 0.9569\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9806\n",
      "Epoch 00077: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0546 - acc: 0.9806 - val_loss: 0.1842 - val_acc: 0.9578\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9815\n",
      "Epoch 00078: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0537 - acc: 0.9815 - val_loss: 0.1991 - val_acc: 0.9534\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9809\n",
      "Epoch 00079: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0560 - acc: 0.9809 - val_loss: 0.1800 - val_acc: 0.9574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9818\n",
      "Epoch 00080: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0518 - acc: 0.9819 - val_loss: 0.1831 - val_acc: 0.9583\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9830\n",
      "Epoch 00081: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0517 - acc: 0.9830 - val_loss: 0.1747 - val_acc: 0.9567\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9831\n",
      "Epoch 00082: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0489 - acc: 0.9831 - val_loss: 0.1931 - val_acc: 0.9560\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9830\n",
      "Epoch 00083: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0488 - acc: 0.9830 - val_loss: 0.1889 - val_acc: 0.9585\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9840\n",
      "Epoch 00084: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0483 - acc: 0.9841 - val_loss: 0.1868 - val_acc: 0.9576\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9850\n",
      "Epoch 00085: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0446 - acc: 0.9850 - val_loss: 0.2075 - val_acc: 0.9564\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9833\n",
      "Epoch 00086: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0491 - acc: 0.9833 - val_loss: 0.1785 - val_acc: 0.9569\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9839\n",
      "Epoch 00087: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0464 - acc: 0.9839 - val_loss: 0.1893 - val_acc: 0.9569\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9833\n",
      "Epoch 00088: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0490 - acc: 0.9833 - val_loss: 0.1812 - val_acc: 0.9574\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9846\n",
      "Epoch 00089: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0445 - acc: 0.9846 - val_loss: 0.2006 - val_acc: 0.9567\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9847\n",
      "Epoch 00090: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0449 - acc: 0.9847 - val_loss: 0.1872 - val_acc: 0.9581\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9850\n",
      "Epoch 00091: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0435 - acc: 0.9850 - val_loss: 0.1982 - val_acc: 0.9583\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9860\n",
      "Epoch 00092: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0393 - acc: 0.9860 - val_loss: 0.1882 - val_acc: 0.9599\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9842\n",
      "Epoch 00093: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0450 - acc: 0.9842 - val_loss: 0.1928 - val_acc: 0.9571\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9848\n",
      "Epoch 00094: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0452 - acc: 0.9848 - val_loss: 0.1738 - val_acc: 0.9588\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9860\n",
      "Epoch 00095: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0391 - acc: 0.9860 - val_loss: 0.1996 - val_acc: 0.9571\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9861\n",
      "Epoch 00096: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0422 - acc: 0.9860 - val_loss: 0.1891 - val_acc: 0.9581\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9855\n",
      "Epoch 00097: val_loss did not improve from 0.15192\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0418 - acc: 0.9855 - val_loss: 0.2036 - val_acc: 0.9581\n",
      "\n",
      "1D_CNN_9_conv_custom_conv_3_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8VNX5+PHPmX2yb+wBAkrZZQkgior7hsVdbKUurdr219r6tVVRu1jbfl1qW2tr61ZbrftXtHWrtKiIG8oiCgiKbEJYkpB9ktmf3x9nEgIkIYEMIZnn/XrdVzJ37nLu3Jnz3HPPuecYEUEppZRqiaOrE6CUUurQpUFCKaVUqzRIKKWUapUGCaWUUq3SIKGUUqpVGiSUUkq1SoOEUkqpVmmQUEop1SoNEkoppVrl6uoEdFRBQYEUFRV1dTKUUqpbWbp0abmI9Oroet0uSBQVFbFkyZKuToZSSnUrxphN+7Oe3m5SSinVKg0SSimlWqVBQimlVKu6XZ1ESyKRCFu2bCEYDHZ1Urotn89HYWEhbre7q5OilDqE9IggsWXLFjIzMykqKsIY09XJ6XZEhJ07d7JlyxaGDBnS1clRSh1CesTtpmAwSH5+vgaI/WSMIT8/X0tiSqm99IggAWiAOED6+SmlWtJjgsS+xGINhEIlxOORrk6KUkp1GykTJOLxIOHwNkQ6P0hUVVXx5z//eb/WPfPMM6mqqmr38rfeeit33333fu1LKaU6KmWChDGNhxrv9G23FSSi0Wib67766qvk5OR0epqUUqozpEyQaDxUkc4PEnPmzGHdunWMHz+e66+/ngULFnDssccyc+ZMRo0aBcA555xDcXExo0eP5sEHH2xat6ioiPLycjZu3MjIkSO56qqrGD16NKeeeioNDQ1t7nf58uVMnTqVI444gnPPPZfKykoA7r33XkaNGsURRxzBxRdfDMBbb73F+PHjGT9+PBMmTKC2trbTPwelVM/TI5rANrd27bXU1S1v4Z0YsVg9DocfYzp22BkZ4xk27J5W37/jjjtYuXIly5fb/S5YsIBly5axcuXKpialjzzyCHl5eTQ0NDB58mTOP/988vPz90j7Wp566ikeeughLrroIubOncvs2bNb3e+ll17KH//4R6ZPn87PfvYzfvGLX3DPPfdwxx13sGHDBrxeb9OtrLvvvpv77ruPadOmUVdXh8/n69BnoJRKTSlUkji4rXemTJmy2zMH9957L+PGjWPq1Kls3ryZtWvX7rXOkCFDGD9+PADFxcVs3Lix1e1XV1dTVVXF9OnTAbjssstYuHAhAEcccQSXXHIJjz/+OC6XDYjTpk3juuuu495776WqqqppvlJKtaXH5RStXfHH4yECgRV4vUV4PAVJT0d6enrT/wsWLGD+/Pm8//77pKWlcfzxx7f4TILX62363+l07vN2U2teeeUVFi5cyEsvvcSvf/1rVqxYwZw5c5gxYwavvvoq06ZNY968eYwYMWK/tq+USh0pVJJIXsV1ZmZmm/f4q6uryc3NJS0tjTVr1rBo0aID3md2dja5ubm8/fbbAPzjH/9g+vTpxONxNm/ezAknnMCdd95JdXU1dXV1rFu3jrFjx3LjjTcyefJk1qxZc8BpUEr1fD2uJNGaxtZNyai4zs/PZ9q0aYwZM4YzzjiDGTNm7Pb+6aefzv3338/IkSMZPnw4U6dO7ZT9Pvroo3znO9+hvr6eoUOH8re//Y1YLMbs2bOprq5GRPjBD35ATk4OP/3pT3nzzTdxOByMHj2aM844o1PSoJTq2YyIdHUaOmTSpEmy56BDq1evZuTIkW2uJyLU1S3F4+mP19s/mUnsttrzOSqluidjzFIRmdTR9VLmdpPtdsIkpSShlFI9VcoECctJMuoklFKqp0qpIGGMQ0sSSinVASkVJOzhapBQSqn2SqkgYUsSsa5OhlJKdRspFSS0JKGUUh2TUkHiUKqTyMjI6NB8pZTqCikVJLQkoZRSHZNSQSJZJYk5c+Zw3333Nb1uHBiorq6Ok046iYkTJzJ27Fj+9a9/tXubIsL111/PmDFjGDt2LM888wwA27Zt47jjjmP8+PGMGTOGt99+m1gsxuWXX9607O9///tOP0alVGrqed1yXHstLG+pq3DwxoOIRMHZwVs648fDPa13FT5r1iyuvfZavve97wHw7LPPMm/ePHw+Hy+88AJZWVmUl5czdepUZs6c2a7xpJ9//nmWL1/Oxx9/THl5OZMnT+a4447jySef5LTTTuOWW24hFotRX1/P8uXLKSkpYeXKlQAdGulOKaXa0vOCRJsMyeiEZMKECZSWlrJ161bKysrIzc1l4MCBRCIRbr75ZhYuXIjD4aCkpIQdO3bQt2/ffW7znXfe4Wtf+xpOp5M+ffowffp0Fi9ezOTJk/nmN79JJBLhnHPOYfz48QwdOpT169dzzTXXMGPGDE499dQkHKVSKhUlLUgYYwYCjwF9AAEeFJE/7LGMAf4AnAnUA5eLyLID2nEbV/yR0BbC4R1kZhYf0C5acuGFF/Lcc8+xfft2Zs2aBcATTzxBWVkZS5cuxe12U1RU1GIX4R1x3HHHsXDhQl555RUuv/xyrrvuOi699FI+/vhj5s2bx/3338+zzz7LI4880hmHpZRKccmsk4gCPxKRUcBU4HvGmFF7LHMGMCwxXQ38JYnpwR6ukIxODWfNmsXTTz/Nc889x4UXXgjYLsJ79+6N2+3mzTffZNOmTe3e3rHHHsszzzxDLBajrKyMhQsXMmXKFDZt2kSfPn246qqruPLKK1m2bBnl5eXE43HOP/98fvWrX7Fs2YHFWaWUapS0koSIbAO2Jf6vNcasBgYAnzZb7GzgMbG59iJjTI4xpl9i3U7X2F24beHk7NRtjx49mtraWgYMGEC/fv0AuOSSS/jqV7/K2LFjmTRpUocG+Tn33HN5//33GTduHMYY7rrrLvr27cujjz7Kb37zG9xuNxkZGTz22GOUlJRwxRVXEI/bSvnbb7+9U49NKZW6DkpX4caYImAhMEZEaprNfxm4Q0TeSbx+HbhRRJbssf7V2JIGgwYNKt7ziry9XVyHw6WEQl+Snj4Oh8N9QMfUE2lX4Ur1XIdsV+HGmAxgLnBt8wDRESLyoIhMEpFJvXr1OoC0JG90OqWU6omSGiSMMW5sgHhCRJ5vYZESYGCz14WJeUmSvNHplFKqJ0pakEi0XPorsFpEftfKYi8ClxprKlCdrPoIm6bGeggNEkop1R7JfE5iGvANYIUxpvHptpuBQQAicj/wKrb56xfYJrBXJDE9aElCKaU6Jpmtm94B2ny0ONGq6XvJSsOetE5CKaU6JqX6btpVktAxJZRSqj1SKkgkqyRRVVXFn//85/1a98wzz9S+lpRSh6yUChLJqpNoK0hEo9E213311VfJycnp1PQopVRnSakgkaySxJw5c1i3bh3jx4/n+uuvZ8GCBRx77LHMnDmTUaNsTyTnnHMOxcXFjB49mgcffLBp3aKiIsrLy9m4cSMjR47kqquuYvTo0Zx66qk0NDTsta+XXnqJI488kgkTJnDyySezY8cOAOrq6rjiiisYO3YsRxxxBHPnzgXgtddeY+LEiYwbN46TTjqpU49bKdXz9bheYNvoKRxwEIsNxxgPjg6Ex330FM4dd9zBypUrWZ7Y8YIFC1i2bBkrV65kyJAhADzyyCPk5eXR0NDA5MmTOf/888nPz99tO2vXruWpp57ioYce4qKLLmLu3LnMnj17t2WOOeYYFi1ahDGGhx9+mLvuuovf/va3/PKXvyQ7O5sVK1YAUFlZSVlZGVdddRULFy5kyJAhVFRUtP+glVKKHhgk2rbvcRw6y5QpU5oCBMC9997LCy+8AMDmzZtZu3btXkFiyJAhjB8/HoDi4mI2bty413a3bNnCrFmz2LZtG+FwuGkf8+fP5+mnn25aLjc3l5deeonjjjuuaZm8vLxOPUalVM/X44JEW1f8ALW1X+B25+PzDUpqOtLT05v+X7BgAfPnz+f9998nLS2N448/vsUuw71eb9P/TqezxdtN11xzDddddx0zZ85kwYIF3HrrrUlJv1JKQYrVSUByhjDNzMyktra21ferq6vJzc0lLS2NNWvWsGjRov3eV3V1NQMGDADg0UcfbZp/yimn7DaEamVlJVOnTmXhwoVs2LABQG83KaU6LOWChD3kzg0S+fn5TJs2jTFjxnD99dfv9f7pp59ONBpl5MiRzJkzh6lTp+73vm699VYuvPBCiouLKSgoaJr/k5/8hMrKSsaMGcO4ceN488036dWrFw8++CDnnXce48aNaxoMSSml2uugdBXemSZNmiRLluzWk3iHurgOBFZhjJe0tMOTkbxuTbsKV6rnOmS7Cj/0dH5JQimleqqUCxLJqJNQSqmeKuWChB22VIOEUkq1R8oFCS1JKKVU+6VckNA6CaWUar+UCxJaklBKqfZLuSBhD7nrx5PIyMjo6iQopdQ+pVyQsD3BCt3t+RCllOoKKRckdh1y591ymjNnzm5dYtx6663cfffd1NXVcdJJJzFx4kTGjh3Lv/71r31uq7UuxVvq8ru17sGVUqqz9LgO/q597VqWb2+1r3BEIsTjQZzODNrbK+z4vuO55/TWew6cNWsW1157Ld/7nh2u+9lnn2XevHn4fD5eeOEFsrKyKC8vZ+rUqcycORNjWt9vS12Kx+PxFrv8bql7cKWU6kw9Lki0n9BZXYdPmDCB0tJStm7dSllZGbm5uQwcOJBIJMLNN9/MwoULcTgclJSUsGPHDvr27dvqtlrqUrysrKzFLr9b6h5cKaU6U48LEm1d8QNEIhUEg+tJSxuN0+nvtP1eeOGFPPfcc2zfvr2pI70nnniCsrIyli5ditvtpqioqMUuwhu1t0txpZQ6WLROopPMmjWLp59+mueee44LL7wQsN169+7dG7fbzZtvvsmmTZva3EZrXYq31uV3S92DK6VUZ0q5INE4znVnPysxevRoamtrGTBgAP369QPgkksuYcmSJYwdO5bHHnuMESNGtLmN1roUb63L75a6B1dKqc6Ucl2Fx2J11Nevwe8fhsuVnYwkdlvaVbhSPZd2Fd5uySlJKKVUT5RyQaLxdpP236SUUvvWY4JE+2+baUmiJd3ttqNS6uDoEUHC5/Oxc+fOdmV0u0oSXd9/06FCRNi5cyc+n6+rk6KUOsT0iOckCgsL2bJlC2VlZftcVkQIhcpxuaK4XNpktJHP56OwsLCrk6GUOsT0iCDhdrubnkZuj7feGs/AgT9m6ND/TWKqlFKq++sRt5s6yuFIIxar7+pkKKXUIS8lg4TTmUY8rkFCKaX2JSWDhC1JBLo6GUopdchLySDhdKZrSUIppdohaUHCGPOIMabUGLOylfePN8ZUG2OWJ6afJSste3I6tU5CKaXaI5mtm/4O/Al4rI1l3haRs5KYhhY5HFonoZRS7ZG0koSILAQqkrX9A6ElCaWUap+urpM4yhjzsTHm38aY0Qdrp1qSUEqp9unKh+mWAYNFpM4YcybwT2BYSwsaY64GrgYYNGjQAe/YliS0dZNSSu1Ll5UkRKRGROoS/78KuI0xBa0s+6CITBKRSb169TrgfTsc6Xq7SSml2qHLgoQxpq8xxiT+n5JIy86DsW99mE4ppdonabebjDFPAccDBcaYLcDPATeAiNwPXAB81xgTBRqAi+Ug9Vdt6yQaEIk36xVWKaXUnpIWJETka/t4/0/YJrIHndOZBkA8Hmz6Xyml1N5S5zL6+echIwM+/xyHwwYGrbxWSqm2pU6Q8PshEICKCpzOdACtl1BKqX1InSCRl2f/VlQ03WLSFk5KKdW2lAwSjbebtCShlFJtS8kgoSUJpZRqn9QJEjk5YAzs3KklCaWUaqfUCRJOpw0Uu5UktHWTUkq1JXWCBNhbThUVuFz5AEQiB+UBb6WU6rZSMkh4PH0AQyhU0tUpUkqpQ1pKBgmHw43b3ZtweGtXp0gppQ5pKRkkALze/oRCGiSUUqotqRUk8vNhp62H8Hj6a0lCKaX2IbWCRF4eVFVBLKYlCaWUaofUCxIiUF2Nx9OfSKSUeDzS1alSSqlDVuoFCYCKCrze/oAQDu/o0iQppdShLGWDhMfTH0DrJZRSqg2pGSR27kyUJNB6CaWUakNqBYl8+6S1liSUUqp9UitI7Ha7qRfg1JKEUkq1oV1BwhjzQ2NMlrH+aoxZZow5NdmJ63Q5OfZvRQXGOPF4+mpJQiml2tDeksQ3RaQGOBXIBb4B3JG0VCWLywXZ2frUtVJKtVN7g4RJ/D0T+IeIrGo2r3vJy9OnrpVSqp3aGySWGmP+gw0S84wxmUA8eclKovx8LUkopVQ7udq53LeA8cB6Eak3xuQBVyQvWUnUrJM/j6c/0ehO4vEQDoe3ixOmlFKHnvaWJI4CPhORKmPMbOAnQHXykpVEe/QECxAKbevKFCml1CGrvUHiL0C9MWYc8CNgHfBY0lKVTHuUJECflVBKqda0N0hERUSAs4E/ich9QGbykpVEeXlQWQnxuD51rZRS+9DeOolaY8xN2KavxxpjHIA7eclKorw8iMdtT7DpWpJQSqm2tLckMQsIYZ+X2A4UAr9JWqqSqVnXHG53Psa4tSShlFKtaFeQSASGJ4BsY8xZQFBEum+dBCSeujb6rIRSSrWhvd1yXAR8CFwIXAR8YIy5IJkJS5pmQQL0WQmllGpLe+skbgEmi0gpgDGmFzAfeC5ZCUuaPYKEx9Of+vpPuzBBSil16GpvnYSjMUAk7OzAuoeWZmNKgJYklFKqLe0tSbxmjJkHPJV4PQt4NTlJSrIWShKxWDWxWACnM70LE6aUUoeedgUJEbneGHM+MC0x60EReSF5yUoilwuysprVSQwA7FPXaWmHd2XKlFLqkNPekgQiMheYm8S0HDwtdM0RDm/VIKGUUntos17BGFNrjKlpYao1xtTsY91HjDGlxpiVrbxvjDH3GmO+MMZ8YoyZeCAH0iEtdM2h9RJKKbW3NoOEiGSKSFYLU6aIZO1j238HTm/j/TOAYYnpamz/UAdHszEldpUkSg7a7pVSqrtIWgslEVkIVLSxyNnAY2ItAnKMMf2SlZ7dNCtJOJ1ZuFx51Nd/dlB2rZRS3Um76ySSYACwudnrLYl5e/XbbYy5GlvaYNCgQQe+52YDDxljyMycSG3t0gPfrlKqWxOBWAycTjAHMPZmPL5rCochGIRQCNxuyMwEn2/X9kUgGrXLNDTY5UR2bcvptO1tXC5ISwO//8COsaO6Mki0m4g8CDwIMGnSJNnH4vvWWJKIx8HhICOjmC1bfqeDD6luKxSC+nqbCXk8NkNpzPASX3McDpvhRCJ22T2nSGTX+g6HzbACAZt5uVx2vtttM72GBjvfGJvh+Xx2XzU1dmpo2JW2eNwuGwzadZ1Oux2XC6qrobQUysvt+l6vnRrTv6fGTDcctul1OHZloNGo/RwaM+XGKRKx22q+vcYMOhTalYE3TiJ2uxkZkJ5u0xuN2vSJ7NqfiD3Oxs+ipfS2xum0n2ckYrfdXjfeCHfc0f7lO0NXBokSYGCz14WJecnX2BNsbS1kZ5OZWYxIhEBgJZmZxQclCar7CARs7/LNr/QaM6lIZFfm0jzTcjptxltVZTNCsFeB6en2q1debqfqavsabCYTiezadmPGFI3aeY37afw/HLb7qKmxr7sDY3bPTF0u6NXLTi7Xrgw7GrXL7nk1b4zNXJsHksbPyuWy8z0eG7Sys+1Vt8u1a1uN+29Mg8+3KzA1Th6PTUMgYLMIkV1X87DrnIDdvt9vt+NodvO+MSA3prdxP5GI3WZtrT1/jcHS49m1Ha9317ZE7PcjGrXTxIPXvKdJVwaJF4HvG2OeBo4EqkXk4AwR1/yBuuxsMjMnAVBbu0SDxCGg8QotFNqVITgcUFdnM8Tqaigrs1egZWWJq9daobo2SjwuTT/oGCEC0VoC0RrqwyEaan001PgJ1HioD8ZoCMYIBgVHKB+3ZNirO18E+qwk2msp4QY3NV+MJbBxFMTckLseen0K2ZvBxO0EEMqEcKb9G3dD3GWnYA7U9YWGPLtseilkbLN/fVW4syrxZdVinFFwxBATx4UXF37c+HBLFm6ycTuycGaFMP4q8FXicTnJNQVkOArwu724M6twpFcSc1cTjgUJxoKEY2E8Jg2/IwufIxOPZOCK2ynDnUWOP4v89GyMt44a1zoqzTqqolupi9RSF6khFAuR6c0g25dJji+bXHdfcpwDyHb0J8uXQVaal4w0DzuDpayvWsfGqnXUxSrx+uJ4vHHSvT76ZxTSP6OQbG8220Mb2Vy3jtL6bQzMHszIvDEcnjMSrzdORXAnO+t3srlmMxsqN7ChagN14TrS3GmkudNwO9yEY2FCMRsJC7MKKcopon9mf8rry9lSs4WSmhLqwnVNy7mdbjLcGWR4MvC5fLidbtwONzGJUdlQSUVDBTXhGsIOF8bpxTi9OFw+XG4/4vLhARzxKGnxGMKuqBaXOLF4jGjcRgmXw4Xb6UaMg0A0SH2knoZoA7F4zC4rMRoiDQQiAerCdXg9Xgp6FVCQVoDX6aUyMT8Sj5DmTiPDnYHf7ScSixCOhQnHw0izqNo3Zwa2C72DJ2lBwhjzFHA8UGCM2QL8nMQYFCJyP/aJ7TOBL4B6DuaY2c275hgyBJ+vCJcrN+XrJUSEnQ07+bL6S76s/pJttdvwOD2kudPwuXxUh6opDZRSFigjPy2fsb3HMrbPWPqlF1IfMAQChtLqWtZWfM4XlZ+zofoLtlSXsL2+hJ2h7dTHagjFA4QlYH92cSeIE2IeiPiRiI94KJ1YIAeC2VA5BJZfDjuH2wS6gjDuUZjwCKSVg6cOPAFwhsAbhQO4U+iOZ+KL9Sbg3ELc0eyyfCoYHDhxE2X/LtddDhexPTIbgEhi6hSxxNSo8Qo8npiaz48CtYmpBX6XH6/LS11lXVNm2FkMZq/PYU+5vlyyvFk0RBuoj9QTiUXwurx4nV5iEqOiYe/2MD6Xj0xPJl6XF4/TQzQepS5cRyAcaAoujTxOD/n+fLK8WUTjUUKxEKFoiGA0SDAaJBLfdVacxonD7CoiGGNwOVw4jROAaDxKJB4hFo/hd/tJc6fhd/lxOVw4jANjDGnuNNLd6WR4MgjHwqwuX015fTnBaJBMTybpnnTcDjf1kXrqwnU0RBtwO9x4XV7cDvdu+x9ZMHK/PvcDkbQgISJf28f7AnwvWftvU7MxJaCx8rq4RwSJYDTIhyUfsnDTQj4s+ZBMbyZF2UUMyh7EtrptLNm6hKXblhKJRfhK/lcYXjAcn9PPiu2f8mn5SipDO/e5DxPzIs52ZpiBAqgdALX9IHQYRNLxkI7bbXB7org8MVzeME5fAw5vEMmoJdannIhzHRUyl/ixd1DE8RTK0XzseIRa2U6RdwKHZx9NXnoGeVnpZKV58bpdeJy7/6DcDjfZvuymzKMxEwhFQzgdTlwO+/UvC5SxrW4bOwI7KMw8l+L+xRT3KyYmMVbsWMGK0hUEo0FGFoxkVK9RFOUU4U7sKy5xAuEANaEaasO1RGIRYmKvNCsaKthRt4PtddtxOpz0y+hHv8x+9E7vTa4vl1y/zQwbMx1jDOFYmIZIAw3RBmpDtVSHqqkOVuN1ecn15ZLjyyEmMcrryymvLycUDZHrzyXXl0u2Lxu/y9905RwIB6gN11ITqiEQtlesdeE6akI1Tdv1u/0clnsYh+cdTmFWIZnezKbPRUQIxUJUB6vZVreNkpoSttZupT5S35SxFqQVcFjeYRyWexgFaQU4HU4MhvpIPSW1JWyu3kxVsIrBOYM5PO9w+qT3YVP1JlaVrmJN+RrcTjd5/jzy/HkMyBzAkNwh5Phy2v5KhQN8Wf0lJbUlFKQVMDBrIHn+PEwrNc1xidvMPBbBGIPf5W91WYBYPIYxZrfvUioz0pHalkPApEmTZMmSJQe2kc8+gxEj4LHH4BvfAGDdujls2fI7jj229qBVXoeiIT7a/hGry1bTP7M/w/KHMSh7EFtrt7KqdBWrylZRE6ohGo82FXFjEiMWjxGMBqkMVlIZrKQqWEVVsIrqYDVVwSpiEsNgGJY7gvpwkK2BL4lj5xUwivzgJEIBL+V8TsD3OXFnAEpHQ9loKBsJVUVQPQjq+oGJ4U6rp09hA/kZWRT4e5OXmY4ns5qGzJXU+FcQ8ZTi8QhuT5x0TxoD077CwPSvUJR5OH3yfeTkQE6O7Q0lLa39rUZ21O3gb8v/xgNLH2Bj1UZOGXoKNx1zE8cXHd/mj1wptTdjzFIRmdTR9bpF66ZON2SIrVX6bNezEZmZkxCJUFe3gqysDn+ObYpLnMc/eZz/rv8voWiIUCzEjrodfLT9I8Kx8G7LtlQcb7zSdDlcOHBicOIQL954Ls5wLtLQj3j9CKQuG19VHuENU4isO4bPGxK31RxRyNiGBHMpC2cQyYE+fWDqIBg0CPr1g9zRkJtrK/vS0nZVshYW2kpFx14XVTnAMYkpOfpk9GHOMXO4YdoNlAXK6JPRJ2n7Ukq1LDWDhMcDhx0Gq1c3zWqssK6rW9qpQeKTHZ/w/175f7y7+V36ZfQj25eN1+klx5fDD6b8gKMGHsXY3mPZVreNtTvXsrFqI33SBlDoHUN+bBRfrMjj7bfhnXdg3bpdLWEa+f02I+/d22bmBX0gd4TN7LOz7bzevV306jWQ3r1tdYyrm511h3FogFCqi3Sz7KITjRwJa9Y0vdyfymsR4aXPX+I37/2G+kg9XqetNHM73TiNk7jEeWPDG+T4cvjrzL9y+fjL97rPWVkJS5bA++8P4733juPDD+285vLz4Zhj4OKLYcAA6N/fToMH2/f0zotSKllSO0i8+mpTA2tbeT2J2tr21Xd8suMTrpt3Ha9veJ1hecP4Sv5Xmprf1Ufqm+oRvl38bW474Tby0/IRgVWr4I034O23YelSWL/ebs8YGDMGLrjA3gLKz7fTmDG2+mTv2z1KKZV8qRskRoywT7asWwfDbRPLzMxiNm/+batPXsclzn/W/Yc/L/4zr6x9hRxfDn884498u/jbuJ3uFndTXg7z/gn//jfMnw/bt9v5gwfD5Mlw1VVQXAzgoh2FAAAgAElEQVRTptjbQ0opdShJ3SAxMtHeePXqpiCRkVG8V+V1XOIs3bqUFz97kSdXPsn6yvX0Tu/NTcfcxI+O+hG5/ty9Nl1dDc8+axtPvfuufTisoABOOQVOPhlOPBGKig7WgSql1P5L3SAxYoT926xeYs/K6weWPMBtC29ja+1WHMbB9MHT+d8T/5dzR56Lx+nZa5NLl8Lvfw9z59ruBUaOhJ//HM4805YW9JaRUqq7Sd0gkZVla3+btXCyldd51NQsZt4OD9955TscO+hYbj/pdmYMm0F+Wv5em4nF4LXX4Le/hTfftJv91rfgsstg0iStVFZKdW+pGyTAXuo3CxLGGHJyjuNfa17g5k/+xilDT+Glr72E17V3/cSyZfD44/DUU7aeobAQ7r7b1jFk7Ws4JqWU6iY0SDz6qK00SFzyfx4exU8/+ScT+ozi+VnP7xUgdu6Ea66xwcHjgRkz4JJL4Ktfta+VUqon0SBRWwtbt8KAAcz9dC7f+Pfv6e+H+489kQxPxm6Lv/yyLSmUl8Ott8IPfmCfUlZKqZ4qtYNEovJaPv2UOzf8g5tev4mjCo/i12O9RGv+jYhgjCEYhGuvhQcegCOOsM1Zx4/v4rQrpdRBkNrtbUaORIBvL72Vm16/iYvHXMwbl73B8MKvEwyuIxBYwdq1MHWqDRDXXw8ffqgBQimVOlI7SPTtyzOT/TwUeo/rj76eJ897Ep/LR0HB2YDhqadWUlwMmzfDSy/BXXfZAXCUUipVpHSQqApVc+3JUSbVZHL7Sbc3dT/t8fTm449v4LvfvZDhw+Gjj+Css7o4sUop1QVSOkjc8votlHmi3P8fD06Hs2n+f/8LN9zwaw4/fDkvvvgFgwZ1YSKVUqoLpWyQ+LDkQ/6y5C9833U0xSt32hHrgYUL4eyzYfjwGHfddRrh8HNdnFKllOo6KRkkYvEY33752/TL7Mcvx1xjZ65ZQ2Wl7YV18GCYP9/DgAHDKCv7v65NrFJKdaGUDBKLtixi+fbl3H7S7WSNsf01sXo1t9xiH5Z76ik7iE+fPrOpq1tGTc0BDpeqlFLdVMoGCYDTDjvNDmWakcGSf5Vw//3w/e/vauLat++lOBxpbN36ly5MrVJKdZ2UDBIflHxAUU6RHRLT6SR+znn8v5fPoE8f4bbbdi3ncmXTp89sSkufIhKpbH2DSinVQ6VkkFi0ZRFTC6c2vX44/wYWx4q5+6LFew3807//d4nHG9i+/dGDnEqllOp6KRckttZuZXPNZo4ccCQAoRDc/Pgoprvf4+ubbt9r+czM8WRlHc3WrX9GJH6wk6uUUl0q5YLEB1s+AGgqSbz1FuzcafjxjE8xr74CFRV7rdO//3dpaFhLZeUbBzWtSinV1VIvSJR8gNvhZnxfWzv90kvg98NJN0yyY14/++xe6/TqdQFud4FWYCulUk7KBYlFWxYxod8EfC4fIvDii3DqqeCfOg5Gj7YjCe3B6fTRt++3KC//J/X1X3RBqpVSqmukVJCIxqMs2bqkqT7ik0/gyy9h5kzsoEOzZ8O778L69XutW1h4LQ6Hl02bfnmQU62UUl0npYLEqtJVBCKBpvqIF1+0sWHGjMQCX/+6/fvEE3ut6/X2pX//77Jjx+PU139+kFKslFJdK6WCxAclttK6sSTx4ot2rIg+fRILDBoExx0HzzzT4vqDBt2Aw+HT0oRSKmWkVJBYtGURBWkFDM0dSkkJLFlix6bezYUXwqpVsHr1Xut7PH0YMOB77NjxJIHAmoOTaKWU6kIpFSQ+KPmAIwcciTGGl1+282bO3GOh886z96Cea7n314EDr8fh8LNp020tvq+UUj1JygSJ6mA1q8tWN9VHvPQSDB0Ko0btsWD//jBtGvxfy72/ejy9KCy8htLSp6mqeifJqVZKqa6VMkFi8dbFCMKRA44kEID5820pIjEY3e4uuABWrIDPPmtxW4MGzcHvP5xVq84jGPwyuQlXSqkulDJBIt2dznkjz2PygMmsXGm74zjhhFYWPv98+3fu3BbfdrmyGTPmReLxMCtWzCQWCyQn0Uop1cWSGiSMMacbYz4zxnxhjJnTwvuXG2PKjDHLE9OVyUrLUQOPYu5Fc8nx5bBxo503dGgrCxcWwlFHtXrLCSA9fQSjRj1FILCC1asv036dlFI9UtKChDHGCdwHnAGMAr5mjNmzBgDgGREZn5geTlZ6mtu0yf4dPLiNhS64AJYvhy9af8I6P/8MDjvsLsrL57J5892dm0illDoEJLMkMQX4QkTWi0gYeBo4O4n7a7eNGyEvDzIz21io8ZZTK62cGhUWXkdBwfls2HALNTWLOy2NSil1KEhmkBgAbG72ekti3p7ON8Z8Yox5zhgzMInpabJp0z5KEWAXmDIFHnkEamtbXcwYw/DhD+Hx9OPTT79GNNr6skop1d10dcX1S0CRiBwB/BdocWQfY8zVxpglxpglZWVlB7zTjRvbESQAbrvN9uN00UUQjba6mNudy8iRTxIMbmDt2u8dcPqUUupQkcwgUQI0LxkUJuY1EZGdIhJKvHwYKG5pQyLyoIhMEpFJvXr1OqBEidiSRFFROxY+7TT4y1/gtdfgu9+1K7ciJ+cYiop+xo4d/2Dbtr8fUBqVUupQkcwgsRgYZowZYozxABcDLzZfwBjTr9nLmcDefWF0sp07IRBoZ0kC4Kqr4JZb4OGH4de/bnPRQYNuISfnRD7//GoqK9888MQqpVQXS1qQEJEo8H1gHjbzf1ZEVhljbjPGNHaG8QNjzCpjzMfAD4DLk5WeRo0tm9pVkmj0y1/absR/+lNbqmiFw+Fi9Oi5+P3DWLnyXAKBVQeUVqWU6mpG2riFciiaNGmSLFmyZL/Xf/5523Bp2TKYMKEDKzY02Irs0lL4+GPo27fVRYPBTSxbNhVjPEycuAivt1+ryyql1MFgjFkqIpM6ul5XV1wfdI0P0nWoJAF2jNOnn4aaGrjsMoi3/vCczzeYsWNfIRLZyUcfHU1V1dv7m1yllOpSKRckNm2yz0fk5OzHyqNHwz33wH/+A7/7XZuLZmZOZNy4+YCD5cuns27dHOLxUJvrKKXUoSblgkRj89cWO/Zrj6uvtt2J33STvWfVhuzsqUyatJx+/a5k8+Y7+eij44hEqvZzx0opdfClXJBod/PX1hgDDz0EvXvDN74BwWCbi7tcmQwf/iCjRz9HXd1HrFhxhj5wp5TqNlIySLS7+Wtr8vLsk9iffgo/+Um7VunV63xGjXqGmprFrFgxQ3uOVUp1CykVJKqroarqAEsSjU47zT5g97vfwVtvtWuVXr3OZdSoJ6iufpcVK84iGNzUCQlRSqnkSakg0a7eXzviN7+x/Y1fdlmrAxTtqXfvWYwY8Sg1NYv48MMRbNjwU6LRuk5KkFJKda6UChL73fy1Nenp8NhjsG0bjBgBw4fDj38Mr74KFRWtrta372ymTPmMgoJz2bTpV3z44XDKyubS3Z5ZUUr1fCkVJDq9JAFw9NF2zIk//clGn3vvhRkzID8fRo6Ev/61xdV8vkGMGvUkEya8i8fTh1WrLmDlynMJhUpaXF4ppbpCSj1x/aMf2f76AoEDaAK7L3V1sHgxvP8+vPCCHbho0SIobrHvQgDi8ShbtvyejRt/hjFusrKOwucbjM9XRO/eF+P3tzaEnlJKtc/+PnGdUkHiggtg1SpYnfRuBBMqK2HMGMjNhSVLwOdrc/GGhnVs3PhL6us/JRjcSCRShsuVy+jRz5Gbe+JBSrRSqifSbjnaoVOav3ZEbq693bRqFfz85/tc3O8/jJEj/05x8YdMm1bKkUeuw+PpzyefnMbWrQ8chAQrpdTuUipIbNzYiZXW7XX66fYp7d/8Bt57r0Or+v1DmTjxPXJzT+Hzz7/DqlWzqKx8HZHW+41SSqnOlDJBIhCA8vKDXJJodPfdNjpNnw7jxsHll9uH8droJLCRy5XF2LEvMWjQLVRUvMbHH5/MokVFrF9/s3ZFrpRKupQJEvs1jkRnycyEefPg+uuhf387JsW3vgWXXgrh8D5XN8bJ0KG/4uijtzNq1NOkp4/hyy/vYvHiMSxePI4vv7xTH8xTSiWFq6sTcLAkpflrRwwbBv/7v/Z/Ebj9djvi3fbtdpCLykpbf/Hii3D88XDDDTagNON0+undexa9e88iHC6lrOz/2LHjCdavn8P69XPIyjqa3r0vJjt7Gunpo3E4vAf/OJVSPUrKtG5auBDuuMPe5WljvKCD69FH4cor7TMVpaV23pQptiWU07mrtDFhAnhbz/AbGjZQWvo0paVPEgisBMAYN+npY8jPP4vevb9GevrIg3FESqlDlDaB7a7+8x87LOrpp8M3v2mLOhs22Ij2t79BJAIejw0UAwdCNAqxmB0EadAgOw0ebJ/2HjqUhuiX1NYupbZ2GTU1i6iufhuIk5ExgYKC88jLO53MzIkYkzJ3GpVSaJDomUpL4d137cN4ixbZmnen006BAGzevHtX5S6Xfcr73nvtLSsgFNpGWdmz7NjxJLW1HwLgdheQk3M8mZlHkpU1mYyMYlyujC44wHZasgR+9Sv7JGQ/HQpWqf2hQSIViUBZGaxfD59/DmvWwNy59vUf/mB7qW32aHk4XEpl5X+pqHiN6up3CQY3kL0C0r6E6nOHk5FTTGbmRNLTjyAj4wg8nj5deHAJkQhMnAgrV8IJJ8B//2uDpFKqQzRIKKumBi65BF5+2dZpnHAClJTYTgiHD7ePnRcUQFUVsR//AOdf/wFA/ahsPr/eQ1VRWdOm3O4+5OaeRH7+DPLyTsPtzj/4x3PPPfA//2OP6Ykn7K252247+OlQnW/jRnsRU1i4f4FfpPP713nvPfv9Ovts+M532rf9eBy+/PIAh7xspr4e0tJ2n1ddDf/4h73tPG3afm12f4MEItKtpuLiYlH7EIuJ3HKLiP0Z2cnvt39dLpHTTxfp10/E4RD58Y9FnnhCpHdvEadToj/6vlR+8pRs3nyPrFp1ibzzToG8+Sby5psO+fDDI2TNmm/Ltm1/l9qa5RJ9/hmRceNEBg0S+eEPRd55x+67s2zdKpKZKXLGGSLxuMjll4sYIzJvXuftI9XE4/u/7ttvi1xwgchFF4n8z/+I/Pa3Ih9/3PHthEL2e9f43XS5RIYOFbnuOpGKit2XjUZFSkt3fa9iMZFXXxWZMUPE6RS58EKRzz5r335ff13k1ltFHnxQ5LXXRFasENmyRaSuTmTzZpFLLrHp8fns3yuvtGltVF4usmnT7p/hf/4jMn68XX7YMJFf/1pkzRqRZ5+12ysoEDniCJEbbhB54w2Rjz4Sef55kbvvFnn0UZFweNe26upEvvlNu60RI0R+9CO77Le+JZKWZuf/+Mcd/7wTgCWyH3lul2f6HZ00SHTAZ5/ZL2xtrf1iL18ucuONIkOGiEyeLLJ48a5ld+60mTDYjPjkk0X+/neJL1ksNetekw3rfy6fvHOCLPlbuqz8GVI90v7A6we5pXp6b4m7nSIgsewMiU0YK/Hzzxe56SaRBQtEIpH9S/8ll4h4vSJr19rXgYDI6NEivXqJ/P73Iu++a+cl24YN+5cZHgq2brUB/KSTbEbsdttM7b77RKqq2reNZctEzjzTfjd69bKZYWOmBfai4403ds88AwGbmf/whzbI33qryMKFIp98IjJhgl3v298Weegh+z055xx70ZKXJ3LvvfbcXnONSJ8+dlmvV+Tww+0FCdj5l14qkp5ug8VVV9mM94Yb7Pf4xhtFXn7ZBp233xY5/vjdL5pamrxee3FVXS1y88123rRpInfeKXLMMTZ9INK/vw2WJ59sXxcV2eAwffru2ysoEJk9W+SEE+zn3tI+hw2zAWXpUpGvfMX+9q66SuTUU0U8HrtMWpoNWEuWHNBXYX+DhN5uUrtbv96OkfHoo7sG4ABwu239QEJsQD6V10xjx+leGiJrCZV9Ru47DWSvBN928G934NsqOKJCLMtD/XFFUDwJ34QzcI89GhwOqK21t8c+/xyWLbNTXZ1to5yTA88+Cz/7GfziF7vSsXo1zJxpu2cHe5ti6lQ480w44wz4ylfsPIdjVyX/vqxaBQ88YPc3eTLcdZdtABCL2bqdW26xx37nnXDddW3fUgiH4Y034KWXdh9TJDPTPvcyYIBt8uz12lZrBQX2KXxHO1qbidh0rFoFb75pp1AIzj/f3kbMb3Y7MB63xzRnjm3cMHGifZJ0wAB4/XXbO3Famv3s8vNtP2N9+9pxUUaMsOn717/guefsecnLgxtvhO9/364nifqwhx+2n1FpKWRl2WNyu+2xh0K2U8uhQ+15a8xr8vPtM0Fnn7378X3yie2qef58+9rrhbPOst3xb99uG2rU18PXvw7nnmv3tWOHbdTwwAO7WgL26mXnR6O7tt2njz2P3/wm7Nxpbw+VlNihKqurbVpnz4YhQ3at88wzcMUV0NBgz9FXv2q3s2iRvS0VCMBNN9m6v8Ym6uvX2/Fkxo2z6W78/tXW2hEsg0G7jyFD7DbmzLHnE+y5efzxpkYnTT1KT5wI2dn7/n7sg9ZJqM4Vj9sf7YYN9se5davNKIqK7DRu3G7PbojECYVKqK9fQ339Z9TXryG88zP8b28k660dZC2qw1vR+ndN0v0wYSImN8/+wLdvtz/It96yzX33tHWr/QEtWmSbES9b1vKGjbGtvvx+mwn262cz5ljMZgylpbB0qc1cTj8dFiywP/4rr7TH//77NnNwu+1DjxdcYDO4bdvgww9thXp9vd1WRYXN4KqrISNj18OQInZe47Mwe+rXz+7jmGNsZvree/Z4wuFdwS4atfto/nsdNswe3+ef22OcNs0GV68X1q2zx3XiiXD//XbZXSfLvvfww/YYKyvtVFa2d1cxRx1lj/lb32o9owoGbea2YoXNqCMRm46TT4bjjrOffWWlPZerV9uRHPd4UHS3tM2fb9Ny1lk28LRHVZX9LLKy7N/6evv9eOcdG6CvvHLv+/ztsWOHPQ8DB3Z83faIxexnt3Sp7QQ0P3n1fhok1CFNJEbdpgXUL51LeMU7RKLlhDyVRHxBGvpCQyEYpwufbwg+3xD8/qG4XPlEo1VEo1WIhPB6B5OWNgy//ytkZR2J09nsR799uw0W27fbjC4etxlrNGozrUDAvrd9u72SdLlsYEhLsyWTyy6zwaOszJZc7r/fZjh//KO9cgXbB9ecOfb/xszU47EjFPp8dlvTp8N559kMcs8HIMNhu/+KCpumUMiW1l58Ef79b3vl6HLB+PH2ocrMTJuJxGJ2vtdrpyFD7H4KC22munw5PPmkzRAbGmym7XLZK//Zs9tfmRoKwdq1tpVcVZUdxz1ZmaM66DRIqG4pGq2mvn5togSymoaGtQSDG2ho2EA0WonLlYPLlYMxbkKhTcTj9rkQh8NHTs6J5OefSUbGeHy+IXg8fTvvIcGNG21poKBg9/kLF8I//wljx9qMfMSIzmmSGwrZzHnYsP274lVqHzRIqB5HRDDNroIbb2kFAiupqJhHRcUrNDR80fS+MV683n643b1xu3vhcuXgcHhwOLy4XDlkZIwnM3MSPt/Q3barVCrY3yCRMh38qe5nz4zcGAc+30B8voHk558B3ENDw3rq6z8jGNxIMLiBcHgb4XAZ4fBW6utXIxImHg8TjVYiYivenc4s/P7D8PmG4vMNQiRKLFZLLFaHSJTGCye/fwi5uaeSkzN991tbSqUQDRKqW/P7h7ZrDPB4PEwgsJLa2qXU1X1MMLie+vpVVFT8G4fDg9OZidOZgTHuxBpCZeU8tmy5B2M8+P2HIxJDJIoxDtzu3ng8ffF4+uLzDcTrHYTXW4hIjHg8QCzWgNc7gPT0sbt1eRKNVgMOXK7M5HwgSnUyDRIqJTgcHjIzJ5KZObHd68RiDVRXv0NFxTyCwY0Y48IYFyJRIpFS6us/parqdaLRqja2YvD7D8cYD6HQZmKxGsBJdvZR5OWdQVbWVOLxcKIUE8brHYDPV4THMwCHw5UIOhEcDq/eIlNdQoOEUq1wOv3k5Z1CXt4pbS4XjdYSCm0mFCrBGBdOZzoOh49gcCN1dR9TV/cxECM39yS83oFEo5VUVLzGhg23tLHVxoBgb305HH683kH4fINxuXY1RXU6s8jIGEt6+lh8vsFEIuWEwzuIRqtwuXITpZ3eOBx+jHEnSkqCSAyI4XRm4XC499q7Uo204lqpLhIKbae+fhUOR1riVpeTUKiEYHAjodBmQBIZu4tIZCfB4CZCoU3EYoGmbUQi5UQiZa3vZB+M8ZKRMZaMjIn4fIOJxeqJx+sRieLx9MHj6Yfb3Yt4vJ5IpJJYrAaHw4/LlYvbnYvD4cMOcGlwOHy4XFk4nVk4nWmJkpcTYzwaiA4BWnGtVDfj9fbF6919BKz09FEd3k44vIO6uhWEQlvweHrhdvfB5cohGq0gHN5BJFJKPB4kHo8kKu9NIvN2EAqVUFu7lLKyZxO3zQxOZzrgSNwa6xwOR1qiOXMWInFEIojE8PsPJytrCpmZk3G5conF6hK33mI4HN6mqbEU5HB4EkHHizEuYrHaxLM0Nbhcufh8g/F6B+BweDot7alOg4RS3ZzH04e8vAPr1l1EiMeDOBy+prqPWKyBcHg7kUg5TmcGLlcOTmcm8XgD0Wgl0Wgl8XgYiCfqTkLEYjVEo7XE44Gmiv54PEQ0Wk00WpUIPI5EycIQCHzK5s2/bWp51jlMooRjORx+3O6CRLPobBpv5RljMMYFOHE4PLjdvfF6B+Dx9CUarUy0mNsICC5XPm53AcY4iUYriER2IhLB6x2Mz1eE1zsgsd0YInEcDh9OZxoORxoeTx+83oE4nX5EhFBoM/X1qwmHSxOfXRyHw096+ijS0oY3DTscj0eIRHYCcYxxAk6czrSD3tJOg4RSCmMMTufu3Z84nX78/iH4/UP2WDoDj6dXp+07FgsSCHxCPB7E6UzH6cwAHMTjIURCib+RREnINmkWCSMSwenMwuXKxunMJBqtIBj8kmBwE/F4fbPtBxK35Wx9zS7x3QJZJLKDWKyu6V2Hw4/PV4QxTiKRD4hEyhGJ4Xbn4XLlY4yLysr5u63TFre7N7FYgHg80MZSTrzewkSwrdzr3YEDb+Sww+5o1/46S1KDhDHmdOAPgBN4WETu2ON9L/AYUAzsBGaJyMZkpkkpdWhxOn1kZU3p6mQAthFCOLwNlysHt7vXHg9zCraeyLHbvGi0klBoK0DiPUM8HiIebyAWCxAObyMUssHL4fCTljaS9PSReDwDEiUEQyxWSyCwikBgJcHghkSjg95NpReROI3DEB9sSQsSxh79fcApwBZgsTHmRRH5tNli3wIqReRwY8zFwJ3ArGSlSSml2uJyZbb6DIsNGHs+4Glwu/Nwu/MOeN8ZGWMPeBvJ0Ekd3bRoCvCFiKwXkTDwNLBH38CcDTya+P854CSjjcGVUuqQkcwgMQDY3Oz1lsS8FpcRkShQDezVV64x5mpjzBJjzJKysv1v7qeUUqpjkhkkOo2IPCgik0RkUq9enVdhppRSqm3JDBIlQPPO6AsT81pcxti2aNnYCmyllFKHgGQGicXAMGPMEGOMB7gYeHGPZV4ELkv8fwHwhnS3R8CVUqoHS1rrJhGJGmO+D8zDNoF9RERWGWNuww7I/SLwV+AfxpgvgApsIFFKKXWISOpzEiLyKvDqHvN+1uz/IHBhMtOglFJq/3WLimullFJdo9v1AmuMKQM27efqBUB5Jyanu0nl40/lY4fUPn49dmuwiHS4eWi3CxIHwhizZH+6yu0pUvn4U/nYIbWPX4/9wI5dbzcppZRqlQYJpZRSrUq1IPFgVyegi6Xy8afysUNqH78e+wFIqToJpZRSHZNqJQmllFIdkDJBwhhzujHmM2PMF8aYOV2dnmQyxgw0xrxpjPnUGLPKGPPDxPw8Y8x/jTFrE39zuzqtyWKMcRpjPjLGvJx4PcQY80Hi/D+T6CqmRzLG5BhjnjPGrDHGrDbGHJUq594Y8z+J7/xKY8xTxhhfTz73xphHjDGlxpiVzea1eK6NdW/ic/jEGDOxPftIiSDRbACkM4BRwNeMMR0fcb77iAI/EpFRwFTge4njnQO8LiLDgNcTr3uqHwKrm72+E/i9iBwOVGIHvOqp/gC8JiIjgHHYz6HHn3tjzADgB8AkERmD7Q6ocTCznnru/w6cvse81s71GcCwxHQ18Jf27CAlggTtGwCpxxCRbSKyLPF/LTaTGMDugzw9CpzTNSlMLmNMITADeDjx2gAnYge2gp597NnAcdh+0RCRsIhUkSLnHtvVkD/Rq3QasI0efO5FZCG237vmWjvXZwOPibUIyDHG9NvXPlIlSLRnAKQeyRhTBEwAPgD6iMi2xFvbgT5dlKxkuwe4AYgnXucDVYmBraBnn/8hQBnwt8TttoeNMemkwLkXkRLgbuBLbHCoBpaSOue+UWvner/ywVQJEinJGJMBzAWuFZGa5u9J46juPYwx5iygVESWdnVauogLmAj8RUQmAAH2uLXUg899LvZqeQjQH0hn71sxKaUzznWqBIn2DIDUoxhj3NgA8YSIPJ+YvaOxeJn4W9pV6UuiacBMY8xG7G3FE7H36HMStyCgZ5//LcAWEfkg8fo5bNBIhXN/MrBBRMpEJAI8j/0+pMq5b9Taud6vfDBVgkR7BkDqMRL34P8KrBaR3zV7q/kgT5cB/zrYaUs2EblJRApFpAh7nt8QkUuAN7EDW0EPPXYAEdkObDbGDE/MOgn4lBQ499jbTFONMWmJ30DjsafEuW+mtXP9InBpopXTVKC62W2pVqXMw3TGmDOx96obB0D6dRcnKWmMMccAbwMr2HVf/mZsvcSzwCBsT7oXicielV49hjHmeODHInKWMWYotmSRB3wEzBaRUFemL1mMMeOxlfYeYD1wBfaCsMefe2PML4BZ2BZ+HwFXYn/e0vcAAAIvSURBVO+798hzb4x5Cjge29vrDuDnwD9p4VwnAuefsLfg6oErRGTJPveRKkFCKaVUx6XK7SallFL7QYOEUkqpVmmQUEop1SoNEkoppVqlQUIppVSrNEgodRAZY45v7JlWqe5Ag4RSSqlWaZBQqgXGmNnGmA+NMcuNMQ8kxqeoM8b8PjFewevGmF6JZccbYxYl+uh/oVn//YcbY+YbYz42xiwzxhyW2HxGs/Eenkg85KTUIUmDhFJ7MMaMxD61O01ExgMx4BJsh3FLRGQ08Bb26VaAx4AbReQI7FPujfOfAO4TkXHA0dieScH2ynstdmyTodj+hZQ6JLn2vYhSKeckoBhYnLjI92M7SYsDzySWeRx4PjF+Q46IvJWY/yjwf8aYTGCAiLwAICJBgMT2PhSRLYnXy4Ei4J3kH5b6/+3dMUoEMRiG4fezEcTa1lvYeQcLbQRP4AkWtPEUWnoNwULwDJ7AykYEO1l+i2RFdwmoLKPF+5SZECZF+CYZ+KOfMySkVQGuq2r2pTE5X+r325o2n+sGzXEd6h/zuEladQscJtmBjzuDd2nrZVFN9Bi4r6oX4DnJfm8/Ae76jYCPSQ76GJtJtiadhbQGfsFIS6rqIckZcJNkA3gDTmkX+Oz1Z0+0/xbQyjFf9hBYVF2FFhhXSS76GEcTTkNaC6vASt+U5LWqtv/6PaQpedwkSRpyJyFJGnInIUkaMiQkSUOGhCRpyJCQJA0ZEpKkIUNCkjT0DmI34UDlTgd7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 641us/sample - loss: 0.1995 - acc: 0.9402\n",
      "Loss: 0.19947422533948844 Accuracy: 0.9401869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_{}_conv_custom_conv_3_DO'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_1_conv_custom_conv_3_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,272\n",
      "Trainable params: 16,384,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 390us/sample - loss: 2.3283 - acc: 0.2569\n",
      "Loss: 2.328297340337609 Accuracy: 0.2569055\n",
      "\n",
      "1D_CNN_2_conv_custom_conv_3_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,473,616\n",
      "Trainable params: 5,473,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 538us/sample - loss: 1.9484 - acc: 0.3961\n",
      "Loss: 1.9483548640214519 Accuracy: 0.396054\n",
      "\n",
      "1D_CNN_3_conv_custom_conv_3_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,844,624\n",
      "Trainable params: 1,844,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 585us/sample - loss: 1.6956 - acc: 0.4795\n",
      "Loss: 1.6955603861734503 Accuracy: 0.4795431\n",
      "\n",
      "1D_CNN_4_conv_custom_conv_3_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 643,536\n",
      "Trainable params: 643,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 610us/sample - loss: 1.2561 - acc: 0.6278\n",
      "Loss: 1.2561477027082988 Accuracy: 0.6278297\n",
      "\n",
      "1D_CNN_5_conv_custom_conv_3_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 465,488\n",
      "Trainable params: 465,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 647us/sample - loss: 1.0106 - acc: 0.6941\n",
      "Loss: 1.0106030552434278 Accuracy: 0.694081\n",
      "\n",
      "1D_CNN_6_conv_custom_conv_3_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 244,432\n",
      "Trainable params: 244,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 646us/sample - loss: 0.6294 - acc: 0.8299\n",
      "Loss: 0.6293874348435446 Accuracy: 0.8299065\n",
      "\n",
      "1D_CNN_7_conv_custom_conv_3_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 203,600\n",
      "Trainable params: 203,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 660us/sample - loss: 0.2910 - acc: 0.9153\n",
      "Loss: 0.2909540087882108 Accuracy: 0.9152648\n",
      "\n",
      "1D_CNN_8_conv_custom_conv_3_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 224,208\n",
      "Trainable params: 224,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 696us/sample - loss: 0.1899 - acc: 0.9443\n",
      "Loss: 0.18985166766933192 Accuracy: 0.9443406\n",
      "\n",
      "1D_CNN_9_conv_custom_conv_3_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 316,624\n",
      "Trainable params: 316,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 707us/sample - loss: 0.1995 - acc: 0.9402\n",
      "Loss: 0.19947422533948844 Accuracy: 0.9401869\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_{}_conv_custom_conv_3_DO'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
