{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, \\\n",
    "                                    Flatten, Conv1D, MaxPooling1D, Dropout, \\\n",
    "                                    Concatenate, GlobalMaxPool1D, GlobalAvgPool1D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(conv_num=1):\n",
    "    filter_size = 128\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    layer_outputs = []\n",
    "    for i in range(conv_num):\n",
    "        x = Conv1D (kernel_size=5, filters=filter_size*(2**(i//4)), \n",
    "                          strides=1, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling1D(pool_size=3, strides=3)(x)\n",
    "        layer_outputs.append(x)    \n",
    "    \n",
    "    x = Concatenate()([Flatten()(output) for output in layer_outputs[-3:]])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 16000, 128)   768         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 16000, 128)   512         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16000, 128)   0           batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 5333, 128)    0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 5333, 128)    82048       max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_1 (Batch (None, 5333, 128)    512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5333, 128)    0           batch_normalization_v1_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1777, 128)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1777, 128)    82048       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_2 (Batch (None, 1777, 128)    512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1777, 128)    0           batch_normalization_v1_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 592, 128)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 682624)       0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 227456)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 75776)        0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 985856)       0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_3 (Batch (None, 985856)       3943424     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           15773712    batch_normalization_v1_3[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 19,883,536\n",
      "Trainable params: 17,911,056\n",
      "Non-trainable params: 1,972,480\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 16000, 128)   768         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_4 (Batch (None, 16000, 128)   512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16000, 128)   0           batch_normalization_v1_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 5333, 128)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 5333, 128)    82048       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_5 (Batch (None, 5333, 128)    512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 5333, 128)    0           batch_normalization_v1_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1777, 128)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1777, 128)    82048       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_6 (Batch (None, 1777, 128)    512         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1777, 128)    0           batch_normalization_v1_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 592, 128)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 592, 128)     82048       max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_7 (Batch (None, 592, 128)     512         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 592, 128)     0           batch_normalization_v1_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 197, 128)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 227456)       0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 75776)        0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 25216)        0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 328448)       0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_8 (Batch (None, 328448)       1313792     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           5255184     batch_normalization_v1_8[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 6,817,936\n",
      "Trainable params: 6,160,016\n",
      "Non-trainable params: 657,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 16000, 128)   768         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_9 (Batch (None, 16000, 128)   512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16000, 128)   0           batch_normalization_v1_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 5333, 128)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 5333, 128)    82048       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_10 (Batc (None, 5333, 128)    512         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5333, 128)    0           batch_normalization_v1_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1777, 128)    0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1777, 128)    82048       max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_11 (Batc (None, 1777, 128)    512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1777, 128)    0           batch_normalization_v1_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 592, 128)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_12 (Batc (None, 592, 128)     512         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 592, 128)     0           batch_normalization_v1_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 197, 128)     0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_13 (Batc (None, 197, 256)     1024        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 197, 256)     0           batch_normalization_v1_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 65, 256)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 75776)        0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 25216)        0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 16640)        0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 117632)       0           flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_14 (Batc (None, 117632)       470528      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           1882128     batch_normalization_v1_14[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 2,766,736\n",
      "Trainable params: 2,529,936\n",
      "Non-trainable params: 236,800\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 16000, 128)   768         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_15 (Batc (None, 16000, 128)   512         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 5333, 128)    0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_16 (Batc (None, 5333, 128)    512         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1777, 128)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_17 (Batc (None, 1777, 128)    512         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 592, 128)     0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_18 (Batc (None, 592, 128)     512         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 592, 128)     0           batch_normalization_v1_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 197, 128)     0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_19 (Batc (None, 197, 256)     1024        conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 197, 256)     0           batch_normalization_v1_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 65, 256)      0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_20 (Batc (None, 65, 256)      1024        conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 65, 256)      0           batch_normalization_v1_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 21, 256)      0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 25216)        0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 16640)        0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 5376)         0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 47232)        0           flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_21 (Batc (None, 47232)        188928      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           755728      batch_normalization_v1_21[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 1,687,696\n",
      "Trainable params: 1,591,184\n",
      "Non-trainable params: 96,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 16000, 128)   768         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_22 (Batc (None, 16000, 128)   512         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 5333, 128)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_23 (Batc (None, 5333, 128)    512         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1777, 128)    0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_24 (Batc (None, 1777, 128)    512         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 592, 128)     0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_25 (Batc (None, 592, 128)     512         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 592, 128)     0           batch_normalization_v1_25[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 197, 128)     0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_26 (Batc (None, 197, 256)     1024        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 197, 256)     0           batch_normalization_v1_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 65, 256)      0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_27 (Batc (None, 65, 256)      1024        conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 65, 256)      0           batch_normalization_v1_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 21, 256)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 21, 256)      327936      max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_28 (Batc (None, 21, 256)      1024        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 21, 256)      0           batch_normalization_v1_28[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 7, 256)       0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 16640)        0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 5376)         0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 1792)         0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 23808)        0           flatten_12[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_29 (Batc (None, 23808)        95232       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           380944      batch_normalization_v1_29[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 1,548,176\n",
      "Trainable params: 1,498,000\n",
      "Non-trainable params: 50,176\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 16000, 128)   768         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_30 (Batc (None, 16000, 128)   512         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_30[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 5333, 128)    0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_31 (Batc (None, 5333, 128)    512         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_31[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1777, 128)    0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_32 (Batc (None, 1777, 128)    512         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_32[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 592, 128)     0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_33 (Batc (None, 592, 128)     512         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 592, 128)     0           batch_normalization_v1_33[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 197, 128)     0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_34 (Batc (None, 197, 256)     1024        conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 197, 256)     0           batch_normalization_v1_34[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 65, 256)      0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_35 (Batc (None, 65, 256)      1024        conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 65, 256)      0           batch_normalization_v1_35[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 21, 256)      0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 21, 256)      327936      max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_36 (Batc (None, 21, 256)      1024        conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 21, 256)      0           batch_normalization_v1_36[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 7, 256)       0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 7, 256)       327936      max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_37 (Batc (None, 7, 256)       1024        conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 256)       0           batch_normalization_v1_37[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 2, 256)       0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 5376)         0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 1792)         0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 512)          0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 7680)         0           flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "                                                                 flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_38 (Batc (None, 7680)         30720       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           122896      batch_normalization_v1_38[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 1,554,576\n",
      "Trainable params: 1,536,144\n",
      "Non-trainable params: 18,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 9):\n",
    "    model = build_cnn(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.7488 - acc: 0.4663\n",
      "Epoch 00001: val_loss improved from inf to 3.92718, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_4_conv_checkpoint/001-3.9272.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 3.7488 - acc: 0.4662 - val_loss: 3.9272 - val_acc: 0.4426\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0549 - acc: 0.7171\n",
      "Epoch 00002: val_loss improved from 3.92718 to 3.82459, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_4_conv_checkpoint/002-3.8246.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 2.0548 - acc: 0.7171 - val_loss: 3.8246 - val_acc: 0.5236\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4185 - acc: 0.8063\n",
      "Epoch 00003: val_loss improved from 3.82459 to 3.60098, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_4_conv_checkpoint/003-3.6010.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 1.4184 - acc: 0.8063 - val_loss: 3.6010 - val_acc: 0.5973\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1094 - acc: 0.8531\n",
      "Epoch 00004: val_loss improved from 3.60098 to 3.33018, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_4_conv_checkpoint/004-3.3302.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 1.1093 - acc: 0.8531 - val_loss: 3.3302 - val_acc: 0.6089\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8985 - acc: 0.8874\n",
      "Epoch 00005: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.8984 - acc: 0.8874 - val_loss: 3.4203 - val_acc: 0.6201\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8414 - acc: 0.8966\n",
      "Epoch 00006: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.8415 - acc: 0.8966 - val_loss: 4.8183 - val_acc: 0.5360\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7634 - acc: 0.9071\n",
      "Epoch 00007: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.7638 - acc: 0.9071 - val_loss: 3.9740 - val_acc: 0.5854\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7517 - acc: 0.9121\n",
      "Epoch 00008: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.7517 - acc: 0.9121 - val_loss: 5.1769 - val_acc: 0.5304\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6542 - acc: 0.9265\n",
      "Epoch 00009: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.6542 - acc: 0.9265 - val_loss: 4.3578 - val_acc: 0.5926\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6448 - acc: 0.9279\n",
      "Epoch 00010: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.6451 - acc: 0.9278 - val_loss: 5.0406 - val_acc: 0.5656\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6426 - acc: 0.9283\n",
      "Epoch 00011: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.6426 - acc: 0.9283 - val_loss: 4.7722 - val_acc: 0.5898\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6158 - acc: 0.9332\n",
      "Epoch 00012: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.6162 - acc: 0.9332 - val_loss: 3.6041 - val_acc: 0.6695\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5892 - acc: 0.9379\n",
      "Epoch 00013: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.5891 - acc: 0.9379 - val_loss: 4.1091 - val_acc: 0.6285\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5476 - acc: 0.9436\n",
      "Epoch 00014: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.5477 - acc: 0.9435 - val_loss: 4.3754 - val_acc: 0.6203\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5425 - acc: 0.9451\n",
      "Epoch 00015: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.5425 - acc: 0.9450 - val_loss: 4.0247 - val_acc: 0.6518\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5100 - acc: 0.9494\n",
      "Epoch 00016: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.5102 - acc: 0.9494 - val_loss: 4.3880 - val_acc: 0.6250\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4845 - acc: 0.9525\n",
      "Epoch 00017: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4846 - acc: 0.9524 - val_loss: 3.9186 - val_acc: 0.6564\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5184 - acc: 0.9502\n",
      "Epoch 00018: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.5188 - acc: 0.9502 - val_loss: 4.3309 - val_acc: 0.6313\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4509 - acc: 0.9573\n",
      "Epoch 00019: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4509 - acc: 0.9573 - val_loss: 3.8060 - val_acc: 0.6795\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4584 - acc: 0.9554\n",
      "Epoch 00020: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4584 - acc: 0.9554 - val_loss: 4.0896 - val_acc: 0.6494\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4667 - acc: 0.9557\n",
      "Epoch 00021: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4666 - acc: 0.9557 - val_loss: 3.9706 - val_acc: 0.6664\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4445 - acc: 0.9580\n",
      "Epoch 00022: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4448 - acc: 0.9580 - val_loss: 4.6312 - val_acc: 0.6187\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4263 - acc: 0.9606\n",
      "Epoch 00023: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4262 - acc: 0.9606 - val_loss: 4.0590 - val_acc: 0.6648\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4286 - acc: 0.9605\n",
      "Epoch 00024: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4295 - acc: 0.9604 - val_loss: 4.0259 - val_acc: 0.6667\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4833 - acc: 0.9558\n",
      "Epoch 00025: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4837 - acc: 0.9557 - val_loss: 5.1130 - val_acc: 0.5991\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4198 - acc: 0.9628\n",
      "Epoch 00026: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4201 - acc: 0.9627 - val_loss: 4.1877 - val_acc: 0.6594\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3944 - acc: 0.9648\n",
      "Epoch 00027: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3946 - acc: 0.9647 - val_loss: 4.2801 - val_acc: 0.6594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4454 - acc: 0.9598\n",
      "Epoch 00028: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4455 - acc: 0.9598 - val_loss: 4.4221 - val_acc: 0.6469\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3980 - acc: 0.9644\n",
      "Epoch 00029: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3981 - acc: 0.9644 - val_loss: 4.4121 - val_acc: 0.6434\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3959 - acc: 0.9654\n",
      "Epoch 00030: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3960 - acc: 0.9653 - val_loss: 3.7500 - val_acc: 0.6956\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4160 - acc: 0.9635\n",
      "Epoch 00031: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4160 - acc: 0.9634 - val_loss: 4.4444 - val_acc: 0.6564\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4092 - acc: 0.9650\n",
      "Epoch 00032: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4101 - acc: 0.9650 - val_loss: 4.2599 - val_acc: 0.6655\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3351 - acc: 0.9724\n",
      "Epoch 00033: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3355 - acc: 0.9724 - val_loss: 3.9738 - val_acc: 0.6830\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3549 - acc: 0.9703\n",
      "Epoch 00034: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3548 - acc: 0.9703 - val_loss: 5.0833 - val_acc: 0.6070\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3715 - acc: 0.9690\n",
      "Epoch 00035: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3714 - acc: 0.9690 - val_loss: 4.0699 - val_acc: 0.6881\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3596 - acc: 0.9697\n",
      "Epoch 00036: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3597 - acc: 0.9697 - val_loss: 4.1132 - val_acc: 0.6778\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3777 - acc: 0.9687\n",
      "Epoch 00037: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3784 - acc: 0.9686 - val_loss: 4.7341 - val_acc: 0.6352\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4514 - acc: 0.9600\n",
      "Epoch 00038: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4513 - acc: 0.9600 - val_loss: 4.5303 - val_acc: 0.6527\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3201 - acc: 0.9740\n",
      "Epoch 00039: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3205 - acc: 0.9739 - val_loss: 3.9439 - val_acc: 0.6921\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3389 - acc: 0.9727\n",
      "Epoch 00040: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3389 - acc: 0.9727 - val_loss: 4.6167 - val_acc: 0.6520\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3250 - acc: 0.9738\n",
      "Epoch 00041: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3258 - acc: 0.9738 - val_loss: 4.0099 - val_acc: 0.6902\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3332 - acc: 0.9730\n",
      "Epoch 00042: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3334 - acc: 0.9729 - val_loss: 4.4224 - val_acc: 0.6655\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3469 - acc: 0.9705\n",
      "Epoch 00043: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3475 - acc: 0.9704 - val_loss: 4.6633 - val_acc: 0.6450\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3647 - acc: 0.9696\n",
      "Epoch 00044: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3650 - acc: 0.9695 - val_loss: 4.3568 - val_acc: 0.6699\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3107 - acc: 0.9742\n",
      "Epoch 00045: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3112 - acc: 0.9742 - val_loss: 4.9021 - val_acc: 0.6338\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3359 - acc: 0.9725\n",
      "Epoch 00046: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3358 - acc: 0.9725 - val_loss: 4.1838 - val_acc: 0.6792\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2977 - acc: 0.9762\n",
      "Epoch 00047: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.2986 - acc: 0.9761 - val_loss: 4.1954 - val_acc: 0.6827\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3429 - acc: 0.9716\n",
      "Epoch 00048: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3432 - acc: 0.9716 - val_loss: 4.2646 - val_acc: 0.6799\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3181 - acc: 0.9740\n",
      "Epoch 00049: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3183 - acc: 0.9740 - val_loss: 4.1458 - val_acc: 0.6832\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3099 - acc: 0.9748\n",
      "Epoch 00050: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3105 - acc: 0.9748 - val_loss: 4.4634 - val_acc: 0.6646\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3291 - acc: 0.9732\n",
      "Epoch 00051: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3290 - acc: 0.9732 - val_loss: 4.4814 - val_acc: 0.6697\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2965 - acc: 0.9766\n",
      "Epoch 00052: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.2969 - acc: 0.9766 - val_loss: 4.3094 - val_acc: 0.6769\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2888 - acc: 0.9772\n",
      "Epoch 00053: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.2890 - acc: 0.9772 - val_loss: 5.1224 - val_acc: 0.6233\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3295 - acc: 0.9732\n",
      "Epoch 00054: val_loss did not improve from 3.33018\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3299 - acc: 0.9732 - val_loss: 4.4250 - val_acc: 0.6711\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 3.6625 - acc: 0.5782\n",
      "Loss: 3.6625097466901577 Accuracy: 0.5781931\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0698 - acc: 0.5181\n",
      "Epoch 00001: val_loss improved from inf to 1.84966, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_5_conv_checkpoint/001-1.8497.hdf5\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 2.0697 - acc: 0.5181 - val_loss: 1.8497 - val_acc: 0.5118\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0837 - acc: 0.7322\n",
      "Epoch 00002: val_loss improved from 1.84966 to 1.72805, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_5_conv_checkpoint/002-1.7281.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 1.0838 - acc: 0.7322 - val_loss: 1.7281 - val_acc: 0.6254\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6302 - acc: 0.8355\n",
      "Epoch 00003: val_loss did not improve from 1.72805\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.6303 - acc: 0.8355 - val_loss: 1.7714 - val_acc: 0.6450\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3959 - acc: 0.8955\n",
      "Epoch 00004: val_loss improved from 1.72805 to 1.42978, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_5_conv_checkpoint/004-1.4298.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.3961 - acc: 0.8955 - val_loss: 1.4298 - val_acc: 0.6946\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3154 - acc: 0.9182\n",
      "Epoch 00005: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.3154 - acc: 0.9182 - val_loss: 1.7772 - val_acc: 0.6604\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2040 - acc: 0.9494\n",
      "Epoch 00006: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2042 - acc: 0.9494 - val_loss: 1.6685 - val_acc: 0.6914\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2336 - acc: 0.9430\n",
      "Epoch 00007: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2339 - acc: 0.9430 - val_loss: 1.6852 - val_acc: 0.6872\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9479\n",
      "Epoch 00008: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2088 - acc: 0.9479 - val_loss: 2.0582 - val_acc: 0.6415\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1866 - acc: 0.9550\n",
      "Epoch 00009: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1866 - acc: 0.9550 - val_loss: 1.8939 - val_acc: 0.6737\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1453 - acc: 0.9655\n",
      "Epoch 00010: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1457 - acc: 0.9655 - val_loss: 1.7432 - val_acc: 0.7060\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1957 - acc: 0.9555\n",
      "Epoch 00011: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1963 - acc: 0.9554 - val_loss: 2.0422 - val_acc: 0.6746\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9606\n",
      "Epoch 00012: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1717 - acc: 0.9605 - val_loss: 1.9706 - val_acc: 0.7018\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9688\n",
      "Epoch 00013: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1370 - acc: 0.9688 - val_loss: 1.8635 - val_acc: 0.7170\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9709\n",
      "Epoch 00014: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1292 - acc: 0.9708 - val_loss: 2.7590 - val_acc: 0.6331\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9608\n",
      "Epoch 00015: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1773 - acc: 0.9607 - val_loss: 2.1274 - val_acc: 0.6960\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9764\n",
      "Epoch 00016: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1117 - acc: 0.9763 - val_loss: 1.7741 - val_acc: 0.7435\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9738\n",
      "Epoch 00017: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1244 - acc: 0.9738 - val_loss: 2.0481 - val_acc: 0.7200\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9754\n",
      "Epoch 00018: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1173 - acc: 0.9754 - val_loss: 2.0666 - val_acc: 0.7284\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9736\n",
      "Epoch 00019: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1237 - acc: 0.9736 - val_loss: 2.2052 - val_acc: 0.7237\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9755\n",
      "Epoch 00020: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1196 - acc: 0.9755 - val_loss: 2.0564 - val_acc: 0.7214\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9818\n",
      "Epoch 00021: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0936 - acc: 0.9818 - val_loss: 2.6317 - val_acc: 0.6825\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9778\n",
      "Epoch 00022: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1130 - acc: 0.9778 - val_loss: 2.1312 - val_acc: 0.7249\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9809\n",
      "Epoch 00023: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0964 - acc: 0.9808 - val_loss: 2.0862 - val_acc: 0.7331\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9770\n",
      "Epoch 00024: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1175 - acc: 0.9769 - val_loss: 2.0514 - val_acc: 0.7410\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9820\n",
      "Epoch 00025: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0935 - acc: 0.9819 - val_loss: 2.2884 - val_acc: 0.7123\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9819\n",
      "Epoch 00026: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0965 - acc: 0.9819 - val_loss: 2.2654 - val_acc: 0.7319\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9792\n",
      "Epoch 00027: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1123 - acc: 0.9792 - val_loss: 2.1483 - val_acc: 0.7386\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9855\n",
      "Epoch 00028: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0812 - acc: 0.9855 - val_loss: 2.4610 - val_acc: 0.7081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9848\n",
      "Epoch 00029: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0772 - acc: 0.9848 - val_loss: 2.4425 - val_acc: 0.7174\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9825\n",
      "Epoch 00030: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0991 - acc: 0.9825 - val_loss: 2.5234 - val_acc: 0.7081\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9849\n",
      "Epoch 00031: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0860 - acc: 0.9849 - val_loss: 2.5978 - val_acc: 0.7244\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9832\n",
      "Epoch 00032: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0941 - acc: 0.9832 - val_loss: 2.4623 - val_acc: 0.7091\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9887\n",
      "Epoch 00033: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0664 - acc: 0.9887 - val_loss: 2.6416 - val_acc: 0.7081\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9825\n",
      "Epoch 00034: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0989 - acc: 0.9825 - val_loss: 2.7533 - val_acc: 0.7016\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9857\n",
      "Epoch 00035: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0815 - acc: 0.9857 - val_loss: 2.3257 - val_acc: 0.7463\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9876\n",
      "Epoch 00036: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0722 - acc: 0.9876 - val_loss: 2.2393 - val_acc: 0.7473\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9839\n",
      "Epoch 00037: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0902 - acc: 0.9839 - val_loss: 2.4761 - val_acc: 0.7249\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9862\n",
      "Epoch 00038: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0829 - acc: 0.9862 - val_loss: 2.6766 - val_acc: 0.7130\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9861\n",
      "Epoch 00039: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0810 - acc: 0.9860 - val_loss: 2.6509 - val_acc: 0.7279\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9880\n",
      "Epoch 00040: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0710 - acc: 0.9880 - val_loss: 2.3833 - val_acc: 0.7382\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9836\n",
      "Epoch 00041: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0982 - acc: 0.9836 - val_loss: 2.4668 - val_acc: 0.7393\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9908\n",
      "Epoch 00042: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0578 - acc: 0.9908 - val_loss: 2.2699 - val_acc: 0.7575\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9901\n",
      "Epoch 00043: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0655 - acc: 0.9901 - val_loss: 2.5273 - val_acc: 0.7382\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9876\n",
      "Epoch 00044: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0765 - acc: 0.9876 - val_loss: 2.5725 - val_acc: 0.7305\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9873\n",
      "Epoch 00045: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0756 - acc: 0.9873 - val_loss: 2.5580 - val_acc: 0.7298\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9856\n",
      "Epoch 00046: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0930 - acc: 0.9856 - val_loss: 2.3998 - val_acc: 0.7379\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9875\n",
      "Epoch 00047: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0758 - acc: 0.9875 - val_loss: 2.4401 - val_acc: 0.7494\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9895\n",
      "Epoch 00048: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0647 - acc: 0.9895 - val_loss: 2.3416 - val_acc: 0.7582\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9905\n",
      "Epoch 00049: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0579 - acc: 0.9905 - val_loss: 2.7288 - val_acc: 0.7258\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9862\n",
      "Epoch 00050: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0880 - acc: 0.9862 - val_loss: 2.3756 - val_acc: 0.7633\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9887\n",
      "Epoch 00051: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0710 - acc: 0.9888 - val_loss: 2.3141 - val_acc: 0.7629\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9910\n",
      "Epoch 00052: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0574 - acc: 0.9910 - val_loss: 2.2794 - val_acc: 0.7624\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9914\n",
      "Epoch 00053: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0594 - acc: 0.9914 - val_loss: 2.7068 - val_acc: 0.7347\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9900\n",
      "Epoch 00054: val_loss did not improve from 1.42978\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0685 - acc: 0.9900 - val_loss: 2.6149 - val_acc: 0.7335\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.5778 - acc: 0.6600\n",
      "Loss: 1.5777674066438605 Accuracy: 0.66002077\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5691 - acc: 0.5644\n",
      "Epoch 00001: val_loss improved from inf to 1.35284, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_6_conv_checkpoint/001-1.3528.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 1.5690 - acc: 0.5644 - val_loss: 1.3528 - val_acc: 0.5998\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8452 - acc: 0.7644\n",
      "Epoch 00002: val_loss improved from 1.35284 to 1.01697, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_6_conv_checkpoint/002-1.0170.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.8452 - acc: 0.7644 - val_loss: 1.0170 - val_acc: 0.7310\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5471 - acc: 0.8445\n",
      "Epoch 00003: val_loss improved from 1.01697 to 0.84496, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_6_conv_checkpoint/003-0.8450.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.5471 - acc: 0.8445 - val_loss: 0.8450 - val_acc: 0.7806\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3880 - acc: 0.8890\n",
      "Epoch 00004: val_loss improved from 0.84496 to 0.84258, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_6_conv_checkpoint/004-0.8426.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.3882 - acc: 0.8890 - val_loss: 0.8426 - val_acc: 0.7869\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2859 - acc: 0.9164\n",
      "Epoch 00005: val_loss improved from 0.84258 to 0.59668, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_6_conv_checkpoint/005-0.5967.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2861 - acc: 0.9164 - val_loss: 0.5967 - val_acc: 0.8362\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2001 - acc: 0.9432\n",
      "Epoch 00006: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2002 - acc: 0.9432 - val_loss: 0.6704 - val_acc: 0.8290\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9502\n",
      "Epoch 00007: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1770 - acc: 0.9502 - val_loss: 0.6286 - val_acc: 0.8407\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9692\n",
      "Epoch 00008: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1144 - acc: 0.9692 - val_loss: 0.7464 - val_acc: 0.8169\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9693\n",
      "Epoch 00009: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1163 - acc: 0.9693 - val_loss: 0.7866 - val_acc: 0.8064\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9642\n",
      "Epoch 00010: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1238 - acc: 0.9642 - val_loss: 0.7992 - val_acc: 0.8146\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9747\n",
      "Epoch 00011: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0924 - acc: 0.9747 - val_loss: 0.6395 - val_acc: 0.8539\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9718\n",
      "Epoch 00012: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0996 - acc: 0.9718 - val_loss: 0.8615 - val_acc: 0.8239\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9791\n",
      "Epoch 00013: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0757 - acc: 0.9791 - val_loss: 0.7659 - val_acc: 0.8318\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9844\n",
      "Epoch 00014: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0610 - acc: 0.9844 - val_loss: 0.8201 - val_acc: 0.8369\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9737\n",
      "Epoch 00015: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1017 - acc: 0.9737 - val_loss: 0.6697 - val_acc: 0.8607\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9776\n",
      "Epoch 00016: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0841 - acc: 0.9775 - val_loss: 0.7473 - val_acc: 0.8444\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9838\n",
      "Epoch 00017: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0645 - acc: 0.9838 - val_loss: 0.6114 - val_acc: 0.8833\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9785\n",
      "Epoch 00018: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0809 - acc: 0.9784 - val_loss: 0.6503 - val_acc: 0.8784\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9837\n",
      "Epoch 00019: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0624 - acc: 0.9837 - val_loss: 0.7108 - val_acc: 0.8737\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9883\n",
      "Epoch 00020: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0496 - acc: 0.9883 - val_loss: 0.6429 - val_acc: 0.8719\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9890\n",
      "Epoch 00021: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0486 - acc: 0.9889 - val_loss: 0.9197 - val_acc: 0.8304\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9844\n",
      "Epoch 00022: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0595 - acc: 0.9844 - val_loss: 0.7980 - val_acc: 0.8502\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9871\n",
      "Epoch 00023: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0518 - acc: 0.9870 - val_loss: 0.7034 - val_acc: 0.8686\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9845\n",
      "Epoch 00024: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0585 - acc: 0.9845 - val_loss: 0.7719 - val_acc: 0.8544\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9878\n",
      "Epoch 00025: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0473 - acc: 0.9878 - val_loss: 0.7496 - val_acc: 0.8623\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9867\n",
      "Epoch 00026: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0488 - acc: 0.9867 - val_loss: 0.6812 - val_acc: 0.8763\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9908\n",
      "Epoch 00027: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0387 - acc: 0.9908 - val_loss: 0.8254 - val_acc: 0.8526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9839\n",
      "Epoch 00028: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0607 - acc: 0.9839 - val_loss: 0.8036 - val_acc: 0.8710\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9898\n",
      "Epoch 00029: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0403 - acc: 0.9898 - val_loss: 0.8319 - val_acc: 0.8623\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9926\n",
      "Epoch 00030: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0302 - acc: 0.9926 - val_loss: 0.6779 - val_acc: 0.8793\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9912\n",
      "Epoch 00031: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0369 - acc: 0.9911 - val_loss: 0.8075 - val_acc: 0.8686\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9828\n",
      "Epoch 00032: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0675 - acc: 0.9828 - val_loss: 0.7153 - val_acc: 0.8791\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9921\n",
      "Epoch 00033: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0330 - acc: 0.9921 - val_loss: 0.8792 - val_acc: 0.8532\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9912\n",
      "Epoch 00034: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0347 - acc: 0.9912 - val_loss: 0.8193 - val_acc: 0.8700\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9903\n",
      "Epoch 00035: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0375 - acc: 0.9903 - val_loss: 0.9821 - val_acc: 0.8449\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9905\n",
      "Epoch 00036: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0378 - acc: 0.9905 - val_loss: 0.9186 - val_acc: 0.8537\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9887\n",
      "Epoch 00037: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0431 - acc: 0.9887 - val_loss: 0.8257 - val_acc: 0.8565\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9946\n",
      "Epoch 00038: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0231 - acc: 0.9946 - val_loss: 0.9533 - val_acc: 0.8593\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9911\n",
      "Epoch 00039: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0353 - acc: 0.9911 - val_loss: 0.8139 - val_acc: 0.8744\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9881\n",
      "Epoch 00040: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0510 - acc: 0.9880 - val_loss: 0.8750 - val_acc: 0.8721\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 00041: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0330 - acc: 0.9917 - val_loss: 0.7624 - val_acc: 0.8793\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9934\n",
      "Epoch 00042: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0294 - acc: 0.9933 - val_loss: 0.7688 - val_acc: 0.8828\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9913\n",
      "Epoch 00043: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0357 - acc: 0.9913 - val_loss: 1.1695 - val_acc: 0.8300\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9897\n",
      "Epoch 00044: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0418 - acc: 0.9897 - val_loss: 0.8072 - val_acc: 0.8817\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9945\n",
      "Epoch 00045: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0255 - acc: 0.9945 - val_loss: 0.9027 - val_acc: 0.8626\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9942\n",
      "Epoch 00046: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0264 - acc: 0.9942 - val_loss: 0.9071 - val_acc: 0.8679\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9913\n",
      "Epoch 00047: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0365 - acc: 0.9913 - val_loss: 0.8273 - val_acc: 0.8700\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9942\n",
      "Epoch 00048: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0241 - acc: 0.9941 - val_loss: 0.8627 - val_acc: 0.8693\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9914\n",
      "Epoch 00049: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0361 - acc: 0.9914 - val_loss: 0.7110 - val_acc: 0.8896\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9928\n",
      "Epoch 00050: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0322 - acc: 0.9927 - val_loss: 0.9491 - val_acc: 0.8691\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9880\n",
      "Epoch 00051: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0496 - acc: 0.9880 - val_loss: 0.7805 - val_acc: 0.8817\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9930\n",
      "Epoch 00052: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0314 - acc: 0.9930 - val_loss: 0.6894 - val_acc: 0.8959\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9968\n",
      "Epoch 00053: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0164 - acc: 0.9968 - val_loss: 0.7983 - val_acc: 0.8859\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9939\n",
      "Epoch 00054: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0269 - acc: 0.9939 - val_loss: 0.7910 - val_acc: 0.8882\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9923\n",
      "Epoch 00055: val_loss did not improve from 0.59668\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0319 - acc: 0.9923 - val_loss: 0.8242 - val_acc: 0.8810\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.7025 - acc: 0.8114\n",
      "Loss: 0.7024740458525106 Accuracy: 0.81142265\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3045 - acc: 0.6126\n",
      "Epoch 00001: val_loss improved from inf to 1.21019, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_7_conv_checkpoint/001-1.2102.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 1.3045 - acc: 0.6125 - val_loss: 1.2102 - val_acc: 0.6003\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5999 - acc: 0.8269\n",
      "Epoch 00002: val_loss improved from 1.21019 to 0.52355, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_7_conv_checkpoint/002-0.5236.hdf5\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.6000 - acc: 0.8269 - val_loss: 0.5236 - val_acc: 0.8449\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3963 - acc: 0.8853\n",
      "Epoch 00003: val_loss improved from 0.52355 to 0.50866, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_7_conv_checkpoint/003-0.5087.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.3964 - acc: 0.8853 - val_loss: 0.5087 - val_acc: 0.8570\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2879 - acc: 0.9164\n",
      "Epoch 00004: val_loss improved from 0.50866 to 0.43872, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_7_conv_checkpoint/004-0.4387.hdf5\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.2880 - acc: 0.9164 - val_loss: 0.4387 - val_acc: 0.8740\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2290 - acc: 0.9319\n",
      "Epoch 00005: val_loss did not improve from 0.43872\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.2292 - acc: 0.9318 - val_loss: 0.4428 - val_acc: 0.8735\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1888 - acc: 0.9435\n",
      "Epoch 00006: val_loss improved from 0.43872 to 0.34876, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_7_conv_checkpoint/006-0.3488.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1889 - acc: 0.9435 - val_loss: 0.3488 - val_acc: 0.9038\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9548\n",
      "Epoch 00007: val_loss did not improve from 0.34876\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1473 - acc: 0.9548 - val_loss: 0.3704 - val_acc: 0.9119\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9654\n",
      "Epoch 00008: val_loss did not improve from 0.34876\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1141 - acc: 0.9654 - val_loss: 0.5434 - val_acc: 0.8528\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9691\n",
      "Epoch 00009: val_loss improved from 0.34876 to 0.31940, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_7_conv_checkpoint/009-0.3194.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1017 - acc: 0.9691 - val_loss: 0.3194 - val_acc: 0.9103\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9790\n",
      "Epoch 00010: val_loss did not improve from 0.31940\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0743 - acc: 0.9789 - val_loss: 0.4608 - val_acc: 0.8877\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9745\n",
      "Epoch 00011: val_loss did not improve from 0.31940\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0860 - acc: 0.9745 - val_loss: 0.3291 - val_acc: 0.9203\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9775\n",
      "Epoch 00012: val_loss did not improve from 0.31940\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0764 - acc: 0.9774 - val_loss: 0.4847 - val_acc: 0.8810\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9739\n",
      "Epoch 00013: val_loss improved from 0.31940 to 0.30240, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_7_conv_checkpoint/013-0.3024.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0883 - acc: 0.9739 - val_loss: 0.3024 - val_acc: 0.9266\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9861\n",
      "Epoch 00014: val_loss did not improve from 0.30240\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0492 - acc: 0.9860 - val_loss: 0.3300 - val_acc: 0.9234\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9869\n",
      "Epoch 00015: val_loss did not improve from 0.30240\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0460 - acc: 0.9869 - val_loss: 0.3148 - val_acc: 0.9238\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9890\n",
      "Epoch 00016: val_loss did not improve from 0.30240\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0401 - acc: 0.9890 - val_loss: 0.3704 - val_acc: 0.9152\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9862\n",
      "Epoch 00017: val_loss did not improve from 0.30240\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0457 - acc: 0.9861 - val_loss: 0.3694 - val_acc: 0.9152\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9793\n",
      "Epoch 00018: val_loss improved from 0.30240 to 0.30061, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_7_conv_checkpoint/018-0.3006.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0666 - acc: 0.9793 - val_loss: 0.3006 - val_acc: 0.9262\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9881\n",
      "Epoch 00019: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0394 - acc: 0.9880 - val_loss: 0.3157 - val_acc: 0.9322\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9888\n",
      "Epoch 00020: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0382 - acc: 0.9888 - val_loss: 0.3071 - val_acc: 0.9306\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9856\n",
      "Epoch 00021: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0469 - acc: 0.9856 - val_loss: 0.3367 - val_acc: 0.9245\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9907\n",
      "Epoch 00022: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0317 - acc: 0.9907 - val_loss: 0.3017 - val_acc: 0.9315\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9935\n",
      "Epoch 00023: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0253 - acc: 0.9935 - val_loss: 0.3340 - val_acc: 0.9280\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9903\n",
      "Epoch 00024: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0340 - acc: 0.9903 - val_loss: 0.3809 - val_acc: 0.9157\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9926\n",
      "Epoch 00025: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0284 - acc: 0.9926 - val_loss: 0.3492 - val_acc: 0.9290\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9932\n",
      "Epoch 00026: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0247 - acc: 0.9932 - val_loss: 0.3483 - val_acc: 0.9308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9864\n",
      "Epoch 00027: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0438 - acc: 0.9864 - val_loss: 0.4116 - val_acc: 0.9140\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9949\n",
      "Epoch 00028: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0183 - acc: 0.9949 - val_loss: 0.3150 - val_acc: 0.9369\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9957\n",
      "Epoch 00029: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0169 - acc: 0.9957 - val_loss: 0.3098 - val_acc: 0.9357\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9868\n",
      "Epoch 00030: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0471 - acc: 0.9868 - val_loss: 0.3789 - val_acc: 0.9210\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 00031: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0161 - acc: 0.9951 - val_loss: 0.3857 - val_acc: 0.9283\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9870\n",
      "Epoch 00032: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0434 - acc: 0.9870 - val_loss: 0.3306 - val_acc: 0.9352\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9960\n",
      "Epoch 00033: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0143 - acc: 0.9960 - val_loss: 0.3348 - val_acc: 0.9352\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9963\n",
      "Epoch 00034: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0141 - acc: 0.9963 - val_loss: 0.3108 - val_acc: 0.9399\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9906\n",
      "Epoch 00035: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0313 - acc: 0.9906 - val_loss: 0.5460 - val_acc: 0.9089\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9962\n",
      "Epoch 00036: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0152 - acc: 0.9962 - val_loss: 0.3704 - val_acc: 0.9320\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9937\n",
      "Epoch 00037: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0236 - acc: 0.9937 - val_loss: 0.6686 - val_acc: 0.8887\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9914\n",
      "Epoch 00038: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0282 - acc: 0.9914 - val_loss: 0.3826 - val_acc: 0.9257\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9892\n",
      "Epoch 00039: val_loss did not improve from 0.30061\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0357 - acc: 0.9892 - val_loss: 0.3065 - val_acc: 0.9422\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9958\n",
      "Epoch 00040: val_loss improved from 0.30061 to 0.27744, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_7_conv_checkpoint/040-0.2774.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0140 - acc: 0.9958 - val_loss: 0.2774 - val_acc: 0.9467\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9968\n",
      "Epoch 00041: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0124 - acc: 0.9968 - val_loss: 0.2973 - val_acc: 0.9439\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9913\n",
      "Epoch 00042: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0317 - acc: 0.9913 - val_loss: 0.3528 - val_acc: 0.9357\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9946\n",
      "Epoch 00043: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0189 - acc: 0.9946 - val_loss: 0.3986 - val_acc: 0.9241\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9969\n",
      "Epoch 00044: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0112 - acc: 0.9969 - val_loss: 0.3649 - val_acc: 0.9287\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9944\n",
      "Epoch 00045: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0187 - acc: 0.9944 - val_loss: 0.4143 - val_acc: 0.9292\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9954\n",
      "Epoch 00046: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0153 - acc: 0.9953 - val_loss: 0.3699 - val_acc: 0.9317\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9896\n",
      "Epoch 00047: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0374 - acc: 0.9896 - val_loss: 0.4007 - val_acc: 0.9238\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9930\n",
      "Epoch 00048: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0239 - acc: 0.9930 - val_loss: 0.3416 - val_acc: 0.9369\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9980\n",
      "Epoch 00049: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0078 - acc: 0.9980 - val_loss: 0.3213 - val_acc: 0.9415\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9979\n",
      "Epoch 00050: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0080 - acc: 0.9979 - val_loss: 0.3276 - val_acc: 0.9376\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9930\n",
      "Epoch 00051: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0221 - acc: 0.9930 - val_loss: 0.4447 - val_acc: 0.9194\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9937\n",
      "Epoch 00052: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0216 - acc: 0.9937 - val_loss: 0.4223 - val_acc: 0.9294\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9949\n",
      "Epoch 00053: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0166 - acc: 0.9949 - val_loss: 0.3251 - val_acc: 0.9427\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9972\n",
      "Epoch 00054: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0104 - acc: 0.9972 - val_loss: 0.3832 - val_acc: 0.9287\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9939\n",
      "Epoch 00055: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0227 - acc: 0.9939 - val_loss: 0.3862 - val_acc: 0.9324\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9916\n",
      "Epoch 00056: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0341 - acc: 0.9916 - val_loss: 0.3670 - val_acc: 0.9331\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9951\n",
      "Epoch 00057: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0199 - acc: 0.9951 - val_loss: 0.3237 - val_acc: 0.9436\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9974\n",
      "Epoch 00058: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0096 - acc: 0.9974 - val_loss: 0.3590 - val_acc: 0.9455\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9946\n",
      "Epoch 00059: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0175 - acc: 0.9946 - val_loss: 0.3439 - val_acc: 0.9441\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9985\n",
      "Epoch 00060: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0066 - acc: 0.9985 - val_loss: 0.3309 - val_acc: 0.9429\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9982\n",
      "Epoch 00061: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0073 - acc: 0.9982 - val_loss: 0.5040 - val_acc: 0.9199\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9936\n",
      "Epoch 00062: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0217 - acc: 0.9936 - val_loss: 0.4267 - val_acc: 0.9276\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9921\n",
      "Epoch 00063: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0289 - acc: 0.9921 - val_loss: 0.4235 - val_acc: 0.9304\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9957\n",
      "Epoch 00064: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0141 - acc: 0.9957 - val_loss: 0.3625 - val_acc: 0.9413\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9977\n",
      "Epoch 00065: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0083 - acc: 0.9977 - val_loss: 0.4088 - val_acc: 0.9359\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9933\n",
      "Epoch 00066: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0261 - acc: 0.9933 - val_loss: 0.3574 - val_acc: 0.9439\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9973\n",
      "Epoch 00067: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0086 - acc: 0.9973 - val_loss: 0.3789 - val_acc: 0.9406\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9984\n",
      "Epoch 00068: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0060 - acc: 0.9984 - val_loss: 0.3738 - val_acc: 0.9394\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9966\n",
      "Epoch 00069: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0134 - acc: 0.9965 - val_loss: 0.3985 - val_acc: 0.9341\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9925\n",
      "Epoch 00070: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0267 - acc: 0.9925 - val_loss: 0.3771 - val_acc: 0.9408\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9976\n",
      "Epoch 00071: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0093 - acc: 0.9976 - val_loss: 0.3477 - val_acc: 0.9401\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9937\n",
      "Epoch 00072: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0238 - acc: 0.9937 - val_loss: 0.3822 - val_acc: 0.9378\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 00073: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0079 - acc: 0.9976 - val_loss: 0.3404 - val_acc: 0.9392\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9978\n",
      "Epoch 00074: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0084 - acc: 0.9978 - val_loss: 0.4329 - val_acc: 0.9327\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9944\n",
      "Epoch 00075: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0191 - acc: 0.9944 - val_loss: 0.3787 - val_acc: 0.9364\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9983\n",
      "Epoch 00076: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0054 - acc: 0.9983 - val_loss: 0.3432 - val_acc: 0.9434\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9986\n",
      "Epoch 00077: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0068 - acc: 0.9986 - val_loss: 0.3656 - val_acc: 0.9404\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9965\n",
      "Epoch 00078: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0112 - acc: 0.9965 - val_loss: 0.4647 - val_acc: 0.9290\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9927\n",
      "Epoch 00079: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0265 - acc: 0.9927 - val_loss: 0.3623 - val_acc: 0.9439\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9977\n",
      "Epoch 00080: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0064 - acc: 0.9977 - val_loss: 0.3511 - val_acc: 0.9443\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9986\n",
      "Epoch 00081: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0053 - acc: 0.9986 - val_loss: 0.4345 - val_acc: 0.9304\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9976\n",
      "Epoch 00082: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0099 - acc: 0.9976 - val_loss: 0.4046 - val_acc: 0.9352\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9962\n",
      "Epoch 00083: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0113 - acc: 0.9962 - val_loss: 0.4618 - val_acc: 0.9292\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9961\n",
      "Epoch 00084: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0133 - acc: 0.9961 - val_loss: 0.4379 - val_acc: 0.9308\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9942\n",
      "Epoch 00085: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0207 - acc: 0.9942 - val_loss: 0.3803 - val_acc: 0.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 00086: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0079 - acc: 0.9976 - val_loss: 0.3862 - val_acc: 0.9446\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9978\n",
      "Epoch 00087: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0078 - acc: 0.9978 - val_loss: 0.3488 - val_acc: 0.9492\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9979\n",
      "Epoch 00088: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0075 - acc: 0.9979 - val_loss: 0.3881 - val_acc: 0.9371\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9939\n",
      "Epoch 00089: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0213 - acc: 0.9939 - val_loss: 0.3873 - val_acc: 0.9399\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9969\n",
      "Epoch 00090: val_loss did not improve from 0.27744\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0104 - acc: 0.9969 - val_loss: 0.3573 - val_acc: 0.9467\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.3865 - acc: 0.9244\n",
      "Loss: 0.386487360042544 Accuracy: 0.9244029\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0631 - acc: 0.6811\n",
      "Epoch 00001: val_loss improved from inf to 0.77607, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_8_conv_checkpoint/001-0.7761.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 1.0632 - acc: 0.6811 - val_loss: 0.7761 - val_acc: 0.7661\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4232 - acc: 0.8720\n",
      "Epoch 00002: val_loss improved from 0.77607 to 0.35306, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_8_conv_checkpoint/002-0.3531.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.4232 - acc: 0.8719 - val_loss: 0.3531 - val_acc: 0.8963\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2763 - acc: 0.9173\n",
      "Epoch 00003: val_loss did not improve from 0.35306\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2764 - acc: 0.9172 - val_loss: 0.3622 - val_acc: 0.8938\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2141 - acc: 0.9343\n",
      "Epoch 00004: val_loss improved from 0.35306 to 0.26041, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_8_conv_checkpoint/004-0.2604.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2142 - acc: 0.9342 - val_loss: 0.2604 - val_acc: 0.9201\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9466\n",
      "Epoch 00005: val_loss improved from 0.26041 to 0.25145, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_8_conv_checkpoint/005-0.2514.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1742 - acc: 0.9466 - val_loss: 0.2514 - val_acc: 0.9215\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9601\n",
      "Epoch 00006: val_loss improved from 0.25145 to 0.19939, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_8_conv_checkpoint/006-0.1994.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1342 - acc: 0.9601 - val_loss: 0.1994 - val_acc: 0.9401\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9674\n",
      "Epoch 00007: val_loss did not improve from 0.19939\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1079 - acc: 0.9675 - val_loss: 0.4241 - val_acc: 0.8735\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9712\n",
      "Epoch 00008: val_loss did not improve from 0.19939\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0940 - acc: 0.9712 - val_loss: 0.2142 - val_acc: 0.9341\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9759\n",
      "Epoch 00009: val_loss did not improve from 0.19939\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0784 - acc: 0.9759 - val_loss: 0.2188 - val_acc: 0.9385\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9814\n",
      "Epoch 00010: val_loss did not improve from 0.19939\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0631 - acc: 0.9814 - val_loss: 0.2210 - val_acc: 0.9369\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9845\n",
      "Epoch 00011: val_loss did not improve from 0.19939\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0528 - acc: 0.9845 - val_loss: 0.2297 - val_acc: 0.9362\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9811\n",
      "Epoch 00012: val_loss did not improve from 0.19939\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0611 - acc: 0.9810 - val_loss: 0.2427 - val_acc: 0.9283\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9830\n",
      "Epoch 00013: val_loss improved from 0.19939 to 0.17709, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_8_conv_checkpoint/013-0.1771.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0555 - acc: 0.9830 - val_loss: 0.1771 - val_acc: 0.9476\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9896\n",
      "Epoch 00014: val_loss did not improve from 0.17709\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0360 - acc: 0.9896 - val_loss: 0.1852 - val_acc: 0.9492\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9901\n",
      "Epoch 00015: val_loss did not improve from 0.17709\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0347 - acc: 0.9901 - val_loss: 0.2378 - val_acc: 0.9327\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9879\n",
      "Epoch 00016: val_loss did not improve from 0.17709\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0399 - acc: 0.9879 - val_loss: 0.1810 - val_acc: 0.9522\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9943\n",
      "Epoch 00017: val_loss did not improve from 0.17709\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0206 - acc: 0.9943 - val_loss: 0.2191 - val_acc: 0.9432\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9901\n",
      "Epoch 00018: val_loss did not improve from 0.17709\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0324 - acc: 0.9901 - val_loss: 0.2443 - val_acc: 0.9320\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9911\n",
      "Epoch 00019: val_loss did not improve from 0.17709\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0298 - acc: 0.9911 - val_loss: 0.2098 - val_acc: 0.9509\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9927\n",
      "Epoch 00020: val_loss did not improve from 0.17709\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0240 - acc: 0.9927 - val_loss: 0.1941 - val_acc: 0.9520\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9956\n",
      "Epoch 00021: val_loss did not improve from 0.17709\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0163 - acc: 0.9955 - val_loss: 0.2115 - val_acc: 0.9434\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9855\n",
      "Epoch 00022: val_loss improved from 0.17709 to 0.16734, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_8_conv_checkpoint/022-0.1673.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0429 - acc: 0.9855 - val_loss: 0.1673 - val_acc: 0.9569\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9962\n",
      "Epoch 00023: val_loss improved from 0.16734 to 0.16218, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_8_conv_checkpoint/023-0.1622.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0145 - acc: 0.9962 - val_loss: 0.1622 - val_acc: 0.9576\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9947\n",
      "Epoch 00024: val_loss did not improve from 0.16218\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0199 - acc: 0.9947 - val_loss: 0.1632 - val_acc: 0.9550\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9968\n",
      "Epoch 00025: val_loss did not improve from 0.16218\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0136 - acc: 0.9967 - val_loss: 0.2398 - val_acc: 0.9434\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9879\n",
      "Epoch 00026: val_loss did not improve from 0.16218\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0385 - acc: 0.9879 - val_loss: 0.1935 - val_acc: 0.9518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9974\n",
      "Epoch 00027: val_loss did not improve from 0.16218\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0106 - acc: 0.9974 - val_loss: 0.1820 - val_acc: 0.9576\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9916\n",
      "Epoch 00028: val_loss did not improve from 0.16218\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0271 - acc: 0.9916 - val_loss: 0.1738 - val_acc: 0.9541\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9981\n",
      "Epoch 00029: val_loss improved from 0.16218 to 0.15576, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_BN_8_conv_checkpoint/029-0.1558.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0078 - acc: 0.9981 - val_loss: 0.1558 - val_acc: 0.9571\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9977\n",
      "Epoch 00030: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0089 - acc: 0.9977 - val_loss: 0.2167 - val_acc: 0.9469\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9921\n",
      "Epoch 00031: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0242 - acc: 0.9921 - val_loss: 0.3725 - val_acc: 0.9173\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9908\n",
      "Epoch 00032: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0286 - acc: 0.9908 - val_loss: 0.1566 - val_acc: 0.9618\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9973\n",
      "Epoch 00033: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0102 - acc: 0.9973 - val_loss: 0.1583 - val_acc: 0.9606\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9991\n",
      "Epoch 00034: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0047 - acc: 0.9991 - val_loss: 0.1826 - val_acc: 0.9588\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9967\n",
      "Epoch 00035: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0120 - acc: 0.9967 - val_loss: 0.3198 - val_acc: 0.9334\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9918\n",
      "Epoch 00036: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0258 - acc: 0.9918 - val_loss: 0.2289 - val_acc: 0.9462\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9953\n",
      "Epoch 00037: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0163 - acc: 0.9953 - val_loss: 0.2023 - val_acc: 0.9520\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9981\n",
      "Epoch 00038: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0068 - acc: 0.9981 - val_loss: 0.2331 - val_acc: 0.9490\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9977\n",
      "Epoch 00039: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0086 - acc: 0.9977 - val_loss: 0.2667 - val_acc: 0.9453\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9924\n",
      "Epoch 00040: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0249 - acc: 0.9924 - val_loss: 0.2356 - val_acc: 0.9441\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9968\n",
      "Epoch 00041: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0093 - acc: 0.9968 - val_loss: 0.1781 - val_acc: 0.9630\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9989\n",
      "Epoch 00042: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0046 - acc: 0.9989 - val_loss: 0.1995 - val_acc: 0.9548\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9952\n",
      "Epoch 00043: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0149 - acc: 0.9952 - val_loss: 0.2260 - val_acc: 0.9509\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9943\n",
      "Epoch 00044: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0171 - acc: 0.9943 - val_loss: 0.2002 - val_acc: 0.9571\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9975\n",
      "Epoch 00045: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0076 - acc: 0.9975 - val_loss: 0.1734 - val_acc: 0.9609\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9981\n",
      "Epoch 00046: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0067 - acc: 0.9981 - val_loss: 0.1876 - val_acc: 0.9585\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9968\n",
      "Epoch 00047: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0103 - acc: 0.9968 - val_loss: 0.3012 - val_acc: 0.9362\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9939\n",
      "Epoch 00048: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0183 - acc: 0.9939 - val_loss: 0.2357 - val_acc: 0.9483\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9981\n",
      "Epoch 00049: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0061 - acc: 0.9981 - val_loss: 0.1878 - val_acc: 0.9599\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9968\n",
      "Epoch 00050: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0108 - acc: 0.9968 - val_loss: 0.2988 - val_acc: 0.9413\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9950\n",
      "Epoch 00051: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0150 - acc: 0.9950 - val_loss: 0.1760 - val_acc: 0.9637\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9985\n",
      "Epoch 00052: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0048 - acc: 0.9985 - val_loss: 0.2154 - val_acc: 0.9557\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9985\n",
      "Epoch 00053: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0053 - acc: 0.9985 - val_loss: 0.2747 - val_acc: 0.9453\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9947\n",
      "Epoch 00054: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0174 - acc: 0.9946 - val_loss: 0.3175 - val_acc: 0.9350\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9952\n",
      "Epoch 00055: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0152 - acc: 0.9952 - val_loss: 0.1730 - val_acc: 0.9602\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9994\n",
      "Epoch 00056: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0026 - acc: 0.9994 - val_loss: 0.1644 - val_acc: 0.9627\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 00057: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0037 - acc: 0.9990 - val_loss: 0.1755 - val_acc: 0.9625\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9961\n",
      "Epoch 00058: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0117 - acc: 0.9961 - val_loss: 0.2363 - val_acc: 0.9492\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9973\n",
      "Epoch 00059: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0081 - acc: 0.9973 - val_loss: 0.2493 - val_acc: 0.9522\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9986\n",
      "Epoch 00060: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0048 - acc: 0.9986 - val_loss: 0.1866 - val_acc: 0.9588\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9970\n",
      "Epoch 00061: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0093 - acc: 0.9970 - val_loss: 0.2116 - val_acc: 0.9574\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9968\n",
      "Epoch 00062: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0108 - acc: 0.9967 - val_loss: 0.3486 - val_acc: 0.9320\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9952\n",
      "Epoch 00063: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0143 - acc: 0.9952 - val_loss: 0.1941 - val_acc: 0.9627\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 00064: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0030 - acc: 0.9993 - val_loss: 0.1742 - val_acc: 0.9646\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 00065: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0028 - acc: 0.9992 - val_loss: 0.2048 - val_acc: 0.9599\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9962\n",
      "Epoch 00066: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0120 - acc: 0.9962 - val_loss: 0.2862 - val_acc: 0.9492\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9987\n",
      "Epoch 00067: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0044 - acc: 0.9987 - val_loss: 0.1994 - val_acc: 0.9611\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9955\n",
      "Epoch 00068: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0139 - acc: 0.9955 - val_loss: 0.2208 - val_acc: 0.9569\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9964\n",
      "Epoch 00069: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0099 - acc: 0.9964 - val_loss: 0.1802 - val_acc: 0.9632\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 00070: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0026 - acc: 0.9993 - val_loss: 0.1784 - val_acc: 0.9660\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 00071: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0018 - acc: 0.9996 - val_loss: 0.1598 - val_acc: 0.9704\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9961\n",
      "Epoch 00072: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0127 - acc: 0.9961 - val_loss: 0.2285 - val_acc: 0.9534\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9965\n",
      "Epoch 00073: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0112 - acc: 0.9965 - val_loss: 0.1833 - val_acc: 0.9627\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9994\n",
      "Epoch 00074: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0023 - acc: 0.9994 - val_loss: 0.1888 - val_acc: 0.9620\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9991\n",
      "Epoch 00075: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0032 - acc: 0.9991 - val_loss: 0.1953 - val_acc: 0.9597\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9956\n",
      "Epoch 00076: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0148 - acc: 0.9956 - val_loss: 0.2041 - val_acc: 0.9560\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 00077: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0030 - acc: 0.9993 - val_loss: 0.1844 - val_acc: 0.9658\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9991\n",
      "Epoch 00078: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0032 - acc: 0.9991 - val_loss: 0.2131 - val_acc: 0.9592\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9983\n",
      "Epoch 00079: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0062 - acc: 0.9983 - val_loss: 0.2763 - val_acc: 0.9450\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd4FNX6x79nd5NseiMUCRBKaKGEHi8KWFARBWygV1DhWq4/e8eGWK/eq/cqigUbgmJFEAuCSLMhBAg9ISRAEiAhvW+yu/P+/ngzqZvspmxiyPt5nn2SnTlzzjuzM+d73veUUUQEQRAEQQAAQ1sbIAiCIPx1EFEQBEEQKhFREARBECoRURAEQRAqEVEQBEEQKhFREARBECoRURAEQRAqEVEQBEEQKhFREARBECoxtbUBjaVTp04UERHR1mYIgiC0K3bu3JlFRGHO0rU7UYiIiEBsbGxbmyEIgtCuUEoddyWdhI8EQRCESkQUBEEQhEpEFARBEIRK2l2fgiOsVivS0tJgsVja2pR2i9lsRnh4ODw8PNraFEEQ2pAzQhTS0tLg7++PiIgIKKXa2px2BxEhOzsbaWlp6N27d1ubIwhCG3JGhI8sFgtCQ0NFEJqIUgqhoaHiaQmCcGaIAgARhGYi108QBOAMEgVn2GyFKCs7AXn9qCAIQv10GFHQtGKUl58CoLV43nl5eXjzzTebdOyll16KvLw8l9MvXLgQL7/8cpPKEgRBcEaHEQX9VIlaVxRsNluDx/7www8ICgpqcZsEQRCaQgcSBT1m3vKiMH/+fCQlJSE6OhoPPfQQNm/ejHPPPRfTpk3D4MGDAQAzZszAqFGjEBUVhSVLllQeGxERgaysLBw7dgyDBg3CLbfcgqioKFx00UUoLS1tsNy4uDjExMRg2LBhuOKKK5CbmwsAWLRoEQYPHoxhw4bh2muvBQBs2bIF0dHRiI6OxogRI1BYWNji10EQhPbPGTEktTqJifeiqCiuznYiKzTNAqPRF43VQj+/aERGvlrv/hdffBH79+9HXByXu3nzZuzatQv79++vHOL5wQcfICQkBKWlpRgzZgyuuuoqhIaG1rI9EZ9++ineffddzJw5EytXrsTs2bPrLfeGG27A66+/jokTJ2LBggV4+umn8eqrr+LFF1/E0aNH4eXlVRmaevnll7F48WKMHz8eRUVFMJvNjboGgiB0DDqgp9A6jB07tsaY/0WLFmH48OGIiYlBamoqEhMT6xzTu3dvREdHAwBGjRqFY8eO1Zt/fn4+8vLyMHHiRADAjTfeiK1btwIAhg0bhuuvvx4ff/wxTCbW/fHjx+P+++/HokWLkJeXV7ldEAShOmdczVBfi95my0dpaSJ8fAbCaPRzux2+vr6V/2/evBkbNmzAH3/8AR8fH0yaNMnhnAAvL6/K/41Go9PwUX18//332Lp1K7799ls8//zz2LdvH+bPn4+pU6fihx9+wPjx47Fu3ToMHDiwSfkLgnDm0uE8BXcMSfX3928wRp+fn4/g4GD4+PggPj4e27Zta3aZgYGBCA4Oxi+//AIAWL58OSZOnAhN05CamorzzjsPL730EvLz81FUVISkpCQMHToUjzzyCMaMGYP4+Phm2yAIwpnHGecp1I+ufy3f0RwaGorx48djyJAhmDJlCqZOnVpj/yWXXIK3334bgwYNwoABAxATE9Mi5X700Uf45z//iZKSEvTp0wcffvgh7HY7Zs+ejfz8fBAR7r77bgQFBeHJJ5/Epk2bYDAYEBUVhSlTprSIDYIgnFkod03mUkp9AOAyAKeJaIiD/QrAawAuBVAC4CYi2uUs39GjR1Ptl+wcOnQIgwYNavA4u70EJSUHYTb3hYdHsOsn0oFw5ToKgtA+UUrtJKLRztK5M3y0FMAlDeyfAiCy4nMrgLfcaAvcOSRVEAThTMFtokBEWwHkNJBkOoBlxGwDEKSU6uYue5TSJ6/JMheCIAj10ZZ9Ct0BpFb7nlax7ZR7inNfn0JHhwhwtJ6epgHZ2UBAAFBtYFUNEhOBkBCg1pQNAMCpU8DmzYDNBphMgIcH4OsLjBvHxzgjOxuIiwMyMoDTp/kDAD17Vn369gW8vRs+t/R0ICkJOH4csNvZDg8PwGwGRo0CujloythswJEjwMmTfHx6OmCxAIMGAUOHAr17A0aj4zKLioDDh4HMTKCsjI+zWPgaBgVVfbp3B/z86pZ76BBw4ADbGBQEBAfz37AwTq//VlYrX/+DB4HUVD5XHT8/tnPIEMDfv66NmsbnFxsL7NoF5OVVXRcPD6BrV762ffvyuQJAQUHVJy8PyM3lT1ER3yOdOvEnOJjzMJn4Gnl58e/t41P1m5w6xeXu2gWcOMHbleJPcDAQGVn1IQJSUvj3S03lsvr350+XLjWvR2Ehp0tKqvrNy8r4utrtgMEA9OsHREUBgwcDffpUXXerFcjP5+MSE/n6ZGdXnYfJxOc3eDAf368f53nwILB3L7B/P18Lg4HTG418j/n4VH0mTeJj3Um76GhWSt0KDjGhZ8+eTc2j4r+OIwp2O9+kBQV8Q/r4cKXq6Vn1IGgaf2w2vvm//ZYr0eRkvrmTk7lCuu024B//qKpAiYD164GnngK2b+cHUa/cNY0f2vR0zjc0FLjlFuD227ki1jRg7VrgP/8BtmxhW8aMAS6+GDjnHGD3bmD1aqC+QVpKAaNHA5MnA+eeyw+2XvHl5gJr1vDxW7dyWTr61IzqK494eHDFfu65wPjxnP7AAf4cPMgPdklJw9d54EDgvPOAkSO5Qt6+Hdi5E2hoRLG3N1cofn788fXlCiEhoaqSc4XOnbni7dULOHYM2LOn4XLNZj7GbAaOHuWKzBl9+wLh4Zy2rAwoL+fKsqCgKs+QEN5vtfJ+Z9esKejl2GxVAq8Unw/A96SmseA4WV2mEj8/rnyLix0fo4uRXqmXlwPLl7uWt5cXC7HdXlM0dPE1maqeP/38goI4vf7RGwU6b7/tflFwW0czACilIgB8V09H8zsANhPRpxXfEwBMIqIGPYWmdjQTaSgq2gVPz+7w8nJblMqt2Gx8U+Xl8Y1CVPUxGLiy11tqJSXc6iHiG1rTqm5GvYVafRsAZGUdwpQpfB1NJq5o+vblh3/bNq58778fGD4cePZZ4LffOM2sWfxQZWfzx2Dg1nO3bnzMli3AN99wGZddxq2oQ4eAHj2AO+9kW9evB/78s+oBGT0amDEDuPRSbtnpD1V2NnsPP/3ENtntjq/VkCF8/HnnAWedxRVHUFBVy19vOcbFAb/8AuzYUbOCjIjgh2/AAK68+/ThFq+HR1XlV1AA/P47sGkT51FUxBXByJHA2LH8t0ePqmthMrHQ7NvHn+PH+boVF/OxZjOXp3+6deNtZjPnW17Ov73eyk5JqdmiDQ9ngRs1Chg2jM9VT5+Tw57H6dP8t6iIW9F6q7W255KTw63XvXtZaDIy2AZPT/5068a/0ejRnEftuZB6izkpicXHaOTfMSCAPQ/dgwkO5oq5oIB/26wsPjebrepjsbA92dn8lwiIjubrGx3t2Fs6dozvs8REFo5evfjToweXlZDA3tiRI5yfry9//Py44aL/5gEBde+t4mIgPp5/y2PH+Nx0z8bPj5+Zfv349zDUCtCXlvKxesPD05N/q6FD+ThH3qOm8XElJVUNu6bgakdzW4rCVAB3gkcfjQOwiIjGOsuz6aJAKCraCU/PbvDy6u7yObgDm41vLIulqiVgs1VVAGYz32R6RWi1cnq9ktfDKLq7rBRXjnorzWqtGWrw8+Pj9BurpISP0d1Ug4Fv6OPHD8FuH4SwML6hqz/oW7cCzz3HlTHAoYvHH2fvwdPT+TmnpHAr54MPuJJ+8EHgmmv4XHRyc1kYoqL44XVGQQF7FXoYIi+PbZ4yhR/KxlBayqEIT08O8dSuaJxhtXIF0auXa9dDEFqbNhcFpdSnACYB6AQgA8BTADwAgIjerhiS+gZ4hFIJgLlEFOs4tyqaKgoAUFi4Cx4eYTCbXahxWhC7nSv1ggKu2IuLgQkT/LB1a1FlzNRkYoEYN46310Z3LYOCqgShPuqL8TvDleu4Ywe3vq68km0SBKF94KoouK1PgYiuc7KfANzhrvIdYwDg3tFHmsYt/5KSqrCAHuNViiv0bt24dT58OItB9QrcYOCWqs1WFQqqncYZ7nyJ2pgx/BGEjkZhWSEySzLRJ7hPW5viVtpFR3NLoZRq8fcpaBpw//3zERzcA1dffQcsFuCddxbC29sP11zzTzz00HQUFeVC06x47rnncMUV0yuPrR46qY6vL4e7Hn74YaxduxZKKTzxxBOYNWsWTp06hVmzZqGgoAA2mw1vvfUW/va3v+Ef//gHYmNjoZTCvHnzcN9997XoeQrCXw27Zkd2aTZMBhNCvF0YjuYiVrsVqQWpSM5NxuHsw4g9GYvtJ7bjYOZBEAh3jLkD/7v4f/Aw1vMANwEiwh9pf8Db5I3ortFt+nrcM08U7r2Xew8d4G0vBpQRMDQy7hEdDbxac6G94uKqTrExY2bhv/+9F3//+x0IDAS2bPkC3323DhERZqxbtwoBAQHIyspCTEwMZsyY5tIP/vXXXyMuLg579uxBVlYWxowZgwkTJmDFihW4+OKL8fjjj8Nut6OkpARxcXE4ceIE9u/fDwCNepPbmcTejL14a8db8PX0RYBXAAK8AhBsDkZn387o4tcFXXy7oKtfVxgN9YwFbUFWHVqF/277L6YPmI4bht+Azr6dXTrOYrPgUOYh7Du9D+X2coQHhKNHQA+EB4Qj0BzoUh5EhD0ZezCk8xCYDHUf8eV7lmP+z/MxNXIq5kbPRUx4TKMqodT8VGxI3oDj+cdxLO8YjucfR4m1BEZlhEEZYDKYMH3AdNw17i6H5demzFYGT6OnSzasSViDBZsW4FTRKWSVZEGraORFhkTi7B5n4+zws3FJv0sQERRR51ibZsMXB76ATbNhVLdRGNhpIIwGI8rt5dhybAu+Pfwt1iWtQ1JOEuxUNYKhk08njOs+DjOjZiKzOBNv7HgDBzIP4Iurv0CYbxgAIK0gDW9sfwNbjm+Bl9ELZpMZ3h7eCPQKRHhAeOXv2Ce4DyJDIyuvi12zY+WhlXjpt5ew6xQv6NAzsCdmDJiB6QOnY2Kvia1yv1bnzBMFpzQvfGSzAWlpLAgGA8f4p04dgeeeOw1f35PIzMxEp07BiIzsAavVisceewxbt26FwWDAiRMnkJGRga5duzot59dff8V1110Ho9GILl26YOLEidixYwfGjBmDefPmwWq1YsaMGYiOjkafPn2QnJyMu+66C1OnTsVFF13UrHOsDyLCsj3L8PmBz1FiLYHFZkGprRSeRk/0DOyJXoG90CuwF87tdS5GdhtZbz5WuxV/pP2BdUfWYdOxTfD38kdUWBSiwqLQP7Q/skqykJiTiMTsRKQXp+PqQVfj70P/7rRlds+P9+C3lN/gafREsbXYYZpR3UZh041cprt4a8dbuOOHOxDqE4pfU37Foz8/imkDpmHOsDkY230suvl1q6wAi8uLsSF5A747/B1+S/0Nh7MP16iQqnPdkOuw7IplDVa029K24YH1D+D31N8xNXIqPr/6c/h6Vg1XWXVoFW765ib0C+mHT/Z9gnd3vYuBnQZiXvQ83Db6NgR4ORhuU43jeccx9r2xOF18GgoK3QO6o1dgLwSbg2EnO+yaHbmWXNy//n58vO9jvHv5uw7vhYSsBHyT8A1Wx6/GtrRtUEohyByEYHMw+gT3wQfTP0B4QHiNY1LyUzBn1Rx08+uGGQNmVIp9UXkRtqVtw9rEtVi2ZxmMyoibom/CkxOeRK+gXgCAH4/8iAfWP4CDmQcr8/Px8MHgsMFIyEpAYXkhvE3euKDPBZg5eCb6BPep/IQHhNcQrJjwGNz87c0Y8+4YvHzRy1gdvxqfH/gcGmn4W4+/gUDIteTiZOFJ5FpycarwVI3f1MvohajOURjSeQh+T/0dR3KOoH9ofyy5bAmMBiNWx6/GOzvfwaLtixATHoOPZnyE/qH9G/xdWhK3jj5yB83paC4uPgilPODjE9mksvVhgFYrT87p1q1qCNmCBQvQqVMnpKeno2vXrrj77ruxdOlSrF27Fh9//DE8PDwQERGBzZs3IyIiAn5+figqqtuhrG+/7777MHToUMybNw8AMGfOHFxx1RWYMnUKUtNS8fP6n/HOW+/g/vvvxw033ICioiKsW7cOy5Ytg4efB15e/DI6+3aGj4dPg+dks9uQXpwOq92KlKQULDywEESEawZfgznD51RWEkdzj+K2727DT8k/ITIkEt38u8Hb5A2zyQyLzYLj+cdxPO84Sm3cgTIrahb+dcG/0DuYZy5ppOHn5J/x3u73sDZxLQrLC2FURoztPhZl9jIcyjxUeaxOZ9/O8PXwxdG8o+gd1BuPnvMoboy+EZ7GusN7tqVtw9nvn41XLnoF9599P2yaDYVlhcgpzcHp4tPIKM7A4ezDeOznx3BZ/8vw9ayvYVB1J/RrpCEuPa5SsLxMXogMiURkSCT6h/ZHVOcodPHt4rBVS0R4avNTeHbrs7is/2X4/OrPcSzvGN7f9T6W7V2GrJKsyvOK7hoNgzJg09FNKLOXIcArABN7TcTwLsMxtMtQDOsyDN4mb6QVpCGtIA3b0rbh1T9fxU3RN+H9ae/Xsf1o7lHM/3k+vjjwBbr6dcVVg67CW7FvYVS3Ufju79+hs29nbEjegKkrpmJkt5H4ac5PICJ8efBLfBj3IX5N+RUh3iF44OwHcOfYOx2KQ1F5EcZ/MB7H8o5h3ex1GNltpMPfgoiw8tBK3LX2LpwuPo17xt2DgZ0GIjE7EYk5iTiQeQBHco4AAEZ2G4lL+l4CpRRyS3ORY8nB94e/R2RoJH6Z+0vl/auRhos/vhh/pP6BvbfvdRjXJyIcyTmC17e/jnd2vgMiwrwR83A8/zh+PPIj+gb3xX8m/wcDOg3AzpM7sfPUTuzN2It+If0wbcA0nN/7fKfPi07syVhc8fkVSCtIg5+nH24ecTPuHnd35f1eHZtmQ3pROlLzU5GYk4i9GXux7/Q+7D+9Hz0CeuDh8Q9j+oDpNTyCovIifHHgCzy4/kGU2krx4gUv4q5xdzm8Z13F1Y5mEFG7+owaNYpqc/DgwTrbHFFUdIiKi+NdSlsdi4UoMZFoxw6iAweIiorqptm/fz+dffbZFBkZSSdPniQioldffZXuvPNOIiLauHEjAaCjR48SEZGvr6/DsvTtK1eupIsuuojKreW0/fB26tq9K63dvZbW/LmGtqVso50nd9JLr7xE99xzD2VmZlJ+fj6V28pp1eZV1H9wf9p5ciftOLGD4jPjKackhzRNq3teVgvty9hHsSdiaW/6Xvr5z5/p3A/OpaFvDiUsBPk+70u3rrmVnt/6PPk870N+L/jR4u2Lya7ZHdquaRqdKjxFT258kryf8ybPZz3pwXUP0gtbX6Der/YmLAR1+ncnunXNrbTy4ErKK82rPNZmt1FSThKtTVxLsSdiK/dpmkZr4tfQmCVjCAtBvf7Xi5JykuqUPf3T6RTyUggVlhXW8ysyi7YtIiwEPbbhsRrbM4sz6f+++z/q/J/OhIUgLAQNe2sYDX1zKHk/5125TT+H8z86n+764S56ZvMz9Oofr9KHuz+kG1fdSFgImrd6Hlnt1hr5l9nKaOuxrfTattdo7uq5NOLtETTwjYF079p7aUPSBiqzlTVoNxHR05ufJiwE3bP2nsrfs8BSQPN/mk+ez3qS93PetGDjgsprsPrQajI/Z6a+r/WlFXtXkO/zvjT0zaGUU5JTJ+8dJ3bQZSsuIywEhbwUQs9vfZ7yLfmV++2anWZ8NoMMTxtobeJap7YSEeWW5tJt395Wed28nvWiwYsH04zPZtDrf75Ox/OOOzzuu4TvSC1UNPPLmZXnuXj7YsJC0Dux77hUdmp+Kv3z23+SxzMeFPivQHr5t5fJYrW4dKyrpBem09LdS2vcxy3NiYITNPWTqYSFoIkfTqTknOQm5wUgllyoY9u8km/spzmiUFycQEVFrqUlIrLbiU6cIIqNJdq5k+jkSd6maRplFGVQSXlJjfRDhgyhSZMmVX7PzMykmJgYihoSRdfPuZ76D+hP8YnxZLPbnIqCpml0/wP3U+TASOo7sC+9/v7rlFGUQW8seYMGDR5EA4cMpOix0fT7nt9p9+7dFB0dTQOiBlD/wf3pq9VfkdVupVOFp2hP+h7acWIH7c/YT7mluZUPWXF5McWdiqNdJ3dRgaWgznXcnrad5q6eS+bnzISFoKmfTKWUvBSXr11afhrNXT2X1EJFWAiatHQSfbrv0yY/mJqm0drEtRT4r0CKeS+mRqW7P2M/YSHoqU1PuZTPLWtuISwEfbL3E7JrdloSu4RCXgoh0zMmuu6r62hZ3DI6VXiq8hi7ZqfU/FT6Oflnem3ba3TzNzfT2HfHkt8LfjXEAgtBj//8uEMBbgk0TaN7195LWAhasHEBLd29lLq+3JWwEHTDqhsoLT+tzjG/p/xOoS+FEhaC+i3qV+O8HLHjxI7KSijoxSB6atNTlFOSQ49ueJSwEPTqH6822u6knCQ6lnuMbHaby8e89OtLhIWgZzY/Q4nZieTzvA9dvPziRl/bzOLMGuLWHtE0jd7f9T75v+Dvsig6wlVR6FDho5KSRBBZ4es72Gna/HyeJVpezrMue/TgSUkaaTiaexS5llwEmYPQL6TuLCkiQnZpNvIt+Si2FqPcXl4njYKCQRlgUAYopeBh8ECwdzBCvUPhYfSAzW5DYk4iiq3FiAiKQCefTjWO10hDSn4Kskqy4O/pD4vNAo00RIZGws+zauYVEcc3TxScQJm9DH6efgj1DkVaQRoMyoDI0MhKl9nRdcwtzcXRvKMY0XVEk0ZE6GECR9epKXy2/zNct/I6PDXxKSyctBAAcOPqG/HVwa+Qcm8KQn0cLKJUi3J7OSYvn4ztJ7ZjaOeh2HFyByb2mog3p76JwWHO743qWO1WFJYXoqCsAAqqMobtLjTScPOam/Fh3IcAgHHdx2HRlEUY273+eZ8JWQl45Y9X8Ni5jznsgHXEzpM78dwvz2F1/Gr4evii2FqMW0begncue6dVRsYQEW5cfSOW712OPsF9kFOag/2370f3gLadeNqWnCo8ha5+XZt8/dt88pq7aI4olJYmQdNK4etbZ4J1JVSx2NbJk7w+TY8eVVPdbZoNR3KOoKi8CN4mb1jsFkR3ia4zOqCgrACHsw/D0+gJXw9f+Hr6wtvkDQLBptkqPxppICJopMFis1R2jgZ6BaLMXoYyWxn6BPdBsHf973/ILM5ESn4KTAZTjQq+NhppyC7JxsnCk7BqVphNZkSGRMLLVLVSXXt5n8KcVXOwYt8K/Dr3V5zlfxb6vd4Pd465E/+75H8u55FZnIlx741DUXkRXrnoFcweNrtNhwE2Bptmw7NbnkX/0P64buh1zYozO2Nvxl688MsLIBCWX7HcYR+Cu7DYLDjvo/OwLW0bPr7iY1w/7PpWK/tMRETBAaWlR2G3F8LPb5jD/XY7L1WQm8sLYUVE8AgjjTSU28pxJPcIymxl6B3cGx4GDyRkJ6BvcN86lfaxvGPIKc3B8C7DGzWcrNRaiuzSbGSXZMNOdkSGRLo0SsZis8CojC6Nm7ZrduRZ8hBoDqwziqW9iEK+JR/D3x4OgzJgYsREfLL3EyTdnYQegY2bqV5YVgijwehy56LQ+uSU5uCP1D9waeSl7Ua0/6q0+YzmvyJ8UzkWwbIyXhyrtBQIDydYvdOwPzO3skUPAEZlRP/Q/vD38gcRwWQwIdeSW0MUNNKQW8qhpcaOL/b28Ea4Rzi6+3eHRprLx5tNrs+7MBqMLoVY/soEmgPx8ZUfY+LSiVgatxRzo+c2WhAAuHVYqtAyhHiHYGr/qc4TCi2GO9+89hfEUO+M5qNHuf8gMhJQfjyE0dvkjTCfMJzlfxZ6BvbEoLBBlRWJUgqB5kDkW/IrRQPg0JGd7M2aYamUavUJK+2Nc3qegwUTFsDb5I2Hxz/c1uYIwhlDh/IUWAPrikJREX969ACUuQCp2akIMgehb3DfBl3WYK9gZJdko6i8qHJcd05pDkwGk9NJQELzeWrSU7jv7PvkWgtCC9KhPAV+JWfFWNxqpKfzonMBwWVIzk2G2WRG76DeTmOYAV4BMCgD8iy8rIQerw8yB7m180+oQgRBEFqWDlZz6ZU8odxejqySLGQW5iOvyIJOYTYczU8CEaFfcD+XwjcGgwEBXgE4nn4cixcvRn4Zh5IaEzq69NJLO+xaRYIg/PXoUOEjVdF6J9JwqvAUMksyeUdnIB0ArDye3uzhesdtsDkYB/MOYvGbi3HxdRfDw+ABf8+qDkybzQZT7ddSVeOHH35oyqkIgiC4hQ7mKeinq6HUVgpvkw+QPQAB9t483j24H4LMQY3KMdAciDdeeAPJycmYeu5UvPnCm9iyZQvOPfdcTJs2DYMH82SoGTNmYNSoUYiKisKSJUsqj4+IiEBWVhaOHTuGQYMG4ZZbbkFUVBQuuugilDp42e63336LcePGYcSIEbjwwguRkZEBACgqKsLcuXMxdOhQDBs2DCtXrgQA/Pjjjxg5ciSGDx+OCy64oAnXTBCEjsQZ5yk0sHI2iIKgaWYYjSYUlYdDkQlauRm+vnXfpVodBytnV2IymPDIU48gKSEJn/z0CQZ2GojY32Oxa9cu7N+/H7178wJZH3zwAUJCQlBaWooxY8bgqquuQmhozaGhiYmJ+PTTT/Huu+9i5syZWLlyJWbPnl0jzTnnnINt23hVyffeew///ve/8corr+DZZ59FYGAg9u3bBwDIzc1FZmYmbrnlFmzduhW9e/dGTk6OaxdREIQOyxknCq6gkQYCgewGeHg0LAiuoK9z72X0gq8HL1M8duzYSkEAgEWLFmHVqlUAgNTUVCQmJtYRhd69eyM6OhoAMGrUKBw7dqxOWWlpaZUv2ykvL68sY8OGDfjss88q0wUHB+Pbb7/FhAkTKtOEhLTci0gEQTgzOeNEob4WPQBYrcWwWI5AM/VCYu5xIDsSg/t6wqeZE1r1ETAh3iGVI5Z8favWsN9qVEoIAAAgAElEQVS8eTM2bNiAP/74Az4+Ppg0aRIsFkudfLy8qpacMBqNDsNHd911F+6//35MmzYNmzdvxsKFC5tnvCAIQjU6VJ+CXmFbbFwheyhzswUBAEKDQmEttaKbXzeH+/Pz8xEcHAwfHx/Ex8dj27ZtTS4rPz8f3bvzomAfffRR5fbJkydj8eLFld9zc3MRExODrVu34ujRowAg4SNBEJzSoURBP12LvQwgA7xMLbO4V2hoKM4Zfw6GDRuGhx56qM7+Sy65BDabDYMGDcL8+fMRExPT5LIWLlyIa665BqNGjUKnTlUrpz7xxBPIzc3FkCFDMHz4cGzatAlhYWFYsmQJrrzySgwfPhyzZs1qcrmCIHQMOtSCeHZ7MUpKDuFkmQ+KSoAg62D07esuS9sf7WVBPEEQGo+rC+J1ME9BDx+Vg6xmeLbeKsCCIAjtgg4mCgZoBFg1G2D1FlEQBEGoRYcSBaUMKNPXw7OZ4eH89QOCIAgdig4lCoBCeTVREE9BEAShJh1KFJQyVBMFLxEFQRCEWnQoUQBYFEzkCcAg4SNBEIRadChRUIrDR0rzgocH0JavfPXz82u7wgVBEOrBraKglLpEKZWglDqilJrvYH9PpdQmpdRupdRepdSl7rRHI41FQfoTBEEQHOI2UVBKGQEsBjAFwGAA1ymlBtdK9gSAL4hoBIBrAbzpLnsAoMxWBgDQylt2OOr8+fNrLDGxcOFCvPzyyygqKsIFF1yAkSNHYujQofjmm2+c5lXfEtuOlsCub7lsQRCEpuLOBfHGAjhCRMkAoJT6DMB0AAerpSEA+vsUAwGcbG6h9/54L+LSHa+dbdNsKLWVAlYfeJqM8PrFtTyju0bj1UvqX2lv1qxZuPfee3HHHXcAAL744gusW7cOZrMZq1atQkBAALKyshATE4Np06Y1+JpPR0tsa5rmcAlsR8tlC4IgNAd3ikJ3AKnVvqcBGFcrzUIA65VSdwHwBXCho4yUUrcCuBUAevbs2WSDNKoYeqQZWrQ/YcSIETh9+jROnjyJzMxMBAcHo0ePHrBarXjsscewdetWGAwGnDhxAhkZGejatWu9eTlaYjszM9PhEtiOlssWBEFoDm29dPZ1AJYS0StKqbMBLFdKDSHSa2+GiJYAWALw2kcNZdhQiz45NxkFljzYToxEnz5AS75e4JprrsFXX32F9PT0yoXnPvnkE2RmZmLnzp3w8PBARESEwyWzdVxdYlsQBMFduLOj+QSAHtW+h1dsq84/AHwBAET0BwAzgE5wE6XWUpgqdLClO5pnzZqFzz77DF999RWuueYaALzMdefOneHh4YFNmzbh+PHjDeZR3xLb9S2B7Wi5bEEQhObgTlHYASBSKdVbKeUJ7kheUytNCoALAEApNQgsCpnuMIaIYLFZYNRYDVp6jkJUVBQKCwvRvXt3dOvG71W4/vrrERsbi6FDh2LZsmUYOHBgg3nUt8R2fUtgO1ouWxAEoTm4densiiGmrwIwAviAiJ5XSj0DIJaI1lSMRnoXgB+40/lhIlrfUJ5NXTrbcioV+ykD/rZOKDzdCyNHqma/hvNMQ5bOFoQzF1eXznZrnwIR/QDgh1rbFlT7/yCA8e60QceiNJYdqzdMJhsMBpnOLAiCUJsO01a2KBsAnqNgMlnb2BpBEIS/JmeMKDgLgwWZ/NEnF7BbvUQUHNDe3sAnCIJ7OCNEwWw2Izs7u8GKzWzyQkgpYLWZ4OFR3orW/fUhImRnZ8NsNre1KYIgtDFtPU+hRQgPD0daWhoyMxsYuFRWBi0rGxk4jOKSPJSXZ7Wege0As9mM8PDwtjZDEIQ25owQBQ8Pj8rZvvWybx/ip9yDKYjH44/PxnPPfdw6xgmCILQjzojwkUv4+yMN3BIOC0uBptna2CBBEIS/Hh1UFNKgaaVtbJAgCMJfj44jCn5+SK1YdaNTp5PQNFlTSBAEoTZnRJ+CS3h5Ic3QE5288uDpWSaiIAiC4ICO4ykASDP2QndvHqEk4SNBEIS6dCxRQDjCzacBQDwFQRAEB3QsUdDOQnePDADiKQiCIDiiw4hCSQmQYw9CuOEUAPEUBEEQHNFhROFExet9eqg0ACIKgiAIjugwopDGWoBwO7822m6X8JEgCEJtOpwo9Cg/BkA8BUEQBEd0GFFIZQcB4WX8nmMRBUEQhLp0GFG4805gz9xX4VPEq6PK6CNBEIS6dJgZzQEBwLC+xUB5OZRVPAVBEARHdBhPAQDg7w8AMJaKpyAIguCIjiUKfn4AAGOJeAqCIAiO6FiiUOEpeFg8RRQEQRAc0DFFocxLwkeCIAgO6FiiUBE+MpV6iKcgCILggI4lChWegsniITOaBUEQHNBBRcEonoIgCIIDOpYo6OGjEhEFQRAER3QsUdA9hVKDdDQLgiA4wK2ioJS6RCmVoJQ6opSaX0+amUqpg0qpA0qpFe60B2YzYDTCWKrEUxAEQXCA25a5UEoZASwGMBlAGoAdSqk1RHSwWppIAI8CGE9EuUqpzu6yp6JAwM8PplKZvCYIguAId3oKYwEcIaJkIioH8BmA6bXS3AJgMRHlAgARnXajPYy/f8WMZgkfCYIg1MadotAdQGq172kV26rTH0B/pdRvSqltSqlL3GgP4+8PY4kmnoIgCIID2nqVVBOASACTAIQD2KqUGkpEedUTKaVuBXArAPTs2bN5Jfr5wVBaCE0rb14+giAIZyDu9BROAOhR7Xt4xbbqpAFYQ0RWIjoK4DBYJGpAREuIaDQRjQ4LC2ueVf7+MBbbxVMQBEFwgDtFYQeASKVUb6WUJ4BrAayplWY12EuAUqoTOJyU7EabAH9/GEpsIgqCIAgOcJsoEJENwJ0A1gE4BOALIjqglHpGKTWtItk6ANlKqYMANgF4iIiy3WUTAA4fVYgCEbm1KEEQhPaGW/sUiOgHAD/U2rag2v8E4P6KT+vg7w9DMfcnaFoZjEZzqxUtCILwV8clT0EpdY9SKkAx7yuldimlLnK3cW7B3x+qqAyADEsVBEGojavho3lEVADgIgDBAOYAeNFtVrkTPz8YymxQdpnAJgiCUBtXRUFV/L0UwHIiOlBtW/uixnuaRRQEQRCq46oo7FRKrQeLwjqllD8AzX1muRFdFGRWsyAIQh1c7Wj+B4BoAMlEVKKUCgEw131muZGK5bPFUxAEQaiLq57C2QASiChPKTUbwBMA8t1nlhup4SmIKAiCIFTHVVF4C0CJUmo4gAcAJAFY5jar3ImEjwRBEOrFVVGwVcwpmA7gDSJaDMDffWa5Ef3taxI+EgRBqIOrfQqFSqlHwUNRz1VKGQB4uM8sN1Jt9JHdLp6CIAhCdVz1FGYBKAPPV0gHL273H7dZ5U6kT0EQBKFeXBKFCiH4BECgUuoyABYiap99CvroIxEFQRCEOri6zMVMANsBXANgJoA/lVJXu9Mwt+HrC1KqYkiqhI8EQRCq42qfwuMAxuivy1RKhQHYAOArdxnmNire02wsLRRPQRAEoRau9ikYar0/ObsRx/718PODScJHgiAIdXDVU/hRKbUOwKcV32eh1pLY7Qnl7w9jabqEjwRBEGrhkigQ0UNKqasAjK/YtISIVrnPLDfj7w9TqUE8BUEQhFq4/JIdIloJYKUbbWk9/P1hzDWIpyAIglCLBkVBKVUIwNE7KxX4xWkBbrHK3fj5wXhS+hQEQRBq06AoEFH7XMrCGf7+0tEsCILggPY7gqg5+PvDWEKyzIUgCEItOqYo+PnBUKqJpyAIglCLjikK/v4wlmrQbCVtbYkgCMJfig4rCgCAIhEFQRCE6nRMUahYFE8ViygIgiBUp2OKQoWnoMRTEARBqEEHFwXpaBYEQahOxxSFivCRobgFReGbb4CsrJbLTxAEoQ3omKJQ2dFcDCKt+fnl5gIzZgDvvtv8vARBENoQt4qCUuoSpVSCUuqIUmp+A+muUkqRUmq0O+2ppEIUDMU2lJefan5+pyrySEtrfl6CIAhtiNtEQSllBLAYwBQAgwFcp5Qa7CCdP4B7APzpLlvqUO2VnCUlic3PLz2d/5482fy8BEEQ2hB3egpjARwhomQiKgfwGYDpDtI9C+AlAK3X61vhKRgtQGnpkebnl5HBf0+1gNchCILQhrhTFLoDSK32Pa1iWyVKqZEAehDR9260oy6+vgAAU4kBpaXiKQiCIOi0WUezUsoA4L8AHnAh7a1KqVilVGxmZmbzCzcaAR8feFkDW8ZT0EUhPR3QWqDjWhAEoY1wpyicANCj2vfwim06/gCGANislDoGIAbAGkedzUS0hIhGE9HosLCwlrHO3x+e5f4t6ylYrUB2dvPzEwRBaCPcKQo7AEQqpXorpTwBXAtgjb6TiPKJqBMRRRBRBIBtAKYRUawbbarC3x+eFm+Ulh5p/rBUXRQA6VcQBKFd4zZRICIbgDsBrANwCMAXRHRAKfWMUmqau8p1GT8/mCwe0LTS5g9LTU8HOnXi/6VfQRCEdoxb+xSI6Aci6k9EfYno+YptC4hojYO0k1rNSwD47WsWI4AWGJaang6MHMn/i6fQeuzaBVx8MWCR5UoEoaXomDOaAX6nQrEdQDOHpdpsQGYmEB3N38VTaD1++AFYvx5ISmprSwThjKHjioKfH1RxOZTdBMPX3wETJwKzZzc+n8xMgAiIiACCg0UUWhNdDMQ7E4QWw9TWBrQZ/v5QqamImQ14pX8DeHoCv/8OvPceYDa7no8+ca1rV+Css6SCak2Sk/mvXHNBaDE6rqcQHg6UlsLaIxCJ/+kFfPIJh4L27GlcPvrIo65dgW7dxFNoTcRTOPMpKgJ+/rmtrehQdFxReOQR4NgxpK+4AafGngaNHcvbYxvZ111dFMRTaD0sFuBExbQXueZnLm+/DVx4YZVHLridjisK3t5Ar17w9u7Hw1I7G4AuXYAdOxqXjy4KXbqwp3DqFPcxCO7l6NGq/6vPExHOLA4c4L+JLTDJVHCJjisKFXh7RwIASi1JwOjRTROFgADAx4c9BZnV3Dro/Qne3uIpnMkkJPBfGWHWaogoePcDUDFXYcwY4NAhjmO6Sno6ewkAewqA9Cu0BnolMXasiMKZjC4KeiNAcDsdXhTM5p5QyoPnKowZw6GfXbtczyA9nfsTAPYUAKmkWoPkZF7tdvhwud5nKllZQE4O/y+eQqvR4UVBKSPM5j68MN7oirX4GhNCciQK4im4n6QkoG9f9s4KC4Hi4sbnMXMmcMstLW/bmcbGjcDHH7d+ubqX4OEhotCKdHhRAAAfn0gWhc6dgZ49my4KevhIWq7uJzkZ6NOnedd840bgm29kYEBDlJUBN9wA3Hdf65cdH89/J0yQ8FErIqIA7lfg1VKJQ0iuDku1WID8/CpRMJtlVnNrQMSVhO4pAI0Xhexs/mRmysiWhvjwQx76m5UF5OW1btkJCTyp9PzzgdOn2SMU3I6IAngEEq+WepJDSElJVbHMhqg+m1lHJrC5n1OnWJCrewqNHZaqhyYA4LffWs621uKDD6qGa7pCYwZP6JSXA//6F4/wAlpfPBMSgH79gEgeISjeQusgooCqEUiVnc2Aa95C9YlrOjKBzf3olUNzwke6KBiN7U8UioqAm28GnnjCtfS7dgFBQY2frb98OZCSAjzzDH9vC1EYMIA9QkD6FVoJEQVUzVUoKUkERo3ijY0RBX1IKsCiIJ6Ce9Erh759gZAQwGRqmih4eACTJ7c/Udi3j0NoP/7oWgf71q2A3Q788YfrZdhswAsv8PNwxx2AUq0rClYr/84DB1aJgngKrYKIAgAvrx5Vw1KDgoD+/V3rbHbkKcisZveTnAwYDECvXvy3a9emiUK/ftyJGR/fviYcxsXxX4uFhcEZu3fz3/37XS9jxQq+zk8+yeGjHj1aVxSOHmVhGjAACAxk8W+Kp/DMM8D777e8fWcwIgoADAZT1bBUwPWZzboodO5ctU1mNbufpCSupDw9+bsuxI1BD02MH8/ff/+9ZW10J3v2cOMlNBT4+mvn6XURcbUPwm4Hnn+e54BMq3hJYv/+wOHDTbO3KejhvQED+G/fvo0XhbIy7hP5739b1ra2oin9Qk1ARKECH59IlJQc4i9jxvCIC2cVjf4aTg+Pqm0yLNX96MNRdRorCjYbcOQIVzhjxvDv9+uvLW+nu9izhyvs6dOB777jyq8+ysqAgwf5fz3s5Iwvv2QBeOIJDhsB3NmbmNh6HrA+HLU5orBtG3tTBw/yKLP2TG4uNz7fecftRYkoVBAUNAklJYdQUtKIzubqcxR0ZAKb+0lKap4oHD3K3tyAARwaGTWqaf0KBQWNP6a52O1cuQ8fDlx5JduwcWP96Q8cYBEcP56919OnnZfx7rtcCV95ZdW2yEgektpaHnBCAhAWxkO8Abbn+HE+F1epfl3ak+g74ptvgNJSYMQItxclolBBWNjVAIDMzC/51ZoGg/MQUkZGXVEQT8G9FBVxxaZ3PgJ8zbOyuKJ3hdqhifHjuQHQUIu7Nj//zOGbt95y/ZiWICmJO5eHDwcuuADw9284hKSHjvS3CjoLIZ08CWzaxOkN1aoHfVhoa/UrJCRwJ7NOnz4siCkpruexcSNfJ7OZO9vbM19+yX1oeoPVjYgoVGA290JAQAwyM7/gNXWGDOG3sL3xRv2TZhx5CrIonnvRl8yu7SkArq+570gUysqAnTtdO95iAf75T261Pvggh6JaC31YaXQ0V3ZTpwKrV3OF6Yi4OMDPr6pvwFln82efcYjo73+vub0tREH/fYDGD0stLubw0SWXADEx7VsU8vKAn34Crr66KpznRkQUqhEWNhNFRXEoKTkMvPkmL3lx111A9+7A3XfXbP0TORYFb292ecVTcA/Vh6Pq6L+Bq9c8IYH7gkJD+fvf/sZ/XQ0hvfACC8HSpdwfcdNN9VfKLc2ePTy3YvBg/n7llewl1Rce2b2bW8vduvH5OhOFFSt4oEX//jW39+7NnkNriEJuLvcBOBIFV4el/vori/b55/MIs7i4tgn3tQRr1rAXfM01rVKciEI1aoSQxo/nlsaff3KH3ttvV7ngAHsPpaU15yjoyKxm91F94ppOY0N2tVuhXbrw8FRXRCE+HnjxRb4XbrwRWLSIj3vtNdfKbi579nBYRX+P+JQpgJeX4xCSpnH66GhuYQ4Z0nD4KCGBvaXaXgLAI70iIponCkTAsmUsUtu2NWwHUPM3OussPk9XPYWNG1mwx49nUdC09jXCrDpffsmj7fS3Q7oZEYVqmM09EBAwHqdPf1G1cexYntm5cCHfaPqwPEdzFHSaM4FN03hc9dNPN+14Z+zezRWqK0MZW4KSksbF6p2RlMTj1vUOSKD5ogBw5fH77w2PriECbruNwzGvvMLb5szh0Mxjj1WNmHEn+sgjHT8/4OKL+fesbfvRo9x4iY7m70OGsKdQ3zmuWMHice21jvf37990UTh0iFvtN94I7N3Lnnh9OBIFg4G9FVdFYdMmDhv5+vJfk6l9hpDy84H161stdASIKNShc+eZKC7ei+LiWg/4vHl8Yy1Zwt8bEoWmjJsH+IGdMIGXMFi40PVx4QsWcP+HM9LT2es5ehT4v//jG87dTJ7csm6vvhBe9QekSxf+7so1z8/nvgdHouBscbylS7li+fe/q+amKMXDBH19ucJrzOiYxpKTA6Sm1hQFgENIaWl1R8vpk9b0EStRURxCSUurmzcR8MknXHHrIlubyEi+Jxs7LPW559jmPXv4+bnhBh5NU19jISGBn7XevWtud3VYal4eezznn8/ffX15hFl7FIU1a3gNqlYKHQEiCnUIC7sKgOIQUnW6duUKdelS7mh05ik0ZlZzQQHw6KP88MbHc6UDAKtWOT82JYUfuieeaLhCsliAK67g+PO77/IIniefdM2+ppKezq3vb7/l1mFLUHs4KsBhgk6dXBMFR61QoGoSW30hpIwM4KGHgHPO4QZCdbp25TDS9u38ELuL6p3M1bn8cg7vfPRRze1xcdz/EBXF34cM4b+O+hV27OBre/319ZcfGcmjv1zt0NfLevJJtjE+nt9fce21fM+vX+/4mPh4DudVn/8DsCgkJzt/rrZuZY9bFwWAG1s7dnDItyVx97yNr74CwsOBcePcW041RBRq4eXVHYGB5+D06c/r7rztNh6n/fXXzj2F8nLnK63u3QvcfjuLyIsvcigiPp4rn9GjXQvxfPAB35gZGfU/ZET8MG7bxqGwm2/mchcvrmpNuoMNG/ivwdAys0rtduDYsbqiAPA1d2Wl1PpEYeBA7ohdvrxupzERjzYqKuKWrsHBYzNrFt8Ly5e7dCrYsYOHszamUtFFobanEBICXHcdN1iqL28dFwcMGlTV/6CLg6N+hU8+4Zh99bkJtWnKCKRPP+Xr9dZbVd7VBRfwjOwvv3R8jKPwHsC/e2EhN2waYuNGHvBRvSKdMIGfye3bXbfdGV9/zefkrv7DggJg3ToOHTm659wFEbWrz6hRo8jdpKa+Tps2gYqK9tfcYbcT9elDNGEC0aOPEplMvK02X3xBBBDt3cvf8/OJtmwh+vhjohdfJLrzTqKzz+Y0ZjPRTTcR7dhRM48XXuD9qan1G2q1EoWHE51/PlFoKNHMmY7Tvfgi5/XMM1XbcnKIOncmiolxfA4twZw5RJ068fl6eBClpTUvv2PH+DzeeafuvosvJhozxnkejz9OZDQSlZXV3bdkCef/+OM1ty9bxttffrnhvO+/n88zK6vhdMnJRCEhnOeiRc5t1rnpJqIuXRzv27Wrro1nncW/QXW6dSO68caa26xWvheuuqrh8o8c4TLef981ezWNn5fJk+vumzuXKCCAyGKpud1mI/L0JHr44brHfPstl//HHw2XO3Ro3TJzcoiUqvkMlJcT/etfRIcOuXY+tZk+ne156KGmHe+Mjz/m/H/7rUWyAxBLLtSxbq3AAVwCIAHAEQDzHey/H8BBAHsB/Aygl7M8W0MULJaTtGmTouTkp+ru1CvYs88m6t7dcQa//sppJk8miorim5HbhPwJDCQaMYLolVeIsrMd5xEfz2lff71+Q/WH5OuvueL18iLKza2ZZt8+IoOBaNYsfkir89FHfPy779ZfRlPRNK7ArruOK0GDwfGD3hg2bGB7f/qp7r4bb2SBdMbVVxNFRta//x//4DJWr+bvKSn8e51zDldYDbF7Nx+7eHH9aYqLiaKjiYKCiC64gAXq55+d203E98xFF9W/f+JEol69uJLPyGBbXnmlZprJk4lqP0M//shpV65suHyrlRtC8+e7Zu/27ZzvBx/U3ffDD7xvzZqa2xsSnoMHed/HH9dfpn7e//pX3X3DhhFdeGHVuVxzDacdP77us+GMkhIib2/+/fz96z53LcH06VzHtFCjrc1FAYARQBKAPgA8AewBMLhWmvMA+FT8fzuAz53l2xqiQES0e/f59Ntv3clmK625IyODW4MA0ciRjg/OyOAKOiSEaMoUoqef5ocgPp6osNB1IwYPJjrvvPr3X345Udeu3OLZscNxK3rKFK6AHImPphGdey7befy44/2LF7MNeXmu201EtGcP2/Phh/x95kxuGebnNy6f6ugt8Zycuvvmz6/fc6vO0KFEl11W//7SUqLRo9nW+HiuRH18uLJyhqZx/jEx9e+fM4cbCd9/z9di0CD28pKTG867vLz+FrTOqlV8zb/6imj9ev6/tuDcdx9XZvp10jQWk86d+dydMWCAc49CR/+9HFWYZWVEwcFEs2fX3K43VH79te4xJSV1Pd7afP45p/nzz7r77ryTyNeXz/O66zjdhRfy37VrXTsnHb1B9tJL9YtQc9i/n3/ve+5psSz/CqJwNoB11b4/CuDRBtKPAPCbs3xbSxRycjbSpk2glJT/1t05axZfuksvrT+DkpLGtz5q8/jj3MLOzKy7LzWV9z36KH/XNK5gxo+vSqO3rBsKe+zfzy2dkBCuqHTKy4n++c8q7+bFFxtn+3/+w8fpISO91fhfB9fTFex2bjVdfrnj/a+9xvmfPl1/HjYbi/WDDzZc1vHjHPYKCuI833zTdTv//W8+JiGh7r7XX+d9Tz9dte3wYS5n2DCioqL68927l4/95JP609hsRL17s1ej21G7MfD++7xdFzndS3jjDdfO77LL2FZn6L/XtGn1p9FDSLoY7dvH9+KIEY7De0ScZ+3wV3VuvpnzsFrr7tPDuuPHV1XoZWVEERHsPTXmedXLKSvjhkOXLq6Jqk5xMQvg5s1195WUcIShc2eiU6dcz9MJfwVRuBrAe9W+zwHwRgPp3wDwhLN8W0sUiIji4i6kX3/tRFZrQc0dGzfypZs3z70G7NxJ9brfTz/N+5KSqrbpoa3ERH4oR4zgG7523LY2CQlEw4fzsY88QpSezt6B/n3yZL5BS0pct10PnVVnwgSinj1ZcBrL1q0NV4r6A79nT/15JCeTy+GyDRtYdCdPblxlkZbGnsCTT9bcvmkTezKXX17Xm/nxRy7rmmvqL2v5crZ9/37H+3X+9z9OFxXF17o227ZRZXjMbudQVu/e9VfCtbnvPvacnHlkW7ZwOStW1J9m7VpO8803LOYREez5NtSPNmECi54j4uLYM6lPNE6dqmrkPPdc1fYPP+Rtq1Y1fE46djuLgN6Hpze+lixxfmxiIntQwcF8jMlE9NlnNdPojbEff3TNHhdpV6IAYDaAbQC86tl/K4BYALE9Hd3obiI//0/atAl09Ggtd1XT2FtwFoNtLprGMeLa4Q6bjR/42p1pqalcIS1YUNU52tBDWZ2SEqLbbuNjPD3589FHvG/TJnIaK6+dl5cXVyDV0V3u119vvBf1f//HYY/6wm+//OL8QdIroa1bXStz//6GW+/1MXkyV3B6xfnbb0R+fkQDB9Yfe9bDEPV5dQ8+yNfUUQu4Onl5XBbguJVeUMD7nn+e6NNPyWmMvjZvvklOB0AQEd1+O4tHQ9evvJwrx9xM4CsAABtuSURBVKuv5orebHYc9qnO3LncQKndsLBY2IPp2rXhjv5bb2UvtjpWK1H//kRDhjjvNyKqElb9umkaexqRkY6PT05msZ44sUoIZs0iWreORU6pKkH56itO48ybbQJ/BVFwKXwE4EIAhwB0diXf1vQUiIj27buCtm4NoPJyJyNK3MW993IFXVDNW9E76b78sm76yZNZSHr04Bu1sZ1UK1awe119xIOmccd6r16utfLXrSOHcVq7nePtAI+Y2rnTNZusVqKwMG5J14feQbl0af1pXn2V02RkuFZuU9EFeetWruQCArjCOHGi/mM0jWP1RiOLcG3OO6/+Pqza3H03l79ggeP9ERFcEfftyxVpY+6Rn37ivDdurD+N1crht1mznOc3b15V6712i9kRukd42WU1wzWPPsrbv/vOeR6O0AXSlUbUY4/x71Q9NKfb9dVX3Cj66Sfu5xo2rOr8hgzh/pCTJ6uOKy7mfj+AzyEoiEfRueq5NYK/giiYACQD6F2tozmqVpoRFZ3Rka7m29qiUFS0nzZtUnTkSDNHzjQVPWzy2Wfs/r70EnsJnTs7vnH0MAPguHJpKnorf9ky52kfeICFrLi47r6yMh6GGRrK+c2ezaNKGkLvNG3IMysqIqcdfrffzg9dc/t6nFFYyK3k88/n8vr0cd6yJmLhHziQBVBPn5nJYYrGtB6Tkji84aizloho6tSqEXGNrUQbGhaso/dTuBKO+flnTvvUU67b8NZbbP/55/O1/v13Dr/94x+u51Ebu50HCURGOm/4DBlCNGlSzW02G4tscDB7dLpHMGECjwBraKBCWVnVSCh/f9cGNTSBNhcFtgGXAjhcUfE/XrHtGQDTKv7fACADQFzFZ42zPFtbFIiIDh6cQ1u2eJPF0kBLz13YbCwAXbpw60TvKKtvGGNREQ+hrK9DtqnoI2sGDXJthM8FFzScJi+PW1JmM5/T3/7GfSeOwkPz5vHD4qwjz9+fW8mOiI3linrq1IbzaCnmzOHz6tWLK1JXOXiQwz8xMdzq7NKF4+TPP+88dOQqjzzCtp1zTuMF0m533ll/0018Dzrry9JJSWm8HcuX8/MQE8MVea9ezRvZRsT9LADn27Urt/KnTq3ZT5WUxGn+97+6x3/1FdG4cdxn8P33jRtpaLNxP8f69c07hwb4S4iCOz5tIQolJUm0ebOJEhJub/WyiYjd1bPO4kkyrky0SUqqGW5qKVascN4CPHmSKkd2uEJGBsd4Bw6saim9917VfouFW9s33OA8r/79HYeYjh3jhzwigjvRW4M9e1iYnQ01dYQeigB4AEBcXMvatnIlt7R/+aVpx0dFcQe1PjlTJy2NY/ZGo/sHYRDx/BxPz5bzijWNh7Q+/jjRLbfwPIHOnTn8pzfC9I58N7Xm3YmIQguTkHA7bd5sopKSJOeJz1SsVg6FDBjArfqkpPonxO3e3bi8NY3DHeefT5XxVbudJzcB3I/ijIkT645MycvjSiwwkOjAgcbZ1Ja8/jp7B26ILZPd7nheiqssXlwVIjnnHA4pPvQQe30eHuytuWMylyN++40rcneRmsrhIg8P7lg+77y6o+raCSIKLYzFcoK2bDHTwYNznCc+k1mzhjsR9ZZseDiHimJi+OEJCuLWVVNnYZaXcysN4I7Kq67iORSudHBfey3HdavndeGFHNt1ddaw4BpZWTxSql8//q2UYm/u6NG2tqzlyc3lPgT9PPW5Qe0MV0XB1MCySEI1vLzOQvfudyE19WX07PkIfH2j2tqktuHyy3nxvUOHgC1b+JOSwu8K7taNV3qdOrXpC3h5ePBS1P36AY88wttuvbXuipmO6NaNX+5+9tm8DPbp07yA2ocf1lwxU2g+oaHAAw8A993HK8uGhdV8p/KZRFAQ8OOP/Ia9zz8HrrqqrS1yK4oFpP0wevRoiq29bnwrYbVmY9u2PggOvgBDhrTSS2o6Ml9+CTz8MC8fPGqU8/QbNvAS5EFBXEmFhfGS2DNnut9W4cxH03hF1PDwtrakSSildhLRaKfpRBQax7Fjz+LYsQUYOXI7AgLGtJkdgiAIjcFVUZD3KTSS8PB74eHRCUePPt7WpgiCILQ4IgqNxGTyR8+ejyE39yfk5m5sa3MEQRBaFBGFJnDWWbfDbI5AfPxclJdntrU5giAILYaIQhMwGs0YPPhLlJdn4ODBWdA0N76sXRAEoRURUWgiAQGjMWDAEuTlbUJy8iNtbY4gCEKLIPMUmkHXrjegsDAWaWn/hb//KHTp8ve2NkkQBKFZiKfQTPr2fQWBgROQkHAz8vK2tLU5giAIzUJEoZkYDB6IivoSXl7dERd3Ho4cuQ92e0lbmyUIgtAkRBRaAE/Pzhg1ajfOOut2pKW9itjY4cjL+7WtzRIEQWg0IgothMnkh/79F2P48I0gsiMubgKSkx+VkUmCILQrRBRamODg8zB69F5063YzUlJeRFzcJFgsqW1tliAIgkuIKLgBk8kPAwYswaBBn6K4eC9iY6ORlfVtW5slCILgFBEFN9Kly7UYNWoXzOYI7N8/DYmJ90LTytraLEEQhHoRUXAzPj79MHLk7+je/W6cOPEadu06GyUlh9vaLEEQBIeIKLQCBoMXIiNfw5Aha2CxpCA2diROnVqK9rZsuSAIZz4iCq1Ip06XY8yYPfD3H42EhLnYuXMUMjNXV4oDkYbc3I04cOBaxMaORGLiPcjK+g42W2EbWy4IQkdBXrLTBhDZkZ6+HCkpz6O09Ah8fYcjNPQyZGZ+jtLSIzCZguHnNxwFBdugaRYoZUKnTldgwIAPYDL5tbX5giC0Q1x9yY6sfdQGKGVEt243oUuX2Th9+lMcP/4cUlKeR2DgBERELESnTlfBaDTDbregoOB3ZGd/j7S0V2GxpGDYsB/g4RHS1qcgCMIZingKfwGI7LBac+DpGVZvmszMVTh48Fr4+PTHsGHr4eXVrRUtrMJiOY7CwliEhZ3ZLy8XhDMNeR1nO0IpY4OCAABhYVdg2LAfUFp6FLt3n4P8/N9hsaTCZisEEaG09ChOnVqK+Pi52L59EJKSHgaR1qJ2Wq152LNnMg4cuBoZGZ82+ngiwvHjLyAnZ32L2iUIQssh4aN2RHDwBYiO3vj/7d15cBzVncDx729mNNJcuq3Dso0l21g+MD4I4IUkHAkYL0suEmwSQgWykIpzsHHVEjY3uRfvEnKSLCQQwhJiAgQoKiQG4k0IwdhY+JBtsLGETkuyNJrRMVfP2z+6PciSLYTAnsH+faqmNN39uuc33T36Tb83/R7btl3C1q3njFjiAuwE4PGU4ffX09JyC/F4K/X1d+FyeTMlE4keOjvvRCSfgoKZFBTMxOerxeMpGve1jUmze/fHicX24/cv4KWXricUegd+/+wJx9/cfDNNTV/H7Q6ybNlm/P65b+TtK6WOA00KbzOFhWfyjndso7//WVKpcObh9VZRXHwegcB8QGhp+U9eeeWLpFJ9LFjwACIeWlt/RHPzt7Cs/jHbDQROp7T0YkpLL6ao6BxcrvzDljc3f5uDBx9l9uwfUl7+PjZvXkxj4yqWLn1mTNkj6eq6n6Ymu70kHP4LO3d+hKVL/4Hb7cuUsawh2tt/Rnn5B/H5aie0P5LJMNHoZqLRTUQimwDDqaf+lPz8mgmtP9Lw8Cu4XAXk5099w+sCpFIRPJ7CSa2rVK7QNoUTWEfHnezZcx3B4BJSqV5isf2Ulq5k1qxb8HoricWaiMWaGBraTV/fBvr7n8GYJG53kPLyD1JZeRUlJefT2/sE27dfSmXlR6mv/zUiQnf3w+zc+QGmTbuB2bNvzbxmPN4OmMP+KUcim2hoeDeh0BmcfvoG+vqeYvv2lVRXX8fcuT8H7H/IO3Z8kMHBF/F6q1i06AmCwUVHfW/pdJx9+26kre2HgH0O+3xzSSTa8HiKOe20xwkGT5vQfrKsIfbv/zKtrT9AxE1FxSqmTVtLKLR4Quun0wn27VtLW9uPmTbtBurqvn/Y1ZlSuWCibQqaFE5wdgP1avz+Ocya9V+Ull501LKpVJRw+Gl6eh6hu3s9lhXB663Bsgbw+WpZsuQZ3G5/pvzLL3+WtrYfU1v7beLxNvr6nmR4eA8AweBiysouo6joHHbvvhqXy8fSpc9l2k5eeeUmXn31e8ybdy8eTym7dtmj1tXVfZfm5m+RSkU57bTHKC4+d0ycg4O72bVrNQMDDVRXX8+UKZcTCp1BXl4x0WgD27f/M5Y1wMKFD1JScuG4+ycc3sju3dcSi+2juvp63G4f7e3/Qzo9SHHxhUyfvpbS0hWIyBHXj8VaaWz8MJHIPygqejf9/RsJhc5g/vz78fnqjvq6iUQP/f0bicfbSSTaicfbycsrp6ZmzbjrjTY8vI/Ozrvo6XmEkpILOOWUr5GXV3zU8sYYYrH9JBKdFBaejcj4zYqWNUhLyzoikefJz6/G660hP38qRUXnOlelx1cqFcGYJHl5ZW/J9ixrGJfLi4j7LdneG5FIHEAk77j9mjAnkoKIrABuA9zAHcaY741ang/8GlgGHASuMMY0jbdNTQpvXDLZi8dT9IZOfMsa5uDBRzlw4B6Ghl5i0aI/jqnSsawYW7cuZ2CgAZcrQHHxuygpuRBj0hw8+Cj9/c8AadzuQpYu/TuBwILMuul0ioaG8xgY2EI6HScQWMTChQ/i89URi73Kiy9eRDzezPz56yktXYFlRbGsCL29f2Lv3htwuXzU199FefmlY2KPxVrYtu0Shof3MGvWOioqVuP1Vhz22uHw03R23k1X170UFNQxd+4dlJSc7+yvMB0dv6C19YckEm34/QuYPn0tlZVXZqrK0ukk4fDT7Nr1MdLpYebO/RUVFZfT3f0Qe/ZcgzFpTj3Vrgpzuwsyr51IHKClZR1tbT8lnbYHYxLJw+utIpHoxBiLKVM+xPTpayksPGvMe0ulogwNNRKNbqWr67f0928EXIRCZxCNPk9eXhm1td+muvpaRNzE4x1EIs8SiTxHNLqZgYEXSKXCAPj98zjllC8xZcoVuFyH1yQbY+jq+l/27bvR2QfzSSYPkkx2YV+ZuaipWUNt7TeP2h5ljEVv75/p7v4dbneIQGCh81hw1Gq2ZDLM4OAOkskeUqleksleEol2BgcbGRpqJB5vQcRDdfX1zJz5FbzeyiNuByAabaC9/XZEPFRWfozCwrMyyX1wcBctLes4cOA3iHgIBk8nGFxCKLSU0tJLXrcKMZnspaXlFnp6/oDbHSIvrxSPpxSfr46qqmvGrf5MJg/S3Pwt2tp+goiXGTNuZPr0tYd94ToWsp4UxP4P9BLwXqAVeB5YbYxpHFHm08AiY8ynRGQV8AFjzBXjbVeTQm5JJHoYHt5LKLR0TJVJItFDb+8f8fvrKSwcey7GYq1s3XouxcXv4tRTbz/sQ5FIdLN9+0qi0bHHurj4fObNu2fcdoNkMszOnR8iHH4KsNtMSkregzEJurp+RzJ5ALe7kOrqf6W29hu43YEx20inE3R13U9LyzoGB7eRlzcFj6eYZLL7sH+sCxY8SCBQn1lveLiJxsZVRKPPIeIlFFpKYeFyjEnR0XEH6XScysormTp1DT7fLPLyyhBxEY+30dr6I9rbb8ey+vF6q3C7g7hcftzuAIlEB7FYU+Z1fL7ZVFV9gsrKj1NQMI1otIG9ez9Pf///4ffXk07HMuVF8ggEFhEKLSMUWobLle+8rx34fLOprr4el6sAYxKk03EOHnyUSORZgsFlzJlzG0VF5zj7JEk83kpLyy20t99OXl4Fs2bdQkXFR7CsAVKpCKlULz09D9PZeRfxeCtudxHGpEinBzOxe701+P31+P315OdPY2iokUhkU+ZKcySXqwC/fx6BwAL8/vnEYk10dNyJy1XA9OlfYOrUTzttU25EhL6+DbS2/oBw+C+4XAHAIp2O4fPNoaJiNQMDL3Dw4GO4XAVUVn4cl6uAgYGtDAxsxbIGAKG4+N1UVKxmypQPHXZVkkpFaW29jZaWdVhWhJKSixARJ2H2Ovs7TVnZpdTUfC5zpZpOx7GsKJ2ddzvtelGqqj5BKhWmp+f3eL011NV9l7KySzHGcmK29/Xw8N7Mo7r6GkpKLjjqeT+eXEgKy4GvG2MudqZvAjDGfHdEmSecMs+KiAfoBKaYcYLSpHBiMcYctWomlYrS1vZjp52jEI8nRF5eJWVll0zoqseYNNHoFvr6NjhtJn8DhLKyS6msvJLS0pWHfYsfL8a+vg10dNwJGLzeCvLypuD1TqWiYtUR7zJPp5P09j5Of//fiUT+TjS6mXQ6SVXVVcyY8R/4/XOO+nqpVJTOzrsYHNyGZQ1iWUOk04N4PGUEg6cRCCzE71+AzzdrzL4zxtDd/QCtrbeSn19DYeFyCguXO0k7f1TZND09f6C5+ZsMDGw9bJnXW0Vt7Xeoqrr6qFVMkchmXn55DdHopiMsdVFaejFVVddQXv4viOQRizUzOLiDwcEdDA3tdh67sKwoXm8VodBZFBaeSTC4BK+3yvn2XYbbHRjzPoeGXmL//i/T3b3+iLHl58+gpuazVFd/EhEX3d0PcODAPYTDf3Gq6T7D1KmfPuyn4MakGRraRVfXerq67mN42O640k7KflyuAKlUGMvqp7z8/cycefOYdqtYrJX29tvp6PgFyWQ3LpefdDrGoV8HApSWrqSu7vsEgwsBCIf/yr59XzjiF6DXCPn5M6ir+w6VlVeOU26cLeRAUrgcWGGM+aQzfRVwljHmMyPK7HDKtDrT+5wyPaO2dR1wHcCMGTOWNTc3H5OY1YnNsoaxq7PGXhUca+l0AssaGre+P1uMMU79tsepX/c6f1//NiZj0nR13Ucs1oTbHcok71DoLAoKpk3otS0rgttdeNQvB+OJRrcQDv8VSDv35aTx+WZTVnbZmCoxgESiy4nTN2bZ6LgGBhro7X3cSQR2chZxMXXqpygsPHPc9S0rRnf3eqLRLbjdAdzuIG53kGBwMcXF7zzC66Xp6XmYWOxVRDzOw01+/lR8vtkUFMyc0K/8xnNCJYWR9EpBKaXeuFy4o7kNmD5iepoz74hlnOqjIuwGZ6WUUllwLJPC88AcEakVES+wCnhkVJlHgKud55cDT43XnqCUUurYOmZ3NBtjUiLyGeAJ7J+k/tIYs1NEbgY2G2MeAe4E7hGRvUAvduJQSimVJce0mwtjzOPA46PmfXXE8xjw4WMZg1JKqYnTXlKVUkplaFJQSimVoUlBKaVUhiYFpZRSGW+7XlJFpBuY7C3N5cBRb4zLMo1tcjS2ydHYJuftHNspxpjxh3jkbZgU3gwR2TyRO/qyQWObHI1tcjS2yTkZYtPqI6WUUhmaFJRSSmWcbEnhF9kOYBwa2+RobJOjsU3OCR/bSdWmoJRSanwn25WCUkqpcZw0SUFEVojIHhHZKyJfzHIsvxSRLmc8iUPzSkXkzyLysvO3JEuxTReRp0WkUUR2isjncyU+ESkQkU0i8qIT2zec+bUi8pxzbO93euXNChFxi8hWEXksl2ITkSYR2S4iDSKy2ZmX9WPqxFEsIg+IyG4R2SUiy3MhNhGZ6+yvQ4+IiNyQC7E58f2b8znYISL3OZ+PN32+nRRJwRkv+ifAJcB8YLWIzM9iSHcBK0bN+yLwpDFmDvCkM50NKWCtMWY+cDawxtlXuRBfHLjAGHM6sBhYISJnA98HbjXGzAb6gGuzENshnwd2jZjOpdjON8YsHvGzxVw4pgC3AX80xtQDp2Pvv6zHZozZ4+yvxcAyYAh4KBdiE5Ea4HPAGcaYhdg9Ua/irTjfjDEn/ANYDjwxYvom4KYsxzQT2DFieg9Q7TyvBvZke785sfwBeG+uxQf4gReAs7Bv2PEc6Vgf55imYf+TuAB4DJAciq0JKB81L+vHFHtgrf047Zu5FNuoeC4CnsmV2IAaoAUoxe7t+jHg4rfifDsprhR4bQce0urMyyWVxpgO53knUJnNYABEZCawBHiOHInPqZ5pALqAPwP7gLAxJuUUyeax/QHw77w2SnsZuRObAf4kIlucMc8hN45pLdAN/MqpdrtDRAI5EttIq4D7nOdZj80Y0wasA14FOoB+YAtvwfl2siSFtxVjp/ms/ixMRILA74EbjDGRkcuyGZ8xxjL25fw04EygPhtxjCYilwJdxpgt2Y7lKM41xizFrkJdIyLvGrkwi8fUAywFfmaMWQIMMqo6JtufB6de/jJg/ehl2YrNacd4H3ZSnQoEGFslPSknS1KYyHjR2XZARKoBnL9d2QpERPKwE8K9xpgHcy0+AGNMGHga+xK52BnjG7J3bM8BLhORJuC32FVIt+VIbIe+WWKM6cKuFz+T3DimrUCrMeY5Z/oB7CSRC7EdcgnwgjHmgDOdC7G9B9hvjOk2xiSBB7HPwTd9vp0sSWEi40Vn28jxqq/Grss/7kREsIdJ3WWM+e8Ri7Ien4hMEZFi57kPu61jF3ZyuDybsRljbjLGTDPGzMQ+v54yxnw0F2ITkYCIhA49x64f30EOHFNjTCfQIiJznVkXAo25ENsIq3mt6ghyI7ZXgbNFxO98Zg/ttzd/vmWz8eY4N8ysBF7CroP+UpZjuQ+7HjCJ/U3pWuz65yeBl4ENQGmWYjsX+3J4G9DgPFbmQnzAImCrE9sO4KvO/DpgE7AX+xI/P8vH9zzgsVyJzYnhReex89D5nwvH1IljMbDZOa4PAyU5FFsAOAgUjZiXK7F9A9jtfBbuAfLfivNN72hWSimVcbJUHymllJoATQpKKaUyNCkopZTK0KSglFIqQ5OCUkqpDE0KSh1HInLeoR5UlcpFmhSUUkplaFJQ6ghE5GPO2A0NIvJzpyO+ARG51enD/kkRmeKUXSwi/xCRbSLy0KH+9UVktohscMZ/eEFEZjmbD44YP+Be545UpXKCJgWlRhGRecAVwDnG7nzPAj6KfXfrZmPMAmAj8DVnlV8DNxpjFgHbR8y/F/iJscd/+Cfsu9jB7nn2BuyxPeqw+6xRKid4Xr+IUiedC7EHVXne+RLvw+70LA3c75T5DfCgiBQBxcaYjc78u4H1Tl9DNcaYhwCMMTEAZ3ubjDGtznQD9tgafzv2b0up16dJQamxBLjbGHPTYTNFvjKq3GT7iImPeG6hn0OVQ7T6SKmxngQuF5EKyIxlfAr25+VQD5RXAn8zxvQDfSLyTmf+VcBGY0wUaBWR9zvbyBcR/3F9F0pNgn5DUWoUY0yjiHwZe6QyF3ZvtmuwB4A501nWhd3uAHYXxbc7//RfAT7hzL8K+LmI3Oxs48PH8W0oNSnaS6pSEyQiA8aYYLbjUOpY0uojpZRSGXqloJRSKkOvFJRSSmVoUlBKKZWhSUEppVSGJgWllFIZmhSUUkplaFJQSimV8f8lR78qoAnFQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2443 - acc: 0.9452\n",
      "Loss: 0.24427985519070183 Accuracy: 0.94517136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_multi_3_concat_ch_128_BN'\n",
    "\n",
    "for i in range(4, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_cnn(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 128)   768         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_39 (Batc (None, 16000, 128)   512         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_39[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 128)    0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_40 (Batc (None, 5333, 128)    512         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_40[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 128)    0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_41 (Batc (None, 1777, 128)    512         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_41[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 128)     0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_42 (Batc (None, 592, 128)     512         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 592, 128)     0           batch_normalization_v1_42[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 197, 128)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 227456)       0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 75776)        0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 25216)        0           max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 328448)       0           flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_43 (Batc (None, 328448)       1313792     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           5255184     batch_normalization_v1_43[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 6,817,936\n",
      "Trainable params: 6,160,016\n",
      "Non-trainable params: 657,920\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 3.6625 - acc: 0.5782\n",
      "Loss: 3.6625097466901577 Accuracy: 0.5781931\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 16000, 128)   768         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_44 (Batc (None, 16000, 128)   512         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_44[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 5333, 128)    0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_45 (Batc (None, 5333, 128)    512         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_45[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 1777, 128)    0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_46 (Batc (None, 1777, 128)    512         conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_46[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 592, 128)     0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_47 (Batc (None, 592, 128)     512         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 592, 128)     0           batch_normalization_v1_47[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 197, 128)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_48 (Batc (None, 197, 256)     1024        conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 197, 256)     0           batch_normalization_v1_48[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 65, 256)      0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 75776)        0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 25216)        0           max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 16640)        0           max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 117632)       0           flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_49 (Batc (None, 117632)       470528      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           1882128     batch_normalization_v1_49[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 2,766,736\n",
      "Trainable params: 2,529,936\n",
      "Non-trainable params: 236,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.5778 - acc: 0.6600\n",
      "Loss: 1.5777674066438605 Accuracy: 0.66002077\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 16000, 128)   768         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_50 (Batc (None, 16000, 128)   512         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_50[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 5333, 128)    0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_51 (Batc (None, 5333, 128)    512         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_51[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 1777, 128)    0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_52 (Batc (None, 1777, 128)    512         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_52[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 592, 128)     0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_53 (Batc (None, 592, 128)     512         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 592, 128)     0           batch_normalization_v1_53[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 197, 128)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_54 (Batc (None, 197, 256)     1024        conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 197, 256)     0           batch_normalization_v1_54[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 65, 256)      0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_55 (Batc (None, 65, 256)      1024        conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 65, 256)      0           batch_normalization_v1_55[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 21, 256)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 25216)        0           max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 16640)        0           max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 5376)         0           max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 47232)        0           flatten_24[0][0]                 \n",
      "                                                                 flatten_25[0][0]                 \n",
      "                                                                 flatten_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_56 (Batc (None, 47232)        188928      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           755728      batch_normalization_v1_56[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 1,687,696\n",
      "Trainable params: 1,591,184\n",
      "Non-trainable params: 96,512\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.7025 - acc: 0.8114\n",
      "Loss: 0.7024740458525106 Accuracy: 0.81142265\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 16000, 128)   768         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_57 (Batc (None, 16000, 128)   512         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_57[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 5333, 128)    0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_58 (Batc (None, 5333, 128)    512         conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_58[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 1777, 128)    0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_59 (Batc (None, 1777, 128)    512         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_59[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 592, 128)     0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_60 (Batc (None, 592, 128)     512         conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 592, 128)     0           batch_normalization_v1_60[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 197, 128)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_61 (Batc (None, 197, 256)     1024        conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 197, 256)     0           batch_normalization_v1_61[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 65, 256)      0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_62 (Batc (None, 65, 256)      1024        conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 65, 256)      0           batch_normalization_v1_62[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 21, 256)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 21, 256)      327936      max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_63 (Batc (None, 21, 256)      1024        conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 21, 256)      0           batch_normalization_v1_63[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 7, 256)       0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 16640)        0           max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 5376)         0           max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 1792)         0           max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 23808)        0           flatten_27[0][0]                 \n",
      "                                                                 flatten_28[0][0]                 \n",
      "                                                                 flatten_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_64 (Batc (None, 23808)        95232       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           380944      batch_normalization_v1_64[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 1,548,176\n",
      "Trainable params: 1,498,000\n",
      "Non-trainable params: 50,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3865 - acc: 0.9244\n",
      "Loss: 0.386487360042544 Accuracy: 0.9244029\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 16000, 128)   768         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_65 (Batc (None, 16000, 128)   512         conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_65[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 5333, 128)    0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_66 (Batc (None, 5333, 128)    512         conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_66[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 1777, 128)    0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_67 (Batc (None, 1777, 128)    512         conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_67[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 592, 128)     0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_68 (Batc (None, 592, 128)     512         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 592, 128)     0           batch_normalization_v1_68[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 197, 128)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_69 (Batc (None, 197, 256)     1024        conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 197, 256)     0           batch_normalization_v1_69[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 65, 256)      0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_70 (Batc (None, 65, 256)      1024        conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 65, 256)      0           batch_normalization_v1_70[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 21, 256)      0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 21, 256)      327936      max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_71 (Batc (None, 21, 256)      1024        conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 21, 256)      0           batch_normalization_v1_71[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 7, 256)       0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 7, 256)       327936      max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_72 (Batc (None, 7, 256)       1024        conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 256)       0           batch_normalization_v1_72[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 2, 256)       0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 5376)         0           max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 1792)         0           max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 512)          0           max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 7680)         0           flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_73 (Batc (None, 7680)         30720       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           122896      batch_normalization_v1_73[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 1,554,576\n",
      "Trainable params: 1,536,144\n",
      "Non-trainable params: 18,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2443 - acc: 0.9452\n",
      "Loss: 0.24427985519070183 Accuracy: 0.94517136\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_multi_3_concat_ch_128_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(4, 9):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 128)   768         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_39 (Batc (None, 16000, 128)   512         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_39[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 128)    0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_40 (Batc (None, 5333, 128)    512         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_40[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 128)    0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_41 (Batc (None, 1777, 128)    512         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_41[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 128)     0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_42 (Batc (None, 592, 128)     512         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 592, 128)     0           batch_normalization_v1_42[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 197, 128)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 227456)       0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 75776)        0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 25216)        0           max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 328448)       0           flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_43 (Batc (None, 328448)       1313792     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           5255184     batch_normalization_v1_43[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 6,817,936\n",
      "Trainable params: 6,160,016\n",
      "Non-trainable params: 657,920\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 5.1580 - acc: 0.6241\n",
      "Loss: 5.1580394666638085 Accuracy: 0.6240914\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 16000, 128)   768         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_44 (Batc (None, 16000, 128)   512         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_44[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 5333, 128)    0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_45 (Batc (None, 5333, 128)    512         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_45[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 1777, 128)    0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_46 (Batc (None, 1777, 128)    512         conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_46[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 592, 128)     0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_47 (Batc (None, 592, 128)     512         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 592, 128)     0           batch_normalization_v1_47[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 197, 128)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_48 (Batc (None, 197, 256)     1024        conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 197, 256)     0           batch_normalization_v1_48[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 65, 256)      0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 75776)        0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 25216)        0           max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 16640)        0           max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 117632)       0           flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_49 (Batc (None, 117632)       470528      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           1882128     batch_normalization_v1_49[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 2,766,736\n",
      "Trainable params: 2,529,936\n",
      "Non-trainable params: 236,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 3.1752 - acc: 0.6908\n",
      "Loss: 3.1751595623891795 Accuracy: 0.69075805\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 16000, 128)   768         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_50 (Batc (None, 16000, 128)   512         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_50[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 5333, 128)    0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_51 (Batc (None, 5333, 128)    512         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_51[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 1777, 128)    0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_52 (Batc (None, 1777, 128)    512         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_52[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 592, 128)     0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_53 (Batc (None, 592, 128)     512         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 592, 128)     0           batch_normalization_v1_53[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 197, 128)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_54 (Batc (None, 197, 256)     1024        conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 197, 256)     0           batch_normalization_v1_54[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 65, 256)      0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_55 (Batc (None, 65, 256)      1024        conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 65, 256)      0           batch_normalization_v1_55[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 21, 256)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 25216)        0           max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 16640)        0           max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 5376)         0           max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 47232)        0           flatten_24[0][0]                 \n",
      "                                                                 flatten_25[0][0]                 \n",
      "                                                                 flatten_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_56 (Batc (None, 47232)        188928      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           755728      batch_normalization_v1_56[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 1,687,696\n",
      "Trainable params: 1,591,184\n",
      "Non-trainable params: 96,512\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.9555 - acc: 0.8640\n",
      "Loss: 0.9555431140163142 Accuracy: 0.86396676\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 16000, 128)   768         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_57 (Batc (None, 16000, 128)   512         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_57[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 5333, 128)    0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_58 (Batc (None, 5333, 128)    512         conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_58[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 1777, 128)    0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_59 (Batc (None, 1777, 128)    512         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_59[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 592, 128)     0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_60 (Batc (None, 592, 128)     512         conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 592, 128)     0           batch_normalization_v1_60[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 197, 128)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_61 (Batc (None, 197, 256)     1024        conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 197, 256)     0           batch_normalization_v1_61[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 65, 256)      0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_62 (Batc (None, 65, 256)      1024        conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 65, 256)      0           batch_normalization_v1_62[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 21, 256)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 21, 256)      327936      max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_63 (Batc (None, 21, 256)      1024        conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 21, 256)      0           batch_normalization_v1_63[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 7, 256)       0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 16640)        0           max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 5376)         0           max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 1792)         0           max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 23808)        0           flatten_27[0][0]                 \n",
      "                                                                 flatten_28[0][0]                 \n",
      "                                                                 flatten_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_64 (Batc (None, 23808)        95232       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           380944      batch_normalization_v1_64[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 1,548,176\n",
      "Trainable params: 1,498,000\n",
      "Non-trainable params: 50,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.4468 - acc: 0.9292\n",
      "Loss: 0.446770729758387 Accuracy: 0.92917967\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_BN_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 16000, 128)   768         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_65 (Batc (None, 16000, 128)   512         conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16000, 128)   0           batch_normalization_v1_65[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 5333, 128)    0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_66 (Batc (None, 5333, 128)    512         conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 5333, 128)    0           batch_normalization_v1_66[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 1777, 128)    0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_67 (Batc (None, 1777, 128)    512         conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 1777, 128)    0           batch_normalization_v1_67[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 592, 128)     0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_68 (Batc (None, 592, 128)     512         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 592, 128)     0           batch_normalization_v1_68[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 197, 128)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_69 (Batc (None, 197, 256)     1024        conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 197, 256)     0           batch_normalization_v1_69[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 65, 256)      0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_70 (Batc (None, 65, 256)      1024        conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 65, 256)      0           batch_normalization_v1_70[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 21, 256)      0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 21, 256)      327936      max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_71 (Batc (None, 21, 256)      1024        conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 21, 256)      0           batch_normalization_v1_71[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 7, 256)       0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 7, 256)       327936      max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_72 (Batc (None, 7, 256)       1024        conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 256)       0           batch_normalization_v1_72[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 2, 256)       0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 5376)         0           max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 1792)         0           max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 512)          0           max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 7680)         0           flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_73 (Batc (None, 7680)         30720       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           122896      batch_normalization_v1_73[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 1,554,576\n",
      "Trainable params: 1,536,144\n",
      "Non-trainable params: 18,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4039 - acc: 0.9275\n",
      "Loss: 0.40390394258768386 Accuracy: 0.9275182\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
