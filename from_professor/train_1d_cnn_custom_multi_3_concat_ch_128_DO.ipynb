{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, \\\n",
    "                                    Flatten, Conv1D, MaxPooling1D, Dropout, \\\n",
    "                                    Concatenate, GlobalMaxPool1D, GlobalAvgPool1D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(conv_num=1):\n",
    "    filter_size = 128\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    layer_outputs = []\n",
    "    for i in range(conv_num):\n",
    "        x = Conv1D (kernel_size=5, filters=filter_size*(2**(i//4)), \n",
    "                          strides=1, padding='same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling1D(pool_size=3, strides=3)(x)\n",
    "        layer_outputs.append(x)    \n",
    "    \n",
    "    x = Concatenate()([Flatten()(output) for output in layer_outputs[-3:]])\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 16000, 128)   768         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16000, 128)   0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 5333, 128)    0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 5333, 128)    82048       max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5333, 128)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1777, 128)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1777, 128)    82048       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1777, 128)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 592, 128)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 682624)       0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 227456)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 75776)        0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 985856)       0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 985856)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           15773712    dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,938,576\n",
      "Trainable params: 15,938,576\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 16000, 128)   768         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16000, 128)   0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 5333, 128)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 5333, 128)    82048       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 5333, 128)    0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1777, 128)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1777, 128)    82048       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1777, 128)    0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 592, 128)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 592, 128)     82048       max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 592, 128)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 197, 128)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 227456)       0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 75776)        0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 25216)        0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 328448)       0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 328448)       0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           5255184     dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,502,096\n",
      "Trainable params: 5,502,096\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 16000, 128)   768         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16000, 128)   0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 5333, 128)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 5333, 128)    82048       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5333, 128)    0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1777, 128)    0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1777, 128)    82048       max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1777, 128)    0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 592, 128)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 592, 128)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 197, 128)     0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 197, 256)     0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 65, 256)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 75776)        0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 25216)        0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 16640)        0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 117632)       0           flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 117632)       0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           1882128     dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,293,136\n",
      "Trainable params: 2,293,136\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 16000, 128)   768         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16000, 128)   0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 5333, 128)    0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5333, 128)    0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1777, 128)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1777, 128)    0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 592, 128)     0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 592, 128)     0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 197, 128)     0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 197, 256)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 65, 256)      0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 65, 256)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 21, 256)      0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 25216)        0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 16640)        0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 5376)         0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 47232)        0           flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 47232)        0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           755728      dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,494,672\n",
      "Trainable params: 1,494,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 16000, 128)   768         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16000, 128)   0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 5333, 128)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 5333, 128)    0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1777, 128)    0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1777, 128)    0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 592, 128)     0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 592, 128)     0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 197, 128)     0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 197, 256)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 65, 256)      0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 65, 256)      0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 21, 256)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 21, 256)      327936      max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 21, 256)      0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 7, 256)       0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 16640)        0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 5376)         0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 1792)         0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 23808)        0           flatten_12[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 23808)        0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           380944      dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,447,824\n",
      "Trainable params: 1,447,824\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 16000, 128)   768         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16000, 128)   0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 5333, 128)    0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 5333, 128)    0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1777, 128)    0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1777, 128)    0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 592, 128)     0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 592, 128)     0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 197, 128)     0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 197, 256)     0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 65, 256)      0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 65, 256)      0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 21, 256)      0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 21, 256)      327936      max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 21, 256)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 7, 256)       0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 7, 256)       327936      max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 256)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 2, 256)       0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 5376)         0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 1792)         0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 512)          0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 7680)         0           flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "                                                                 flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7680)         0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           122896      dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,517,712\n",
      "Trainable params: 1,517,712\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 9):\n",
    "    model = build_cnn(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8789 - acc: 0.4103\n",
      "Epoch 00001: val_loss improved from inf to 1.49863, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_3_conv_checkpoint/001-1.4986.hdf5\n",
      "36805/36805 [==============================] - 77s 2ms/sample - loss: 1.8788 - acc: 0.4104 - val_loss: 1.4986 - val_acc: 0.5358\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2594 - acc: 0.6084\n",
      "Epoch 00002: val_loss improved from 1.49863 to 1.36500, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_3_conv_checkpoint/002-1.3650.hdf5\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 1.2594 - acc: 0.6084 - val_loss: 1.3650 - val_acc: 0.5744\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0113 - acc: 0.6905\n",
      "Epoch 00003: val_loss improved from 1.36500 to 1.32545, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_3_conv_checkpoint/003-1.3254.hdf5\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 1.0115 - acc: 0.6904 - val_loss: 1.3254 - val_acc: 0.5721\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8260 - acc: 0.7508\n",
      "Epoch 00004: val_loss improved from 1.32545 to 1.25326, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_3_conv_checkpoint/004-1.2533.hdf5\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.8260 - acc: 0.7508 - val_loss: 1.2533 - val_acc: 0.6152\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6735 - acc: 0.8006\n",
      "Epoch 00005: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.6735 - acc: 0.8006 - val_loss: 1.2748 - val_acc: 0.6040\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5516 - acc: 0.8368\n",
      "Epoch 00006: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.5516 - acc: 0.8368 - val_loss: 1.3156 - val_acc: 0.6180\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4453 - acc: 0.8735\n",
      "Epoch 00007: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.4454 - acc: 0.8734 - val_loss: 1.3055 - val_acc: 0.6296\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3648 - acc: 0.8972\n",
      "Epoch 00008: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.3647 - acc: 0.8972 - val_loss: 1.3644 - val_acc: 0.6287\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2954 - acc: 0.9201\n",
      "Epoch 00009: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.2954 - acc: 0.9201 - val_loss: 1.4575 - val_acc: 0.6282\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2432 - acc: 0.9343\n",
      "Epoch 00010: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.2432 - acc: 0.9344 - val_loss: 1.4739 - val_acc: 0.6375\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1989 - acc: 0.9499\n",
      "Epoch 00011: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.1989 - acc: 0.9499 - val_loss: 1.5467 - val_acc: 0.6327\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9568\n",
      "Epoch 00012: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.1738 - acc: 0.9568 - val_loss: 1.6299 - val_acc: 0.6366\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9641\n",
      "Epoch 00013: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.1496 - acc: 0.9641 - val_loss: 1.6472 - val_acc: 0.6394\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9720\n",
      "Epoch 00014: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.1242 - acc: 0.9720 - val_loss: 1.6821 - val_acc: 0.6375\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9768\n",
      "Epoch 00015: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.1054 - acc: 0.9768 - val_loss: 1.8348 - val_acc: 0.6525\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9765\n",
      "Epoch 00016: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.1003 - acc: 0.9765 - val_loss: 1.8565 - val_acc: 0.6389\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9783\n",
      "Epoch 00017: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0924 - acc: 0.9783 - val_loss: 1.7927 - val_acc: 0.6527\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9768\n",
      "Epoch 00018: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0950 - acc: 0.9768 - val_loss: 1.8819 - val_acc: 0.6392\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9831\n",
      "Epoch 00019: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0769 - acc: 0.9831 - val_loss: 1.8195 - val_acc: 0.6627\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9853\n",
      "Epoch 00020: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0700 - acc: 0.9853 - val_loss: 1.9073 - val_acc: 0.6546\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9872\n",
      "Epoch 00021: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0639 - acc: 0.9872 - val_loss: 1.9394 - val_acc: 0.6508\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9883\n",
      "Epoch 00022: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0576 - acc: 0.9883 - val_loss: 2.0069 - val_acc: 0.6492\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9829\n",
      "Epoch 00023: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0716 - acc: 0.9829 - val_loss: 2.0207 - val_acc: 0.6464\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9880\n",
      "Epoch 00024: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0568 - acc: 0.9880 - val_loss: 2.0868 - val_acc: 0.6448\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9882\n",
      "Epoch 00025: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0573 - acc: 0.9882 - val_loss: 2.0043 - val_acc: 0.6608\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9901\n",
      "Epoch 00026: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0483 - acc: 0.9901 - val_loss: 2.1064 - val_acc: 0.6557\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9878\n",
      "Epoch 00027: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0595 - acc: 0.9878 - val_loss: 2.0851 - val_acc: 0.6615\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9872\n",
      "Epoch 00028: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0581 - acc: 0.9872 - val_loss: 2.0624 - val_acc: 0.6569\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9892\n",
      "Epoch 00029: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0503 - acc: 0.9892 - val_loss: 2.0771 - val_acc: 0.6536\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9933\n",
      "Epoch 00030: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0408 - acc: 0.9933 - val_loss: 2.0524 - val_acc: 0.6632\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9906\n",
      "Epoch 00031: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0471 - acc: 0.9905 - val_loss: 2.1358 - val_acc: 0.6681\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9903\n",
      "Epoch 00032: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0462 - acc: 0.9903 - val_loss: 2.1423 - val_acc: 0.6641\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9916\n",
      "Epoch 00033: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0430 - acc: 0.9916 - val_loss: 2.1513 - val_acc: 0.6608\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9937\n",
      "Epoch 00034: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0357 - acc: 0.9937 - val_loss: 2.2410 - val_acc: 0.6592\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9889\n",
      "Epoch 00035: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0494 - acc: 0.9889 - val_loss: 2.1425 - val_acc: 0.6671\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9942\n",
      "Epoch 00036: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0350 - acc: 0.9942 - val_loss: 2.1315 - val_acc: 0.6734\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9943\n",
      "Epoch 00037: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0341 - acc: 0.9943 - val_loss: 2.1112 - val_acc: 0.6755\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9949\n",
      "Epoch 00038: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0297 - acc: 0.9949 - val_loss: 2.3730 - val_acc: 0.6653\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9907\n",
      "Epoch 00039: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0437 - acc: 0.9907 - val_loss: 2.1637 - val_acc: 0.6751\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9943\n",
      "Epoch 00040: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0318 - acc: 0.9943 - val_loss: 2.2498 - val_acc: 0.6608\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9947\n",
      "Epoch 00041: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0320 - acc: 0.9947 - val_loss: 2.2277 - val_acc: 0.6632\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9903\n",
      "Epoch 00042: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0434 - acc: 0.9903 - val_loss: 2.2154 - val_acc: 0.6737\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9951\n",
      "Epoch 00043: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0296 - acc: 0.9951 - val_loss: 2.2203 - val_acc: 0.6718\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9925\n",
      "Epoch 00044: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0375 - acc: 0.9925 - val_loss: 2.2340 - val_acc: 0.6783\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 00045: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0393 - acc: 0.9917 - val_loss: 2.3158 - val_acc: 0.6678\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9936\n",
      "Epoch 00046: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0329 - acc: 0.9936 - val_loss: 2.3041 - val_acc: 0.6716\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9945\n",
      "Epoch 00047: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0336 - acc: 0.9945 - val_loss: 2.2830 - val_acc: 0.6704\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9952\n",
      "Epoch 00048: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0296 - acc: 0.9952 - val_loss: 2.2366 - val_acc: 0.6790\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9939\n",
      "Epoch 00049: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0330 - acc: 0.9939 - val_loss: 2.3578 - val_acc: 0.6681\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9962\n",
      "Epoch 00050: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0239 - acc: 0.9962 - val_loss: 2.3854 - val_acc: 0.6604\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9936\n",
      "Epoch 00051: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0338 - acc: 0.9936 - val_loss: 2.2491 - val_acc: 0.6730\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9956\n",
      "Epoch 00052: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0272 - acc: 0.9956 - val_loss: 2.2417 - val_acc: 0.6792\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9936\n",
      "Epoch 00053: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0329 - acc: 0.9936 - val_loss: 2.3541 - val_acc: 0.6792\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9943\n",
      "Epoch 00054: val_loss did not improve from 1.25326\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 0.0298 - acc: 0.9943 - val_loss: 2.2382 - val_acc: 0.6811\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 784us/sample - loss: 1.3458 - acc: 0.5842\n",
      "Loss: 1.3458196849714064 Accuracy: 0.584216\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8265 - acc: 0.4212\n",
      "Epoch 00001: val_loss improved from inf to 1.45392, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_4_conv_checkpoint/001-1.4539.hdf5\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 1.8265 - acc: 0.4212 - val_loss: 1.4539 - val_acc: 0.5579\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2528 - acc: 0.6160\n",
      "Epoch 00002: val_loss improved from 1.45392 to 1.26454, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_4_conv_checkpoint/002-1.2645.hdf5\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 1.2527 - acc: 0.6160 - val_loss: 1.2645 - val_acc: 0.5980\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0082 - acc: 0.6967\n",
      "Epoch 00003: val_loss improved from 1.26454 to 1.09093, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_4_conv_checkpoint/003-1.0909.hdf5\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 1.0083 - acc: 0.6966 - val_loss: 1.0909 - val_acc: 0.6583\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8282 - acc: 0.7526\n",
      "Epoch 00004: val_loss improved from 1.09093 to 1.06252, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_4_conv_checkpoint/004-1.0625.hdf5\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.8281 - acc: 0.7526 - val_loss: 1.0625 - val_acc: 0.6751\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6773 - acc: 0.7957\n",
      "Epoch 00005: val_loss improved from 1.06252 to 1.02822, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_4_conv_checkpoint/005-1.0282.hdf5\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.6773 - acc: 0.7957 - val_loss: 1.0282 - val_acc: 0.6809\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5624 - acc: 0.8309\n",
      "Epoch 00006: val_loss improved from 1.02822 to 1.02259, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_4_conv_checkpoint/006-1.0226.hdf5\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.5624 - acc: 0.8309 - val_loss: 1.0226 - val_acc: 0.6960\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4659 - acc: 0.8607\n",
      "Epoch 00007: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.4660 - acc: 0.8606 - val_loss: 1.0645 - val_acc: 0.6923\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3868 - acc: 0.8845\n",
      "Epoch 00008: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.3868 - acc: 0.8844 - val_loss: 1.1015 - val_acc: 0.6932\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3173 - acc: 0.9071\n",
      "Epoch 00009: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.3172 - acc: 0.9071 - val_loss: 1.1283 - val_acc: 0.6918\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2622 - acc: 0.9241\n",
      "Epoch 00010: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.2622 - acc: 0.9241 - val_loss: 1.0743 - val_acc: 0.7186\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2147 - acc: 0.9367\n",
      "Epoch 00011: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.2148 - acc: 0.9367 - val_loss: 1.1914 - val_acc: 0.6965\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1922 - acc: 0.9443\n",
      "Epoch 00012: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.1922 - acc: 0.9444 - val_loss: 1.2331 - val_acc: 0.7109\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9537\n",
      "Epoch 00013: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.1605 - acc: 0.9537 - val_loss: 1.2666 - val_acc: 0.7053\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9596\n",
      "Epoch 00014: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.1426 - acc: 0.9596 - val_loss: 1.3105 - val_acc: 0.7126\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9692\n",
      "Epoch 00015: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.1139 - acc: 0.9692 - val_loss: 1.3566 - val_acc: 0.7140\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9694\n",
      "Epoch 00016: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.1084 - acc: 0.9694 - val_loss: 1.3183 - val_acc: 0.7263\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9721\n",
      "Epoch 00017: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.1013 - acc: 0.9722 - val_loss: 1.3805 - val_acc: 0.7200\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9770\n",
      "Epoch 00018: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0843 - acc: 0.9770 - val_loss: 1.3463 - val_acc: 0.7328\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9779\n",
      "Epoch 00019: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0803 - acc: 0.9779 - val_loss: 1.4147 - val_acc: 0.7272\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9786\n",
      "Epoch 00020: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0789 - acc: 0.9786 - val_loss: 1.4151 - val_acc: 0.7289\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9810\n",
      "Epoch 00021: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0706 - acc: 0.9810 - val_loss: 1.4696 - val_acc: 0.7303\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9817\n",
      "Epoch 00022: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0686 - acc: 0.9817 - val_loss: 1.4585 - val_acc: 0.7326\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9852\n",
      "Epoch 00023: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0602 - acc: 0.9852 - val_loss: 1.4833 - val_acc: 0.7233\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9836\n",
      "Epoch 00024: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0622 - acc: 0.9836 - val_loss: 1.4458 - val_acc: 0.7459\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9869\n",
      "Epoch 00025: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0529 - acc: 0.9869 - val_loss: 1.4749 - val_acc: 0.7414\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9841\n",
      "Epoch 00026: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0581 - acc: 0.9841 - val_loss: 1.5350 - val_acc: 0.7277\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9877\n",
      "Epoch 00027: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0493 - acc: 0.9877 - val_loss: 1.5135 - val_acc: 0.7358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9852\n",
      "Epoch 00028: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0541 - acc: 0.9852 - val_loss: 1.5635 - val_acc: 0.7379\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9876\n",
      "Epoch 00029: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0481 - acc: 0.9876 - val_loss: 1.5393 - val_acc: 0.7370\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9873\n",
      "Epoch 00030: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0487 - acc: 0.9873 - val_loss: 1.5341 - val_acc: 0.7440\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9900\n",
      "Epoch 00031: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0401 - acc: 0.9900 - val_loss: 1.5641 - val_acc: 0.7391\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9894\n",
      "Epoch 00032: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0427 - acc: 0.9894 - val_loss: 1.6645 - val_acc: 0.7240\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9901\n",
      "Epoch 00033: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0421 - acc: 0.9901 - val_loss: 1.5903 - val_acc: 0.7463\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9915\n",
      "Epoch 00034: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0365 - acc: 0.9916 - val_loss: 1.5568 - val_acc: 0.7410\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9874\n",
      "Epoch 00035: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0487 - acc: 0.9874 - val_loss: 1.7241 - val_acc: 0.7160\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9882\n",
      "Epoch 00036: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0463 - acc: 0.9882 - val_loss: 1.5721 - val_acc: 0.7338\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9929\n",
      "Epoch 00037: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0321 - acc: 0.9929 - val_loss: 1.5709 - val_acc: 0.7491\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9920\n",
      "Epoch 00038: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0334 - acc: 0.9920 - val_loss: 1.5948 - val_acc: 0.7463\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9937\n",
      "Epoch 00039: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0291 - acc: 0.9938 - val_loss: 1.9184 - val_acc: 0.7165\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9860\n",
      "Epoch 00040: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0529 - acc: 0.9860 - val_loss: 1.5975 - val_acc: 0.7412\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9937\n",
      "Epoch 00041: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0286 - acc: 0.9937 - val_loss: 1.5694 - val_acc: 0.7529\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9933\n",
      "Epoch 00042: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0306 - acc: 0.9933 - val_loss: 1.7228 - val_acc: 0.7358\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9933\n",
      "Epoch 00043: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0296 - acc: 0.9933 - val_loss: 1.6265 - val_acc: 0.7438\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9916\n",
      "Epoch 00044: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0329 - acc: 0.9916 - val_loss: 1.6661 - val_acc: 0.7473\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9938\n",
      "Epoch 00045: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0285 - acc: 0.9938 - val_loss: 1.6648 - val_acc: 0.7459\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9921\n",
      "Epoch 00046: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0314 - acc: 0.9921 - val_loss: 1.8150 - val_acc: 0.7265\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9928\n",
      "Epoch 00047: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0318 - acc: 0.9928 - val_loss: 1.7206 - val_acc: 0.7431\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9926\n",
      "Epoch 00048: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0309 - acc: 0.9926 - val_loss: 1.7553 - val_acc: 0.7407\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9935\n",
      "Epoch 00049: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0301 - acc: 0.9935 - val_loss: 1.7286 - val_acc: 0.7456\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9931\n",
      "Epoch 00050: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0296 - acc: 0.9931 - val_loss: 1.8484 - val_acc: 0.7335\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9937\n",
      "Epoch 00051: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0279 - acc: 0.9938 - val_loss: 1.7762 - val_acc: 0.7417\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9935\n",
      "Epoch 00052: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0285 - acc: 0.9935 - val_loss: 1.7033 - val_acc: 0.7498\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9954\n",
      "Epoch 00053: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0228 - acc: 0.9954 - val_loss: 1.7315 - val_acc: 0.7538\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9946\n",
      "Epoch 00054: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0246 - acc: 0.9946 - val_loss: 1.7532 - val_acc: 0.7517\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9924\n",
      "Epoch 00055: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0304 - acc: 0.9924 - val_loss: 1.6996 - val_acc: 0.7519\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9951\n",
      "Epoch 00056: val_loss did not improve from 1.02259\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0237 - acc: 0.9951 - val_loss: 1.8622 - val_acc: 0.7356\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd4VFX6wPHvSSchgSSE3kKHAKEECNJFqgUsWNaCWFh/u7q67rqiqy7qWlZdRRR1sXdUUBFFBBUERISASAmdQAolvdeZeX9/nEmDlEmZTELO53nuM8mtJ4Hc995T3qNEBMMwDMOojpurC2AYhmE0DSZgGIZhGA4xAcMwDMNwiAkYhmEYhkNMwDAMwzAcYgKGYRiG4RATMAzDMAyHOC1gKKW6KKXWK6WilVL7lFJ3V7CPUkotVkodUUrtVkoNK7NtrlLqsH2Z66xyGoZhGI5Rzhq4p5TqAHQQkZ1KKX9gBzBbRKLL7DMTuAuYCYwCXhSRUUqpICAKiADEfuxwEUlzSmENwzCMank468Qicgo4Zf86Sym1H+gERJfZbRbwnuiotVUp1doeaCYC60QkFUAptQ6YDnxc1TXbtGkj3bt3r+8fxTAM47y1Y8eOZBEJcWRfpwWMspRS3YGhwK9nbeoExJX5Pt6+rrL1VerevTtRUVF1KaphGEazopQ64ei+Tm/0Vkq1BFYA94hIphPOP18pFaWUikpKSqrv0xuGYRh2Tg0YSilPdLD4UEQ+r2CXBKBLme8729dVtv4cIrJURCJEJCIkxKG3KsMwDKMWnNlLSgFvAvtF5PlKdvsKuMneWyoSyLC3fXwHTFVKBSqlAoGp9nWGYRiGizizDWMMcCOwRym1y77uQaArgIi8BqxG95A6AuQC8+zbUpVSjwPb7cc9VtwAXlNFRUXEx8eTn59f6x+kOfPx8aFz5854enq6uiiGYbiY07rVukJERISc3egdExODv78/wcHB6Jcew1EiQkpKCllZWYSGhrq6OIZhOIFSaoeIRDiy73k/0js/P98Ei1pSShEcHGzezgzDAJpBwABMsKgD87szDKNYswgYhmE0gN274aefXF0Kw4lMwHCy9PR0XnnllVodO3PmTNLT0x3ef+HChTz33HO1upZh1Nk//gE33eTqUhhOZAKGk1UVMCwWS5XHrl69mtatWzujWIZR//btg9hYyKz38blGI2EChpMtWLCAo0ePMmTIEO677z42bNjAuHHjuOyyyxgwYAAAs2fPZvjw4YSFhbF06dKSY7t3705ycjLHjx+nf//+3H777YSFhTF16lTy8vKqvO6uXbuIjIxk8ODBXH755aSl6byNixcvZsCAAQwePJhrr70WgJ9++okhQ4YwZMgQhg4dSlZWlpN+G8Z5KzMT4uP11wcOuLYshtM0SC6pxuLw4XvIzt5V/Y410LLlEHr3XlTp9qeffpq9e/eya5e+7oYNG9i5cyd79+4t6ar61ltvERQURF5eHiNGjODKK68kODj4rLIf5uOPP+b111/n6quvZsWKFdxwww2VXvemm27ipZdeYsKECTzyyCM8+uijLFq0iKeffpqYmBi8vb1Lqruee+45lixZwpgxY8jOzsbHx6euvxajudm/v/Trfftg5EjXlcVwGvOG4QIjR44sN65h8eLFhIeHExkZSVxcHIcPHz7nmNDQUIYMGQLA8OHDOX78eKXnz8jIID09nQkTJgAwd+5cNm7cCMDgwYO5/vrr+eCDD/Dw0M8LY8aM4d5772Xx4sWkp6eXrDcMh0VHV/y1cV5pVneGqt4EGpKfn1/J1xs2bOD777/nl19+wdfXl4kTJ1Y47sHb27vka3d392qrpCrzzTffsHHjRlatWsUTTzzBnj17WLBgARdffDGrV69mzJgxfPfdd/Tr169W5zeaqeho8PaGXr1MwGho77wDO3bA88+DkzMymDcMJ/P396+yTSAjI4PAwEB8fX05cOAAW7durfM1W7VqRWBgIJs2bQLg/fffZ8KECdhsNuLi4pg0aRL/+c9/yMjIIDs7m6NHjzJo0CDuv/9+RowYwQFTB23UVHQ09OsHgwfrKqnmIisLCgtdW4Y33oCNG50eLKCZvWG4QnBwMGPGjGHgwIHMmDGDiy++uNz26dOn89prr9G/f3/69u1LZGRkvVz33Xff5Y477iA3N5cePXrw9ttvY7VaueGGG8jIyEBE+Mtf/kLr1q15+OGHWb9+PW5uboSFhTFjxox6KYPRjERHw+jRMGAAfPwxZGdDy5auLpVz2WwwbhwoBVu2QIsWDV+Gkyf1tR99tEEud97nktq/fz/9+/d3UYnOD+Z3aFQpJ0cHh8cfh7AwuOIK2L4dIhxKT9R0rV4NxQ+Af/oTLFnS8GVYsgTuvFMH7Fr+jZpcUjUgImRn76ag4KSri2IYTVNxFeaAAXqB5lEt9cIL0KkT3H03vPIKrFjR8GVYsUIHigZ6oGv2AUPnShJsNhfXQxpGU1XcyD1gAPTsCV5eja/h++GHYc2a+jvf7t3w/ff66f6ZZ2DECLj1Vqii92K9S0rSqViuuqrBLtnsAwaAUp6IFLm6GIbRNEVH6wbXnj3BwwP69m1cAePQIfj3v+GWW3TbSn1YtAh8fWH+fB0gly0DEfjDH6Coge4lX36p21GuvLJhrocJGAAo5WEChmHUVnQ09OlT2ktnwIDGVSX10Ue6YfrUKXj22bqf7/Rp+PBDuPlmCArS63r0gKVL4Zdf4JFH6n4NRyxfrrsxDx7cMNfDBAyg+A2j6rxOhmFUIjq6tO0C9NfHj+vGcFcT0Tf3SZPgmmt0wChOYVJbr76q3yLuvrv8+muugdtvh6efhrVr63aN6qSmwo8/6reLBpyCwJlzer+llEpUSu2tZPt9Sqld9mWvUsqqlAqybzuulNpj3xZV0fH1W1ZdJXU+9RgzjAaRlwfHjpUPGGFh+kZ98KDrylUsKgqOHNFVRU8/ratw/vnP2p8vL08HjEsu0W9VZ1u0SP8ubrxRv4k4y1dfgcXSoO0X4Nw3jHeA6ZVtFJFnRWSIiAwBHgB+Omve7kn27U7vm+fm5gkIIlZnX8ohLSvpv17ZesNwmUOH9E347DcMaBzVUh99pNsYrrwSuneHe+6B997TgaQ2PvxQNzbfe2/F23194ZNPdDLGuXP178YZVqyAbt1g+HDnnL8STgsYIrIRSK12R+064GNnlaU6Sunxi6YdwzBqqGwPqWK9eun2DFc3fFutujH64ouheJqABx6AkBD429/0W9DZRGDlSvjhh3O3i+iutEOGgD1PW4UGDtRvGmvX6nQdtREfX3mPq4wMfe4Gro6CRtCGoZTyRb+JlO3ELMBapdQOpdR855dBN9Y5I2AsWLCAJWUG9BRPcpSdnc3kyZMZNmwYgwYNYuXKlQ6fU0S47777GDhwIIMGDeKTTz4B4NSpU4wfP54hQ4YwcOBANm3ahNVq5eabby7Z94UXXqj3n9FoxqKjwd0devcuXefpqatrXB0w1q/X1ULXX1+6rlUreOwxnUrjyy/L73/sGEyZArNnw0UXwZgxsG5daeBYu1b/TPfeW/2Nev58fUN/4AE9iNERVqseDHjZZfrtYdAgPYr7bF9/rdORNHB1FKBvPs5agO7A3mr2uQZYdda6TvbPtsDvwPgqjp8PRAFRXbt2lbNFR0eXfnP33SITJpyz2MaPk6Kxw8Q6/oIKt1e53H33Odcsa+fOnTJ+/PiS7/v37y+xsbFSVFQkGRkZIiKSlJQkPXv2FJvNJiIifn5+FZ6reP3y5cvloosuEovFIqdPn5YuXbrIyZMn5bnnnpN///vfIiJisVgkMzNToqKi5KKLLio5R1paWpXlrUi536FhlHXFFSJ9+567fs4ckZ49G748Zd18s0hAgEhubvn1RUUiAwbo8hUUiFgsIosWifj6ivj7i7z6ql46dxYBkTFjRL7/XmTaNJEOHfQxjkhNFenSRV/H/rdeoTNnRJ58UqR7d329du1EFiwQ6dNHl2fLlvL7X365SMeOIlZrzX4flQCixMF7usvfMIBrOas6SkQS7J+JwBdApcn1RWSpiESISERISEjtSlDytFD/jd5Dhw4lMTGRkydP8vvvvxMYGEiXLl0QER588EEGDx7MRRddREJCAmfOnHHonJs3b+a6667D3d2ddu3aMWHCBLZv386IESN4++23WbhwIXv27MHf358ePXpw7Ngx7rrrLtasWUNAQEC9/4xGE5OUBDWY+rdKZ/eQKjZggH5ir2lW5VpmYa7wPCtW6DQlZ+d48vCA//4Xjh6F++/X+aDuuQcmTtTtLnfcoZcjR/QI7hMn9BvHd9/pgXpeXo6VITBQt6HExMCf/3zu9qQkfd0uXeDBByE0VLd/xMbCU0/pXlDt2sG0afDrr/qY7Gz49lv99uLmgtu3o5GlNgvVvGEArdDtHH5l1vkB/mW+3gJMd+R6w4cPPyd6OvJ0bLPZJDMzSvLy4qrdtzYefvhhefHFF+WBBx6QF198UURE3n77bbn66qulsLBQRES6desmMTExIlL9G8Y999wjb775Zsn6G264QVauXCkiIgkJCbJ06VIJDw+Xd999V0REsrKyZPny5TJr1iyZN29ejctv3jDOM4MG6afluiooEHF3F/nnP8/d9umn+mn5t98cP19ion6iXrSo7mX77DN9/XXrKt9n+nS9T1CQyPvvi9jf8M+Rny/y8ssis2eLpKTUvCyPPqqvY/97lMxMkYULRVq2FHFzE7nlFpH9+ys+Ni5Ov6EEBIj8+mvp73XDhpqXoxLU4A3DmcHiY+AUUATEA7cCdwB3lNnnZmDZWcf1QFdD/Q7sA/7p6DVrGzBERLKyfpfc3GMO7VtTe/fuldGjR0vv3r3l5MmTIiKyaNEiufPOO0VE5McffxTA4YCxYsUKmTp1qlgsFklMTJSuXbvKqVOn5Pjx42KxWERE5KWXXpK7775bkpKSSqq+9uzZI+Hh4TUuvwkY55HoaP1nr5SI/f9ire3dq8/14YeVb/vgA8fP98or+phWrUSSk+tWtssvF2nfXlc3Veb4cR3sTp+u27WqY7GIjB8v4ucn8thjIm3a6J/zyisrDxRlxcaK9Oihfy8jR4q0bVv1z1VDjSJguGKpS8DIzt4nOTkHHdq3NgYOHCgTJ04s+T4pKUkiIyNl4MCBcvPNN0u/fv0cDhg2m03+/ve/S1hYmAwcOFCWLVsmIiLvvPOOhIWFyZAhQ2Ts2LFy7Ngx2bVrlwwdOlTCw8MlPDxcVq9eXeOym4BxHnniCf1nD3V/kq/qLaKgQMTDQ+TBBx0/37hxum7eza3atsEqpaaKeHmJ3HNP7c9R3+Li9JsMiFx4oci2bTU7/sSJ0jaOP/6xXotmAkYZjt7scnIOSXb2Xof2bW5MwDiPRESIjBolMnSoflqti4UL9ZvK2Y3Kxfr319U4joiL07ejxx8Xuf12EU9PkSNHaleuN97Q56rpTdnZfv9d5Kefan98TIzuZLBvX70VSaRmAaMxNHo3Cm5uJj2IcZ6Li9MD1i6/HK67DrZt0w2/tRUdrXMoVTZxUE1yStm7hnPttXoyIC8v3SW1Nj76SHfzbWzzcQweDOPH1/747t11Q35FnQwaiAkYdiY9iNFk1Pb/aPG4g8sv13mPQA9sq63KekgVCwvTAamCOerPsWyZvsH36gUdOsDf/w6ffQZVTVl88iTs2aNTkMTE6O+jo/X4iz/8ocEHtTUHJmDYlQ7eM28ZRiP2ySf6SbM2eZo+/1zf4Pv0ga5ddXfSjz6qXQCyWHQZqgoYAwbo1BiHDlV9rsOH9ZvPtdeWrvv736F9e/15dvlEdLfYbt30U3u/fvpNp1On0jxW111X85/JqJaZ09uufHoQ50+mbhg1lp+vb6Dx8Xr08pYtjo8JSE7Wo5vLVvNcd52eWnTPnpqnyD56VGdsrS5ggK6Wqur8y5bpt4Hitx7QU74++ij88Y/6zejyy/X6lBSdVvzrr/WI7Ouv16Oeyy4dO+o5OYx6ZwKGnTPTgxhGvXjlFR0s7r1X5yh6+GH4z38cO3bVKv20f8UVpeuuugruuku/ZdQ0YFSUQ+psffrotCFVpQgRgY8/1m87nTuX33bLLTon0/336+yw27bpt5DERFi8WA+iM9VODcpUSdmZgGE0apmZ8OSTOtfRf/+rcxU9+6weDeyIL77QVThDh5auCwmBqVNLZ4urieIg0K9f5ft4e+s2iaoCxp49sH9/+eqoYh4eevrTw4d1fqUJE/Qb1ZYtOtCZYNHgTMCw0ynOwWar3zaM9PR0XnnllVodO3PmTNLrK4WD0bT997+6OubJJ/X3zz+vq11uvFGvr0p2tk6cN3v2uTfZ667TqS9++aVm5YmO1gGoupT71fWUWrZMv4VUlkjv4ot1yo41a3Q6jJ07Gzylt1HKBIwSboBbvb9hVBUwLJaqg9Pq1atpXZyW2Wi+kpJ0gLjqqtKuon5+uiopKQluu63qN4Q1a6CgoLQdoKzZs8HHR5+rJqrrIVUsLEznZCooOHebiA4YF12k33YqopSusvr6a71vq1Y1K6dRr0zAsFNKlXStrU8LFizg6NGjDBkyhPvuu48NGzYwbtw4LrvsMgbY/+Bmz57N8OHDCQsLY+nSpSXHdu/eneTkZI4fP07//v25/fbbCQsLY+rUqeRVkKRt1apVjBo1iqFDh3LRRReVJDPMzs5m3rx5DBo0iMGDB7Nihc4kv2bNGoYNG0Z4eDiTJ0+u15/bqEdPPgm5ufD44+XXDx2qk9R9+SW8/nrlx3/+ub4hjx177jZ/f7j0Uvj0U93zyRFWKxw44FjAGDBA73/48Lnbtm3T3WGr69HUvr1+0zBVUK7n6Ai/prBUN9K7kuzmJcvYsdkyblxOfWY3l5iYGAkLCyv5fv369eLr6yvHjpXmrUqxJzTLzc2VsLAwSbbn0enWrZskJSVJTEyMuLu7y2/2FAxz5syR999//5xrpaamlqRIf/311+Xee+8VEZF//OMfcneZgqampkpiYqJ07ty5pBwpVSRVMyO9Xej4cZ3m4pZbKt5utYpMmSLSooXOE3W2ggKduO7WWyu/xuef65HRa9ZUX57CQpH//U/vXyYBZqV279b7zphxbt6ku+8W8fYWSU+v/jyG02BGeteOUm4NMnBv5MiRhIaGlny/ePFiwsPDiYyMJC4ujsMVPI2FhoYyZMgQAIYPH87xCmbjio+PZ9q0aQwaNIhnn32Wffa64++//54/l0mvHBgYyNatWxk/fnxJOYKCgurzRzTqy6OP6ifrf/2r4u1ubvDOO7qKavRoeO218tOC/vijbjCvqDqq2IwZEBCgq34qk56uG6BDQ3VX17Aw/dRfnYED9VzamzfrY269Vafvtlr1W83MmaaaqQlpVt1qFy2qent+fiJFRWn4+w9xajn8/PxKvt6wYQPff/89v/zyC76+vkycOJH8CkbGent7l3zt7u5eYZXUXXfdxb333stll13Ghg0bWLhwoVPKbzSQ/fvh3Xfh7rv1QLvKdOyoG63/+Ef4v/+D99+HpUv1DfqLL3TDdFVVjj4+ukF5+XLdwOzlVbp4eup5IN58UzeeX3ihPvf06Y7Nx6CU7hZ7yy26+mzJEvjgA91N9tQpM8CuiTFvGGXorrUWROpv4nZ/f3+ysrIq3Z6RkUFgYCC+vr4cOHCArVWlQqhGRkYGnTp1AuDdd98tWT9lypRy08SmpaURGRnJxo0biYmJASA11dHp1w2HHDgAb7wBVfzbVyk3V8877evrWE6lXr3g++/128aBA7p945FH9PzUM2fqoFCVefN0WefN04Ph5syBWbP0sUuW6MbxnTv1XNczZ9Z88p6QEN1wf/gw3HCDbndp2dKxtxSj0TABowxnpAcJDg5mzJgxDBw4kPvuu++c7dOnT8disdC/f38WLFhAZGRkra+1cOFC5syZw/Dhw2nTpk3J+oceeoi0tDQGDhxIeHg469evJyQkhKVLl3LFFVcQHh7ONWVH2Rp1s3Wrrh66/Xb9ZvDAA/pp2hE2m35D6NNHz6z26KOV9yA6m1Iwd64OGNdcoxvJz5wpP1ivMuPG6dHgMTE65ceePbBjhx7zEBury1R2DEdtde2q31b279cjz319635Oo+E42tjRFJa6pDcXESksTJXMzO1isWQ7fExzYBq9a+CHH/REOT17iqxcqSfJUaq04bqq3+WmTTr9OOjPTZvqVpa1a0X+9CeRnJy6ncc4r1GDRu9m1YZRHZOA0KhSVFRpeoqKOgmsWqWrcnr31gPlOnTQI5SPHNHVMW+/DW+9pbuJduigl44d9Wd0tE5d3akTvPeerhaq65zNU6boxTDqidOqpJRSbymlEpVSeyvZPlEplaGU2mVfHimzbbpS6qBS6ohSaoGzyni20tHeJj2IcZa9e/UAsz//Wd/k587VDc3Fveo+/lj3RBo8GDZs0EGgWK9eOg9UbKzuaXTxxXr7qVN6QNoTT5RWPx06pEdv1zVYGIYTOPMN4x3gZeC9KvbZJCKXlF2hlHIHlgBT0HOBb1dKfSUiVSSkqR8mn5RRoYQE3fXU11d3BV25Utfpv/eeDhATJsDLL+vJcVat0oPhKhISAhW0Y2Gx6LYLRzPPGoaLOO0xRkQ2ArXpejMSOCIix0SkEFgGzKrXwlVCKTfA3QQMo1RGhu4VlJEBq1frZH1Llugg8r//6TeBl17S+3z7beXBoioeHiZYGE2Cq997RyulfldKfauUCrOv6wTEldkn3r6uQTgjPYjRRBUW6vEJxe0LQ8qMz/H31xljd+7UvYq+/LLyqUoN4zzhykbvnUA3EclWSs0EvgR61/QkSqn5wHyArlUNbnKQm5uHCRjnq4ICnXLbESJ6VPIPP+jBc5U1Hiulu8AaRjPgsjcMEckUkWz716sBT6VUGyAB6FJm1872dZWdZ6mIRIhIRIij/dWroJRnvac4r6mW1aWMNhwnom/6U6bowWs336xTZVR3zIMP6hHJ//433HRTgxTVMBo7lwUMpVR7pXT6SaXUSHtZUoDtQG+lVKhSygu4Fviq4cplqqSajMOHdcqJRx7RvY3s2XkBnato+XIYOVL3btq7V/c+ev99XbW0ZUvF59y6VTdeP/20rnJ68MGG+VkMowlwZrfaj4FfgL5KqXil1K1KqTuUUnfYd7kK2KuU+h1YDFxrH0diAe4EvgP2A5+KSBUzsNQDq7UktbPuKWWtt/QgCxYsKJeWY+HChTz33HNkZ2czefJkhg0bxqBBg1i5cmW156osDXpFacorS2l+3jh2DCZN0t1Zn3hCp+hu315P6nPVVdC/vx4TkZ6ucx/FxOheTRs36uPHjdOBpsj+cHDkiN5/9GgdiF59VXeFNSm1DaOEkgbIztpQIiIiJCoqqty6/fv3079/fwDuWXMPu07vOvfA7GydZM3bG5EibLZ83N39cCSeDmk/hEXTK89q+Ntvv3HPPffw008/ATBgwAC+++47OnToQG5uLgEBASQnJxMZGcnhw4dRStGyZUuys7PPOVdqaipBQUHk5eUxYsQIfvrpJ2w2G8OGDWPjxo2EhoaW7HP//fdTUFDAInvGxbS0NAIDA6v9eSpS9nfYKJw4obuyZmXB+vXQs6dufN6+XQ+s275dd2H9+9/12Ah39/LHZ2bqKT7few9GjdKTEv3vf7qn0n336RxOtentZBhNkFJqh4hEOLKvGekNumuk1Wr/Rj9Riki9PFwOHTqUxMRETp48SVJSEoGBgXTp0oWioiIefPBBNm7ciJubGwkJCZw5c4b27dtXeq7FixfzxRdfAJSkQU9KSqowTfn333/PsmXLSo6tbbBodOLjdcbU9HSdunvwYL1+3Di9OCIgQDdkX3wx3HGHDjC33QYLF5YfcGcYRjnNKmBU+iZw6pTuVx8ejtWtkNzc/fj49MLTs36mR50zZw7Lly/n9OnTJUn+PvzwQ5KSktixYweenp507969wrTmxRxNg35eO3VKp+lOSoJ162DYsLqd7+qrdTrv7Gzo0aNeimgY5zNXj8NoHAIC9GdmplNGe19zzTUsW7aM5cuXM2fOHECnIm/bti2enp6sX7+eEydOVHmOytKgV5amvKKU5k2SiB4Fffq0brxOSNAD5EaNqp/zt21rgoVhOMgEDNApHzw8ICMDpfRLV30GjLCwMLKysujUqRMd7FUe119/PVFRUQwaNIj33nuPfv36VXmOytKgV5amvKKU5k3CihV6BjZ3d93g7Oamv+7QQTdcf/01jBnj6lIaRrPUrBq9q3TsmG4MDQ8nK/t3PD0D8fHp5qSSNi0N1ugdHa27wfbtq1NtFAcMNzf99YwZuoHaMIx6Yxq9a6NVK0hNhdxcM9rbFbKydBoOPz/46iud5tswjEbFVEkVO6sdw9Wjvc8r6enw+eclY13OUZyG4/Bh+OQTEywMo5FqFgHDoWo3T0/dlpGRYUZ7l1HnKsv8fLjkEv32EBkJuyoYB7NoEXz2GTz1lO61ZBhGo3TeBwwfHx9SUlIcu/G1agXZ2biJSXEOOlikpKTg4+NT2xPoN4eff9YD4uLjdRvEgw/qQAKwaZPedsUVeqCdYRiN1nnf6F1UVER8fLxjYxby8+HMGaxBfhR55uDt3cU+R0bz5ePjQ+fOnfH09CxdKaKT8n3xhZ4bYvToig9euFDPIvfUU7BggW4j+tvf4J13dIbXp57SM9j5++vBc61aNcSPZBhGGTVp9HZo4u+msgwfPtzBac8rUVgoEhAgOddPkPXrkZycw3U73/mooEDkxhtFQCQgQMTdXeTxx0UslvL7ffCB3mfePBGbrfy2tWtFunfX2319RfbsabjyG4ZRDhAlDt5jm/fj89k8PWHyZLw3RINAUdGZ6o9pTtLSYPp0nfH18cf1HNVXXw0PP6xHYMfZ573avFlnkZ00CV577dwEflOm6Oyxjz6qx10MHNjwP4thGDVmAsbZpk/HPSEJ3xNQWHja1aVpPI4f1wPmNm/WAeOhh3QV0ocf6rxMO3ZAeLiuopo9G0JDdTCobOpRPz+dLXb69Ab9MQzDqD0TMM42bRoAQdtNwCgRFaV7OJ06pXM43XBD6Tal9ARDv/2ms8beeade//XXcL4kPDQMAzAB41w4uxNIAAAgAElEQVTduiH9+xO0DQoLTZUUy5frCYVatNCTDk2YUPF+vXrp3lCLFumg0qtXw5bTMAynMwGjAmraNFrvhqKMeFcXxXVE4LHH9KRCQ4bomeiqSw/i5QV33w1DhzZMGQ3DaFAmYFRk+nTcCsFzi3Mn+mu0cnPh2mvhX//S1U3r10O7dq4ulWEYLubMKVrfUkolKqX2VrL9eqXUbqXUHqXUFqVUeJltx+3rdymloio63qnGj8fm7Ybv5qpTjp+X4uP1RESffQbPPqvHTHh7u7pUhmE0As5MPvgO8DLwXiXbY4AJIpKmlJoBLAXKTnIwSUSSnVi+yrVoQe6I9gT8nOiSy7vMxo1wzTWQk6MTAF5yiatLZBhGI+K0NwwR2QikVrF9i4gUz+qzFejsrLLURv7EfrSItSBHjri6KM6Xlgbz5+sGbV9f+OUXEywMwzhHY2nDuBX4tsz3AqxVSu1QSs13RYEKp+oJiqxfLqtmzyZMRGeH7d8f3nxTp+3YvRvCwlxdMsMwGiGXBwyl1CR0wLi/zOqxIjIMmAH8WSk1vorj5yulopRSUUlJSfVWrhYDLySnO8jK5fV2zkblxAn9FnHttdC5sx5r8dxzekCdYRhGBVwaMJRSg4E3gFkiklK8XkQS7J+JwBfAyMrOISJLRSRCRCJCQkLqrWz+/iNIvgA8ftmjq2zOJ59+qt8ifvpJj5v49VfTFdYwjGq5LGAopboCnwM3isihMuv9lFL+xV8DU4EKe1o5k4dHANkXhqKsNli9uqEv7xwWi652uuYancYjOlqPm3B3d3XJDMNoApzZrfZj4Begr1IqXil1q1LqDqXUHfZdHgGCgVfO6j7bDtislPod2AZ8IyJrnFXOqriPnkhhkEK++soVl69fiYk66d/zz+v0HevXQ9euri6VYRhNiNO61YrIddVsvw24rYL1x4Dwc49oeAGtR5M8+m06fPsNFBZWnkivsdu6Fa66ClJS4L334MYbXV0iwzCaIJc3ejdmAQGRpFwAKitH1/c3RStW6FxQXl66u6wJFoZh1JIJGFXw8xtA5kg/bD4esHKlq4tTc0VFcO+9er6JqCidE8owDKOWTMCoglLu+LUZScYoPz3yualNZ7t8uZ7k6NFHISjI1aUxDKOJMwGjGgEBo0gclaVnk/v9d1cXx3EielxF375w8cWuLo1hGOcBEzCqERAQSfIoG6KUfstoKjZsgJ07dTdaN/PPbBhG3Zk7STX8/UdRFASFw7o1rXaM556Dtm1NI7dhGPXGBIxqeHu3x9u7G+nj/fUTe3wjmFSpqAjy8yvfvm+fHmx4553g49Nw5TIM47xmAoYDAgIiOTXCnqdq1SrXFaSgAJYsge7ddWqPuLiK93v+eT2l6v/9X4MWzzCM85sJGA4ICBhFevvT2HqFuqYdo7AQXntNz5N9550QGqoH4U2aBAkJ5fc9dQo++ADmzYM2bRq+rIZhnLdMwHBAQEAkKMifMgh+/BGyshrmwlYrvPEG9O6t3xa6dIF162DTJvjuO53uY9IkHSSKvfyyrrL6618bpoyGYTQbJmA4oGXLoSjlSdo4P/20/913zr/o8eM6GNx+O7RvD2vWwM8/w0UXgVIwapRed+oUXHghnDkD2dnw6qtw+eX6bcQwDKMemYDhAHd3H1q2HEJirwRo1w7uuANeeKHqhufaEoF334XBg2HXLj2n9tatMG2aDhRlXXCBbtyOjdVB45lndCr2v/+9/stlGEazZwKGgwICIsnKi8K2ZjUMG6ZTbvTtq2/oVmv9XCQ5WScJvPlmPT/F7t0wd+65gaKscePgm28gJgYef1wHkdGj66c8hmEYZZiA4aCAgFHYbLnk9nKHtWvh++/1OId58/TcEqtW1S11yHff6ZxPq1bpN4Uff9S9oRwxcaI+rmNHWLiw9mUwDMOoggkYDgoI0HN8Z2Zu1SsmT4Zt2/TsdYWFcNlluu3g5Mmandhm028GM2ZASAhs3w733VfzSY0mT9ZjRKZMqdlxhmEYDjIBw0E+Pj3w9GxTGjBAVxXNmaMHyj3zjH5LGDBA92xy5G0jIwNmz4ZHHoHrr9dTpYbXYSqQqqquDMMw6sgEDAcppfD3H0Vm5q/nbvT01G8Fe/botofbb9dP/EeOVH7CfftgxAj49ltYvFhPbOTr67wfwDAMo44cChhKqbuVUgFKe1MptVMpNdWB495SSiUqpSqck9t+vsVKqSNKqd1KqWFlts1VSh22L3Md/5GcJyAgktzc/RQVpVe8Q69e8MMPsHQp7NihezrNnQsPPaS7u371lV7/0Ue6W2xmpm6ruOsu83ZgGEaj5+gUrbeIyItKqWlAIHAj8D6wtprj3gFeBt6rZPsMoLd9GQW8CoxSSgUB/wIiAAF2KKW+EpE0B8vrFAEBowDIytpOUFAlbQVubvoNY+ZM3b31hx/g9Olze1KNHq3nq+jY0cmlNgzDqB+OBozix9+ZwPsisk+p6h+JRWSjUqp7FbvMAt4TEQG2KqVaK6U6ABOBdSKSCqCUWgdMBz52sLxOERAwElBkZv5SecAo1qkTfGwvrtWqB9YlJOglPx+uuKLpzhFuGEaz5GjA2KGUWguEAg8opfwBWz1cvxNQNoNevH1dZetdysOjFX5+g0hPXw884viB7u76TaJjR91uYRjnERH9DJSfr5Mjt2hR/TEWC6Sn6xfys5eKHkXd3PTzVVWPqUVFkJOjP729dVk8PWtf2yuiOzFaLPqcVqs+19nltdn0YrWWLjb73VGp8ovVCrm5kJdXuuTn6/N4eOjF3V1/enmBn59u2vTz079XpXS5cnJ0hqLixWLRtdzO5mjAuBUYAhwTkVx7ldE85xXLcUqp+cB8gK5duzr9esHBM4mNfZaionQ8PVs7/XpG3dhsuqkoPV1/eniU3ky8vfViteoOa+nppZ+ZmfoP1N+/dAkI0H/YaWmQmqo/09L0/l5e0LJl+cXDQ/9hFy/Z2frTZiu98RTfSGw2/YefnV3+02bTNxA3t9LP4huP1apvFMWfRUU6oXFhof4sKNDHBwbqPJTBwfqzTZvSn9tiKV0KCiApSb8MJybqzzNn9A3N01P/PJ6eenF31/sXB4qyOneGPn10CrQ+ffRwotOn4fBhvRw6pMeZWiw1//f08Sm/FBbq32lurv75z+bmVrovlP6+in/2s2/sxb9fm63i87maj4/+vZ/dCbNdO/07djZHA8ZoYJeI5CilbgCGAS/Ww/UTgC5lvu9sX5eArpYqu35DRScQkaXAUoCIiAinT7odHHwJsbFPk5a2lrZtr3b25c47eXmlN6IzZ0qfCItveMVfl70ZFn9dUFB60y3+zM0tf9Mr3jcnpzQA2OrjXbiBeHrq4FQ26JR9arVa9c2i+CnU3b108fLSgSAgoPTr4gAXFwe//aaTCVSW0cbdXQeTdu300quX/vT1Lf33Kfvp7a2DavFbRYsWOtAWB4bPPtOBtZivrw4i4eE6oUH79np98RN68c9XEau1fIAqXjw9yz+F+/npdYWFpU/v+fn6a6VKf1fFv7viyShFSpfiIF0cIMs++Zfdp7i8ZYN58fkrOm/xv5uvb+nvq/j3J3Lu/+P8fP3/Oze39P96bu65DzItW+qHgobgaMB4FQhXSoUDfwPeQDdkT6jj9b8C7lRKLUM3emeIyCml1HfAk0qp4l/DVOCBOl6rXgQEROLhEURKytfNMmDk5MDevTprSUyM/qM5+48iL0/fOMq+Mqen6wCRmVn7axc/xfv5lX76+uo/uLKv8sV/lIGB0Lq1/gwM1H9cZW88xZ/u7nq/1q2hVSv96e+vtxWXv/jnsVohKKj0nEFB+hiLRQexskthYWk5i8vs63vujUdE32BattQ3YWfLydFlK74Rnn3zrE+pqTqPZrt2ukbWdAZs2hwNGBYREaXULOBlEXlTKXVrdQcppT5Gvym0UUrFo3s+eQKIyGvAanRD+hEgF3s1l4ikKqUeB7bbT/VYcQO4qynlTlDQdFJTv0XEilI1HJHdBGRk6CfS+Hj9GRsL0dE6SBw9Wvo6XPw0dXY9bfETUECA/gwOhh49Sp9cyy7+/udWd5S9iZVdGvvNJiTE1SVwTHEAawhBQXoxzg+OBowspdQD6O6045RSbthv/FURkeuq2S7AnyvZ9hbwloPla1DBwZeQmPgRmZnbadUq0tXFqRUR/cS/Z0/55dChc6f7UEpXT4SHw0036eEl4eHQrVvjv4kbhlF/HA0Y1wB/QI/HOK2U6go867xiNW5BQdMAN1JSvm70ASMvT78dHD6sB56XbXhMSSndr107GDRIjzPs2lXP1dS5s/7s0MH0ADYMw8GAYQ8SHwIjlFKXANtEpLLBeOc9T88gWrUaQ2rqN/To8W9XF6ectDQ9z9LmzXpivu3by/f26NRJNzxecYWeFnzQIL00leoUwzBcx6GAoZS6Gv1GsQE9iO8lpdR9IrLciWVr1IKDL+bYsQUUFCTg7e26ISIi8Pvv8PnnOvPI7t16nacnRETAPffAyJG6e2OvXiZdlWEYtedoldQ/gREikgiglAoBvgeabcAICtIBIyXlGzp2nN+g17bZdGLbzz/Xy7FjuofLuHHw2GMwdqwOEiY4GIZRnxwNGG7FwcIuhWae6dbPLwxv724NGjDS0+Gtt2DJEh0kPD31FN8PPACzZplqJcMwnMvRgLHGPjaiOJfTNegusc2WUorg4Is5ffodrNZ83N19nHatffvgpZfg/ff1wJ2xY+HRR+HSS/UYAMMwjIbg0FuCiNyHHk092L4sFZH7nVmwpiA4+BJstlzS0zfU+7ltNvj6az2txsCBeurwa6+FnTt1Y/YNN5hgYRhGw3L0DQMRWQGscGJZmpzWrSfi5taC1NRvCA6eXi/nzMvTcym98AIcPKi7tj71FNx2m07bYBiG4SpVBgylVBZ6PopzNqHH3QU4pVRNhLt7CwIDJ5OS8jW9ei3GgYzvlUpKgpdfhlde0fl+hg2DDz/UM8B6VjtE0jAMw/mqDBgi4t9QBWmqgoMvISXla3Jz9+PnN6DGx+fl6beJp57S+YcuvRT+9jcYP96MojYMo3Fp1j2d6kNQ0EwAUlK+qdFxNht88AH07Qv//Kduq4iO1mMpJkwwwcIwjMbHBIw68vHpgp/fYFJSvnb4mE2b9GQnN96ou8KuXw9ffgn9+zuxoIZhGHVkAkY9CA6+hIyMnykqqjqhbno63HKLrm46dQrefVen7pg4sWHKaRiGURcmYNSDNm1mA1aSk7+odJ9vvtG5m957DxYs0Mn/brrJOXMQGIZhOIO5XdUDf/8IWrToxZkzH52zLS1NZ4C95BI9L8DWrbqB26TtMAyjqTEBox4opWjb9nrS09dTUHCyZP3q1fqt4sMP4aGHICpKJwQ0DMNoikzAqCft2l0HCImJn2Cz6SSAF1+sB9tt2waPP94w028ahmE4i1MDhlJqulLqoFLqiFJqQQXbX1BK7bIvh5RS6WW2Wcts+8qZ5awPvr59adlyOMePf8GcOfCvf+leUNu26UF4hmEYTZ3DqUFqSunJrpcAU4B4YLtS6isRiS7eR0T+Wmb/u4ChZU6RJyJDnFU+Z8jP/z9uvnkEx48Lzz+vuOceM57CMIzzhzPfMEYCR0TkmIgUAsuAWVXsfx2l2XCbnB9/hFmz5pGU1Jm3336fv/7VBAvDMKomImQXZlNoLUSkoixMjYvT3jCATkBcme/jgVEV7aiU6gaEAj+WWe2jlIoCLMDTIvKlswpaVx9/rKuf+vZ146mn/kK7dtsQubFOuaWMhpGcm8yJ9BO08W1DiF8Ivp4N331NRLDYLHi61z5pWHRSNBn5GXTw70CHlh3w9qhbg5mIEJ0UzbdHvuVk1kkCvAPw9/InwDuAAO8Agn2DmdBtgsNlttqs7E3cy9b4rWxN2MrW+K3kW/K5tM+lXNH/CsZ2HYuHW+W3o9yiXNLy0kjLTyv5TM9PR6Hw9vDGy90Lb3dvvD28aevXlrCQsHr7+8styuVM9hmyC7Pp26YvXu6OTXBvExvxmfEcTD7IgeQDHEw5SHxmPCl5KaTkppR8WsUKgLtyx9fTt2TxcvdCEGxiQ0QQBHflTmTnSGb1ncXUnlPx927Y7E3ODBg1cS2wXMT+m9O6iUiCUqoH8KNSao+IHD37QKXUfGA+QNeuXRumtGWsXKmDxdixOq1HdvZEDh36kKysHQQEmC5RjdX2hO28tO0lPtn3CYXWwpL1fp5+hPiF0M6vHaM6jeLC0AuZ0H0CrX1aV3iefEs+x9KOkZGfQW5Rbrml0FqIh5sHHm4eeLp74uHmgZty43T2aWLSYjiWfkx/ph0jqzCL1j6tad+yPe382tG+ZXvat2zP8A7DmdZrGm392p5z7UJrISuiV/Dy9pfZErel3LbgFsF09O9IaGAo84fNZ2bvmdXeQHMKc/gx5kdWH17N6iOric2IBcDX05fcotxz9u8b3Jfnpj7Hxb0vrvDcNrGx6uAqlmxfwpa4LeQU5QDQxrcNozuPRinF6ztf56VtL9HGtw2z+s7isr6XYbFZOJh8kEOphziUopfk3OQqy362fm36cePgG7lh8A10bVX+vnAq6xRfHfyKLw9+ybaEbfh4+ODn6Yeflx8tvVri5+lHTlEOZ7LPcDr7NFmFWSXH+nj4MKLjCMZ0GcMFXS5gdJfR+Hj4cDD5IAdTDpZ8Hkg+wKGUQ+RZ8kqODfAOoFurbrTxbUNY2zCCWwQT3CKY1j6tKbIVlfy/ySnMIdei//+4KTcUCqUUCkWeJY9vDn/D+7vfx8vdi8mhk5nVdxaX9r2Ujv4da/Q7qg3lrNcgpdRoYKGITLN//wCAiDxVwb6/AX8WkS1nb7Nvfwf4uro5xCMiIiQqKqquRXfYunV6fMXQofprf38oKkpjy5b2dOr0Z3r1er7BytIYiAgx6TF4uHnQ0b9jhU+MiTmJbDqxiY0nNrI5bjNWm5VOAZ3o5N+Jjv4d6eTfiRC/ECw2C/mWfPIt+RRYCkq+LrQWUmAtoMBSUPKZU5Sjl0L9mV2YTSvvVgxsO5BBbQcxqN0gBrUdREuvlnwW/Rkvb3uZXxN+paVXS+aGz2Vy6GRS8lJIykkiKVcv8Znx/Br/K3mWPNyUG8M7DOfC0Avp2qorh1IOldwcjqcfRypM6Fy1Fh4tCA0MpUdgD3q07kGwbzBJOUmczjldcqM6mXWy5CYb0TGCGb1mMKPXDDoHdOaNnW/wvx3/40zOGXoG9uRPI/5E/zb9OZl1klPZpziZdZKTWSeJOhlFQlYCg9oOYsHYBVwddnW5f5fMgkxWHVzFZ9GfsebIGgqsBfh5+jGl5xRm9prJjN76elablezCbLIKs8gsyGRf4j4eWv8Qh1IOMTl0Mv+d+l/C24cDOpB9uPtDntnyDAeSD9CtVTcu7XMpkZ0jiewcSY/AHiUBJqcwhzVH1vD5gc9ZdXBVuZtzh5Yd6NumL32C+tC9dXeCWgQR2CKQQJ9AAlsElgTxQmthuf8PB1MO8sHuD9gUuwmAid0ncv2g60nOTWblwZVsjd8KQM/AnlwYeiE2sZX8/8kuzCanKAdfT99zgre3uzfbT25nS9wWdp7aSZGt6Jx/V4UiNDCUvsF96demX+lnm76082tXL289FpuFn2N/ZuXBlaw8uJJjacdo5d2K5H8kV/mWVhml1A4Rcejp1pkBwwM4BEwGEoDtwB9EZN9Z+/UD1gChYi+MUioQyBWRAqVUG+AXYFbZBvOKNGTA2LwZpk2DXr1gwwYIDCzdtnfv5WRm/sro0XHotn/nyyvKY92xdYzoOIIO/h0a5JqF1kJ+O/UbP8f9zObYzfwc9zOJOXomX3flTqeATnRt1ZWurbri4+7DlvgtHEg+AOgb5uguo/H19CUhM4GErISSY6tTtvrBy92r5Kmw7BNiSl4Ku8/sJjWvNF2Lt7s3BdYC+gT34c4RdzJ3yFwCvCvP0F9gKeDXhF/5MeZHfoj5ga3xW7HYLPh6+tI3uC992/Slb3Bf+gT3IbhFcLnqBF9PXzzdPbHarBTZirDYLCVLW7+2Dt08bGJj1+ldrD68mm+PfMvW+K3YxAboG9PM3jO5c+SdTO05FTdVcXNkkbWIj/d+zH9+/g/RSdF0b92d+y64j9Y+rfl036clQaKjf0eu6n8Vl/W9jLFdxzpUpVVkLeK1qNdY+NNC0vLSmDdkHv1D+rNo6yISshIIbxfO/WPuZ07YHIduZAWWAn6J/wV/L3/6BPepc3VLTFoMH+z+gPd3v8/h1MOADryz+85mdr/ZDAgZUOsbeF5RXknwsNqsJUGhV1AvfDycN/vm2YqrDg+mHOSK/lfU6hyNImDYCzITWAS4A2+JyBNKqceAKBH5yr7PQsBHRBaUOe4C4H+ADd0wv0hE3qzueg0VMHbsgAsvhPbtYeNGaNeu/PbExM+Ijr6a8PAfCAy80Kllybfk8/qO13lq81Ocyj6Fh5sHl/e7nD+P+DPju40/5w8iqyCLDcc3sPHERnw8fEqe7os/vT28OZZ2jKOpRzmadpRjaceISY8hqyCr3JN9obWQ5Nxk8i35gH5aG9N1DBd0vgA35UZsRiyxmbGcSD9BbEYs2YXZjOo8inFdxzG+23iGdRh2Tl1wobWQU1mnSM5NxsvdCx8Pn5LF28MbHw8fPN08Hf4jFxFOZZ9iz5k97Encw4n0E1zS5xKm9JxS6Q22KjmFOaTlp9HRv2Otjq+r1LxU1h1dx7G0Y1wddjU9g3o6fGxx9dBTm5/i14RfAejo35E5A+YwZ8AcRncZXeufKS0vjSc2PcHiXxdTZCtiUvdJ/GPMP5jWc1qjaMcTEXaf2U1QiyC6tOri6uI0Oo0mYDS0hggY+/bp9OMtW+qss10q+P9nteaxZUtbQkKuoV+/N87ZbrFZcFfudfpjKrAU8MbON3hq81MkZCUwvtt4/hr5VzbHbuat394iLT+NsJAw/jTiTwxpP4QfY35k7dG1/BL/CxabBS93Lyw2S8kTa2VCfEPoEdiD1j6tyzcuunsT2CKQ0Z1HM6brGNq3bF/rn8VoOCLCrwm/YhMbkZ0j6zXwxWbEklmQycC2A+vtnIbzmYDhJBkZMGgQWCw6WPSs4gFv//65JCevZMyYMwgebEvYVlK1sOPUDrzdvQlqEVRu8fbwLqm2KLLqagyrWPF089Q3ag99o/Zy92LdsXXEZ8YztutYHp34KJO6TyoJQLlFuSzbu4wl25ew89ROQFdhDOswjCk9pjC151Qu6HIB7m7unM4+TUJmAiezTpKQlUC+JZ8egT3oGdiTHoE9GrwXhmEYDcsEDCf54x/hjTdgyxY9n8XZbGIjOTeZ+Mx49id8xbaDjxLHWH5KiCY1LxU35UZk50gmdJuAxWYhNS+1ZEnJS6HIWlSuR42nmyduyg2LzXJOdVDPwJ48NP4hJodOrvRNRUTYlrCNuMw4JnSbQIhfiNN+N4ZhNE01CRiNpVtto/fDD7B0Kdx3X2mwKLAU8EPMD3yx/wvWH19PXGZcuS6aAMHe27m037XM6DWDKT2nENQiqMHKrJRiVOdRjKp4+IthGEaNmDcMB2Rn66ooLy/Y9GsWP8Z/wxcHvmD14dVkF2bj7+XPlJ5T6B3Um84BnUsWa9oH5CS+SOSoA/j69q33chmGYdSVecOoZw88ACdOwGfrYhn+9hjiM+Np69eW6wZex+X9LufC0Asr7IZY2KYrvyS/Rlzcf+nbd6kLSm4YhlF/TMCoxsaN8PLL8Me70/nXwZlkFWSx7sZ1TOo+CXe3qsdYeHm1pUOHeZw69Rbduz+Gt7fpSWQYRtNl5sOoQm4u3HordO9ZQPTgyzmUcogvrvmCi3pcVG2wKNa5898QKSIh4UUnl9YwDMO5TMCowsMPw5GjNnrcO49NcRt4e9bbTAqdVKNz+Pr2IiTkShISXsViyXRSSQ3DMJzPBIxKREXBCy/AkL89yI9JH/PkhU9y/eDra3WuLl3+gdWawalTr9dzKQ3DMBqOCRiVePdd8Ih8lV0t/8Mfh/+RBWPPmTDQYQEBI2jdehJxcS9gsxVWf4BhGEYjZAJGJT478iZFU+/kkj6X8PLMl+ucE6dLl39QWJhAYmKTnSPKMIxmzgSMs+QU5nDVBzdzJvI2entMYtmVy2qVMvhsQUHT8PMbTGzsM0g1+ZsMwzAaIxMwytiftJ+Rb4zk86PvwYZ/seLy7/Dz8quXcyul6Nr1H+TmRpOSsrpezmkYhtGQTMCw+2D3B0S8HkFSThLjjn9Hx0MLGTigfueyCAm5Gm/vrsTFPVOv5zUMw2gIzT5g5BXlMX/VfG784kYiOkaw4/Zd7Fk5halTob5T+bu5edKly71kZGwiPX1j/Z7cMAzDyZp9wBD0/AAPjH2AH276gdOHO5KWBlOnOud6HTrcjpdXJ44evY/zKY+XYRjnv2afGsTX05dfb/u1ZFrFtWv1+osucs713N19CQ39NwcPziMp6VPatr3GORcyDMOoZ059w1BKTVdKHVRKHVFKnTOQQSl1s1IqSSm1y77cVmbbXKXUYfsy15nlLDsH79q1MHQohDhx6oj27W/Ez28wx449gM1W4LwLGYZh1COnBQyllDuwBJgBDACuU0oNqGDXT0RkiH15w35sEPAvYBQwEviXUirQWWUtlpWlJ0dyVnVUMaXc6dnzWfLzY0hIeMW5FzMMw6gnznzDGAkcEZFjIlIILANmOXjsNGCdiKSKSBqwDpjupHKW+OknPf2qswMGQFDQVAIDp3LixOMUFaU5/4KGYRh15MyA0QmIK/N9vH3d2a5USu1WSi1XSnWp4bH1au1aaNECxoxx9pW0nj2fxWJJJzb2yYa5oGEYRh24upfUKqC7iAxGv0W8W9MTKKXmK6WilFJRSUlJdSrM2rUwYQJ4nzsXklO0bDmY9u3nEh+/mLy84w1zUcMwjFpyZsBIALqU+b6zfV0JEUkRkeJW3xA0tN0AABNkSURBVDeA4Y4eW+YcS0UkQkQiQurQUh0bCwcPNkx1VFnduz+OUm7ExPyzYS9sGIZRQ84MGNuB3kqpUKWUF3At8FXZHZRSHcp8exmw3/71d8BUpVSgvbF7qn2d06xbpz8bOmD4+HSmc+e/kpj4EZmZ9T8fuWEYRn1xWsAQEQtwJ/pGvx/4VET2KaUeU0pdZt/tL0qpfUqp34G/ADfbj00FHkcHne3AY/Z1TrN2LXTsCAMq6sflZF273o+nZxuOHLnHJCY0DKPRUufTaOOIiAiJiqr5U7rVCm3bwqWXwjvv1H+5HHH69LscOHAzPXu+QJcu97imEIZhNDtKqR0iEuHIvq5u9G4Udu6E1NSGr44qq127mwgOvoSYmAfJzT3kuoIYhmFUwgQMStsvnJUOxBFKKfr0+R9ubt4cODAPEavrCmMYhlEBEzDQ7RdDhuhqKVfy9u5Ir14vkZm5hfj4F11bGMMwjLM0+4CRlwdbt7q2Oqqsdu2uJzj4MmJi/klu7kFXF8cwDKNEsw8YLVpAfDz89a+uLolWWjXla6qmDMNoVJp9wABo0wbat3d1KUp5e7end++XyMz8hbi4F1xdHMMwDMAEjEarbdvraNPmcmJiHiI7e6+ri2MYhmECRmOlq6ZexcOjNdHRc7BYsl1dJMMwmjkTMBoxL692DBiwjNzcQxw6NN9M6WoYhkuZgNHIBQZOJDT0cRITP+bkyddcXRzDMJoxEzCagK5dFxAUNJMjR+4xCQoNw3AZEzCaAKXc6N//Pby82hMdPcfM0GcYhkuYgNFEeHoGExb2GQUFCRw4MNdktTUMo8GZgNGEBASMpGfP/5KSsorY2P+4ujiGYTQzHq4ugFEznTrdSWbmFmJiHsTTM4SOHW9zdZEMw2gmTMBoYpRS9Ov3DhZLOocOzcfdvQXt2l3v6mIZhtEMmCqpJsjNzZuwsM9p3Xoi+/fPJSlphauLZBhGM2ACRhPl7t6CgQO/IiBgFNHR15Kc/LWri2QYxnnOqQFDKTVdKXVQKXVEKbWggu33KqWilVK7lVI/KKW6ldlmVUrtsi9fObOcTZWHR0sGD15Ny5ZD2LfvSlJT17m6SIZhnMecFjCUUu7AEmAGMAC4Tik14KzdfgMiRGQwsBx4psy2PBEZYl8uc1Y5mzoPj1YMHvwdvr792Lt3lgkahmE4jTPfMEYCR0TkmIgUAsuAWWV3EJH1IpJr/3Yr0NmJ5TlveXoGER6+jhYterNnz0zOnPnQ1UUyDOM85MyA0QmIK/N9vH1dZW4Fvi3zvY9SKkoptVUpNbuyg5RS8+37RSUlJdWtxE2Yl1dbhg7dSKtW49i//wZiY58xyQoNw6hXjaLRWyl1AxABPFtmdTcRiQD+ACxSSvWs6FgRWSoiESISERIS0gClbbx09dS3hIRcw7Fj93PkyD1mRLhhGPXGmeMwEoAuZb7vbF9XjlLqIuCfwAQRKSheLyIJ9s9jSqkNwFDgqBPLe15wc/NmwICPOHq0I/HxL1BYeIp+/d7D3d3H1UUzDKOJc+Ybxnagt1IqVCnlBVwLlOvtpJQaCvwPuExEEsusD1RKedu/bgOMAaKdWNbzilJu9Or1PD17PkdS0mf89tsYEhM/xWYrcnXRDMNowpwWMETEAtwJfAfsBz4VkX1KqceUUsW9np4FWgKfndV9tj8QpZT6HVgPPC0iJmDUUJcuf2PAgM+wWNKJjr6GrVu7c/z44xQWnnF10QzDaILU+dQwGhERIVFRZr6Is4lYSUn5loSEl0hLW4tSnoSEXE337g/j69vX1cUzDMOFlFI77O3F1WoUjd6GcynlTps2lxAe/h0jRx6gY8c7SElZyfbtgzh6dIGZL9wwDIeYgNHM+Pr2pXfvxYwadYS2bf9AXNx/2L69P4mJn5luuIZhVMkEjGbKy6sd/fu/w9Chm/H0bEN09NX8/vsUcnL2ubpohmE0UiZgNHOtWo1h2LDt9Or1EllZUWzfPpAdO0YQG/ss+fknXF08wzAaEdPobZQoLEzi9Ol3SUr6hKws/Xv09x9F27ZX0779XDw9g11cQsMw6ltNGr1NwPj/9u49Rq6rPuD493fvPHd29uHNYlyv1/aGhODg4BDXpAlNU5e0aQsNIGhCAaEKNaqaliC1tAlq1TYqEpXaQtQiAQqoSZtCDMFgtX9QE9IUaBp784CA7biJ49a7fuz6ta953/vrH/fseLxy8PU+PDuzv490dOfeuXvnnJ27+5tz7p3zMxdULB5ibGwH4+M7mJ5+Ht/vYnDwPgYG7sX3O5pdPWPMIrG7pMyCZbNDrF9/H1u3PsfWrT+kp+cXePXVT/LMM1dx9OhDhGGt2VU0xlxmFjDMRXV2XsfmzbvYsuUpMplBDh78HYaHN3P8+CNMTu6hVBqxAGLMCmA5vU1sPT23cP31/8XJk9/k0KH7OXDgIw3PCqnUalKptWQy68lmh8hkhshmrySTGSKTGcTzUk2ruzFm4SxgmEsiIvT3v4e+vncxM/MjyuWjVCqjlMtHKZdHqVRGKRT2c+rUv9EwlySel6G391fo738vfX3vIpnsbWIrjDHzYQHDzIvnJcjn30o+/9YLPq8aUqkco1g8RKl0iKmpZzl5cienTn0LkQQ9Pdvp738vnZ03kEz2kUz24ft5ROQyt8QYE5fdJWUuG9WQqalhxscfZ3z8cUql82erF0mSSKwimezF87J4XhqRNJ4XlVRqNR0d19RLJrOBKBOwMWa+LuUuKethmMtGxKOraxtdXdsYGvo0hcI+isVXqFZPUa2eolabXZ4hDMuulKjVJgjDEpOTT1Otnmw4Xopsdgjf78b3O/C8jvpybnCxITBjFs4ChmkKESGXu5Zc7tpL+rlq9RSFwksUCgcoFA5QLB4iCKYJwwKVynHCsEAQzFCpHCdKJR9JJleTzV4JKGFYJAgKbt8ivp8jl3szudxmOjs3k8u9mY6OawiCApXKMVeOUy4fA5SOjjeRy21yPZwL32gYHb9CItFtw2ymbVjAMC0lmeyju/smurtv+qn7hWGNUukwhcL+huDyCp6XJJnsx/Oy9d5IrXaWmZkXOXNmN6rxk0x5Xtb1YN5IGJapVE5QqZygWj1BEEy7fTpIp9eRyawjnV5HOj2A56VRDeoFAjwvQzZ7NbncJrLZq/H97EJ+Ta/xOykzNfUcExM/IAgm8P1OfL8Tz8vh+50kk73k8z9LItG1KK9XKv0fo6N/z9jYY3R338Lg4Cfo7HzLohzbNIddwzDGCcMqxeJBpqdfpFh8Cd/Pk0qtIZVaQzodLVVDF4T2MTOzj0JhH4XCS/VhsNmSTK7G81KUyyOUy0colY5QLh+hUol6KecIIr4LHFrflslspKPjGjwvTRBMEwRTbjlNEBRcz8ZH5FxJJHpJp9eSTg+QSq0lnV6L73cwObmXyckfMDm5t+HONZlTj1k+XV030tv7Dlatuo18fhuel7yk3+Pk5DAjI3/L2NjXAOjt3c7k5NMEwTS9vbexbt0n6O19h/W8lgmbGsSYZSr6gmPoLtZ79X+aQVCiWDxIobCfmZn99Z6RakAika/3Bnw/j+dlAHU9lBAIUK1RrZ6mXB6lXB4hCCbqrymSJJ+/ga6um+nuvpnu7ptIJl9HGJYagtA0lcpxzp79D86c2e3mElN8P08msxHVirumVEG1jGqNRKKXZPIKksn++nJqag8TE9/D9/OsWXM3AwN/QCaznmr1LEePfp7R0QepVI7T2bmF/v73o1prGB4sEIZFQPC8JCLnCoTUahOunCUIosdRoO53dYhKIpEnCKap1SYJgkm3nCIMK0DofmezS0Uk4V4n4V43cV6JAnOiHpij9+3cY89L4XmZ80qUlTpseH+i98r3O84L6q81ZKkaUq2edresj9Tf10rlBMnkFWQyGxrKIJ6Xnvc5uWwChojcDjwI+MBDqvrpOc+ngUeAG4BTwJ2qetg9dz/wUSAAPqaq377Y61nAMCYSBDOUy6PUapPkctde8hBXtXq6HjzK5aP1O9VEUm6ZoFY7Q6UyTrU6TrV6kmp1nFRqNWvXfow1az56waGtMCxz4sSjHDnyNxQK+wEQSdeHB88FwyqqVcKwSpTtGRKJHhKJ7vrS97sIw5mGOoxTq52pv5bn5UgkuvD9LhKJPCJp1zPz6ksA1Zor1YYSuG3nL6N//qHrEYZue/WShjIbeV6OVOr1QEAQFAnDImFYOu/6W8PeJJN9VKunif4tnpPNvpG3ve3AvOqwLAKGROH3IHAbMALsBT7QmJtbRH4PuE5Vf1dE7gLeo6p3isgm4CvANuBngO8AV2v0Lr0mCxjGNJeqxhpqUlXCsOA+jS/erdFhWCUMC/h+52W95Vo1qN/VF5Vyw7Ch5+riEwRTDb2FUfdl1+Oud5N119ayeF6GRKKnYXhxgFTq9XhegjCsUakcpVQ6XC9hWGFo6K/mVfflclvtNuBlVT3kKvVV4A5gX8M+dwB/4R5/HfgHic62O4CvajTg+qqIvOyO9/QS1tcYs0Bxr0uICL6fW/TX97wknte96Me9GBEf3++IMZPzFWSzGxf0Wp6XIJMZJJMZBG5Z0LEu+bWX8NhrgSMN6yNu2wX30ai/NwH0xfxZAETkbhEZFpHh8fHxRaq6McaYuVp+tlpV/aKqblXVrf39/c2ujjHGtK2lDBijwLqG9QG37YL7SHQ7QjfRxe84P2uMMeYyWsqAsRe4SkQ2SnSP2V3Arjn77AJm58h+H/Bdja7C7wLuEpG0iGwErgL2LGFdjTHGXMSSXfRW1ZqI/D7wbaLbar+sqj8RkQeAYVXdBXwJ+Cd3Ufs0UVDB7beD6AJ5DbjnYndIGWOMWVr2xT1jjFnBLKe3McaYRWcBwxhjTCxtNSQlIuPA/87zx68ATl50r9ZkbWtd7dw+a9vysF5VY30noa0CxkKIyHDccbxWY21rXe3cPmtb67EhKWOMMbFYwDDGGBOLBYxzvtjsCiwha1vrauf2WdtajF3DMMYYE4v1MIwxxsSy4gOGiNwuIi+JyMsicl+z67NQIvJlERkTkR83bFslIrtF5H/csreZdZwvEVknIk+KyD4R+YmI3Ou2t3z7RCQjIntE5IeubX/ptm8UkWfc+fmYm5etJYmILyLPi8i/uvV2atthEXlRRF4QkWG3reXPy7lWdMBwWQE/B/wqsAn4gMv218r+Ebh9zrb7gCdU9SrgCbfeimrAH6rqJuBG4B73frVD+8rAdlV9C7AFuF1EbgT+GviMqr4BOEOUtrhV3Qvsb1hvp7YB/KKqbmm4nbYdzsvzrOiAQUNWQI2S6M5mBWxZqvqfRBM5NroDeNg9fhh492Wt1CJR1WOq+px7PEX0z2ctbdA+jUy71aQrCmwnykYJLdo2ABEZAH4deMitC23Stp+i5c/LuVZ6wIid2a/FrVbVY+7xcWB1MyuzGERkA3A98Axt0j43ZPMCMAbsBl4BzrpslNDa5+dngT8GQrfeR/u0DaLg/u8i8qyI3O22tcV52Wgpc3qbZUhVVURa+tY4EekEHgc+rqqTjXmkW7l9bgr/LSLSA+wErmlylRaFiLwTGFPVZ0Xk1mbXZ4m8XVVHReR1wG4ROdD4ZCufl41Weg9jpWT2OyEiawDccqzJ9Zk3EUkSBYtHVfUbbnPbtA9AVc8CTwI/B/S4bJTQuufnzcBviMhhomHf7cCDtEfbAFDVUbccIwr222iz8xIsYMTJCtgOGjMbfgT4VhPrMm9u3PtLwH5V/buGp1q+fSLS73oWiEgWuI3oGs2TRNkooUXbpqr3q+qAqm4g+hv7rqp+kDZoG4CI5EQkP/sY+GXgx7TBeTnXiv/inoj8GtH46mxWwE81uUoLIiJfAW4lmi3zBPDnwDeBHcAg0Wy+v6mqcy+ML3si8nbge8CLnBsL/yTRdYyWbp+IXEd0YdQn+iC3Q1UfEJEhok/lq4DngQ+parl5NV0YNyT1R6r6znZpm2vHTreaAP5FVT8lIn20+Hk514oPGMYYY+JZ6UNSxhhjYrKAYYwxJhYLGMYYY2KxgGGMMSYWCxjGGGNisYBhzDIgIrfOzuJqzHJlAcMYY0wsFjCMuQQi8iGXt+IFEfmCmzBwWkQ+4/JYPCEi/W7fLSLy3yLyIxHZOZsPQUTeICLfcbkvnhORK93hO0Xk6yJyQEQelcZJsoxZBixgGBOTiLwJuBO4WVW3AAHwQSAHDKvqtcBTRN+uB3gE+BNVvY7o2+mz2x8FPudyX9wEzM5oej3wcaLcLENEczAZs2zYbLXGxPdLwA3AXvfhP0s0oVwIPOb2+WfgGyLSDfSo6lNu+8PA19ycQ2tVdSeAqpYA3PH2qOqIW38B2AB8f+mbZUw8FjCMiU+Ah1X1/vM2ivzZnP3mO99O4zxKAfb3aZYZG5IyJr4ngPe5nAezOZvXE/0dzc66+lvA91V1AjgjIj/vtn8YeMplChwRkXe7Y6RFpOOytsKYebJPMMbEpKr7RORPiTKreUAVuAeYAba558aIrnNANKX1511AOAT8ttv+YeALIvKAO8b7L2MzjJk3m63WmAUSkWlV7Wx2PYxZajYkZYwxJhbrYRhjjInFehjGGGNisYBhjDEmFgsYxhhjYrGAYYwxJhYLGMYYY2KxgGGMMSaW/wfHW9h78H73GwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 748us/sample - loss: 1.1330 - acc: 0.6584\n",
      "Loss: 1.1330423045628786 Accuracy: 0.6583593\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8210 - acc: 0.4230\n",
      "Epoch 00001: val_loss improved from inf to 1.47760, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_5_conv_checkpoint/001-1.4776.hdf5\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 1.8208 - acc: 0.4231 - val_loss: 1.4776 - val_acc: 0.5239\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2266 - acc: 0.6243\n",
      "Epoch 00002: val_loss improved from 1.47760 to 1.08612, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_5_conv_checkpoint/002-1.0861.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 1.2265 - acc: 0.6243 - val_loss: 1.0861 - val_acc: 0.6681\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0198 - acc: 0.6920\n",
      "Epoch 00003: val_loss improved from 1.08612 to 0.97184, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_5_conv_checkpoint/003-0.9718.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 1.0198 - acc: 0.6920 - val_loss: 0.9718 - val_acc: 0.7044\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8643 - acc: 0.7409\n",
      "Epoch 00004: val_loss improved from 0.97184 to 0.87270, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_5_conv_checkpoint/004-0.8727.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.8643 - acc: 0.7409 - val_loss: 0.8727 - val_acc: 0.7438\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7342 - acc: 0.7831\n",
      "Epoch 00005: val_loss improved from 0.87270 to 0.80846, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_5_conv_checkpoint/005-0.8085.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.7341 - acc: 0.7831 - val_loss: 0.8085 - val_acc: 0.7540\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6140 - acc: 0.8189\n",
      "Epoch 00006: val_loss improved from 0.80846 to 0.76496, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_5_conv_checkpoint/006-0.7650.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.6140 - acc: 0.8189 - val_loss: 0.7650 - val_acc: 0.7778\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5179 - acc: 0.8473\n",
      "Epoch 00007: val_loss improved from 0.76496 to 0.73838, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_5_conv_checkpoint/007-0.7384.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.5179 - acc: 0.8473 - val_loss: 0.7384 - val_acc: 0.7782\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4395 - acc: 0.8706\n",
      "Epoch 00008: val_loss improved from 0.73838 to 0.67238, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_5_conv_checkpoint/008-0.6724.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.4395 - acc: 0.8706 - val_loss: 0.6724 - val_acc: 0.8071\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3704 - acc: 0.8892\n",
      "Epoch 00009: val_loss improved from 0.67238 to 0.64970, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_5_conv_checkpoint/009-0.6497.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.3704 - acc: 0.8892 - val_loss: 0.6497 - val_acc: 0.8078\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3090 - acc: 0.9090\n",
      "Epoch 00010: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.3091 - acc: 0.9090 - val_loss: 0.7386 - val_acc: 0.7866\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2679 - acc: 0.9200\n",
      "Epoch 00011: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.2679 - acc: 0.9200 - val_loss: 0.7131 - val_acc: 0.7973\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2243 - acc: 0.9328\n",
      "Epoch 00012: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.2242 - acc: 0.9328 - val_loss: 0.6687 - val_acc: 0.8083\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1879 - acc: 0.9453\n",
      "Epoch 00013: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1878 - acc: 0.9453 - val_loss: 0.7114 - val_acc: 0.8141\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1612 - acc: 0.9520\n",
      "Epoch 00014: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1612 - acc: 0.9520 - val_loss: 0.7284 - val_acc: 0.8139\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1495 - acc: 0.9548\n",
      "Epoch 00015: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1495 - acc: 0.9548 - val_loss: 0.7201 - val_acc: 0.8150\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9624\n",
      "Epoch 00016: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1243 - acc: 0.9624 - val_loss: 0.7473 - val_acc: 0.8162\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9671\n",
      "Epoch 00017: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1103 - acc: 0.9672 - val_loss: 0.7676 - val_acc: 0.8220\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9714\n",
      "Epoch 00018: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0977 - acc: 0.9713 - val_loss: 0.7682 - val_acc: 0.8290\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9725\n",
      "Epoch 00019: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0939 - acc: 0.9725 - val_loss: 0.7823 - val_acc: 0.8183\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9764\n",
      "Epoch 00020: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0831 - acc: 0.9764 - val_loss: 0.7853 - val_acc: 0.8192\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9765\n",
      "Epoch 00021: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0809 - acc: 0.9765 - val_loss: 0.8302 - val_acc: 0.8188\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9807\n",
      "Epoch 00022: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0703 - acc: 0.9807 - val_loss: 0.8226 - val_acc: 0.8223\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9801\n",
      "Epoch 00023: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0674 - acc: 0.9801 - val_loss: 0.8329 - val_acc: 0.8248\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9833\n",
      "Epoch 00024: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0598 - acc: 0.9833 - val_loss: 0.9085 - val_acc: 0.8197\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9835\n",
      "Epoch 00025: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0597 - acc: 0.9835 - val_loss: 0.8253 - val_acc: 0.8332\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9823\n",
      "Epoch 00026: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0612 - acc: 0.9823 - val_loss: 0.8312 - val_acc: 0.8330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9846\n",
      "Epoch 00027: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0554 - acc: 0.9846 - val_loss: 0.9154 - val_acc: 0.8167\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9848\n",
      "Epoch 00028: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0540 - acc: 0.9848 - val_loss: 0.8906 - val_acc: 0.8267\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9864\n",
      "Epoch 00029: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0484 - acc: 0.9864 - val_loss: 0.8487 - val_acc: 0.8367\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9848\n",
      "Epoch 00030: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0533 - acc: 0.9848 - val_loss: 0.8349 - val_acc: 0.8416\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9892\n",
      "Epoch 00031: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0413 - acc: 0.9892 - val_loss: 0.8677 - val_acc: 0.8386\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9869\n",
      "Epoch 00032: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0460 - acc: 0.9869 - val_loss: 0.9277 - val_acc: 0.8304\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9876\n",
      "Epoch 00033: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0469 - acc: 0.9876 - val_loss: 0.8847 - val_acc: 0.8346\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9893\n",
      "Epoch 00034: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0415 - acc: 0.9893 - val_loss: 0.8606 - val_acc: 0.8388\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9909\n",
      "Epoch 00035: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0364 - acc: 0.9909 - val_loss: 0.9226 - val_acc: 0.8383\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9886\n",
      "Epoch 00036: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0413 - acc: 0.9886 - val_loss: 0.9143 - val_acc: 0.8332\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9902\n",
      "Epoch 00037: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0373 - acc: 0.9901 - val_loss: 1.0350 - val_acc: 0.8195\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9872\n",
      "Epoch 00038: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0463 - acc: 0.9872 - val_loss: 0.9087 - val_acc: 0.8395\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9900\n",
      "Epoch 00039: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0372 - acc: 0.9899 - val_loss: 0.9104 - val_acc: 0.8332\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9916\n",
      "Epoch 00040: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0331 - acc: 0.9916 - val_loss: 0.9243 - val_acc: 0.8423\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9915\n",
      "Epoch 00041: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0338 - acc: 0.9915 - val_loss: 0.9012 - val_acc: 0.8395\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9914\n",
      "Epoch 00042: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0316 - acc: 0.9914 - val_loss: 0.9668 - val_acc: 0.8365\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9911\n",
      "Epoch 00043: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0358 - acc: 0.9911 - val_loss: 0.9220 - val_acc: 0.8367\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9916\n",
      "Epoch 00044: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0319 - acc: 0.9916 - val_loss: 0.9735 - val_acc: 0.8372\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9908\n",
      "Epoch 00045: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0351 - acc: 0.9908 - val_loss: 0.9209 - val_acc: 0.8341\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9920\n",
      "Epoch 00046: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0300 - acc: 0.9920 - val_loss: 0.9727 - val_acc: 0.8372\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9922\n",
      "Epoch 00047: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0312 - acc: 0.9922 - val_loss: 0.9481 - val_acc: 0.8465\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9926\n",
      "Epoch 00048: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0296 - acc: 0.9926 - val_loss: 0.8914 - val_acc: 0.8465\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9908\n",
      "Epoch 00049: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0330 - acc: 0.9908 - val_loss: 0.9900 - val_acc: 0.8362\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9938\n",
      "Epoch 00050: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0259 - acc: 0.9938 - val_loss: 0.9674 - val_acc: 0.8311\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9935\n",
      "Epoch 00051: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0262 - acc: 0.9935 - val_loss: 0.9761 - val_acc: 0.8358\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9921\n",
      "Epoch 00052: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0324 - acc: 0.9921 - val_loss: 0.9261 - val_acc: 0.8484\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9928\n",
      "Epoch 00053: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0277 - acc: 0.9928 - val_loss: 0.9611 - val_acc: 0.8439\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9939\n",
      "Epoch 00054: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0248 - acc: 0.9939 - val_loss: 0.9204 - val_acc: 0.8519\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9939\n",
      "Epoch 00055: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0273 - acc: 0.9939 - val_loss: 0.9092 - val_acc: 0.8486\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9944\n",
      "Epoch 00056: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0241 - acc: 0.9944 - val_loss: 0.9582 - val_acc: 0.8474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9928\n",
      "Epoch 00057: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0298 - acc: 0.9928 - val_loss: 0.9020 - val_acc: 0.8535\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9937\n",
      "Epoch 00058: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0259 - acc: 0.9937 - val_loss: 0.9282 - val_acc: 0.8449\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9937\n",
      "Epoch 00059: val_loss did not improve from 0.64970\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0283 - acc: 0.9937 - val_loss: 0.9366 - val_acc: 0.8456\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 729us/sample - loss: 0.7751 - acc: 0.7688\n",
      "Loss: 0.7750880870739867 Accuracy: 0.76884735\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8362 - acc: 0.4158\n",
      "Epoch 00001: val_loss improved from inf to 1.29384, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv_checkpoint/001-1.2938.hdf5\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 1.8362 - acc: 0.4158 - val_loss: 1.2938 - val_acc: 0.6122\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1730 - acc: 0.6404\n",
      "Epoch 00002: val_loss improved from 1.29384 to 0.88927, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv_checkpoint/002-0.8893.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 1.1729 - acc: 0.6404 - val_loss: 0.8893 - val_acc: 0.7340\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8719 - acc: 0.7368\n",
      "Epoch 00003: val_loss improved from 0.88927 to 0.74331, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv_checkpoint/003-0.7433.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.8719 - acc: 0.7368 - val_loss: 0.7433 - val_acc: 0.7857\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6958 - acc: 0.7921\n",
      "Epoch 00004: val_loss improved from 0.74331 to 0.56146, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv_checkpoint/004-0.5615.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.6958 - acc: 0.7921 - val_loss: 0.5615 - val_acc: 0.8393\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5797 - acc: 0.8257\n",
      "Epoch 00005: val_loss improved from 0.56146 to 0.51064, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv_checkpoint/005-0.5106.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.5797 - acc: 0.8256 - val_loss: 0.5106 - val_acc: 0.8537\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4979 - acc: 0.8488\n",
      "Epoch 00006: val_loss improved from 0.51064 to 0.42356, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv_checkpoint/006-0.4236.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.4979 - acc: 0.8488 - val_loss: 0.4236 - val_acc: 0.8817\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4329 - acc: 0.8675\n",
      "Epoch 00007: val_loss did not improve from 0.42356\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.4329 - acc: 0.8675 - val_loss: 0.4620 - val_acc: 0.8584\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3829 - acc: 0.8858\n",
      "Epoch 00008: val_loss improved from 0.42356 to 0.35721, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv_checkpoint/008-0.3572.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.3829 - acc: 0.8858 - val_loss: 0.3572 - val_acc: 0.9012\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3449 - acc: 0.8937\n",
      "Epoch 00009: val_loss did not improve from 0.35721\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.3450 - acc: 0.8936 - val_loss: 0.3889 - val_acc: 0.8910\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3141 - acc: 0.9023\n",
      "Epoch 00010: val_loss did not improve from 0.35721\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.3140 - acc: 0.9023 - val_loss: 0.3669 - val_acc: 0.8966\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2791 - acc: 0.9134\n",
      "Epoch 00011: val_loss improved from 0.35721 to 0.32506, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv_checkpoint/011-0.3251.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.2791 - acc: 0.9134 - val_loss: 0.3251 - val_acc: 0.9057\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2524 - acc: 0.9216\n",
      "Epoch 00012: val_loss improved from 0.32506 to 0.29146, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv_checkpoint/012-0.2915.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.2523 - acc: 0.9216 - val_loss: 0.2915 - val_acc: 0.9208\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2287 - acc: 0.9284\n",
      "Epoch 00013: val_loss did not improve from 0.29146\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.2287 - acc: 0.9284 - val_loss: 0.2919 - val_acc: 0.9173\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2024 - acc: 0.9366\n",
      "Epoch 00014: val_loss did not improve from 0.29146\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.2024 - acc: 0.9366 - val_loss: 0.3022 - val_acc: 0.9192\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1825 - acc: 0.9420\n",
      "Epoch 00015: val_loss improved from 0.29146 to 0.28417, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv_checkpoint/015-0.2842.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1825 - acc: 0.9420 - val_loss: 0.2842 - val_acc: 0.9241\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1709 - acc: 0.9464\n",
      "Epoch 00016: val_loss did not improve from 0.28417\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1708 - acc: 0.9464 - val_loss: 0.3052 - val_acc: 0.9173\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9514\n",
      "Epoch 00017: val_loss improved from 0.28417 to 0.27197, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv_checkpoint/017-0.2720.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1527 - acc: 0.9514 - val_loss: 0.2720 - val_acc: 0.9269\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9571\n",
      "Epoch 00018: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1370 - acc: 0.9571 - val_loss: 0.2924 - val_acc: 0.9250\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9602\n",
      "Epoch 00019: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1226 - acc: 0.9602 - val_loss: 0.2879 - val_acc: 0.9243\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9642\n",
      "Epoch 00020: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1118 - acc: 0.9641 - val_loss: 0.2827 - val_acc: 0.9259\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9671\n",
      "Epoch 00021: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1011 - acc: 0.9672 - val_loss: 0.3246 - val_acc: 0.9259\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9689\n",
      "Epoch 00022: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0956 - acc: 0.9689 - val_loss: 0.3142 - val_acc: 0.9182\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9739\n",
      "Epoch 00023: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0817 - acc: 0.9739 - val_loss: 0.3115 - val_acc: 0.9276\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9732\n",
      "Epoch 00024: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0794 - acc: 0.9732 - val_loss: 0.2965 - val_acc: 0.9273\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9774\n",
      "Epoch 00025: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0681 - acc: 0.9774 - val_loss: 0.3601 - val_acc: 0.9150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9778\n",
      "Epoch 00026: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0696 - acc: 0.9778 - val_loss: 0.3320 - val_acc: 0.9236\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9800\n",
      "Epoch 00027: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0611 - acc: 0.9800 - val_loss: 0.3248 - val_acc: 0.9259\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9820\n",
      "Epoch 00028: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0576 - acc: 0.9820 - val_loss: 0.3592 - val_acc: 0.9201\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9839\n",
      "Epoch 00029: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0516 - acc: 0.9839 - val_loss: 0.3288 - val_acc: 0.9271\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9843\n",
      "Epoch 00030: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0506 - acc: 0.9843 - val_loss: 0.3305 - val_acc: 0.9297\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9857\n",
      "Epoch 00031: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0448 - acc: 0.9857 - val_loss: 0.3457 - val_acc: 0.9271\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9865\n",
      "Epoch 00032: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0439 - acc: 0.9865 - val_loss: 0.3527 - val_acc: 0.9280\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9854\n",
      "Epoch 00033: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0466 - acc: 0.9854 - val_loss: 0.3441 - val_acc: 0.9238\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9866\n",
      "Epoch 00034: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0426 - acc: 0.9866 - val_loss: 0.3529 - val_acc: 0.9259\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9882\n",
      "Epoch 00035: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0390 - acc: 0.9882 - val_loss: 0.3210 - val_acc: 0.9341\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9883\n",
      "Epoch 00036: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0363 - acc: 0.9883 - val_loss: 0.3540 - val_acc: 0.9294\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9879\n",
      "Epoch 00037: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0378 - acc: 0.9879 - val_loss: 0.3692 - val_acc: 0.9301\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9895\n",
      "Epoch 00038: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0320 - acc: 0.9895 - val_loss: 0.3613 - val_acc: 0.9306\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9890\n",
      "Epoch 00039: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0363 - acc: 0.9890 - val_loss: 0.3483 - val_acc: 0.9336\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9905\n",
      "Epoch 00040: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0310 - acc: 0.9905 - val_loss: 0.3688 - val_acc: 0.9287\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9892\n",
      "Epoch 00041: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0352 - acc: 0.9892 - val_loss: 0.3399 - val_acc: 0.9311\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9921\n",
      "Epoch 00042: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0256 - acc: 0.9921 - val_loss: 0.4123 - val_acc: 0.9262\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9901\n",
      "Epoch 00043: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0337 - acc: 0.9901 - val_loss: 0.3378 - val_acc: 0.9308\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9924\n",
      "Epoch 00044: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0245 - acc: 0.9924 - val_loss: 0.3693 - val_acc: 0.9259\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9922\n",
      "Epoch 00045: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0267 - acc: 0.9922 - val_loss: 0.3714 - val_acc: 0.9297\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9920\n",
      "Epoch 00046: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0256 - acc: 0.9920 - val_loss: 0.3632 - val_acc: 0.9359\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9923\n",
      "Epoch 00047: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0265 - acc: 0.9923 - val_loss: 0.3942 - val_acc: 0.9266\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9930\n",
      "Epoch 00048: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0238 - acc: 0.9930 - val_loss: 0.3680 - val_acc: 0.9285\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9925\n",
      "Epoch 00049: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0245 - acc: 0.9925 - val_loss: 0.3929 - val_acc: 0.9304\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9940\n",
      "Epoch 00050: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0219 - acc: 0.9940 - val_loss: 0.3924 - val_acc: 0.9248\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9923\n",
      "Epoch 00051: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0256 - acc: 0.9923 - val_loss: 0.3881 - val_acc: 0.9287\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9937\n",
      "Epoch 00052: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0212 - acc: 0.9937 - val_loss: 0.3709 - val_acc: 0.9327\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9935\n",
      "Epoch 00053: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0220 - acc: 0.9935 - val_loss: 0.3821 - val_acc: 0.9276\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9943\n",
      "Epoch 00054: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0202 - acc: 0.9943 - val_loss: 0.3691 - val_acc: 0.9338\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9927\n",
      "Epoch 00055: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0242 - acc: 0.9927 - val_loss: 0.3572 - val_acc: 0.9359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9944\n",
      "Epoch 00056: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0209 - acc: 0.9944 - val_loss: 0.3649 - val_acc: 0.9322\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9937\n",
      "Epoch 00057: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0215 - acc: 0.9937 - val_loss: 0.3742 - val_acc: 0.9341\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9941\n",
      "Epoch 00058: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0204 - acc: 0.9941 - val_loss: 0.3672 - val_acc: 0.9369\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9945\n",
      "Epoch 00059: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0185 - acc: 0.9945 - val_loss: 0.3990 - val_acc: 0.9299\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9946\n",
      "Epoch 00060: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0193 - acc: 0.9946 - val_loss: 0.3906 - val_acc: 0.9334\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9944\n",
      "Epoch 00061: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0205 - acc: 0.9944 - val_loss: 0.3917 - val_acc: 0.9313\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9941\n",
      "Epoch 00062: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0206 - acc: 0.9941 - val_loss: 0.3743 - val_acc: 0.9315\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9953\n",
      "Epoch 00063: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0162 - acc: 0.9953 - val_loss: 0.4074 - val_acc: 0.9320\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9946\n",
      "Epoch 00064: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0184 - acc: 0.9946 - val_loss: 0.4046 - val_acc: 0.9345\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9944\n",
      "Epoch 00065: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0191 - acc: 0.9944 - val_loss: 0.3966 - val_acc: 0.9331\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9945\n",
      "Epoch 00066: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0192 - acc: 0.9945 - val_loss: 0.3916 - val_acc: 0.9324\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9956\n",
      "Epoch 00067: val_loss did not improve from 0.27197\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0158 - acc: 0.9956 - val_loss: 0.3952 - val_acc: 0.9331\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 748us/sample - loss: 0.3458 - acc: 0.9032\n",
      "Loss: 0.34576512503970575 Accuracy: 0.9032191\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8037 - acc: 0.4173\n",
      "Epoch 00001: val_loss improved from inf to 1.07992, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/001-1.0799.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 1.8036 - acc: 0.4173 - val_loss: 1.0799 - val_acc: 0.6699\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9713 - acc: 0.6950\n",
      "Epoch 00002: val_loss improved from 1.07992 to 0.80365, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/002-0.8036.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.9712 - acc: 0.6951 - val_loss: 0.8036 - val_acc: 0.7438\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6916 - acc: 0.7843\n",
      "Epoch 00003: val_loss improved from 0.80365 to 0.49699, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/003-0.4970.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.6916 - acc: 0.7844 - val_loss: 0.4970 - val_acc: 0.8546\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5472 - acc: 0.8286\n",
      "Epoch 00004: val_loss improved from 0.49699 to 0.39793, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/004-0.3979.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.5471 - acc: 0.8286 - val_loss: 0.3979 - val_acc: 0.8821\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4437 - acc: 0.8642\n",
      "Epoch 00005: val_loss improved from 0.39793 to 0.34539, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/005-0.3454.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.4437 - acc: 0.8641 - val_loss: 0.3454 - val_acc: 0.8982\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3802 - acc: 0.8824\n",
      "Epoch 00006: val_loss improved from 0.34539 to 0.28801, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/006-0.2880.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.3802 - acc: 0.8824 - val_loss: 0.2880 - val_acc: 0.9171\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3341 - acc: 0.8958\n",
      "Epoch 00007: val_loss improved from 0.28801 to 0.26178, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/007-0.2618.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.3341 - acc: 0.8958 - val_loss: 0.2618 - val_acc: 0.9220\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2925 - acc: 0.9094\n",
      "Epoch 00008: val_loss improved from 0.26178 to 0.23864, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/008-0.2386.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.2925 - acc: 0.9094 - val_loss: 0.2386 - val_acc: 0.9283\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2621 - acc: 0.9179\n",
      "Epoch 00009: val_loss improved from 0.23864 to 0.21255, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/009-0.2126.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.2621 - acc: 0.9179 - val_loss: 0.2126 - val_acc: 0.9366\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2379 - acc: 0.9254\n",
      "Epoch 00010: val_loss improved from 0.21255 to 0.19840, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/010-0.1984.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.2379 - acc: 0.9254 - val_loss: 0.1984 - val_acc: 0.9418\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2180 - acc: 0.9310\n",
      "Epoch 00011: val_loss did not improve from 0.19840\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.2180 - acc: 0.9310 - val_loss: 0.2459 - val_acc: 0.9224\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9366\n",
      "Epoch 00012: val_loss did not improve from 0.19840\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1994 - acc: 0.9366 - val_loss: 0.2020 - val_acc: 0.9390\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1874 - acc: 0.9411\n",
      "Epoch 00013: val_loss improved from 0.19840 to 0.19303, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/013-0.1930.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1874 - acc: 0.9411 - val_loss: 0.1930 - val_acc: 0.9392\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9450\n",
      "Epoch 00014: val_loss improved from 0.19303 to 0.18144, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/014-0.1814.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1739 - acc: 0.9450 - val_loss: 0.1814 - val_acc: 0.9469\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9488\n",
      "Epoch 00015: val_loss improved from 0.18144 to 0.18142, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/015-0.1814.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1600 - acc: 0.9488 - val_loss: 0.1814 - val_acc: 0.9485\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9530\n",
      "Epoch 00016: val_loss improved from 0.18142 to 0.16764, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/016-0.1676.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1445 - acc: 0.9530 - val_loss: 0.1676 - val_acc: 0.9513\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9549\n",
      "Epoch 00017: val_loss did not improve from 0.16764\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1376 - acc: 0.9549 - val_loss: 0.1897 - val_acc: 0.9481\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9573\n",
      "Epoch 00018: val_loss improved from 0.16764 to 0.16292, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/018-0.1629.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1290 - acc: 0.9573 - val_loss: 0.1629 - val_acc: 0.9515\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9626\n",
      "Epoch 00019: val_loss did not improve from 0.16292\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1137 - acc: 0.9626 - val_loss: 0.1942 - val_acc: 0.9413\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9644\n",
      "Epoch 00020: val_loss did not improve from 0.16292\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1076 - acc: 0.9644 - val_loss: 0.1798 - val_acc: 0.9471\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9665\n",
      "Epoch 00021: val_loss did not improve from 0.16292\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0984 - acc: 0.9665 - val_loss: 0.1780 - val_acc: 0.9525\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9683\n",
      "Epoch 00022: val_loss did not improve from 0.16292\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0947 - acc: 0.9683 - val_loss: 0.1806 - val_acc: 0.9534\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9712\n",
      "Epoch 00023: val_loss did not improve from 0.16292\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0871 - acc: 0.9712 - val_loss: 0.1724 - val_acc: 0.9532\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9730\n",
      "Epoch 00024: val_loss improved from 0.16292 to 0.15937, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv_checkpoint/024-0.1594.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0808 - acc: 0.9730 - val_loss: 0.1594 - val_acc: 0.9543\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9744\n",
      "Epoch 00025: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0792 - acc: 0.9744 - val_loss: 0.1790 - val_acc: 0.9504\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9758\n",
      "Epoch 00026: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0705 - acc: 0.9758 - val_loss: 0.1806 - val_acc: 0.9504\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9777\n",
      "Epoch 00027: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0642 - acc: 0.9777 - val_loss: 0.1949 - val_acc: 0.9506\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9771\n",
      "Epoch 00028: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0686 - acc: 0.9771 - val_loss: 0.1742 - val_acc: 0.9534\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9796\n",
      "Epoch 00029: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0595 - acc: 0.9796 - val_loss: 0.1760 - val_acc: 0.9555\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9811\n",
      "Epoch 00030: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0551 - acc: 0.9811 - val_loss: 0.1893 - val_acc: 0.9522\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9830\n",
      "Epoch 00031: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0486 - acc: 0.9830 - val_loss: 0.1810 - val_acc: 0.9541\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9829\n",
      "Epoch 00032: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0487 - acc: 0.9829 - val_loss: 0.1907 - val_acc: 0.9550\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9848\n",
      "Epoch 00033: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0472 - acc: 0.9848 - val_loss: 0.1781 - val_acc: 0.9567\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9850\n",
      "Epoch 00034: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0432 - acc: 0.9850 - val_loss: 0.1774 - val_acc: 0.9574\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9870\n",
      "Epoch 00035: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0379 - acc: 0.9870 - val_loss: 0.2048 - val_acc: 0.9525\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9860\n",
      "Epoch 00036: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0414 - acc: 0.9860 - val_loss: 0.1965 - val_acc: 0.9581\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9865\n",
      "Epoch 00037: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0403 - acc: 0.9866 - val_loss: 0.1908 - val_acc: 0.9571\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9868\n",
      "Epoch 00038: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0396 - acc: 0.9868 - val_loss: 0.2067 - val_acc: 0.9543\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9896\n",
      "Epoch 00039: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0316 - acc: 0.9896 - val_loss: 0.2050 - val_acc: 0.9534\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9887\n",
      "Epoch 00040: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0349 - acc: 0.9887 - val_loss: 0.2036 - val_acc: 0.9525\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9905\n",
      "Epoch 00041: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0288 - acc: 0.9905 - val_loss: 0.2082 - val_acc: 0.9571\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9903\n",
      "Epoch 00042: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0291 - acc: 0.9903 - val_loss: 0.1808 - val_acc: 0.9581\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9888\n",
      "Epoch 00043: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0324 - acc: 0.9888 - val_loss: 0.1898 - val_acc: 0.9583\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9916\n",
      "Epoch 00044: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0248 - acc: 0.9916 - val_loss: 0.2158 - val_acc: 0.9557\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9915\n",
      "Epoch 00045: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0252 - acc: 0.9915 - val_loss: 0.2296 - val_acc: 0.9541\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9905\n",
      "Epoch 00046: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0275 - acc: 0.9905 - val_loss: 0.2099 - val_acc: 0.9569\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9926\n",
      "Epoch 00047: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0232 - acc: 0.9926 - val_loss: 0.2242 - val_acc: 0.9532\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9907\n",
      "Epoch 00048: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0279 - acc: 0.9907 - val_loss: 0.2026 - val_acc: 0.9574\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9943\n",
      "Epoch 00049: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0179 - acc: 0.9943 - val_loss: 0.2228 - val_acc: 0.9562\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9916\n",
      "Epoch 00050: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0255 - acc: 0.9916 - val_loss: 0.2292 - val_acc: 0.9553\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9939\n",
      "Epoch 00051: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0187 - acc: 0.9939 - val_loss: 0.2449 - val_acc: 0.9536\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9921\n",
      "Epoch 00052: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0236 - acc: 0.9921 - val_loss: 0.2170 - val_acc: 0.9599\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9936\n",
      "Epoch 00053: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0205 - acc: 0.9935 - val_loss: 0.2815 - val_acc: 0.9362\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9929\n",
      "Epoch 00054: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0213 - acc: 0.9929 - val_loss: 0.2069 - val_acc: 0.9618\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9936\n",
      "Epoch 00055: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0195 - acc: 0.9936 - val_loss: 0.1992 - val_acc: 0.9578\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9943\n",
      "Epoch 00056: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0178 - acc: 0.9943 - val_loss: 0.2164 - val_acc: 0.9553\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9935\n",
      "Epoch 00057: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0186 - acc: 0.9935 - val_loss: 0.2356 - val_acc: 0.9522\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9941\n",
      "Epoch 00058: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0174 - acc: 0.9941 - val_loss: 0.2416 - val_acc: 0.9539\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9934\n",
      "Epoch 00059: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0199 - acc: 0.9934 - val_loss: 0.2421 - val_acc: 0.9567\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9943\n",
      "Epoch 00060: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0166 - acc: 0.9943 - val_loss: 0.2099 - val_acc: 0.9592\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9949\n",
      "Epoch 00061: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0153 - acc: 0.9949 - val_loss: 0.2322 - val_acc: 0.9583\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9945\n",
      "Epoch 00062: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0176 - acc: 0.9945 - val_loss: 0.2278 - val_acc: 0.9571\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9960\n",
      "Epoch 00063: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0135 - acc: 0.9960 - val_loss: 0.2355 - val_acc: 0.9583\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9947\n",
      "Epoch 00064: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0158 - acc: 0.9947 - val_loss: 0.2160 - val_acc: 0.9604\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9960\n",
      "Epoch 00065: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0122 - acc: 0.9960 - val_loss: 0.2223 - val_acc: 0.9623\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9957\n",
      "Epoch 00066: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0127 - acc: 0.9957 - val_loss: 0.2575 - val_acc: 0.9543\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9938\n",
      "Epoch 00067: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0192 - acc: 0.9938 - val_loss: 0.2431 - val_acc: 0.9527\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9958\n",
      "Epoch 00068: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0129 - acc: 0.9958 - val_loss: 0.2356 - val_acc: 0.9583\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9959\n",
      "Epoch 00069: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0124 - acc: 0.9959 - val_loss: 0.2425 - val_acc: 0.9569\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9957\n",
      "Epoch 00070: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0142 - acc: 0.9957 - val_loss: 0.2522 - val_acc: 0.9532\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9945\n",
      "Epoch 00071: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0163 - acc: 0.9945 - val_loss: 0.2475 - val_acc: 0.9562\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9959\n",
      "Epoch 00072: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0130 - acc: 0.9959 - val_loss: 0.2310 - val_acc: 0.9574\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9969\n",
      "Epoch 00073: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0097 - acc: 0.9969 - val_loss: 0.2383 - val_acc: 0.9595\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9952\n",
      "Epoch 00074: val_loss did not improve from 0.15937\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0146 - acc: 0.9952 - val_loss: 0.2111 - val_acc: 0.9609\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 749us/sample - loss: 0.2272 - acc: 0.9379\n",
      "Loss: 0.22724942879389629 Accuracy: 0.9379024\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8522 - acc: 0.3930\n",
      "Epoch 00001: val_loss improved from inf to 0.96636, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/001-0.9664.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 1.8521 - acc: 0.3931 - val_loss: 0.9664 - val_acc: 0.6834\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8870 - acc: 0.7082\n",
      "Epoch 00002: val_loss improved from 0.96636 to 0.58412, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/002-0.5841.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.8871 - acc: 0.7081 - val_loss: 0.5841 - val_acc: 0.8153\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6049 - acc: 0.8078\n",
      "Epoch 00003: val_loss improved from 0.58412 to 0.39779, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/003-0.3978.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.6048 - acc: 0.8078 - val_loss: 0.3978 - val_acc: 0.8819\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4524 - acc: 0.8551\n",
      "Epoch 00004: val_loss improved from 0.39779 to 0.34911, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/004-0.3491.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.4525 - acc: 0.8551 - val_loss: 0.3491 - val_acc: 0.8938\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3639 - acc: 0.8833\n",
      "Epoch 00005: val_loss improved from 0.34911 to 0.25623, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/005-0.2562.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.3639 - acc: 0.8833 - val_loss: 0.2562 - val_acc: 0.9187\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3065 - acc: 0.9018\n",
      "Epoch 00006: val_loss improved from 0.25623 to 0.23131, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/006-0.2313.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.3066 - acc: 0.9018 - val_loss: 0.2313 - val_acc: 0.9250\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2624 - acc: 0.9165\n",
      "Epoch 00007: val_loss improved from 0.23131 to 0.19774, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/007-0.1977.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.2624 - acc: 0.9165 - val_loss: 0.1977 - val_acc: 0.9399\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2270 - acc: 0.9285\n",
      "Epoch 00008: val_loss did not improve from 0.19774\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.2270 - acc: 0.9285 - val_loss: 0.2000 - val_acc: 0.9401\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2069 - acc: 0.9325\n",
      "Epoch 00009: val_loss did not improve from 0.19774\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.2069 - acc: 0.9325 - val_loss: 0.1986 - val_acc: 0.9373\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9383\n",
      "Epoch 00010: val_loss improved from 0.19774 to 0.15790, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/010-0.1579.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.1874 - acc: 0.9383 - val_loss: 0.1579 - val_acc: 0.9522\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9449\n",
      "Epoch 00011: val_loss improved from 0.15790 to 0.15712, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/011-0.1571.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.1710 - acc: 0.9449 - val_loss: 0.1571 - val_acc: 0.9515\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1563 - acc: 0.9491\n",
      "Epoch 00012: val_loss did not improve from 0.15712\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.1565 - acc: 0.9491 - val_loss: 0.2219 - val_acc: 0.9315\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9515\n",
      "Epoch 00013: val_loss did not improve from 0.15712\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.1479 - acc: 0.9516 - val_loss: 0.1744 - val_acc: 0.9467\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9572\n",
      "Epoch 00014: val_loss improved from 0.15712 to 0.15663, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/014-0.1566.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.1288 - acc: 0.9572 - val_loss: 0.1566 - val_acc: 0.9553\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9622\n",
      "Epoch 00015: val_loss improved from 0.15663 to 0.14391, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/015-0.1439.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1156 - acc: 0.9622 - val_loss: 0.1439 - val_acc: 0.9553\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9631\n",
      "Epoch 00016: val_loss did not improve from 0.14391\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1105 - acc: 0.9631 - val_loss: 0.1700 - val_acc: 0.9474\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9660\n",
      "Epoch 00017: val_loss did not improve from 0.14391\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.1026 - acc: 0.9660 - val_loss: 0.1562 - val_acc: 0.9562\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9682\n",
      "Epoch 00018: val_loss improved from 0.14391 to 0.14026, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/018-0.1403.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.0927 - acc: 0.9682 - val_loss: 0.1403 - val_acc: 0.9588\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9720\n",
      "Epoch 00019: val_loss did not improve from 0.14026\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0834 - acc: 0.9720 - val_loss: 0.1486 - val_acc: 0.9541\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9717\n",
      "Epoch 00020: val_loss improved from 0.14026 to 0.13349, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/020-0.1335.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.0832 - acc: 0.9717 - val_loss: 0.1335 - val_acc: 0.9599\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9764\n",
      "Epoch 00021: val_loss did not improve from 0.13349\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0722 - acc: 0.9763 - val_loss: 0.1815 - val_acc: 0.9515\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9760\n",
      "Epoch 00022: val_loss improved from 0.13349 to 0.13306, saving model to model/checkpoint/1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv_checkpoint/022-0.1331.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0713 - acc: 0.9760 - val_loss: 0.1331 - val_acc: 0.9611\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9766\n",
      "Epoch 00023: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0685 - acc: 0.9766 - val_loss: 0.1390 - val_acc: 0.9602\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9803\n",
      "Epoch 00024: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0572 - acc: 0.9803 - val_loss: 0.1545 - val_acc: 0.9602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9805\n",
      "Epoch 00025: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0585 - acc: 0.9805 - val_loss: 0.1856 - val_acc: 0.9543\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9807\n",
      "Epoch 00026: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0575 - acc: 0.9807 - val_loss: 0.1573 - val_acc: 0.9576\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9836\n",
      "Epoch 00027: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0477 - acc: 0.9836 - val_loss: 0.1651 - val_acc: 0.9564\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9845\n",
      "Epoch 00028: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0464 - acc: 0.9845 - val_loss: 0.1669 - val_acc: 0.9555\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9862\n",
      "Epoch 00029: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0417 - acc: 0.9862 - val_loss: 0.1527 - val_acc: 0.9585\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9854\n",
      "Epoch 00030: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0416 - acc: 0.9854 - val_loss: 0.1520 - val_acc: 0.9599\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9871\n",
      "Epoch 00031: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0374 - acc: 0.9871 - val_loss: 0.1733 - val_acc: 0.9623\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9879\n",
      "Epoch 00032: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0371 - acc: 0.9879 - val_loss: 0.1863 - val_acc: 0.9595\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9889\n",
      "Epoch 00033: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0339 - acc: 0.9889 - val_loss: 0.1883 - val_acc: 0.9595\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9887\n",
      "Epoch 00034: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0341 - acc: 0.9887 - val_loss: 0.1836 - val_acc: 0.9588\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9893\n",
      "Epoch 00035: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0315 - acc: 0.9893 - val_loss: 0.1886 - val_acc: 0.9536\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9890\n",
      "Epoch 00036: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0327 - acc: 0.9890 - val_loss: 0.1757 - val_acc: 0.9578\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9899\n",
      "Epoch 00037: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0283 - acc: 0.9899 - val_loss: 0.2059 - val_acc: 0.9543\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9896\n",
      "Epoch 00038: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0309 - acc: 0.9896 - val_loss: 0.1907 - val_acc: 0.9557\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9901\n",
      "Epoch 00039: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0279 - acc: 0.9901 - val_loss: 0.1885 - val_acc: 0.9616\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9910\n",
      "Epoch 00040: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0262 - acc: 0.9910 - val_loss: 0.1902 - val_acc: 0.9602\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9907\n",
      "Epoch 00041: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0281 - acc: 0.9907 - val_loss: 0.1807 - val_acc: 0.9604\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 00042: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0251 - acc: 0.9916 - val_loss: 0.1828 - val_acc: 0.9613\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9913\n",
      "Epoch 00043: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0274 - acc: 0.9913 - val_loss: 0.1986 - val_acc: 0.9555\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9926\n",
      "Epoch 00044: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0229 - acc: 0.9926 - val_loss: 0.1754 - val_acc: 0.9611\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9939\n",
      "Epoch 00045: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0190 - acc: 0.9939 - val_loss: 0.1891 - val_acc: 0.9618\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9939\n",
      "Epoch 00046: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0181 - acc: 0.9939 - val_loss: 0.2027 - val_acc: 0.9623\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9930\n",
      "Epoch 00047: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0218 - acc: 0.9930 - val_loss: 0.2205 - val_acc: 0.9597\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9931\n",
      "Epoch 00048: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0211 - acc: 0.9931 - val_loss: 0.1914 - val_acc: 0.9585\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9943\n",
      "Epoch 00049: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0172 - acc: 0.9943 - val_loss: 0.2213 - val_acc: 0.9574\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9932\n",
      "Epoch 00050: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0205 - acc: 0.9932 - val_loss: 0.2163 - val_acc: 0.9583\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9935\n",
      "Epoch 00051: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0196 - acc: 0.9935 - val_loss: 0.2251 - val_acc: 0.9585\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9948\n",
      "Epoch 00052: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0161 - acc: 0.9948 - val_loss: 0.2065 - val_acc: 0.9630\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9948\n",
      "Epoch 00053: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0167 - acc: 0.9948 - val_loss: 0.2089 - val_acc: 0.9630\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9945\n",
      "Epoch 00054: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0168 - acc: 0.9945 - val_loss: 0.2033 - val_acc: 0.9620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9946\n",
      "Epoch 00055: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0170 - acc: 0.9946 - val_loss: 0.2285 - val_acc: 0.9616\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9944\n",
      "Epoch 00056: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0181 - acc: 0.9944 - val_loss: 0.1869 - val_acc: 0.9639\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9958\n",
      "Epoch 00057: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0127 - acc: 0.9958 - val_loss: 0.1966 - val_acc: 0.9641\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9954\n",
      "Epoch 00058: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0145 - acc: 0.9954 - val_loss: 0.2211 - val_acc: 0.9632\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9957\n",
      "Epoch 00059: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0140 - acc: 0.9957 - val_loss: 0.2036 - val_acc: 0.9639\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9957\n",
      "Epoch 00060: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0133 - acc: 0.9957 - val_loss: 0.2141 - val_acc: 0.9618\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9953\n",
      "Epoch 00061: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0153 - acc: 0.9953 - val_loss: 0.2102 - val_acc: 0.9660\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9948\n",
      "Epoch 00062: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0169 - acc: 0.9948 - val_loss: 0.2322 - val_acc: 0.9567\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9968\n",
      "Epoch 00063: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0109 - acc: 0.9968 - val_loss: 0.2053 - val_acc: 0.9632\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9959\n",
      "Epoch 00064: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0121 - acc: 0.9959 - val_loss: 0.2335 - val_acc: 0.9651\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9958\n",
      "Epoch 00065: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0135 - acc: 0.9958 - val_loss: 0.2078 - val_acc: 0.9644\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9954\n",
      "Epoch 00066: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0159 - acc: 0.9954 - val_loss: 0.2187 - val_acc: 0.9595\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9966\n",
      "Epoch 00067: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0113 - acc: 0.9966 - val_loss: 0.2068 - val_acc: 0.9641\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9967\n",
      "Epoch 00068: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0101 - acc: 0.9967 - val_loss: 0.2134 - val_acc: 0.9639\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9960\n",
      "Epoch 00069: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0135 - acc: 0.9960 - val_loss: 0.2156 - val_acc: 0.9602\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9965\n",
      "Epoch 00070: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0105 - acc: 0.9965 - val_loss: 0.2307 - val_acc: 0.9627\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9958\n",
      "Epoch 00071: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0131 - acc: 0.9958 - val_loss: 0.2363 - val_acc: 0.9641\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9972\n",
      "Epoch 00072: val_loss did not improve from 0.13306\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0093 - acc: 0.9972 - val_loss: 0.2557 - val_acc: 0.9560\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 774us/sample - loss: 0.1851 - acc: 0.9456\n",
      "Loss: 0.18510139149885435 Accuracy: 0.9455867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_multi_3_concat_ch_128_DO'\n",
    "\n",
    "for i in range(3, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_cnn(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 128)   768         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 128)   0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 128)    0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 128)    0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 128)    0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 128)    0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 128)     0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 682624)       0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 227456)       0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 75776)        0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 985856)       0           flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 985856)       0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           15773712    dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,938,576\n",
      "Trainable params: 15,938,576\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 809us/sample - loss: 1.3458 - acc: 0.5842\n",
      "Loss: 1.3458196849714064 Accuracy: 0.584216\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 16000, 128)   768         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16000, 128)   0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 5333, 128)    0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5333, 128)    0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1777, 128)    0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1777, 128)    0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 592, 128)     0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 592, 128)     0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 197, 128)     0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 227456)       0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 75776)        0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 25216)        0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 328448)       0           flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 328448)       0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           5255184     dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,502,096\n",
      "Trainable params: 5,502,096\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 765us/sample - loss: 1.1330 - acc: 0.6584\n",
      "Loss: 1.1330423045628786 Accuracy: 0.6583593\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 16000, 128)   768         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16000, 128)   0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 5333, 128)    0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5333, 128)    0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1777, 128)    0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1777, 128)    0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 592, 128)     0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 592, 128)     0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 197, 128)     0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 197, 256)     0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 65, 256)      0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 75776)        0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 25216)        0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 16640)        0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 117632)       0           flatten_24[0][0]                 \n",
      "                                                                 flatten_25[0][0]                 \n",
      "                                                                 flatten_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 117632)       0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           1882128     dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,293,136\n",
      "Trainable params: 2,293,136\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 759us/sample - loss: 0.7751 - acc: 0.7688\n",
      "Loss: 0.7750880870739867 Accuracy: 0.76884735\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 16000, 128)   768         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16000, 128)   0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 5333, 128)    0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5333, 128)    0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1777, 128)    0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1777, 128)    0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 592, 128)     0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 592, 128)     0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 197, 128)     0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 197, 256)     0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 65, 256)      0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 65, 256)      0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 21, 256)      0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 25216)        0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 16640)        0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 5376)         0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 47232)        0           flatten_27[0][0]                 \n",
      "                                                                 flatten_28[0][0]                 \n",
      "                                                                 flatten_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 47232)        0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           755728      dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,494,672\n",
      "Trainable params: 1,494,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 769us/sample - loss: 0.3458 - acc: 0.9032\n",
      "Loss: 0.34576512503970575 Accuracy: 0.9032191\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 16000, 128)   768         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16000, 128)   0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 5333, 128)    0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5333, 128)    0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 1777, 128)    0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1777, 128)    0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 592, 128)     0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 592, 128)     0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 197, 128)     0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 197, 256)     0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 65, 256)      0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 65, 256)      0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 21, 256)      0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 21, 256)      327936      max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 21, 256)      0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 7, 256)       0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 16640)        0           max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 5376)         0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 1792)         0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 23808)        0           flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 23808)        0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           380944      dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,447,824\n",
      "Trainable params: 1,447,824\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 812us/sample - loss: 0.2272 - acc: 0.9379\n",
      "Loss: 0.22724942879389629 Accuracy: 0.9379024\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 16000, 128)   768         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16000, 128)   0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 5333, 128)    0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5333, 128)    0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 1777, 128)    0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1777, 128)    0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 592, 128)     0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 592, 128)     0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 197, 128)     0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 197, 256)     0           conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 65, 256)      0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 65, 256)      0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 21, 256)      0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 21, 256)      327936      max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 21, 256)      0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 7, 256)       0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 7, 256)       327936      max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 256)       0           conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 2, 256)       0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 5376)         0           max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 1792)         0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 512)          0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 7680)         0           flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 7680)         0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           122896      dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,517,712\n",
      "Trainable params: 1,517,712\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 829us/sample - loss: 0.1851 - acc: 0.9456\n",
      "Loss: 0.18510139149885435 Accuracy: 0.9455867\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_multi_3_concat_ch_128_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 9):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 128)   768         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 128)   0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 128)    0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 128)    0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 128)    0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 128)    0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 128)     0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 682624)       0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 227456)       0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 75776)        0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 985856)       0           flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 985856)       0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           15773712    dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,938,576\n",
      "Trainable params: 15,938,576\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 842us/sample - loss: 2.4657 - acc: 0.6390\n",
      "Loss: 2.4657108455927323 Accuracy: 0.63904464\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 16000, 128)   768         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16000, 128)   0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 5333, 128)    0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5333, 128)    0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1777, 128)    0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1777, 128)    0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 592, 128)     0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 592, 128)     0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 197, 128)     0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 227456)       0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 75776)        0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 25216)        0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 328448)       0           flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 328448)       0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           5255184     dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,502,096\n",
      "Trainable params: 5,502,096\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 807us/sample - loss: 2.0547 - acc: 0.7032\n",
      "Loss: 2.054721259006211 Accuracy: 0.7032191\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 16000, 128)   768         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16000, 128)   0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 5333, 128)    0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5333, 128)    0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1777, 128)    0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1777, 128)    0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 592, 128)     0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 592, 128)     0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 197, 128)     0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 197, 256)     0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 65, 256)      0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 75776)        0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 25216)        0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 16640)        0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 117632)       0           flatten_24[0][0]                 \n",
      "                                                                 flatten_25[0][0]                 \n",
      "                                                                 flatten_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 117632)       0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           1882128     dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,293,136\n",
      "Trainable params: 2,293,136\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 797us/sample - loss: 1.1008 - acc: 0.8137\n",
      "Loss: 1.100814703543238 Accuracy: 0.8137072\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 16000, 128)   768         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16000, 128)   0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 5333, 128)    0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5333, 128)    0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1777, 128)    0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1777, 128)    0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 592, 128)     0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 592, 128)     0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 197, 128)     0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 197, 256)     0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 65, 256)      0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 65, 256)      0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 21, 256)      0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 25216)        0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 16640)        0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 5376)         0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 47232)        0           flatten_27[0][0]                 \n",
      "                                                                 flatten_28[0][0]                 \n",
      "                                                                 flatten_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 47232)        0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           755728      dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,494,672\n",
      "Trainable params: 1,494,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 852us/sample - loss: 0.4799 - acc: 0.9121\n",
      "Loss: 0.4798922586104874 Accuracy: 0.91214955\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 16000, 128)   768         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16000, 128)   0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 5333, 128)    0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5333, 128)    0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 1777, 128)    0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1777, 128)    0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 592, 128)     0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 592, 128)     0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 197, 128)     0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 197, 256)     0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 65, 256)      0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 65, 256)      0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 21, 256)      0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 21, 256)      327936      max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 21, 256)      0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 7, 256)       0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 16640)        0           max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 5376)         0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 1792)         0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 23808)        0           flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 23808)        0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           380944      dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,447,824\n",
      "Trainable params: 1,447,824\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 863us/sample - loss: 0.3004 - acc: 0.9458\n",
      "Loss: 0.3003582650458422 Accuracy: 0.9457944\n",
      "\n",
      "1D_CNN_custom_multi_3_concat_ch_128_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 16000, 128)   768         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16000, 128)   0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 5333, 128)    0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5333, 128)    82048       max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5333, 128)    0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 1777, 128)    0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1777, 128)    82048       max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1777, 128)    0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 592, 128)     0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 592, 128)     82048       max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 592, 128)     0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 197, 128)     0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 197, 256)     164096      max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 197, 256)     0           conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 65, 256)      0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 65, 256)      327936      max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 65, 256)      0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 21, 256)      0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 21, 256)      327936      max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 21, 256)      0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 7, 256)       0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 7, 256)       327936      max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 256)       0           conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 2, 256)       0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 5376)         0           max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 1792)         0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 512)          0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 7680)         0           flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 7680)         0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           122896      dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,517,712\n",
      "Trainable params: 1,517,712\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 837us/sample - loss: 0.3158 - acc: 0.9479\n",
      "Loss: 0.3158362437357291 Accuracy: 0.9478712\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
