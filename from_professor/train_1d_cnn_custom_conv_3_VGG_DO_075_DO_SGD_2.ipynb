{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_DO_075_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                      activation='relu', input_shape=input_shape)) \n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                  activation='relu')) \n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))         \n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.75))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,498,320\n",
      "Trainable params: 5,498,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_075_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7484 - acc: 0.0790\n",
      "Epoch 00001: val_loss improved from inf to 2.72719, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/001-2.7272.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 2.7484 - acc: 0.0790 - val_loss: 2.7272 - val_acc: 0.0820\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7294 - acc: 0.0795\n",
      "Epoch 00002: val_loss improved from 2.72719 to 2.72077, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/002-2.7208.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7294 - acc: 0.0795 - val_loss: 2.7208 - val_acc: 0.0820\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7258 - acc: 0.0785\n",
      "Epoch 00003: val_loss improved from 2.72077 to 2.71899, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/003-2.7190.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7258 - acc: 0.0785 - val_loss: 2.7190 - val_acc: 0.0820\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7248 - acc: 0.0783\n",
      "Epoch 00004: val_loss did not improve from 2.71899\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7247 - acc: 0.0783 - val_loss: 2.7194 - val_acc: 0.0885\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7228 - acc: 0.0815\n",
      "Epoch 00005: val_loss improved from 2.71899 to 2.71844, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/005-2.7184.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7228 - acc: 0.0815 - val_loss: 2.7184 - val_acc: 0.0820\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7229 - acc: 0.0798\n",
      "Epoch 00006: val_loss did not improve from 2.71844\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7229 - acc: 0.0798 - val_loss: 2.7190 - val_acc: 0.0820\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7227 - acc: 0.0785\n",
      "Epoch 00007: val_loss did not improve from 2.71844\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7227 - acc: 0.0785 - val_loss: 2.7187 - val_acc: 0.0820\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7224 - acc: 0.0803\n",
      "Epoch 00008: val_loss did not improve from 2.71844\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7224 - acc: 0.0803 - val_loss: 2.7188 - val_acc: 0.0820\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7221 - acc: 0.0790\n",
      "Epoch 00009: val_loss did not improve from 2.71844\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7221 - acc: 0.0790 - val_loss: 2.7188 - val_acc: 0.0820\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7219 - acc: 0.0804\n",
      "Epoch 00010: val_loss improved from 2.71844 to 2.71832, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/010-2.7183.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7219 - acc: 0.0804 - val_loss: 2.7183 - val_acc: 0.0936\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7213 - acc: 0.0807\n",
      "Epoch 00011: val_loss improved from 2.71832 to 2.71781, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/011-2.7178.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7213 - acc: 0.0806 - val_loss: 2.7178 - val_acc: 0.0820\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7204 - acc: 0.0833\n",
      "Epoch 00012: val_loss improved from 2.71781 to 2.71669, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/012-2.7167.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7204 - acc: 0.0833 - val_loss: 2.7167 - val_acc: 0.0820\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7197 - acc: 0.0839\n",
      "Epoch 00013: val_loss improved from 2.71669 to 2.71491, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/013-2.7149.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7196 - acc: 0.0840 - val_loss: 2.7149 - val_acc: 0.0857\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7158 - acc: 0.0929\n",
      "Epoch 00014: val_loss improved from 2.71491 to 2.70902, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/014-2.7090.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7158 - acc: 0.0929 - val_loss: 2.7090 - val_acc: 0.0929\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7068 - acc: 0.1034\n",
      "Epoch 00015: val_loss improved from 2.70902 to 2.68931, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/015-2.6893.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.7068 - acc: 0.1034 - val_loss: 2.6893 - val_acc: 0.1353\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6833 - acc: 0.1215\n",
      "Epoch 00016: val_loss improved from 2.68931 to 2.64560, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/016-2.6456.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.6833 - acc: 0.1215 - val_loss: 2.6456 - val_acc: 0.1542\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6471 - acc: 0.1450\n",
      "Epoch 00017: val_loss improved from 2.64560 to 2.58468, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/017-2.5847.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.6471 - acc: 0.1450 - val_loss: 2.5847 - val_acc: 0.1840\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5889 - acc: 0.1587\n",
      "Epoch 00018: val_loss improved from 2.58468 to 2.51558, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/018-2.5156.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.5889 - acc: 0.1587 - val_loss: 2.5156 - val_acc: 0.1896\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5346 - acc: 0.1765\n",
      "Epoch 00019: val_loss improved from 2.51558 to 2.44231, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/019-2.4423.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.5347 - acc: 0.1765 - val_loss: 2.4423 - val_acc: 0.2131\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4867 - acc: 0.1885\n",
      "Epoch 00020: val_loss did not improve from 2.44231\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.4867 - acc: 0.1884 - val_loss: 2.5083 - val_acc: 0.1670\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3614 - acc: 0.2287\n",
      "Epoch 00021: val_loss improved from 2.44231 to 2.11804, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/021-2.1180.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.3613 - acc: 0.2287 - val_loss: 2.1180 - val_acc: 0.3175\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1896 - acc: 0.2803\n",
      "Epoch 00022: val_loss did not improve from 2.11804\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.1896 - acc: 0.2803 - val_loss: 2.2243 - val_acc: 0.2588\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9694 - acc: 0.3537\n",
      "Epoch 00023: val_loss improved from 2.11804 to 1.89381, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/023-1.8938.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.9693 - acc: 0.3537 - val_loss: 1.8938 - val_acc: 0.3727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7103 - acc: 0.4340\n",
      "Epoch 00024: val_loss improved from 1.89381 to 1.51490, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/024-1.5149.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.7103 - acc: 0.4339 - val_loss: 1.5149 - val_acc: 0.4836\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5426 - acc: 0.4881\n",
      "Epoch 00025: val_loss improved from 1.51490 to 1.33844, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/025-1.3384.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.5426 - acc: 0.4881 - val_loss: 1.3384 - val_acc: 0.5625\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4067 - acc: 0.5327\n",
      "Epoch 00026: val_loss improved from 1.33844 to 1.27654, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/026-1.2765.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.4068 - acc: 0.5326 - val_loss: 1.2765 - val_acc: 0.5833\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2991 - acc: 0.5746\n",
      "Epoch 00027: val_loss did not improve from 1.27654\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.2991 - acc: 0.5746 - val_loss: 2.3830 - val_acc: 0.3233\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2001 - acc: 0.6085\n",
      "Epoch 00028: val_loss improved from 1.27654 to 0.90330, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/028-0.9033.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.2000 - acc: 0.6086 - val_loss: 0.9033 - val_acc: 0.7058\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1024 - acc: 0.6447\n",
      "Epoch 00029: val_loss did not improve from 0.90330\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.1026 - acc: 0.6447 - val_loss: 0.9565 - val_acc: 0.6921\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0203 - acc: 0.6684\n",
      "Epoch 00030: val_loss improved from 0.90330 to 0.81086, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/030-0.8109.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.0203 - acc: 0.6684 - val_loss: 0.8109 - val_acc: 0.7291\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9406 - acc: 0.6952\n",
      "Epoch 00031: val_loss improved from 0.81086 to 0.78597, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/031-0.7860.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.9407 - acc: 0.6952 - val_loss: 0.7860 - val_acc: 0.7570\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8736 - acc: 0.7177\n",
      "Epoch 00032: val_loss improved from 0.78597 to 0.65302, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/032-0.6530.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8736 - acc: 0.7177 - val_loss: 0.6530 - val_acc: 0.7834\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7987 - acc: 0.7426\n",
      "Epoch 00033: val_loss improved from 0.65302 to 0.54989, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/033-0.5499.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7987 - acc: 0.7426 - val_loss: 0.5499 - val_acc: 0.8216\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7486 - acc: 0.7561\n",
      "Epoch 00034: val_loss did not improve from 0.54989\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7485 - acc: 0.7561 - val_loss: 0.5909 - val_acc: 0.8125\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6908 - acc: 0.7791\n",
      "Epoch 00035: val_loss did not improve from 0.54989\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6907 - acc: 0.7791 - val_loss: 0.6198 - val_acc: 0.8081\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6357 - acc: 0.7952\n",
      "Epoch 00036: val_loss improved from 0.54989 to 0.47635, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/036-0.4763.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6358 - acc: 0.7951 - val_loss: 0.4763 - val_acc: 0.8446\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6040 - acc: 0.8059\n",
      "Epoch 00037: val_loss did not improve from 0.47635\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6041 - acc: 0.8058 - val_loss: 0.5465 - val_acc: 0.8281\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5612 - acc: 0.8200\n",
      "Epoch 00038: val_loss improved from 0.47635 to 0.34255, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/038-0.3425.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5611 - acc: 0.8199 - val_loss: 0.3425 - val_acc: 0.8942\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5201 - acc: 0.8323\n",
      "Epoch 00039: val_loss did not improve from 0.34255\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5201 - acc: 0.8323 - val_loss: 0.3775 - val_acc: 0.8784\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4821 - acc: 0.8442\n",
      "Epoch 00040: val_loss improved from 0.34255 to 0.28362, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/040-0.2836.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4821 - acc: 0.8443 - val_loss: 0.2836 - val_acc: 0.9136\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4573 - acc: 0.8542\n",
      "Epoch 00041: val_loss improved from 0.28362 to 0.25558, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/041-0.2556.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4572 - acc: 0.8542 - val_loss: 0.2556 - val_acc: 0.9189\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4316 - acc: 0.8612\n",
      "Epoch 00042: val_loss did not improve from 0.25558\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4315 - acc: 0.8613 - val_loss: 0.2643 - val_acc: 0.9171\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4086 - acc: 0.8699\n",
      "Epoch 00043: val_loss improved from 0.25558 to 0.21763, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/043-0.2176.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4086 - acc: 0.8699 - val_loss: 0.2176 - val_acc: 0.9341\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3886 - acc: 0.8765\n",
      "Epoch 00044: val_loss did not improve from 0.21763\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3886 - acc: 0.8765 - val_loss: 0.2213 - val_acc: 0.9290\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3690 - acc: 0.8829\n",
      "Epoch 00045: val_loss did not improve from 0.21763\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3690 - acc: 0.8829 - val_loss: 0.2180 - val_acc: 0.9324\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3535 - acc: 0.8902\n",
      "Epoch 00046: val_loss did not improve from 0.21763\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3536 - acc: 0.8901 - val_loss: 0.4136 - val_acc: 0.8789\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3417 - acc: 0.8921\n",
      "Epoch 00047: val_loss did not improve from 0.21763\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3417 - acc: 0.8921 - val_loss: 0.2408 - val_acc: 0.9217\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3194 - acc: 0.9001\n",
      "Epoch 00048: val_loss did not improve from 0.21763\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3194 - acc: 0.9001 - val_loss: 0.3654 - val_acc: 0.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3167 - acc: 0.8992\n",
      "Epoch 00049: val_loss improved from 0.21763 to 0.17533, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/049-0.1753.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3167 - acc: 0.8992 - val_loss: 0.1753 - val_acc: 0.9457\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2962 - acc: 0.9076\n",
      "Epoch 00050: val_loss did not improve from 0.17533\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2962 - acc: 0.9076 - val_loss: 0.1821 - val_acc: 0.9436\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2833 - acc: 0.9112\n",
      "Epoch 00051: val_loss did not improve from 0.17533\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2833 - acc: 0.9112 - val_loss: 0.1763 - val_acc: 0.9469\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2728 - acc: 0.9124\n",
      "Epoch 00052: val_loss did not improve from 0.17533\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2729 - acc: 0.9123 - val_loss: 0.1897 - val_acc: 0.9415\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2615 - acc: 0.9178\n",
      "Epoch 00053: val_loss improved from 0.17533 to 0.14370, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/053-0.1437.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2615 - acc: 0.9178 - val_loss: 0.1437 - val_acc: 0.9522\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2572 - acc: 0.9206\n",
      "Epoch 00054: val_loss did not improve from 0.14370\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2572 - acc: 0.9206 - val_loss: 0.1721 - val_acc: 0.9443\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2504 - acc: 0.9204\n",
      "Epoch 00055: val_loss did not improve from 0.14370\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2504 - acc: 0.9204 - val_loss: 0.2527 - val_acc: 0.9243\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2428 - acc: 0.9243\n",
      "Epoch 00056: val_loss did not improve from 0.14370\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2428 - acc: 0.9243 - val_loss: 0.1491 - val_acc: 0.9574\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2302 - acc: 0.9252\n",
      "Epoch 00057: val_loss improved from 0.14370 to 0.13940, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/057-0.1394.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2302 - acc: 0.9252 - val_loss: 0.1394 - val_acc: 0.9611\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2205 - acc: 0.9308\n",
      "Epoch 00058: val_loss did not improve from 0.13940\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2205 - acc: 0.9309 - val_loss: 0.1667 - val_acc: 0.9481\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2157 - acc: 0.9315\n",
      "Epoch 00059: val_loss improved from 0.13940 to 0.13165, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/059-0.1316.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2157 - acc: 0.9316 - val_loss: 0.1316 - val_acc: 0.9613\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9336\n",
      "Epoch 00060: val_loss did not improve from 0.13165\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2102 - acc: 0.9337 - val_loss: 0.1692 - val_acc: 0.9485\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9359\n",
      "Epoch 00061: val_loss did not improve from 0.13165\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2021 - acc: 0.9359 - val_loss: 0.1317 - val_acc: 0.9637\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1962 - acc: 0.9372\n",
      "Epoch 00062: val_loss improved from 0.13165 to 0.12936, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/062-0.1294.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1962 - acc: 0.9372 - val_loss: 0.1294 - val_acc: 0.9604\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1953 - acc: 0.9381\n",
      "Epoch 00063: val_loss improved from 0.12936 to 0.12645, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/063-0.1265.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1954 - acc: 0.9381 - val_loss: 0.1265 - val_acc: 0.9627\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1906 - acc: 0.9390\n",
      "Epoch 00064: val_loss did not improve from 0.12645\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1906 - acc: 0.9390 - val_loss: 0.1645 - val_acc: 0.9504\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1869 - acc: 0.9402\n",
      "Epoch 00065: val_loss did not improve from 0.12645\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1869 - acc: 0.9401 - val_loss: 0.1815 - val_acc: 0.9497\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1822 - acc: 0.9414\n",
      "Epoch 00066: val_loss improved from 0.12645 to 0.11525, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/066-0.1153.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1822 - acc: 0.9414 - val_loss: 0.1153 - val_acc: 0.9662\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9437\n",
      "Epoch 00067: val_loss did not improve from 0.11525\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1747 - acc: 0.9437 - val_loss: 0.1415 - val_acc: 0.9606\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1734 - acc: 0.9442\n",
      "Epoch 00068: val_loss did not improve from 0.11525\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1734 - acc: 0.9442 - val_loss: 0.1457 - val_acc: 0.9592\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9456\n",
      "Epoch 00069: val_loss did not improve from 0.11525\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1681 - acc: 0.9456 - val_loss: 0.1194 - val_acc: 0.9655\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9461\n",
      "Epoch 00070: val_loss did not improve from 0.11525\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1668 - acc: 0.9461 - val_loss: 0.1589 - val_acc: 0.9569\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9470\n",
      "Epoch 00071: val_loss did not improve from 0.11525\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1620 - acc: 0.9470 - val_loss: 0.1194 - val_acc: 0.9655\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9494\n",
      "Epoch 00072: val_loss did not improve from 0.11525\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1567 - acc: 0.9494 - val_loss: 0.1702 - val_acc: 0.9474\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9488\n",
      "Epoch 00073: val_loss did not improve from 0.11525\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1587 - acc: 0.9488 - val_loss: 0.1217 - val_acc: 0.9644\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1518 - acc: 0.9515\n",
      "Epoch 00074: val_loss improved from 0.11525 to 0.11124, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/074-0.1112.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1518 - acc: 0.9515 - val_loss: 0.1112 - val_acc: 0.9695\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9543\n",
      "Epoch 00075: val_loss did not improve from 0.11124\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1451 - acc: 0.9543 - val_loss: 0.1223 - val_acc: 0.9655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9547\n",
      "Epoch 00076: val_loss did not improve from 0.11124\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1454 - acc: 0.9547 - val_loss: 0.1130 - val_acc: 0.9644\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9554\n",
      "Epoch 00077: val_loss did not improve from 0.11124\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1383 - acc: 0.9554 - val_loss: 0.1264 - val_acc: 0.9634\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9556\n",
      "Epoch 00078: val_loss did not improve from 0.11124\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1371 - acc: 0.9556 - val_loss: 0.1357 - val_acc: 0.9611\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9566\n",
      "Epoch 00079: val_loss did not improve from 0.11124\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1362 - acc: 0.9566 - val_loss: 0.1117 - val_acc: 0.9669\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9564\n",
      "Epoch 00080: val_loss did not improve from 0.11124\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1320 - acc: 0.9564 - val_loss: 0.1394 - val_acc: 0.9590\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9565\n",
      "Epoch 00081: val_loss improved from 0.11124 to 0.10693, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/081-0.1069.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1298 - acc: 0.9565 - val_loss: 0.1069 - val_acc: 0.9688\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9579\n",
      "Epoch 00082: val_loss did not improve from 0.10693\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1304 - acc: 0.9579 - val_loss: 0.2519 - val_acc: 0.9453\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9549\n",
      "Epoch 00083: val_loss did not improve from 0.10693\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1390 - acc: 0.9549 - val_loss: 0.1196 - val_acc: 0.9669\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9594\n",
      "Epoch 00084: val_loss did not improve from 0.10693\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1229 - acc: 0.9594 - val_loss: 0.1152 - val_acc: 0.9693\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9617\n",
      "Epoch 00085: val_loss did not improve from 0.10693\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1196 - acc: 0.9617 - val_loss: 0.2726 - val_acc: 0.9297\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9569\n",
      "Epoch 00086: val_loss did not improve from 0.10693\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1305 - acc: 0.9569 - val_loss: 0.1170 - val_acc: 0.9665\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9619\n",
      "Epoch 00087: val_loss did not improve from 0.10693\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1140 - acc: 0.9619 - val_loss: 0.1148 - val_acc: 0.9681\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9634\n",
      "Epoch 00088: val_loss improved from 0.10693 to 0.10353, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/088-0.1035.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1147 - acc: 0.9634 - val_loss: 0.1035 - val_acc: 0.9713\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9637\n",
      "Epoch 00089: val_loss did not improve from 0.10353\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1134 - acc: 0.9637 - val_loss: 0.1094 - val_acc: 0.9681\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9655\n",
      "Epoch 00090: val_loss did not improve from 0.10353\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1086 - acc: 0.9655 - val_loss: 0.1242 - val_acc: 0.9676\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9633\n",
      "Epoch 00091: val_loss did not improve from 0.10353\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1111 - acc: 0.9633 - val_loss: 0.1268 - val_acc: 0.9669\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9650\n",
      "Epoch 00092: val_loss did not improve from 0.10353\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1046 - acc: 0.9650 - val_loss: 0.1179 - val_acc: 0.9688\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9655\n",
      "Epoch 00093: val_loss did not improve from 0.10353\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1060 - acc: 0.9655 - val_loss: 0.1165 - val_acc: 0.9658\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9661\n",
      "Epoch 00094: val_loss did not improve from 0.10353\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1055 - acc: 0.9661 - val_loss: 0.1454 - val_acc: 0.9611\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9652\n",
      "Epoch 00095: val_loss did not improve from 0.10353\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1064 - acc: 0.9652 - val_loss: 0.1438 - val_acc: 0.9646\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9646\n",
      "Epoch 00096: val_loss did not improve from 0.10353\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1068 - acc: 0.9646 - val_loss: 0.1066 - val_acc: 0.9686\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9666\n",
      "Epoch 00097: val_loss did not improve from 0.10353\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1011 - acc: 0.9666 - val_loss: 0.1221 - val_acc: 0.9623\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9676\n",
      "Epoch 00098: val_loss did not improve from 0.10353\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0978 - acc: 0.9676 - val_loss: 0.1359 - val_acc: 0.9646\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9683\n",
      "Epoch 00099: val_loss did not improve from 0.10353\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0959 - acc: 0.9683 - val_loss: 0.1085 - val_acc: 0.9695\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9678\n",
      "Epoch 00100: val_loss did not improve from 0.10353\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0997 - acc: 0.9678 - val_loss: 0.1050 - val_acc: 0.9704\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9702\n",
      "Epoch 00101: val_loss improved from 0.10353 to 0.09672, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv_checkpoint/101-0.0967.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0912 - acc: 0.9702 - val_loss: 0.0967 - val_acc: 0.9723\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9692\n",
      "Epoch 00102: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0919 - acc: 0.9691 - val_loss: 0.1191 - val_acc: 0.9679\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9698\n",
      "Epoch 00103: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0919 - acc: 0.9698 - val_loss: 0.1125 - val_acc: 0.9711\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9706\n",
      "Epoch 00104: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0900 - acc: 0.9706 - val_loss: 0.1089 - val_acc: 0.9695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9701\n",
      "Epoch 00105: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0886 - acc: 0.9701 - val_loss: 0.1173 - val_acc: 0.9686\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9710\n",
      "Epoch 00106: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0887 - acc: 0.9710 - val_loss: 0.1038 - val_acc: 0.9697\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9729\n",
      "Epoch 00107: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0814 - acc: 0.9729 - val_loss: 0.1079 - val_acc: 0.9695\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9727\n",
      "Epoch 00108: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0836 - acc: 0.9727 - val_loss: 0.1265 - val_acc: 0.9660\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9721\n",
      "Epoch 00109: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0837 - acc: 0.9721 - val_loss: 0.1124 - val_acc: 0.9723\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9725\n",
      "Epoch 00110: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0831 - acc: 0.9725 - val_loss: 0.1108 - val_acc: 0.9709\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9740\n",
      "Epoch 00111: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0791 - acc: 0.9741 - val_loss: 0.1198 - val_acc: 0.9693\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9742\n",
      "Epoch 00112: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0787 - acc: 0.9742 - val_loss: 0.1063 - val_acc: 0.9725\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9724\n",
      "Epoch 00113: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0810 - acc: 0.9724 - val_loss: 0.1275 - val_acc: 0.9702\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9736\n",
      "Epoch 00114: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0775 - acc: 0.9736 - val_loss: 0.1522 - val_acc: 0.9543\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9698\n",
      "Epoch 00115: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0906 - acc: 0.9698 - val_loss: 0.1188 - val_acc: 0.9720\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9766\n",
      "Epoch 00116: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0740 - acc: 0.9766 - val_loss: 0.1205 - val_acc: 0.9720\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9756\n",
      "Epoch 00117: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0718 - acc: 0.9756 - val_loss: 0.1300 - val_acc: 0.9690\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9767\n",
      "Epoch 00118: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0722 - acc: 0.9767 - val_loss: 0.1210 - val_acc: 0.9700\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9758\n",
      "Epoch 00119: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0735 - acc: 0.9758 - val_loss: 0.1092 - val_acc: 0.9706\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9775\n",
      "Epoch 00120: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0699 - acc: 0.9775 - val_loss: 0.1213 - val_acc: 0.9697\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9776\n",
      "Epoch 00121: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0656 - acc: 0.9776 - val_loss: 0.1324 - val_acc: 0.9688\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9776\n",
      "Epoch 00122: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0667 - acc: 0.9776 - val_loss: 0.1052 - val_acc: 0.9727\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9787\n",
      "Epoch 00123: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0657 - acc: 0.9787 - val_loss: 0.1241 - val_acc: 0.9702\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9768\n",
      "Epoch 00124: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0694 - acc: 0.9768 - val_loss: 0.1259 - val_acc: 0.9688\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9770\n",
      "Epoch 00125: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0697 - acc: 0.9770 - val_loss: 0.1236 - val_acc: 0.9704\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9788\n",
      "Epoch 00126: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0630 - acc: 0.9788 - val_loss: 0.1116 - val_acc: 0.9704\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9774\n",
      "Epoch 00127: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0681 - acc: 0.9774 - val_loss: 0.1277 - val_acc: 0.9693\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9795\n",
      "Epoch 00128: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0616 - acc: 0.9795 - val_loss: 0.1274 - val_acc: 0.9709\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9796\n",
      "Epoch 00129: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0618 - acc: 0.9796 - val_loss: 0.1215 - val_acc: 0.9706\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9790\n",
      "Epoch 00130: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0629 - acc: 0.9791 - val_loss: 0.1229 - val_acc: 0.9679\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9792\n",
      "Epoch 00131: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0611 - acc: 0.9792 - val_loss: 0.1368 - val_acc: 0.9681\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9818\n",
      "Epoch 00132: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0577 - acc: 0.9819 - val_loss: 0.1256 - val_acc: 0.9693\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9797\n",
      "Epoch 00133: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0617 - acc: 0.9797 - val_loss: 0.1532 - val_acc: 0.9613\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9798\n",
      "Epoch 00134: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0613 - acc: 0.9798 - val_loss: 0.1213 - val_acc: 0.9713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9808\n",
      "Epoch 00135: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0561 - acc: 0.9808 - val_loss: 0.1226 - val_acc: 0.9723\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9806\n",
      "Epoch 00136: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0616 - acc: 0.9806 - val_loss: 0.1091 - val_acc: 0.9723\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9814\n",
      "Epoch 00137: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0555 - acc: 0.9814 - val_loss: 0.1319 - val_acc: 0.9713\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9812\n",
      "Epoch 00138: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0556 - acc: 0.9812 - val_loss: 0.1292 - val_acc: 0.9686\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9813\n",
      "Epoch 00139: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0544 - acc: 0.9813 - val_loss: 0.1265 - val_acc: 0.9718\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9836\n",
      "Epoch 00140: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0488 - acc: 0.9836 - val_loss: 0.1399 - val_acc: 0.9683\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9823\n",
      "Epoch 00141: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0518 - acc: 0.9823 - val_loss: 0.1406 - val_acc: 0.9683\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9811\n",
      "Epoch 00142: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0580 - acc: 0.9811 - val_loss: 0.1236 - val_acc: 0.9700\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9822\n",
      "Epoch 00143: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0542 - acc: 0.9822 - val_loss: 0.1290 - val_acc: 0.9688\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9826\n",
      "Epoch 00144: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0508 - acc: 0.9826 - val_loss: 0.1327 - val_acc: 0.9711\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9827\n",
      "Epoch 00145: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0523 - acc: 0.9827 - val_loss: 0.1223 - val_acc: 0.9727\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9838\n",
      "Epoch 00146: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0486 - acc: 0.9838 - val_loss: 0.1333 - val_acc: 0.9686\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9844\n",
      "Epoch 00147: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0483 - acc: 0.9844 - val_loss: 0.1238 - val_acc: 0.9711\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9833\n",
      "Epoch 00148: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0517 - acc: 0.9833 - val_loss: 0.1174 - val_acc: 0.9676\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9832\n",
      "Epoch 00149: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0502 - acc: 0.9832 - val_loss: 0.1367 - val_acc: 0.9702\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9842\n",
      "Epoch 00150: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0477 - acc: 0.9842 - val_loss: 0.1280 - val_acc: 0.9711\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9837\n",
      "Epoch 00151: val_loss did not improve from 0.09672\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0476 - acc: 0.9837 - val_loss: 0.1435 - val_acc: 0.9658\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 978us/sample - loss: 0.1351 - acc: 0.9603\n",
      "Loss: 0.1350821490982704 Accuracy: 0.9603323\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7466 - acc: 0.0786\n",
      "Epoch 00001: val_loss improved from inf to 2.72701, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/001-2.7270.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 2.7466 - acc: 0.0786 - val_loss: 2.7270 - val_acc: 0.0785\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7282 - acc: 0.0785\n",
      "Epoch 00002: val_loss improved from 2.72701 to 2.72011, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/002-2.7201.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7282 - acc: 0.0785 - val_loss: 2.7201 - val_acc: 0.0818\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7255 - acc: 0.0796\n",
      "Epoch 00003: val_loss improved from 2.72011 to 2.71973, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/003-2.7197.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7255 - acc: 0.0796 - val_loss: 2.7197 - val_acc: 0.0820\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7243 - acc: 0.0804\n",
      "Epoch 00004: val_loss improved from 2.71973 to 2.71905, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/004-2.7190.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7243 - acc: 0.0804 - val_loss: 2.7190 - val_acc: 0.0820\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7243 - acc: 0.0786\n",
      "Epoch 00005: val_loss improved from 2.71905 to 2.71892, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/005-2.7189.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7243 - acc: 0.0786 - val_loss: 2.7189 - val_acc: 0.0820\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7230 - acc: 0.0787\n",
      "Epoch 00006: val_loss improved from 2.71892 to 2.71877, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/006-2.7188.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7231 - acc: 0.0787 - val_loss: 2.7188 - val_acc: 0.0820\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7227 - acc: 0.0809\n",
      "Epoch 00007: val_loss improved from 2.71877 to 2.71865, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/007-2.7187.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7227 - acc: 0.0809 - val_loss: 2.7187 - val_acc: 0.0820\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7229 - acc: 0.0785\n",
      "Epoch 00008: val_loss improved from 2.71865 to 2.71863, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/008-2.7186.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7229 - acc: 0.0785 - val_loss: 2.7186 - val_acc: 0.0820\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7222 - acc: 0.0805\n",
      "Epoch 00009: val_loss improved from 2.71863 to 2.71848, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/009-2.7185.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7222 - acc: 0.0805 - val_loss: 2.7185 - val_acc: 0.0820\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7215 - acc: 0.0810\n",
      "Epoch 00010: val_loss improved from 2.71848 to 2.71786, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/010-2.7179.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7214 - acc: 0.0810 - val_loss: 2.7179 - val_acc: 0.0820\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7214 - acc: 0.0820\n",
      "Epoch 00011: val_loss improved from 2.71786 to 2.71742, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/011-2.7174.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7214 - acc: 0.0819 - val_loss: 2.7174 - val_acc: 0.0985\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7199 - acc: 0.0861\n",
      "Epoch 00012: val_loss improved from 2.71742 to 2.71564, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/012-2.7156.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7199 - acc: 0.0860 - val_loss: 2.7156 - val_acc: 0.0867\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7173 - acc: 0.0928\n",
      "Epoch 00013: val_loss improved from 2.71564 to 2.71105, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/013-2.7110.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7172 - acc: 0.0928 - val_loss: 2.7110 - val_acc: 0.1009\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7101 - acc: 0.1052\n",
      "Epoch 00014: val_loss improved from 2.71105 to 2.69570, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/014-2.6957.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.7101 - acc: 0.1051 - val_loss: 2.6957 - val_acc: 0.1554\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6814 - acc: 0.1368\n",
      "Epoch 00015: val_loss improved from 2.69570 to 2.63404, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/015-2.6340.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.6814 - acc: 0.1368 - val_loss: 2.6340 - val_acc: 0.1794\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6005 - acc: 0.1658\n",
      "Epoch 00016: val_loss improved from 2.63404 to 2.54423, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/016-2.5442.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.6006 - acc: 0.1658 - val_loss: 2.5442 - val_acc: 0.1703\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5032 - acc: 0.1843\n",
      "Epoch 00017: val_loss improved from 2.54423 to 2.44045, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/017-2.4405.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.5032 - acc: 0.1843 - val_loss: 2.4405 - val_acc: 0.1989\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3970 - acc: 0.2156\n",
      "Epoch 00018: val_loss improved from 2.44045 to 2.31355, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/018-2.3135.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.3969 - acc: 0.2157 - val_loss: 2.3135 - val_acc: 0.2681\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2580 - acc: 0.2739\n",
      "Epoch 00019: val_loss improved from 2.31355 to 2.03989, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/019-2.0399.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.2580 - acc: 0.2738 - val_loss: 2.0399 - val_acc: 0.3541\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0633 - acc: 0.3372\n",
      "Epoch 00020: val_loss improved from 2.03989 to 1.84941, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/020-1.8494.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.0633 - acc: 0.3372 - val_loss: 1.8494 - val_acc: 0.3960\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8542 - acc: 0.3960\n",
      "Epoch 00021: val_loss did not improve from 1.84941\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.8542 - acc: 0.3960 - val_loss: 2.6588 - val_acc: 0.2052\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5882 - acc: 0.4775\n",
      "Epoch 00022: val_loss improved from 1.84941 to 1.33196, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/022-1.3320.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.5881 - acc: 0.4775 - val_loss: 1.3320 - val_acc: 0.5581\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3383 - acc: 0.5603\n",
      "Epoch 00023: val_loss improved from 1.33196 to 1.10612, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/023-1.1061.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.3382 - acc: 0.5603 - val_loss: 1.1061 - val_acc: 0.6508\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1649 - acc: 0.6192\n",
      "Epoch 00024: val_loss improved from 1.10612 to 0.93306, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/024-0.9331.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.1649 - acc: 0.6192 - val_loss: 0.9331 - val_acc: 0.6956\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0419 - acc: 0.6646\n",
      "Epoch 00025: val_loss improved from 0.93306 to 0.77193, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/025-0.7719.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.0418 - acc: 0.6646 - val_loss: 0.7719 - val_acc: 0.7442\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9523 - acc: 0.6941\n",
      "Epoch 00026: val_loss improved from 0.77193 to 0.70272, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/026-0.7027.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9522 - acc: 0.6941 - val_loss: 0.7027 - val_acc: 0.7652\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8675 - acc: 0.7227\n",
      "Epoch 00027: val_loss improved from 0.70272 to 0.66381, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/027-0.6638.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8675 - acc: 0.7226 - val_loss: 0.6638 - val_acc: 0.7731\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8115 - acc: 0.7421\n",
      "Epoch 00028: val_loss improved from 0.66381 to 0.63219, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/028-0.6322.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8114 - acc: 0.7421 - val_loss: 0.6322 - val_acc: 0.7885\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7469 - acc: 0.7614\n",
      "Epoch 00029: val_loss improved from 0.63219 to 0.62455, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/029-0.6246.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7468 - acc: 0.7614 - val_loss: 0.6246 - val_acc: 0.7899\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7019 - acc: 0.7734\n",
      "Epoch 00030: val_loss improved from 0.62455 to 0.56483, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/030-0.5648.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7018 - acc: 0.7734 - val_loss: 0.5648 - val_acc: 0.8106\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6620 - acc: 0.7903\n",
      "Epoch 00031: val_loss did not improve from 0.56483\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6620 - acc: 0.7903 - val_loss: 0.6148 - val_acc: 0.7987\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6233 - acc: 0.8019\n",
      "Epoch 00032: val_loss improved from 0.56483 to 0.54913, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/032-0.5491.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6233 - acc: 0.8019 - val_loss: 0.5491 - val_acc: 0.8176\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5853 - acc: 0.8140\n",
      "Epoch 00033: val_loss improved from 0.54913 to 0.47813, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/033-0.4781.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5852 - acc: 0.8140 - val_loss: 0.4781 - val_acc: 0.8451\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5506 - acc: 0.8270\n",
      "Epoch 00034: val_loss improved from 0.47813 to 0.46371, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/034-0.4637.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5506 - acc: 0.8270 - val_loss: 0.4637 - val_acc: 0.8505\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5167 - acc: 0.8370\n",
      "Epoch 00035: val_loss did not improve from 0.46371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5167 - acc: 0.8370 - val_loss: 0.5130 - val_acc: 0.8351\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4838 - acc: 0.8455\n",
      "Epoch 00036: val_loss improved from 0.46371 to 0.45802, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/036-0.4580.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4837 - acc: 0.8455 - val_loss: 0.4580 - val_acc: 0.8598\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4446 - acc: 0.8634\n",
      "Epoch 00037: val_loss improved from 0.45802 to 0.35684, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/037-0.3568.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4445 - acc: 0.8634 - val_loss: 0.3568 - val_acc: 0.8870\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4166 - acc: 0.8683\n",
      "Epoch 00038: val_loss improved from 0.35684 to 0.31158, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/038-0.3116.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4165 - acc: 0.8683 - val_loss: 0.3116 - val_acc: 0.9022\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3888 - acc: 0.8784\n",
      "Epoch 00039: val_loss did not improve from 0.31158\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3888 - acc: 0.8784 - val_loss: 0.5396 - val_acc: 0.8539\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3547 - acc: 0.8890\n",
      "Epoch 00040: val_loss did not improve from 0.31158\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3547 - acc: 0.8890 - val_loss: 0.3417 - val_acc: 0.8956\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3224 - acc: 0.8986\n",
      "Epoch 00041: val_loss improved from 0.31158 to 0.25800, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/041-0.2580.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3225 - acc: 0.8985 - val_loss: 0.2580 - val_acc: 0.9147\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3094 - acc: 0.9071\n",
      "Epoch 00042: val_loss improved from 0.25800 to 0.22758, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/042-0.2276.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3094 - acc: 0.9071 - val_loss: 0.2276 - val_acc: 0.9304\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2813 - acc: 0.9151\n",
      "Epoch 00043: val_loss did not improve from 0.22758\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2813 - acc: 0.9151 - val_loss: 0.2348 - val_acc: 0.9324\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2602 - acc: 0.9201\n",
      "Epoch 00044: val_loss improved from 0.22758 to 0.21911, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/044-0.2191.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2602 - acc: 0.9201 - val_loss: 0.2191 - val_acc: 0.9306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2504 - acc: 0.9215\n",
      "Epoch 00045: val_loss improved from 0.21911 to 0.20724, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/045-0.2072.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2504 - acc: 0.9215 - val_loss: 0.2072 - val_acc: 0.9378\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2282 - acc: 0.9286\n",
      "Epoch 00046: val_loss did not improve from 0.20724\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2282 - acc: 0.9285 - val_loss: 0.3028 - val_acc: 0.9115\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2216 - acc: 0.9313\n",
      "Epoch 00047: val_loss improved from 0.20724 to 0.17735, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/047-0.1773.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2217 - acc: 0.9313 - val_loss: 0.1773 - val_acc: 0.9453\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2079 - acc: 0.9364\n",
      "Epoch 00048: val_loss did not improve from 0.17735\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2079 - acc: 0.9363 - val_loss: 0.1863 - val_acc: 0.9464\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1970 - acc: 0.9391\n",
      "Epoch 00049: val_loss improved from 0.17735 to 0.16493, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/049-0.1649.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1970 - acc: 0.9391 - val_loss: 0.1649 - val_acc: 0.9509\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1856 - acc: 0.9411\n",
      "Epoch 00050: val_loss did not improve from 0.16493\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1856 - acc: 0.9411 - val_loss: 0.1723 - val_acc: 0.9499\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1794 - acc: 0.9445\n",
      "Epoch 00051: val_loss did not improve from 0.16493\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1794 - acc: 0.9445 - val_loss: 0.2130 - val_acc: 0.9406\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1743 - acc: 0.9459\n",
      "Epoch 00052: val_loss did not improve from 0.16493\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1743 - acc: 0.9459 - val_loss: 0.2041 - val_acc: 0.9448\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9490\n",
      "Epoch 00053: val_loss did not improve from 0.16493\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1653 - acc: 0.9490 - val_loss: 0.1720 - val_acc: 0.9495\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1570 - acc: 0.9508\n",
      "Epoch 00054: val_loss did not improve from 0.16493\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1570 - acc: 0.9508 - val_loss: 0.1702 - val_acc: 0.9506\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9539\n",
      "Epoch 00055: val_loss did not improve from 0.16493\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1492 - acc: 0.9539 - val_loss: 0.3263 - val_acc: 0.9150\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9517\n",
      "Epoch 00056: val_loss improved from 0.16493 to 0.16335, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/056-0.1634.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1512 - acc: 0.9517 - val_loss: 0.1634 - val_acc: 0.9490\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9544\n",
      "Epoch 00057: val_loss did not improve from 0.16335\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1420 - acc: 0.9544 - val_loss: 0.1654 - val_acc: 0.9534\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9568\n",
      "Epoch 00058: val_loss improved from 0.16335 to 0.14686, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/058-0.1469.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1349 - acc: 0.9568 - val_loss: 0.1469 - val_acc: 0.9534\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9597\n",
      "Epoch 00059: val_loss did not improve from 0.14686\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1282 - acc: 0.9597 - val_loss: 0.1617 - val_acc: 0.9532\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9617\n",
      "Epoch 00060: val_loss did not improve from 0.14686\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1203 - acc: 0.9617 - val_loss: 0.1686 - val_acc: 0.9515\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9619\n",
      "Epoch 00061: val_loss did not improve from 0.14686\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1220 - acc: 0.9618 - val_loss: 0.1792 - val_acc: 0.9511\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9641\n",
      "Epoch 00062: val_loss did not improve from 0.14686\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1137 - acc: 0.9641 - val_loss: 0.1485 - val_acc: 0.9578\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9645\n",
      "Epoch 00063: val_loss did not improve from 0.14686\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1085 - acc: 0.9645 - val_loss: 0.1582 - val_acc: 0.9560\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9668\n",
      "Epoch 00064: val_loss did not improve from 0.14686\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1050 - acc: 0.9668 - val_loss: 0.1637 - val_acc: 0.9546\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9678\n",
      "Epoch 00065: val_loss did not improve from 0.14686\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1027 - acc: 0.9678 - val_loss: 0.1685 - val_acc: 0.9560\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9670\n",
      "Epoch 00066: val_loss did not improve from 0.14686\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1047 - acc: 0.9670 - val_loss: 0.1608 - val_acc: 0.9583\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9689\n",
      "Epoch 00067: val_loss improved from 0.14686 to 0.14641, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv_checkpoint/067-0.1464.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0970 - acc: 0.9689 - val_loss: 0.1464 - val_acc: 0.9553\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9691\n",
      "Epoch 00068: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0946 - acc: 0.9691 - val_loss: 0.1560 - val_acc: 0.9555\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9707\n",
      "Epoch 00069: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0917 - acc: 0.9707 - val_loss: 0.1567 - val_acc: 0.9616\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9705\n",
      "Epoch 00070: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0895 - acc: 0.9705 - val_loss: 0.1812 - val_acc: 0.9513\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9709\n",
      "Epoch 00071: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0901 - acc: 0.9709 - val_loss: 0.1695 - val_acc: 0.9571\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9731\n",
      "Epoch 00072: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0836 - acc: 0.9731 - val_loss: 0.1542 - val_acc: 0.9609\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9724\n",
      "Epoch 00073: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0821 - acc: 0.9724 - val_loss: 0.1799 - val_acc: 0.9520\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9736\n",
      "Epoch 00074: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0794 - acc: 0.9736 - val_loss: 0.1584 - val_acc: 0.9595\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9752\n",
      "Epoch 00075: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0784 - acc: 0.9752 - val_loss: 0.1617 - val_acc: 0.9567\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9754\n",
      "Epoch 00076: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0730 - acc: 0.9754 - val_loss: 0.1648 - val_acc: 0.9599\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9762\n",
      "Epoch 00077: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0726 - acc: 0.9762 - val_loss: 0.1854 - val_acc: 0.9557\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9751\n",
      "Epoch 00078: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0745 - acc: 0.9751 - val_loss: 0.1585 - val_acc: 0.9606\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9764\n",
      "Epoch 00079: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0703 - acc: 0.9764 - val_loss: 0.1645 - val_acc: 0.9560\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9779\n",
      "Epoch 00080: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0679 - acc: 0.9779 - val_loss: 0.1705 - val_acc: 0.9550\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9774\n",
      "Epoch 00081: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0689 - acc: 0.9774 - val_loss: 0.1842 - val_acc: 0.9562\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9784\n",
      "Epoch 00082: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0675 - acc: 0.9784 - val_loss: 0.1691 - val_acc: 0.9609\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9804\n",
      "Epoch 00083: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0620 - acc: 0.9804 - val_loss: 0.1628 - val_acc: 0.9581\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9795\n",
      "Epoch 00084: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0623 - acc: 0.9795 - val_loss: 0.1482 - val_acc: 0.9606\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9806\n",
      "Epoch 00085: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0589 - acc: 0.9806 - val_loss: 0.1731 - val_acc: 0.9581\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9821\n",
      "Epoch 00086: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0547 - acc: 0.9821 - val_loss: 0.1701 - val_acc: 0.9618\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9801\n",
      "Epoch 00087: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0588 - acc: 0.9801 - val_loss: 0.1780 - val_acc: 0.9590\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9798\n",
      "Epoch 00088: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0604 - acc: 0.9798 - val_loss: 0.1813 - val_acc: 0.9592\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9815\n",
      "Epoch 00089: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0552 - acc: 0.9816 - val_loss: 0.1630 - val_acc: 0.9630\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9824\n",
      "Epoch 00090: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0547 - acc: 0.9824 - val_loss: 0.1804 - val_acc: 0.9599\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9822\n",
      "Epoch 00091: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0535 - acc: 0.9822 - val_loss: 0.2333 - val_acc: 0.9539\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9823\n",
      "Epoch 00092: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0540 - acc: 0.9823 - val_loss: 0.1696 - val_acc: 0.9613\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9837\n",
      "Epoch 00093: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0494 - acc: 0.9837 - val_loss: 0.1789 - val_acc: 0.9588\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9821\n",
      "Epoch 00094: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0530 - acc: 0.9821 - val_loss: 0.1860 - val_acc: 0.9595\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9825\n",
      "Epoch 00095: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0521 - acc: 0.9825 - val_loss: 0.1810 - val_acc: 0.9632\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9850\n",
      "Epoch 00096: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0472 - acc: 0.9850 - val_loss: 0.1834 - val_acc: 0.9613\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9841\n",
      "Epoch 00097: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0477 - acc: 0.9841 - val_loss: 0.1810 - val_acc: 0.9606\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9848\n",
      "Epoch 00098: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0468 - acc: 0.9848 - val_loss: 0.2038 - val_acc: 0.9543\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9864\n",
      "Epoch 00099: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0437 - acc: 0.9864 - val_loss: 0.1832 - val_acc: 0.9623\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9866\n",
      "Epoch 00100: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0419 - acc: 0.9866 - val_loss: 0.1980 - val_acc: 0.9590\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9838\n",
      "Epoch 00101: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0479 - acc: 0.9838 - val_loss: 0.1762 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9869\n",
      "Epoch 00102: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0390 - acc: 0.9869 - val_loss: 0.2285 - val_acc: 0.9581\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9864\n",
      "Epoch 00103: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0410 - acc: 0.9863 - val_loss: 0.1932 - val_acc: 0.9583\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9845\n",
      "Epoch 00104: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0473 - acc: 0.9845 - val_loss: 0.2210 - val_acc: 0.9597\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9875\n",
      "Epoch 00105: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0384 - acc: 0.9875 - val_loss: 0.1874 - val_acc: 0.9620\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9867\n",
      "Epoch 00106: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0399 - acc: 0.9867 - val_loss: 0.1958 - val_acc: 0.9618\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9881\n",
      "Epoch 00107: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0348 - acc: 0.9881 - val_loss: 0.2172 - val_acc: 0.9578\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9882\n",
      "Epoch 00108: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0353 - acc: 0.9882 - val_loss: 0.2018 - val_acc: 0.9644\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9878\n",
      "Epoch 00109: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0358 - acc: 0.9878 - val_loss: 0.2176 - val_acc: 0.9571\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9886\n",
      "Epoch 00110: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0355 - acc: 0.9886 - val_loss: 0.1906 - val_acc: 0.9655\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9890\n",
      "Epoch 00111: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0341 - acc: 0.9890 - val_loss: 0.2222 - val_acc: 0.9627\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9874\n",
      "Epoch 00112: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0383 - acc: 0.9874 - val_loss: 0.2081 - val_acc: 0.9595\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9890\n",
      "Epoch 00113: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0319 - acc: 0.9890 - val_loss: 0.2224 - val_acc: 0.9616\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9888\n",
      "Epoch 00114: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0345 - acc: 0.9888 - val_loss: 0.2341 - val_acc: 0.9576\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9885\n",
      "Epoch 00115: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0368 - acc: 0.9885 - val_loss: 0.1968 - val_acc: 0.9651\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9875\n",
      "Epoch 00116: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0383 - acc: 0.9875 - val_loss: 0.2010 - val_acc: 0.9651\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9880\n",
      "Epoch 00117: val_loss did not improve from 0.14641\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0365 - acc: 0.9880 - val_loss: 0.1904 - val_acc: 0.9609\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 959us/sample - loss: 0.2045 - acc: 0.9421\n",
      "Loss: 0.2044540225886977 Accuracy: 0.94205606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD'\n",
    "\n",
    "for i in range(8, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_075_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=SGD(lr=0.001, momentum=0.9, decay=1e-6, nesterov=True),\n",
    "                  metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "    \n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 875us/sample - loss: 1.2714 - acc: 0.6195\n",
      "Loss: 1.2713904990833 Accuracy: 0.61952233\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 918us/sample - loss: 0.7915 - acc: 0.7801\n",
      "Loss: 0.7915258266225164 Accuracy: 0.7800623\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 964us/sample - loss: 0.5926 - acc: 0.8594\n",
      "Loss: 0.592554632711262 Accuracy: 0.8593977\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_114 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 965us/sample - loss: 2.7130 - acc: 0.0781\n",
      "Loss: 2.7129934609493365 Accuracy: 0.078089304\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_126 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 989us/sample - loss: 0.2081 - acc: 0.9475\n",
      "Loss: 0.2080932543262441 Accuracy: 0.9474559\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1351 - acc: 0.9603\n",
      "Loss: 0.1350821490982704 Accuracy: 0.9603323\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_106 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2045 - acc: 0.9421\n",
      "Loss: 0.2044540225886977 Accuracy: 0.94205606\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 901us/sample - loss: 1.5248 - acc: 0.6839\n",
      "Loss: 1.5247803859869145 Accuracy: 0.68390447\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 961us/sample - loss: 0.9413 - acc: 0.8004\n",
      "Loss: 0.9412812744902673 Accuracy: 0.8004154\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 997us/sample - loss: 0.6436 - acc: 0.8619\n",
      "Loss: 0.6436304615913027 Accuracy: 0.8618899\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_114 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 2.7131 - acc: 0.0800\n",
      "Loss: 2.713131129382679 Accuracy: 0.07995846\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_126 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2238 - acc: 0.9456\n",
      "Loss: 0.22379237889792858 Accuracy: 0.9455867\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1520 - acc: 0.9616\n",
      "Loss: 0.15201902663252276 Accuracy: 0.9615784\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_075_DO_SGD_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_106 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2661 - acc: 0.9510\n",
      "Loss: 0.2661246947166974 Accuracy: 0.9509865\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_conv_3_VGG_DO_075_DO'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
