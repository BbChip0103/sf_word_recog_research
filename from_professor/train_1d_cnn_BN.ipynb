{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "import scipy.io as sio\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(wav):\n",
    "    wav = sklearn.preprocessing.maxabs_scale(wav)\n",
    "    wav_mfcc = librosa.feature.mfcc(y=wav, n_mfcc=13)\n",
    "    wav_mfcc_std = StandardScaler().fit_transform(wav_mfcc)\n",
    "    wav_mfcc_std_mean = wav_mfcc_std.mean(axis=1)\n",
    "\n",
    "    features = np.concatenate([wav_mfcc_std_mean])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batchnorm_cnn(conv_num=1, fcn_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D(kernel_size=25, filters=8, strides=1, padding='valid', \n",
    "                  activation='relu', input_shape=input_shape))  \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=4, strides=4, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=25, filters=8*(2**(i+1)), strides=1, padding='valid', \n",
    "                          activation='relu'))  \n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=4, strides=4, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for i in range(fcn_num):\n",
    "        model.add(Dense( 1024/(2**i), activation='relu' ))\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = build_cnn(conv_num=3, fcn_num=1)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4757 - acc: 0.3335\n",
      "Epoch 00001: val_loss improved from inf to 1.66259, saving model to model/checkpoint/1D_BN_CNN_1_conv_1_fcn_checkpoint/01-1.6626.hdf5\n",
      "36805/36805 [==============================] - 32s 856us/step - loss: 2.4756 - acc: 0.3335 - val_loss: 1.6626 - val_acc: 0.5479\n",
      "Epoch 2/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3266 - acc: 0.5931\n",
      "Epoch 00002: val_loss improved from 1.66259 to 1.14209, saving model to model/checkpoint/1D_BN_CNN_1_conv_1_fcn_checkpoint/02-1.1421.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/step - loss: 1.3264 - acc: 0.5932 - val_loss: 1.1421 - val_acc: 0.6536\n",
      "Epoch 3/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8941 - acc: 0.7200\n",
      "Epoch 00003: val_loss improved from 1.14209 to 1.07957, saving model to model/checkpoint/1D_BN_CNN_1_conv_1_fcn_checkpoint/03-1.0796.hdf5\n",
      "36805/36805 [==============================] - 29s 789us/step - loss: 0.8946 - acc: 0.7201 - val_loss: 1.0796 - val_acc: 0.6730\n",
      "Epoch 4/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6279 - acc: 0.8022\n",
      "Epoch 00004: val_loss improved from 1.07957 to 1.00712, saving model to model/checkpoint/1D_BN_CNN_1_conv_1_fcn_checkpoint/04-1.0071.hdf5\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.6285 - acc: 0.8019 - val_loss: 1.0071 - val_acc: 0.6965\n",
      "Epoch 5/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4720 - acc: 0.8558\n",
      "Epoch 00005: val_loss did not improve from 1.00712\n",
      "36805/36805 [==============================] - 29s 785us/step - loss: 0.4720 - acc: 0.8558 - val_loss: 1.0145 - val_acc: 0.7149\n",
      "Epoch 6/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3594 - acc: 0.8912\n",
      "Epoch 00006: val_loss improved from 1.00712 to 1.00490, saving model to model/checkpoint/1D_BN_CNN_1_conv_1_fcn_checkpoint/06-1.0049.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/step - loss: 0.3594 - acc: 0.8912 - val_loss: 1.0049 - val_acc: 0.7179\n",
      "Epoch 7/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2873 - acc: 0.9135\n",
      "Epoch 00007: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 793us/step - loss: 0.2873 - acc: 0.9135 - val_loss: 1.0370 - val_acc: 0.7160\n",
      "Epoch 8/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2422 - acc: 0.9281\n",
      "Epoch 00008: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.2423 - acc: 0.9280 - val_loss: 1.0546 - val_acc: 0.7247\n",
      "Epoch 9/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2087 - acc: 0.9401\n",
      "Epoch 00009: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 791us/step - loss: 0.2087 - acc: 0.9401 - val_loss: 1.0868 - val_acc: 0.7235\n",
      "Epoch 10/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1884 - acc: 0.9455\n",
      "Epoch 00010: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 782us/step - loss: 0.1889 - acc: 0.9454 - val_loss: 1.1514 - val_acc: 0.7123\n",
      "Epoch 11/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9494\n",
      "Epoch 00011: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 784us/step - loss: 0.1754 - acc: 0.9493 - val_loss: 1.1271 - val_acc: 0.7230\n",
      "Epoch 12/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9548\n",
      "Epoch 00012: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 791us/step - loss: 0.1608 - acc: 0.9548 - val_loss: 1.1424 - val_acc: 0.7331\n",
      "Epoch 13/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9596\n",
      "Epoch 00013: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 792us/step - loss: 0.1458 - acc: 0.9596 - val_loss: 1.1801 - val_acc: 0.7251\n",
      "Epoch 14/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9681\n",
      "Epoch 00014: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 789us/step - loss: 0.1183 - acc: 0.9681 - val_loss: 1.2677 - val_acc: 0.7186\n",
      "Epoch 15/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9670\n",
      "Epoch 00015: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 783us/step - loss: 0.1205 - acc: 0.9670 - val_loss: 1.2481 - val_acc: 0.7365\n",
      "Epoch 16/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9684\n",
      "Epoch 00016: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 801us/step - loss: 0.1110 - acc: 0.9684 - val_loss: 1.2234 - val_acc: 0.7342\n",
      "Epoch 17/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9676\n",
      "Epoch 00017: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.1167 - acc: 0.9675 - val_loss: 1.2771 - val_acc: 0.7244\n",
      "Epoch 18/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9730\n",
      "Epoch 00018: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 786us/step - loss: 0.0994 - acc: 0.9730 - val_loss: 1.3590 - val_acc: 0.7191\n",
      "Epoch 19/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9735\n",
      "Epoch 00019: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 788us/step - loss: 0.0993 - acc: 0.9735 - val_loss: 1.2937 - val_acc: 0.7317\n",
      "Epoch 20/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9747\n",
      "Epoch 00020: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.0917 - acc: 0.9747 - val_loss: 1.3058 - val_acc: 0.7300\n",
      "Epoch 21/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9781\n",
      "Epoch 00021: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 786us/step - loss: 0.0847 - acc: 0.9781 - val_loss: 1.2659 - val_acc: 0.7389\n",
      "Epoch 22/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9778\n",
      "Epoch 00022: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 785us/step - loss: 0.0817 - acc: 0.9778 - val_loss: 1.3131 - val_acc: 0.7298\n",
      "Epoch 23/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9775\n",
      "Epoch 00023: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 785us/step - loss: 0.0837 - acc: 0.9774 - val_loss: 1.3488 - val_acc: 0.7261\n",
      "Epoch 24/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9773\n",
      "Epoch 00024: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 785us/step - loss: 0.0819 - acc: 0.9773 - val_loss: 1.4344 - val_acc: 0.7319\n",
      "Epoch 25/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9786\n",
      "Epoch 00025: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 780us/step - loss: 0.0790 - acc: 0.9786 - val_loss: 1.3403 - val_acc: 0.7340\n",
      "Epoch 26/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9817\n",
      "Epoch 00026: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 779us/step - loss: 0.0677 - acc: 0.9817 - val_loss: 1.3317 - val_acc: 0.7358\n",
      "Epoch 27/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9800\n",
      "Epoch 00027: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 789us/step - loss: 0.0738 - acc: 0.9800 - val_loss: 1.3793 - val_acc: 0.7345\n",
      "Epoch 28/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9821\n",
      "Epoch 00028: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 781us/step - loss: 0.0688 - acc: 0.9821 - val_loss: 1.4385 - val_acc: 0.7352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9826\n",
      "Epoch 00029: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 780us/step - loss: 0.0668 - acc: 0.9826 - val_loss: 1.4397 - val_acc: 0.7296\n",
      "Epoch 30/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9819\n",
      "Epoch 00030: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 780us/step - loss: 0.0697 - acc: 0.9819 - val_loss: 1.3353 - val_acc: 0.7419\n",
      "Epoch 31/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9840\n",
      "Epoch 00031: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 780us/step - loss: 0.0617 - acc: 0.9840 - val_loss: 1.4550 - val_acc: 0.7370\n",
      "Epoch 32/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9824\n",
      "Epoch 00032: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 780us/step - loss: 0.0656 - acc: 0.9825 - val_loss: 1.4409 - val_acc: 0.7268\n",
      "Epoch 33/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9844\n",
      "Epoch 00033: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 780us/step - loss: 0.0588 - acc: 0.9844 - val_loss: 1.4361 - val_acc: 0.7428\n",
      "Epoch 34/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9863\n",
      "Epoch 00034: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 780us/step - loss: 0.0552 - acc: 0.9863 - val_loss: 1.4541 - val_acc: 0.7354\n",
      "Epoch 35/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9845\n",
      "Epoch 00035: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0581 - acc: 0.9845 - val_loss: 1.5451 - val_acc: 0.7414\n",
      "Epoch 36/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9845\n",
      "Epoch 00036: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0570 - acc: 0.9845 - val_loss: 1.6242 - val_acc: 0.7370\n",
      "Epoch 37/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9852\n",
      "Epoch 00037: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 778us/step - loss: 0.0569 - acc: 0.9852 - val_loss: 1.4523 - val_acc: 0.7342\n",
      "Epoch 38/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9864\n",
      "Epoch 00038: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0535 - acc: 0.9864 - val_loss: 1.5306 - val_acc: 0.7377\n",
      "Epoch 39/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9882\n",
      "Epoch 00039: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0466 - acc: 0.9882 - val_loss: 1.5432 - val_acc: 0.7396\n",
      "Epoch 40/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9888\n",
      "Epoch 00040: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0452 - acc: 0.9888 - val_loss: 1.5828 - val_acc: 0.7207\n",
      "Epoch 41/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9844\n",
      "Epoch 00041: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0547 - acc: 0.9844 - val_loss: 1.5648 - val_acc: 0.7338\n",
      "Epoch 42/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9889\n",
      "Epoch 00042: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0453 - acc: 0.9889 - val_loss: 1.5969 - val_acc: 0.7407\n",
      "Epoch 43/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9860\n",
      "Epoch 00043: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0509 - acc: 0.9860 - val_loss: 1.5457 - val_acc: 0.7414\n",
      "Epoch 44/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9879\n",
      "Epoch 00044: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 778us/step - loss: 0.0486 - acc: 0.9879 - val_loss: 1.5485 - val_acc: 0.7396\n",
      "Epoch 45/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9896\n",
      "Epoch 00045: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 778us/step - loss: 0.0393 - acc: 0.9896 - val_loss: 1.6420 - val_acc: 0.7396\n",
      "Epoch 46/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9889\n",
      "Epoch 00046: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0444 - acc: 0.9889 - val_loss: 1.5727 - val_acc: 0.7379\n",
      "Epoch 47/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9892\n",
      "Epoch 00047: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0431 - acc: 0.9892 - val_loss: 1.5505 - val_acc: 0.7454\n",
      "Epoch 48/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9886\n",
      "Epoch 00048: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0449 - acc: 0.9886 - val_loss: 1.6380 - val_acc: 0.7379\n",
      "Epoch 49/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9882\n",
      "Epoch 00049: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0465 - acc: 0.9882 - val_loss: 1.5844 - val_acc: 0.7384\n",
      "Epoch 50/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9882\n",
      "Epoch 00050: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 778us/step - loss: 0.0464 - acc: 0.9883 - val_loss: 1.6674 - val_acc: 0.7389\n",
      "Epoch 51/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9891\n",
      "Epoch 00051: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 776us/step - loss: 0.0437 - acc: 0.9892 - val_loss: 1.6659 - val_acc: 0.7338\n",
      "Epoch 52/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9909\n",
      "Epoch 00052: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0359 - acc: 0.9909 - val_loss: 1.5768 - val_acc: 0.7403\n",
      "Epoch 53/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9899\n",
      "Epoch 00053: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0410 - acc: 0.9899 - val_loss: 1.6055 - val_acc: 0.7398\n",
      "Epoch 54/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9902\n",
      "Epoch 00054: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0417 - acc: 0.9902 - val_loss: 1.6330 - val_acc: 0.7407\n",
      "Epoch 55/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9906\n",
      "Epoch 00055: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0379 - acc: 0.9906 - val_loss: 1.7132 - val_acc: 0.7354\n",
      "Epoch 56/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9903\n",
      "Epoch 00056: val_loss did not improve from 1.00490\n",
      "36805/36805 [==============================] - 29s 777us/step - loss: 0.0384 - acc: 0.9902 - val_loss: 1.6369 - val_acc: 0.7412\n",
      "\n",
      "1 Conv 1 FCN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 168us/step\n",
      "Loss: 1.208793905071009 Accuracy: 0.6616822429968436\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.8699 - acc: 0.1943\n",
      "Epoch 00001: val_loss improved from inf to 2.14194, saving model to model/checkpoint/1D_BN_CNN_1_conv_2_fcn_checkpoint/01-2.1419.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/step - loss: 2.8688 - acc: 0.1945 - val_loss: 2.1419 - val_acc: 0.4079\n",
      "Epoch 2/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9925 - acc: 0.3727\n",
      "Epoch 00002: val_loss improved from 2.14194 to 1.52403, saving model to model/checkpoint/1D_BN_CNN_1_conv_2_fcn_checkpoint/02-1.5240.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/step - loss: 1.9924 - acc: 0.3727 - val_loss: 1.5240 - val_acc: 0.5255\n",
      "Epoch 3/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6248 - acc: 0.4825\n",
      "Epoch 00003: val_loss improved from 1.52403 to 1.27938, saving model to model/checkpoint/1D_BN_CNN_1_conv_2_fcn_checkpoint/03-1.2794.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/step - loss: 1.6248 - acc: 0.4825 - val_loss: 1.2794 - val_acc: 0.6133\n",
      "Epoch 4/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3582 - acc: 0.5657\n",
      "Epoch 00004: val_loss improved from 1.27938 to 1.10107, saving model to model/checkpoint/1D_BN_CNN_1_conv_2_fcn_checkpoint/04-1.1011.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/step - loss: 1.3582 - acc: 0.5657 - val_loss: 1.1011 - val_acc: 0.6597\n",
      "Epoch 5/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1571 - acc: 0.6285\n",
      "Epoch 00005: val_loss improved from 1.10107 to 1.01789, saving model to model/checkpoint/1D_BN_CNN_1_conv_2_fcn_checkpoint/05-1.0179.hdf5\n",
      "36805/36805 [==============================] - 29s 791us/step - loss: 1.1572 - acc: 0.6285 - val_loss: 1.0179 - val_acc: 0.6904\n",
      "Epoch 6/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9797 - acc: 0.6843\n",
      "Epoch 00006: val_loss improved from 1.01789 to 0.93221, saving model to model/checkpoint/1D_BN_CNN_1_conv_2_fcn_checkpoint/06-0.9322.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/step - loss: 0.9797 - acc: 0.6843 - val_loss: 0.9322 - val_acc: 0.7126\n",
      "Epoch 7/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8438 - acc: 0.7271\n",
      "Epoch 00007: val_loss improved from 0.93221 to 0.90366, saving model to model/checkpoint/1D_BN_CNN_1_conv_2_fcn_checkpoint/07-0.9037.hdf5\n",
      "36805/36805 [==============================] - 29s 793us/step - loss: 0.8438 - acc: 0.7271 - val_loss: 0.9037 - val_acc: 0.7172\n",
      "Epoch 8/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7181 - acc: 0.7683\n",
      "Epoch 00008: val_loss improved from 0.90366 to 0.84514, saving model to model/checkpoint/1D_BN_CNN_1_conv_2_fcn_checkpoint/08-0.8451.hdf5\n",
      "36805/36805 [==============================] - 29s 794us/step - loss: 0.7183 - acc: 0.7682 - val_loss: 0.8451 - val_acc: 0.7303\n",
      "Epoch 9/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6140 - acc: 0.8021\n",
      "Epoch 00009: val_loss improved from 0.84514 to 0.81867, saving model to model/checkpoint/1D_BN_CNN_1_conv_2_fcn_checkpoint/09-0.8187.hdf5\n",
      "36805/36805 [==============================] - 29s 793us/step - loss: 0.6140 - acc: 0.8021 - val_loss: 0.8187 - val_acc: 0.7391\n",
      "Epoch 10/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5208 - acc: 0.8326\n",
      "Epoch 00010: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 789us/step - loss: 0.5208 - acc: 0.8326 - val_loss: 0.8402 - val_acc: 0.7391\n",
      "Epoch 11/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4600 - acc: 0.8525\n",
      "Epoch 00011: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 788us/step - loss: 0.4600 - acc: 0.8525 - val_loss: 0.8454 - val_acc: 0.7358\n",
      "Epoch 12/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3996 - acc: 0.8738\n",
      "Epoch 00012: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.3997 - acc: 0.8738 - val_loss: 0.8338 - val_acc: 0.7459\n",
      "Epoch 13/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3604 - acc: 0.8861\n",
      "Epoch 00013: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 789us/step - loss: 0.3604 - acc: 0.8862 - val_loss: 0.8362 - val_acc: 0.7482\n",
      "Epoch 14/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3099 - acc: 0.9020\n",
      "Epoch 00014: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 788us/step - loss: 0.3101 - acc: 0.9020 - val_loss: 0.8421 - val_acc: 0.7515\n",
      "Epoch 15/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2786 - acc: 0.9134\n",
      "Epoch 00015: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.2787 - acc: 0.9134 - val_loss: 0.8576 - val_acc: 0.7608\n",
      "Epoch 16/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2487 - acc: 0.9224\n",
      "Epoch 00016: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.2486 - acc: 0.9225 - val_loss: 0.8925 - val_acc: 0.7515\n",
      "Epoch 17/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.9265\n",
      "Epoch 00017: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.2387 - acc: 0.9265 - val_loss: 0.9001 - val_acc: 0.7545\n",
      "Epoch 18/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2149 - acc: 0.9348\n",
      "Epoch 00018: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.2149 - acc: 0.9348 - val_loss: 0.8972 - val_acc: 0.7605\n",
      "Epoch 19/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1889 - acc: 0.9418\n",
      "Epoch 00019: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 788us/step - loss: 0.1889 - acc: 0.9418 - val_loss: 0.9352 - val_acc: 0.7475\n",
      "Epoch 20/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1905 - acc: 0.9415\n",
      "Epoch 00020: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.1905 - acc: 0.9415 - val_loss: 0.9407 - val_acc: 0.7498\n",
      "Epoch 21/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1699 - acc: 0.9473\n",
      "Epoch 00021: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 788us/step - loss: 0.1698 - acc: 0.9473 - val_loss: 0.9752 - val_acc: 0.7487\n",
      "Epoch 22/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1638 - acc: 0.9500\n",
      "Epoch 00022: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 788us/step - loss: 0.1638 - acc: 0.9500 - val_loss: 1.0016 - val_acc: 0.7466\n",
      "Epoch 23/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9508\n",
      "Epoch 00023: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.1627 - acc: 0.9508 - val_loss: 0.9667 - val_acc: 0.7477\n",
      "Epoch 24/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1541 - acc: 0.9539\n",
      "Epoch 00024: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.1543 - acc: 0.9538 - val_loss: 1.0352 - val_acc: 0.7561\n",
      "Epoch 25/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9560\n",
      "Epoch 00025: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.1448 - acc: 0.9560 - val_loss: 1.0550 - val_acc: 0.7512\n",
      "Epoch 26/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9580\n",
      "Epoch 00026: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 788us/step - loss: 0.1425 - acc: 0.9580 - val_loss: 1.0649 - val_acc: 0.7529\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9619\n",
      "Epoch 00027: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 788us/step - loss: 0.1277 - acc: 0.9619 - val_loss: 1.0397 - val_acc: 0.7501\n",
      "Epoch 28/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9630\n",
      "Epoch 00028: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.1223 - acc: 0.9630 - val_loss: 1.0828 - val_acc: 0.7480\n",
      "Epoch 29/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9644\n",
      "Epoch 00029: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.1209 - acc: 0.9644 - val_loss: 1.0972 - val_acc: 0.7442\n",
      "Epoch 30/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9637\n",
      "Epoch 00030: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 788us/step - loss: 0.1190 - acc: 0.9637 - val_loss: 1.0636 - val_acc: 0.7489\n",
      "Epoch 31/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9661\n",
      "Epoch 00031: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 789us/step - loss: 0.1178 - acc: 0.9661 - val_loss: 1.1260 - val_acc: 0.7463\n",
      "Epoch 32/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9691\n",
      "Epoch 00032: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.1056 - acc: 0.9691 - val_loss: 1.0926 - val_acc: 0.7470\n",
      "Epoch 33/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9689\n",
      "Epoch 00033: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 786us/step - loss: 0.1076 - acc: 0.9689 - val_loss: 1.1071 - val_acc: 0.7584\n",
      "Epoch 34/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9714\n",
      "Epoch 00034: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 787us/step - loss: 0.0992 - acc: 0.9713 - val_loss: 1.1251 - val_acc: 0.7556\n",
      "Epoch 35/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9728\n",
      "Epoch 00035: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 786us/step - loss: 0.0928 - acc: 0.9729 - val_loss: 1.1161 - val_acc: 0.7489\n",
      "Epoch 36/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9742\n",
      "Epoch 00036: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 786us/step - loss: 0.0887 - acc: 0.9742 - val_loss: 1.1371 - val_acc: 0.7547\n",
      "Epoch 37/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9711\n",
      "Epoch 00037: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.0988 - acc: 0.9711 - val_loss: 1.1542 - val_acc: 0.7612\n",
      "Epoch 38/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9733\n",
      "Epoch 00038: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 789us/step - loss: 0.0918 - acc: 0.9734 - val_loss: 1.1770 - val_acc: 0.7461\n",
      "Epoch 39/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9754\n",
      "Epoch 00039: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 791us/step - loss: 0.0886 - acc: 0.9754 - val_loss: 1.1471 - val_acc: 0.7445\n",
      "Epoch 40/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9739\n",
      "Epoch 00040: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 791us/step - loss: 0.0929 - acc: 0.9739 - val_loss: 1.1765 - val_acc: 0.7568\n",
      "Epoch 41/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9768\n",
      "Epoch 00041: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.0803 - acc: 0.9768 - val_loss: 1.1255 - val_acc: 0.7536\n",
      "Epoch 42/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9771\n",
      "Epoch 00042: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.0775 - acc: 0.9771 - val_loss: 1.1754 - val_acc: 0.7482\n",
      "Epoch 43/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9772\n",
      "Epoch 00043: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 791us/step - loss: 0.0833 - acc: 0.9772 - val_loss: 1.1863 - val_acc: 0.7591\n",
      "Epoch 44/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9770\n",
      "Epoch 00044: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.0791 - acc: 0.9770 - val_loss: 1.1979 - val_acc: 0.7549\n",
      "Epoch 45/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9780\n",
      "Epoch 00045: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.0808 - acc: 0.9780 - val_loss: 1.1835 - val_acc: 0.7540\n",
      "Epoch 46/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9785\n",
      "Epoch 00046: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.0768 - acc: 0.9785 - val_loss: 1.1633 - val_acc: 0.7529\n",
      "Epoch 47/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9785\n",
      "Epoch 00047: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 791us/step - loss: 0.0752 - acc: 0.9785 - val_loss: 1.2284 - val_acc: 0.7545\n",
      "Epoch 48/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9796\n",
      "Epoch 00048: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 791us/step - loss: 0.0758 - acc: 0.9796 - val_loss: 1.2347 - val_acc: 0.7552\n",
      "Epoch 49/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9800\n",
      "Epoch 00049: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.0730 - acc: 0.9800 - val_loss: 1.2233 - val_acc: 0.7529\n",
      "Epoch 50/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9810\n",
      "Epoch 00050: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 789us/step - loss: 0.0708 - acc: 0.9810 - val_loss: 1.2522 - val_acc: 0.7505\n",
      "Epoch 51/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9811\n",
      "Epoch 00051: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 791us/step - loss: 0.0685 - acc: 0.9811 - val_loss: 1.2247 - val_acc: 0.7545\n",
      "Epoch 52/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9812\n",
      "Epoch 00052: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 791us/step - loss: 0.0686 - acc: 0.9812 - val_loss: 1.2842 - val_acc: 0.7617\n",
      "Epoch 53/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9801\n",
      "Epoch 00053: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.0734 - acc: 0.9801 - val_loss: 1.3127 - val_acc: 0.7561\n",
      "Epoch 54/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9810\n",
      "Epoch 00054: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.0686 - acc: 0.9810 - val_loss: 1.3384 - val_acc: 0.7526\n",
      "Epoch 55/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9819\n",
      "Epoch 00055: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.0653 - acc: 0.9819 - val_loss: 1.2836 - val_acc: 0.7582\n",
      "Epoch 56/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9810\n",
      "Epoch 00056: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.0682 - acc: 0.9810 - val_loss: 1.2587 - val_acc: 0.7547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9843\n",
      "Epoch 00057: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 791us/step - loss: 0.0553 - acc: 0.9843 - val_loss: 1.3387 - val_acc: 0.7545\n",
      "Epoch 58/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9829\n",
      "Epoch 00058: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 790us/step - loss: 0.0606 - acc: 0.9829 - val_loss: 1.2475 - val_acc: 0.7538\n",
      "Epoch 59/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9832\n",
      "Epoch 00059: val_loss did not improve from 0.81867\n",
      "36805/36805 [==============================] - 29s 791us/step - loss: 0.0632 - acc: 0.9832 - val_loss: 1.2388 - val_acc: 0.7622\n",
      "\n",
      "1 Conv 2 FCN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 188us/step\n",
      "Loss: 0.9895170656691459 Accuracy: 0.7021806854325292\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/200\n",
      " 8000/36805 [=====>........................] - ETA: 23s - loss: 3.1720 - acc: 0.2193"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[15888,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_4/Adam/mul_42}} = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_4/Adam/sub_26, training_4/Adam/gradients/dense_5/MatMul_grad/MatMul_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4e900d98ecd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=200, \n\u001b[1;32m     16\u001b[0m                          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val_abs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_onehot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                          callbacks = [checkpointer, early_stopping])\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Conv {} FCN Model'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/sf_word_recog_research/vir_sfword/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Research/sf_word_recog_research/vir_sfword/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/sf_word_recog_research/vir_sfword/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/sf_word_recog_research/vir_sfword/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/sf_word_recog_research/vir_sfword/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[15888,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_4/Adam/mul_42}} = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_4/Adam/sub_26, training_4/Adam/gradients/dense_5/MatMul_grad/MatMul_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    for j in range(1, 3):\n",
    "        model = build_batchnorm_cnn(conv_num=i, fcn_num=j)\n",
    "#         model.summary()\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "        model_path = 'model/checkpoint/1D_BN_CNN_{}_conv_{}_fcn_checkpoint/'.format(i, j)\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        model_filename = model_path+'{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "        checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                       verbose=1, save_best_only=True)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "        hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=200, \n",
    "                         validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                         callbacks = [checkpointer, early_stopping])\n",
    "        print()\n",
    "        print('{} Conv {} FCN Model'.format(i, j))\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "        ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "        ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "        ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.set_ylabel('loss')\n",
    "        ax.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        png_path = 'visualization/learning_curve/'\n",
    "        filename = '1D_BN_CNN_{}_conv_{}_fcn'.format(i, j)+'.png'\n",
    "        os.makedirs(png_path, exist_ok=True)\n",
    "        fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "        del(model)\n",
    "        \n",
    "        model_path = 'model/checkpoint/1D_BN_CNN_{}_conv_{}_fcn_checkpoint/'.format(i, j)\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "        model = load_model(model_filename)\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "        print()\n",
    "        \n",
    "        del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    for j in range(1, 3):\n",
    "        print()\n",
    "        print('{} Conv {} FCN Model'.format(i, j))\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "        model_path = 'model/checkpoint/1D_BN_CNN_{}_conv_{}_fcn_checkpoint/'.format(i, j)\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "  \n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "    \n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "        \n",
    "        del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
