{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, padding='same', \n",
    "                      activation='relu', input_shape=input_shape)) \n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))\n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,400\n",
      "Trainable params: 16,384,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,481,936\n",
      "Trainable params: 5,481,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,136\n",
      "Trainable params: 1,861,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 668,240\n",
      "Trainable params: 668,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 506,576\n",
      "Trainable params: 506,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 318,288\n",
      "Trainable params: 318,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 310,224\n",
      "Trainable params: 310,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 363,600\n",
      "Trainable params: 363,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 521,552\n",
      "Trainable params: 521,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4294 - acc: 0.2413\n",
      "Epoch 00001: val_loss improved from inf to 2.24727, saving model to model/checkpoint/1D_CNN_1_conv_custom_DO_checkpoint/001-2.2473.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 2.4293 - acc: 0.2414 - val_loss: 2.2473 - val_acc: 0.3189\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9645 - acc: 0.4201\n",
      "Epoch 00002: val_loss improved from 2.24727 to 2.13194, saving model to model/checkpoint/1D_CNN_1_conv_custom_DO_checkpoint/002-2.1319.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 1.9646 - acc: 0.4201 - val_loss: 2.1319 - val_acc: 0.3445\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6755 - acc: 0.5128\n",
      "Epoch 00003: val_loss improved from 2.13194 to 2.11547, saving model to model/checkpoint/1D_CNN_1_conv_custom_DO_checkpoint/003-2.1155.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 1.6754 - acc: 0.5128 - val_loss: 2.1155 - val_acc: 0.3471\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4447 - acc: 0.5875\n",
      "Epoch 00004: val_loss did not improve from 2.11547\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 1.4447 - acc: 0.5875 - val_loss: 2.1598 - val_acc: 0.3399\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2622 - acc: 0.6464\n",
      "Epoch 00005: val_loss did not improve from 2.11547\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 1.2622 - acc: 0.6464 - val_loss: 2.1849 - val_acc: 0.3308\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1107 - acc: 0.6945\n",
      "Epoch 00006: val_loss did not improve from 2.11547\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 1.1107 - acc: 0.6945 - val_loss: 2.2224 - val_acc: 0.3433\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9821 - acc: 0.7351\n",
      "Epoch 00007: val_loss did not improve from 2.11547\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.9821 - acc: 0.7351 - val_loss: 2.2724 - val_acc: 0.3368\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8744 - acc: 0.7689\n",
      "Epoch 00008: val_loss did not improve from 2.11547\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.8743 - acc: 0.7689 - val_loss: 2.3417 - val_acc: 0.3326\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7734 - acc: 0.8021\n",
      "Epoch 00009: val_loss did not improve from 2.11547\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.7734 - acc: 0.8021 - val_loss: 2.4044 - val_acc: 0.3375\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6964 - acc: 0.8262\n",
      "Epoch 00010: val_loss did not improve from 2.11547\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.6964 - acc: 0.8262 - val_loss: 2.4904 - val_acc: 0.3226\n",
      "Epoch 11/500\n",
      "11008/36805 [=======>......................] - ETA: 26s - loss: 0.5734 - acc: 0.8750"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_{}_conv_custom_DO'.format(i)\n",
    "    model = build_1d_cnn_custom_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_1_conv_custom_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,400\n",
      "Trainable params: 16,384,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 461us/sample - loss: 2.1419 - acc: 0.3321\n",
      "Loss: 2.141924336716641 Accuracy: 0.33208722\n",
      "\n",
      "1D_CNN_2_conv_custom_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,481,936\n",
      "Trainable params: 5,481,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 744us/sample - loss: 1.8082 - acc: 0.4434\n",
      "Loss: 1.808169612854812 Accuracy: 0.44340602\n",
      "\n",
      "1D_CNN_3_conv_custom_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,136\n",
      "Trainable params: 1,861,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 847us/sample - loss: 1.4653 - acc: 0.5412\n",
      "Loss: 1.4653394272022902 Accuracy: 0.5412253\n",
      "\n",
      "1D_CNN_4_conv_custom_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 668,240\n",
      "Trainable params: 668,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 904us/sample - loss: 1.0939 - acc: 0.6698\n",
      "Loss: 1.0938899715370107 Accuracy: 0.6697819\n",
      "\n",
      "1D_CNN_5_conv_custom_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 506,576\n",
      "Trainable params: 506,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 921us/sample - loss: 0.8304 - acc: 0.7537\n",
      "Loss: 0.8304384512940919 Accuracy: 0.75368637\n",
      "\n",
      "1D_CNN_6_conv_custom_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 318,288\n",
      "Trainable params: 318,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 942us/sample - loss: 0.4508 - acc: 0.8754\n",
      "Loss: 0.4507794922138424 Accuracy: 0.8753894\n",
      "\n",
      "1D_CNN_7_conv_custom_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 310,224\n",
      "Trainable params: 310,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 973us/sample - loss: 0.2110 - acc: 0.9360\n",
      "Loss: 0.21100966663932502 Accuracy: 0.93603325\n",
      "\n",
      "1D_CNN_8_conv_custom_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 363,600\n",
      "Trainable params: 363,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 993us/sample - loss: 0.1919 - acc: 0.9545\n",
      "Loss: 0.19189429886615908 Accuracy: 0.9545171\n",
      "\n",
      "1D_CNN_9_conv_custom_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 521,552\n",
      "Trainable params: 521,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1931 - acc: 0.9406\n",
      "Loss: 0.19314148334838518 Accuracy: 0.9406023\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_{}_conv_custom_DO'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, \n",
    "                      padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.1053 - acc: 0.2314\n",
      "Epoch 00001: val_loss improved from inf to 2.44364, saving model to model/checkpoint/1D_CNN_1_conv_custom_BN_checkpoint/001-2.4436.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 4.1055 - acc: 0.2314 - val_loss: 2.4436 - val_acc: 0.2700\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5623 - acc: 0.5508\n",
      "Epoch 00002: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 1.5623 - acc: 0.5508 - val_loss: 2.8288 - val_acc: 0.2819\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0122 - acc: 0.7029\n",
      "Epoch 00003: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 1.0121 - acc: 0.7029 - val_loss: 3.1305 - val_acc: 0.2816\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7293 - acc: 0.7952\n",
      "Epoch 00004: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.7293 - acc: 0.7952 - val_loss: 3.1336 - val_acc: 0.2849\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5591 - acc: 0.8456\n",
      "Epoch 00005: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.5591 - acc: 0.8455 - val_loss: 3.7085 - val_acc: 0.2749\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4531 - acc: 0.8739\n",
      "Epoch 00006: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4531 - acc: 0.8738 - val_loss: 4.0507 - val_acc: 0.2718\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3920 - acc: 0.8962\n",
      "Epoch 00007: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3919 - acc: 0.8962 - val_loss: 4.1819 - val_acc: 0.2704\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3387 - acc: 0.9110\n",
      "Epoch 00008: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3387 - acc: 0.9110 - val_loss: 5.1820 - val_acc: 0.2567\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2823 - acc: 0.9300\n",
      "Epoch 00009: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2823 - acc: 0.9300 - val_loss: 5.5147 - val_acc: 0.2520\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2388 - acc: 0.9442\n",
      "Epoch 00010: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2388 - acc: 0.9442 - val_loss: 4.6116 - val_acc: 0.2984\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2080 - acc: 0.9546\n",
      "Epoch 00011: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2080 - acc: 0.9546 - val_loss: 4.9923 - val_acc: 0.2905\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2085 - acc: 0.9510\n",
      "Epoch 00012: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2085 - acc: 0.9510 - val_loss: 5.2509 - val_acc: 0.2742\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9607\n",
      "Epoch 00013: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1768 - acc: 0.9607 - val_loss: 5.0833 - val_acc: 0.2954\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1540 - acc: 0.9698\n",
      "Epoch 00014: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1540 - acc: 0.9698 - val_loss: 5.3407 - val_acc: 0.2984\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9686\n",
      "Epoch 00015: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1556 - acc: 0.9686 - val_loss: 5.9293 - val_acc: 0.2660\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9718\n",
      "Epoch 00016: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1432 - acc: 0.9718 - val_loss: 6.0312 - val_acc: 0.2905\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9739\n",
      "Epoch 00017: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1355 - acc: 0.9739 - val_loss: 5.9535 - val_acc: 0.2742\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9791\n",
      "Epoch 00018: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1168 - acc: 0.9791 - val_loss: 6.3393 - val_acc: 0.2856\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9763\n",
      "Epoch 00019: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1240 - acc: 0.9763 - val_loss: 5.7244 - val_acc: 0.2961\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9756\n",
      "Epoch 00020: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1222 - acc: 0.9756 - val_loss: 6.0141 - val_acc: 0.2874\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9809\n",
      "Epoch 00021: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1068 - acc: 0.9809 - val_loss: 6.0924 - val_acc: 0.3003\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9827\n",
      "Epoch 00022: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0971 - acc: 0.9827 - val_loss: 6.1217 - val_acc: 0.2965\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9839\n",
      "Epoch 00023: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0928 - acc: 0.9839 - val_loss: 6.4850 - val_acc: 0.2905\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9846\n",
      "Epoch 00024: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0949 - acc: 0.9846 - val_loss: 6.6946 - val_acc: 0.2828\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9862\n",
      "Epoch 00025: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0850 - acc: 0.9863 - val_loss: 6.3333 - val_acc: 0.3000\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9834\n",
      "Epoch 00026: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0974 - acc: 0.9834 - val_loss: 7.2215 - val_acc: 0.2746\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9904\n",
      "Epoch 00027: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0715 - acc: 0.9904 - val_loss: 6.3041 - val_acc: 0.2923\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9891\n",
      "Epoch 00028: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0772 - acc: 0.9891 - val_loss: 6.4755 - val_acc: 0.2912\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9859\n",
      "Epoch 00029: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0869 - acc: 0.9859 - val_loss: 7.2546 - val_acc: 0.2739\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9799\n",
      "Epoch 00030: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1049 - acc: 0.9799 - val_loss: 7.3768 - val_acc: 0.2690\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9844\n",
      "Epoch 00031: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0904 - acc: 0.9844 - val_loss: 6.7130 - val_acc: 0.2914\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9885\n",
      "Epoch 00032: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0764 - acc: 0.9885 - val_loss: 7.0509 - val_acc: 0.2851\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9923\n",
      "Epoch 00033: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0614 - acc: 0.9923 - val_loss: 6.5063 - val_acc: 0.2982\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9955\n",
      "Epoch 00034: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0535 - acc: 0.9955 - val_loss: 6.6463 - val_acc: 0.2956\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9907\n",
      "Epoch 00035: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0681 - acc: 0.9907 - val_loss: 6.8062 - val_acc: 0.2877\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9894\n",
      "Epoch 00036: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0716 - acc: 0.9894 - val_loss: 7.3856 - val_acc: 0.2874\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9795\n",
      "Epoch 00037: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1080 - acc: 0.9795 - val_loss: 8.3473 - val_acc: 0.2616\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9891\n",
      "Epoch 00038: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0743 - acc: 0.9891 - val_loss: 7.2489 - val_acc: 0.2898\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9918\n",
      "Epoch 00039: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0649 - acc: 0.9918 - val_loss: 7.2801 - val_acc: 0.2749\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9940\n",
      "Epoch 00040: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0559 - acc: 0.9940 - val_loss: 7.1065 - val_acc: 0.2881\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9961\n",
      "Epoch 00041: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0476 - acc: 0.9961 - val_loss: 6.7343 - val_acc: 0.3035\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9935\n",
      "Epoch 00042: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0559 - acc: 0.9935 - val_loss: 7.9797 - val_acc: 0.2593\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9882\n",
      "Epoch 00043: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0725 - acc: 0.9882 - val_loss: 7.5357 - val_acc: 0.2770\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9881\n",
      "Epoch 00044: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0767 - acc: 0.9881 - val_loss: 7.1174 - val_acc: 0.2823\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9888\n",
      "Epoch 00045: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0744 - acc: 0.9888 - val_loss: 7.3937 - val_acc: 0.2795\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9945\n",
      "Epoch 00046: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0525 - acc: 0.9945 - val_loss: 7.3282 - val_acc: 0.2809\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9946\n",
      "Epoch 00047: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0522 - acc: 0.9946 - val_loss: 7.1298 - val_acc: 0.2958\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9899\n",
      "Epoch 00048: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0693 - acc: 0.9899 - val_loss: 7.5981 - val_acc: 0.2979\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9911\n",
      "Epoch 00049: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0633 - acc: 0.9911 - val_loss: 8.0733 - val_acc: 0.2546\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9907\n",
      "Epoch 00050: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0656 - acc: 0.9907 - val_loss: 7.5117 - val_acc: 0.2786\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9937\n",
      "Epoch 00051: val_loss did not improve from 2.44364\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0564 - acc: 0.9937 - val_loss: 7.4131 - val_acc: 0.2968\n",
      "\n",
      "1D_CNN_1_conv_custom_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 522us/sample - loss: 2.6021 - acc: 0.2152\n",
      "Loss: 2.6020969323032492 Accuracy: 0.21516095\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.7046 - acc: 0.2498\n",
      "Epoch 00001: val_loss improved from inf to 7.03060, saving model to model/checkpoint/1D_CNN_2_conv_custom_BN_checkpoint/001-7.0306.hdf5\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 6.7040 - acc: 0.2499 - val_loss: 7.0306 - val_acc: 0.2068\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.9307 - acc: 0.3857\n",
      "Epoch 00002: val_loss improved from 7.03060 to 6.24542, saving model to model/checkpoint/1D_CNN_2_conv_custom_BN_checkpoint/002-6.2454.hdf5\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 5.9304 - acc: 0.3857 - val_loss: 6.2454 - val_acc: 0.3308\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.5318 - acc: 0.4869\n",
      "Epoch 00003: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 5.5319 - acc: 0.4869 - val_loss: 6.7779 - val_acc: 0.2902\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.3879 - acc: 0.5296\n",
      "Epoch 00004: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 5.3877 - acc: 0.5295 - val_loss: 7.8196 - val_acc: 0.2117\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.2355 - acc: 0.5781\n",
      "Epoch 00005: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 5.2349 - acc: 0.5782 - val_loss: 7.5530 - val_acc: 0.2434\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.1076 - acc: 0.6145\n",
      "Epoch 00006: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 5.1082 - acc: 0.6145 - val_loss: 7.0493 - val_acc: 0.3038\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0751 - acc: 0.6288\n",
      "Epoch 00007: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 5.0757 - acc: 0.6288 - val_loss: 7.6428 - val_acc: 0.2679\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0408 - acc: 0.6420\n",
      "Epoch 00008: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 5.0405 - acc: 0.6420 - val_loss: 9.0049 - val_acc: 0.2152\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0214 - acc: 0.6458\n",
      "Epoch 00009: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 5.0212 - acc: 0.6458 - val_loss: 8.0808 - val_acc: 0.2958\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0032 - acc: 0.6519\n",
      "Epoch 00010: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 5.0031 - acc: 0.6519 - val_loss: 8.1050 - val_acc: 0.2840\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9717 - acc: 0.6618\n",
      "Epoch 00011: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 4.9719 - acc: 0.6618 - val_loss: 7.6890 - val_acc: 0.3138\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9988 - acc: 0.6541\n",
      "Epoch 00012: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 4.9990 - acc: 0.6541 - val_loss: 7.7455 - val_acc: 0.3266\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9448 - acc: 0.6696\n",
      "Epoch 00013: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 4.9454 - acc: 0.6695 - val_loss: 8.7673 - val_acc: 0.2397\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9729 - acc: 0.6647\n",
      "Epoch 00014: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 4.9733 - acc: 0.6646 - val_loss: 8.1434 - val_acc: 0.3026\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9651 - acc: 0.6676\n",
      "Epoch 00015: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 4.9649 - acc: 0.6677 - val_loss: 8.1834 - val_acc: 0.2979\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9369 - acc: 0.6753\n",
      "Epoch 00016: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 4.9371 - acc: 0.6753 - val_loss: 8.1042 - val_acc: 0.3233\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9464 - acc: 0.6713\n",
      "Epoch 00017: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 4.9466 - acc: 0.6713 - val_loss: 7.9431 - val_acc: 0.3298\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9480 - acc: 0.6705\n",
      "Epoch 00018: val_loss did not improve from 6.24542\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 4.9478 - acc: 0.6705 - val_loss: 8.1810 - val_acc: 0.3219\n",
      "Epoch 19/500\n",
      "23872/36805 [==================>...........] - ETA: 34s - loss: 4.9166 - acc: 0.6792"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-13dda0297f43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n\u001b[1;32m     15\u001b[0m                      \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val_abs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_onehot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                      callbacks = [checkpointer, early_stopping])\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_{}_conv_custom_BN'.format(i)\n",
    "    model = build_1d_cnn_custom_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_{}_conv_custom_BN'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_{}_conv_custom_DO_BN'.format(i)\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_{}_conv_custom_DO_BN'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_BN_2(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, \n",
    "                      padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())    \n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_BN_2(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_{}_conv_custom_BN_2'.format(i)\n",
    "    model = build_1d_cnn_custom_BN_2(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_{}_conv_custom_BN_2'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
