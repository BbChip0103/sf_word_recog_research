{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_BN_2(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, \n",
    "                      padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())    \n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,480,656\n",
      "Trainable params: 18,432,528\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 512000)            2048000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                8192016   \n",
      "=================================================================\n",
      "Total params: 10,261,456\n",
      "Trainable params: 9,237,200\n",
      "Non-trainable params: 1,024,256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 256000)            1024000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 5,162,256\n",
      "Trainable params: 4,649,872\n",
      "Non-trainable params: 512,384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 128000)            512000    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,623,056\n",
      "Trainable params: 2,366,544\n",
      "Non-trainable params: 256,512\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 128000)            512000    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,664,656\n",
      "Trainable params: 2,407,888\n",
      "Non-trainable params: 256,768\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 64000)             256000    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,467,216\n",
      "Trainable params: 1,338,192\n",
      "Non-trainable params: 129,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 32000)             128000    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 909,776\n",
      "Trainable params: 844,496\n",
      "Non-trainable params: 65,280\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 16000)             64000     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 672,336\n",
      "Trainable params: 638,800\n",
      "Non-trainable params: 33,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 15872)             63488     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                253968    \n",
      "=================================================================\n",
      "Total params: 834,896\n",
      "Trainable params: 801,104\n",
      "Non-trainable params: 33,792\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 7936)              31744     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 1,005,136\n",
      "Trainable params: 986,704\n",
      "Non-trainable params: 18,432\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 3840)              15360     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                61456     \n",
      "=================================================================\n",
      "Total params: 1,252,176\n",
      "Trainable params: 1,241,424\n",
      "Non-trainable params: 10,752\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 1792)              7168      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,540,176\n",
      "Trainable params: 1,533,008\n",
      "Non-trainable params: 7,168\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 7, 512)            2048      \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 1536)              6144      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                24592     \n",
      "=================================================================\n",
      "Total params: 2,192,976\n",
      "Trainable params: 2,185,296\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 14):\n",
    "    model = build_1d_cnn_custom_BN_2(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.9671 - acc: 0.4027\n",
      "Epoch 00001: val_loss improved from inf to 2.39656, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_3_conv_checkpoint/001-2.3966.hdf5\n",
      "36805/36805 [==============================] - 100s 3ms/sample - loss: 2.9672 - acc: 0.4027 - val_loss: 2.3966 - val_acc: 0.4172\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9507 - acc: 0.7848\n",
      "Epoch 00002: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.9513 - acc: 0.7848 - val_loss: 3.0202 - val_acc: 0.4135\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4243 - acc: 0.9078\n",
      "Epoch 00003: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.4244 - acc: 0.9078 - val_loss: 3.0717 - val_acc: 0.4705\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2642 - acc: 0.9505\n",
      "Epoch 00004: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.2642 - acc: 0.9505 - val_loss: 3.0734 - val_acc: 0.4782\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.9641\n",
      "Epoch 00005: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.2038 - acc: 0.9641 - val_loss: 3.5755 - val_acc: 0.4416\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1979 - acc: 0.9627\n",
      "Epoch 00006: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1980 - acc: 0.9626 - val_loss: 3.7272 - val_acc: 0.4433\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2258 - acc: 0.9536\n",
      "Epoch 00007: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.2260 - acc: 0.9535 - val_loss: 4.5739 - val_acc: 0.4146\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2397 - acc: 0.9498\n",
      "Epoch 00008: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.2400 - acc: 0.9498 - val_loss: 4.0282 - val_acc: 0.4603\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2317 - acc: 0.9526\n",
      "Epoch 00009: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.2317 - acc: 0.9525 - val_loss: 4.0332 - val_acc: 0.4682\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9614\n",
      "Epoch 00010: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.2005 - acc: 0.9614 - val_loss: 4.5848 - val_acc: 0.4400\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1883 - acc: 0.9638\n",
      "Epoch 00011: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1883 - acc: 0.9638 - val_loss: 5.6833 - val_acc: 0.4135\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9633\n",
      "Epoch 00012: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.2018 - acc: 0.9633 - val_loss: 5.1079 - val_acc: 0.4237\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1534 - acc: 0.9727\n",
      "Epoch 00013: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1535 - acc: 0.9727 - val_loss: 5.2960 - val_acc: 0.4302\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1660 - acc: 0.9695\n",
      "Epoch 00014: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1663 - acc: 0.9694 - val_loss: 5.2523 - val_acc: 0.4566\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9714\n",
      "Epoch 00015: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1618 - acc: 0.9714 - val_loss: 5.7689 - val_acc: 0.4191\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9708\n",
      "Epoch 00016: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1667 - acc: 0.9708 - val_loss: 5.0773 - val_acc: 0.4612\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9758\n",
      "Epoch 00017: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1451 - acc: 0.9758 - val_loss: 5.2587 - val_acc: 0.4752\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9782\n",
      "Epoch 00018: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1326 - acc: 0.9782 - val_loss: 5.1826 - val_acc: 0.4624\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9783\n",
      "Epoch 00019: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1361 - acc: 0.9783 - val_loss: 5.4266 - val_acc: 0.4524\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9791\n",
      "Epoch 00020: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1290 - acc: 0.9791 - val_loss: 5.5568 - val_acc: 0.4470\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9775\n",
      "Epoch 00021: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1450 - acc: 0.9775 - val_loss: 5.3505 - val_acc: 0.4750\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9805\n",
      "Epoch 00022: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1326 - acc: 0.9805 - val_loss: 5.3986 - val_acc: 0.4789\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9796\n",
      "Epoch 00023: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1380 - acc: 0.9796 - val_loss: 5.8025 - val_acc: 0.4535\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9807\n",
      "Epoch 00024: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1294 - acc: 0.9807 - val_loss: 6.3178 - val_acc: 0.4284\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9811\n",
      "Epoch 00025: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1243 - acc: 0.9811 - val_loss: 5.7304 - val_acc: 0.4656\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9822\n",
      "Epoch 00026: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1214 - acc: 0.9822 - val_loss: 5.7489 - val_acc: 0.4601\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9835\n",
      "Epoch 00027: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1095 - acc: 0.9835 - val_loss: 5.4187 - val_acc: 0.4836\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9806\n",
      "Epoch 00028: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1318 - acc: 0.9805 - val_loss: 5.6395 - val_acc: 0.4722\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9857\n",
      "Epoch 00029: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1042 - acc: 0.9856 - val_loss: 6.1015 - val_acc: 0.4458\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9821\n",
      "Epoch 00030: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1222 - acc: 0.9821 - val_loss: 5.7953 - val_acc: 0.4710\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9847\n",
      "Epoch 00031: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1074 - acc: 0.9847 - val_loss: 5.5863 - val_acc: 0.4962\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9833\n",
      "Epoch 00032: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1209 - acc: 0.9832 - val_loss: 5.6758 - val_acc: 0.4966\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9855\n",
      "Epoch 00033: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1053 - acc: 0.9855 - val_loss: 5.7958 - val_acc: 0.4736\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9846\n",
      "Epoch 00034: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1127 - acc: 0.9845 - val_loss: 5.7236 - val_acc: 0.4903\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9806\n",
      "Epoch 00035: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1411 - acc: 0.9805 - val_loss: 5.8495 - val_acc: 0.4652\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9812\n",
      "Epoch 00036: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1323 - acc: 0.9811 - val_loss: 5.6959 - val_acc: 0.4936\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9854\n",
      "Epoch 00037: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1119 - acc: 0.9853 - val_loss: 6.1878 - val_acc: 0.4510\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9830\n",
      "Epoch 00038: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1222 - acc: 0.9830 - val_loss: 5.7045 - val_acc: 0.4915\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9870\n",
      "Epoch 00039: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1030 - acc: 0.9870 - val_loss: 6.1946 - val_acc: 0.4608\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9883\n",
      "Epoch 00040: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0933 - acc: 0.9883 - val_loss: 5.9009 - val_acc: 0.4878\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9878\n",
      "Epoch 00041: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1010 - acc: 0.9877 - val_loss: 6.3050 - val_acc: 0.4610\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9858\n",
      "Epoch 00042: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1123 - acc: 0.9858 - val_loss: 6.1169 - val_acc: 0.4782\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9897\n",
      "Epoch 00043: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0900 - acc: 0.9897 - val_loss: 6.1555 - val_acc: 0.4747\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1322 - acc: 0.9841\n",
      "Epoch 00044: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1323 - acc: 0.9841 - val_loss: 5.9886 - val_acc: 0.4852\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9860\n",
      "Epoch 00045: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1113 - acc: 0.9859 - val_loss: 6.4452 - val_acc: 0.4587\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9843\n",
      "Epoch 00046: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1195 - acc: 0.9843 - val_loss: 6.0465 - val_acc: 0.4824\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9874\n",
      "Epoch 00047: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1072 - acc: 0.9874 - val_loss: 6.3450 - val_acc: 0.4803\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9872\n",
      "Epoch 00048: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1057 - acc: 0.9871 - val_loss: 6.1320 - val_acc: 0.4771\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9882\n",
      "Epoch 00049: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1038 - acc: 0.9882 - val_loss: 6.7496 - val_acc: 0.4568\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9901\n",
      "Epoch 00050: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0957 - acc: 0.9901 - val_loss: 6.3688 - val_acc: 0.4705\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9874\n",
      "Epoch 00051: val_loss did not improve from 2.39656\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1107 - acc: 0.9874 - val_loss: 6.0864 - val_acc: 0.4861\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 2.5690 - acc: 0.3799\n",
      "Loss: 2.569016988304669 Accuracy: 0.37985462\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2160 - acc: 0.4475\n",
      "Epoch 00001: val_loss improved from inf to 1.96821, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_4_conv_checkpoint/001-1.9682.hdf5\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 2.2161 - acc: 0.4475 - val_loss: 1.9682 - val_acc: 0.4433\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7471 - acc: 0.7914\n",
      "Epoch 00002: val_loss improved from 1.96821 to 1.91519, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_4_conv_checkpoint/002-1.9152.hdf5\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 0.7476 - acc: 0.7913 - val_loss: 1.9152 - val_acc: 0.5355\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3211 - acc: 0.9189\n",
      "Epoch 00003: val_loss improved from 1.91519 to 1.82711, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_4_conv_checkpoint/003-1.8271.hdf5\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.3211 - acc: 0.9189 - val_loss: 1.8271 - val_acc: 0.5686\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1630 - acc: 0.9696\n",
      "Epoch 00004: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.1630 - acc: 0.9697 - val_loss: 1.9238 - val_acc: 0.5712\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9792\n",
      "Epoch 00005: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.1226 - acc: 0.9792 - val_loss: 1.9964 - val_acc: 0.5686\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9844\n",
      "Epoch 00006: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0972 - acc: 0.9844 - val_loss: 2.1124 - val_acc: 0.5653\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9829\n",
      "Epoch 00007: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.1007 - acc: 0.9828 - val_loss: 2.4370 - val_acc: 0.5413\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9810\n",
      "Epoch 00008: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0935 - acc: 0.9809 - val_loss: 2.5280 - val_acc: 0.5372\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9743\n",
      "Epoch 00009: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.1134 - acc: 0.9742 - val_loss: 2.6138 - val_acc: 0.5465\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9766\n",
      "Epoch 00010: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.1051 - acc: 0.9765 - val_loss: 2.6994 - val_acc: 0.5446\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9770\n",
      "Epoch 00011: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.1038 - acc: 0.9769 - val_loss: 2.7329 - val_acc: 0.5577\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9778\n",
      "Epoch 00012: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0966 - acc: 0.9777 - val_loss: 2.7253 - val_acc: 0.5542\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9825\n",
      "Epoch 00013: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0760 - acc: 0.9825 - val_loss: 3.0050 - val_acc: 0.5420\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9894\n",
      "Epoch 00014: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0545 - acc: 0.9893 - val_loss: 2.5972 - val_acc: 0.5821\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9795\n",
      "Epoch 00015: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0935 - acc: 0.9794 - val_loss: 3.0202 - val_acc: 0.5448\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9816\n",
      "Epoch 00016: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0789 - acc: 0.9816 - val_loss: 3.0835 - val_acc: 0.5651\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9834\n",
      "Epoch 00017: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0771 - acc: 0.9833 - val_loss: 3.6618 - val_acc: 0.5029\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9855\n",
      "Epoch 00018: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0706 - acc: 0.9854 - val_loss: 3.5847 - val_acc: 0.5127\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9836\n",
      "Epoch 00019: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0775 - acc: 0.9836 - val_loss: 3.2673 - val_acc: 0.5488\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9869\n",
      "Epoch 00020: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0658 - acc: 0.9868 - val_loss: 3.3369 - val_acc: 0.5556\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9801\n",
      "Epoch 00021: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0904 - acc: 0.9801 - val_loss: 3.3038 - val_acc: 0.5458\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9905\n",
      "Epoch 00022: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0512 - acc: 0.9904 - val_loss: 3.7178 - val_acc: 0.5220\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9855\n",
      "Epoch 00023: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0661 - acc: 0.9855 - val_loss: 3.4996 - val_acc: 0.5327\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9893\n",
      "Epoch 00024: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0545 - acc: 0.9892 - val_loss: 3.8603 - val_acc: 0.5122\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9862\n",
      "Epoch 00025: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0642 - acc: 0.9862 - val_loss: 3.6341 - val_acc: 0.5420\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9888\n",
      "Epoch 00026: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0597 - acc: 0.9888 - val_loss: 3.6657 - val_acc: 0.5469\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9878\n",
      "Epoch 00027: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0646 - acc: 0.9878 - val_loss: 3.8395 - val_acc: 0.5229\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9882\n",
      "Epoch 00028: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0599 - acc: 0.9882 - val_loss: 3.5452 - val_acc: 0.5502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9909\n",
      "Epoch 00029: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0486 - acc: 0.9908 - val_loss: 3.5568 - val_acc: 0.5579\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9880\n",
      "Epoch 00030: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0583 - acc: 0.9880 - val_loss: 3.8232 - val_acc: 0.5486\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9945\n",
      "Epoch 00031: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0365 - acc: 0.9945 - val_loss: 3.5833 - val_acc: 0.5497\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9918\n",
      "Epoch 00032: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0447 - acc: 0.9918 - val_loss: 3.5628 - val_acc: 0.5681\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9913\n",
      "Epoch 00033: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0473 - acc: 0.9913 - val_loss: 3.9576 - val_acc: 0.5320\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9854\n",
      "Epoch 00034: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0732 - acc: 0.9853 - val_loss: 3.6681 - val_acc: 0.5570\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9886\n",
      "Epoch 00035: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0578 - acc: 0.9886 - val_loss: 3.8322 - val_acc: 0.5590\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9924\n",
      "Epoch 00036: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0443 - acc: 0.9924 - val_loss: 3.7840 - val_acc: 0.5588\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9924\n",
      "Epoch 00037: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0451 - acc: 0.9924 - val_loss: 3.6913 - val_acc: 0.5570\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9936\n",
      "Epoch 00038: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0413 - acc: 0.9935 - val_loss: 4.2759 - val_acc: 0.5285\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9885\n",
      "Epoch 00039: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0599 - acc: 0.9885 - val_loss: 3.9323 - val_acc: 0.5434\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9930\n",
      "Epoch 00040: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0434 - acc: 0.9930 - val_loss: 4.0268 - val_acc: 0.5584\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9905\n",
      "Epoch 00041: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0493 - acc: 0.9905 - val_loss: 4.4081 - val_acc: 0.5386\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9901\n",
      "Epoch 00042: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 0.0527 - acc: 0.9901 - val_loss: 3.9852 - val_acc: 0.5528\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9891\n",
      "Epoch 00043: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0605 - acc: 0.9891 - val_loss: 4.2649 - val_acc: 0.5425\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9901\n",
      "Epoch 00044: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0538 - acc: 0.9901 - val_loss: 3.9472 - val_acc: 0.5572\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9922\n",
      "Epoch 00045: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0464 - acc: 0.9921 - val_loss: 4.0192 - val_acc: 0.5584\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9898\n",
      "Epoch 00046: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0543 - acc: 0.9898 - val_loss: 4.0432 - val_acc: 0.5572\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9939\n",
      "Epoch 00047: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0388 - acc: 0.9939 - val_loss: 3.8374 - val_acc: 0.5791\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9932\n",
      "Epoch 00048: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0430 - acc: 0.9932 - val_loss: 4.4757 - val_acc: 0.5316\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9935\n",
      "Epoch 00049: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0415 - acc: 0.9935 - val_loss: 4.0440 - val_acc: 0.5635\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9895\n",
      "Epoch 00050: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0548 - acc: 0.9895 - val_loss: 4.2227 - val_acc: 0.5411\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9915\n",
      "Epoch 00051: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0483 - acc: 0.9916 - val_loss: 4.0082 - val_acc: 0.5747\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9943\n",
      "Epoch 00052: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0394 - acc: 0.9943 - val_loss: 4.3062 - val_acc: 0.5420\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9910\n",
      "Epoch 00053: val_loss did not improve from 1.82711\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0532 - acc: 0.9910 - val_loss: 4.0894 - val_acc: 0.5651\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.9381 - acc: 0.5375\n",
      "Loss: 1.9381323531656869 Accuracy: 0.53748703\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1211 - acc: 0.4793\n",
      "Epoch 00001: val_loss improved from inf to 1.82394, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_5_conv_checkpoint/001-1.8239.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 2.1211 - acc: 0.4793 - val_loss: 1.8239 - val_acc: 0.4922\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7460 - acc: 0.7932\n",
      "Epoch 00002: val_loss improved from 1.82394 to 1.80033, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_5_conv_checkpoint/002-1.8003.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.7462 - acc: 0.7931 - val_loss: 1.8003 - val_acc: 0.5733\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.9156\n",
      "Epoch 00003: val_loss did not improve from 1.80033\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.3159 - acc: 0.9156 - val_loss: 1.8868 - val_acc: 0.5891\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9623\n",
      "Epoch 00004: val_loss improved from 1.80033 to 1.66849, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_5_conv_checkpoint/004-1.6685.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1576 - acc: 0.9623 - val_loss: 1.6685 - val_acc: 0.6299\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9797\n",
      "Epoch 00005: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1074 - acc: 0.9797 - val_loss: 1.7238 - val_acc: 0.6289\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9839\n",
      "Epoch 00006: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0887 - acc: 0.9839 - val_loss: 1.7979 - val_acc: 0.6187\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9760\n",
      "Epoch 00007: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1050 - acc: 0.9760 - val_loss: 1.9898 - val_acc: 0.6035\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9734\n",
      "Epoch 00008: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1105 - acc: 0.9733 - val_loss: 2.4092 - val_acc: 0.5677\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9607\n",
      "Epoch 00009: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1449 - acc: 0.9606 - val_loss: 2.1903 - val_acc: 0.6184\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9719\n",
      "Epoch 00010: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1109 - acc: 0.9719 - val_loss: 2.3010 - val_acc: 0.6073\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9779\n",
      "Epoch 00011: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0875 - acc: 0.9779 - val_loss: 2.5487 - val_acc: 0.5903\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9863\n",
      "Epoch 00012: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0615 - acc: 0.9863 - val_loss: 2.4869 - val_acc: 0.5973\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9820\n",
      "Epoch 00013: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0773 - acc: 0.9820 - val_loss: 2.4997 - val_acc: 0.5998\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9857\n",
      "Epoch 00014: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0670 - acc: 0.9857 - val_loss: 3.0158 - val_acc: 0.5535\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9785\n",
      "Epoch 00015: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0908 - acc: 0.9784 - val_loss: 2.5630 - val_acc: 0.6061\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9777\n",
      "Epoch 00016: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0920 - acc: 0.9777 - val_loss: 2.7865 - val_acc: 0.5998\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9819\n",
      "Epoch 00017: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0804 - acc: 0.9819 - val_loss: 3.0875 - val_acc: 0.5765\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9871\n",
      "Epoch 00018: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0626 - acc: 0.9871 - val_loss: 2.9434 - val_acc: 0.5812\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9884\n",
      "Epoch 00019: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0551 - acc: 0.9883 - val_loss: 3.2376 - val_acc: 0.5686\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9817\n",
      "Epoch 00020: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0789 - acc: 0.9817 - val_loss: 3.6253 - val_acc: 0.5353\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9849\n",
      "Epoch 00021: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0648 - acc: 0.9849 - val_loss: 2.9311 - val_acc: 0.5986\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 00022: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0429 - acc: 0.9917 - val_loss: 3.0281 - val_acc: 0.6024\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9849\n",
      "Epoch 00023: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0651 - acc: 0.9849 - val_loss: 2.7839 - val_acc: 0.6301\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9859\n",
      "Epoch 00024: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0665 - acc: 0.9859 - val_loss: 3.4690 - val_acc: 0.5744\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9915\n",
      "Epoch 00025: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0427 - acc: 0.9914 - val_loss: 2.8503 - val_acc: 0.6254\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9837\n",
      "Epoch 00026: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0743 - acc: 0.9837 - val_loss: 3.0718 - val_acc: 0.6061\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9909\n",
      "Epoch 00027: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0480 - acc: 0.9909 - val_loss: 3.7345 - val_acc: 0.5577\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9853\n",
      "Epoch 00028: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0651 - acc: 0.9852 - val_loss: 3.0644 - val_acc: 0.6031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9812\n",
      "Epoch 00029: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0838 - acc: 0.9812 - val_loss: 3.2542 - val_acc: 0.6084\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9889\n",
      "Epoch 00030: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0545 - acc: 0.9889 - val_loss: 3.6090 - val_acc: 0.5737\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9860\n",
      "Epoch 00031: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0671 - acc: 0.9860 - val_loss: 3.3533 - val_acc: 0.6038\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9926\n",
      "Epoch 00032: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0386 - acc: 0.9926 - val_loss: 3.3284 - val_acc: 0.6061\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9899\n",
      "Epoch 00033: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0516 - acc: 0.9899 - val_loss: 3.1759 - val_acc: 0.6247\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9906\n",
      "Epoch 00034: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0505 - acc: 0.9905 - val_loss: 3.6904 - val_acc: 0.5726\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9886\n",
      "Epoch 00035: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0537 - acc: 0.9886 - val_loss: 3.0748 - val_acc: 0.6271\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9880\n",
      "Epoch 00036: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0570 - acc: 0.9880 - val_loss: 3.4067 - val_acc: 0.6019\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9886\n",
      "Epoch 00037: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0563 - acc: 0.9886 - val_loss: 3.4589 - val_acc: 0.6038\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9928\n",
      "Epoch 00038: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0409 - acc: 0.9927 - val_loss: 3.3875 - val_acc: 0.6152\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9891\n",
      "Epoch 00039: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0587 - acc: 0.9891 - val_loss: 3.5850 - val_acc: 0.5898\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9883\n",
      "Epoch 00040: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0571 - acc: 0.9883 - val_loss: 3.7360 - val_acc: 0.5959\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9932\n",
      "Epoch 00041: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0399 - acc: 0.9931 - val_loss: 3.6356 - val_acc: 0.5998\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9877\n",
      "Epoch 00042: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0605 - acc: 0.9877 - val_loss: 3.8348 - val_acc: 0.5765\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9923\n",
      "Epoch 00043: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0409 - acc: 0.9923 - val_loss: 3.6001 - val_acc: 0.6033\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9920\n",
      "Epoch 00044: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0432 - acc: 0.9920 - val_loss: 3.8055 - val_acc: 0.5844\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9927\n",
      "Epoch 00045: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0405 - acc: 0.9927 - val_loss: 3.5762 - val_acc: 0.5970\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9904\n",
      "Epoch 00046: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0511 - acc: 0.9904 - val_loss: 3.5547 - val_acc: 0.5996\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9927\n",
      "Epoch 00047: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0369 - acc: 0.9927 - val_loss: 4.2561 - val_acc: 0.5625\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9905\n",
      "Epoch 00048: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0529 - acc: 0.9904 - val_loss: 3.9050 - val_acc: 0.5786\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9883\n",
      "Epoch 00049: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0621 - acc: 0.9882 - val_loss: 3.6388 - val_acc: 0.6103\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9922\n",
      "Epoch 00050: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0461 - acc: 0.9922 - val_loss: 3.3051 - val_acc: 0.6429\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9945\n",
      "Epoch 00051: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0314 - acc: 0.9945 - val_loss: 3.5778 - val_acc: 0.6212\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9905\n",
      "Epoch 00052: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0502 - acc: 0.9905 - val_loss: 3.4451 - val_acc: 0.6299\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9898\n",
      "Epoch 00053: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0553 - acc: 0.9898 - val_loss: 3.7121 - val_acc: 0.6063\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9945\n",
      "Epoch 00054: val_loss did not improve from 1.66849\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0340 - acc: 0.9945 - val_loss: 3.6811 - val_acc: 0.6210\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.9277 - acc: 0.5751\n",
      "Loss: 1.927673839037292 Accuracy: 0.5750779\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8288 - acc: 0.4989\n",
      "Epoch 00001: val_loss improved from inf to 1.64076, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_6_conv_checkpoint/001-1.6408.hdf5\n",
      "36805/36805 [==============================] - 130s 4ms/sample - loss: 1.8289 - acc: 0.4989 - val_loss: 1.6408 - val_acc: 0.5215\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9292 - acc: 0.7335\n",
      "Epoch 00002: val_loss improved from 1.64076 to 1.41677, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_6_conv_checkpoint/002-1.4168.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.9292 - acc: 0.7335 - val_loss: 1.4168 - val_acc: 0.6196\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4954 - acc: 0.8546\n",
      "Epoch 00003: val_loss improved from 1.41677 to 1.26405, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_6_conv_checkpoint/003-1.2640.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.4954 - acc: 0.8546 - val_loss: 1.2640 - val_acc: 0.6683\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2824 - acc: 0.9252\n",
      "Epoch 00004: val_loss improved from 1.26405 to 1.25330, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_6_conv_checkpoint/004-1.2533.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2824 - acc: 0.9253 - val_loss: 1.2533 - val_acc: 0.6837\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9620\n",
      "Epoch 00005: val_loss improved from 1.25330 to 1.18306, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_6_conv_checkpoint/005-1.1831.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1672 - acc: 0.9620 - val_loss: 1.1831 - val_acc: 0.6962\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9772\n",
      "Epoch 00006: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1195 - acc: 0.9772 - val_loss: 1.2942 - val_acc: 0.6930\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9788\n",
      "Epoch 00007: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1073 - acc: 0.9787 - val_loss: 1.5071 - val_acc: 0.6541\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9720\n",
      "Epoch 00008: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1195 - acc: 0.9720 - val_loss: 1.3169 - val_acc: 0.6972\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9826\n",
      "Epoch 00009: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0836 - acc: 0.9825 - val_loss: 1.4848 - val_acc: 0.6744\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9822\n",
      "Epoch 00010: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0837 - acc: 0.9821 - val_loss: 1.4922 - val_acc: 0.6783\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9835\n",
      "Epoch 00011: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0751 - acc: 0.9835 - val_loss: 1.6368 - val_acc: 0.6594\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9826\n",
      "Epoch 00012: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0754 - acc: 0.9826 - val_loss: 1.6197 - val_acc: 0.6741\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9892\n",
      "Epoch 00013: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0546 - acc: 0.9892 - val_loss: 1.6139 - val_acc: 0.6834\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9857\n",
      "Epoch 00014: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0657 - acc: 0.9856 - val_loss: 1.9369 - val_acc: 0.6331\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9806\n",
      "Epoch 00015: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0794 - acc: 0.9805 - val_loss: 1.9308 - val_acc: 0.6469\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9837\n",
      "Epoch 00016: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0664 - acc: 0.9836 - val_loss: 1.8495 - val_acc: 0.6683\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9866\n",
      "Epoch 00017: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0582 - acc: 0.9866 - val_loss: 1.6950 - val_acc: 0.6890\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9935\n",
      "Epoch 00018: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0400 - acc: 0.9935 - val_loss: 1.7114 - val_acc: 0.6895\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9914\n",
      "Epoch 00019: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0439 - acc: 0.9913 - val_loss: 1.9300 - val_acc: 0.6562\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9798\n",
      "Epoch 00020: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0793 - acc: 0.9798 - val_loss: 1.7449 - val_acc: 0.6811\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9847\n",
      "Epoch 00021: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0620 - acc: 0.9846 - val_loss: 1.8213 - val_acc: 0.6809\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9884\n",
      "Epoch 00022: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0487 - acc: 0.9883 - val_loss: 2.1160 - val_acc: 0.6462\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9899\n",
      "Epoch 00023: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0444 - acc: 0.9899 - val_loss: 1.7585 - val_acc: 0.7056\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9922\n",
      "Epoch 00024: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0367 - acc: 0.9922 - val_loss: 2.0689 - val_acc: 0.6546\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9895\n",
      "Epoch 00025: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0446 - acc: 0.9895 - val_loss: 1.9565 - val_acc: 0.6867\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9931\n",
      "Epoch 00026: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0340 - acc: 0.9931 - val_loss: 2.4739 - val_acc: 0.6231\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9908\n",
      "Epoch 00027: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0440 - acc: 0.9908 - val_loss: 2.5024 - val_acc: 0.6138\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9870\n",
      "Epoch 00028: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0523 - acc: 0.9870 - val_loss: 2.0828 - val_acc: 0.6620\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9863\n",
      "Epoch 00029: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0566 - acc: 0.9863 - val_loss: 2.4962 - val_acc: 0.6126\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9845\n",
      "Epoch 00030: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0656 - acc: 0.9845 - val_loss: 2.1470 - val_acc: 0.6746\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9951\n",
      "Epoch 00031: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0280 - acc: 0.9951 - val_loss: 2.2139 - val_acc: 0.6716\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9909\n",
      "Epoch 00032: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0409 - acc: 0.9909 - val_loss: 1.9407 - val_acc: 0.7025\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9949\n",
      "Epoch 00033: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0278 - acc: 0.9949 - val_loss: 1.9527 - val_acc: 0.6965\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9885\n",
      "Epoch 00034: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0496 - acc: 0.9885 - val_loss: 2.2196 - val_acc: 0.6727\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9933\n",
      "Epoch 00035: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0320 - acc: 0.9933 - val_loss: 2.0626 - val_acc: 0.6806\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9942\n",
      "Epoch 00036: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0283 - acc: 0.9942 - val_loss: 2.1243 - val_acc: 0.6834\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9915\n",
      "Epoch 00037: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0378 - acc: 0.9914 - val_loss: 2.5248 - val_acc: 0.6385\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9855\n",
      "Epoch 00038: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0622 - acc: 0.9855 - val_loss: 2.3016 - val_acc: 0.6618\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9915\n",
      "Epoch 00039: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0382 - acc: 0.9914 - val_loss: 2.0061 - val_acc: 0.6967\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9907\n",
      "Epoch 00040: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0426 - acc: 0.9906 - val_loss: 2.1329 - val_acc: 0.6944\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9892\n",
      "Epoch 00041: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0441 - acc: 0.9891 - val_loss: 2.0378 - val_acc: 0.6900\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9888\n",
      "Epoch 00042: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0472 - acc: 0.9888 - val_loss: 2.0722 - val_acc: 0.6956\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9958\n",
      "Epoch 00043: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0248 - acc: 0.9958 - val_loss: 2.3010 - val_acc: 0.6639\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9870\n",
      "Epoch 00044: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0519 - acc: 0.9870 - val_loss: 2.0574 - val_acc: 0.6960\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9929\n",
      "Epoch 00045: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0327 - acc: 0.9929 - val_loss: 2.1793 - val_acc: 0.6867\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9970\n",
      "Epoch 00046: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0210 - acc: 0.9970 - val_loss: 2.1220 - val_acc: 0.6969\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9945\n",
      "Epoch 00047: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0283 - acc: 0.9944 - val_loss: 2.5015 - val_acc: 0.6462\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9864\n",
      "Epoch 00048: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0552 - acc: 0.9864 - val_loss: 2.0622 - val_acc: 0.7025\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9943\n",
      "Epoch 00049: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0274 - acc: 0.9942 - val_loss: 2.6421 - val_acc: 0.6529\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9905\n",
      "Epoch 00050: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0425 - acc: 0.9905 - val_loss: 2.5125 - val_acc: 0.6622\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9910\n",
      "Epoch 00051: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0384 - acc: 0.9910 - val_loss: 2.2166 - val_acc: 0.7007\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9901\n",
      "Epoch 00052: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0400 - acc: 0.9901 - val_loss: 2.3127 - val_acc: 0.6813\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9935\n",
      "Epoch 00053: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0290 - acc: 0.9935 - val_loss: 2.5625 - val_acc: 0.6632\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9925\n",
      "Epoch 00054: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0360 - acc: 0.9924 - val_loss: 2.2189 - val_acc: 0.7018\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9925\n",
      "Epoch 00055: val_loss did not improve from 1.18306\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0342 - acc: 0.9925 - val_loss: 2.3220 - val_acc: 0.6855\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.3118 - acc: 0.6638\n",
      "Loss: 1.3117821176970612 Accuracy: 0.6637591\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6733 - acc: 0.5127\n",
      "Epoch 00001: val_loss improved from inf to 1.42738, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_7_conv_checkpoint/001-1.4274.hdf5\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 1.6733 - acc: 0.5126 - val_loss: 1.4274 - val_acc: 0.5441\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0146 - acc: 0.7038\n",
      "Epoch 00002: val_loss improved from 1.42738 to 1.06648, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_7_conv_checkpoint/002-1.0665.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 1.0148 - acc: 0.7037 - val_loss: 1.0665 - val_acc: 0.6995\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7512 - acc: 0.7798\n",
      "Epoch 00003: val_loss did not improve from 1.06648\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.7515 - acc: 0.7797 - val_loss: 1.1557 - val_acc: 0.6788\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5490 - acc: 0.8387\n",
      "Epoch 00004: val_loss improved from 1.06648 to 1.04584, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_7_conv_checkpoint/004-1.0458.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.5490 - acc: 0.8387 - val_loss: 1.0458 - val_acc: 0.7107\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3871 - acc: 0.8876\n",
      "Epoch 00005: val_loss did not improve from 1.04584\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.3871 - acc: 0.8876 - val_loss: 1.2028 - val_acc: 0.6739\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2744 - acc: 0.9244\n",
      "Epoch 00006: val_loss improved from 1.04584 to 1.03379, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_7_conv_checkpoint/006-1.0338.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2747 - acc: 0.9243 - val_loss: 1.0338 - val_acc: 0.7296\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2385 - acc: 0.9354\n",
      "Epoch 00007: val_loss improved from 1.03379 to 0.97005, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_7_conv_checkpoint/007-0.9701.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2386 - acc: 0.9353 - val_loss: 0.9701 - val_acc: 0.7403\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9655\n",
      "Epoch 00008: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1509 - acc: 0.9654 - val_loss: 1.0139 - val_acc: 0.7461\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9725\n",
      "Epoch 00009: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1247 - acc: 0.9724 - val_loss: 1.0045 - val_acc: 0.7491\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9791\n",
      "Epoch 00010: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1029 - acc: 0.9791 - val_loss: 1.0637 - val_acc: 0.7244\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9815\n",
      "Epoch 00011: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0894 - acc: 0.9815 - val_loss: 1.1865 - val_acc: 0.7268\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9844\n",
      "Epoch 00012: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0785 - acc: 0.9844 - val_loss: 1.2379 - val_acc: 0.7179\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9777\n",
      "Epoch 00013: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0946 - acc: 0.9777 - val_loss: 1.2009 - val_acc: 0.7177\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9921\n",
      "Epoch 00014: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0523 - acc: 0.9921 - val_loss: 1.3282 - val_acc: 0.6951\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9878\n",
      "Epoch 00015: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0619 - acc: 0.9878 - val_loss: 1.6986 - val_acc: 0.6529\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9888\n",
      "Epoch 00016: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0588 - acc: 0.9888 - val_loss: 1.0438 - val_acc: 0.7582\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9894\n",
      "Epoch 00017: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0539 - acc: 0.9894 - val_loss: 1.3415 - val_acc: 0.7181\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9845\n",
      "Epoch 00018: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0669 - acc: 0.9845 - val_loss: 1.2734 - val_acc: 0.7389\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9892\n",
      "Epoch 00019: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0511 - acc: 0.9892 - val_loss: 1.3711 - val_acc: 0.7275\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9832\n",
      "Epoch 00020: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0686 - acc: 0.9832 - val_loss: 1.2899 - val_acc: 0.7391\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9924\n",
      "Epoch 00021: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0400 - acc: 0.9924 - val_loss: 1.2306 - val_acc: 0.7538\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9894\n",
      "Epoch 00022: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0495 - acc: 0.9894 - val_loss: 1.3379 - val_acc: 0.7277\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9863\n",
      "Epoch 00023: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0566 - acc: 0.9863 - val_loss: 1.2006 - val_acc: 0.7617\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9913\n",
      "Epoch 00024: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0413 - acc: 0.9912 - val_loss: 1.2347 - val_acc: 0.7610\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9887\n",
      "Epoch 00025: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0481 - acc: 0.9887 - val_loss: 1.4640 - val_acc: 0.7249\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9957\n",
      "Epoch 00026: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0281 - acc: 0.9957 - val_loss: 1.3331 - val_acc: 0.7545\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9933\n",
      "Epoch 00027: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0356 - acc: 0.9933 - val_loss: 1.5357 - val_acc: 0.7063\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9785\n",
      "Epoch 00028: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0796 - acc: 0.9785 - val_loss: 1.2708 - val_acc: 0.7431\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9945\n",
      "Epoch 00029: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0312 - acc: 0.9945 - val_loss: 1.3887 - val_acc: 0.7386\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9916\n",
      "Epoch 00030: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0384 - acc: 0.9916 - val_loss: 1.3019 - val_acc: 0.7559\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9922\n",
      "Epoch 00031: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0385 - acc: 0.9922 - val_loss: 1.2993 - val_acc: 0.7575\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9949\n",
      "Epoch 00032: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0289 - acc: 0.9949 - val_loss: 1.3132 - val_acc: 0.7624\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9877\n",
      "Epoch 00033: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0498 - acc: 0.9876 - val_loss: 1.3359 - val_acc: 0.7526\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9912\n",
      "Epoch 00034: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0391 - acc: 0.9911 - val_loss: 1.2559 - val_acc: 0.7706\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9912\n",
      "Epoch 00035: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0418 - acc: 0.9912 - val_loss: 1.2628 - val_acc: 0.7668\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9964\n",
      "Epoch 00036: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0236 - acc: 0.9964 - val_loss: 1.4177 - val_acc: 0.7438\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9887\n",
      "Epoch 00037: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0456 - acc: 0.9887 - val_loss: 1.3209 - val_acc: 0.7587\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9888\n",
      "Epoch 00038: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0465 - acc: 0.9888 - val_loss: 1.4763 - val_acc: 0.7475\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9908\n",
      "Epoch 00039: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0394 - acc: 0.9908 - val_loss: 1.3210 - val_acc: 0.7566\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9968\n",
      "Epoch 00040: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0206 - acc: 0.9968 - val_loss: 1.3669 - val_acc: 0.7650\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9952\n",
      "Epoch 00041: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0257 - acc: 0.9952 - val_loss: 1.3927 - val_acc: 0.7584\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9933\n",
      "Epoch 00042: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0316 - acc: 0.9933 - val_loss: 1.7315 - val_acc: 0.7133\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9861\n",
      "Epoch 00043: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0508 - acc: 0.9861 - val_loss: 1.4292 - val_acc: 0.7519\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9942\n",
      "Epoch 00044: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0285 - acc: 0.9942 - val_loss: 1.5411 - val_acc: 0.7393\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9965\n",
      "Epoch 00045: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0224 - acc: 0.9965 - val_loss: 1.5153 - val_acc: 0.7498\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9903\n",
      "Epoch 00046: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0404 - acc: 0.9902 - val_loss: 1.5822 - val_acc: 0.7372\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 00047: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0359 - acc: 0.9917 - val_loss: 1.5311 - val_acc: 0.7412\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9965\n",
      "Epoch 00048: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0205 - acc: 0.9965 - val_loss: 1.4560 - val_acc: 0.7556\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9967\n",
      "Epoch 00049: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0193 - acc: 0.9967 - val_loss: 1.7453 - val_acc: 0.7223\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9893\n",
      "Epoch 00050: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0422 - acc: 0.9893 - val_loss: 1.4611 - val_acc: 0.7554\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9905\n",
      "Epoch 00051: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0395 - acc: 0.9904 - val_loss: 1.4626 - val_acc: 0.7633\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9906\n",
      "Epoch 00052: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0395 - acc: 0.9905 - val_loss: 1.6083 - val_acc: 0.7363\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9914\n",
      "Epoch 00053: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0366 - acc: 0.9914 - val_loss: 1.4979 - val_acc: 0.7577\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9939\n",
      "Epoch 00054: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0287 - acc: 0.9939 - val_loss: 1.4705 - val_acc: 0.7577\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9940\n",
      "Epoch 00055: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0296 - acc: 0.9940 - val_loss: 1.5158 - val_acc: 0.7598\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9929\n",
      "Epoch 00056: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0336 - acc: 0.9928 - val_loss: 1.5890 - val_acc: 0.7384\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9910\n",
      "Epoch 00057: val_loss did not improve from 0.97005\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0376 - acc: 0.9910 - val_loss: 1.4771 - val_acc: 0.7519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.0674 - acc: 0.7148\n",
      "Loss: 1.0673616539775892 Accuracy: 0.7148494\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6864 - acc: 0.4897\n",
      "Epoch 00001: val_loss improved from inf to 1.46598, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_8_conv_checkpoint/001-1.4660.hdf5\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 1.6864 - acc: 0.4897 - val_loss: 1.4660 - val_acc: 0.5271\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9985 - acc: 0.7041\n",
      "Epoch 00002: val_loss improved from 1.46598 to 1.09617, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_8_conv_checkpoint/002-1.0962.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.9986 - acc: 0.7040 - val_loss: 1.0962 - val_acc: 0.6930\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7947 - acc: 0.7684\n",
      "Epoch 00003: val_loss improved from 1.09617 to 0.85883, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_8_conv_checkpoint/003-0.8588.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.7947 - acc: 0.7683 - val_loss: 0.8588 - val_acc: 0.7638\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6455 - acc: 0.8126\n",
      "Epoch 00004: val_loss did not improve from 0.85883\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.6455 - acc: 0.8126 - val_loss: 0.9551 - val_acc: 0.7405\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5379 - acc: 0.8434\n",
      "Epoch 00005: val_loss did not improve from 0.85883\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.5382 - acc: 0.8433 - val_loss: 0.9139 - val_acc: 0.7556\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8654\n",
      "Epoch 00006: val_loss did not improve from 0.85883\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.4592 - acc: 0.8653 - val_loss: 0.9002 - val_acc: 0.7496\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3918 - acc: 0.8861\n",
      "Epoch 00007: val_loss improved from 0.85883 to 0.70735, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_8_conv_checkpoint/007-0.7074.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.3919 - acc: 0.8860 - val_loss: 0.7074 - val_acc: 0.8022\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3081 - acc: 0.9125\n",
      "Epoch 00008: val_loss did not improve from 0.70735\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.3081 - acc: 0.9125 - val_loss: 0.7290 - val_acc: 0.7985\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2632 - acc: 0.9254\n",
      "Epoch 00009: val_loss did not improve from 0.70735\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2633 - acc: 0.9254 - val_loss: 0.9072 - val_acc: 0.7517\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2218 - acc: 0.9376\n",
      "Epoch 00010: val_loss improved from 0.70735 to 0.63829, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_8_conv_checkpoint/010-0.6383.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2219 - acc: 0.9376 - val_loss: 0.6383 - val_acc: 0.8300\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1851 - acc: 0.9508\n",
      "Epoch 00011: val_loss did not improve from 0.63829\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1851 - acc: 0.9508 - val_loss: 0.6498 - val_acc: 0.8360\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9637\n",
      "Epoch 00012: val_loss did not improve from 0.63829\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1439 - acc: 0.9637 - val_loss: 0.7365 - val_acc: 0.8164\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9696\n",
      "Epoch 00013: val_loss did not improve from 0.63829\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1199 - acc: 0.9695 - val_loss: 0.6578 - val_acc: 0.8360\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9669\n",
      "Epoch 00014: val_loss did not improve from 0.63829\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1261 - acc: 0.9669 - val_loss: 0.7981 - val_acc: 0.8125\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9704\n",
      "Epoch 00015: val_loss did not improve from 0.63829\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1175 - acc: 0.9704 - val_loss: 0.6975 - val_acc: 0.8255\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9830\n",
      "Epoch 00016: val_loss did not improve from 0.63829\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0783 - acc: 0.9829 - val_loss: 0.7553 - val_acc: 0.8006\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9813\n",
      "Epoch 00017: val_loss did not improve from 0.63829\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0819 - acc: 0.9813 - val_loss: 0.6591 - val_acc: 0.8393\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9851\n",
      "Epoch 00018: val_loss did not improve from 0.63829\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0707 - acc: 0.9850 - val_loss: 0.9676 - val_acc: 0.7706\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9722\n",
      "Epoch 00019: val_loss improved from 0.63829 to 0.59638, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_8_conv_checkpoint/019-0.5964.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1034 - acc: 0.9722 - val_loss: 0.5964 - val_acc: 0.8532\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9898\n",
      "Epoch 00020: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0533 - acc: 0.9898 - val_loss: 0.7632 - val_acc: 0.8232\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9897\n",
      "Epoch 00021: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0517 - acc: 0.9897 - val_loss: 0.6880 - val_acc: 0.8407\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9837\n",
      "Epoch 00022: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0683 - acc: 0.9837 - val_loss: 0.6576 - val_acc: 0.8432\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9908\n",
      "Epoch 00023: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0464 - acc: 0.9908 - val_loss: 0.8203 - val_acc: 0.8262\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9787\n",
      "Epoch 00024: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0813 - acc: 0.9786 - val_loss: 0.7856 - val_acc: 0.8253\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9794\n",
      "Epoch 00025: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0795 - acc: 0.9793 - val_loss: 0.6682 - val_acc: 0.8458\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9860\n",
      "Epoch 00026: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0604 - acc: 0.9860 - val_loss: 0.7492 - val_acc: 0.8311\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9929\n",
      "Epoch 00027: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0376 - acc: 0.9928 - val_loss: 0.6619 - val_acc: 0.8521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9918\n",
      "Epoch 00028: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0402 - acc: 0.9918 - val_loss: 0.7789 - val_acc: 0.8309\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9948\n",
      "Epoch 00029: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0303 - acc: 0.9948 - val_loss: 0.7481 - val_acc: 0.8321\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9899\n",
      "Epoch 00030: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0445 - acc: 0.9899 - val_loss: 1.1862 - val_acc: 0.7601\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9863\n",
      "Epoch 00031: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0550 - acc: 0.9863 - val_loss: 0.7062 - val_acc: 0.8500\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9943\n",
      "Epoch 00032: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0300 - acc: 0.9942 - val_loss: 0.6947 - val_acc: 0.8477\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9880\n",
      "Epoch 00033: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0490 - acc: 0.9880 - val_loss: 0.6757 - val_acc: 0.8553\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9881\n",
      "Epoch 00034: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0486 - acc: 0.9881 - val_loss: 0.7008 - val_acc: 0.8530\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9927\n",
      "Epoch 00035: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0341 - acc: 0.9927 - val_loss: 0.8746 - val_acc: 0.8188\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9890- ETA: 5s\n",
      "Epoch 00036: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0451 - acc: 0.9890 - val_loss: 0.7386 - val_acc: 0.8477\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9927\n",
      "Epoch 00037: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0340 - acc: 0.9927 - val_loss: 0.7523 - val_acc: 0.8453\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9957\n",
      "Epoch 00038: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0229 - acc: 0.9957 - val_loss: 0.7381 - val_acc: 0.8444\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9955\n",
      "Epoch 00039: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0220 - acc: 0.9955 - val_loss: 0.7337 - val_acc: 0.8514\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9934\n",
      "Epoch 00040: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0304 - acc: 0.9934 - val_loss: 1.2369 - val_acc: 0.7722\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9881\n",
      "Epoch 00041: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0468 - acc: 0.9880 - val_loss: 0.7797 - val_acc: 0.8393\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9909\n",
      "Epoch 00042: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0386 - acc: 0.9909 - val_loss: 0.7136 - val_acc: 0.8551\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9927\n",
      "Epoch 00043: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0326 - acc: 0.9926 - val_loss: 0.7637 - val_acc: 0.8484\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9949\n",
      "Epoch 00044: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0257 - acc: 0.9949 - val_loss: 0.7884 - val_acc: 0.8348\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9974\n",
      "Epoch 00045: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0174 - acc: 0.9974 - val_loss: 0.7123 - val_acc: 0.8588\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9948\n",
      "Epoch 00046: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0275 - acc: 0.9947 - val_loss: 0.9607 - val_acc: 0.8239\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9835\n",
      "Epoch 00047: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0589 - acc: 0.9835 - val_loss: 1.1004 - val_acc: 0.7787\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9969\n",
      "Epoch 00048: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0175 - acc: 0.9968 - val_loss: 0.6965 - val_acc: 0.8623\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9906\n",
      "Epoch 00049: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0362 - acc: 0.9905 - val_loss: 0.8055 - val_acc: 0.8407\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9945\n",
      "Epoch 00050: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0248 - acc: 0.9944 - val_loss: 0.7691 - val_acc: 0.8537\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9934- ETA: 0s - loss: 0.0278 - acc: 0.993\n",
      "Epoch 00051: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0280 - acc: 0.9934 - val_loss: 1.0088 - val_acc: 0.8055\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9954\n",
      "Epoch 00052: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0228 - acc: 0.9954 - val_loss: 0.8114 - val_acc: 0.8393\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9919\n",
      "Epoch 00053: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0333 - acc: 0.9919 - val_loss: 0.8435 - val_acc: 0.8344\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9962\n",
      "Epoch 00054: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0187 - acc: 0.9962 - val_loss: 0.7692 - val_acc: 0.8526\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9957\n",
      "Epoch 00055: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0206 - acc: 0.9956 - val_loss: 0.8624 - val_acc: 0.8288\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9933\n",
      "Epoch 00056: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0274 - acc: 0.9932 - val_loss: 0.8779 - val_acc: 0.8400\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9942\n",
      "Epoch 00057: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0239 - acc: 0.9942 - val_loss: 0.7862 - val_acc: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9980\n",
      "Epoch 00058: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0130 - acc: 0.9979 - val_loss: 0.8744 - val_acc: 0.8383\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9911\n",
      "Epoch 00059: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0333 - acc: 0.9911 - val_loss: 0.7871 - val_acc: 0.8493\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9978\n",
      "Epoch 00060: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0131 - acc: 0.9978 - val_loss: 0.7787 - val_acc: 0.8556\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9977\n",
      "Epoch 00061: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0139 - acc: 0.9977 - val_loss: 0.7645 - val_acc: 0.8523\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9852\n",
      "Epoch 00062: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0507 - acc: 0.9852 - val_loss: 0.8518 - val_acc: 0.8314\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9958\n",
      "Epoch 00063: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0187 - acc: 0.9958 - val_loss: 0.9032 - val_acc: 0.8355\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9983\n",
      "Epoch 00064: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0116 - acc: 0.9982 - val_loss: 0.8353 - val_acc: 0.8442\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9920\n",
      "Epoch 00065: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0307 - acc: 0.9919 - val_loss: 0.9111 - val_acc: 0.8325\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9948\n",
      "Epoch 00066: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0239 - acc: 0.9947 - val_loss: 0.7501 - val_acc: 0.8579\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9924\n",
      "Epoch 00067: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0307 - acc: 0.9924 - val_loss: 0.8492 - val_acc: 0.8425\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9965\n",
      "Epoch 00068: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0162 - acc: 0.9965 - val_loss: 0.7569 - val_acc: 0.8602\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9981\n",
      "Epoch 00069: val_loss did not improve from 0.59638\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0113 - acc: 0.9981 - val_loss: 0.8772 - val_acc: 0.8500\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXlcVFUbx3+HYZN9UVBcwV0Wwd1cSzM1U3tzyaVdbTezTMtKLC1TK3NPzdJel0zzVcu9RNTcFZVSwwUCBFkEBFln5nn/eLjMADMwLAMo5/v5XIa5yznn3rn3/M7znHOeK4gIEolEIpGUhkV1F0AikUgk9wdSMCQSiURiElIwJBKJRGISUjAkEolEYhJSMCQSiURiElIwJBKJRGISUjAkEolEYhJSMCQSiURiEpbmSlgIsRbAEAAJRORnYPs0AOP0ytEWQD0iuiOEiASQDkADQE1EncxVTolEIpGYhjDXTG8hRG8AGQDWGxKMIvs+AeBtInok/3skgE5ElFSWPOvWrUvNmjUrX4ElEomkFnL27NkkIqpnyr5mszCIKFQI0czE3ccA2FTRPJs1a4YzZ85UNBmJRCKpNQghokzdt9r7MIQQdgAGAtimt5oA7BdCnBVCTKqekkkkEolEH7NZGGXgCQDHiOiO3rqeRBQrhPAAcEAIcYWIQg0dnC8okwCgSZMm5i+tRCKR1FKq3cIA8DSKuKOIKDb/MwHAdgBdjB1MRKuIqBMRdapXzyQ3nEQikUjKQbVaGEIIZwB9AIzXW2cPwIKI0vP/HwDgk/LmkZeXh5iYGGRnZ1e4vLURW1tbNGrUCFZWVtVdFIlEUs2Yc1jtJgB9AdQVQsQAmAXACgCIaGX+bk8C2E9E9/QO9QSwXQihlG8jEe0tbzliYmLg6OiIZs2aIT9NiYkQEZKTkxETEwNvb+/qLo5EIqlmzDlKaowJ+/wA4Ici624AaF9Z5cjOzpZiUU6EEHB3d0diYmJ1F0UikdQAakIfhtmRYlF+5LWTSCQKtUIwSiMn5xbU6rTqLoZEIpHUaKRgAMjNjYdafdcsaaempmL58uXlOnbw4MFITU01ef/g4GAsXLiwXHlJJBJJaUjBACCECkQas6RdkmCo1eoSj929ezdcXFzMUSyJRCIpM1IwwILBcQ4rnxkzZuD69esIDAzEtGnTEBISgl69emHo0KFo164dAGD48OHo2LEjfH19sWrVqoJjmzVrhqSkJERGRqJt27aYOHEifH19MWDAAGRlZZWYb1hYGLp164aAgAA8+eSTSElJAQAsXrwY7dq1Q0BAAJ5++mkAwOHDhxEYGIjAwEAEBQUhPT3dLNdCIpHc39SEmd5VRkTEFGRkhBVbr9VmAhCwsKhT5jQdHALRsuUio9vnzZuH8PBwhIVxviEhITh37hzCw8MLhqquXbsWbm5uyMrKQufOnfHUU0/B3d29SNkjsGnTJqxevRqjRo3Ctm3bMH78+GL5KTz77LNYsmQJ+vTpg48//hizZ8/GokWLMG/ePNy8eRM2NjYF7q6FCxdi2bJl6NGjBzIyMmBra1vm6yCRSB58pIUBABDg8FVVQ5cuXQrNa1i8eDHat2+Pbt26ITo6GhEREcWO8fb2RmBgIACgY8eOiIyMNJp+WloaUlNT0adPHwDAc889h9BQjqwSEBCAcePG4b///S8sLbm90KNHD0ydOhWLFy9GampqwXqJRCLRp1bVDMYsgays69Bqs2BvX2IU9krD3t6+4P+QkBAcPHgQx48fh52dHfr27WtwVrqNjU3B/yqVqlSXlDF+++03hIaGYteuXZg7dy4uXbqEGTNm4PHHH8fu3bvRo0cP7Nu3D23atClX+hKJ5MFFWhgAABWItGZJ2dHRscQ+gbS0NLi6usLOzg5XrlzBiRMnKpyns7MzXF1dceTIEQDAjz/+iD59+kCr1SI6OhoPP/wwvvjiC6SlpSEjIwPXr1+Hv78/pk+fjs6dO+PKlSsVLoNEInnwqFUWhjHMOUrK3d0dPXr0gJ+fHwYNGoTHH3+80PaBAwdi5cqVaNu2LVq3bo1u3bpVSr7r1q3DK6+8gszMTPj4+OD777+HRqPB+PHjkZaWBiLC5MmT4eLigo8++giHDh2ChYUFfH19MWjQoEopg0QiebAw2xv3qoNOnTpR0RcoXb58GW3bti3xuJycWOTmxsHBoaOc2WwAU66hRCK5PxFCnDX1NdjSJQVlWC0AmMctJZFIJA8CUjAAACwY5nJLSSQSyYOAFAzoLAwpGBKJRGIcKRiQgiGRSCSmIAUDgOKSMld4EIlEInkQkIIBaWFIJBKJKUjBACAEXwZzTd4rKw4ODmVaL5FIJFWBFAwA0iUlkUgkpSMFA+Z1Sc2YMQPLli0r+K685CgjIwP9+vVDhw4d4O/vjx07dpicJhFh2rRp8PPzg7+/P3766ScAQFxcHHr37o3AwED4+fnhyJEj0Gg0eP755wv2/frrryv9HCUSSe2gdoUGmTIFCCse3lwAqKPJgIWwAixsih9XEoGBwCLj4c1Hjx6NKVOm4PXXXwcAbNmyBfv27YOtrS22b98OJycnJCUloVu3bhg6dKhJM81/+eUXhIWF4cKFC0hKSkLnzp3Ru3dvbNy4EY899hhmzpwJjUaDzMxMhIWFITY2FuHh4QBQpjf4SSQSiT5mszCEEGuFEAlCiHAj2/sKIdKEEGH5y8d62wYKIa4KIa4JIWaYq4yFygPAHCHOg4KCkJCQgFu3buHChQtwdXVF48aNQUT44IMPEBAQgP79+yM2Nha3b982Kc2jR49izJgxUKlU8PT0RJ8+fXD69Gl07twZ33//PYKDg3Hp0iU4OjrCx8cHN27cwJtvvom9e/fCycmp0s9RIpHUDsxpYfwAYCmA9SXsc4SIhuivEOwfWgbgUQAxAE4LIXYS0d8VLlEJlkBWRjhUqjqoU6d5hbMpysiRI7F161bEx8dj9OjRAIANGzYgMTERZ8+ehZWVFZo1a2YwrHlZ6N27N0JDQ/Hbb7/h+eefx9SpU/Hss8/iwoUL2LdvH1auXIktW7Zg7dq1lXFaEomklmE2C4OIQgHcKcehXQBcI6IbRJQLYDOAYZVaOAOYM2Lt6NGjsXnzZmzduhUjR44EwGHNPTw8YGVlhUOHDiEqKsrk9Hr16oWffvoJGo0GiYmJCA0NRZcuXRAVFQVPT09MnDgREyZMwLlz55CUlAStVounnnoKc+bMwblz58xyjhKJ5MGnuvswugshLgC4BeBdIvoLQEMA0Xr7xADoaiwBIcQkAJMAoEmTJuUuCAuGeYbV+vr6Ij09HQ0bNkSDBg0AAOPGjcMTTzwBf39/dOrUqUwvLHryySdx/PhxtG/fHkIIzJ8/H/Xr18e6deuwYMECWFlZwcHBAevXr0dsbCxeeOEFaLV8bp9//rlZzlEikTz4mDW8uRCiGYBfiajYq+yEEE4AtESUIYQYDOAbImophBgBYCARTcjf7xkAXYnojdLyK294cwDIyroGrTYH9va+JpxZ7UKGN5dIHlzui/DmRHSXiDLy/98NwEoIURdALIDGers2yl9nZsznkpJIJJIHgWoTDCFEfZE/hlQI0SW/LMkATgNoKYTwFkJYA3gawE6zFYQIiIuD6p5GCoZEIpGUgNn6MIQQmwD0BVBXCBEDYBYAKwAgopUARgB4VQihBpAF4Gli/5haCPEGgH3gKdhr8/s2zFVQID4eFi62gI0GRCTfuieRSCQGMJtgENGYUrYvBQ+7NbRtN4Dd5iiXQaysINRKh7cWulAhEolEIlGQoUEAFow8FgzplpJIJBLDSMEAAGtrCDULhRQMiUQiMYwUDACwsgLyNPmRQSp3LkZqaiqWL19ermMHDx4sYz9JJJIagxQMgF1SRBCayrcwShIMtVpd4rG7d++Gi4tLpZZHIpFIyosUDACwtgYACHXlC8aMGTNw/fp1BAYGYtq0aQgJCUGvXr0wdOhQtGvXDgAwfPhwdOzYEb6+vli1alXBsc2aNUNSUhIiIyPRtm1bTJw4Eb6+vhgwYACysrKK5bVr1y507doVQUFB6N+/f0Eww4yMDLzwwgvw9/dHQEAAtm3bBgDYu3cvOnTogPbt26Nfv36Vet4SieTBo7pDg1QpRqKbAxonILM1tDaAsLJFWUbVlhLdHPPmzUN4eDjC8jMOCQnBuXPnEB4eDm9vbwDA2rVr4ebmhqysLHTu3BlPPfUU3N3dC6UTERGBTZs2YfXq1Rg1ahS2bduG8ePHF9qnZ8+eOHHiBIQQWLNmDebPn48vv/wSn376KZydnXHp0iUAQEpKChITEzFx4kSEhobC29sbd+6UJ+yXRCKpTdQqwTCKohBU8MesdOnSpUAsAGDx4sXYvn07ACA6OhoRERHFBMPb2xuBgYEAgI4dOyIyMrJYujExMRg9ejTi4uKQm5tbkMfBgwexefPmgv1cXV2xa9cu9O7du2AfNze3Sj1HiUTy4FGrBMOoJaAFcO4qctwBeHnBxsbLrOWwt7cv+D8kJAQHDx7E8ePHYWdnh759+xoMc25jo3uxk0qlMuiSevPNNzF16lQMHToUISEhCA4ONkv5JRJJ7UT2YQCAhQVgaWmWTm9HR0ekp6cb3Z6WlgZXV1fY2dnhypUrOHHiRLnzSktLQ8OGDQEA69atK1j/6KOPFnpNbEpKCrp164bQ0FDcvHkTAKRLSiKRlIoUDAUrK1ioBSp7WK27uzt69OgBPz8/TJs2rdj2gQMHQq1Wo23btpgxYwa6detW7ryCg4MxcuRIdOzYEXXr1i1Y/+GHHyIlJQV+fn5o3749Dh06hHr16mHVqlX4z3/+g/bt2xe82EkikUiMYdbw5lVNRcKbIyICmpy7yG3uijp1fMxUwvsTGd5cInlwuS/Cm9c4rKzMMqxWIpFIHhSkYChYWUGoCZCCIZFIJAaRgqFgbQ0BAHklz76WSCSS2ooUDAUrK/7MkxaGRCKRGEIKhkK+YChRayUSiURSGCkYCko8qTwtHqSRYxKJRFJZSMFQsLQEgQMQVvZcjLLi4OBQrflLJBKJIaRgKAgBWKnyh9ZWr2BIJBJJTUQKhh5kZQmLSp6LMWPGjEJhOYKDg7Fw4UJkZGSgX79+6NChA/z9/bFjx45S0zIWBt1QmHJjIc0lEomkvJgt+KAQYi2AIQASiMjPwPZxAKYDEADSAbxKRBfyt0Xmr9MAUJs6C7E0puydgrB4Q/HN88nKBGk1wEk7CKEyKc3A+oFYNNB4fPPRo0djypQpeP311wEAW7Zswb59+2Bra4vt27fDyckJSUlJ6NatG4YOHQpRQmx1Q2HQtVqtwTDlhkKaSyQSSUUwZ7TaHwAsBbDeyPabAPoQUYoQYhCAVQC66m1/mIiSzFi+4ggBQZUb4DwoKAgJCQm4desWEhMT4erqisaNGyMvLw8ffPABQkNDYWFhgdjYWNy+fRv169c3mpahMOiJiYkGw5QbCmkukUgkFcFsgkFEoUKIZiVs/1Pv6wkAjcxVFoWSLAEA0Mb+C4u4BOT5+8DKpvLeDzFy5Ehs3boV8fHxBUH+NmzYgMTERJw9exZWVlZo1qyZwbDmCqaGQZdIJBJzUVP6MF4CsEfvOwHYL4Q4K4SYVGWlyB9ai7zcSk129OjR2Lx5M7Zu3YqRI0cC4FDkHh4esLKywqFDhxAVFVViGsbCoBsLU24opLlEIpFUhGoXDCHEw2DBmK63uicRdQAwCMDrQojeJRw/SQhxRghxJjExsWKFsTKPYPj6+iI9PR0NGzZEgwYNAADjxo3DmTNn4O/vj/Xr16NNmzYlpmEsDLqxMOWGQppLHjAyMgATBktIJJWFWcOb57ukfjXU6Z2/PQDAdgCDiOgfI/sEA8ggooWl5Veh8OYAKPMexN+XkdfEFVYezU06pjYgw5vXUL79FnjlFeDff4HGjau7NJL7lPsivLkQogmAXwA8oy8WQgh7IYSj8j+AAQDCq6RM1vmvQZUBCCX3A7dv82d8fPWWQ1JrMOew2k0A+gKoK4SIATALgBUAENFKAB8DcAewPH8oqTJ81hPA9vx1lgA2EtFec5WzECoVSABCCobkfiA5mT8r6oqVSEzEnKOkxpSyfQKACQbW3wDQvpLLUuL8hgKEAFkKGbFWDxlXqwaTlD/qXAqGpIqo9k5vc2Nra4vk5GSTKz6yEhB5MjQIwGKRnJwMW1vb6i6KxBCKhZGQUL3lkNQazDlxr0bQqFEjxMTEwNQRVNqEJIg8ghCXzVyy+wNbW1s0amT2KTLVDxGwZQswbBhwvwikdElJqpgHXjCsrKwKZkGbQtLnQ+C6NRKqe2oOSCipHfz9N/D008CGDcDYsdVdGtOQLilJFfPAu6TKisbTBaosLZCeXt1FkVQlcXH8eT+NOJIWhqSKkYJRBG39/JAgsbHVWxBJ1aL0AyRVbfiycpObq2vUSMGQVBFSMIpAXh78KQWjdqHMabhfBCM/BAwA2ektqTKkYBSBGnC0WIr9t5pLIqlS7jcLQylnw4bSwpBUGVIwiiC8GgIAtLE3q7kkkirlfhMMpf+ibVvg3j0gK6t6yyOpFUjBKIKFUz2o7QGKKTl6rOQBQxGM+6W1rgiGErTyfim35L5GCkYRLC2dkFMXwK1b1V0USVVyv1kYSjmVoJCyH0NSBUjBKIJK5Yxcd0Dcuo+GV0oqjlLh3rkDaO6D0DDSwpBUA1IwimBp6YQcd0DEyxZbrYGIR0nZ2ABaLZCaWt0lKp3kZKBOHaBJE/5eHYJx+jSQmVn1+UqqDSkYRVCpnJBbF7CIv8OVh+TBR+k0vp9a68nJQN26QL16/L2qyxwVBXTtCnz3XdXmK6lWpGAUwdLSCVkNAJGn4RfTSB58FHeUry9/3g/9GElJgLs74OTErxau6j6M/fvZMpPPSK1CCkYRVConZDbN/3LlSrWWRVJFKJVtu3b8eT8IRnIyC4YQbGVUtYWxfz9/3k+hVCQVRgpGESwsbJDZND8m42UZsbZWcD8LBlD1gqHRAL//zv9LwahVSMEoghAC5O4MjYutFIzagiIYyhDV+0EwkpK4DwOoesE4exZISeFBAlIwahVSMAxgaemEHB9HKRi1BSWOVLNmgJ1dze/01mi4wlYsDA+Pqu3DOHCAP4cMkYJRy5CCYQCVygnZ3nZSMGoLCQnceWxry631mm5hpKZyh3N1uaT27weCgoCAAL5WeXlVl7ekWpGCYQBLS2dkNbNkP3FNb21KKk5CArfSAXbz1HTBUCbt6bukMjKA7Gzz552RARw/Djz6KFCfA3XKWea1BykYBrC0dMK9/PlQ0sqoBdxvgqGUT9/CAKqmcXP4MFsUAwboBEO6pWoNZhUMIcRaIUSCECLcyHYhhFgshLgmhLgohOigt+05IURE/vKcOctZFJXKCRmN881sKRgPPkUFo6ZblYqFod+HAVRNuffvZ9ddjx5SMGoh5rYwfgAwsITtgwC0zF8mAVgBAEIINwCzAHQF0AXALCGEq1lLqoelpROy6mZyB6gUjAcffcG4H/owDLmkgKpxDR04APTpw6JRGYKh1QLLlslXIt8nWJozcSIKFUI0K2GXYQDWExEBOCGEcBFCNADQF8ABIroDAEKIA2Dh2WTO8iqoVE5Qa9OBNr5SMB50NBoWCH0LIz0dyMnhYaM1ETO5pIj41FNSgLQ01gR3d8DFBVCpAMTE8PPw0kt8gKcnf+YLRm4ucPeubj6hSZw6BbzxBh/w2msml1Wt5mgulpa8qFSARRmav1lZXOy4OB7v0Lo1YGVVfL/sbD7lu3e5iMri6Aj4+5ecZ04OX8vUVF7S0viStWnD17Y8EOl+n3v3dAsR0K9f+dIsC2YVDBNoCCBa73tM/jpj64shhJgEtk7QRAnEVkGsrNxAlANt6xawOHq8UtKsbZw/z/WLUnEIwbHyWrYEGjUqXKEQ8YMbFsYPwoABurrQVHJy+MG+cAG4eJHTs7bmOt/GhiuDu3e5rlUWIqCZlxre2qXwvhQA758Br1RfNIA36sfcgV3zBsjN5fROneJYe3/9xeX39eV5fu3acUObiBeAXfwxMRxuSVm0WqBBA93i6spluHWLyxoXx/W9fvmUGIhKJWVhwdfQiSbAGQPhNNARbm6AT8MmaIE30SLUAc278L7JybolJYX7qvWXu3d1lVhamq5SMxao18UFaOpYB49hHoa4D0d3NWBpYwOtixuOnrXHxleAn3/mYL/u7nxdfH2BVq24Qrt1S7ekp+t+F+uUZrDGQWTObob05bwtPZ3P1dOTr62nJ+DmxgZUdDQvcXHFQ72pVFz5u7jw4urKYpKTo1syM1ko0tIKH2ttzWUOCOB4jv/8w797RITxa9KwIfDUU8CIEcBDD7GIHT0K7N0L7NsHXLpk+DgLC8DHh69Pw4Z83fV/K2tr3Tm4uPDvGRvL91RsrOGxDR4eutHh5kSQcpebKwO2MH4lIj8D234FMI+IjuZ//x3AdLCFYUtEc/LXfwQgi4gWlpRXp06d6MyZMxUuc3Lyb7h0aQi6HpyIOnNX8x3s4FDhdGs6SUnAzp38YNrb82Jnx5Xt7du6ii0+HvD2BkaNYle20srSaoHdu4EvvuAHxxj29tzKatWKK8mwsMJeIJWKvR5PPQUMH84VrEbDD2ReHj9Yly4VXq5c0T3Ytrb8IObl6SqK3FzA2ZkNCGXRaoHIy1m4+Xcm7qC4Qjk68nE5OfzdwwPw8+NKr6SKpChubnxOxgwApXL09ORyubvzp1JZKGKk1XLLOG3PMdyNSsXdXo8jMRG4fp2QkVF6k97Ghm9je3tdxersrFtcXXWLiwvndeeObvlrSzhCb7eGGlZwdQV69wbO/haHGHUD2Nnxb9WhA3D1KvD33yyuiui5uQFeXvy76F/XnL+vIzc6HnaOlnDs3xVOTrxdreZ77vZtvt/u3OHr37ixbnFy0t0XarXOwklN5Yo3JYWvmX7DwdaWr7Mi3PXr834XLxZubHh7s3j4+/NSt27hRsGtW8D27cCePXweHh4sxJmZ/Lz06sXXx8NDV/E7OfFxf/2luz7x8Xy93d15cXXl81DEPDWVz61hQ26oNGrE/zs7655R5ffs0MH4b18SQoizRNTJlH2r28KIBdBY73uj/HWxYNHQXx9SVYWyt28PAMhsSqgD8BPQsWNVZV+lJCTwjb91K3DoUMmVoIUFPwCenhwZYulSvnlHjuTKf9kyfgiaNAG++YbFRHnIiPiB+ucftgSuXOHRme7uwLBhQPv2vNjYsGht2wa8/jovJdG0KT/Qw4fzAx4QwFaMSmXiBfjjONCvH9J2hSKycS/E7buI+OlfIf6lDxFn3wI2NkCXLrw0bqyzjHJzWTT++ovFTrECAG7Venlx2Zo21bU18vIKV4D16nGlVa9eGcoLANFfAVZXgQOPAwCIBBIbBOBap6dxffQHEEJXAdWty5WQg4Nhl4vJaLXApoeRNvo/ODDiW/z2G98vgc6RmF/3Www9Gwx7+8KHELG4OziU4IIZ+jYQvQvIsQZ+yqhgIcvPuHG6//PyTCvGs89yW3L3br5nXV2BgQOBvn1Lbl+OHFnh4lYb1S0YOwG8IYTYDO7gTiOiOCHEPgCf6XV0DwDwflUVysamISwt3XG3YQq3Oy9frvGCERfHbpOrV7kyvnqVXSEODty6c3XlT7WaKyxlUVqALVsC06ezed2mTWH/aF4eC4WHR37F9u23SPdqjV3pffHTT8Dy5VyB+vsDP/4IjB5t/IF75JHSz6VrV2DuXG6F/forC42VFS+Wlty68vXl1r6TUwUvXH5HsbOPO9q3A9pbWQLT1wGPDgJGtzB6mLU1l0EJcGsKVla6VmKFUCLV5iME4FHfAh4WJ/DQMxVM2xgXLgBJSXB+vCdGjOD7BAAwdgn76uyDix0ihK5f3ihXrrCaKJ0FAQGVXfIyUxbNcnTk+330aPOVpyZhVsEQQmwCWwp1hRAx4JFPVgBARCsB7AYwGMA1AJkAXsjfdkcI8SmA0/lJfaJ0gFcFQgg4OATijtVNeFtaGu741mi4ti2rs70SSUzklvhPP/HweMVc9vTkTrz+/XVuhdu3uQJWqbhV6+fH2xs1AgYP5u/6/Qp16pTwsH/wARz79MHYX/pi7Fg2na9f58m/Jnd2moDSR2BWlJFF+p3eQM0eKZWczCadPuae7a2EA+nfv/D6+vXLP0oqJ4dvnP/8h03c8+drhGBIjGPuUVJjStlOAAw6HYhoLYC15iiXKTg4tMetu8tBzZtDGBKMGTPYJ7N/Pzssq4i0NHYhbd4MHDzIutWmDfDxx2wOt2nD/lKzkZ7OCqT3znNn5/L7T6ud27dZRd3c+LvyWdMFo6ia16sH3LxpvjzDwti/1qBB4fX16+t60svaz3ftGru6hg5lv87588BzVTrlSlJGqtslVWNxcAiEVpsNTctGsCwqGFlZwJo1bEYPGQKEhrID3kxkZgK//QZs2sTPVU4Od8q99x6bwgEBlduyL5GoKP7UE4z7moQErmyVnntLS90QppoIUTGXFADzByC8epXN1qIoczFu3y67YCjPlZ8f38Tnz1esjBKzI0ODGMHBgQUgx8eeW0L6Ada2bWN31A8/sBP9scfYtK5E7t5lgRgxguuzUaO4k/iVV4ATJzi7zz5jnaoysQCAyEj+NDSu8X5Ef9KeQnW8kMhU0tO5I6qoYNSrp5s/UtkQ8WiFkgSjPG4p5QVlrVqxP/P8+QfjnnqAkYJhBDu7NhDCGhmN88ftXbum27h6NdC8OfDMM+ySUqt58kBcXIXyTEsD1q0DHn+cn/+xY4Fjx9hK//13Hoe9aBF3ClepSOijWBhqdc2tVMuCIcGoyfGkis7yVjBnPKlbt9jlVNmCcfkyu7ns7dmnmZ4O3LhRsbJKzIoUDCNYWFjD3t4XaV75FYdiPl+9yi6oCRPYjdG2LfuJbt/mToToaOOJGiAzky2J4cO53nr+eSA8nCe/Hj3KE3WWL+fRRWUaemkuFAsDeDDcUverYBiyMADzCMbVq/xpDgujTRv+PyiIP6VbqkYjBaMEHBzaI7lefotHEYw1a9jP/fzzuh27dAH+9z9+AJo25Tn6339ffDppEY4f56GoY8fyyMTXXgOOH9Mi8p0l+PLjtEJAgLqCAAAgAElEQVST4moMioUBSMGoDoqGBVFQzsEc/RiKYCiVuz7u7tySKatgaLX8vChvOfTz4+fqQRIMtbrk7cuX8/mXtl8NwqTqSAjxlhDCKT+67HdCiHNCiAHmLlx14+AQiByrRFAjL765c3PZZ/TEE7qWlUL//iwqwcFsZbz4Io9vfb/49JG8POCjj4CePfm52bOHD/n6a6Cb9k+ItybzWNmaSGSk7iG/3wUjM5NdLcb6MMwcBaFcVIdL6upVdhs1NBCdR6Xi61dWwYiJ4euviJCNDY+hflAEY84cvl4xMYa3p6fz0MYrV3gE2n2Cqe3XF4noLngCnSuAZwDMM1upagjKjG91y/osBjt28AM5caLhA3x8+Ca4ehU4eRJ4+GGOk3HvXsEuly8D3bvz/fTsszwfauBAPUvi1Cn+1O8zqUlERek6Ue53wVBa40oQPYW6dblxkJFR9WUqjepySbVqZbzjrDxzMRSLXWl8AOyWOneuZgp1Wfj9d64HEhKAmTMN77Nsme63LCmOTg3DVMFQ7pTBAH4kor/01j2wKCOlsrzrcEtg1SqOezGgFONKCHZTvfYa3/xhYUhN5ZnUQUHcSN+2jb1WxWYqnzzJnzVRMDIz+SFo0YJblQ+KYBhySQE10y2lxCEpOtnGxYVdOuYSDEP9Fwr165d9wIcyQkrfzRUUxL9JBQePFKBWmx7wq7K4fRsYP56v1xtvAOvXswjqk54OLFzIM2abNau4YKSmVtlrck0VjLNCiP1gwdgnhHAE8MCPf7OycoWNTVNkNM5hK+HgQXY1mdr73KEDcmCNr7/UonlzYMECnjdx6RJPbjVITbYw/v2XP5s142BJsbHVWpwKU1WCsXYtsHFj5aSVnKyLZqiPEOYZDpydzS2c0gSjPBaGq6vOMgJ0sz8r6pa6ehWYOpV/19ICN61Ywf2PlYFWy0MaU1LYpTxnDt9L77xT2GpSrItZs9gvffRoxayq2bO577QKRMNUwXgJwAwAnYkoExze4wWzlaoG4eDQHmkN8h9CIVgwTIAI2HLUC20sIjB1ey907szPwbp1xSfLFpCQwA+nnZ1uFmxNQhkh1bQpC4a0MEqHCPjwQ44MUBmuluRk4+Fo6tWr/E7va9e43KUJxu3byMi+i8jUSNPSVTq89d1cyuTX8ggGEZvtjzzCVsvSpfygbd9ufI5UbCwweTLw6qvsgqwoCxdyXPNFi3giorMz92mGhAC7dvE+6encchw8mL0QPXuyVVLeBiIRn2PHjlUSuNFUwegO4CoRpQohxgP4EEDJQ4AeEBwcAnHHM79lPXAghywthfPnOTz36KcFnO3zsL/ZJOzda8JkcMW6GDaMZ5NXlmleWSgjpBQLI18wiAhJmTXQfVMaygsE9Fu5+t9LaK0TEa7duYbN4Zux4vQKbLq0CXsi9uB49PHClWZMDP+O0dE6N0xFKE0wipQ5IjkC/734X5yOPY3MvEyTsjgRcwL91vfDqrOrSh5Sq1C/PqBWY8K25+DzjQ8m7JyA+AzDFkfCvQTcSr/FFkbRUVdOTuzuNEEwNFoNCr2aYccOnuV68ybw+ed8vQ8cYEts5UrDiaxcqYvGuWVLsc1JmUk4HHkYK8+sxIrTK7Dt7204EnUEV5KuID2nyBsCT5zg/ooRI4CXX9atnzSJr920aWwBLF3KoXVmzeLtSliho0cRlRqFSbsmYU7oHMSlF3/2b6XfwnsH3oP7fHcErAjAu/vfxb79y5F5K4rH5VcBpoYGWQGgvRCiPYB3AKwBsB5AH3MVrKbg4BCIPBdC9kevwnbEKyXum5jIjcnVq/mZ/vZb4KXIH6CavxbI+oYj+pXEyZN8g48axZMzrl0zPDKluoiMZD95gwYsGAkJQF4eVoStxhu738DsvrMxs/dMWAjT2iFEBFHGGYjJmcmITI1EUIMgg/mERoXivQPvIfpuND7o+QEmdZwEK5WRlpf+iz/0ybcwlt36H/773Qo42zjDxdYFLrYusFHZIDwxHGdvnUVajvE208xeM/Hpw59CnDihW7l3L9C2LeLS4/Dd+e9gZWEFF1sXONty+vZW9rBWWRcsedo8hCeE40L8BYTdDkN4Qjgm1iV8YtvZcKb16gFnzkCj1WB3xG4sO70M+67vK9gsINDCrQUCPAPwqM+jGOk7Em513Aq23825i5m/z8Sy08tgrbLGHzf/QLxFP3wEQBQNdqhP/fq44Qr8fG0nghoEYf2F9djy1xbM7DUTb3V7C1l5Wfjl8i/Y/Ndm/HHzDzhbO+FMXip89Du8FYKCAEPvtCEChMDdnLtYeWYlvjr+FaxUVlg6aCmGtRnGbp4mTTjmvKVetfbkk+wS/OSTws9fdjY/oE88AUREQLvoa5x7uDX2XNuLQ5GHEJ4QjsRM4w0Ga5U13uj8Bmb2ngk3Kyfut2jUiB9+/XvayootiqFDcXfBHNh/tQQqxboAgDZtQG6uWBW2Bu/GT0aeJg85mhzMPjwbw1oPwytW3dH4TAQWdtVg/cX1UGvVGN5mOFKzU7Hk1BJ8qcmF9XSgD37Ebu1zsLQwb7QnU1NXExEJIYYBWEpE3wkhXjJnwWoKSsf3nVeC4OVlPJLmvn3AmDFscU6ZwoMkXFwA/BLEHW+XLuluEmOcOsXj0RVT5No1NlWKkKfJQ8K9BHg5epVY4WbkZsDBumIvforPiMf/rvwPLwW9BKuoKLawVCoWDCLkxcVg3tF5cLB2wMchH+NM3BmsH74ezrbOBWlk5WVh3YV12Hl1J5KzknEn6w5SslKQlpOG7o26453u72BIqyFQWRjvG7qXew9fn/ga84/NR3puOnxcffBi4It4PvB5NHRqiKtJVzH94HTsuLoDDR0bwsfVB2/seQNLTy/FgkcX4PGWjxe/VgkJxUdIAYCTEzLqqDAzezdcMxpAS1rcTL2J1OxUZOZlok3dNhjjNwadvDqhk1cneNh7IC0nDanZqUjNTsWWv7Zg7pG5iM+Ix8oTjrBU3ui0bx9CngzC01ufxu17pr8ezUZlA18PX3jYe2BBi0t4/ZY9DJQaqFcP33nE4tPFzRGVFgUvRy/M7jsbQ1sPxc2Um7h4+yIuJVzCubhz2HZ5G97c8yYGtRyEcf7jYGlhicl7JuNW+i282eVNBPcNxtv73sasC+uQPMIeX9vbGXdH1K+Pr7sBKmGBX8f8iozcDLx74F3M+H0GFp1chOTMZORp89DCrQWmPTQNq04ux39GA3+2aga7omkFBSHk9M84uv9DNPVsDR9XH3jv/hPWn8zFkrnDsDhhJ1KzU/Goz6O4fe82hv80HMMb9ceSUwfR6L05gKUlNFoNTsWewu6I3Yjplw7k3QGWDwBatICAgJ2VHeyv3oB9u0TYPdUA4fGJ2JN0AglrukBAoEODDhjaeih86/miXb12aFevHaxUVki4l1CwHLhxAF+f+Brfh32PD52fwOuR12Hz8y8FgxFyNbm4duca/oz+E39qj+HP9+rgat4nqPsiMKSVwNDL2zGg+QAkZyVjwvMqHHD6E/0a9sOaoWuQp8nDqrOr8H3Y99iWtQ2wBmwv2GBChwl456F34OPqAwDIzMvEkcG+ONBEjYQOTcwuFoCJb9wTQhwGsBfAiwB6AUgAcIGI/M1bvLJRWW/c04dIi6NHXeHpOR6tWi0zsJ1dlzNmcF2/eXPhkYKIimIXzvLl7Cs1hlbLZsmoUdxasrPjzrLPP0dEcgR+CPsBl5Mu43LSZVy7cw1qrRq9mvTCnEfmoHfT3oWSOhFzAh8d+ggHbxzEiHYj8M3Ab+Dl6FXmc7+dcRt91/XFlaQrWDJoCd6YspHfXfDHHxwNccgQbPhlNsZfnIWdT+9EZGokpu6fCm8Xb2wfvR0NHBtg+enlWHxyMRIzE9Gmbhs0dW4K1zqucLV1RR3LOth2eRui0qLQwq0F3u72Np4PfB52VrpqJE+Th7Xn1yL4cDDiM+IxvM1wDG4xGBvDNyIkMgQWwgLdGnXDyZiTqGNVB+/3fB9Tuk1BHcs62PXPLkw7MA3/JP+Dvs36wreeL7LV2cjR5CBbnY1Ov4Vh+tW6PIOyCN8+4oxX+tzFsReP4aHGD5XpuhERZoXMwqehn+KJBFdsvtQatkGdMe/SCnzUV4uWbi2xddRWNHdtXiAyihjlanKRo8lBriYXAgLt6rVD67qtYWlhiYjkCLRZ3ArT8jpj3meniuV75tNX0Vm7Et28uuKdHu9iWOthBq0rIkJYfBg2XNqAjZc2Ii6D3R/+Hv5Y/cRqdG3UFQCgJS2mPd8QX/nEY5z/OHw/7HuD6SVfOokmm7thtHtvrJ16uGD9wRsHsejEIrSt2xZP+z2NDg06QAiBPcvexuOJizDeZzjWPfNLISH/dv1kvHZ9CbRG1Gl46+H4oNcH6NywM/I0efj6xNcIPjATqlw1pnZ/G5GaZOyO2I2kzCSohIobVXFxPG69fn1oSYvMvEzcy0hBjorrPjdbNwwMS8cghyA8tuhX1LOvZzjzIly8fRHvHXgP+67vg3e6Jdp3ehwx6bGITosu1CCoa1cXDzn6ovOmw7gS4IXfGmUiNTsVNiobruTz8rDw11y8vCsOQm9+V/al8/hlXAfEOgLPtRsDj9VFBk5cv84uvK++At5+26QyG6Isb9wDEZW6AKgPYCqAXvnfmwB41pRjq3Lp2LEjmYNz53rS2bM9iq2/d49o7Fh+n9zIkUQZGQYO1mqJ3NyIJkwoOZOrVzmhNWv4e6tWRCNGkFqjpjZL25BqtopaL2lNwzYNoxkHZtCcw3OowcIGhGDQo+sfpRPRJ+jcrXM0ZOMQQjCo3vx6NGHHBLKdY0uOnznS4hOLSa1RExFRrjqXfvvnN3rml2fIb7kfrT23lrRabaHiJGQkULtl7churh35L/cn9y/cKbVpfaLnn1cuCmkBCpjXjNoubUsarYaIiEIjQ8lzgSfZz7Unu7l2hGDQ4A2DKeRmSLE8iIjyNHn0U/hP1GV1F0IwSAQLsvnUhhw/c6S68+uSyzwXQjCox3c96Ni/xwodG5EcQR8c/IB8l/nSq7++SvHp8cXSz1Xn0uITi6nRV43I7Qs38vrSi3y+8aHGXzUmBIPOjO5t4CfTkt/bNhT0nrPBMpvK8uOLScwCPfSRFw3+ujMhGPT0kj50N/tu+RLMzKTRI0COwTZ0J/NOsTL3nNuCPN4Fpd24bHKSao2aDl4/SD9e+JFy1bmFN2q1pHV2os/f6UoIBg3ZOKT4PkQ0Z/+HhGBQ+BfvmJbpu+/S7EdUhGDQkpNLCsr/4e+czuCxoKTg6XRl5CO0uwVo2bt9KHjhELrkAaJduwqnlZVFN7xdaOA7noRgkNsXbjT+l/G06dIm3TVavJifrTNn+PuRI0QA5a1cTqlZqfxcTJtGpFIR/fuvydeOiIjOnKF9zUHdP21Gvst8aeB/B9KEHRMo+FAwrQtbR1eTruruof37iWJjKVedS3/c+IPe2vMWPfPLM3Tj4FYu37Ztxa4TWVoSDR9OVKcO0Z3CvzktWMDH3bxZtjIXAcAZMrGONbkyBuAJYEj+4mHqcVW5mEsw/vnnDQoNdSBtfqVIRBQdTdShA5EQRHPnsi4YpX9/3rkk1q/nn+PSJf4+eDBRYCBtCd9CCAb9FP5TsUPu5d6jhccWUt35dQnBIASDXOa50Gehn1F6TjoREV1LvkYDfhxACAZ1/LYjTdw5kdy+cCvY13+5PyEY9NiPj1FUahQRESXdS6KAFQFUZ04d+uPGH3Qm9gwhGDSjP4iCgznz+Hja15zzXHtubaFyxaTF0KD/DqJntz9LF+Mvlnze+Wi1WjoS/CJ93Bc0/fN+NGXPFHrt19do0s5JtOPKjgpV3IZIy04j9+mCBsxoWGzb4cjDhGDQd6NaVCyT06dpa1uQ9WxLsv7UmpZ1tyTt21PKn150NF3w5Gv+ScgnhTb9/NfPhGDQtx1BdP58xcqtEB/P9+Q339DyU8sJwaBXf3210G+RlZdFngs8adAzFkTvmCgYQ4aQxt+PhmwcQpafWFLIzRB64X8vEIJBL+14ifIaNuB8LSyIlrCgUG4ukY8PUVBQ4Yftxx+JANIePEiRKZEFjaJCpKYS2dkRvfQSfx85ksjVtXALLzKS85s+vWzX6JlniBwcOI/ykpNDZGtL9PbbunW5uUQeHiwW58/z9fj668LH9ehBFBhY/nzzqXTBADAKQBSAdeDO7psARpiaSVUt5hKMW7fW0KFDoMzMa0RElJJC1LYtkaNj8QaPQaZPJ7KyIsrJoaR7SRSfHl/QIi/gjTf4xlPn3/CTJ5PGwZ4CVgRQm6VtDD8I+dzNvkvzj86nz0I/o5SslGLbtVotbb60meovrE/2c+1p3LZxtOvqLspR55BGq6GlJ5eS/Vx7cvjMgb458Q0FrQwim09t6MD1AwVpjP9hGNnOBP27eiGv0Gio37OgBrMcKDsv24SLYAJ9+rACA0QffFCKClcQjYa+fEgQgkGHbh4qtGnklpHk9qE1Zfq2qlgeS5YQAXQxbD/9lfAXNxzatSt/emFhRAA98WUncvvCraBRkJ2XTd6LvMl/gQ+pBbglWxkcPsy/xd69RET03v73CMGgxScWF+yy5uwaQjDo9+71icaNK3y8RkO0ciVXxvo0b040ciSlZKVQi8UtSATz7zDr0CwWo1Gj+OHas6fwcevWcXl++UW3rkcPtsZLu1cmTeJW+oULbElMm1Z8n6eeKi4kJREXx8/1G2+Ytn9J9OlD1KmT7vv//sfnunMnf+/Wjah1a915xsfzszJ7doWzNodgXNC3KgDUA/dhVLtI6C/mEoy0tNN06BAoIWEr5eYS9evHluIff5iYwE8/EQF0ZP8asv7UmhAMUs1WkdeXXtTx2470/sH3Sdu5E1HfvrpjFi+mHa25Nbk+bH2lnEfe+h8oe4PhtG6m3KT+6/sTgkHWn1rTnojCD2vkrxvI5kPQsysGEBHR2VtnCcGgeZMr6ZorrazJk4kmTuRbc+JEnYBWNomJlGkJajjbmbqt6VbQao5JiyHVbBVNmxZIVLduxfIYN47Iy0v3kC9cyOdVVreHwu+/EwF0fMcyQjBo4TEW7/lH5xOCQQdC1nL6//1vxcqtsGoV6bs8NFoNDds0jCxmW9CeiD2k0Wqo7dK2FLQyiLTdu/GDoc+BA3x8w4bsciUiysrilvzHHxMR0cX4i9R2aVtafXa17ri0NKLk5OLlyctjcfDzYzG6eJHT//LL0s9FaaU3acL5G3Lj5LuqaOXK0tMjIpo1i/dXzq0izJzJQpbOjQAaOpSofn0+ZyKdWP7+O3//9lv+fuFChbM2h2BcKvLdoui6mrCYSzDU6kwKCbGka9dm0IQJfNW+/74MCUREUIotqMmnbuTzjQ8tObmEPjj4Ab3wvxeo9/e9CcGguX0siN57r+AQ7W+/UeeJIO8vGlCeJq/iJ6HRsInr7s6VswG0Wi1turSJDkceLr5xzRp6rz/3MZyPO09jto4hx5kWlDLo4YqXjYjo+HEq8ONqtfwAAUT/+Q9XMpXNX38RAbRqxQRCMGjHlR1ERPTRHx+RCBZ046M3uGKpiGA1b87lV7h0ic9p9Wrjx5REfsODwsPpkXWPUIOFDejf1H/J6XMnenzD41zJGnJdlMbZs+wSLco777CIa3TWcHpOOrVf0Z6cPncqEKoNFzcQPfkkka9v4eNffJGt5nr1iDw9+fyVSn7jxnJcAOLjAL4Wr79OZGNDlJRk2rEPPcTHPvmk4e1aLbuO27Qhuny5ZKslO5ufp8cfL/s5GGLvXi7bwYNsuahUheoDysrivtARI/j7oEHsoqsEK9wcgrEAwD4Az+cvewB8YWomVbWYSzCIiM6e7U6TJy8p8JaUBa1GQ6PGWJHlLAs6GXOy8DatlsZ8O4DELNCv3+sS3nd4LSEYtGrx85VR/AJ3hsHONVP46CNKqSPI/Qt36vhtR1LNVtE7r7Xg1l5loHTgxet1XC9axOuUfpOK8PvvhTsNDx0iAijv4H5qubgl+S33o8zcTPJY4EFPbHxC11GamFi+/BIS+Pj583XrtFpubSsPfVlZvpzTjIuj32/8TggGeS/yJstPLOly4mWu2FUq02/QzEx2zVhYcLqhoYW3DxlC5O9f7LCo1CjyXMCdzI2/aswd4a++yo0RhexsImdnomef5crXy4srvBkzOK/y9rOo1SxMrVoROTlxH4KpbN5s+Dz1+fln3XPi6soV8yefEJ0+Xbhy/uEH3qey3H9pafw7BAfrnoXLRQYvKJ3gV64QWVub3mdUCubq9H4KwFf5y5MmHjMQwFUA1wDMMLD9awBh+cs/AFL1tmn0tu00JT9zCsayZRsIIBo1Kle/wWUSa89x5f/5040Mbr/3zULqMAnkNNeRH3wi6vVdT2r0Nih7Zhk74Ywxfz7/3G5uXBGUlWeeIWrcmL458Q0hGGT5iSVFv/kcp1cZDB9O1MJAJ3PfvtxhVBHOnuVz9/EhCg/ndUpr/dIl2nxpMyEYNHTTUEIwaN+1fbqWbNGH1lR27TJcOb34IlekeeWwGj/9lNPMySGtVktdV/PopTd3v6nbx9eX+0lKS//wYaKWLTm9F1/k1nJRl1LLlkbF7UT0CXL63IlWns5338yeXVA2ItL54JV+iGvXiJo25XVC8BDD8qJfqf/5p+nHabWmjSi6coVHK06YwNdT6Vdr146fo9hY7nxv165y+9kCA/k3aNuWraGiRERwOYKC+PPIkUrJ1iyCUdYFgArAdQA+AKzz+0HalbD/mwDW6n3PKGue5hKMyEgtWT08lxr3W0DR0XtKP0CPq0lXyX6uPT38YWNS21rz6IeijBtHUS09qN78etRqSSvacWUHdy4Orks0enTlnMSjj/LNP306t0Lj4sp2fO/eRL16UY46h/yW+9HLu17m4WEAt1SLsnGj6a1IrZb7C5Qhu/rkdxzT33+Xrbz6vP8+n3P9+uwi2b5dl+7t26TRaihwZSAhGNRqSSsekLB/f8Ueyg8/5DyLVoyKUB07Zvi4knjrLW5V5xNyM4R6fNeDEu/pWUG//MLpL11qOA2tlkfjAETe3uwCIeJ+AP3zzcnh8s+cabQ4OWo916biU4+O5u+jR/Nvqn+/R0Vxo6B167KcdXE0GnYdFR0xZS6Sk/n8FJeWIiDfflu5+bz5ps7aU4bXF2XAAN7u4VFp/XuVJhgA0gHcNbCkA7hbyrHdAezT+/4+gPdL2P9PAI/qfa8xgtH9hV8Khq0++l2LguGnClqtlg7dPESTdk6it/e+TavOrKIjUUcoLj2OOn7bkdy+cKOYdfkV1EUDw0xbtiQaPpxCI0PJ8hNLUs1WkccCD8oc1J+oMs4pK4t90VOmcIsZYLPXEN9/X3x0ChF3Fo4fT0Q8dl+r1fK+ANH168Xzs7LSdU6WxpUrZNS3HxPD2+bMKT0dQ2i17L7o35/T6tKF02vdulAfxZ6IPYVHAJ07x/tt316+fI0NpU5OLtTpW8A//+gqW2OMH8+VfElotUQPP8yWn6GO46++4vN65ZXCo4Hu3eNKqH9//q7cJ4b6NgyxYwfvf/o0d9zWqcNuqqKkpfHvUFHu3DF8fubm6lUW0ZEjK2YlGUJpTNjZEd01Mldn+3YqGBBSSdQUC2MEgDV6358BhxUxtG9TAHEAVHrr1ADOADgBYLgpeZpDMPYdyCO83obqBremyT81I5tPBNnNtaP5R+fTrbu3aMGxBdRqSStCMMjhMweynWNbIC7Ksv3ydt0DWLS3XOmo/OwzIiJacXoFIRi04NgC7tRzdq54K0oZrfLbb/y9Wze2Noqme+wYt56aNi1c0eflcWvzww+LXJx9hlvhymgTpXOyNL77jkp0/3Trxq1JQ9y9S9S1K9GvvxrernQ0r1jB37OyiJ57TtdK0+NUzCnd8OXoaN5n1arSy18UtZqHhRqqMJXz6dKF6NYtrsAVF4MQ7JJYv97w0M5BgwoPvTTGhQssSpMnF15//Dj7wIcNM3xPKaO4jhzRuZROniy+nyFOnuT9d+0i2rCBSu0rkBQnNpavmyFLWyEvj/suKmJxF+F+FIzpAJYUWdcw/9MHQCSA5kaOnZQvLGeaNGlSaReRiK3pBo/zOPNNYdvoxo1ZtGmPoCEbBhUShB7f9aD1YespMzeTNFoN3bhzg3775zf68s8v6fvz33NiGg27Q958s3AmyugIZbgcEf2V8Be34L/+mkzueL182fgQu2nTuMWvVEKK++DUKd0+WVnc6rax4W35Y++JiP2+hiwApTIuKgpffEEFLo927Uo3nV94gTtMjQmj0glY1JIh0lVyHTsaPj44mCtifRecVssCki/SBsnMLCTkZSI8nI9dt87wdmU4puJ+6NSJf+vgYL5mAN8r48axZbV+PVFICFFAANFjj5lWhpdfZpFXKpakJKLGjTn9ojOGFTIydFaG8huaOiEtKkp3jwwZQtSokWnWpaQwP//MDYkqpKYIhskuKQDnATxUQlo/wISJgpVtYXzxVSZhakNqNb8rabVaSkkJoUOHQImJO2jnlZ308R8fU/jtcNMT7NmTJxrp8+67XKGlpRXfX+k4PX685HQ1GvYNe3oa7k8IDCw8xyM1lV1Ur72mW6eMXtm1i33PTz2l2xYSwtsO6CbyEZHxYZzDhrGbTTGxN20qufwtW/K4c2PcuMHpLFxYeH12No++cXDg7UePFj/W35+ve3mwtyeaOrXsx61Zw+UxNj4/IoL94TNnFreqNBrukFY6ohVLTVmefda0MiQkcH/HoEGc5uDBPLLm9OmSj1ME2M+P7ydTyc7m495+mxsn775r+rGSaqWmCIYlgBsAvPU6vX0N7Ncm34IQeutcAdjk/18XQERJHebKUpmCER9PZPMIjzP/48YhIiLSaLLp8GFbiogoZ3iHyZPZP6lWc8tv0CD+CRS/cVEUN9aPP5ac7s6dugqlaGfn7du8fu7cwuvHjuVhg1lZXImoVG/TbxMAACAASURBVFxJEbHJa2mpG+KqDCH855/CaWi1bJHoz5rVannc/XPPcUXl68vj2o1ZGUr59IefGiIoiKh798LrlIp5+3YiFxf2K+vzzz+GBc1UmjY1vYLWZ8IEvraV0SGbmcnCc/Ag/w5liRukVP7DhvHnsmWlH5ORwb8fwAMdyoKrKy8Aj0yT3BfUCMHgcmBw/nDZ6wBm5q/7BMBQvX2CAcwrctxDAC7li8wlAC+Zkl9lCsbYF1MI012p17cDC60/f/4ROnWqffkSVWZrjh7NFbSzM49OMTKRjrKz2fqYNavkdB95hF0A3buz20E/PWV4qL77iUg3CujHH7kV7uXFMU+IdEL1xRf8XRkymW0gBIiPT+GQEEolrfj+t2zh7xs2GC67MqqntOGRc+bwfkqHqVrNndkdOnDFrASPi9IbkPD553xMVJThNEujUydumZcVPz9uDFQ3OTm6obOjR5suYIoLcNKksuXXti0fZ0qoDkmNocYIRlUvlSUYp04Rod8MQjDofFzhoaE3b35Khw6BcnNNnF2qj+Lzt7DgDtGEhNKPadq0eIwefS5c4DTnzSPavZv//+473fYXXuBWX9EWvlrN4mJnRwWuKH169eLKRqvlNBo0MJx/z56F3V2KNaLMd9BoWJBatzZsZUydylaKITHS5++/OV0lGN22bfx9yxb+rgSP058d26kTUefOJadbEgMHslto0SLD/SeGuHu30mL8VApHjrA1acjlaYyMDO6Y14/ZZAoPP8y/SWkNHEmNQgpGBZn0TixhZh0atbl4RZ2aerQgrlSZ0Wq5Mjc0tNYY/frxKCBjvPgiD2FMTtaFNmjZkivn0mYWK+E3DAmSEj330CG2YIq6gxRGjeIWpcKkSWw56Xd4bs0P32zItdalC4uTKbRty5WSVstC0KJFYRHSDx4XGakT0vLyyy/caa+4+/z8eBa1sVhQt24RPfEEFR3EUGsYM4bP/cqV6i6JpAxIwagg3i/OIsyyoOt3ircqNZocOnzYjq5efb1S8iqVl182Ppv69m1unb/yim6d0vLetEnXKjc2NDQujo81FIsnM5P7BcaOZbfT008bTmPKFO50VvDz45a5PhoNj/Bp0aJwXvfucV/J++8bTrsoH37IVoQS4qHoxKnQUF6/cqVuvkFEhGlpl8S1a9wP8vDD7PaysmILUREOrZbdjS4uPJjgyy9rp0tm2zYeCi65r5CCUUGsJzxC7u8bf39FWNgAOnmyAmGqy4LScWloktInn1Cx+QsaDbeK/fx0sZjK+4KVN95gQbK05FFUhlBCjty9y30gQnAIi6IcOMCjdLy9Oa4VUUE8J6NzKIqiRBy1t+dZ20WDEioWVrt2PAopIMDkUzWZqCgWWSsrXl55hfs5AB4BVxmRSyWSKqQsgmH0Nb21lVvxauR6nERbB+Ov5XRxeRiZmX8jN9f09zKXmxYt+PP69cLrc3L4ta+DBgFt2ujWW1gA778PhIcDn33GxzdrVr68J0zgfNRqoGlTw/t45b/69dYt4MQJdt48ZODa9e8PHDkC5OYC3bvzu2yPHuVthvY3RPv2gI8PcO8ev5LS1rbwdiGAt94C/v4b+PNP4KmnTEu3LDRpAqxYwe9bf+kl4LvvgEOHgEWLgMOHgVatKj9PiaSGIAWjCDtPXgSs76G3dw+j+7i6PgwASE0NMX+BFMG4dq3w+i1bgPh4YMqU4sc8/TRXrAkJwKOPlj/v9u2Bzp35f2Oioy8Yf/7JgtWli+F9u3QBzpwBOnYExozhdxH7+QGurqaVRwhg/HigXj3g5ZcN7zN6NODpyf+bQzAUFOGIjub3tr/1FqBSmS8/iaQGIAWjCAeu/AkA+E9n461eB4eOUKkckZJyyPwF8vHhT33BIOIWbdu2hgXB0hKYMYP/f+yxiuX/+utcUetbMfo0bMifsbEsGO3bAw4OxtOrXx/4/XfgtdeAlBSgd++ylefjj9nacnY2vN3GBpg9GxgxAmjXrmxplwdPTxYwiaQWYFndBahpnE8+BgtqhI4tmhjdx8LCEs7OvZCa+of5C1SnDtCoEbuYdu8Gdu4Edu3iFv2qVVyZG+Kll4DGjYEBAyqW/7PPAn37GndJNWjAn//+C5w8CTz3XOlpWlsDy5axlVHWSl2lAhwdS97n5ZeNWyASiaTcSMEoQqz4E3UzS/epu7kNxLVru3Hv3l+wt/c1b6FatGAX1JYtgL09MHAg8OSTwNixxo+xsOD9KooQxsUC4Mrb0RHYtw/IyAB6GHflFaNnz4qXTyKRVBnSJaVHVEoMcu3+RVv70is9D49RACxw+/ZG8xfsnXeAyZOBPXuApCRg61Zg3Djj1kVV4+XFHdqA6R3YEonkvkMKhh7/O8v9F729S6/0rK094eraHwkJG3l8sjkZMgT45hu2GIqODKoJeHlxv4qXF3cGSySSBxIpGHrsv3IMyLXD4A7tTdrf03McsrMjcffucTOXrIajjJR66KGaY/VIJJJKRwqGHueTjgGxXRHgZ2XS/nXrDoeFhW3VuKVqMopglKX/QiKR3HdIwcjnXu49xCMMbvcegp2dacdYWjrB3X0oEhN/glabZ94C1mSUobWy/0IieaCRo6TyORV7CiQ0JnV46+PpORaJiVuQknIQ7u6DzFS6Gs7IkTxCqmPH6i6JRCIxI9LCyCfkBnd49/TuVqbj3NwGwtLSBQkJtdgt5eUFzJwpZzpLJA84UjDyOXj1GJDgiy7+JoapyMfCwgb16o1EYuJ2aDT3zFQ6iUQiqX6kYADQkhZhSceB6IcQEFD24z08xkKrvYekpF2VXziJRCKpIUjBAHA58TIyKRXW8T0KQjeVBReX3rC2boiEhA2VXziJRCKpIUjBAPBnNPdftLZ7CBbluCJCWMDTcwzu3NmLvLzkSi6dRCKR1AykYAA4Fn0MIrMeOiuhxMuBh8dYEKnlnAyJRPLAIgUDQOjNY6CoHgjwL/8sZQeHQDg5dUN09Je1e06GRCJ5YDGrYAghBgohrgohrgkhZhjY/rwQIlEIEZa/TNDb9pwQIiJ/MSFmdvnIUefAEQ2Bm4/A37/86Qgh0KTJTOTkRNXuIbYSieSBxWyCIYRQAVgGYBCAdgDGCCEMvfzgJ6L/t3fncXLVZb7HP09V9b7v3Uk63emsNEkI0IZNhUGEIIowLoCgqHnJ3BFwcFAhFwcwsg0oyr0XHQRRGBEUBmTVABl0BhkgDYQQspNe0qH3Jb1VdVfVee4fddJ2QodUr1Xded6v13l1nVPnnPpWd3U9dX6/U+enK9zpPnfbXOAG4ARgJXCDiIzufNcoJfmSuFT/DK9fOa6CAZCXdw5pacdQV3crquEJyWeMMfFiMo8wVgK7VHW3qg4CjwCfjXLbs4AXVLVDVTuBF4AJGNxhZO+8ExkIbrwDp4kIZWX/G79/O62tj09MOGOMiROTWTBmA3uGzTe4yw72ORHZJCKPiUjpKLdFRC4TkWoRqW5tbR1T0E2bGPfRxX4FBZ8jJWUxdXU3T/5lz40xZgrFutP7aaBcVZcTOYp4YLQ7UNVfqGqVqlYVjOEQIRyGLVsmrmCIeJk791r6+t6mo+O5idmpMcbEgcksGHuB0mHzc9xlQ1S1XVUH3Nn7gOOj3XaiiMCGDXDFFRO3z6Kii0lKKqOu7iY7yjDGzBiTWTA2AAtFZJ6IJAIXAk8NX0FESobNngtsdW+vA84UkRy3s/tMd9mE83hg6VKYN28i95nA3Lnfo7v7Vbq6Xpq4HRtjTAxNWsFQ1RBwBZE3+q3A71X1XRFZKyLnuqt9S0TeFZG3gW8BX3W37QB+SKTobADWusumjeLir5OYWExd3U2xjmKMMRNCZlKTSVVVlVZXV8c6xpCGhrvYtesqli37I3l5k3aSlzHGjJmIvKGqVdGsG+tO7xlt1qx/JCVlAe+9dzWOE4p1HGOMGRcrGJPI40mkouJ2+vu30Nh4b6zjGGPMuFjBmGT5+eeRlXUqtbXXEwrti3UcY4wZMysYk0xEWLDgToLBdurqbol1HGOMGTMrGFMgI+M4ioq+QkPDT/H7a2IdxxhjxsQKxhSpqLgZER+7d18T6yjGGDMmVjCmSFLSbObO/R6trY+yb98rsY5jjDGjZgVjCpWWfoeEhHzq62+LdRRjjBk1KxhTyOtNY9asy2lvf5q+vm2xjmOMMaNiBWOKzZ79TTyeZBoa7ox1FGOMGRUrGFMsMbGQoqJLaWp6kMHB5ljHMcaYqFnBiIHS0m+jOsjevXfHOooxxkTNCkYMpKYuJi/vXPbu/RnhcH+s4xhjTFSsYMRIaenVhELtNDWNepBBY4yJCSsYMZKV9VEyMlbS0HAnquFYxzHGmMOyghEjIkJp6Xfw+3fR1vbU4TcwxpgYs4IRQ/n555OcPI+6uptwnMFYxzHGmA9lBSOGPB4fFRX/Sm/vm+zY8Q/MpNEPjTEzjxWMGCss/AJlZdfT1PRr9uy5PdZxjDHmkHyxDmCgvPxG/P4d7N59LSkpCyko+PtYRzLGmA+Y1CMMEVklIttFZJeIXDvC/f8sIltEZJOIrBeRsmH3hUVkozvN6F5hEWHx4l+RmXkiW7deQk/PG7GOZIwxHzBpBUNEvMDdwNlAJXCRiFQetNpbQJWqLgceA4a3yfhVdYU7nTtZOeOF15vM0qV/ICGhkHfe+QyBwJ5YRzLGmANM5hHGSmCXqu5W1UHgEeCzw1dQ1ZdUdf9XnV8F5kxinriXmFjEsmXPEA73sWnTWQSD7bGOZIwxQyazYMwGhn9MbnCXHcpq4I/D5pNFpFpEXhWR8yYjYDxKT1/KsmVP4ffvZtOmcwiH+2IdyRhjgDg5S0pELgGqgDuGLS5T1SrgS8BPRWT+Iba9zC0s1a2trVOQdvJlZ59KZeUj9PRsYPPmz9l3NIwxcWEyC8ZeoHTY/Bx32QFE5AzgOuBcVR3Yv1xV97o/dwN/Bo4d6UFU9ReqWqWqVQUFBROXPsYKCs5j8eJ76excx7ZtX0XViXUkY8wRbjILxgZgoYjME5FE4ELggLOdRORY4B4ixaJl2PIcEUlyb+cDpwBbJjFrXCop+ToVFbfR0vIwO3deaV/sM8bE1KR9D0NVQyJyBbAO8AL3q+q7IrIWqFbVp4g0QaUDj4oIQL17RtRRwD0i4hAparep6hFXMABKS79HMNjBnj23oxpm0aKfIRIXLYnGmCPMpH5xT1WfA547aNn1w26fcYjtXgGWTWa26UJEqKi4DREv9fW3ojrA4sX3ETlr2Rhjpo5903saEBHmzbsZjyeJ2tobcZxBlix5AI/H/nzGmKlj7zjThIhQXn4DIknU1KzBcQaorHwYjych1tGMMUcIawyfZsrKrmX+/Dtpa/sPO3vKGDOl7AhjGiot/TaOM0BNzRoSEnJZsOD/4J40YIwxk8YKxjQ1d+41BINtNDT8mISEAsrLrz/8RsYYMw5WMKYpEWH+/DsIhdqprb2BhIQ8Zs++PNaxjDEzmBWMaUxEWLToXoLBDnbuvBKPJ4Xi4q9Z85QxZlJYp/c05/H4qKx8hOzs09i+fTWbN59PINAQ61jGmBnICsYM4PWmsHz5Oioqbqez83k2bKhk7967UQ0D4Dgh+vt30Nb2JO3tfyIY7IpxYmPMdCQz6fpEVVVVWl1dHesYMeX3v8eOHf9IZ+cLpKUtBYT+/u1EhiT5m9TUo8nKOpns7NMoLLzAvjluzBFKRN5wrwx+WNaHMcOkpMxn+fJ1NDc/REPDT0lMLCY3dxWpqZWkpR1FONzHvn2v0N39Cq2tj9LYeC9dXS+xaNE9do0qY8yHsoIxA4kIxcWXUFx8yYj35+ScDoCqQ23tDdTV3YRIEgsX/t8xdZjv2/cKzc2/paLiNny+9HFlN8bELysYRzARD+Xla3GcAHv2/AiPJ4n58380qqLR3PwI27ZdiuogoVAXRx3173aWljEzlBWMI1zkari34zgBGhruxONJoaLiJiByBBIMduA4/SQllR5QCFSV+vpbqam5jqysj5GZeSJ79txBdvapzJr1jQnLFw4HUB3A6023fhZjYswKhkFEWLDgLhwnQH39zbS3P0kw2Ekw2IxqCIDk5HLy8j5NXt6nycw8hV27rqKp6ZcUFn6JJUvuRySB3t632bnzSjIyPkJGxopx5+rsfInNm88nHN4HgMeTgtebTnJyBXPnfpf8/POt38WYKWRnSZkhqg41Nd+nt/ctEhNLSEwsJjGxGPDQ2fk8nZ0v4jh+ImdjO5SV/Qvl5T8YOvIYHGyluvpYvN4Ujj/+DXy+zEM+1sBAEy0tj5Cefgw5OX/3gftbWx9ny5aLSElZSEnJ1wmHe4emzs71+P07SEs7hvLyG8jPP8+awYwZo9GcJWUFw0QtHPbT1fUSnZ0vkJl5MoWFX/jAOl1dL7Nx42kUFPw9lZW/+8AbeU/PWzQ03EVLy8NDp/rm55/P/Pk/IiWlAoDGxl+yfftlZGauZNmyZ0lIyD1gH6phmpsfpq5uLX7/TtLTVzB//o/IyfnEJD1zczBVh9bWx8jOPo3ExMJYxzHjYAXDxFR9/e3s3n0NGRkrSUjIxeNJxetNJRCoZd++l/F40igp+RolJZfR3v4MdXU3oxqktPSf8XrTqan5Prm5qzj66MfwetMO+TiOE6Kl5bfU1t5IIFBDQcEXmT//xyQnzxlz9lCoh66ul+joWEdn5/P4fNksXPgzMjM/MuL6gUA9/f1bAS8ikcnjSSUj49gZ2+cSCvWwdeuXaW9/krS0paxY8V8kJOTEOlZMtbb+gdTURaSlVcY6yqhZwTAxFWnauo7u7lcJh/sIh/txnD48nhRKSlZTXLyahITsofUHBt5n9+41NDc/CEBh4YXuiIKJUT1eOBxgz547qK+/BfBSXn49c+ZchapDKNRBKNRJKNRNaupRBzzufqHQPlpafk9z80N0d/8V1RAeTxrZ2afR27uRwcFGSku/Q3n5jXi9KQD4/TXU199CU9Ovh/p5hktKmkNR0aWUlHyNlJT5bk4/XV1/oaPjOXp73yIz80Ryc88hK+uUcQ+ENTDwPu+//280Nt4LeMnMPGFoSk8/fsJOd/b7a9m8+Vz6+rYwe/Y3ef/9e8jI+AjHHPM8Xm/qhDzGdKKq1NX9kNraG/B40qisfIj8/M/GOtaoWMEw01J392v09LzFrFnfGNOnc7+/hl27vk17+5OI+EZ4I/eQkVFFTs4nyM4+HXBoanqAtrbHcZwAqalLyM8/j5ycM8nKOhmPJ4lQaB/vvfddGhvvJSVlMRUVt9HR8SxNTb8GvMyadRkFBZGmucilWMIMDjbT3PwbOjrWAQ5ZWafi82XQ2bkex/Hj8aSQlraU3t6NqAbxerPIzT2TvLxzyM09O+omHlWlp+d1GhruorX1UVTD5OWdg9ebQXf3awQCu4fWTUoqIzV1CWlpR7k/l5KWtuxD+5kO1tX1Mu++ez6qISorf09u7idpaXmULVsuIDf3Uyxd+sRQ4VNV2tufpbHxPlJSFpCf/xkyM08Z9bDCqkp//xZ6et4gO/tUkpPLRrX9aA0MNNHd/Qq5uasOWwBVlZqa71NffwuFhRfj9++gp6eaiorbKS29+rD9aqoO4XAPPl/WIddxnAEcZxCfL2NMzycaVjDMEa29/U90db2Ez5dNQkIuPl8OHk8qPT0b6OxcT0/Pa0PFxOfLprDwSxQXf5WMjKpD/pN3dLzIjh3fIBCoRSSJWbMuY+7ca0hKmn3IHAMDe2lqepCmpgdQDZGXdza5ueeQnX0aXm8yoVAPnZ0v0t7+LB0dzzE42AgIGRlV5OWdQ3b26fh8WYgk4vEkIeLD799Fd/erdHf/D93drxIMtuL1ZlJSsprZsy8fOpqByEkIPT2v09PzJv392+jv30p//3Ycp39oneTkeaSnH0N6+goyM090mxH/1rwUDHa5/VbP09j4S5KT57Fs2dOkpi4aWmfv3p+zc+c3KSr6CkuW3E97+zPU1q6lt/dNEhKKCIU6UA3i8+WQm3s2aWnLCAbbCAZbCQZbCYU6SUwsJjl5PikpkSkU6qKjYx0dHesYHNzrPpKQk3MGJSWryc8/D48n6YDft6oyMFBPb+8m+vreobd3E44TGDp5IzGxmKSkOWRnf+wDb9Kh0D7q6++goeEnOE4/iYkllJVdT0nJ6hGP/lSV9977Lg0NP6ak5DIWLfo5jjPAtm2X0tr6KMXFq1m06GcjHiVH+n8ep67uB/T1bSYhoYj09OWkpS0nLa2SYLCV3t636e3dRH//NkSEvLzPUFz8dXJzV4266B5O3BQMEVkF3AV4gftU9baD7k8CHgSOB9qBC1S11r1vDbAaCAPfUtV1h3s8KxgmGqFQD/v2/TeOM+h+kkyOcrte2tufJjv74x9aKMZC1aG3dyPt7c/R0fEs3d2vAYf+30xJWUxW1klkZX2UgoIvRv0JVNVhYGAPvb3v0Nf39tAbk9+/Y+jxUlOXkJ5+PH7/Lnp6NgAOHk8a+fmfZeHCu0ds1qutXUtt7Q0kJs5icPB9kpPnU1Z2HUVFl+A4ATo7n6et7Wk6Op4lGGzD40khIaGAhIQCfL5sBgffx+/fjerA0D59vmxycs4gJ+csMjKOo63tKZqafsXAQD0+Xy4ZGccRDvcSCvUQDvcQCnUQDvcObZ+cPA+vN43BwWaCwdZhab1kZZ1Mbu7Z5OaeRVfXn6mru4VQqJ3CwgspKPgie/b8mO7uv5KcPJ95824iL+9sHCeIamTas+cO9u79f8yefSULFtw19EEjcvWEG6mr+6Fb+D9NevoK0tNXkJRUSlvbH6it/QF9fZtISVlMUdHFBAK73b/H5qHnn5Q0d6iIOE6A5ubfEAy2kJhYTFHRV8jMPImUlHkkJ88b1VHiSOKiYEikTWEH8EmgAdgAXKSqW4at801guar+LxG5EDhfVS8QkUrgYWAlMAt4EVik+y+/eghWMMxMMTjYRk/PazhOAMcZRHUQxxkkKWkOmZknfODMsfEKhbrp6al2j15epafnDZKTy8jJ+SQ5OWeQmXnCh/YpqSq7d19DR8efKC29msLCi0f8JKwaxnECI57MEClm7xMIvIdIEhkZVR/Yh2qYzs71NDX9ikCgFq83Y2jy+bJJSzvK/aS+9IAi6jhBgsFW/P6ddHQ8T0fHH+ntfWvo/pycM6mouJWMjOOGnk97+7PU1Kyhr2/ziM+5tPQ7VFTcPuJRaXPzb6mtXXtAIfZ4knGcACkpiygvv57CwgsPaHp1nBCBQI1bSA8syo4TpKPjORob76e9/Vkin6MjfL5c0tKO5thj/2vEnIcTLwXjJOBGVT3LnV8DoKq3DltnnbvO/4iID2gCCoBrh687fL0Pe0wrGMaYaA0MNNLZuZ7k5LlkZ398xHVUw7S2PsHAQD0iCYgk4PEkkpg4i9zcsw7bTxEO99Hbu4ne3o309b1LZuaJFBVdNK4z6ILBLvz+XQQCNQQCtQQCNaiGWLz4F2PaX7xcrXY2sGfYfANwwqHWUdWQiOwD8tzlrx607YhtACJyGXAZwNy5cyckuDFm5ktKKjnkBTr3E/FSWPj5MT+G15vmNh2eNOZ9HCwhIZuEhCoyM6N6j59Q0/66Cqr6C1WtUtWqgoKCWMcxxpgZazILxl6gdNj8HHfZiOu4TVJZRDq/o9nWGGPMFJrMgrEBWCgi80QkEbgQeOqgdZ4CLnVvfx74T410qjwFXCgiSSIyD1gIvD6JWY0xxhzGpPVhuH0SVwDriJxWe7+qvisia4FqVX0K+CXw7yKyC+ggUlRw1/s9sAUIAZcf7gwpY4wxk8u+uGeMMUew0ZwlNe07vY0xxkwNKxjGGGOiYgXDGGNMVGZUH4aItAJ1Y9w8H2ibwDhTYbplnm55wTJPlemWebrlhUNnLlPVqL7ENqMKxniISHW0HT/xYrplnm55wTJPlemWebrlhYnJbE1SxhhjomIFwxhjTFSsYPzN2C71GFvTLfN0ywuWeapMt8zTLS9MQGbrwzDGGBMVO8IwxhgTlSO+YIjIKhHZLiK7ROTaWOcZiYjcLyItIrJ52LJcEXlBRHa6P3M+bB9TTURKReQlEdkiIu+KyD+5y+M2t4gki8jrIvK2m/kH7vJ5IvKa+xr5nXsxzbghIl4ReUtEnnHn4z1vrYi8IyIbRaTaXRa3rwsAEckWkcdEZJuIbBWRk+I5s4gsdn+/+6duEblqvJmP6ILhDiN7N3A2UAlc5A4PG29+Daw6aNm1wHpVXQisd+fjSQi4WlUrgROBy93fbTznHgBOV9VjgBXAKhE5EfhX4CequgDoJDLWfDz5J2DrsPl4zwvwd6q6YthpnvH8ugC4C/iTqi4BjiHy+47bzKq63f39rgCOB/qBJxhvZlU9YifgJGDdsPk1wJpY5zpE1nJg87D57UCJe7sE2B7rjIfJ/ySR8d2nRW4gFXiTyCiRbYBvpNdMrCciY8WsB04HngEknvO6mWqB/IOWxe3rgsg4PTW4fb7TIfNBOc8E/joRmY/oIwxGHkZ2xKFg41CRqja6t5uAoliG+TAiUg4cC7xGnOd2m3c2Ai3AC8B7QJeqhtxV4u018lPge4DjzucR33kBFHheRN5wh1iG+H5dzANagV+5TX/3iUga8Z15uAuBh93b48p8pBeMGUEjHxfi8nQ3EUkH/gO4SlW7h98Xj7lVNayRw/g5wEpgSYwjHZKIfBpoUdU3Yp1llD6qqscRaQq+XEQ+PvzOOHxd+IDjgJ+r6rFAHwc15cRhZgDc/qtzgUcPvm8smY/0gjGdh4JtFpESAPdnS4zzfICIJBApFg+p6uPu4rjPDaCqXcBLRJp0st0hhCG+XiOnAOeKSC3wCJFmqbuI37wAqOpe92cLkXb1lcT366IBaFDV19z5x4gUkHjOvN/ZwJuq2uzOjyvzkV4wohlGNl4NH972UiJ9BHFDRITIiIpbVfXOYXfFbW4RKRCRbPd2CpE+l61ECsfnq1nZ/AAAAqZJREFU3dXiJrOqrlHVOapaTuS1+5+qejFxmhdARNJEJGP/bSLt65uJ49eFqjYBe0RksbvoE0RGA43bzMNcxN+ao2C8mWPdIRPrCfgUsINIW/V1sc5ziIwPA41AkMinndVE2qrXAzuBF4HcWOc8KPNHiRzubgI2utOn4jk3sBx4y828GbjeXV5BZEz5XUQO7ZNinXWE7KcBz8R7Xjfb2+707v7/uXh+Xbj5VgDV7mvjD0DONMicBrQDWcOWjSuzfdPbGGNMVI70JiljjDFRsoJhjDEmKlYwjDHGRMUKhjHGmKhYwTDGGBMVKxjGxAEROW3/1WaNiVdWMIwxxkTFCoYxoyAil7hjZmwUkXvcixX2ishP3DE01otIgbvuChF5VUQ2icgT+8ceEJEFIvKiO+7GmyIy3919+rAxFx5yvy1vTNywgmFMlETkKOAC4BSNXKAwDFxM5Bu11ap6NPAX4AZ3kweBa1R1OfDOsOUPAXdrZNyNk4l8ix8iV/S9isjYLBVErhVlTNzwHX4VY4zrE0QGo9ngfvhPIXLxNgf4nbvOb4DHRSQLyFbVv7jLHwAeda+jNFtVnwBQ1QCAu7/XVbXBnd9IZAyUlyf/aRkTHSsYxkRPgAdUdc0BC0X+5aD1xnq9nYFht8PY/6eJM9YkZUz01gOfF5FCGBqHuozI/9H+q8N+CXhZVfcBnSLyMXf5l4G/qGoP0CAi57n7SBKR1Cl9FsaMkX2CMSZKqrpFRL5PZLQ4D5GrB19OZECdle59LUT6OSBy+eh/cwvCbuBr7vIvA/eIyFp3H1+YwqdhzJjZ1WqNGScR6VXV9FjnMGayWZOUMcaYqNgRhjHGmKjYEYYxxpioWMEwxhgTFSsYxhhjomIFwxhjTFSsYBhjjImKFQxjjDFR+f+D2h4BE6VQPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.7235 - acc: 0.8243\n",
      "Loss: 0.7234576030559876 Accuracy: 0.82429904\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5629 - acc: 0.5311\n",
      "Epoch 00001: val_loss improved from inf to 1.28778, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_9_conv_checkpoint/001-1.2878.hdf5\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 1.5627 - acc: 0.5312 - val_loss: 1.2878 - val_acc: 0.6061\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8659 - acc: 0.7478\n",
      "Epoch 00002: val_loss improved from 1.28778 to 0.79267, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_9_conv_checkpoint/002-0.7927.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.8661 - acc: 0.7478 - val_loss: 0.7927 - val_acc: 0.7731\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6382 - acc: 0.8163\n",
      "Epoch 00003: val_loss improved from 0.79267 to 0.64994, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_9_conv_checkpoint/003-0.6499.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.6382 - acc: 0.8163 - val_loss: 0.6499 - val_acc: 0.8104\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4962 - acc: 0.8548\n",
      "Epoch 00004: val_loss did not improve from 0.64994\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.4962 - acc: 0.8548 - val_loss: 0.7260 - val_acc: 0.7976\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4036 - acc: 0.8824\n",
      "Epoch 00005: val_loss did not improve from 0.64994\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.4036 - acc: 0.8824 - val_loss: 0.7890 - val_acc: 0.7932\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3409 - acc: 0.9010\n",
      "Epoch 00006: val_loss improved from 0.64994 to 0.64294, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_9_conv_checkpoint/006-0.6429.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.3410 - acc: 0.9010 - val_loss: 0.6429 - val_acc: 0.8230\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2865 - acc: 0.9143\n",
      "Epoch 00007: val_loss improved from 0.64294 to 0.53558, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_9_conv_checkpoint/007-0.5356.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.2866 - acc: 0.9143 - val_loss: 0.5356 - val_acc: 0.8537\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9304\n",
      "Epoch 00008: val_loss did not improve from 0.53558\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.2363 - acc: 0.9304 - val_loss: 0.6207 - val_acc: 0.8451\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2033 - acc: 0.9394\n",
      "Epoch 00009: val_loss did not improve from 0.53558\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.2035 - acc: 0.9394 - val_loss: 0.5376 - val_acc: 0.8665\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9491\n",
      "Epoch 00010: val_loss did not improve from 0.53558\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1751 - acc: 0.9491 - val_loss: 0.5652 - val_acc: 0.8463\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9588\n",
      "Epoch 00011: val_loss improved from 0.53558 to 0.50834, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_9_conv_checkpoint/011-0.5083.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1424 - acc: 0.9588 - val_loss: 0.5083 - val_acc: 0.8644\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9597\n",
      "Epoch 00012: val_loss did not improve from 0.50834\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1388 - acc: 0.9596 - val_loss: 0.5307 - val_acc: 0.8710\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9686\n",
      "Epoch 00013: val_loss did not improve from 0.50834\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1123 - acc: 0.9686 - val_loss: 0.6925 - val_acc: 0.8328\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9734\n",
      "Epoch 00014: val_loss did not improve from 0.50834\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0955 - acc: 0.9734 - val_loss: 0.5917 - val_acc: 0.8600\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9783\n",
      "Epoch 00015: val_loss improved from 0.50834 to 0.48898, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_9_conv_checkpoint/015-0.4890.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0817 - acc: 0.9783 - val_loss: 0.4890 - val_acc: 0.8819\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9714\n",
      "Epoch 00016: val_loss did not improve from 0.48898\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0984 - acc: 0.9714 - val_loss: 0.5865 - val_acc: 0.8649\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9846\n",
      "Epoch 00017: val_loss did not improve from 0.48898\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0609 - acc: 0.9845 - val_loss: 0.5309 - val_acc: 0.8754\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9771\n",
      "Epoch 00018: val_loss did not improve from 0.48898\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0820 - acc: 0.9771 - val_loss: 0.4895 - val_acc: 0.8884\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9872\n",
      "Epoch 00019: val_loss did not improve from 0.48898\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0509 - acc: 0.9872 - val_loss: 0.5838 - val_acc: 0.8574\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9826\n",
      "Epoch 00020: val_loss did not improve from 0.48898\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0649 - acc: 0.9825 - val_loss: 0.5414 - val_acc: 0.8831\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9841\n",
      "Epoch 00021: val_loss improved from 0.48898 to 0.43633, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_9_conv_checkpoint/021-0.4363.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0581 - acc: 0.9841 - val_loss: 0.4363 - val_acc: 0.8935\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9859\n",
      "Epoch 00022: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0539 - acc: 0.9858 - val_loss: 0.5967 - val_acc: 0.8747\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9836\n",
      "Epoch 00023: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0597 - acc: 0.9836 - val_loss: 0.5653 - val_acc: 0.8761\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 00024: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0346 - acc: 0.9917 - val_loss: 0.4993 - val_acc: 0.8945\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9878- ETA: 5s\n",
      "Epoch 00025: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0445 - acc: 0.9877 - val_loss: 0.5336 - val_acc: 0.8835\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9787\n",
      "Epoch 00026: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0723 - acc: 0.9786 - val_loss: 0.4390 - val_acc: 0.9024\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9945\n",
      "Epoch 00027: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0253 - acc: 0.9945 - val_loss: 0.4982 - val_acc: 0.8987\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9905\n",
      "Epoch 00028: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0368 - acc: 0.9905 - val_loss: 0.4819 - val_acc: 0.8933\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9892\n",
      "Epoch 00029: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0417 - acc: 0.9892 - val_loss: 0.5067 - val_acc: 0.9008\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9827\n",
      "Epoch 00030: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0593 - acc: 0.9827 - val_loss: 0.4671 - val_acc: 0.8982\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9940\n",
      "Epoch 00031: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0266 - acc: 0.9940 - val_loss: 0.5450 - val_acc: 0.8917\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9940\n",
      "Epoch 00032: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0267 - acc: 0.9940 - val_loss: 0.5444 - val_acc: 0.8945\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9843\n",
      "Epoch 00033: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0533 - acc: 0.9843 - val_loss: 0.4789 - val_acc: 0.9012\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9945\n",
      "Epoch 00034: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0235 - acc: 0.9944 - val_loss: 0.5328 - val_acc: 0.8845\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9851\n",
      "Epoch 00035: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0535 - acc: 0.9850 - val_loss: 0.4940 - val_acc: 0.8891\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9875\n",
      "Epoch 00036: val_loss did not improve from 0.43633\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0448 - acc: 0.9874 - val_loss: 0.5071 - val_acc: 0.8998\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9931\n",
      "Epoch 00037: val_loss improved from 0.43633 to 0.42312, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_9_conv_checkpoint/037-0.4231.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0274 - acc: 0.9931 - val_loss: 0.4231 - val_acc: 0.9133\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9929\n",
      "Epoch 00038: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0287 - acc: 0.9928 - val_loss: 0.4678 - val_acc: 0.9024\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9833\n",
      "Epoch 00039: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0563 - acc: 0.9833 - val_loss: 0.5060 - val_acc: 0.8959\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9913\n",
      "Epoch 00040: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0334 - acc: 0.9913 - val_loss: 0.4558 - val_acc: 0.9089\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9970\n",
      "Epoch 00041: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0159 - acc: 0.9970 - val_loss: 0.4788 - val_acc: 0.9068\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9942\n",
      "Epoch 00042: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0238 - acc: 0.9942 - val_loss: 0.5001 - val_acc: 0.9043\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9951\n",
      "Epoch 00043: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0215 - acc: 0.9951 - val_loss: 0.7304 - val_acc: 0.8635\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9910\n",
      "Epoch 00044: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0349 - acc: 0.9910 - val_loss: 0.5875 - val_acc: 0.8800\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9943\n",
      "Epoch 00045: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0221 - acc: 0.9943 - val_loss: 0.6742 - val_acc: 0.8740\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9861\n",
      "Epoch 00046: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0481 - acc: 0.9861 - val_loss: 0.5464 - val_acc: 0.8935\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9960\n",
      "Epoch 00047: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0183 - acc: 0.9960 - val_loss: 0.5374 - val_acc: 0.8984\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9974\n",
      "Epoch 00048: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0140 - acc: 0.9974 - val_loss: 0.6676 - val_acc: 0.8749\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9845\n",
      "Epoch 00049: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0572 - acc: 0.9845 - val_loss: 0.5387 - val_acc: 0.8996\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9900\n",
      "Epoch 00050: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0371 - acc: 0.9900 - val_loss: 0.5707 - val_acc: 0.8908\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9958\n",
      "Epoch 00051: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0172 - acc: 0.9957 - val_loss: 0.5563 - val_acc: 0.8987\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9922\n",
      "Epoch 00052: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0303 - acc: 0.9922 - val_loss: 0.5655 - val_acc: 0.8915\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9919\n",
      "Epoch 00053: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0315 - acc: 0.9919 - val_loss: 0.5684 - val_acc: 0.8908\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9929\n",
      "Epoch 00054: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0264 - acc: 0.9929 - val_loss: 0.5323 - val_acc: 0.9050\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9978\n",
      "Epoch 00055: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0119 - acc: 0.9978 - val_loss: 0.4902 - val_acc: 0.9087\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9964\n",
      "Epoch 00056: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0158 - acc: 0.9963 - val_loss: 0.6092 - val_acc: 0.8931\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9883\n",
      "Epoch 00057: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0394 - acc: 0.9883 - val_loss: 0.5095 - val_acc: 0.9031\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9953\n",
      "Epoch 00058: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0182 - acc: 0.9952 - val_loss: 0.5054 - val_acc: 0.9082\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9933\n",
      "Epoch 00059: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0255 - acc: 0.9933 - val_loss: 0.5608 - val_acc: 0.9015\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9961\n",
      "Epoch 00060: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0169 - acc: 0.9961 - val_loss: 0.5973 - val_acc: 0.8896\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9932\n",
      "Epoch 00061: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0254 - acc: 0.9932 - val_loss: 0.7766 - val_acc: 0.8698\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9887\n",
      "Epoch 00062: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0404 - acc: 0.9886 - val_loss: 0.6058 - val_acc: 0.8910\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9920\n",
      "Epoch 00063: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0284 - acc: 0.9920 - val_loss: 0.4974 - val_acc: 0.9115\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9973\n",
      "Epoch 00064: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0126 - acc: 0.9973 - val_loss: 0.4701 - val_acc: 0.9145\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9978\n",
      "Epoch 00065: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0104 - acc: 0.9978 - val_loss: 0.5179 - val_acc: 0.9087\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9901\n",
      "Epoch 00066: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0356 - acc: 0.9901 - val_loss: 0.5032 - val_acc: 0.9110\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9943\n",
      "Epoch 00067: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0221 - acc: 0.9942 - val_loss: 0.6218 - val_acc: 0.8863\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9932\n",
      "Epoch 00068: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0239 - acc: 0.9932 - val_loss: 0.5901 - val_acc: 0.8973\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9975\n",
      "Epoch 00069: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0117 - acc: 0.9975 - val_loss: 0.5206 - val_acc: 0.9103\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9978\n",
      "Epoch 00070: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0120 - acc: 0.9977 - val_loss: 0.5654 - val_acc: 0.8982\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9864\n",
      "Epoch 00071: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0478 - acc: 0.9863 - val_loss: 0.5116 - val_acc: 0.9052\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9962\n",
      "Epoch 00072: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0154 - acc: 0.9962 - val_loss: 0.5075 - val_acc: 0.9124\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9955\n",
      "Epoch 00073: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0183 - acc: 0.9955 - val_loss: 0.5667 - val_acc: 0.9038\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 00074: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0298 - acc: 0.9917 - val_loss: 0.5065 - val_acc: 0.9087\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9965\n",
      "Epoch 00075: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0156 - acc: 0.9964 - val_loss: 0.5679 - val_acc: 0.9038\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9952\n",
      "Epoch 00076: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0175 - acc: 0.9952 - val_loss: 0.5486 - val_acc: 0.9075\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9985\n",
      "Epoch 00077: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0082 - acc: 0.9985 - val_loss: 0.4644 - val_acc: 0.9171\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9960\n",
      "Epoch 00078: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0171 - acc: 0.9959 - val_loss: 0.7125 - val_acc: 0.8742\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9907\n",
      "Epoch 00079: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0331 - acc: 0.9907 - val_loss: 0.6540 - val_acc: 0.8828\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9956\n",
      "Epoch 00080: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0179 - acc: 0.9955 - val_loss: 0.5568 - val_acc: 0.9066\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9914\n",
      "Epoch 00081: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0276 - acc: 0.9914 - val_loss: 0.5494 - val_acc: 0.9036\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9940\n",
      "Epoch 00082: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0232 - acc: 0.9940 - val_loss: 0.5542 - val_acc: 0.9059\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9975\n",
      "Epoch 00083: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0126 - acc: 0.9974 - val_loss: 0.5568 - val_acc: 0.9022\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9905\n",
      "Epoch 00084: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0341 - acc: 0.9904 - val_loss: 0.5549 - val_acc: 0.9015\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9944\n",
      "Epoch 00085: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0212 - acc: 0.9944 - val_loss: 0.6587 - val_acc: 0.8847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9956\n",
      "Epoch 00086: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0176 - acc: 0.9956 - val_loss: 0.5674 - val_acc: 0.9045\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9980\n",
      "Epoch 00087: val_loss did not improve from 0.42312\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0097 - acc: 0.9980 - val_loss: 0.5935 - val_acc: 0.8984\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.4908 - acc: 0.8906\n",
      "Loss: 0.4907995786189043 Accuracy: 0.8905504\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4859 - acc: 0.5520\n",
      "Epoch 00001: val_loss improved from inf to 1.40612, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/001-1.4061.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 1.4859 - acc: 0.5520 - val_loss: 1.4061 - val_acc: 0.5660\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7265 - acc: 0.7885\n",
      "Epoch 00002: val_loss improved from 1.40612 to 0.68406, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/002-0.6841.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.7267 - acc: 0.7885 - val_loss: 0.6841 - val_acc: 0.7980\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4969 - acc: 0.8560\n",
      "Epoch 00003: val_loss improved from 0.68406 to 0.49280, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/003-0.4928.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.4970 - acc: 0.8559 - val_loss: 0.4928 - val_acc: 0.8686\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3832 - acc: 0.8900\n",
      "Epoch 00004: val_loss improved from 0.49280 to 0.40770, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/004-0.4077.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.3832 - acc: 0.8900 - val_loss: 0.4077 - val_acc: 0.8819\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3066 - acc: 0.9107\n",
      "Epoch 00005: val_loss improved from 0.40770 to 0.39186, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/005-0.3919.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.3067 - acc: 0.9107 - val_loss: 0.3919 - val_acc: 0.8875\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2575 - acc: 0.9262\n",
      "Epoch 00006: val_loss improved from 0.39186 to 0.33743, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/006-0.3374.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.2575 - acc: 0.9262 - val_loss: 0.3374 - val_acc: 0.9096\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9381\n",
      "Epoch 00007: val_loss did not improve from 0.33743\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.2109 - acc: 0.9381 - val_loss: 0.3469 - val_acc: 0.8977\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1836 - acc: 0.9463\n",
      "Epoch 00008: val_loss improved from 0.33743 to 0.31427, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/008-0.3143.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.1835 - acc: 0.9463 - val_loss: 0.3143 - val_acc: 0.9108\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.9561\n",
      "Epoch 00009: val_loss did not improve from 0.31427\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.1496 - acc: 0.9561 - val_loss: 0.3516 - val_acc: 0.9022\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9551\n",
      "Epoch 00010: val_loss improved from 0.31427 to 0.28352, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/010-0.2835.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.1483 - acc: 0.9551 - val_loss: 0.2835 - val_acc: 0.9189\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.9648\n",
      "Epoch 00011: val_loss improved from 0.28352 to 0.26152, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/011-0.2615.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.1186 - acc: 0.9648 - val_loss: 0.2615 - val_acc: 0.9257\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9710\n",
      "Epoch 00012: val_loss did not improve from 0.26152\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.1003 - acc: 0.9710 - val_loss: 0.4140 - val_acc: 0.8917\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9760\n",
      "Epoch 00013: val_loss improved from 0.26152 to 0.26116, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/013-0.2612.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0854 - acc: 0.9760 - val_loss: 0.2612 - val_acc: 0.9213\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9792\n",
      "Epoch 00014: val_loss did not improve from 0.26116\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0773 - acc: 0.9792 - val_loss: 0.3239 - val_acc: 0.9110\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9750\n",
      "Epoch 00015: val_loss did not improve from 0.26116\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0873 - acc: 0.9749 - val_loss: 0.2833 - val_acc: 0.9227\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9810\n",
      "Epoch 00016: val_loss improved from 0.26116 to 0.26011, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/016-0.2601.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0696 - acc: 0.9809 - val_loss: 0.2601 - val_acc: 0.9350\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9801\n",
      "Epoch 00017: val_loss did not improve from 0.26011\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0701 - acc: 0.9800 - val_loss: 0.2715 - val_acc: 0.9290\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9854\n",
      "Epoch 00018: val_loss did not improve from 0.26011\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0532 - acc: 0.9854 - val_loss: 0.3317 - val_acc: 0.9206\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9904\n",
      "Epoch 00019: val_loss did not improve from 0.26011\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0387 - acc: 0.9903 - val_loss: 0.3449 - val_acc: 0.9080\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9844\n",
      "Epoch 00020: val_loss did not improve from 0.26011\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0580 - acc: 0.9843 - val_loss: 0.2649 - val_acc: 0.9278\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9853\n",
      "Epoch 00021: val_loss improved from 0.26011 to 0.25625, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/021-0.2562.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0514 - acc: 0.9853 - val_loss: 0.2562 - val_acc: 0.9341\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9921\n",
      "Epoch 00022: val_loss did not improve from 0.25625\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0328 - acc: 0.9921 - val_loss: 0.3048 - val_acc: 0.9245\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9911\n",
      "Epoch 00023: val_loss did not improve from 0.25625\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0338 - acc: 0.9911 - val_loss: 0.3805 - val_acc: 0.9154\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9866\n",
      "Epoch 00024: val_loss did not improve from 0.25625\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0461 - acc: 0.9866 - val_loss: 0.3151 - val_acc: 0.9196\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9847\n",
      "Epoch 00025: val_loss improved from 0.25625 to 0.25504, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/025-0.2550.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0548 - acc: 0.9847 - val_loss: 0.2550 - val_acc: 0.9371\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9940\n",
      "Epoch 00026: val_loss improved from 0.25504 to 0.22013, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/026-0.2201.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0249 - acc: 0.9940 - val_loss: 0.2201 - val_acc: 0.9427\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9949\n",
      "Epoch 00027: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0220 - acc: 0.9949 - val_loss: 0.2408 - val_acc: 0.9390\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9901\n",
      "Epoch 00028: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0333 - acc: 0.9900 - val_loss: 0.3571 - val_acc: 0.9136\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9862\n",
      "Epoch 00029: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0473 - acc: 0.9862 - val_loss: 0.2514 - val_acc: 0.9364\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9931\n",
      "Epoch 00030: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0263 - acc: 0.9931 - val_loss: 0.2698 - val_acc: 0.9334\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9931\n",
      "Epoch 00031: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0249 - acc: 0.9930 - val_loss: 0.4422 - val_acc: 0.9003\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9876\n",
      "Epoch 00032: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0451 - acc: 0.9876 - val_loss: 0.2761 - val_acc: 0.9357\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9952\n",
      "Epoch 00033: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0188 - acc: 0.9952 - val_loss: 0.2546 - val_acc: 0.9422\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9963\n",
      "Epoch 00034: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0160 - acc: 0.9963 - val_loss: 0.2675 - val_acc: 0.9406\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9961\n",
      "Epoch 00035: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0162 - acc: 0.9961 - val_loss: 0.3455 - val_acc: 0.9262\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9931\n",
      "Epoch 00036: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0260 - acc: 0.9931 - val_loss: 0.2853 - val_acc: 0.9336\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9894\n",
      "Epoch 00037: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0375 - acc: 0.9893 - val_loss: 0.2639 - val_acc: 0.9380\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9938\n",
      "Epoch 00038: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0237 - acc: 0.9938 - val_loss: 0.3117 - val_acc: 0.9297\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9966\n",
      "Epoch 00039: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0141 - acc: 0.9965 - val_loss: 0.2700 - val_acc: 0.9355\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9946\n",
      "Epoch 00040: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0202 - acc: 0.9946 - val_loss: 0.2599 - val_acc: 0.9432\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9968\n",
      "Epoch 00041: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0125 - acc: 0.9968 - val_loss: 0.4466 - val_acc: 0.9066\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9934\n",
      "Epoch 00042: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0227 - acc: 0.9934 - val_loss: 0.2738 - val_acc: 0.9378\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9964\n",
      "Epoch 00043: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0132 - acc: 0.9964 - val_loss: 0.3021 - val_acc: 0.9369\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9906\n",
      "Epoch 00044: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0344 - acc: 0.9906 - val_loss: 0.2487 - val_acc: 0.9436\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9988\n",
      "Epoch 00045: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0074 - acc: 0.9988 - val_loss: 0.2293 - val_acc: 0.9481\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9959\n",
      "Epoch 00046: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0167 - acc: 0.9959 - val_loss: 0.2633 - val_acc: 0.9406\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9971\n",
      "Epoch 00047: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0117 - acc: 0.9971 - val_loss: 0.3225 - val_acc: 0.9287\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9920\n",
      "Epoch 00048: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0267 - acc: 0.9920 - val_loss: 0.3190 - val_acc: 0.9285\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9937\n",
      "Epoch 00049: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0225 - acc: 0.9937 - val_loss: 0.3077 - val_acc: 0.9338\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9907\n",
      "Epoch 00050: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0317 - acc: 0.9907 - val_loss: 0.2458 - val_acc: 0.9422\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9951\n",
      "Epoch 00051: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0190 - acc: 0.9951 - val_loss: 0.2441 - val_acc: 0.9446\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9961\n",
      "Epoch 00052: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0145 - acc: 0.9961 - val_loss: 0.2584 - val_acc: 0.9432\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9958\n",
      "Epoch 00053: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0167 - acc: 0.9957 - val_loss: 0.2879 - val_acc: 0.9427\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9922\n",
      "Epoch 00054: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0276 - acc: 0.9922 - val_loss: 0.2355 - val_acc: 0.9448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9971\n",
      "Epoch 00055: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0116 - acc: 0.9971 - val_loss: 0.2486 - val_acc: 0.9448\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9930\n",
      "Epoch 00056: val_loss did not improve from 0.22013\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0227 - acc: 0.9930 - val_loss: 0.2504 - val_acc: 0.9495\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9977\n",
      "Epoch 00057: val_loss improved from 0.22013 to 0.21699, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_10_conv_checkpoint/057-0.2170.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0087 - acc: 0.9977 - val_loss: 0.2170 - val_acc: 0.9522\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9934\n",
      "Epoch 00058: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0221 - acc: 0.9933 - val_loss: 0.2628 - val_acc: 0.9469\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9970\n",
      "Epoch 00059: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0123 - acc: 0.9970 - val_loss: 0.2428 - val_acc: 0.9499\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9985\n",
      "Epoch 00060: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0063 - acc: 0.9985 - val_loss: 0.2683 - val_acc: 0.9476\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9925\n",
      "Epoch 00061: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0241 - acc: 0.9924 - val_loss: 0.3108 - val_acc: 0.9399\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9943\n",
      "Epoch 00062: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0203 - acc: 0.9943 - val_loss: 0.2524 - val_acc: 0.9474\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9981\n",
      "Epoch 00063: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0086 - acc: 0.9981 - val_loss: 0.2658 - val_acc: 0.9462\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 00064: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0037 - acc: 0.9995 - val_loss: 0.2250 - val_acc: 0.9532\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9987\n",
      "Epoch 00065: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0058 - acc: 0.9987 - val_loss: 0.5360 - val_acc: 0.9082\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9961\n",
      "Epoch 00066: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0137 - acc: 0.9961 - val_loss: 0.2917 - val_acc: 0.9432\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9919\n",
      "Epoch 00067: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0269 - acc: 0.9919 - val_loss: 0.2529 - val_acc: 0.9464\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9981\n",
      "Epoch 00068: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0080 - acc: 0.9981 - val_loss: 0.2982 - val_acc: 0.9404\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9983\n",
      "Epoch 00069: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0075 - acc: 0.9982 - val_loss: 0.2647 - val_acc: 0.9460\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9936\n",
      "Epoch 00070: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0205 - acc: 0.9936 - val_loss: 0.2646 - val_acc: 0.9478\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9988\n",
      "Epoch 00071: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0055 - acc: 0.9988 - val_loss: 0.2571 - val_acc: 0.9460\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9986\n",
      "Epoch 00072: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0054 - acc: 0.9986 - val_loss: 0.2690 - val_acc: 0.9478\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9947\n",
      "Epoch 00073: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0175 - acc: 0.9947 - val_loss: 0.2966 - val_acc: 0.9420\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9942\n",
      "Epoch 00074: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0182 - acc: 0.9942 - val_loss: 0.2608 - val_acc: 0.9441\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9943\n",
      "Epoch 00075: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0177 - acc: 0.9943 - val_loss: 0.2622 - val_acc: 0.9443\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9968\n",
      "Epoch 00076: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0112 - acc: 0.9968 - val_loss: 0.2582 - val_acc: 0.9492\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9969\n",
      "Epoch 00077: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0112 - acc: 0.9969 - val_loss: 0.2901 - val_acc: 0.9394\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9963\n",
      "Epoch 00078: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0139 - acc: 0.9963 - val_loss: 0.2937 - val_acc: 0.9483\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9962\n",
      "Epoch 00079: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0143 - acc: 0.9962 - val_loss: 0.3022 - val_acc: 0.9411\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9994\n",
      "Epoch 00080: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0037 - acc: 0.9994 - val_loss: 0.2316 - val_acc: 0.9546\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9994\n",
      "Epoch 00081: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0034 - acc: 0.9993 - val_loss: 0.2796 - val_acc: 0.9476\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9929\n",
      "Epoch 00082: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0247 - acc: 0.9929 - val_loss: 0.2505 - val_acc: 0.9474\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9989\n",
      "Epoch 00083: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0053 - acc: 0.9989 - val_loss: 0.2661 - val_acc: 0.9471\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9947\n",
      "Epoch 00084: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0163 - acc: 0.9947 - val_loss: 0.2564 - val_acc: 0.9481\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9994\n",
      "Epoch 00085: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0028 - acc: 0.9994 - val_loss: 0.2539 - val_acc: 0.9453\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9990\n",
      "Epoch 00086: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0040 - acc: 0.9990 - val_loss: 0.3235 - val_acc: 0.9369\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9950\n",
      "Epoch 00087: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0163 - acc: 0.9950 - val_loss: 0.2724 - val_acc: 0.9471\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9971\n",
      "Epoch 00088: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0097 - acc: 0.9971 - val_loss: 0.2379 - val_acc: 0.9506\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9986\n",
      "Epoch 00089: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0049 - acc: 0.9986 - val_loss: 0.2863 - val_acc: 0.9462\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9976\n",
      "Epoch 00090: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0082 - acc: 0.9976 - val_loss: 0.3374 - val_acc: 0.9343\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9936\n",
      "Epoch 00091: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0200 - acc: 0.9936 - val_loss: 0.3145 - val_acc: 0.9411\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9939\n",
      "Epoch 00092: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0194 - acc: 0.9939 - val_loss: 0.2584 - val_acc: 0.9497\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9984\n",
      "Epoch 00093: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0062 - acc: 0.9984 - val_loss: 0.2504 - val_acc: 0.9513\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 00094: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0030 - acc: 0.9993 - val_loss: 0.2348 - val_acc: 0.9574\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9989\n",
      "Epoch 00095: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0042 - acc: 0.9989 - val_loss: 0.2755 - val_acc: 0.9469\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9947\n",
      "Epoch 00096: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0187 - acc: 0.9947 - val_loss: 0.2529 - val_acc: 0.9532\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9988\n",
      "Epoch 00097: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0045 - acc: 0.9988 - val_loss: 0.2765 - val_acc: 0.9432\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9980\n",
      "Epoch 00098: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0072 - acc: 0.9980 - val_loss: 0.3033 - val_acc: 0.9362\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9973\n",
      "Epoch 00099: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0089 - acc: 0.9973 - val_loss: 0.2877 - val_acc: 0.9441\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9975\n",
      "Epoch 00100: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0080 - acc: 0.9975 - val_loss: 0.2677 - val_acc: 0.9436\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9983\n",
      "Epoch 00101: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0056 - acc: 0.9983 - val_loss: 0.2421 - val_acc: 0.9502\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9980\n",
      "Epoch 00102: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0075 - acc: 0.9980 - val_loss: 0.2971 - val_acc: 0.9399\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9972\n",
      "Epoch 00103: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0089 - acc: 0.9972 - val_loss: 0.2865 - val_acc: 0.9441\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9985\n",
      "Epoch 00104: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0053 - acc: 0.9985 - val_loss: 0.3290 - val_acc: 0.9404\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9970\n",
      "Epoch 00105: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0104 - acc: 0.9969 - val_loss: 0.3413 - val_acc: 0.9369\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9950\n",
      "Epoch 00106: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0178 - acc: 0.9949 - val_loss: 0.2919 - val_acc: 0.9455\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9957\n",
      "Epoch 00107: val_loss did not improve from 0.21699\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0140 - acc: 0.9957 - val_loss: 0.2530 - val_acc: 0.9506\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_10_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2771 - acc: 0.9360\n",
      "Loss: 0.27709398446483724 Accuracy: 0.93603325\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3457 - acc: 0.5951\n",
      "Epoch 00001: val_loss improved from inf to 0.90779, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/001-0.9078.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 1.3456 - acc: 0.5951 - val_loss: 0.9078 - val_acc: 0.7228\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5482 - acc: 0.8405\n",
      "Epoch 00002: val_loss improved from 0.90779 to 0.48592, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/002-0.4859.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.5483 - acc: 0.8405 - val_loss: 0.4859 - val_acc: 0.8551\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3714 - acc: 0.8918\n",
      "Epoch 00003: val_loss improved from 0.48592 to 0.38496, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/003-0.3850.hdf5\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.3715 - acc: 0.8918 - val_loss: 0.3850 - val_acc: 0.8854\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2765 - acc: 0.9193\n",
      "Epoch 00004: val_loss improved from 0.38496 to 0.30487, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/004-0.3049.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.2765 - acc: 0.9194 - val_loss: 0.3049 - val_acc: 0.9040\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2162 - acc: 0.9360\n",
      "Epoch 00005: val_loss improved from 0.30487 to 0.28836, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/005-0.2884.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.2163 - acc: 0.9359 - val_loss: 0.2884 - val_acc: 0.9217\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1861 - acc: 0.9445\n",
      "Epoch 00006: val_loss improved from 0.28836 to 0.25926, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/006-0.2593.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1861 - acc: 0.9445 - val_loss: 0.2593 - val_acc: 0.9236\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1585 - acc: 0.9515\n",
      "Epoch 00007: val_loss did not improve from 0.25926\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1586 - acc: 0.9515 - val_loss: 0.3052 - val_acc: 0.9164\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9581\n",
      "Epoch 00008: val_loss improved from 0.25926 to 0.21105, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/008-0.2110.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1382 - acc: 0.9581 - val_loss: 0.2110 - val_acc: 0.9371\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9667\n",
      "Epoch 00009: val_loss did not improve from 0.21105\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1115 - acc: 0.9667 - val_loss: 0.2435 - val_acc: 0.9287\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9663\n",
      "Epoch 00010: val_loss did not improve from 0.21105\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1117 - acc: 0.9662 - val_loss: 0.3689 - val_acc: 0.8942\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9724\n",
      "Epoch 00011: val_loss did not improve from 0.21105\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0936 - acc: 0.9724 - val_loss: 0.2468 - val_acc: 0.9257\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9795\n",
      "Epoch 00012: val_loss improved from 0.21105 to 0.20638, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/012-0.2064.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0722 - acc: 0.9795 - val_loss: 0.2064 - val_acc: 0.9404\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9821\n",
      "Epoch 00013: val_loss improved from 0.20638 to 0.19676, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/013-0.1968.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0624 - acc: 0.9821 - val_loss: 0.1968 - val_acc: 0.9436\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9838\n",
      "Epoch 00014: val_loss did not improve from 0.19676\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0575 - acc: 0.9838 - val_loss: 0.2711 - val_acc: 0.9250\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9798\n",
      "Epoch 00015: val_loss did not improve from 0.19676\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0661 - acc: 0.9798 - val_loss: 0.2041 - val_acc: 0.9425\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9889\n",
      "Epoch 00016: val_loss did not improve from 0.19676\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0413 - acc: 0.9889 - val_loss: 0.2288 - val_acc: 0.9345\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9849\n",
      "Epoch 00017: val_loss improved from 0.19676 to 0.19434, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/017-0.1943.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0532 - acc: 0.9849 - val_loss: 0.1943 - val_acc: 0.9443\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9914\n",
      "Epoch 00018: val_loss improved from 0.19434 to 0.17074, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/018-0.1707.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0349 - acc: 0.9914 - val_loss: 0.1707 - val_acc: 0.9525\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9877\n",
      "Epoch 00019: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0424 - acc: 0.9877 - val_loss: 0.1931 - val_acc: 0.9483\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9905\n",
      "Epoch 00020: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0341 - acc: 0.9905 - val_loss: 0.2123 - val_acc: 0.9439\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9928\n",
      "Epoch 00021: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0276 - acc: 0.9928 - val_loss: 0.2037 - val_acc: 0.9425\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9859\n",
      "Epoch 00022: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0460 - acc: 0.9859 - val_loss: 0.1936 - val_acc: 0.9422\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9956\n",
      "Epoch 00023: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0187 - acc: 0.9956 - val_loss: 0.2628 - val_acc: 0.9338\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9887\n",
      "Epoch 00024: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0400 - acc: 0.9888 - val_loss: 0.1857 - val_acc: 0.9515\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9966\n",
      "Epoch 00025: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0153 - acc: 0.9966 - val_loss: 0.2355 - val_acc: 0.9483\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9915\n",
      "Epoch 00026: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0306 - acc: 0.9914 - val_loss: 0.1853 - val_acc: 0.9495\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9933\n",
      "Epoch 00027: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0248 - acc: 0.9933 - val_loss: 0.1870 - val_acc: 0.9539\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9954\n",
      "Epoch 00028: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0182 - acc: 0.9953 - val_loss: 0.2264 - val_acc: 0.9481\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9894\n",
      "Epoch 00029: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0372 - acc: 0.9894 - val_loss: 0.2022 - val_acc: 0.9460\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9983\n",
      "Epoch 00030: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0106 - acc: 0.9982 - val_loss: 0.2623 - val_acc: 0.9427\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9893\n",
      "Epoch 00031: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0345 - acc: 0.9893 - val_loss: 0.2010 - val_acc: 0.9532\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9979\n",
      "Epoch 00032: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0103 - acc: 0.9979 - val_loss: 0.1805 - val_acc: 0.9553\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9962\n",
      "Epoch 00033: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0151 - acc: 0.9962 - val_loss: 0.1812 - val_acc: 0.9534\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9967\n",
      "Epoch 00034: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0129 - acc: 0.9967 - val_loss: 0.2648 - val_acc: 0.9392\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9953\n",
      "Epoch 00035: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0168 - acc: 0.9953 - val_loss: 0.2629 - val_acc: 0.9404\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9900\n",
      "Epoch 00036: val_loss did not improve from 0.17074\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0322 - acc: 0.9900 - val_loss: 0.1793 - val_acc: 0.9578\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9986\n",
      "Epoch 00037: val_loss improved from 0.17074 to 0.16939, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/037-0.1694.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0079 - acc: 0.9986 - val_loss: 0.1694 - val_acc: 0.9611\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9974\n",
      "Epoch 00038: val_loss did not improve from 0.16939\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0097 - acc: 0.9974 - val_loss: 0.1879 - val_acc: 0.9532\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9941\n",
      "Epoch 00039: val_loss did not improve from 0.16939\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0204 - acc: 0.9941 - val_loss: 0.1987 - val_acc: 0.9527\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9980\n",
      "Epoch 00040: val_loss did not improve from 0.16939\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0085 - acc: 0.9980 - val_loss: 0.5269 - val_acc: 0.8812\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9909\n",
      "Epoch 00041: val_loss improved from 0.16939 to 0.16388, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/041-0.1639.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0291 - acc: 0.9909 - val_loss: 0.1639 - val_acc: 0.9597\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9978\n",
      "Epoch 00042: val_loss improved from 0.16388 to 0.16386, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/042-0.1639.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0086 - acc: 0.9978 - val_loss: 0.1639 - val_acc: 0.9606\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9931\n",
      "Epoch 00043: val_loss did not improve from 0.16386\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0240 - acc: 0.9931 - val_loss: 0.1814 - val_acc: 0.9557\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9986\n",
      "Epoch 00044: val_loss did not improve from 0.16386\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0067 - acc: 0.9986 - val_loss: 0.2256 - val_acc: 0.9443\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 00045: val_loss did not improve from 0.16386\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0274 - acc: 0.9916 - val_loss: 0.1790 - val_acc: 0.9534\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9962\n",
      "Epoch 00046: val_loss did not improve from 0.16386\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0136 - acc: 0.9962 - val_loss: 0.1835 - val_acc: 0.9541\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9943\n",
      "Epoch 00047: val_loss did not improve from 0.16386\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0214 - acc: 0.9943 - val_loss: 0.1843 - val_acc: 0.9562\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9943\n",
      "Epoch 00048: val_loss did not improve from 0.16386\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0203 - acc: 0.9943 - val_loss: 0.1651 - val_acc: 0.9564\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9980\n",
      "Epoch 00049: val_loss did not improve from 0.16386\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0094 - acc: 0.9980 - val_loss: 0.1794 - val_acc: 0.9576\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9995\n",
      "Epoch 00050: val_loss did not improve from 0.16386\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0033 - acc: 0.9995 - val_loss: 0.1666 - val_acc: 0.9576\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9961\n",
      "Epoch 00051: val_loss did not improve from 0.16386\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0133 - acc: 0.9961 - val_loss: 0.1761 - val_acc: 0.9581\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9987\n",
      "Epoch 00052: val_loss improved from 0.16386 to 0.16361, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/052-0.1636.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0059 - acc: 0.9987 - val_loss: 0.1636 - val_acc: 0.9627\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9983\n",
      "Epoch 00053: val_loss did not improve from 0.16361\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0071 - acc: 0.9983 - val_loss: 0.2136 - val_acc: 0.9546\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9944\n",
      "Epoch 00054: val_loss did not improve from 0.16361\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0195 - acc: 0.9944 - val_loss: 0.1838 - val_acc: 0.9583\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9989\n",
      "Epoch 00055: val_loss did not improve from 0.16361\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0053 - acc: 0.9989 - val_loss: 0.1720 - val_acc: 0.9578\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9989\n",
      "Epoch 00056: val_loss did not improve from 0.16361\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0050 - acc: 0.9989 - val_loss: 0.2055 - val_acc: 0.9562\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9945\n",
      "Epoch 00057: val_loss did not improve from 0.16361\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0174 - acc: 0.9945 - val_loss: 0.3090 - val_acc: 0.9331\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9929\n",
      "Epoch 00058: val_loss did not improve from 0.16361\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0235 - acc: 0.9929 - val_loss: 0.1766 - val_acc: 0.9581\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9995\n",
      "Epoch 00059: val_loss did not improve from 0.16361\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0033 - acc: 0.9995 - val_loss: 0.1972 - val_acc: 0.9557\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9990\n",
      "Epoch 00060: val_loss did not improve from 0.16361\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0043 - acc: 0.9990 - val_loss: 0.1707 - val_acc: 0.9611\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9958\n",
      "Epoch 00061: val_loss did not improve from 0.16361\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0147 - acc: 0.9958 - val_loss: 0.1683 - val_acc: 0.9623\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9945\n",
      "Epoch 00062: val_loss did not improve from 0.16361\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0172 - acc: 0.9945 - val_loss: 0.1702 - val_acc: 0.9618\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9994\n",
      "Epoch 00063: val_loss did not improve from 0.16361\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0032 - acc: 0.9994 - val_loss: 0.1871 - val_acc: 0.9557\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9948\n",
      "Epoch 00064: val_loss did not improve from 0.16361\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0183 - acc: 0.9948 - val_loss: 0.1845 - val_acc: 0.9625\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9994\n",
      "Epoch 00065: val_loss improved from 0.16361 to 0.15396, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/065-0.1540.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0035 - acc: 0.9994 - val_loss: 0.1540 - val_acc: 0.9646\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 00066: val_loss did not improve from 0.15396\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0037 - acc: 0.9993 - val_loss: 0.1714 - val_acc: 0.9618\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9943\n",
      "Epoch 00067: val_loss did not improve from 0.15396\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0179 - acc: 0.9943 - val_loss: 0.1753 - val_acc: 0.9604\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9937\n",
      "Epoch 00068: val_loss did not improve from 0.15396\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0227 - acc: 0.9937 - val_loss: 0.1563 - val_acc: 0.9641\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 00069: val_loss did not improve from 0.15396\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0037 - acc: 0.9993 - val_loss: 0.1570 - val_acc: 0.9634\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9997\n",
      "Epoch 00070: val_loss did not improve from 0.15396\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0023 - acc: 0.9997 - val_loss: 0.1564 - val_acc: 0.9625\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9977\n",
      "Epoch 00071: val_loss did not improve from 0.15396\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0085 - acc: 0.9977 - val_loss: 0.1859 - val_acc: 0.9571\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9923\n",
      "Epoch 00072: val_loss did not improve from 0.15396\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0263 - acc: 0.9923 - val_loss: 0.1667 - val_acc: 0.9606\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9996\n",
      "Epoch 00073: val_loss improved from 0.15396 to 0.15136, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/073-0.1514.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0027 - acc: 0.9995 - val_loss: 0.1514 - val_acc: 0.9660\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9969\n",
      "Epoch 00074: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0102 - acc: 0.9969 - val_loss: 0.1657 - val_acc: 0.9620\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9994\n",
      "Epoch 00075: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0035 - acc: 0.9994 - val_loss: 0.1687 - val_acc: 0.9623\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9958\n",
      "Epoch 00076: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0144 - acc: 0.9958 - val_loss: 0.2054 - val_acc: 0.9567\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9985\n",
      "Epoch 00077: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0059 - acc: 0.9985 - val_loss: 0.1613 - val_acc: 0.9648\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9992\n",
      "Epoch 00078: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0036 - acc: 0.9992 - val_loss: 0.1803 - val_acc: 0.9613\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9953\n",
      "Epoch 00079: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0151 - acc: 0.9953 - val_loss: 0.1758 - val_acc: 0.9630\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9991\n",
      "Epoch 00080: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0049 - acc: 0.9990 - val_loss: 0.1673 - val_acc: 0.9625\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9967\n",
      "Epoch 00081: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0115 - acc: 0.9967 - val_loss: 0.1638 - val_acc: 0.9606\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9986\n",
      "Epoch 00082: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0056 - acc: 0.9986 - val_loss: 0.1719 - val_acc: 0.9618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9997\n",
      "Epoch 00083: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0021 - acc: 0.9997 - val_loss: 0.2188 - val_acc: 0.9539\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9986\n",
      "Epoch 00084: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0057 - acc: 0.9986 - val_loss: 0.2443 - val_acc: 0.9483\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9980\n",
      "Epoch 00085: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0073 - acc: 0.9980 - val_loss: 0.1970 - val_acc: 0.9644\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9995\n",
      "Epoch 00086: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0029 - acc: 0.9995 - val_loss: 0.2510 - val_acc: 0.9520\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9966\n",
      "Epoch 00087: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0117 - acc: 0.9966 - val_loss: 0.1971 - val_acc: 0.9518\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9987\n",
      "Epoch 00088: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0054 - acc: 0.9986 - val_loss: 0.1841 - val_acc: 0.9611\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9950\n",
      "Epoch 00089: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0169 - acc: 0.9950 - val_loss: 0.1702 - val_acc: 0.9616\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9995\n",
      "Epoch 00090: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0026 - acc: 0.9995 - val_loss: 0.1560 - val_acc: 0.9658\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 00091: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0038 - acc: 0.9990 - val_loss: 0.1979 - val_acc: 0.9595\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9985\n",
      "Epoch 00092: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0062 - acc: 0.9984 - val_loss: 0.1788 - val_acc: 0.9599\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9969\n",
      "Epoch 00093: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0108 - acc: 0.9969 - val_loss: 0.1737 - val_acc: 0.9641\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 00094: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0030 - acc: 0.9993 - val_loss: 0.1696 - val_acc: 0.9662\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 00095: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0016 - acc: 0.9998 - val_loss: 0.1690 - val_acc: 0.9658\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9982\n",
      "Epoch 00096: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0071 - acc: 0.9981 - val_loss: 0.2484 - val_acc: 0.9513\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9964\n",
      "Epoch 00097: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0124 - acc: 0.9963 - val_loss: 0.1813 - val_acc: 0.9581\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9970\n",
      "Epoch 00098: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0102 - acc: 0.9970 - val_loss: 0.1839 - val_acc: 0.9627\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9997\n",
      "Epoch 00099: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0021 - acc: 0.9997 - val_loss: 0.1982 - val_acc: 0.9564\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9968\n",
      "Epoch 00100: val_loss did not improve from 0.15136\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0111 - acc: 0.9968 - val_loss: 0.1550 - val_acc: 0.9655\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 00101: val_loss improved from 0.15136 to 0.14924, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/101-0.1492.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0016 - acc: 0.9998 - val_loss: 0.1492 - val_acc: 0.9632\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9978\n",
      "Epoch 00102: val_loss did not improve from 0.14924\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0072 - acc: 0.9978 - val_loss: 0.1508 - val_acc: 0.9658\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 00103: val_loss did not improve from 0.14924\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0029 - acc: 0.9992 - val_loss: 0.1813 - val_acc: 0.9583\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 00104: val_loss did not improve from 0.14924\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.2032 - val_acc: 0.9581\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9960\n",
      "Epoch 00105: val_loss did not improve from 0.14924\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0129 - acc: 0.9960 - val_loss: 0.2036 - val_acc: 0.9564\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9963\n",
      "Epoch 00106: val_loss did not improve from 0.14924\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0121 - acc: 0.9963 - val_loss: 0.1613 - val_acc: 0.9634\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9997\n",
      "Epoch 00107: val_loss did not improve from 0.14924\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1708 - val_acc: 0.9651\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9971\n",
      "Epoch 00108: val_loss did not improve from 0.14924\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0107 - acc: 0.9971 - val_loss: 0.1862 - val_acc: 0.9634\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9969\n",
      "Epoch 00109: val_loss did not improve from 0.14924\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0101 - acc: 0.9969 - val_loss: 0.1574 - val_acc: 0.9665\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 00110: val_loss did not improve from 0.14924\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0019 - acc: 0.9996 - val_loss: 0.1960 - val_acc: 0.9597\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9968\n",
      "Epoch 00111: val_loss did not improve from 0.14924\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0110 - acc: 0.9968 - val_loss: 0.1652 - val_acc: 0.9641\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 00112: val_loss improved from 0.14924 to 0.14904, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_11_conv_checkpoint/112-0.1490.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0015 - acc: 0.9998 - val_loss: 0.1490 - val_acc: 0.9667\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 00113: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0013 - acc: 0.9998 - val_loss: 0.1687 - val_acc: 0.9655\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9971\n",
      "Epoch 00114: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0093 - acc: 0.9971 - val_loss: 0.1662 - val_acc: 0.9641\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 00115: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0016 - acc: 0.9997 - val_loss: 0.1556 - val_acc: 0.9674\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9982\n",
      "Epoch 00116: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0068 - acc: 0.9982 - val_loss: 0.1769 - val_acc: 0.9613\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9994\n",
      "Epoch 00117: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0024 - acc: 0.9994 - val_loss: 0.1737 - val_acc: 0.9618\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9977\n",
      "Epoch 00118: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0075 - acc: 0.9977 - val_loss: 0.1921 - val_acc: 0.9606\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9986\n",
      "Epoch 00119: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0046 - acc: 0.9986 - val_loss: 0.2281 - val_acc: 0.9534\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9980\n",
      "Epoch 00120: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0071 - acc: 0.9980 - val_loss: 0.1703 - val_acc: 0.9658\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 00121: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.1528 - val_acc: 0.9672\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9995\n",
      "Epoch 00122: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0022 - acc: 0.9995 - val_loss: 0.2034 - val_acc: 0.9595\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9975\n",
      "Epoch 00123: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0090 - acc: 0.9975 - val_loss: 0.2176 - val_acc: 0.9511\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9958\n",
      "Epoch 00124: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0129 - acc: 0.9958 - val_loss: 0.1505 - val_acc: 0.9641\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9986\n",
      "Epoch 00125: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0042 - acc: 0.9986 - val_loss: 0.1731 - val_acc: 0.9618\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9993\n",
      "Epoch 00126: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0034 - acc: 0.9993 - val_loss: 0.1607 - val_acc: 0.9665\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 00127: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0012 - acc: 0.9997 - val_loss: 0.1730 - val_acc: 0.9669\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 00128: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0020 - acc: 0.9995 - val_loss: 0.1856 - val_acc: 0.9630\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9964\n",
      "Epoch 00129: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0113 - acc: 0.9964 - val_loss: 0.1787 - val_acc: 0.9606\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9973\n",
      "Epoch 00130: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0091 - acc: 0.9973 - val_loss: 0.1871 - val_acc: 0.9634\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 00131: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.1913 - val_acc: 0.9634\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9999\n",
      "Epoch 00132: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0011 - acc: 0.9999 - val_loss: 0.1610 - val_acc: 0.9653\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.9129e-04 - acc: 0.9999\n",
      "Epoch 00133: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 6.9127e-04 - acc: 0.9999 - val_loss: 0.1667 - val_acc: 0.9681\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9970\n",
      "Epoch 00134: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0084 - acc: 0.9970 - val_loss: 0.2060 - val_acc: 0.9632\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 00135: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0038 - acc: 0.9990 - val_loss: 0.2398 - val_acc: 0.9532\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9973\n",
      "Epoch 00136: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0080 - acc: 0.9973 - val_loss: 0.1630 - val_acc: 0.9651\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 00137: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0012 - acc: 0.9998 - val_loss: 0.1597 - val_acc: 0.9660\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.1332e-04 - acc: 0.9998\n",
      "Epoch 00138: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 8.6626e-04 - acc: 0.9998 - val_loss: 0.1702 - val_acc: 0.9662\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9979\n",
      "Epoch 00139: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0068 - acc: 0.9979 - val_loss: 0.1884 - val_acc: 0.9620\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9991\n",
      "Epoch 00140: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0031 - acc: 0.9991 - val_loss: 0.1945 - val_acc: 0.9632\n",
      "Epoch 141/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9987\n",
      "Epoch 00141: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0042 - acc: 0.9987 - val_loss: 0.1752 - val_acc: 0.9634\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 00142: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0015 - acc: 0.9996 - val_loss: 0.1716 - val_acc: 0.9667\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9985\n",
      "Epoch 00143: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0049 - acc: 0.9985 - val_loss: 0.2360 - val_acc: 0.9581\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9974\n",
      "Epoch 00144: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0085 - acc: 0.9974 - val_loss: 0.1853 - val_acc: 0.9618\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 00145: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1857 - val_acc: 0.9627\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 00146: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.1556 - val_acc: 0.9697\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9977\n",
      "Epoch 00147: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0067 - acc: 0.9977 - val_loss: 0.1926 - val_acc: 0.9616\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 00148: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.1721 - val_acc: 0.9686\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9973\n",
      "Epoch 00149: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0087 - acc: 0.9973 - val_loss: 0.1968 - val_acc: 0.9634\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9984\n",
      "Epoch 00150: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0052 - acc: 0.9984 - val_loss: 0.1810 - val_acc: 0.9648\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 00151: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0011 - acc: 0.9997 - val_loss: 0.1699 - val_acc: 0.9667\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 00152: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0013 - acc: 0.9996 - val_loss: 0.1969 - val_acc: 0.9639\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9988\n",
      "Epoch 00153: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0042 - acc: 0.9988 - val_loss: 0.2152 - val_acc: 0.9627\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9980\n",
      "Epoch 00154: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0060 - acc: 0.9979 - val_loss: 0.1862 - val_acc: 0.9662\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9977\n",
      "Epoch 00155: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0078 - acc: 0.9977 - val_loss: 0.1831 - val_acc: 0.9602\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 00156: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0022 - acc: 0.9994 - val_loss: 0.1695 - val_acc: 0.9672\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 00157: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0022 - acc: 0.9994 - val_loss: 0.1721 - val_acc: 0.9686\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9989\n",
      "Epoch 00158: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0036 - acc: 0.9989 - val_loss: 0.2340 - val_acc: 0.9557\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9970\n",
      "Epoch 00159: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0093 - acc: 0.9970 - val_loss: 0.1963 - val_acc: 0.9627\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 00160: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0012 - acc: 0.9998 - val_loss: 0.1883 - val_acc: 0.9653\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.4633e-04 - acc: 0.9999\n",
      "Epoch 00161: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 6.5611e-04 - acc: 0.9999 - val_loss: 0.1756 - val_acc: 0.9648\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9983\n",
      "Epoch 00162: val_loss did not improve from 0.14904\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0052 - acc: 0.9983 - val_loss: 0.1910 - val_acc: 0.9632\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_11_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXl4VcX5xz9zk5s9ISGEhD3sS9h3RQGLIqLigogrihW1trbU/qi4Y2urpWotLqW41qUigrgUlEplU1AJyBIgyJJAQnbISpZ7c+/8/nhzcxOyEnJJ4M7nee5zzzJn5j3nzMx33plz5iitNQaDwWAwAFha2gCDwWAwtB6MKBgMBoOhEiMKBoPBYKjEiILBYDAYKjGiYDAYDIZKjCgYDAaDoRIjCgaDwWCoxIiCwWAwGCrxmCgopd5USmUppRIaCDdKKVWulLrBU7YYDAaDoXEoT73RrJQaDxQB72itB9YRxgf4CigF3tRaL28o3nbt2unY2NjmNNVgMBjOe7Zt25ajtY5qKJyvpwzQWm9USsU2EOwBYAUwqrHxxsbGEh8ffwaWGQwGg/ehlDrSmHAtNqaglOoEXAf8oxFh71FKxSul4rOzsz1vnMFgMHgpLTnQ/CLwkNba2VBArfUSrfVIrfXIqKgGvR+DwWAwNBGPdR81gpHAUqUUQDtgqlKqXGv9SQvaZDAYDF5Ni4mC1rq7a1kp9Tbwn6YKgt1uJzU1ldLS0uYyz+sICAigc+fOWK3WljbFYDC0IB4TBaXUB8BEoJ1SKhV4ErACaK0XN2daqamphIaGEhsbS4XnYTgNtNYcP36c1NRUunfv3vABBoPhvMWTTx/dfBph7zyTtEpLS40gnAFKKSIjIzGD+AaD4bx5o9kIwplhrp/BYIDzSBQawuEooazsGE6nvaVNMRgMhlaL14iC01mCzZaO1uXNHndeXh6vvvpqk46dOnUqeXl5jQ6/YMECnnvuuSalZTAYDA3hNaIAru6R5p/Woz5RKC+vX4RWr15NeHh4s9tkMBgMTcGIQjMwf/58Dh06xNChQ5k3bx7r16/n4osvZtq0aQwYMACAa6+9lhEjRhAXF8eSJUsqj42NjSUnJ4fk5GT69+/PnDlziIuLY/LkyZSUlNSb7o4dOxg7diyDBw/muuuuIzc3F4BFixYxYMAABg8ezE033QTAhg0bGDp0KEOHDmXYsGEUFhY2+3UwGAznPi358ppHOHBgLkVFO2ps17ocp7MEiyUImYev8YSEDKV37xfr3P/ss8+SkJDAjh2S7vr169m+fTsJCQmVj3i++eabtG3blpKSEkaNGsX06dOJjIw8xfYDfPDBB7z22mvceOONrFixgttuu63OdGfNmsVLL73EhAkTeOKJJ3jqqad48cUXefbZZ0lKSsLf37+ya+q5557jlVdeYdy4cRQVFREQEHBa18BgMHgHXugpnB1Gjx5d7Zn/RYsWMWTIEMaOHUtKSgoHDhyocUz37t0ZOnQoACNGjCA5ObnO+PPz88nLy2PChAkA3HHHHWzcuBGAwYMHc+utt/Lee+/h6yu6P27cOB588EEWLVpEXl5e5XaDwWCoynlXM9TVoi8vL6SkZD+BgX3x9Q31uB3BwcGVy+vXr2ft2rVs2bKFoKAgJk6cWOvb1/7+/pXLPj4+DXYf1cWqVavYuHEjn3/+OX/605/YvXs38+fP58orr2T16tWMGzeONWvW0K9fvybFbzAYzl+8yFNw0fxjCqGhofX20efn5xMREUFQUBCJiYl89913Z5xmmzZtiIiIYNOmTQC8++67TJgwAafTSUpKCpdccgl/+ctfyM/Pp6ioiEOHDjFo0CAeeughRo0aRWJi4hnbYDAYzj/OO0+hbjw30BwZGcm4ceMYOHAgV1xxBVdeeWW1/VOmTGHx4sX079+fvn37Mnbs2GZJ91//+hf33XcfxcXF9OjRg7feeguHw8Ftt91Gfn4+Wmt+/etfEx4ezuOPP866deuwWCzExcVxxRVXNIsNBoPh/MJjX17zFCNHjtSnfmRn37599O/fv97jHI6TFBfvIyCgF1areQS0NhpzHQ0Gw7mJUmqb1npkQ+G8qPvIc56CwWAwnC8YUTAYDAZDJUYUDAaDwVCJ14iCmQTUYDAYGsZrRMHlKZxrA+sGg8FwNvE6UTDdRwaDwVA3RhRaiJCQkNPabjAYDGcDIwoGg8FgqMRrRMH9uUnPTJ39yiuvVK67PoRTVFTEpEmTGD58OIMGDeLTTz9tdJxaa+bNm8fAgQMZNGgQH374IQDp6emMHz+eoUOHMnDgQDZt2oTD4eDOO++sDPu3v/2t2c/RYDB4Bx6b5kIp9SZwFZCltR5Yy/5bgYeQJnwh8Aut9c4zTnjuXNhRc+ps0AQ6irAof7D4nV6cQ4fCi3VPnT1z5kzmzp3LL3/5SwCWLVvGmjVrCAgIYOXKlYSFhZGTk8PYsWOZNm1ao76H/PHHH7Njxw527txJTk4Oo0aNYvz48fz73//m8ssv59FHH8XhcFBcXMyOHTs4duwYCQkJAKf1JTeDwWCoiifnPnobeBl4p479ScAErXWuUuoKYAkwxnPmeO6Z1GHDhpGVlUVaWhrZ2dlERETQpUsX7HY7jzzyCBs3bsRisXDs2DEyMzOJiYlpMM5vvvmGm2++GR8fH6Kjo5kwYQJbt25l1KhR3HXXXdjtdq699lqGDh1Kjx49OHz4MA888ABXXnklkydP9ti5GgyG8xuPiYLWeqNSKrae/ZurrH4HdG6WhOtq0WtNSdE2/Pw64u/fsVmSqsqMGTNYvnw5GRkZzJw5E4D333+f7Oxstm3bhtVqJTY2ttYps0+H8ePHs3HjRlatWsWdd97Jgw8+yKxZs9i5cydr1qxh8eLFLFu2jDfffLM5TstgMHgZrWVM4efAF55MwJNjCiBdSEuXLmX58uXMmDEDkCmz27dvj9VqZd26dRw5cqTR8V188cV8+OGHOBwOsrOz2bhxI6NHj+bIkSNER0czZ84c7r77brZv305OTg5Op5Pp06fz9NNPs337do+co8FgOP9p8amzlVKXIKJwUT1h7gHuAejateuZpIanRCEuLo7CwkI6depEhw4dALj11lu5+uqrGTRoECNHjjytj9pcd911bNmyhSFDhqCUYuHChcTExPCvf/2Lv/71r1itVkJCQnjnnXc4duwYs2fPxul0AvDMM8945BwNBsP5j0enzq7oPvpPbQPNFfsHAyuBK7TWPzUmzqZOnQ1QWLgdqzWKgIAujUnK6zBTZxsM5y+tfupspVRX4GPg9sYKQjOkenaSMRgMhnMUTz6S+gEwEWinlEoFngSsAFrrxcATQCTwakV/f3ljVOwMrcK8vGYwGAx148mnj25uYP/dwN2eSr82RHuMKBgMBkNdtJanj84SxlMwGAyG+vA6UTBTZxsMBkPdeJ0oGE/BYDAY6saIQjOQl5fHq6++2qRjp06dauYqMhgMrQavEoXGTETXFOoThfLy8nqPXb16NeHh4Z4wy2AwGE4brxIF8MznOOfPn8+hQ4cYOnQo8+bNY/369Vx88cVMmzaNAQMGAHDttdcyYsQI4uLiWLJkSeWxsbGx5OTkkJycTP/+/ZkzZw5xcXFMnjyZkpKSGml9/vnnjBkzhmHDhnHppZeSmZkJQFFREbNnz2bQoEEMHjyYFStWAPDll18yfPhwhgwZwqRJk5r93A0Gw/lFi09z0dzUOXM24HDEopTCcppS2MDM2Tz77LMkJCSwoyLh9evXs337dhISEujevTsAb775Jm3btqWkpIRRo0Yxffp0IiMjq8Vz4MABPvjgA1577TVuvPFGVqxYwW233VYtzEUXXcR3332HUorXX3+dhQsX8vzzz/PHP/6RNm3asHv3bgByc3PJzs5mzpw5bNy4ke7du3PixInTO3GDweB1nHei0FoYPXp0pSAALFq0iJUrVwKQkpLCgQMHaohC9+7dGTp0KAAjRowgOTm5RrypqanMnDmT9PR0bDZbZRpr165l6dKlleEiIiL4/PPPGT9+fGWYtm3bNus5GgyG84/zThTqa9GfPJmCUoqgoL4etyM4OLhyef369axdu5YtW7YQFBTExIkTa51C29/fv3LZx8en1u6jBx54gAcffJBp06axfv16FixY4BH7DQaDd+JVYwqeGmgODQ2lsLCwzv35+flEREQQFBREYmIi3333XZPTys/Pp1OnTgD861//qtx+2WWXVfskaG5uLmPHjmXjxo0kJSUBmO4jg8HQIF4lCuCZgebIyEjGjRvHwIEDmTdvXo39U6ZMoby8nP79+zN//nzGjh3b5LQWLFjAjBkzGDFiBO3atavc/thjj5Gbm8vAgQMZMmQI69atIyoqiiVLlnD99dczZMiQyo//GAwGQ114dOpsT3AmU2cXF/+E1g6Cg8300LVhps42GM5fWv3U2S2DeaPZYDAY6sOrREHGFIwoGAwGQ114lSgYT8FgMBjqx+tE4RwbQjEYDIazipeJAhhPwWAwGOrGy0TBdB8ZDAZDfXiVKLSmgeaQkJCWNsFgMBhq4FWiYDwFg8FgqB+PiYJS6k2lVJZSKqGO/UoptUgpdVAptUspNdxTtlRJ1WNTZ1edYmLBggU899xzFBUVMWnSJIYPH86gQYP49NNPG4yrrim2a5sCu67psg0Gg6GpeHJCvLeBl4F36th/BdC74jcG+EfF/xkx98u57Miofe5sp7MMre34+Jxe183QmKG8OKXumfZmzpzJ3Llz+eUvfwnAsmXLWLNmDQEBAaxcuZKwsDBycnIYO3Ys06ZNq3cOptqm2HY6nbVOgV3bdNkGg8FwJnhMFLTWG5VSsfUEuQZ4R0vT/TulVLhSqoPWOt1TNnmKYcOGkZWVRVpaGtnZ2URERNClSxfsdjuPPPIIGzduxGKxcOzYMTIzM4mJiakzrtqm2M7Ozq51Cuzapss2GAyGM6Elp87uBKRUWU+t2HZGolBfi76sLBWbLZPQ0BFnkkStzJgxg+XLl5ORkVE58dz7779PdnY227Ztw2q1EhsbW+uU2S5cU2xv3ryF4GCZYruoqBSHo2bYqr1gpaVQXAwREaCULJeWgp8fWCwS1scHrFb5B7Db4fhx2e/nByEhEm7DBtk3aZLE9f33sn3MGMjOhk8+keUhQ2R7ejq0aydxANhssGkTxMdDaioEBcEll0i6P/4IJSUQGAijRsG4cRL/mjVQViZhp06F0aMl7dJSWLIEtm+XfT16SFwDB0p6mzbBZ5/BsGEweTL873/w9ddQXg5t28Itt8Dwik7J48fhjTdg716Jt1076NdP0uvRA3buhNdfhy5doFcvSEyErCwYPx66dxcbkpKgsBA6doSrroLcXFi7FkJDYcAASePQIcjMhLw8CAuTexIRIdc5NVX+x4yR89m/H9q3h8sugz174NNP5foFBUFwsMTbubMsJyRI3MXF4O8vNvfoAT17ynpensSxaxd07Sr3Z+9e2dali9icmSn3sKREbJo8WewuLZXjNm6UNIcOhchIcDhk+08/SbjYWLmv+/fLvY+IgJEjJV9t2ybXvWtXOYesLIkjNlbSy8+X++7jA8nJYouvL7RpI9e7d2/5nTgheSIjA06elF9JieSHwEBJb8QI2ZaSInnq6FFwOt2/jh3hggtk+eBBuQ+dOsHhw3JN7HaxuUcPiIkRWwsLJX6HQ+6jj4/cm/bt5TzS0+U6nDwp5x4bK3EmJ4vNcXGynpkptmdkSJ4ODJT7WfUXHCz5NzUV0tLk3KxW+YWGyvXQGrZulXSdTggPl2t76aWSJz3JOfE9BaXUPcA9AF27dj2TmPDUQPPMmTOZM2cOOTk5bNiwAYC8vHyiotpjtVpZu3YdR44cobjYXaHn5komA8l8WVn5+PpGcOhQECdPyhTbhw5B795jWbfufr75JomoqO5kZZ0gKKgto0dfxsKFr/CLX7xYUSBy6dAhgoovdNZKaKgUksxMKcRVOX4cpkyR5QsukLD//a+sd+0qGd1mk0w8bZpUnPv3SwHq2FEKeXY2FBXJMW3aSCW2cGHttvj4SCH08ZGKrbQU/vAHKai9e0slmJYGHTpIusePu48NDpZrZ7FIoXERESH7srPh+efF7ogIsbO0VCrIgAA5/4IC+PWvRYR++EEKpc3mjisgAP7+d/e6xSLiWVAA8+fLNqWo8UJkZKSce2Gh3GPXdQ4JkeW//a326xEcLGGKi+Xcqp4XSKXj2v/eezXTBYiKgpwc974uXeS+2e1yndu1k4opMxNeeqn6saGhUpFVvQYgx7z5pixbrXJvfHwk3rfeku3h4XIPMzPlOkVGVj/3qoSFSX5xVcC1zeju7+++HoGBcj75+fD229XDBQaKaPv6SrpKwTffSGMC3HkMZF+PHnL+JSXw8cdin4+PpFNaKstt28q1z8qqbn90tNiutRxrt0seadOmul1+fpKH/f0lneJid0OtKkpJuVdK0rHbpey47A0NhW7d5LxOnJCyAOe3KBwDulRZ71yxrQZa6yXAEpBZUpuepHLF16zfVtAaevWKIz+/kJiYTsTEdODECRg8+Fbeeutq+vYdRN++I4mN7cfBg5JRnE6p9FxmZGZC165TsNsXc911/enSpS9xcWNp0wa6d49i/vwl3H339YCTdu3a8957X3HrrY/x7LO/5KabBmK1+jB79pNMnHg9UVFSOdhsko7FIhmttFQK4bFjUuD69JHCVFYmFVhpKaxYIWGefFK2P/+8FPDly0UIZs2SMIsXS4vynnuk8KekyHUIC5OW78SJslxcDJs3y3kOHy4FqKAA1q+XlunIkRJvSIi0dj/5RFr7yckwaBC8/77EBVIoNm6U65aRId7G9ddLa/Hrr6WwTJgg55uXJ8du3iwF7cIL4f77xctw3bPkZKnsVqyQz7g+/rhcp6QkuTZBQdJqTU0V23v1crf4v/xSzm/yZCnMiYlSefboIZVB1bxx8qTEGxYmhX/XLjmmTx+x4euvpWKbOlUqOddxxcVyXQsKoH9/qSRclJXBkSNyLcrLZV+fPlLZFhSIh9Cnj9y78nK5R23buj3FsjLxtFJTpWLr2VPO0eGQcykqEhv69ZM4MjMlvYED5bq4bDx6VOLv0UPucVmZ5CkfH9mekSF5LSxM8pfdLnmgavE7cQIOHJBWfXCwNEiio2svZ8nJsHu3xBcdLQLle0ot5nRKq95qlUq1pETyfOfOks9c1HZdTk0vL09ENipKhK/qsTk5UqlbLLKcmSli0LZt9fOrapdL8MvKxP6qeQXk+iQlyX3o25dqnw6222sKtifw6NTZFWMK/9FaD6xl35XAr4CpyADzIq316IbiPJOps8vK0rHZjhESMhylzuzBK6dTMsLx4+5K3oWvr2Sa4GDJmIWFUmhjYiQzuLoAgoOlErDbpcIrL5dMbLVKwbZaqxdAqJ7Z7HaJLzjYXSBd6daF1lI4AwJqZtyq17G8XMJarWd0mQwGQyuhsVNne8xTUEp9AEwE2imlUoEnASuA1noxsBoRhINAMTDbU7ZUsariv+lCqLW0bNLTpXINCnK75P7+UjHn58t6TEzNijckRFpeVfH3l5ZiVdq0OcXyWloern7IqvGc2vI4FVffbEOc2voyGAzg1E4OnjhIz4ie+FjEvXA4HZXLTaHcWY7D6cDft4HCe5bw5NNHNzewXwO/9FT6teHuMjo9UcjPFxHQ2u3CBQZKd8KprnBoqIiEoSZH848SGRhJsF89rkw9FNmKyDqZhVM7CbYGExMSg1Ly7smOjB3sytxFelE6g6MHM6LDCNoHt6fYXszXSV+TWpBKeEB45W9Q9CBC/KQvweawsWLvCv5z4D8MjxnO5J6T8ff1J8QvhI6hHQH48uCXJOYkMjF2Iu2D23Mk7wg2h40gaxCdwzoTExKDQzsosZcQ6h9aze4jeUfYnr6da/tdW6PbstxZTkFZAWsPr+V/h//H+G7jmTlwJr4WX7TWbEvfxleHvmJvzl7SC9MJ8A1gXJdxzL9ofrW4knKTaB/cnmC/YI7mH+WFLS8QGRhJbHgs+3L2caLkBHPHzqVfu341ruuP6T+yOWUzR/KPEOIXQqfQTuzL2UdCVgLX97+e2UNnszd7L6sOrCI+LZ5jhceIDo6mQ0gHOoZ2JLs4m41HNtIprBPzLpzHyI4jKS0vpY1/m2oV3c6MnTy14SmS85Lx8/HjmUnPcEn3Syr3x6fFc+D4AQZEDSA+LZ7l+5aTUZSB3WFnTKcxXN33akZ3Gk374PbsydrDgRMH0FqTX5bPgeMH2Jm5k++PfU9kYCR3DLmDe0feW5kHFn67kJT8FIrsRZy0yUDe5J6TmRg7kbzSPPJK87A5bBw6cYiNRzfSI7wHT//sadoEtKGwrJC0wjR+Ov4TT214im3p2xjbeSy/u+B3vPzDy3yb8i3X9L2Gy3pcRlphGkl5SSTnJRNoDWRsp7H0bdeXyMBIdmXuYkvqFibGTuSWQbewZNsS/rntn6QWpBJkDWLlzJVc2uNSckty+Trpa7alb+NEyQkCfQOJDokmNjyW4R2G0yeyT5PKT2M5b7681q9fvwbHCWy2TMrKUggOHorF0rAe2u3SF5mT426FKyWVfnh47a331kC5sxytNb4W3xrXxKmdZBRlkF+aT5mjjPbB7aVyRZGYmFjZffTq1lf5R/w/OFFygp4RPZk9dDY3DbyJQGt1N8PhdJCUl0RSbhJljjJK7CVknswktySXcmc5dqcdm8PG+uT1bEvfRqfQTrw45UUCfQPZcGQDDqeDYL9guoR1YXiH4YzoKE+G7czYyWf7PyOufRxJuUks3raYgycOVkt7SPQQ5gyfw9I9S/nm6Dc1roO/jz8ajc1RsyM21C+UWwfdSqGtkDWH1pBTnEPbwLacKKk+6nl5z8ulwCaurPeaB/gGUFZehkZz66BbeX7y80SHRJNbksuo10ZxKPcQ88fN58+T/oxSih/Tf2TWJ7NIyEqoFkdpeSnd2nSjfXB70grTOFYow2xdwrrQOawzBWUF7MnewxPjn+Dhix/m9e2v8/r219mZuZO2gW25ZeAtvLvrXYrtxZIPkHxgtVixO+3cNPAmIgMjCfMPo1ubbnxx8AtW7JOXHv18/CqvlZ+PH53DOnM49zAhfiEU2eTpgd5te9MtvBtZJ7NIL0wnuzibYGswF3a5kF2Zu8g8Wf0ph8jASO4efjeTuk/ixuU34mvxZXSn0ezL3kdSXhJ3DLmD5yY/x6Yjm7hx+Y2UO90ju73a9qJ/u/5oNBuPbKSgrAAAX4tvtXAue/u168eYTmM4lHuIr5O+JiYkhtevfp1nvnmGzSmb6RTWiWBrcOX57D++v9Z72TeyLwdOHKBjaEdiw2PZnLIZp5b+4a5tujJr8CwWb1tMTnEOUUFRTOs7jU/3f0pOcQ4WZaFTaCdiw2PJL8snISuh8liAzmGdSS1IrVyf0msKozqO4pPETzhw4gD3jbiPt3a8RX5ZPr4WXyICIii2F3PSLkL20LiHePbSZ+vNi3XR2O6j80IUkpKSCA0NJTIysl5hsNmyKCs7SnDwECyWujvLy8tl0CgzU8YKYmJkAM9yBsMQJ20nyTyZSZA1iIiAiAZdxZziHMqd5YT6haKUwuawkVeaR2FZIWH+YUSHRBPgG1AZXmtNWmEaOcU52J12AHyUD+2D29MxtGPldUnJTyHzZCbB1mB8Lb6S+ZQvlEByZjLXjL0GpRRDFw/lRMkJLu1xKd+mfMtPx39iWMwwVt+6moSsBOZ9NY9jBcfIK82rTK82XBXSgKgBTO8/naV7lrIrcxcgBdlqsVJsL0ZXeG9rb1/LJd0vYejioezO2l0Zz8VdL2Zq76nEhMTgo3zILs7mte2vkZiTSIeQDjx68aNc2uNSokOi2ZGxg50ZO0ktSEUpxeU9L2dA1AAKygrIK80j62QWH+39iA/3fEh4QDiX9riU2wffzuSekzmSd4TNKZtRSnHwxEH+Ef8PcktyeXLCk9wy6BY2HNlAYVkhseGxBFoDOWk7ydH8oyTlJRFsDaagrIBXtr5CoDWQ+0bcx47MHaxLWseVfa7kk8RPuLTHpbQLasfH+z4mKiiKOcPnEOIXwqhOo7iwy4V8vv9z3vjxDRzaQXhAOJN7TObqvlfTLqhd5X2++7O7eXPHm0QHR5N5MpNRHUcxM24m64+s5z8//YcLOl/Ae9e/R/vg9hzNP0qPiB7kl+bz2NePsTJxJXannSJbEU7tJMQvhHkXzuPnw35Oh9AO2Bw20grT6BjaEX8ff1YdWMXShKVc1PUipvefTlRwVLX7a3PYsCgLvhZfSstL+TDhQ3KKc/D39Se/NJ+dmTv5aO9HAPSM6Mn/Zv2PbuHdKLGX8PTGp1m4eSFh/mEUlBUwquMoXrriJX46/hM9InowutPoynxrc9j4LvU7dmbsJKUghSHRQxjYfiC+Ft/KRkXVLpydGTu54aMbOHjiIFaLlX9P/zc3DLihmu37c/azPX07UcFRRARE4OfjR3RINO2D2/PDsR944IsHKHeWM7XXVPpH9addUDvGdxtPgG8AOcU5rE9ez+U9LyfUP5Sy8jLSi9LpGNoRPx+/auU+pSCF7JPZ9Gzbk46hHfn26Ld8vO9jrut/HRd1vaiyvE96ZxK7MncxtfdUHrnoEUZ0HFFZxotsRSTnJRPqF0q38G711h114VWiYLfbSU1NrfcdAACHoxC7/QT+/p1QqqanoLUMCufnixgEBYlHUN9gq1M7KSsvw6IslRW9w+lAKYVFWdBak1uaS2FZYWVXB0iFGGQNwtfHFx/lg0Lha/HFx+JDib2ErJNZNdJSSuHv40+poxQ0WJQFPx8//H39sTlslNhLCLQG4u/rj0JRWl5Kib2E8IBw2gS0qYw31D+UtoHyAlyJvYRCWyFJRUk8uOVBdv9yNzEhMQT/OZgHRj/AXyf/Fa01nyR+wm0rbyPIGkROcQ59Ivvws9ifER4QTp/IPvRs25NA30ACfAOIDokmIiCiVk/F7rDz0d6PqhWwcmc5Kfkp/Oydn9HGvw2/H/d7bv34Vt6Y9gaD2ks3T/+omg8SOLWTH9N/pH9Uf4KsQfXe+9ooLS/Fz8cPSz0PHdgcNuwO+2l1eSXmJPL4usdnneLfAAAgAElEQVT5eN/HOLWTf171T+YMn8OT659kacJS7E47YzuP5eUrXiYyKLLhCE/B7rBz28rbSCtMY8GEBUzqMaly3/Hi44QHhDfYx2132EkpSKFtYFvCA8LrDXumxKfF8/6u95k3bl5ld5yLPVl7+NUXv0Jrzac3fUqbgDZ1xHL65Jfm84cNf+CqPldV66ZqrRSUFXA49zBDY4Z6JH6vEoXGkp7+Fvv338XYsckEBFRX2/374Y475BHEyZPhmWdg2DDNsj3LuLDLhXRp06VGfH/c8EcWbFiAUzvx9/Fn2z3bCPELYdg/h6GU4rGLH+PdXe/yY8aP3D/yfv486c/kFOfw0d6P+GjvR2xP314tPn8ffx6+6GFejX+V6OBoPrv5M+LT4tFaExMSw8iOIwm0BpJRlMGHCR+SkJXAjxk/8mPGj1iUhZeueIn7Rt5XGZ9TO5m1chbv736f3m17czT/KH3b9eX7u7+v5mUAbDqyifFvj2f1LavpHdmb3i/15s1pbzJ7mHv8Pz4tnptX3MzlPS9n4WULm1QR18fShKXcvOJmAn0D6dm2Jzvv21lvhd3aOZp/lL3Ze5nSa0pLm2IwGFGojYyMd0lMnMXo0QcICupVuT0tTZ7Rttvh5ZfhpptkvOCdne9wxyd3EOoXysLLFnLviHsrW75Lti3h3v/cyw0DbuCOIXdw16d30SmsE0HWIHZn7mZw9GC+TfmWiIAI3rnuHa7qc1UNe/JK80gtSCWnOAebw8bi+MWsTFxJoG8g8ffEMyBqQKPOK680j9LyUmJCak6fYXPYmL92PikFKXQM6chvL/gtseGxtcYR8ZcInpn0DAOiBnDN0mv47uffMabzGU9H1Wi01lzwxgV8f+x7Pr5R3GuDwdA8tPgjqa0RV5eR1u5BKrsdbrwRCsryef6jb8kOPcjmlBH0j+rP7/77O0Z1HEWYfxi/WPULooKimD5gOhuPbOT+VfdzRa8r+GD6B/hafFly9RKu+1AqsaXTl3Jj3I2sOrCKIdFDavUygMonYVxc1uMyVh1YRbA1uNGC4IqnLvx8/Hjh8hcaFUfXNl0r+/uBWrtsPIlSineve5dVB1Zxbb9rz2raBoNB8DJRkMGBqqLw1FPw7dZCop8cyf3fup9u6dammzwaNutrBkQNIPbvsbzx4xtMHzCdZ795lvbB7Vk2Yxm+FU8xXdvvWhZMWIBSipkDZe6j2ryD+u1Tp31MczI4ejC7Mnfha/Glc1hnwvzDzroNvSN7Mzdy7llP12AwCN4jCoWF+B5IR9nconDiBLz4InS//zccKT/MshuWcUGXC3h7x9s8+82zPHzRwwyKHgTA7YNv5y/f/oXNKZv58uCXPD7+8crn3F08OfHJs35azcng9oP54sAXWJTltDwVg8Fw/nDujuKdLqtX0/aiXxOY5haFV16Bk92WkxT+Fg9f9DAz4mbQOawzj41/jLz5efzhkj9UHn7HkDtwaiczPpqBRVmYM2JOS52JxxgcPRiHdrA7azcD2hlRMBi8Ee8RhQB52sZS4SkUF8Pf3kjFev09jOo4iicnVG/ln/o4Zd92fbmg8wWkFaZxdd+r6RzW+ayafzYYHD24cvlsjycYDIbWgdeKwltvO8mdcCc+fmW8d/17WH0anvlt9lB5PPP+kfd71NSWondkb/x95F0L031kMHgn3jOm4BIFO2ht55Uf/gE9/seiqUsaPZfIXcPuIq59HBd2udCTlrYYvhZf4trHsT19O/3bGU/BYPBGvE8UbFBSaiOx7XN0sF3E3cPvbnQUPhaf81YQXIztNJbcktwmvWlrMBjOfbyn+6hiTmmLDV7bsAPdJpmbe/ymWT+2cz7wl8v+wuafb25pMwwGQwvhlZ7CvxI/hYLO/O5e84LUqYT4hdR41NZgMHgP3uMpVIhCkh2S1Baijv6CjjHeo4kGg8HQGLxOFL7WcspXdrirJa0xGAyGVon3NJUrRCGxuD34FHHlhJqTxxkMBoO34z2iUDHQnGwPgaJQxo1rYXsMBoOhFeI93UcVopBntUFhB9q3b2F7DAaDoRXiPaJgsaD9/CjyK8anJBqf+j9MZTAYDF6JR0VBKTVFKbVfKXVQKTW/lv1dlVLrlFI/KqV2KaWmetIeAvwpDizEz2bcBIPBYKgNj4mCUsoHeAW4AhgA3KyUOnVCnceAZVrrYcBNwKuesgegKMSfcmsZgeVRDQc2GAwGL8STnsJo4KDW+rDW2gYsBa45JYwGXF9yaQOkedAe0iOkzyjIGeHJZAwGg+GcxZOi0AlIqbKeWrGtKguA25RSqcBq4IHaIlJK3aOUildKxWdnZzfZoPRwedgqBDOvj8FgMNRGSw803wy8rbXuDEwF3lVK1bBJa71Eaz1Saz0yKqrpXT/pYRJ1uE+bJsdhMBgM5zOeFIVjQNUv1neu2FaVnwPLALTWW4AAoJ2nDEqvmNInwvfsf3vYYDAYzgU8KQpbgd5Kqe5KKT9kIPmzU8IcBSYBKKX6I6LQ9P6hBsgI1lDuR0Sgn6eSMBgMhnMaj4mClg8h/wpYA+xDnjLao5T6g1JqWkWw3wFzlFI7gQ+AO7XW2lM2pQc5oCiakOAyTyVhMBgM5zQeneZCa70aGUCuuu2JKst7gbM24cQx/3Io7EpwaMnZStJgMBjOKVp6oPmskuZnh6IYgoOLW9oUg8FgaJV4lShkWkuhsIMRBYPBYKgDrxEFm8NGrm8pFBlRMBgMhrrwGlHIKMqQhcIOBAWdbFljDAaDoZXiNaKQXpguC0UdCA4ualljDAaDoZXiPaJQVCEKhR0ICixsWWMMBoOhldIoUVBK/UYpFaaEN5RS25VSkz1tXHPSPbw7kzOvg7xYgvyMKBgMBkNtNNZTuEtrXQBMBiKA24FnPWaVBxgSM4QpqQ9ASSQhfgUtbY7BYDC0ShorCqrifyrwrtZ6T5Vt5wwF5UEABKm8FrbEYDAYWieNFYVtSqn/IqKwRikVCjg9Z5ZnKCwPJIiTWB2lLW2KwWAwtEoaO83Fz4GhwGGtdbFSqi0w23NmeYYCeyChFEKpraVNMRgMhlZJYz2FC4D9Wus8pdRtyGc08z1nlmcotPkTRgGqzN7SphgMBkOrpLGi8A+gWCk1BJnZ9BDwjses8hAFNn/xFMqMp2AwGAy10VhRKK+Y0voa4GWt9StAqOfM8gyFpX6EUmg8BYPBYKiDxopCoVLqYeRR1FUVn8y0es4sz1BYajXdRwaDwVAPjRWFmUAZ8r5CBvJpzb96zCoPUVDiW+EplLe0KQaDwdAqaZQoVAjB+0AbpdRVQKnW+pwbUygs9q3wFIwoGAwGQ200dpqLG4EfgBnAjcD3SqkbPGmYJyg4aTGegsFgMNRDY99TeBQYpbXOAlBKRQFrgeWeMqy5sdmgzGYRT8FmRMFgMBhqo7FjChaXIFRw/DSObRUUVsyBZzwFg8FgqJvGVuxfKqXWKKXuVErdCawCVjd0kFJqilJqv1LqoFJqfh1hblRK7VVK7VFK/bvxpp8e1UXB4alkDAaD4ZymUd1HWut5SqnpwLiKTUu01ivrO0Yp5QO8AlwGpAJblVKfaa33VgnTG3gYGKe1zlVKtW/KSTQGlyjIQLMRBYPBYKiNxo4poLVeAaw4jbhHAwe11ocBlFJLkZff9lYJMwd4RWudW5FGVo1YmomCitmyQynEYjOiYDAYDLVRrygopQoBXdsuQGutw+o5vBOQUmU9FRhzSpg+Fel8C/gAC7TWXzZkdFNweQoh1pMoIwoGg8FQK/WKgtba01NZ+AK9gYnIC3EblVKDtNbVPniglLoHuAega9euTUrI5SmE+BWjys65Wb8NBoPhrODJJ4iOAV2qrHeu2FaVVOAzrbVda50E/ISIRDW01ku01iO11iOjoqKaZMzFF8Pnn0O3gFQsNiMKBoPBUBueFIWtQG+lVHellB9wE/DZKWE+QbwElFLtkO6kw54wpkMHuOoqCA6woYwoGAwGQ614TBS01uXAr4A1wD5gmdZ6j1LqD0qpaRXB1gDHlVJ7gXXAPK31cU/ZBKD9fbGU1TZMYjAYDIZGP33UFLTWqznlfQat9RNVljXwYMXv7OBvxWIDrR3IU7MGg8FgcHFOvZXcHGh/KxY7iCNjMBgMhqp4oSj4VngKRhQMBoPhVLxOFPD3w2IDp7OspS0xGAyGVof3iUJgEBYblJfntrQlBoPB0OrwOlFQAcFYbGC3e/Qhp3MXmw2KilraCoPB0EJ4nygEhqLsRhTq5Kmn4KKLWtoKg8HQQnj0kdTWiCUwBG2D8vITLW1K6+TIETh6tKWtMBgMLYQXegptTPdRfRQXQ0lJS1thMBhaCK8TBUuQEYV6KS6G0lLQ5q1vg8Eb8TpRUIFB+Nig3IhC7RQXy39pacvaYTAYWgSvEwUCAgCwF2e3sCGtFJcomC4kg8Er8T5RCAwEwFlgRKFWjCgYDF6N94lC584AWNIyW9iQVooRBYPBq/E+UYiNBcDnaE7L2tFaMaJgMHg13icK3bsD4Jta0MKGtFKMKBgMXo33iUJkJM4gK/5ppTidZqbUamhtRMFg8HK8TxSUwtGlHQEZZlK8GlR9P8GIgsHglXifKADObh0ISDcvsNXA5SWcumwwGLwGrxQF3a2zeAp2M9hcjapCYDwFg8Er8UpRoHtPfIuhPNtM/FYNIwoGg9fjlaKguvcGwHn4pxa2pJVhRMFg8Ho8KgpKqSlKqf1KqYNKqfn1hJuulNJKqZGetMeFT6+Bkm5y8tlI7tzBiILB4PV4TBSUUj7AK8AVwADgZqXUgFrChQK/Ab73lC2n4tPTJQopZyvJcwMjCgaD1+NJT2E0cFBrfVhrbQOWAtfUEu6PwF+AszYtp4qIoDxEYTmacbaSPDcwomAweD2eFIVOQNWmeGrFtkqUUsOBLlrrVfVFpJS6RykVr5SKz85unonsyjr54Ztivr5WDSMKBoPX02IDzUopC/AC8LuGwmqtl2itR2qtR0ZFRTVL+vaOwVjNVBfVMaJgMHg9nhSFY0CXKuudK7a5CAUGAuuVUsnAWOCzszXYbO8Sjl9aCTidZyO5cwOXKISFGVEwGLwUT4rCVqC3Uqq7UsoPuAn4zLVTa52vtW6ntY7VWscC3wHTtNbxHrSpkvKeMVjKtHyo3iC4RCEy0oiCweCleEwUtNblwK+ANcA+YJnWeo9S6g9KqWmeSrexOPt2BUDv3dv4g/bsgbg4aKZxjVaHSxQiIowoGAxeikfHFLTWq7XWfbTWPbXWf6rY9oTW+rNawk48W14CgCVuGACOhNN4EnbzZti7F3bt8pBVLUxxMQQFQXCwmfvIYPBSvPKNZgD/jkOwRYAjYVvjD0pLk/9jx+oPd67iEoXAQOMpGAxeiteKQkBAD4q7gko8jakuXGJgRMFgMJyneLEodONkN/D5KdX9DYGGMJ6CwWA4z/FaUbBY/LD3bItPQSlkZjbuICMKBoPhPMdrRQGgvI88gcS+fY07wHQfGQyG8xyvFgXVv78sNEYU7HbIypJlIwoGg+E8xatFwRo7mPIgcCbsaDhwRsXkee3by3J5uWeNawlOFYXGjrU0J04nnDx59tM1GAyAl4tCQGAviruCc08torBkCfxU5ckkl3cwerRUXI0dhziXqCoKWoPNdvZtePNN6NoVysrOftoGg8G7RSEwsAf5g8FnUzx8+aV7x9GjcO+98Oqr7m2uQeZRo+T/fOxCqioK0DJdSNu3w4kTkJ5+9tM2GAzeLgo9SZoN9n4xcOut4PoS25o18n/okDuwEYWzg+seGFEwGFoErxYFX982WEIiOfb3ieBwwJw5ssPlNZwqCr6+MGSIrBtR8AxGFAyGFsWrRQGkC6mgfQ488gisXQvx8fIPcPiwe2rtY8egQweIiRFxON9EobxcxhBaUhS0NqJgMLQwRhQC+1BcvE+8hKAguPNOKCiAyy6TwU5Xt1FaGnTsCBaLiENtorB2LXz99Vm1v9lwTYBXVRTO9qR4OTluITKiYDC0CF4vCqGhIykrS6UsqBTuukumx/bxgXvukQCuLqS0NOhU8TXRTp1qF4W5c+V3JiQnQ1LS6R1TXAwHD9a9f+FC+M1vYPFiEby64gCZIbWlPAWXlwDuR4ANBsNZxetFISxsNACFhT9IxakUXHABDB8uAVyicOyYeApQuyjYbLB/v0ytXVradINuv11+p8Mzz8hYR20t+9JSmD8fXnoJfvELEYbaqM1TaClRCAgwnoLB0EJ4vSiEhAxDKV8KCr6HXr1g0SJ46il5Vt7XV0Th5EnIz69fFH76SfrlHQ5ISGiaMQ6HPJK5c+fpvTi2aZNU6jtqed/iwAGJ6/33xf66PirUmkRh5MjzUxQ2boT33mueuHJz5dFdg6GZ8XpR8PEJJDh4iIgCwK9+BT/7mQhCt24iCq4KyiUKnTtDUREcP+6OqKoQ/Phj04w5eFAq56IiSElp3DEOhwyOA2zdWnP//v3y368f9O3rXj+V1iIKERFi5/kgCgcOwOOPux9WeOwxuO++5nkb/tZbYcaMM4/HYDgFrxcFkC6kwsKtaO2svqNnTxGFTZtkvV8/+b/oIvl3vc8AsHu3jEWEhkprvyns3Ole3rPHvS0vr+5j9uxxTwvxww8197tEoE8fqWwTE2v3QlqLKMTGykB+VpYI3rnMr38NTz8tol1WJvfn5MmmNxqqEh8P33137l8jT1JaCsOGwYcfNu34rVsb3zhrDpzOVvHFQyMKQFjYGByOQoqLE6vvcInCa6+JIIyW8QfGjJGK6+OP3WETEqTSHT7cXeh/+OH0XPwdO+TpJnBX9mPHSguzLr6v8HAGDapdFBIToUsXGUDu108EprZvTLcGUThyRLyzDh2kgLgmIDwX2bLF/b7LV19JBeOausPVyGgqOTlyD4uLq0/F0pqpy0P1JJ98ImWq6mwFjUVruOKKM39w5HRYuFDqnDMZk2wGjCgAoaFS2Vd2Ibno2VP6brdskUdWlZLtFgtccw188YW74kxIgIEDpWWya5fMvHrhhTBvXuMN2bkT4uLkXYi9e+HbbyWDuN6bcLF1q0zMt3OniELbtnDzzdL9dKoI7d8vYgXu/8RTxA8aJwo2mzyq+9VXjT+nxuJ6R8HlKcC53YX05JMQFQUDBsB//+sWgujoMxeFqrP6NofX4WlWrZIGyTffnN1033pL/l1e9+lw+LB0D69f7+7+8zRr18pTd00RsWbEo6KglJqilNqvlDqolJpfy/4HlVJ7lVK7lFL/U0p186Q9dREU1Bcfnza1iwKAnx/MmlV93/XXS0X63//KGMDhw9JaHzZMKtPbbxfXftmyxs/6uWOHPEUUFycZ2fXOw/797vclAN5+W1qKDz8sojB6tNuLcY0vgFS0+/e7u71c/7W12hojCps2ScZ9/fXGnU9dnDxZswvr+HHZXlUUztXHUn/4QYTz97+Hq6+WRsUXX0D//tL6/OabM5uB9lwThbfflv/162vfv3gxvPxy86Z59Kjcg8BAaWCdbsW+reLb7SdOSCPvTNm+XeqJunA63WW3qd1dzYTHREEp5QO8AlwBDABuVkoNOCXYj8BIrfVgYDmw0FP21IdSFsLDL+b48c9xOu3uHS5RuP56aNeu+kETJ0J4OKxc6X6ix+UpgGSqSZMkI1TtZnKxfLlUEitXynp2tlT8Q4dK63LvXvjf/6S1CbBunfw7nRJfSIhUNAkJIggjR8r+ql1IGRnyXoLLQ+jaVR73bEgUrFYZaD9VFFatkv+vvmp6X3ZRkXRnvfBC9e2uJ4/OB0/hk09kfGnOHPGs7HYR1Isvll9OTu3eWmPZu1fuU9WuytZKfj58/rksb9lSc//rr8uj0k8/3bzp/utfIrxz50pj4+jR0zs+Pl7uIbjLXlPZsEHK53331R3m4EG5VpGR8NlnLTp9vCc9hdHAQa31Ya21DVgKXFM1gNZ6ndbaNbLyHdDZg/bUS4cO92KzpZGTU6UC79cPfv7z2vv0rVZpBS5fLo+xgohCv37g7w9t2oiX0KOHZNCqpKVJhXHokAjO7bdLVxGIKMTFSeUZHy8v0UVEuL2GzZulsl+0yP0y3Zgxkl6/ftVFoeqTRyDdXn36NNx9BLV/aGf1atmfm1vdIzkdvvlGjn/+eaksXbhevuvWTbrPoHWIwltvwZQpp9ey/+9/5V2XNm1g3Di35+USBTizLqR9++SeukThdL2OH36Au++WJ5jefbfpdjSGFStkLGXIEBkYr2rrmjUyG3F4uExF31z3W2spc5dcAldeKdtOtwtp2zZp4PXseWaikJcnvQxaiwdQ1/Q4ricHn3xSyqKrAdYSaK098gNuAF6vsn478HI94V8GHmso3hEjRmhP4HQ69JYtPfW2beMaf9CRI1oPG6Y1aB0YqHV5uWx/8kmt331Xlp96SmulJKwkpPWVV0r4vXslrMWitZ+fxJOdrfWmTbIMWq9fr/V112kdGyvH/+Y3Wvv7a11QoPX772sdFaX1iROyb/ZsrUNDtU5Lk/XFiyWOo0fdNs+YoXWvXtXPo7xc65tukrA2m2xr317re+91hzl4UPY/8YSczx/+0PjrVJV589zn9u9/u7dfd52ciyv9tm21vv9+rZcu1fqll5qW1pnidGo9YIDYunNn447Jyqp5fS6/XOJITpY4o6O1vv762o/PyZHw9aXXpYvWt92m9SuvSLyuvJWaqvWUKVp/+23dxxYUaN2hg9YhIVq3aaN1ZKQ739ZGUZHWzz+vdUlJ3WHq42c/k/z2+utia2Kie98VV2jdrZvWX3wh+1ataloap7Jtm8T3+utSNkDrv/yl7vDHjmmdkOBedzq1Dg+X/D9njlyn2q6R0+le/v57rf/0J60djuphZs3S2sdH8rHFovX8+bXb8Otfax0UpHVZmdYxMVpfdpnWpaXVw9jt9Z93AwDxujF1d2MCNeV3OqIA3IZ4Cv517L8HiAfiu3btekYXpj6OHn1Br1uHLijY1viDSkq0/r//0/qhh2rfn5QklcTvfifrH3wgl/3FF91h1q7Vul07rXv0kPXjxyVMQIBkjEWLZP2HH6RCmDbNfWzVjPnTTyIYN94o63PnSkarmlEff1wypyvDFRVJfKD1gw+6w3XrpvXtt7vX//53CXPggNYjR2o97jTEsyojRmh90UVa9+6t9Zgxsi0zU2tfX/c10loq46FDRSwtFkm3NhITRUibwqkF+FR27nQL2J//3Lg4Xff3++/d21at0vrnP3evu4TxmWdqHu8S8kGDalYKWkulDlIBbd4sy598onVurtYDB8r6zTfXbd9DD0mYLVu0XrZMljdtqh7GJcxau4XnlVcad/5V2btX8v6CBVrv2SPxvPWWO42QEK1/8Qut8/Nl39NP1x9f1bxeWioV7Q03aH3LLdX3PfKIVMSufNGhg1TOp5KVpfXdd2tttUo+271btrsaQEuWSMMFtN66tbow/O9/0gCLj5fKuk8fCff44+4wrnN21Q3Tp2sdESFl7lQuuEDKhdaSL0Drfv3kHmut9cmTWo8erfXLL9d/jeqhNYjCBcCaKusPAw/XEu5SYB/QvjHxespT0Fprmy1Xb9gQrPfurSUDnQmzZ0um27tX686dtR4+vGbLIztbWpIuOnbU+tJLZTkhwV05gdbvvVd3Wn/8o4R54QWtR40ST6Yq770n+/fskfU775RK99TWeL9+UuBcXH65ZHyttX70USl0f/ub1lddpfXYsdLqy8yU/U5n7RXaiRPuSsIldF9+KS3RqjZprfWkSbKtTRsRx7vuqhnfJ5+4r0nfvlKYG0tBgdY9e8r1qouHHhKx6tXLLYJZWdIir4vZs6Xg19f6Li+XigxEbKtyxRVS2YBUbqfyww+y7+OPpXJRSmyLi5PKbcQIaeXW1qrcv1/C3HGHrOfny/q8ee4w8fFy/D/+IesTJkh6AwZUr3gboqxM8nm7dlpnZIgAh4drfc89sn/LFol32TJZ79VLKs26eP99yQv33af1559L/gQRFpdHrbXY2KePu+xoLcsjR1aPz+EQL8bPT+Js107C2O0iNiAeR3q6O48ppfXy5XK8y7MePlzr116T5REjqp/T7bdrHRws3p/W4sGBeGc33OAu7zab5PHf/tZt36pV0jsQEKD1mjXi4Ssl595EWoMo+AKHge6AH7ATiDslzDDgENC7sfF6UhS01vqnn36t16/31SUlRxsO3FhSUuTmtmsnl3zjxoaP2bRJ6337ZNnplEL60ktSidZX4ZSVuVuMIC2hqmzfLtvvvNPdqn3ssZrxDBsm3Vxai70Wi7vFU7V7y1UA/fwko9tsWl99tXSR7N4tti5apPVHH2m9cqX7/AsKpGAHBEhLbuzY6unfdpuEXbxY6wcekMq5qmgeOiSVxIgRWi9cKB7S/fe79xcUSJquAnoqLlGyWKq36l04HFp37ar11KlyfSwWST82Vo67+GIRpao4nSLmM2bUnmZVbDbpMgOpVLTWurBQruNvfyviYrGI17dmjbuSf/ttXa0bZswYuTZDh4pQLF8u+zdsqJnmrFlSSaWnu7dNniyCqrV0o3TsKMd36SL5Vil3BeyqeOvC6RRv8777pEIEuecuLr9c8qbW4nmBiKzWcs1cnnJeXvU8/sYbYkefPnKuIPfms8/kmrVt6xaU3btlv0vUtJYu11M95ueeq37tXV7TAw+4G3FlZe70H39c6+7dpaFVVCTxua6L1SqCUlIiLX5fX/HkfHyqe99ay/W4806tw8KkUZKWpvWPP+oa3alaS0Nx8GA5d5B8fga0uCiIDUwFfqqo+B+t2PYHYFrF8logE9hR8fusoTg9LQolJcl63ToffeDA3OaNeP58udyurh1PcvKkVHR791bvCtBaCu7vf++u1EeMqBlGa60vvFBaUjk54t306iUVrSuODz7Qetcud3iXyzt6tPyHh4sIulqartZmYKC7sGVnSyFzuepV+eQTETSHQxxlbMMAABuUSURBVMZErFapUB58UOtf/UoKVHi41ocPS/g77pAKLy9PKk7XGA1o/dVX1eN2OOR8hg2Tc+vfv3qf+eHDWv/1r7rSK3O1anv3lgL629/KsqurJjFRzmnBguoVTUOUlsoYgFJSIbgq9PXrpbKbO1cqPJD/668Xm61Wt0jYbNVtd7X+/+//qqeVlSXX5Je/rL79pZck/v/+V4QlOFgqNNB64kRd2XUSEVFd7LZtk3u+erWkqbW05kEEGmp6dwsWyLlmZkqfuUsgtHaLRFKSNCjGjJEuMVf31eTJkq8PHND6zTfdeVFryc8+PpJPnnxS0sjIcO9fskTicOWVdevkWlx7bXXvxyVkrnJxKi5b5s5136epU2V5zRoJk5vr9nKt1rq9yi1b5Fp36eIW4to83ZwcrcePlzx/Op5aLbQKUfDEz9OioLXWe/ferjdsCNY2W07zRZqfL90BrkHglubjj6UP0+WNnMqkSdIa6tRJMnd8fP3x2e1uQViwQMY3OnYUEfjnP6WbCaQyqEphoQzK1yZMVXn9dREQf39pZY0aJWMxLrZulfjvvVe8j4sv1vrrr6U116WLiIWLzz+XsEuXiucF0ufvdEq3W1UvqLBQWq0uL89V2dps8hCBq+UaFCT/M2ZoXVxc/7lUpbhYhNNqlQq/bdvqXT8lJXKvbrtNWvSdOmk9c2b9cV56qZx3VVyV7t691bcnJ7vPNyxMBn0dDncfef/+Eu53v5Nz3bFD8nKXLu7jYmKkUoyJkRZzWZk0GE69pwkJcp5Tp0q+eOAB9z7XYPOYMVKpW63iDYB4nrV1R1Y9B4tFbPbxkbxbFVe3zT33yHXw9ZXrc+pYlNMp12fRIq2/+aZmOoWFco1A8rbDIeN/n35avcIuK5N88sILddusteTPCy+UrqjGNiTOACMKZ0Bh4W69bh360KE6nhTwBpYvl5bpdde5+1EbIjVVWryuApKVJV0QWktBeeQRaaWdCQ5H3S2mMWMkS0dHu1uK330nFUa/fiIkI0dKd1Xnzu5K69FH5bjp0+X/uuukG6Jqd8MDD0ilfepTOMnJ0lUxe3bT+3vz8rQeMkTSrjq431RcDwW4BpDtdqnET60sXfzsZ3LtqrZU//EPieOJJ2Q9I0Mqwu7dRaCUEg9szRrp9nH1uW/dWr9tL77oFpOPP3Zvz8hwb58zR0QiMFBE1uVZ1sctt4jn+PvfV/cStBbhHTfO3Q0zdWr1RsLp8JvfSBxV+//PEYwonCF7987S69f76sLC3WclPUMzsGKFVCSndhctXiwtsilTZCB3wgTp/nLhcMh4CMi+uh6/bOhppTMhLU26MxryyBpDSopUkK6Wd1ycrtG/X5XaRLakRMSyagW7ZYu7W65qX3lOjjQgFixo2DanU1r+Vqu0sqvSoYMMsrvSLChofJdJeXnDj2wePy7dqvWNyTVEUpI0LOrysFsxjRUFJWHPHUaOHKnjm/ri1Glgs+Xwww/9CArqw7Bh36CUmSbqnKC0VN7aPl2Ki+VFrptukpfOznVOnIB//lPero6KkokVH37Y/ZZuU/ngA1i6VP5dLzqeLiUl8rLioEHVt7//vrypf801tR9nOCOUUtu01iMbDGdEoW4yMt4lMXEWffu+SYcOs89KmgaDweAJGisKpvlbD9HRtxESMoIjR/6E09kMH0YxGAyGVo4RhXpQStGt26OUlh4iO3tZS5tjMBgMHseIQgO0a3cNQUFxHDnyZ4qLf6Ks7BydztlgMBgagRGFBlDKQrduj1JcvIcffujLli2dOX58dUubZTAYDB7Bt6UNOBdo334mFos/TmcpR4/+hcTE2YwatQs/v+iWNs1gMBiaFeMpNAKlLERFXU909C0MGPBvHI4CEhPv4lx7cstgMBgawojCaRIcHEePHgs5cWI1WVkt+9k8g8FgaG6MKDSBTp3uJyRkBIcOPUh5eWFLm2MwGAzNhhGFJqCUD336vIrNlkFy8oKWNsdgMBiaDSMKTSQsbDQdOswhNfUFDhyYi9NpA2QuqePHv6S4+KcWttBgMBhOH/P00RnQu/dLWCyBHDv2d3Jzv6Jjx3vIy9tATs5KgoLiGDVqJ0qd4VwzBoPBcBYxnsIZYLH40bv3i8TFfYzFEsDBg3M5fnw1UVEzKS7eQ1bWhzidZaSmLqK0NLWlzTUYDIYGMRPiNSMnT+7BxycUf//OxMcPw+ksJiCg+/+3d+fxcZXlAsd/z+xL9slKm7Rp0y10I2UVFQSRwgUEL6tYQK/i7gXxsgjqdUcRRK98REAEEYvsIous3iqXLrS1LW3TJc2eJmmWmUwymf28949zOk1KVySZQN/v55NP5pzzzjnPeWbOPHOWeQ/B4Mvk5Z3IwoX/wGbb985ZJFJPItFFYeFHxjlqTdOOBLpDvCzw+4/G46lCxEZ19feJRhsIBl+lvPzThMMraGq6mR07rueNN46ire1OlEoDkEz2sX796WzYcFamG42urj8QCr1+wOUppUgkesZ8vTRNO3LoojBGAoFzmTLlW8yb9xdmz76fsrIltLX9lLa223A6i9mx41rWrv0AweBrbN36eZLJXpRK0t7+c8LhVWzZcgWbN19MOj0MQDTaiGHERy2jqekWli+fxNDQRgC6u5fS0PCNA/6ozjCSdHcvJZ2OHHQd3mt7kZqm/et0URgjIkJ19fcIBM4GzJPSlZXXU1e3imOPXc+cOQ8Tj7ezfv3p9PY+QXX1DygpuYidO3/N1q1XY7fnkUh00tFxF729f2HlyhpWrKimre0O0ukIAwMraG29FaWStLb+iESih23bPk97++0Egy/vN66Ghmuor/8kTU3f3m8bpRT19Ut4661zUcoAIBZrJZ2OApBM9lNffyXh8Kp3MWOjpdNRksm+d2VeShn77frcMBK0tv6MeLzjXVmWpr3Xjek5BRFZDPwCsAP3KaVu3Wu6G/g9sAjoAy5RSjUfaJ4T+ZzC4UqnY3R23ks83sq0abcyNPQWa9YcA8CcOUvp7n6QcHgFhpHE55uJw1FIKPQaTmcxNpsHsBEInM3OnfcQCJxLX99fcLnKcLkqWLTozVF3i1NK0dHxKxoavobLVU4yGeSEE7bj8VQC0NPzBP39LzF9+m3097/E5s0XATBz5t3k5Cxk3bpTyc09gQULXmH79i/S2XkfDkchCxa8TH//X+nqehCHIx+/fx7Tp9+O01l4wHVPpQZpb7+DsrIr8HqrR+QkQnv7nbS334lSBscdtwm3u/xtz41GG/D7j8Zmc2EYCfr6nqOo6Czs9j13XYvHO2lv/znd3Q/hdJZSV7dy1HSAHTuup63tNoqLz2fu3KcO/0V8F8TjHTidpdhszqwsXzsyZP3Oa2Jei7kNOANoB94ELlNKbR7R5kvAfKXUF0TkUuACpdQlB5rv+6ko7Et9/VUYRpTa2kcYGlrLmjXH4nJNYtGiN3G7KxgYeIOWlh8SDL7M/Pl/xeerZeXKagwjRkXFZ8nP/zBbtlxBWdkSBgfXYBgxfL7ZRCIbicdbCQTOoabml6xaNZuysiXU1NxOW9vttLR8H4CcnDoSiU5crnIcjgIGB9dit3sxjDipVJDi4gvo7X2KsrIlBIOvkkjsBKCg4DREnIRCr+HxVDNv3rP4fDMwjCQtLT/EZnMxefI12O0+kskQGzYsZnBwJR7PdOrq/g+Xq2zU+MLCjxEKLaO4+DyOPtq8l0Us1kp9/acYGHgdUBQUnMa8ec+xbdsX6O5+kJKSi6mtXYqIjURiF//858nEYs3k559CKPQqlZXfYPr02zK57u9/iQ0bzsTtnkI83sIxx7xOXt6JxGIteDxmoWptvZVQaBk1Nbfj9x8NmB/imzZdhMczjZkz70bETl/fc+Tm1uH1TjvoazwwsJx0eojCwo+ya9dStmy5ivz8DzJ//gvYbO5RbROJbqLRJvLyTkBE9prWS3f3QxhGFL9/HoWFp2G3+zGMFMHgyxQUnILdvv9bZnZ1PUgo9A8cjnwCgXMpLDwVgHB4JanUAA5HAbm5ixCxk0oNEg6vpLDw9FFxmHtgBjab66DrvT9KpQmHV9DX9wJe73TKy6/c7+1vU6kB+vtfxO2uwu+fi8OR846XO1GZ5xrlXb8F8EQoCicB/62UOtMavglAKfXjEW1etNosFxEH0AWUqAME9X4vCkqpURtdT8/T+P1z8flqRrUzjERmQ2xouJadO+/lhBO24nKVs3p1HZHIBvLzP4zLVcHw8GY8nqkEAudRVnY5druX7duvoaPjF5n5lZd/mkDgPOrrP4lhxKmrW4nDkcebb87HZnNRV7ectraf0dX1AG53Fccfv5lYrIWmpluoqLiaQGAxAKHQP9i48QIMY5iKis8xNLTW+hAHt7uS3NzjGBpaSzzewZQp36a19Ud4vTMpKfkEvb1PEYlsorb2UUpKzqe5+Qc0N3+Lmpo7sdvzaGy8AcOIM3nytdhsTpqabsHrrSEabSA//4MMDLzOpElfJRA4h6amm4lENrFgwSvk53+ArVu/QGfnPdTWPkJOTh09PY/T1vYTXK6jWLhwGatXz8fpLAUgEllPXt5JuFwV9PaalxsrZVBR8TlycubR0vJDksk+DCOG1zuDdDpMItEJ2CgpuYiSkgvJyZnPwMAbhMNvEIs1A0Jx8flEIhvYufNuALzemUSj2/D5ahke3kxJySVUVf0X8XgHkchbhEL/IBh8BUhTUHAq06b9BJ9vDsPDW+jouItdux5BqT3nmdzuSqZO/R6dnfcQDi/H56tl5sxfEwr9LwMDb1BYeDpFRWfhcpXQ3Px9du68C4ejCMMYxjDiVFV9k2h0Kz09j2fmmZd3EpMmfY2mppuJxRoJBM5h9uwHcDoD9PX9le3bv4RhRJk27TZcrjJrr6yE4uKPEw6voLf3aTyeKfj9cxke3kYi0U1Z2acoLb0YEHp7n6Kp6Wai0QZAMIv96Uya9EUcjkK83um43VUAhMPLqa+/3Mon2Gw+pky5hcrKr48qpn19z9PYeBM2m5uSkouJxRoJhZZRVLSYqqqbcLmKSaUG6ey8l3B4Bfn5HyInZyGpVD82m4ecnEWk02H6+18iGHyJgYHXycs7gerqH5CTs4B0OkJ398OEQn+nuPg8vN4ZNDbewODgagoKTiMQOIdA4GxcLvP9FI93MTi4kuHhrUSjDUSjDSQSXQQC51BR8TmczmIMI04isZNg8BXa23+JYcSoqbmDsrIliAixWDu7di0lN/e4TPE+XBOhKFwILFZKfdYaXgKcoJT6yog2G6027dbwDqtN7/7m+34vCu+EYSRJpfozXXknk32k0xE8nqr9PieZDNLa+iOczlJychZQWHgGIsLg4Dri8XaKi88BIBj8m/WN8RjS6Qjbt3+F8vLPUFDwof3OOxZrobn5u3R3P4SIi1mz7sPtnkRT080kk0Hc7goqK6+nqOgM+vqep77+clKpEHZ7LrW1fyIQOMtarwRr1hxLJPIWAF7vLObN+zM+3ywA2tt/QUPDNZSWXs6cOQ+xffuXMh+4YGfu3Kcz65FKDbJ69UJiscZMnEVFi6mp+R98vhp27ryXbduuxu2upLz8Kjo77yeR6KC6+kdUVHyWhoZr6Ol5AqXiuFzlzJv3AqlUH5s3fxKfbzZVVdcTCv2dzs57SKVCmWU4HEV4vdNJpwcZHt4CCJWV1+HzHU1b28/IyVnIrFn30dHxSxobbxiVR7NY/jsuVxnNzd8llQpmptntOZSVXcGkSV/C7a4kHF5OQ8N1DA9vwm7Pp7LyOjo6fkUyucuaV431wbtHZeU3mDbtVgwjzrZtX6S7+/eIuJg69TsUFJxCJLKJxsZvkkr14fFMpbT0ctrabgMUNpuHdHoQr3cWDkcug4OrrfUtJJ0eQqkkADk5i0gmu4nH23E6y7Db/cRijYg4UMo8z+P3z6Wq6psUFZ1FT8+j7NhxHen0UCZOm82HUimUSuDxVDNjxl0olaSr63f09j6NzebDbvdjs3kQsROLNeP1zsJu9zI0tA6bzUdu7rEMDLyOzebC4QiQTg+QTg/hcpWTSOz/xlludxX5+SfT3/8CqVQIEfOLmFIJ7PZc0unBzHoXFZ1NKPQ3a+9ZrA/7BOn0QGZ+TmcJXm8NdnsOweBrQPptyywoOB3DGCYcXo7TWYrdnkMs1gQoqqpuZNq0H7/tOYfifVUURORq4GqAqqqqRS0tLWMSs/buisc7UCqFxzPloG2VSqOUetvvOFKpIYaG1uB0FuP1znjbYYqhoY34fLOx2RwoZTA4uBqlkrjdk9+23GQySDi8kkSiA79/AXl5e7YPpQyCwVfIzz8Zu91POh0jHm/D55uRaWMYKWKxRuvQWl7meSN38w0jxeDgKiKRt8jLOxG/fz4iglKKSGQTIjb8/tp9rL8iGHwVwxjG5SrH55uDw5GbmZ5I9BIMvkg8vhOHI4/S0ssyMexZdoJdux6loOAUPJ5K4vEuenoeo7DwDPz+2USjjYTDy0kmg3i91QQC/zZq+X19z+HzzcgUXXO5PfT0PEFZ2WU4HPkMDq5j164/YhgJvN5qjjrqC4g46el5DIDi4vNJp4cJBl/B75+L3z/Heh0HsdtzAEV//4uEQsuw23Pw+WZRUvKJUb/8TyZDxOMtJJNBotGtDA9vQcSNy1VORcVnRq13f//L9PU9h2HEUCqOYcTJzT2OSZO+jM3mIhZrxeksxm73EYlsprPzXlKpMDabm/Lyq8jLO55odAfRaANOZzGpVJjBwTXYbB6Kij6G1zsDESGZDNHV9QCJRBdKpSguPp/8/JPo73+RSGQzFRWfxukMoJRiaGgdfX3PEo93YLM58XiqrffC3FGxx2Kt9PU9i1JJRBy4XEfh883B75+NUgZdXQ8wMPAGhjGMzzeb0tLLRr0fD9dEKAr68JGmadoEMRF+vPYmMENEqsXc57oUeGavNs8AV1qPLwReO1BB0DRN08bWmHWIp5RKichXgBcxL0m9Xym1SUS+B6xWSj0D/BZ4SEQagH7MwqFpmqZlyZj2kqqUeh54fq9x3x7xOAZcNJYxaJqmaYdO/6JZ0zRNy9BFQdM0TcvQRUHTNE3L0EVB0zRNy9BFQdM0Tct4z915TUR6gHf6k+ZiYL9daGSRjuvw6LgO3USMCXRch+vdiGuKUqrkYI3ec0XhXyEiqw/lF33jTcd1eHRch24ixgQ6rsM1nnHpw0eapmlahi4KmqZpWsaRVhTuyXYA+6HjOjw6rkM3EWMCHdfhGre4jqhzCpqmadqBHWl7CpqmadoBHDFFQUQWi8hWEWkQkRuzGEeliPxNRDaLyCYR+U9rfJGIvCwi263/hVmIzS4i/xSRZ63hahFZaeXsT7L7tlPjG1OBiDwuIltEpF5ETpogubrWev02ishSEfFkI18icr+I7LJuWLV73D7zI6ZfWvFtEJG6cY7rNut13CAiT4lIwYhpN1lxbRWRM8czrhHTrhMRJSLF1nBW82WN/6qVs00i8tMR48cuX0qp9/0fZtfdO4BpgAtYD9RmKZYKoM56nAtsA2qBnwI3WuNvBH6Shdi+DvwReNYafhS41Hp8N/DFLMT0IPBZ67ELKMh2roBJQBPgHZGnq7KRL+DDQB2wccS4feYHOBt4AfNmyCcCK8c5ro8BDuvxT0bEVWttk26g2tpW7eMVlzW+ErOb/xageILk6yPAK4DbGi4dj3yN6Rt2ovwBJwEvjhi+Cbgp23FZsfwZOAPYClRY4yqAreMcx2TgVeA04FlrQ+gdsRGPyuE4xZRvffjKXuOznatJQBtQhNn9/LPAmdnKFzB1rw+TfeYH+A1w2b7ajUdce027AHjYejxqe7Q+nE8az7iAx4EFQPOIopDVfGF+yfjoPtqNab6OlMNHuzfi3dqtcVklIlOBY4CVQJlSqtOa1AWUjXM4dwLXA4Y1HABCavfd1bOTs2qgB/iddVjrPhHxk+VcKaU6gJ8BrUAnMACsIfv52m1/+ZlI28FnML+FQ5bjEpGPAx1KqfV7Tcp2vmYCH7IOSS4TkePGI64jpShMOCKSAzwBXKOUCo+cpszyP26XhYnIOcAupdSa8VrmIXJg7lL/Wil1DBDBPBySMd65ArCO0X8cs2gdBfiBxeMZw6HKRn4ORkRuBlLAwxMgFh/wTeDbB2ubBQ7MvdETgf8CHhURGeuFHilFoQPzmOFuk61xWSEiTsyC8LBS6klrdLeIVFjTK4Bd4xjSycB5ItIMPIJ5COkXQIGI7L47XzZy1g60K6VWWsOPYxaJbOYK4KNAk1KqRymVBJ7EzGG287Xb/vKT9e1ARK4CzgEutwpWtuOajlnc11vv/8nAWhEpz3JcYL7/n1SmVZh78cVjHdeRUhTeBGZYV4e4MO8F/Uw2ArEq/W+BeqXUHSMmPQNcaT2+EvNcw7hQSt2klJqslJqKmZvXlFKXA38DLsxGTFZcXUCbiMyyRp0ObCaLubK0AieKiM96PXfHldV8jbC//DwDXGFdVXMiMDDiMNOYE5HFmIcoz1NKDe8V76Ui4haRamAGsGo8YlJKvaWUKlVKTbXe/+2YF4J0keV8AU9jnmxGRGZiXmjRy1jna6xOmky0P8wrCbZhnqm/OYtxfBBzd34DsM76OxvzGP6rwHbMKw6KshTfqey5+mia9WZrAB7DugpinONZCKy28vU0UDgRcgV8F9gCbAQewrwSZNzzBSzFPK+RxPxA+4/95Qfz4oG7rG3gLeDYcY6rAfNY+O73/d0j2t9sxbUVOGs849prejN7TjRnO18u4A/We2wtcNp45Ev/olnTNE3LOFIOH2mapmmHQBcFTdM0LUMXBU3TNC1DFwVN0zQtQxcFTdM0LUMXBU0bRyJyqli90GraRKSLgqZpmpahi4Km7YOIfEpEVonIOhH5jZj3mhgSkZ9bfdu/KiIlVtuFIrJixH0Cdt+/oEZEXhGR9SKyVkSmW7PPkT33iHh4PPqz0bRDpYuCpu1FROYAlwAnK6UWAmngcsyO71YrpY4GlgHfsZ7ye+AGpdR8zF++7h7/MHCXUmoB8AHMX6yC2TPuNZj94k/D7DdJ0yYEx8GbaNoR53RgEfCm9SXei9mpnAH8yWrzB+BJEckHCpRSy6zxDwKPiUguMEkp9RSAUioGYM1vlVKq3Rpeh9mP/utjv1qadnC6KGja2wnwoFLqplEjRb61V7t32kdMfMTjNHo71CYQffhI097uVeBCESmFzD2Pp2BuL7t7Qf0k8LpSagAIisiHrPFLgGVKqUGgXUTOt+bhtvru17QJTX9D0bS9KKU2i8gtwEsiYsPsufLLmDf5Od6atgvzvAOY3VPfbX3oNwKftsYvAX4jIt+z5nHROK6Gpr0jupdUTTtEIjKklMrJdhyaNpb04SNN0zQtQ+8paJqmaRl6T0HTNE3L0EVB0zRNy9BFQdM0TcvQRUHTNE3L0EVB0zRNy9BFQdM0Tcv4f5iOASTgRTQVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.1884 - acc: 0.9578\n",
      "Loss: 0.18837949702224133 Accuracy: 0.9578401\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1443 - acc: 0.6513\n",
      "Epoch 00001: val_loss improved from inf to 0.72080, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_12_conv_checkpoint/001-0.7208.hdf5\n",
      "36805/36805 [==============================] - 176s 5ms/sample - loss: 1.1442 - acc: 0.6513 - val_loss: 0.7208 - val_acc: 0.7815\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4206 - acc: 0.8742\n",
      "Epoch 00002: val_loss improved from 0.72080 to 0.37150, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_12_conv_checkpoint/002-0.3715.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.4206 - acc: 0.8743 - val_loss: 0.3715 - val_acc: 0.8898\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2847 - acc: 0.9142\n",
      "Epoch 00003: val_loss did not improve from 0.37150\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.2848 - acc: 0.9142 - val_loss: 0.4139 - val_acc: 0.8758\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2214 - acc: 0.9323\n",
      "Epoch 00004: val_loss improved from 0.37150 to 0.26694, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_12_conv_checkpoint/004-0.2669.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.2214 - acc: 0.9323 - val_loss: 0.2669 - val_acc: 0.9161\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1688 - acc: 0.9483\n",
      "Epoch 00005: val_loss improved from 0.26694 to 0.22850, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_12_conv_checkpoint/005-0.2285.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1688 - acc: 0.9483 - val_loss: 0.2285 - val_acc: 0.9292\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9569\n",
      "Epoch 00006: val_loss did not improve from 0.22850\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1421 - acc: 0.9569 - val_loss: 0.2463 - val_acc: 0.9280\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9645\n",
      "Epoch 00007: val_loss improved from 0.22850 to 0.21799, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_12_conv_checkpoint/007-0.2180.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1184 - acc: 0.9645 - val_loss: 0.2180 - val_acc: 0.9329\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9690\n",
      "Epoch 00008: val_loss did not improve from 0.21799\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1044 - acc: 0.9689 - val_loss: 0.2407 - val_acc: 0.9280\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9698\n",
      "Epoch 00009: val_loss improved from 0.21799 to 0.17089, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_12_conv_checkpoint/009-0.1709.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0982 - acc: 0.9697 - val_loss: 0.1709 - val_acc: 0.9481\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9721\n",
      "Epoch 00010: val_loss improved from 0.17089 to 0.15420, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_12_conv_checkpoint/010-0.1542.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0932 - acc: 0.9722 - val_loss: 0.1542 - val_acc: 0.9548\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9822\n",
      "Epoch 00011: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0622 - acc: 0.9821 - val_loss: 0.2002 - val_acc: 0.9436\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9778\n",
      "Epoch 00012: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0749 - acc: 0.9778 - val_loss: 0.2845 - val_acc: 0.9201\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9828\n",
      "Epoch 00013: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0589 - acc: 0.9828 - val_loss: 0.2271 - val_acc: 0.9338\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9896\n",
      "Epoch 00014: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0403 - acc: 0.9896 - val_loss: 0.2322 - val_acc: 0.9324\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9904\n",
      "Epoch 00015: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0367 - acc: 0.9904 - val_loss: 0.1734 - val_acc: 0.9504\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9872\n",
      "Epoch 00016: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0433 - acc: 0.9872 - val_loss: 0.2150 - val_acc: 0.9429\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9874\n",
      "Epoch 00017: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0433 - acc: 0.9874 - val_loss: 0.1645 - val_acc: 0.9520\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9927\n",
      "Epoch 00018: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0283 - acc: 0.9927 - val_loss: 0.2818 - val_acc: 0.9269\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9892\n",
      "Epoch 00019: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0374 - acc: 0.9892 - val_loss: 0.1960 - val_acc: 0.9460\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9893\n",
      "Epoch 00020: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0387 - acc: 0.9893 - val_loss: 0.1807 - val_acc: 0.9492\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9929\n",
      "Epoch 00021: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0267 - acc: 0.9929 - val_loss: 0.1794 - val_acc: 0.9532\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9961\n",
      "Epoch 00022: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0177 - acc: 0.9961 - val_loss: 0.1929 - val_acc: 0.9483\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9941\n",
      "Epoch 00023: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0239 - acc: 0.9940 - val_loss: 0.1961 - val_acc: 0.9471\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9885\n",
      "Epoch 00024: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0375 - acc: 0.9885 - val_loss: 0.1966 - val_acc: 0.9467\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9961\n",
      "Epoch 00025: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0151 - acc: 0.9961 - val_loss: 0.2066 - val_acc: 0.9471\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9967\n",
      "Epoch 00026: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0142 - acc: 0.9967 - val_loss: 0.1853 - val_acc: 0.9548\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9959\n",
      "Epoch 00027: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0154 - acc: 0.9959 - val_loss: 0.1739 - val_acc: 0.9534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9949\n",
      "Epoch 00028: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0175 - acc: 0.9949 - val_loss: 0.2169 - val_acc: 0.9455\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9939\n",
      "Epoch 00029: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0205 - acc: 0.9939 - val_loss: 0.2511 - val_acc: 0.9357\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9945\n",
      "Epoch 00030: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0189 - acc: 0.9945 - val_loss: 0.3031 - val_acc: 0.9334\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9967\n",
      "Epoch 00031: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0127 - acc: 0.9967 - val_loss: 0.1808 - val_acc: 0.9539\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9966\n",
      "Epoch 00032: val_loss did not improve from 0.15420\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0125 - acc: 0.9966 - val_loss: 0.2780 - val_acc: 0.9366\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9916\n",
      "Epoch 00033: val_loss improved from 0.15420 to 0.14625, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_12_conv_checkpoint/033-0.1462.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0265 - acc: 0.9916 - val_loss: 0.1462 - val_acc: 0.9595\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9955\n",
      "Epoch 00034: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0170 - acc: 0.9955 - val_loss: 0.1508 - val_acc: 0.9620\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9989\n",
      "Epoch 00035: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0058 - acc: 0.9989 - val_loss: 0.1602 - val_acc: 0.9599\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9985\n",
      "Epoch 00036: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0069 - acc: 0.9985 - val_loss: 0.1964 - val_acc: 0.9509\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9961\n",
      "Epoch 00037: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0141 - acc: 0.9961 - val_loss: 0.2521 - val_acc: 0.9371\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9949\n",
      "Epoch 00038: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0169 - acc: 0.9949 - val_loss: 0.2055 - val_acc: 0.9509\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9977\n",
      "Epoch 00039: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0086 - acc: 0.9977 - val_loss: 0.1927 - val_acc: 0.9588\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9936\n",
      "Epoch 00040: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0224 - acc: 0.9936 - val_loss: 0.1633 - val_acc: 0.9585\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9982\n",
      "Epoch 00041: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0074 - acc: 0.9982 - val_loss: 0.1596 - val_acc: 0.9630\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9974\n",
      "Epoch 00042: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0098 - acc: 0.9974 - val_loss: 0.2326 - val_acc: 0.9420\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9988\n",
      "Epoch 00043: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0060 - acc: 0.9988 - val_loss: 0.1628 - val_acc: 0.9588\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9964\n",
      "Epoch 00044: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0123 - acc: 0.9964 - val_loss: 0.1661 - val_acc: 0.9630\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9943\n",
      "Epoch 00045: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0176 - acc: 0.9943 - val_loss: 0.1743 - val_acc: 0.9585\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9975\n",
      "Epoch 00046: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0097 - acc: 0.9975 - val_loss: 0.1499 - val_acc: 0.9648\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 00047: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0039 - acc: 0.9992 - val_loss: 0.1676 - val_acc: 0.9641\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9946\n",
      "Epoch 00048: val_loss did not improve from 0.14625\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0173 - acc: 0.9946 - val_loss: 0.1734 - val_acc: 0.9576\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9993\n",
      "Epoch 00049: val_loss improved from 0.14625 to 0.14199, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_12_conv_checkpoint/049-0.1420.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0034 - acc: 0.9993 - val_loss: 0.1420 - val_acc: 0.9683\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9985\n",
      "Epoch 00050: val_loss did not improve from 0.14199\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0059 - acc: 0.9985 - val_loss: 0.2043 - val_acc: 0.9536\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9982\n",
      "Epoch 00051: val_loss did not improve from 0.14199\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0069 - acc: 0.9982 - val_loss: 0.1920 - val_acc: 0.9557\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9969\n",
      "Epoch 00052: val_loss did not improve from 0.14199\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0104 - acc: 0.9969 - val_loss: 0.1791 - val_acc: 0.9588\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9973\n",
      "Epoch 00053: val_loss did not improve from 0.14199\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0097 - acc: 0.9973 - val_loss: 0.2843 - val_acc: 0.9448\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9974\n",
      "Epoch 00054: val_loss did not improve from 0.14199\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0091 - acc: 0.9974 - val_loss: 0.1529 - val_acc: 0.9648\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9977\n",
      "Epoch 00055: val_loss did not improve from 0.14199\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0082 - acc: 0.9977 - val_loss: 0.1622 - val_acc: 0.9648\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9991\n",
      "Epoch 00056: val_loss did not improve from 0.14199\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0040 - acc: 0.9991 - val_loss: 0.1947 - val_acc: 0.9606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9978\n",
      "Epoch 00057: val_loss did not improve from 0.14199\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0075 - acc: 0.9978 - val_loss: 0.2187 - val_acc: 0.9499\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9987\n",
      "Epoch 00058: val_loss did not improve from 0.14199\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0048 - acc: 0.9987 - val_loss: 0.1605 - val_acc: 0.9639\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9983\n",
      "Epoch 00059: val_loss did not improve from 0.14199\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0074 - acc: 0.9982 - val_loss: 0.2587 - val_acc: 0.9441\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9939\n",
      "Epoch 00060: val_loss did not improve from 0.14199\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0202 - acc: 0.9939 - val_loss: 0.1470 - val_acc: 0.9672\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9995\n",
      "Epoch 00061: val_loss improved from 0.14199 to 0.12419, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_12_conv_checkpoint/061-0.1242.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0025 - acc: 0.9995 - val_loss: 0.1242 - val_acc: 0.9732\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 00062: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0017 - acc: 0.9998 - val_loss: 0.1540 - val_acc: 0.9690\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9989\n",
      "Epoch 00063: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0047 - acc: 0.9988 - val_loss: 0.1779 - val_acc: 0.9592\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9952\n",
      "Epoch 00064: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0157 - acc: 0.9952 - val_loss: 0.1291 - val_acc: 0.9690\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9994\n",
      "Epoch 00065: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0031 - acc: 0.9994 - val_loss: 0.1578 - val_acc: 0.9639\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00066: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1370 - val_acc: 0.9706\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9994\n",
      "Epoch 00067: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0030 - acc: 0.9994 - val_loss: 0.1359 - val_acc: 0.9669\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9960\n",
      "Epoch 00068: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0120 - acc: 0.9960 - val_loss: 0.2153 - val_acc: 0.9488\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9959\n",
      "Epoch 00069: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0131 - acc: 0.9959 - val_loss: 0.1410 - val_acc: 0.9639\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 00070: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0018 - acc: 0.9996 - val_loss: 0.1367 - val_acc: 0.9686\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 00071: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0019 - acc: 0.9996 - val_loss: 0.1393 - val_acc: 0.9676\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9960\n",
      "Epoch 00072: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0143 - acc: 0.9960 - val_loss: 0.1315 - val_acc: 0.9700\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9973\n",
      "Epoch 00073: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0096 - acc: 0.9973 - val_loss: 0.1308 - val_acc: 0.9704\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9995\n",
      "Epoch 00074: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0024 - acc: 0.9995 - val_loss: 0.1295 - val_acc: 0.9723\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 00075: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0012 - acc: 0.9999 - val_loss: 0.1276 - val_acc: 0.9723\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9999\n",
      "Epoch 00076: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0010 - acc: 0.9999 - val_loss: 0.1280 - val_acc: 0.9727\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9974\n",
      "Epoch 00077: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0084 - acc: 0.9974 - val_loss: 0.3539 - val_acc: 0.9266\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9973\n",
      "Epoch 00078: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0080 - acc: 0.9973 - val_loss: 0.1426 - val_acc: 0.9700\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9990\n",
      "Epoch 00079: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0039 - acc: 0.9990 - val_loss: 0.1658 - val_acc: 0.9623\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9980\n",
      "Epoch 00080: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0070 - acc: 0.9980 - val_loss: 0.1437 - val_acc: 0.9702\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9982\n",
      "Epoch 00081: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0065 - acc: 0.9982 - val_loss: 0.1693 - val_acc: 0.9658\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9974\n",
      "Epoch 00082: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0088 - acc: 0.9974 - val_loss: 0.1404 - val_acc: 0.9693\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 00083: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0019 - acc: 0.9996 - val_loss: 0.1445 - val_acc: 0.9704\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 00084: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0017 - acc: 0.9997 - val_loss: 0.1370 - val_acc: 0.9716\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.7127e-04 - acc: 0.9999\n",
      "Epoch 00085: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 6.8310e-04 - acc: 0.9999 - val_loss: 0.1549 - val_acc: 0.9681\n",
      "Epoch 86/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9945\n",
      "Epoch 00086: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0167 - acc: 0.9945 - val_loss: 0.1634 - val_acc: 0.9672\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9986\n",
      "Epoch 00087: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0049 - acc: 0.9986 - val_loss: 0.1374 - val_acc: 0.9720\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 00088: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0015 - acc: 0.9998 - val_loss: 0.1454 - val_acc: 0.9725\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 00089: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0013 - acc: 0.9998 - val_loss: 0.1702 - val_acc: 0.9644\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9964\n",
      "Epoch 00090: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0116 - acc: 0.9964 - val_loss: 0.1553 - val_acc: 0.9679\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9978\n",
      "Epoch 00091: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0069 - acc: 0.9978 - val_loss: 0.1518 - val_acc: 0.9662\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9997\n",
      "Epoch 00092: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0019 - acc: 0.9997 - val_loss: 0.1359 - val_acc: 0.9725\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.7867e-04 - acc: 0.9999\n",
      "Epoch 00093: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0010 - acc: 0.9999 - val_loss: 0.1395 - val_acc: 0.9690\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9972\n",
      "Epoch 00094: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0096 - acc: 0.9972 - val_loss: 0.1443 - val_acc: 0.9674\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9997\n",
      "Epoch 00095: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0018 - acc: 0.9997 - val_loss: 0.1332 - val_acc: 0.9713\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9987\n",
      "Epoch 00096: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0043 - acc: 0.9987 - val_loss: 0.1562 - val_acc: 0.9672\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 00097: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0036 - acc: 0.9990 - val_loss: 0.1473 - val_acc: 0.9637\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9974\n",
      "Epoch 00098: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0085 - acc: 0.9974 - val_loss: 0.1498 - val_acc: 0.9665\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 00099: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0025 - acc: 0.9993 - val_loss: 0.1559 - val_acc: 0.9697\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 00100: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0018 - acc: 0.9996 - val_loss: 0.1400 - val_acc: 0.9704\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 00101: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0028 - acc: 0.9993 - val_loss: 0.2302 - val_acc: 0.9529\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9978\n",
      "Epoch 00102: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0076 - acc: 0.9978 - val_loss: 0.1521 - val_acc: 0.9653\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 00103: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0036 - acc: 0.9990 - val_loss: 0.1697 - val_acc: 0.9662\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 00104: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0037 - acc: 0.9990 - val_loss: 0.1801 - val_acc: 0.9611\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9984\n",
      "Epoch 00105: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0054 - acc: 0.9984 - val_loss: 0.1676 - val_acc: 0.9648\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9994\n",
      "Epoch 00106: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0028 - acc: 0.9994 - val_loss: 0.1452 - val_acc: 0.9718\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9992\n",
      "Epoch 00107: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0035 - acc: 0.9992 - val_loss: 0.2026 - val_acc: 0.9602\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9967\n",
      "Epoch 00108: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0110 - acc: 0.9967 - val_loss: 0.1540 - val_acc: 0.9662\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 00109: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0012 - acc: 0.9998 - val_loss: 0.1578 - val_acc: 0.9683\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9975\n",
      "Epoch 00110: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0080 - acc: 0.9975 - val_loss: 0.1461 - val_acc: 0.9683\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9984\n",
      "Epoch 00111: val_loss did not improve from 0.12419\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0057 - acc: 0.9984 - val_loss: 0.1281 - val_acc: 0.9716\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_12_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.1705 - acc: 0.9583\n",
      "Loss: 0.17051000813852032 Accuracy: 0.95825547\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9678 - acc: 0.6970\n",
      "Epoch 00001: val_loss improved from inf to 0.68262, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_13_conv_checkpoint/001-0.6826.hdf5\n",
      "36805/36805 [==============================] - 176s 5ms/sample - loss: 0.9677 - acc: 0.6971 - val_loss: 0.6826 - val_acc: 0.7808\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3561 - acc: 0.8877\n",
      "Epoch 00002: val_loss improved from 0.68262 to 0.27574, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_13_conv_checkpoint/002-0.2757.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.3561 - acc: 0.8877 - val_loss: 0.2757 - val_acc: 0.9168\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2388 - acc: 0.9239\n",
      "Epoch 00003: val_loss did not improve from 0.27574\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.2388 - acc: 0.9239 - val_loss: 0.3321 - val_acc: 0.8961\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1769 - acc: 0.9434\n",
      "Epoch 00004: val_loss improved from 0.27574 to 0.26281, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_13_conv_checkpoint/004-0.2628.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.1769 - acc: 0.9434 - val_loss: 0.2628 - val_acc: 0.9178\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1446 - acc: 0.9545\n",
      "Epoch 00005: val_loss improved from 0.26281 to 0.24388, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_13_conv_checkpoint/005-0.2439.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.1447 - acc: 0.9545 - val_loss: 0.2439 - val_acc: 0.9271\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9610\n",
      "Epoch 00006: val_loss did not improve from 0.24388\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.1232 - acc: 0.9610 - val_loss: 0.3790 - val_acc: 0.8921\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9659\n",
      "Epoch 00007: val_loss improved from 0.24388 to 0.22050, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_13_conv_checkpoint/007-0.2205.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.1072 - acc: 0.9658 - val_loss: 0.2205 - val_acc: 0.9334\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9663\n",
      "Epoch 00008: val_loss improved from 0.22050 to 0.19713, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_13_conv_checkpoint/008-0.1971.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.1047 - acc: 0.9663 - val_loss: 0.1971 - val_acc: 0.9432\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9783\n",
      "Epoch 00009: val_loss did not improve from 0.19713\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0687 - acc: 0.9783 - val_loss: 0.3211 - val_acc: 0.9059\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9801\n",
      "Epoch 00010: val_loss improved from 0.19713 to 0.16935, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_13_conv_checkpoint/010-0.1694.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0636 - acc: 0.9801 - val_loss: 0.1694 - val_acc: 0.9492\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9825\n",
      "Epoch 00011: val_loss did not improve from 0.16935\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0572 - acc: 0.9825 - val_loss: 0.2018 - val_acc: 0.9362\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9844\n",
      "Epoch 00012: val_loss improved from 0.16935 to 0.15844, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_13_conv_checkpoint/012-0.1584.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0520 - acc: 0.9844 - val_loss: 0.1584 - val_acc: 0.9511\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9846\n",
      "Epoch 00013: val_loss did not improve from 0.15844\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0502 - acc: 0.9845 - val_loss: 0.2547 - val_acc: 0.9294\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9789\n",
      "Epoch 00014: val_loss did not improve from 0.15844\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0685 - acc: 0.9789 - val_loss: 0.1918 - val_acc: 0.9464\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9860\n",
      "Epoch 00015: val_loss did not improve from 0.15844\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0447 - acc: 0.9860 - val_loss: 0.1613 - val_acc: 0.9546\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9924\n",
      "Epoch 00016: val_loss improved from 0.15844 to 0.15363, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_13_conv_checkpoint/016-0.1536.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0268 - acc: 0.9924 - val_loss: 0.1536 - val_acc: 0.9602\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9891\n",
      "Epoch 00017: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0364 - acc: 0.9891 - val_loss: 0.2067 - val_acc: 0.9418\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9923\n",
      "Epoch 00018: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0261 - acc: 0.9923 - val_loss: 0.2237 - val_acc: 0.9467\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9907\n",
      "Epoch 00019: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0302 - acc: 0.9907 - val_loss: 0.2161 - val_acc: 0.9443\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9936\n",
      "Epoch 00020: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0212 - acc: 0.9936 - val_loss: 0.1581 - val_acc: 0.9569\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9879\n",
      "Epoch 00021: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0374 - acc: 0.9879 - val_loss: 0.1951 - val_acc: 0.9492\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9949\n",
      "Epoch 00022: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0176 - acc: 0.9949 - val_loss: 0.2161 - val_acc: 0.9420\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9887\n",
      "Epoch 00023: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0351 - acc: 0.9887 - val_loss: 0.1741 - val_acc: 0.9527\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9962\n",
      "Epoch 00024: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0146 - acc: 0.9962 - val_loss: 0.1551 - val_acc: 0.9590\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9963\n",
      "Epoch 00025: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0142 - acc: 0.9963 - val_loss: 0.1674 - val_acc: 0.9583\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9899\n",
      "Epoch 00026: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0312 - acc: 0.9899 - val_loss: 0.1828 - val_acc: 0.9522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9976\n",
      "Epoch 00027: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0105 - acc: 0.9976 - val_loss: 0.1725 - val_acc: 0.9539\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 00028: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0161 - acc: 0.9951 - val_loss: 0.2132 - val_acc: 0.9506\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9920\n",
      "Epoch 00029: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0259 - acc: 0.9920 - val_loss: 0.1545 - val_acc: 0.9588\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9973\n",
      "Epoch 00030: val_loss did not improve from 0.15363\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0110 - acc: 0.9973 - val_loss: 0.1752 - val_acc: 0.9583\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9977\n",
      "Epoch 00031: val_loss improved from 0.15363 to 0.14608, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_13_conv_checkpoint/031-0.1461.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0095 - acc: 0.9977 - val_loss: 0.1461 - val_acc: 0.9618\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9928\n",
      "Epoch 00032: val_loss did not improve from 0.14608\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0220 - acc: 0.9928 - val_loss: 0.1654 - val_acc: 0.9553\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9972\n",
      "Epoch 00033: val_loss did not improve from 0.14608\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0103 - acc: 0.9972 - val_loss: 0.1934 - val_acc: 0.9576\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9912\n",
      "Epoch 00034: val_loss did not improve from 0.14608\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0282 - acc: 0.9912 - val_loss: 0.1676 - val_acc: 0.9546\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9985\n",
      "Epoch 00035: val_loss improved from 0.14608 to 0.12655, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_13_conv_checkpoint/035-0.1266.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0061 - acc: 0.9985 - val_loss: 0.1266 - val_acc: 0.9679\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9989\n",
      "Epoch 00036: val_loss did not improve from 0.12655\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0046 - acc: 0.9989 - val_loss: 0.1609 - val_acc: 0.9613\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9958\n",
      "Epoch 00037: val_loss did not improve from 0.12655\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0142 - acc: 0.9958 - val_loss: 0.3508 - val_acc: 0.9255\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9919\n",
      "Epoch 00038: val_loss did not improve from 0.12655\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0255 - acc: 0.9918 - val_loss: 0.1497 - val_acc: 0.9632\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9952\n",
      "Epoch 00039: val_loss improved from 0.12655 to 0.11908, saving model to model/checkpoint/1D_CNN_custom_pool_2_BN_13_conv_checkpoint/039-0.1191.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0159 - acc: 0.9951 - val_loss: 0.1191 - val_acc: 0.9665\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9976\n",
      "Epoch 00040: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0092 - acc: 0.9976 - val_loss: 0.1265 - val_acc: 0.9700\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 00041: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0042 - acc: 0.9990 - val_loss: 0.1575 - val_acc: 0.9634\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9975\n",
      "Epoch 00042: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0087 - acc: 0.9975 - val_loss: 0.2262 - val_acc: 0.9481\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9960\n",
      "Epoch 00043: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0140 - acc: 0.9960 - val_loss: 0.1787 - val_acc: 0.9595\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9950\n",
      "Epoch 00044: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0155 - acc: 0.9949 - val_loss: 0.1517 - val_acc: 0.9613\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9945\n",
      "Epoch 00045: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0191 - acc: 0.9945 - val_loss: 0.1416 - val_acc: 0.9658\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9971\n",
      "Epoch 00046: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0103 - acc: 0.9971 - val_loss: 0.1477 - val_acc: 0.9686\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9996\n",
      "Epoch 00047: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0025 - acc: 0.9996 - val_loss: 0.1275 - val_acc: 0.9693\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9968\n",
      "Epoch 00048: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0115 - acc: 0.9968 - val_loss: 0.2355 - val_acc: 0.9460\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9979\n",
      "Epoch 00049: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0073 - acc: 0.9979 - val_loss: 0.1624 - val_acc: 0.9637\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9978\n",
      "Epoch 00050: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0072 - acc: 0.9978 - val_loss: 0.2176 - val_acc: 0.9515\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9946\n",
      "Epoch 00051: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0205 - acc: 0.9946 - val_loss: 0.1436 - val_acc: 0.9665\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9990\n",
      "Epoch 00052: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0045 - acc: 0.9990 - val_loss: 0.1533 - val_acc: 0.9653\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9987\n",
      "Epoch 00053: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0044 - acc: 0.9988 - val_loss: 0.2337 - val_acc: 0.9488\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9970\n",
      "Epoch 00054: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0098 - acc: 0.9970 - val_loss: 0.1638 - val_acc: 0.9620\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9973\n",
      "Epoch 00055: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0089 - acc: 0.9973 - val_loss: 0.2952 - val_acc: 0.9352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9974\n",
      "Epoch 00056: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0086 - acc: 0.9974 - val_loss: 0.1490 - val_acc: 0.9655\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 00057: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0036 - acc: 0.9990 - val_loss: 0.1372 - val_acc: 0.9651\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9977\n",
      "Epoch 00058: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0076 - acc: 0.9977 - val_loss: 0.3164 - val_acc: 0.9415\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9952\n",
      "Epoch 00059: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0148 - acc: 0.9952 - val_loss: 0.2225 - val_acc: 0.9506\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 00060: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0037 - acc: 0.9990 - val_loss: 0.1503 - val_acc: 0.9665\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9985\n",
      "Epoch 00061: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0057 - acc: 0.9985 - val_loss: 0.1980 - val_acc: 0.9569\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9974\n",
      "Epoch 00062: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0078 - acc: 0.9974 - val_loss: 0.1426 - val_acc: 0.9695\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 00063: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0028 - acc: 0.9993 - val_loss: 0.1996 - val_acc: 0.9548\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9983\n",
      "Epoch 00064: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0068 - acc: 0.9983 - val_loss: 0.2105 - val_acc: 0.9567\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9955\n",
      "Epoch 00065: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0133 - acc: 0.9955 - val_loss: 0.1951 - val_acc: 0.9569\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9968\n",
      "Epoch 00066: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0100 - acc: 0.9968 - val_loss: 0.1495 - val_acc: 0.9676\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9993\n",
      "Epoch 00067: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0024 - acc: 0.9993 - val_loss: 0.1503 - val_acc: 0.9686\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9997\n",
      "Epoch 00068: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0016 - acc: 0.9997 - val_loss: 0.1349 - val_acc: 0.9723\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9973\n",
      "Epoch 00069: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0090 - acc: 0.9973 - val_loss: 0.1786 - val_acc: 0.9639\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9970\n",
      "Epoch 00070: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0100 - acc: 0.9970 - val_loss: 0.1397 - val_acc: 0.9700\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 00071: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0029 - acc: 0.9992 - val_loss: 0.1519 - val_acc: 0.9641\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9990\n",
      "Epoch 00072: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0036 - acc: 0.9989 - val_loss: 0.1724 - val_acc: 0.9658\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9957\n",
      "Epoch 00073: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0142 - acc: 0.9957 - val_loss: 0.1303 - val_acc: 0.9706\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9990\n",
      "Epoch 00074: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0032 - acc: 0.9990 - val_loss: 0.1773 - val_acc: 0.9620\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9963\n",
      "Epoch 00075: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0112 - acc: 0.9963 - val_loss: 0.1768 - val_acc: 0.9630\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 00076: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0028 - acc: 0.9993 - val_loss: 0.1558 - val_acc: 0.9658\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9997\n",
      "Epoch 00077: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0018 - acc: 0.9997 - val_loss: 0.1385 - val_acc: 0.9697\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 00078: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.1679 - val_acc: 0.9627\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9954\n",
      "Epoch 00079: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0136 - acc: 0.9954 - val_loss: 0.1624 - val_acc: 0.9667\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994\n",
      "Epoch 00080: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0027 - acc: 0.9994 - val_loss: 0.1414 - val_acc: 0.9718\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 00081: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0055 - acc: 0.9983 - val_loss: 0.1629 - val_acc: 0.9667\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9948\n",
      "Epoch 00082: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0168 - acc: 0.9948 - val_loss: 0.1435 - val_acc: 0.9679\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 00083: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0020 - acc: 0.9995 - val_loss: 0.1449 - val_acc: 0.9674\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9974\n",
      "Epoch 00084: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0085 - acc: 0.9974 - val_loss: 0.1393 - val_acc: 0.9693\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 00085: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0013 - acc: 0.9998 - val_loss: 0.1219 - val_acc: 0.9723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.8139e-04 - acc: 0.9998\n",
      "Epoch 00086: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0011 - acc: 0.9998 - val_loss: 0.1316 - val_acc: 0.9718\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9968\n",
      "Epoch 00087: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0107 - acc: 0.9968 - val_loss: 0.1364 - val_acc: 0.9704\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9992\n",
      "Epoch 00088: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0037 - acc: 0.9991 - val_loss: 0.1347 - val_acc: 0.9723\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9980\n",
      "Epoch 00089: val_loss did not improve from 0.11908\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0066 - acc: 0.9980 - val_loss: 0.1300 - val_acc: 0.9723\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_13_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.1679 - acc: 0.9578\n",
      "Loss: 0.16788074450600246 Accuracy: 0.9578401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 14):\n",
    "    base = '1D_CNN_custom_pool_2_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_BN_2(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 256000)            1024000   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 5,162,256\n",
      "Trainable params: 4,649,872\n",
      "Non-trainable params: 512,384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 2.5690 - acc: 0.3799\n",
      "Loss: 2.569016988304669 Accuracy: 0.37985462\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 128000)            512000    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,623,056\n",
      "Trainable params: 2,366,544\n",
      "Non-trainable params: 256,512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 1.9381 - acc: 0.5375\n",
      "Loss: 1.9381323531656869 Accuracy: 0.53748703\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 128000)            512000    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,664,656\n",
      "Trainable params: 2,407,888\n",
      "Non-trainable params: 256,768\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.9277 - acc: 0.5751\n",
      "Loss: 1.927673839037292 Accuracy: 0.5750779\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 64000)             256000    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,467,216\n",
      "Trainable params: 1,338,192\n",
      "Non-trainable params: 129,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.3118 - acc: 0.6638\n",
      "Loss: 1.3117821176970612 Accuracy: 0.6637591\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_109 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 32000)             128000    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 909,776\n",
      "Trainable params: 844,496\n",
      "Non-trainable params: 65,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 1.0674 - acc: 0.7148\n",
      "Loss: 1.0673616539775892 Accuracy: 0.7148494\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_116 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 16000)             64000     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 672,336\n",
      "Trainable params: 638,800\n",
      "Non-trainable params: 33,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.7235 - acc: 0.8243\n",
      "Loss: 0.7234576030559876 Accuracy: 0.82429904\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_124 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 15872)             63488     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                253968    \n",
      "=================================================================\n",
      "Total params: 834,896\n",
      "Trainable params: 801,104\n",
      "Non-trainable params: 33,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.4908 - acc: 0.8906\n",
      "Loss: 0.4907995786189043 Accuracy: 0.8905504\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_10_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 7936)              31744     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 1,005,136\n",
      "Trainable params: 986,704\n",
      "Non-trainable params: 18,432\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.2771 - acc: 0.9360\n",
      "Loss: 0.27709398446483724 Accuracy: 0.93603325\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_11_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_143 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 3840)              15360     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                61456     \n",
      "=================================================================\n",
      "Total params: 1,252,176\n",
      "Trainable params: 1,241,424\n",
      "Non-trainable params: 10,752\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.1884 - acc: 0.9578\n",
      "Loss: 0.18837949702224133 Accuracy: 0.9578401\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_12_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_154 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_176 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_177 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_178 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_179 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_180 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_181 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_182 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_183 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_184 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_185 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_186 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_187 ( (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_188 ( (None, 1792)              7168      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,540,176\n",
      "Trainable params: 1,533,008\n",
      "Non-trainable params: 7,168\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.1705 - acc: 0.9583\n",
      "Loss: 0.17051000813852032 Accuracy: 0.95825547\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_13_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_166 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_189 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_190 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_191 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_192 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_193 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_194 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_195 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_196 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_197 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_198 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_199 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_200 ( (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_201 ( (None, 7, 512)            2048      \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_154 (MaxPoolin (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_202 ( (None, 1536)              6144      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                24592     \n",
      "=================================================================\n",
      "Total params: 2,192,976\n",
      "Trainable params: 2,185,296\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.1679 - acc: 0.9578\n",
      "Loss: 0.16788074450600246 Accuracy: 0.9578401\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_pool_2_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 14):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 256000)            1024000   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 5,162,256\n",
      "Trainable params: 4,649,872\n",
      "Non-trainable params: 512,384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 6.6954 - acc: 0.4334\n",
      "Loss: 6.695358975035131 Accuracy: 0.43343717\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 128000)            512000    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,623,056\n",
      "Trainable params: 2,366,544\n",
      "Non-trainable params: 256,512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 4.4966 - acc: 0.5250\n",
      "Loss: 4.496604074694038 Accuracy: 0.52502596\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 128000)            512000    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,664,656\n",
      "Trainable params: 2,407,888\n",
      "Non-trainable params: 256,768\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 4.0363 - acc: 0.5772\n",
      "Loss: 4.036344213426299 Accuracy: 0.5771547\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 64000)             256000    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,467,216\n",
      "Trainable params: 1,338,192\n",
      "Non-trainable params: 129,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 2.5972 - acc: 0.6530\n",
      "Loss: 2.597247126392115 Accuracy: 0.6529595\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_109 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 32000)             128000    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 909,776\n",
      "Trainable params: 844,496\n",
      "Non-trainable params: 65,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 1.6086 - acc: 0.7248\n",
      "Loss: 1.6086186961097757 Accuracy: 0.7248183\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_116 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 16000)             64000     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 672,336\n",
      "Trainable params: 638,800\n",
      "Non-trainable params: 33,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.9683 - acc: 0.8239\n",
      "Loss: 0.9682679538291068 Accuracy: 0.8238837\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_124 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 15872)             63488     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                253968    \n",
      "=================================================================\n",
      "Total params: 834,896\n",
      "Trainable params: 801,104\n",
      "Non-trainable params: 33,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.7281 - acc: 0.8741\n",
      "Loss: 0.728079847024361 Accuracy: 0.8741433\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_10_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 7936)              31744     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 1,005,136\n",
      "Trainable params: 986,704\n",
      "Non-trainable params: 18,432\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.3079 - acc: 0.9373\n",
      "Loss: 0.30790221472565754 Accuracy: 0.93727934\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_11_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_143 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 3840)              15360     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                61456     \n",
      "=================================================================\n",
      "Total params: 1,252,176\n",
      "Trainable params: 1,241,424\n",
      "Non-trainable params: 10,752\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.1994 - acc: 0.9601\n",
      "Loss: 0.19936912025978765 Accuracy: 0.9601246\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_12_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_154 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_176 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_177 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_178 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_179 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_180 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_181 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_182 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_183 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_184 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_185 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_186 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_187 ( (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_188 ( (None, 1792)              7168      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,540,176\n",
      "Trainable params: 1,533,008\n",
      "Non-trainable params: 7,168\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.1731 - acc: 0.9614\n",
      "Loss: 0.17309199123684924 Accuracy: 0.9613707\n",
      "\n",
      "1D_CNN_custom_pool_2_BN_13_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_166 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_189 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_190 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_191 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_192 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_193 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_194 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_195 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_196 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_197 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_198 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_199 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_200 ( (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_201 ( (None, 7, 512)            2048      \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_154 (MaxPoolin (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_202 ( (None, 1536)              6144      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                24592     \n",
      "=================================================================\n",
      "Total params: 2,192,976\n",
      "Trainable params: 2,185,296\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 3ms/sample - loss: 0.1590 - acc: 0.9643\n",
      "Loss: 0.15897224372223084 Accuracy: 0.9642783\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_BN_2'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 14):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
