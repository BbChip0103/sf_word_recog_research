{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO(conv_num=1):\n",
    "    init_channel = 64\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=init_channel, strides=1, padding='same', \n",
    "                      activation='relu', input_shape=input_shape)) \n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=int(init_channel*(2**int((i+1)/3))), \n",
    "                          strides=1, padding='same', activation='relu'))\n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,400\n",
      "Trainable params: 16,384,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,481,936\n",
      "Trainable params: 5,481,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,136\n",
      "Trainable params: 1,861,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,294,992\n",
      "Trainable params: 1,294,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 568,080\n",
      "Trainable params: 568,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 379,792\n",
      "Trainable params: 379,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 496,784\n",
      "Trainable params: 496,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 767,376\n",
      "Trainable params: 767,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,074,832\n",
      "Trainable params: 1,074,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0167 - acc: 0.3569\n",
      "Epoch 00001: val_loss improved from inf to 1.52417, saving model to model/checkpoint/1D_CNN_custom_3_DO_4_conv_checkpoint/001-1.5242.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 2.0165 - acc: 0.3570 - val_loss: 1.5242 - val_acc: 0.5111\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4278 - acc: 0.5559\n",
      "Epoch 00002: val_loss improved from 1.52417 to 1.29778, saving model to model/checkpoint/1D_CNN_custom_3_DO_4_conv_checkpoint/002-1.2978.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 1.4279 - acc: 0.5559 - val_loss: 1.2978 - val_acc: 0.6122\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2201 - acc: 0.6260\n",
      "Epoch 00003: val_loss improved from 1.29778 to 1.21699, saving model to model/checkpoint/1D_CNN_custom_3_DO_4_conv_checkpoint/003-1.2170.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 1.2200 - acc: 0.6260 - val_loss: 1.2170 - val_acc: 0.6259\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0714 - acc: 0.6761\n",
      "Epoch 00004: val_loss improved from 1.21699 to 1.19000, saving model to model/checkpoint/1D_CNN_custom_3_DO_4_conv_checkpoint/004-1.1900.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 1.0716 - acc: 0.6760 - val_loss: 1.1900 - val_acc: 0.6177\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9431 - acc: 0.7170\n",
      "Epoch 00005: val_loss improved from 1.19000 to 1.10455, saving model to model/checkpoint/1D_CNN_custom_3_DO_4_conv_checkpoint/005-1.1046.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.9431 - acc: 0.7170 - val_loss: 1.1046 - val_acc: 0.6504\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8260 - acc: 0.7539\n",
      "Epoch 00006: val_loss improved from 1.10455 to 1.09669, saving model to model/checkpoint/1D_CNN_custom_3_DO_4_conv_checkpoint/006-1.0967.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.8260 - acc: 0.7539 - val_loss: 1.0967 - val_acc: 0.6564\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7181 - acc: 0.7842\n",
      "Epoch 00007: val_loss improved from 1.09669 to 1.02295, saving model to model/checkpoint/1D_CNN_custom_3_DO_4_conv_checkpoint/007-1.0229.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.7180 - acc: 0.7842 - val_loss: 1.0229 - val_acc: 0.6837\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6195 - acc: 0.8136\n",
      "Epoch 00008: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.6195 - acc: 0.8136 - val_loss: 1.0447 - val_acc: 0.6823\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5315 - acc: 0.8406\n",
      "Epoch 00009: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.5316 - acc: 0.8405 - val_loss: 1.0367 - val_acc: 0.6914\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4677 - acc: 0.8598\n",
      "Epoch 00010: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.4678 - acc: 0.8597 - val_loss: 1.0880 - val_acc: 0.6818\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3957 - acc: 0.8816\n",
      "Epoch 00011: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.3957 - acc: 0.8816 - val_loss: 1.0711 - val_acc: 0.6939\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3415 - acc: 0.8969\n",
      "Epoch 00012: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.3415 - acc: 0.8969 - val_loss: 1.1619 - val_acc: 0.6797\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2990 - acc: 0.9100\n",
      "Epoch 00013: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2990 - acc: 0.9100 - val_loss: 1.1801 - val_acc: 0.6909\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2708 - acc: 0.9185\n",
      "Epoch 00014: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2707 - acc: 0.9185 - val_loss: 1.1716 - val_acc: 0.6986\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2359 - acc: 0.9276\n",
      "Epoch 00015: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2358 - acc: 0.9276 - val_loss: 1.2484 - val_acc: 0.6853\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9387\n",
      "Epoch 00016: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2045 - acc: 0.9386 - val_loss: 1.2597 - val_acc: 0.6939\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1859 - acc: 0.9439\n",
      "Epoch 00017: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1859 - acc: 0.9439 - val_loss: 1.2393 - val_acc: 0.7051\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9497\n",
      "Epoch 00018: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1664 - acc: 0.9497 - val_loss: 1.3015 - val_acc: 0.6909\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1586 - acc: 0.9513\n",
      "Epoch 00019: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1586 - acc: 0.9513 - val_loss: 1.3152 - val_acc: 0.6956\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9575\n",
      "Epoch 00020: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1394 - acc: 0.9575 - val_loss: 1.3933 - val_acc: 0.6939\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9605\n",
      "Epoch 00021: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1331 - acc: 0.9605 - val_loss: 1.3664 - val_acc: 0.7086\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9624\n",
      "Epoch 00022: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1247 - acc: 0.9624 - val_loss: 1.3916 - val_acc: 0.7093\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9647\n",
      "Epoch 00023: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1182 - acc: 0.9647 - val_loss: 1.3777 - val_acc: 0.7093\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9670\n",
      "Epoch 00024: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1081 - acc: 0.9670 - val_loss: 1.3942 - val_acc: 0.7119\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9697\n",
      "Epoch 00025: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1014 - acc: 0.9697 - val_loss: 1.4214 - val_acc: 0.7112\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9696\n",
      "Epoch 00026: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0989 - acc: 0.9697 - val_loss: 1.5211 - val_acc: 0.7030\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9723\n",
      "Epoch 00027: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0933 - acc: 0.9723 - val_loss: 1.4205 - val_acc: 0.7060\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9744\n",
      "Epoch 00028: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0890 - acc: 0.9744 - val_loss: 1.5740 - val_acc: 0.7030\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9761\n",
      "Epoch 00029: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0838 - acc: 0.9761 - val_loss: 1.5098 - val_acc: 0.7086\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9767\n",
      "Epoch 00030: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0819 - acc: 0.9767 - val_loss: 1.4526 - val_acc: 0.7251\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9767\n",
      "Epoch 00031: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0819 - acc: 0.9767 - val_loss: 1.5440 - val_acc: 0.7039\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9776\n",
      "Epoch 00032: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0761 - acc: 0.9776 - val_loss: 1.5418 - val_acc: 0.7198\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9777\n",
      "Epoch 00033: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0757 - acc: 0.9777 - val_loss: 1.5055 - val_acc: 0.7186\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9793\n",
      "Epoch 00034: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0704 - acc: 0.9793 - val_loss: 1.5427 - val_acc: 0.7186\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9783\n",
      "Epoch 00035: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0725 - acc: 0.9783 - val_loss: 1.5046 - val_acc: 0.7237\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9794\n",
      "Epoch 00036: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0687 - acc: 0.9794 - val_loss: 1.5819 - val_acc: 0.7130\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9814\n",
      "Epoch 00037: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0647 - acc: 0.9814 - val_loss: 1.5168 - val_acc: 0.7256\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9826\n",
      "Epoch 00038: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0611 - acc: 0.9826 - val_loss: 1.6378 - val_acc: 0.7193\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9818\n",
      "Epoch 00039: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0605 - acc: 0.9818 - val_loss: 1.5772 - val_acc: 0.7272\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9832\n",
      "Epoch 00040: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0586 - acc: 0.9832 - val_loss: 1.5294 - val_acc: 0.7240\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9833\n",
      "Epoch 00041: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0600 - acc: 0.9833 - val_loss: 1.5719 - val_acc: 0.7221\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9842\n",
      "Epoch 00042: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0549 - acc: 0.9842 - val_loss: 1.7190 - val_acc: 0.7174\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9842\n",
      "Epoch 00043: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0562 - acc: 0.9842 - val_loss: 1.6300 - val_acc: 0.7265\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9843\n",
      "Epoch 00044: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0538 - acc: 0.9843 - val_loss: 1.6612 - val_acc: 0.7240\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9845\n",
      "Epoch 00045: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0557 - acc: 0.9845 - val_loss: 1.6167 - val_acc: 0.7258\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9848\n",
      "Epoch 00046: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0555 - acc: 0.9848 - val_loss: 1.6075 - val_acc: 0.7291\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9835\n",
      "Epoch 00047: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0564 - acc: 0.9835 - val_loss: 1.5443 - val_acc: 0.7314\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9860\n",
      "Epoch 00048: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0502 - acc: 0.9860 - val_loss: 1.5981 - val_acc: 0.7286\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9870\n",
      "Epoch 00049: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0478 - acc: 0.9870 - val_loss: 1.6311 - val_acc: 0.7291\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9872\n",
      "Epoch 00050: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0486 - acc: 0.9872 - val_loss: 1.6641 - val_acc: 0.7296\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9849\n",
      "Epoch 00051: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0518 - acc: 0.9849 - val_loss: 1.5831 - val_acc: 0.7347\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9876\n",
      "Epoch 00052: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0450 - acc: 0.9876 - val_loss: 1.6426 - val_acc: 0.7272\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9873\n",
      "Epoch 00053: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0470 - acc: 0.9873 - val_loss: 1.6692 - val_acc: 0.7228\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9870\n",
      "Epoch 00054: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0462 - acc: 0.9870 - val_loss: 1.7043 - val_acc: 0.7275\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9861\n",
      "Epoch 00055: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0502 - acc: 0.9861 - val_loss: 1.6808 - val_acc: 0.7405\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9876\n",
      "Epoch 00056: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0439 - acc: 0.9876 - val_loss: 1.6393 - val_acc: 0.7375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9873\n",
      "Epoch 00057: val_loss did not improve from 1.02295\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0444 - acc: 0.9873 - val_loss: 1.6437 - val_acc: 0.7393\n",
      "\n",
      "1D_CNN_custom_3_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 606us/sample - loss: 1.1352 - acc: 0.6540\n",
      "Loss: 1.135193683920372 Accuracy: 0.6539979\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0823 - acc: 0.3193\n",
      "Epoch 00001: val_loss improved from inf to 1.51416, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/001-1.5142.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 2.0823 - acc: 0.3192 - val_loss: 1.5142 - val_acc: 0.5141\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4505 - acc: 0.5389\n",
      "Epoch 00002: val_loss improved from 1.51416 to 1.21992, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/002-1.2199.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 1.4505 - acc: 0.5389 - val_loss: 1.2199 - val_acc: 0.6385\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2108 - acc: 0.6266\n",
      "Epoch 00003: val_loss improved from 1.21992 to 1.08114, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/003-1.0811.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 1.2107 - acc: 0.6266 - val_loss: 1.0811 - val_acc: 0.6785\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0533 - acc: 0.6803\n",
      "Epoch 00004: val_loss improved from 1.08114 to 0.97717, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/004-0.9772.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 1.0532 - acc: 0.6804 - val_loss: 0.9772 - val_acc: 0.7065\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9603 - acc: 0.7070\n",
      "Epoch 00005: val_loss improved from 0.97717 to 0.93947, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/005-0.9395.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.9603 - acc: 0.7070 - val_loss: 0.9395 - val_acc: 0.7237\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8821 - acc: 0.7348\n",
      "Epoch 00006: val_loss improved from 0.93947 to 0.89016, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/006-0.8902.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.8821 - acc: 0.7348 - val_loss: 0.8902 - val_acc: 0.7303\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8127 - acc: 0.7554\n",
      "Epoch 00007: val_loss improved from 0.89016 to 0.81181, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/007-0.8118.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.8127 - acc: 0.7553 - val_loss: 0.8118 - val_acc: 0.7605\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7481 - acc: 0.7747\n",
      "Epoch 00008: val_loss did not improve from 0.81181\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.7480 - acc: 0.7748 - val_loss: 0.8183 - val_acc: 0.7522\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7021 - acc: 0.7887\n",
      "Epoch 00009: val_loss improved from 0.81181 to 0.74748, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/009-0.7475.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.7020 - acc: 0.7887 - val_loss: 0.7475 - val_acc: 0.7822\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6542 - acc: 0.8036\n",
      "Epoch 00010: val_loss improved from 0.74748 to 0.73836, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/010-0.7384.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.6542 - acc: 0.8036 - val_loss: 0.7384 - val_acc: 0.7876\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6126 - acc: 0.8169\n",
      "Epoch 00011: val_loss did not improve from 0.73836\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.6126 - acc: 0.8169 - val_loss: 0.7406 - val_acc: 0.7859\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5715 - acc: 0.8287\n",
      "Epoch 00012: val_loss did not improve from 0.73836\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.5715 - acc: 0.8287 - val_loss: 0.7403 - val_acc: 0.7799\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5223 - acc: 0.8422\n",
      "Epoch 00013: val_loss improved from 0.73836 to 0.71101, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/013-0.7110.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.5224 - acc: 0.8422 - val_loss: 0.7110 - val_acc: 0.7971\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4944 - acc: 0.8500\n",
      "Epoch 00014: val_loss improved from 0.71101 to 0.70678, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/014-0.7068.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.4945 - acc: 0.8500 - val_loss: 0.7068 - val_acc: 0.7990\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.8604\n",
      "Epoch 00015: val_loss did not improve from 0.70678\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.4615 - acc: 0.8603 - val_loss: 0.7333 - val_acc: 0.7941\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4266 - acc: 0.8689\n",
      "Epoch 00016: val_loss improved from 0.70678 to 0.69792, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/016-0.6979.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.4266 - acc: 0.8690 - val_loss: 0.6979 - val_acc: 0.8060\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3951 - acc: 0.8786\n",
      "Epoch 00017: val_loss improved from 0.69792 to 0.69560, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/017-0.6956.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.3951 - acc: 0.8787 - val_loss: 0.6956 - val_acc: 0.8074\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3639 - acc: 0.8899\n",
      "Epoch 00018: val_loss improved from 0.69560 to 0.69477, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/018-0.6948.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.3639 - acc: 0.8899 - val_loss: 0.6948 - val_acc: 0.8143\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3401 - acc: 0.8962\n",
      "Epoch 00019: val_loss improved from 0.69477 to 0.68907, saving model to model/checkpoint/1D_CNN_custom_3_DO_5_conv_checkpoint/019-0.6891.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.3402 - acc: 0.8962 - val_loss: 0.6891 - val_acc: 0.8113\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3204 - acc: 0.9002\n",
      "Epoch 00020: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.3203 - acc: 0.9003 - val_loss: 0.7296 - val_acc: 0.8020\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2986 - acc: 0.9070\n",
      "Epoch 00021: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2987 - acc: 0.9070 - val_loss: 0.6967 - val_acc: 0.8162\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2759 - acc: 0.9147\n",
      "Epoch 00022: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2759 - acc: 0.9147 - val_loss: 0.7446 - val_acc: 0.8036\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2610 - acc: 0.9183\n",
      "Epoch 00023: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2610 - acc: 0.9183 - val_loss: 0.7341 - val_acc: 0.8102\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2443 - acc: 0.9217\n",
      "Epoch 00024: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2443 - acc: 0.9217 - val_loss: 0.7187 - val_acc: 0.8130\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2237 - acc: 0.9284\n",
      "Epoch 00025: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2237 - acc: 0.9284 - val_loss: 0.7345 - val_acc: 0.8141\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2172 - acc: 0.9321\n",
      "Epoch 00026: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2172 - acc: 0.9322 - val_loss: 0.8412 - val_acc: 0.8020\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2030 - acc: 0.9357\n",
      "Epoch 00027: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2029 - acc: 0.9357 - val_loss: 0.7562 - val_acc: 0.8153\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9389\n",
      "Epoch 00028: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1935 - acc: 0.9389 - val_loss: 0.8124 - val_acc: 0.8095\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9415\n",
      "Epoch 00029: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1846 - acc: 0.9416 - val_loss: 0.8595 - val_acc: 0.7985\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9457\n",
      "Epoch 00030: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1705 - acc: 0.9457 - val_loss: 0.8112 - val_acc: 0.8162\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1633 - acc: 0.9479\n",
      "Epoch 00031: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1634 - acc: 0.9479 - val_loss: 0.8076 - val_acc: 0.8139\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1652 - acc: 0.9470\n",
      "Epoch 00032: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1652 - acc: 0.9470 - val_loss: 0.8050 - val_acc: 0.8137\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9508\n",
      "Epoch 00033: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1570 - acc: 0.9508 - val_loss: 0.8397 - val_acc: 0.8025\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9522\n",
      "Epoch 00034: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1501 - acc: 0.9522 - val_loss: 0.7891 - val_acc: 0.8181\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9562\n",
      "Epoch 00035: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1414 - acc: 0.9562 - val_loss: 0.7958 - val_acc: 0.8218\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9565\n",
      "Epoch 00036: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1364 - acc: 0.9565 - val_loss: 0.8348 - val_acc: 0.8164\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9559\n",
      "Epoch 00037: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1397 - acc: 0.9559 - val_loss: 0.8692 - val_acc: 0.8113\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9592\n",
      "Epoch 00038: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1268 - acc: 0.9592 - val_loss: 0.8608 - val_acc: 0.8171\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9615\n",
      "Epoch 00039: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1205 - acc: 0.9615 - val_loss: 0.8811 - val_acc: 0.8109\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9628\n",
      "Epoch 00040: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1209 - acc: 0.9628 - val_loss: 0.8581 - val_acc: 0.8155\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9632\n",
      "Epoch 00041: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1168 - acc: 0.9632 - val_loss: 0.8556 - val_acc: 0.8218\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9647\n",
      "Epoch 00042: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1143 - acc: 0.9647 - val_loss: 0.8693 - val_acc: 0.8248\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9665\n",
      "Epoch 00043: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1122 - acc: 0.9665 - val_loss: 0.8275 - val_acc: 0.8258\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9666\n",
      "Epoch 00044: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1073 - acc: 0.9666 - val_loss: 0.8593 - val_acc: 0.8206\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9682\n",
      "Epoch 00045: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1044 - acc: 0.9682 - val_loss: 0.8573 - val_acc: 0.8185\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9678\n",
      "Epoch 00046: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1031 - acc: 0.9678 - val_loss: 0.8285 - val_acc: 0.8246\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9699\n",
      "Epoch 00047: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1002 - acc: 0.9699 - val_loss: 0.8447 - val_acc: 0.8251\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9689\n",
      "Epoch 00048: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1006 - acc: 0.9689 - val_loss: 0.8380 - val_acc: 0.8279\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9698\n",
      "Epoch 00049: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0967 - acc: 0.9698 - val_loss: 0.8850 - val_acc: 0.8253\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9710\n",
      "Epoch 00050: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0954 - acc: 0.9710 - val_loss: 0.8808 - val_acc: 0.8293\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9711\n",
      "Epoch 00051: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0935 - acc: 0.9711 - val_loss: 0.9336 - val_acc: 0.8211\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9726\n",
      "Epoch 00052: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0885 - acc: 0.9726 - val_loss: 0.9806 - val_acc: 0.8148\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9739\n",
      "Epoch 00053: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0883 - acc: 0.9739 - val_loss: 0.9319 - val_acc: 0.8174\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9729\n",
      "Epoch 00054: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0892 - acc: 0.9729 - val_loss: 0.9163 - val_acc: 0.8265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9736\n",
      "Epoch 00055: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0890 - acc: 0.9736 - val_loss: 0.8908 - val_acc: 0.8288\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9765\n",
      "Epoch 00056: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0801 - acc: 0.9765 - val_loss: 0.9094 - val_acc: 0.8269\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9747\n",
      "Epoch 00057: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0867 - acc: 0.9747 - val_loss: 0.8793 - val_acc: 0.8295\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9752\n",
      "Epoch 00058: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0830 - acc: 0.9752 - val_loss: 0.8335 - val_acc: 0.8348\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9758\n",
      "Epoch 00059: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0798 - acc: 0.9758 - val_loss: 0.9420 - val_acc: 0.8232\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9752\n",
      "Epoch 00060: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0801 - acc: 0.9752 - val_loss: 0.8556 - val_acc: 0.8339\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9770\n",
      "Epoch 00061: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0781 - acc: 0.9770 - val_loss: 0.9106 - val_acc: 0.8255\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9782\n",
      "Epoch 00062: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0758 - acc: 0.9782 - val_loss: 0.9066 - val_acc: 0.8283\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9776\n",
      "Epoch 00063: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0754 - acc: 0.9776 - val_loss: 0.9004 - val_acc: 0.8339\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9779\n",
      "Epoch 00064: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0728 - acc: 0.9779 - val_loss: 0.8901 - val_acc: 0.8332\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9793\n",
      "Epoch 00065: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0717 - acc: 0.9793 - val_loss: 0.8798 - val_acc: 0.8328\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9778\n",
      "Epoch 00066: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0746 - acc: 0.9778 - val_loss: 0.9081 - val_acc: 0.8302\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9790\n",
      "Epoch 00067: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0708 - acc: 0.9791 - val_loss: 0.9118 - val_acc: 0.8276\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9785\n",
      "Epoch 00068: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0705 - acc: 0.9785 - val_loss: 0.9083 - val_acc: 0.8369\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9799\n",
      "Epoch 00069: val_loss did not improve from 0.68907\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0677 - acc: 0.9799 - val_loss: 0.8919 - val_acc: 0.8395\n",
      "\n",
      "1D_CNN_custom_3_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 609us/sample - loss: 0.8078 - acc: 0.7724\n",
      "Loss: 0.8077790394255182 Accuracy: 0.77237797\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2170 - acc: 0.2759\n",
      "Epoch 00001: val_loss improved from inf to 1.51771, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/001-1.5177.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 2.2169 - acc: 0.2760 - val_loss: 1.5177 - val_acc: 0.5181\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5067 - acc: 0.5093\n",
      "Epoch 00002: val_loss improved from 1.51771 to 1.29293, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/002-1.2929.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 1.5067 - acc: 0.5093 - val_loss: 1.2929 - val_acc: 0.5968\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3147 - acc: 0.5757\n",
      "Epoch 00003: val_loss improved from 1.29293 to 1.11116, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/003-1.1112.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 1.3147 - acc: 0.5757 - val_loss: 1.1112 - val_acc: 0.6576\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1421 - acc: 0.6447\n",
      "Epoch 00004: val_loss improved from 1.11116 to 0.97862, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/004-0.9786.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 1.1420 - acc: 0.6447 - val_loss: 0.9786 - val_acc: 0.7091\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0127 - acc: 0.6839\n",
      "Epoch 00005: val_loss improved from 0.97862 to 0.87116, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/005-0.8712.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 1.0127 - acc: 0.6840 - val_loss: 0.8712 - val_acc: 0.7391\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9053 - acc: 0.7231\n",
      "Epoch 00006: val_loss improved from 0.87116 to 0.79090, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/006-0.7909.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.9052 - acc: 0.7231 - val_loss: 0.7909 - val_acc: 0.7689\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8125 - acc: 0.7542\n",
      "Epoch 00007: val_loss improved from 0.79090 to 0.78691, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/007-0.7869.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.8125 - acc: 0.7542 - val_loss: 0.7869 - val_acc: 0.7694\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7387 - acc: 0.7754\n",
      "Epoch 00008: val_loss improved from 0.78691 to 0.65171, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/008-0.6517.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.7386 - acc: 0.7754 - val_loss: 0.6517 - val_acc: 0.8155\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6822 - acc: 0.7955\n",
      "Epoch 00009: val_loss improved from 0.65171 to 0.61959, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/009-0.6196.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.6821 - acc: 0.7955 - val_loss: 0.6196 - val_acc: 0.8220\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6271 - acc: 0.8104\n",
      "Epoch 00010: val_loss improved from 0.61959 to 0.56091, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/010-0.5609.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.6274 - acc: 0.8103 - val_loss: 0.5609 - val_acc: 0.8386\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5770 - acc: 0.8249\n",
      "Epoch 00011: val_loss did not improve from 0.56091\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.5770 - acc: 0.8249 - val_loss: 0.7054 - val_acc: 0.7920\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5509 - acc: 0.8334\n",
      "Epoch 00012: val_loss did not improve from 0.56091\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.5510 - acc: 0.8334 - val_loss: 0.5689 - val_acc: 0.8332\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5144 - acc: 0.8446\n",
      "Epoch 00013: val_loss improved from 0.56091 to 0.51738, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/013-0.5174.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.5147 - acc: 0.8445 - val_loss: 0.5174 - val_acc: 0.8493\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4886 - acc: 0.8536\n",
      "Epoch 00014: val_loss improved from 0.51738 to 0.49241, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/014-0.4924.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.4886 - acc: 0.8536 - val_loss: 0.4924 - val_acc: 0.8607\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4606 - acc: 0.8599\n",
      "Epoch 00015: val_loss did not improve from 0.49241\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.4605 - acc: 0.8599 - val_loss: 0.5127 - val_acc: 0.8542\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4298 - acc: 0.8696\n",
      "Epoch 00016: val_loss improved from 0.49241 to 0.43563, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/016-0.4356.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.4298 - acc: 0.8696 - val_loss: 0.4356 - val_acc: 0.8742\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4135 - acc: 0.8765\n",
      "Epoch 00017: val_loss improved from 0.43563 to 0.41959, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/017-0.4196.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.4136 - acc: 0.8765 - val_loss: 0.4196 - val_acc: 0.8786\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3898 - acc: 0.8808\n",
      "Epoch 00018: val_loss did not improve from 0.41959\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.3897 - acc: 0.8809 - val_loss: 0.4314 - val_acc: 0.8814\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3694 - acc: 0.8884\n",
      "Epoch 00019: val_loss improved from 0.41959 to 0.41838, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/019-0.4184.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.3694 - acc: 0.8884 - val_loss: 0.4184 - val_acc: 0.8849\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3511 - acc: 0.8939\n",
      "Epoch 00020: val_loss improved from 0.41838 to 0.38565, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/020-0.3856.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.3511 - acc: 0.8939 - val_loss: 0.3856 - val_acc: 0.8945\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3378 - acc: 0.8966\n",
      "Epoch 00021: val_loss did not improve from 0.38565\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.3377 - acc: 0.8966 - val_loss: 0.4096 - val_acc: 0.8854\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3230 - acc: 0.9013\n",
      "Epoch 00022: val_loss did not improve from 0.38565\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.3230 - acc: 0.9013 - val_loss: 0.3990 - val_acc: 0.8917\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3079 - acc: 0.9052\n",
      "Epoch 00023: val_loss improved from 0.38565 to 0.37374, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/023-0.3737.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.3079 - acc: 0.9052 - val_loss: 0.3737 - val_acc: 0.9017\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2975 - acc: 0.9070\n",
      "Epoch 00024: val_loss did not improve from 0.37374\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2975 - acc: 0.9070 - val_loss: 0.3906 - val_acc: 0.8926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2850 - acc: 0.9132\n",
      "Epoch 00025: val_loss did not improve from 0.37374\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2849 - acc: 0.9132 - val_loss: 0.3756 - val_acc: 0.8975\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2731 - acc: 0.9156\n",
      "Epoch 00026: val_loss improved from 0.37374 to 0.36877, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/026-0.3688.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2731 - acc: 0.9156 - val_loss: 0.3688 - val_acc: 0.9029\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2583 - acc: 0.9200\n",
      "Epoch 00027: val_loss did not improve from 0.36877\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2584 - acc: 0.9200 - val_loss: 0.4427 - val_acc: 0.8866\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2512 - acc: 0.9231\n",
      "Epoch 00028: val_loss did not improve from 0.36877\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2512 - acc: 0.9231 - val_loss: 0.3707 - val_acc: 0.9019\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2366 - acc: 0.9263\n",
      "Epoch 00029: val_loss did not improve from 0.36877\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2366 - acc: 0.9263 - val_loss: 0.3753 - val_acc: 0.9057\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2307 - acc: 0.9278\n",
      "Epoch 00030: val_loss did not improve from 0.36877\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2307 - acc: 0.9278 - val_loss: 0.3697 - val_acc: 0.9033\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2162 - acc: 0.9327\n",
      "Epoch 00031: val_loss did not improve from 0.36877\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2162 - acc: 0.9327 - val_loss: 0.3803 - val_acc: 0.9024\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9321\n",
      "Epoch 00032: val_loss improved from 0.36877 to 0.36047, saving model to model/checkpoint/1D_CNN_custom_3_DO_6_conv_checkpoint/032-0.3605.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2133 - acc: 0.9321 - val_loss: 0.3605 - val_acc: 0.9071\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2075 - acc: 0.9336\n",
      "Epoch 00033: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2075 - acc: 0.9336 - val_loss: 0.3884 - val_acc: 0.9117\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2015 - acc: 0.9354\n",
      "Epoch 00034: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2015 - acc: 0.9354 - val_loss: 0.3630 - val_acc: 0.9108\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1933 - acc: 0.9376\n",
      "Epoch 00035: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1933 - acc: 0.9376 - val_loss: 0.3695 - val_acc: 0.9080\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9425\n",
      "Epoch 00036: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1816 - acc: 0.9425 - val_loss: 0.3824 - val_acc: 0.9106\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1774 - acc: 0.9428\n",
      "Epoch 00037: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1774 - acc: 0.9428 - val_loss: 0.3654 - val_acc: 0.9064\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1719 - acc: 0.9443\n",
      "Epoch 00038: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1719 - acc: 0.9444 - val_loss: 0.3996 - val_acc: 0.9124\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9461\n",
      "Epoch 00039: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1667 - acc: 0.9461 - val_loss: 0.3674 - val_acc: 0.9115\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1676 - acc: 0.9458\n",
      "Epoch 00040: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1676 - acc: 0.9458 - val_loss: 0.3798 - val_acc: 0.9129\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1562 - acc: 0.9490\n",
      "Epoch 00041: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1562 - acc: 0.9490 - val_loss: 0.3914 - val_acc: 0.9059\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9514\n",
      "Epoch 00042: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1516 - acc: 0.9514 - val_loss: 0.4023 - val_acc: 0.9087\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9510\n",
      "Epoch 00043: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1513 - acc: 0.9510 - val_loss: 0.3898 - val_acc: 0.9129\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9519\n",
      "Epoch 00044: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1471 - acc: 0.9519 - val_loss: 0.3799 - val_acc: 0.9157\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1347 - acc: 0.9554\n",
      "Epoch 00045: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1347 - acc: 0.9554 - val_loss: 0.3715 - val_acc: 0.9138\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9561\n",
      "Epoch 00046: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1343 - acc: 0.9561 - val_loss: 0.3855 - val_acc: 0.9145\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9585\n",
      "Epoch 00047: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1300 - acc: 0.9585 - val_loss: 0.3930 - val_acc: 0.9085\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9569\n",
      "Epoch 00048: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1310 - acc: 0.9569 - val_loss: 0.4437 - val_acc: 0.9038\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9589\n",
      "Epoch 00049: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1259 - acc: 0.9589 - val_loss: 0.3961 - val_acc: 0.9178\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9626\n",
      "Epoch 00050: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1175 - acc: 0.9626 - val_loss: 0.3855 - val_acc: 0.9159\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9616\n",
      "Epoch 00051: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1179 - acc: 0.9616 - val_loss: 0.3842 - val_acc: 0.9140\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9619\n",
      "Epoch 00052: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1166 - acc: 0.9619 - val_loss: 0.3727 - val_acc: 0.9173\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9616\n",
      "Epoch 00053: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1162 - acc: 0.9616 - val_loss: 0.3879 - val_acc: 0.9157\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9642\n",
      "Epoch 00054: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1081 - acc: 0.9642 - val_loss: 0.3770 - val_acc: 0.9201\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9636\n",
      "Epoch 00055: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1101 - acc: 0.9636 - val_loss: 0.3945 - val_acc: 0.9168\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9663\n",
      "Epoch 00056: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1030 - acc: 0.9663 - val_loss: 0.4108 - val_acc: 0.9115\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9665\n",
      "Epoch 00057: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1027 - acc: 0.9665 - val_loss: 0.3731 - val_acc: 0.9201\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9664\n",
      "Epoch 00058: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1031 - acc: 0.9664 - val_loss: 0.4118 - val_acc: 0.9159\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9679\n",
      "Epoch 00059: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1004 - acc: 0.9679 - val_loss: 0.3912 - val_acc: 0.9215\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9701\n",
      "Epoch 00060: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0952 - acc: 0.9701 - val_loss: 0.3968 - val_acc: 0.9157\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9693\n",
      "Epoch 00061: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0957 - acc: 0.9694 - val_loss: 0.4057 - val_acc: 0.9217\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9691\n",
      "Epoch 00062: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0976 - acc: 0.9691 - val_loss: 0.4195 - val_acc: 0.9182\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9719\n",
      "Epoch 00063: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0854 - acc: 0.9719 - val_loss: 0.3972 - val_acc: 0.9185\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9718\n",
      "Epoch 00064: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0863 - acc: 0.9718 - val_loss: 0.4084 - val_acc: 0.9227\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9709\n",
      "Epoch 00065: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0889 - acc: 0.9709 - val_loss: 0.3954 - val_acc: 0.9217\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9715\n",
      "Epoch 00066: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0876 - acc: 0.9716 - val_loss: 0.3909 - val_acc: 0.9178\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9721\n",
      "Epoch 00067: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0875 - acc: 0.9721 - val_loss: 0.4083 - val_acc: 0.9243\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9724\n",
      "Epoch 00068: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0850 - acc: 0.9723 - val_loss: 0.4248 - val_acc: 0.9147\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9732\n",
      "Epoch 00069: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0820 - acc: 0.9731 - val_loss: 0.3999 - val_acc: 0.9231\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9746\n",
      "Epoch 00070: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0814 - acc: 0.9745 - val_loss: 0.4109 - val_acc: 0.9213\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9730\n",
      "Epoch 00071: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0829 - acc: 0.9730 - val_loss: 0.3919 - val_acc: 0.9206\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9745\n",
      "Epoch 00072: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0772 - acc: 0.9745 - val_loss: 0.4212 - val_acc: 0.9229\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9740\n",
      "Epoch 00073: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0797 - acc: 0.9740 - val_loss: 0.4023 - val_acc: 0.9215\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9756\n",
      "Epoch 00074: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0761 - acc: 0.9756 - val_loss: 0.4112 - val_acc: 0.9185\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9765\n",
      "Epoch 00075: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0737 - acc: 0.9765 - val_loss: 0.4387 - val_acc: 0.9157\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9756\n",
      "Epoch 00076: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0748 - acc: 0.9756 - val_loss: 0.4322 - val_acc: 0.9131\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9782\n",
      "Epoch 00077: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0702 - acc: 0.9782 - val_loss: 0.4089 - val_acc: 0.9234\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9772\n",
      "Epoch 00078: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0706 - acc: 0.9772 - val_loss: 0.4303 - val_acc: 0.9222\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9786\n",
      "Epoch 00079: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0690 - acc: 0.9786 - val_loss: 0.4082 - val_acc: 0.9203\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9783\n",
      "Epoch 00080: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0684 - acc: 0.9783 - val_loss: 0.4200 - val_acc: 0.9231\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9786\n",
      "Epoch 00081: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0692 - acc: 0.9786 - val_loss: 0.4436 - val_acc: 0.9113\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9791\n",
      "Epoch 00082: val_loss did not improve from 0.36047\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0652 - acc: 0.9791 - val_loss: 0.4198 - val_acc: 0.9192\n",
      "\n",
      "1D_CNN_custom_3_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 619us/sample - loss: 0.4158 - acc: 0.8862\n",
      "Loss: 0.4157717520202803 Accuracy: 0.886189\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2056 - acc: 0.2735\n",
      "Epoch 00001: val_loss improved from inf to 1.49116, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/001-1.4912.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 2.2055 - acc: 0.2735 - val_loss: 1.4912 - val_acc: 0.5278\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4092 - acc: 0.5402\n",
      "Epoch 00002: val_loss improved from 1.49116 to 1.07226, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/002-1.0723.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 1.4092 - acc: 0.5402 - val_loss: 1.0723 - val_acc: 0.6744\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1277 - acc: 0.6350\n",
      "Epoch 00003: val_loss improved from 1.07226 to 0.89600, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/003-0.8960.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 1.1278 - acc: 0.6349 - val_loss: 0.8960 - val_acc: 0.7275\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9657 - acc: 0.6900\n",
      "Epoch 00004: val_loss improved from 0.89600 to 0.75891, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/004-0.7589.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.9658 - acc: 0.6899 - val_loss: 0.7589 - val_acc: 0.7603\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8354 - acc: 0.7369\n",
      "Epoch 00005: val_loss improved from 0.75891 to 0.65107, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/005-0.6511.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.8353 - acc: 0.7369 - val_loss: 0.6511 - val_acc: 0.7978\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7354 - acc: 0.7680\n",
      "Epoch 00006: val_loss improved from 0.65107 to 0.58323, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/006-0.5832.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.7353 - acc: 0.7681 - val_loss: 0.5832 - val_acc: 0.8330\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6463 - acc: 0.7931\n",
      "Epoch 00007: val_loss improved from 0.58323 to 0.51519, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/007-0.5152.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.6463 - acc: 0.7931 - val_loss: 0.5152 - val_acc: 0.8451\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5747 - acc: 0.8196\n",
      "Epoch 00008: val_loss improved from 0.51519 to 0.43563, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/008-0.4356.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.5747 - acc: 0.8196 - val_loss: 0.4356 - val_acc: 0.8754\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4996 - acc: 0.8428\n",
      "Epoch 00009: val_loss improved from 0.43563 to 0.40364, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/009-0.4036.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.4996 - acc: 0.8428 - val_loss: 0.4036 - val_acc: 0.8868\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4461 - acc: 0.8604\n",
      "Epoch 00010: val_loss improved from 0.40364 to 0.36279, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/010-0.3628.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.4462 - acc: 0.8604 - val_loss: 0.3628 - val_acc: 0.8989\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4029 - acc: 0.8728\n",
      "Epoch 00011: val_loss improved from 0.36279 to 0.33343, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/011-0.3334.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.4029 - acc: 0.8728 - val_loss: 0.3334 - val_acc: 0.9080\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3687 - acc: 0.8846\n",
      "Epoch 00012: val_loss improved from 0.33343 to 0.28762, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/012-0.2876.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.3687 - acc: 0.8846 - val_loss: 0.2876 - val_acc: 0.9187\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3438 - acc: 0.8904\n",
      "Epoch 00013: val_loss did not improve from 0.28762\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.3439 - acc: 0.8903 - val_loss: 0.3152 - val_acc: 0.9085\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3236 - acc: 0.8979\n",
      "Epoch 00014: val_loss did not improve from 0.28762\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.3237 - acc: 0.8978 - val_loss: 0.3063 - val_acc: 0.9117\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2993 - acc: 0.9053\n",
      "Epoch 00015: val_loss improved from 0.28762 to 0.27388, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/015-0.2739.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2993 - acc: 0.9053 - val_loss: 0.2739 - val_acc: 0.9203\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2810 - acc: 0.9102\n",
      "Epoch 00016: val_loss improved from 0.27388 to 0.24666, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/016-0.2467.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2810 - acc: 0.9102 - val_loss: 0.2467 - val_acc: 0.9285\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2614 - acc: 0.9160\n",
      "Epoch 00017: val_loss did not improve from 0.24666\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2614 - acc: 0.9160 - val_loss: 0.2660 - val_acc: 0.9259\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2482 - acc: 0.9211\n",
      "Epoch 00018: val_loss did not improve from 0.24666\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2482 - acc: 0.9211 - val_loss: 0.2533 - val_acc: 0.9283\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.9239\n",
      "Epoch 00019: val_loss improved from 0.24666 to 0.22277, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/019-0.2228.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2356 - acc: 0.9239 - val_loss: 0.2228 - val_acc: 0.9336\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2240 - acc: 0.9278\n",
      "Epoch 00020: val_loss did not improve from 0.22277\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2240 - acc: 0.9278 - val_loss: 0.2314 - val_acc: 0.9331\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2136 - acc: 0.9314\n",
      "Epoch 00021: val_loss did not improve from 0.22277\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2136 - acc: 0.9314 - val_loss: 0.2235 - val_acc: 0.9411\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2002 - acc: 0.9356\n",
      "Epoch 00022: val_loss did not improve from 0.22277\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2002 - acc: 0.9356 - val_loss: 0.2265 - val_acc: 0.9350\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1954 - acc: 0.9358\n",
      "Epoch 00023: val_loss did not improve from 0.22277\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1953 - acc: 0.9358 - val_loss: 0.2456 - val_acc: 0.9257\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1814 - acc: 0.9400\n",
      "Epoch 00024: val_loss improved from 0.22277 to 0.21584, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/024-0.2158.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1814 - acc: 0.9400 - val_loss: 0.2158 - val_acc: 0.9420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1766 - acc: 0.9422\n",
      "Epoch 00025: val_loss did not improve from 0.21584\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1766 - acc: 0.9422 - val_loss: 0.2307 - val_acc: 0.9376\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1650 - acc: 0.9463\n",
      "Epoch 00026: val_loss did not improve from 0.21584\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1650 - acc: 0.9463 - val_loss: 0.2237 - val_acc: 0.9369\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9468\n",
      "Epoch 00027: val_loss did not improve from 0.21584\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1597 - acc: 0.9469 - val_loss: 0.2219 - val_acc: 0.9362\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9486\n",
      "Epoch 00028: val_loss did not improve from 0.21584\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1547 - acc: 0.9486 - val_loss: 0.2319 - val_acc: 0.9334\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9505\n",
      "Epoch 00029: val_loss did not improve from 0.21584\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1479 - acc: 0.9505 - val_loss: 0.2325 - val_acc: 0.9348\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1461 - acc: 0.9511\n",
      "Epoch 00030: val_loss did not improve from 0.21584\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1461 - acc: 0.9511 - val_loss: 0.2256 - val_acc: 0.9404\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1346 - acc: 0.9547\n",
      "Epoch 00031: val_loss improved from 0.21584 to 0.19339, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/031-0.1934.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1346 - acc: 0.9547 - val_loss: 0.1934 - val_acc: 0.9464\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9550\n",
      "Epoch 00032: val_loss did not improve from 0.19339\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1319 - acc: 0.9550 - val_loss: 0.2135 - val_acc: 0.9420\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9586\n",
      "Epoch 00033: val_loss did not improve from 0.19339\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1223 - acc: 0.9586 - val_loss: 0.1948 - val_acc: 0.9474\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9590\n",
      "Epoch 00034: val_loss did not improve from 0.19339\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1248 - acc: 0.9590 - val_loss: 0.2141 - val_acc: 0.9434\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9604\n",
      "Epoch 00035: val_loss improved from 0.19339 to 0.18421, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/035-0.1842.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1174 - acc: 0.9604 - val_loss: 0.1842 - val_acc: 0.9483\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9631\n",
      "Epoch 00036: val_loss did not improve from 0.18421\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1093 - acc: 0.9631 - val_loss: 0.2192 - val_acc: 0.9464\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9628\n",
      "Epoch 00037: val_loss did not improve from 0.18421\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1086 - acc: 0.9628 - val_loss: 0.1873 - val_acc: 0.9481\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9635\n",
      "Epoch 00038: val_loss did not improve from 0.18421\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1086 - acc: 0.9634 - val_loss: 0.1985 - val_acc: 0.9453\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9659\n",
      "Epoch 00039: val_loss improved from 0.18421 to 0.18216, saving model to model/checkpoint/1D_CNN_custom_3_DO_7_conv_checkpoint/039-0.1822.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1029 - acc: 0.9659 - val_loss: 0.1822 - val_acc: 0.9509\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9667\n",
      "Epoch 00040: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0961 - acc: 0.9667 - val_loss: 0.2193 - val_acc: 0.9411\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9688\n",
      "Epoch 00041: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0937 - acc: 0.9688 - val_loss: 0.1940 - val_acc: 0.9511\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9677\n",
      "Epoch 00042: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0927 - acc: 0.9677 - val_loss: 0.1995 - val_acc: 0.9485\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9693\n",
      "Epoch 00043: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0897 - acc: 0.9693 - val_loss: 0.2097 - val_acc: 0.9476\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9693\n",
      "Epoch 00044: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0877 - acc: 0.9693 - val_loss: 0.2102 - val_acc: 0.9485\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9713\n",
      "Epoch 00045: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0824 - acc: 0.9713 - val_loss: 0.2288 - val_acc: 0.9471\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9720\n",
      "Epoch 00046: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0808 - acc: 0.9720 - val_loss: 0.2040 - val_acc: 0.9490\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9734\n",
      "Epoch 00047: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0799 - acc: 0.9734 - val_loss: 0.2209 - val_acc: 0.9495\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9747\n",
      "Epoch 00048: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0741 - acc: 0.9747 - val_loss: 0.2276 - val_acc: 0.9450\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9716\n",
      "Epoch 00049: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0800 - acc: 0.9716 - val_loss: 0.2027 - val_acc: 0.9488\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9759\n",
      "Epoch 00050: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0719 - acc: 0.9759 - val_loss: 0.2078 - val_acc: 0.9481\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9755\n",
      "Epoch 00051: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0708 - acc: 0.9755 - val_loss: 0.2098 - val_acc: 0.9513\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9743\n",
      "Epoch 00052: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0742 - acc: 0.9743 - val_loss: 0.1947 - val_acc: 0.9495\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9779\n",
      "Epoch 00053: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0638 - acc: 0.9779 - val_loss: 0.2527 - val_acc: 0.9432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9771\n",
      "Epoch 00054: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0683 - acc: 0.9771 - val_loss: 0.2096 - val_acc: 0.9532\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9789\n",
      "Epoch 00055: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0598 - acc: 0.9789 - val_loss: 0.1955 - val_acc: 0.9515\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9795\n",
      "Epoch 00056: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0599 - acc: 0.9795 - val_loss: 0.2157 - val_acc: 0.9490\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9788\n",
      "Epoch 00057: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0609 - acc: 0.9788 - val_loss: 0.2076 - val_acc: 0.9518\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9798\n",
      "Epoch 00058: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0591 - acc: 0.9798 - val_loss: 0.2165 - val_acc: 0.9506\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9802\n",
      "Epoch 00059: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0586 - acc: 0.9802 - val_loss: 0.2016 - val_acc: 0.9492\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9795\n",
      "Epoch 00060: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0577 - acc: 0.9795 - val_loss: 0.2311 - val_acc: 0.9460\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9814\n",
      "Epoch 00061: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0543 - acc: 0.9814 - val_loss: 0.1970 - val_acc: 0.9564\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9820\n",
      "Epoch 00062: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0534 - acc: 0.9820 - val_loss: 0.2048 - val_acc: 0.9525\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9831\n",
      "Epoch 00063: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0489 - acc: 0.9831 - val_loss: 0.2418 - val_acc: 0.9485\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9816\n",
      "Epoch 00064: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0546 - acc: 0.9816 - val_loss: 0.2266 - val_acc: 0.9476\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9842\n",
      "Epoch 00065: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0471 - acc: 0.9842 - val_loss: 0.2158 - val_acc: 0.9539\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9840\n",
      "Epoch 00066: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0464 - acc: 0.9840 - val_loss: 0.2219 - val_acc: 0.9532\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9834\n",
      "Epoch 00067: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0490 - acc: 0.9834 - val_loss: 0.2168 - val_acc: 0.9518\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9842\n",
      "Epoch 00068: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0471 - acc: 0.9842 - val_loss: 0.2146 - val_acc: 0.9495\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9849\n",
      "Epoch 00069: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0451 - acc: 0.9849 - val_loss: 0.2299 - val_acc: 0.9518\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9850\n",
      "Epoch 00070: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0457 - acc: 0.9850 - val_loss: 0.2329 - val_acc: 0.9504\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9836\n",
      "Epoch 00071: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0480 - acc: 0.9836 - val_loss: 0.2251 - val_acc: 0.9525\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9849\n",
      "Epoch 00072: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0444 - acc: 0.9849 - val_loss: 0.2158 - val_acc: 0.9541\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9865\n",
      "Epoch 00073: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0418 - acc: 0.9865 - val_loss: 0.2402 - val_acc: 0.9490\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9864\n",
      "Epoch 00074: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0416 - acc: 0.9864 - val_loss: 0.2489 - val_acc: 0.9520\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9867\n",
      "Epoch 00075: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0402 - acc: 0.9867 - val_loss: 0.2334 - val_acc: 0.9495\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9839\n",
      "Epoch 00076: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0490 - acc: 0.9839 - val_loss: 0.2113 - val_acc: 0.9522\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9871\n",
      "Epoch 00077: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0377 - acc: 0.9871 - val_loss: 0.2429 - val_acc: 0.9529\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9879\n",
      "Epoch 00078: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0375 - acc: 0.9879 - val_loss: 0.2470 - val_acc: 0.9525\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9852\n",
      "Epoch 00079: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0434 - acc: 0.9852 - val_loss: 0.2266 - val_acc: 0.9532\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9878\n",
      "Epoch 00080: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0359 - acc: 0.9878 - val_loss: 0.2309 - val_acc: 0.9569\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9887\n",
      "Epoch 00081: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0346 - acc: 0.9887 - val_loss: 0.2319 - val_acc: 0.9541\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9857\n",
      "Epoch 00082: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0398 - acc: 0.9857 - val_loss: 0.2351 - val_acc: 0.9564\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9884\n",
      "Epoch 00083: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0339 - acc: 0.9884 - val_loss: 0.2131 - val_acc: 0.9550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9879\n",
      "Epoch 00084: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0349 - acc: 0.9879 - val_loss: 0.2210 - val_acc: 0.9553\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9893\n",
      "Epoch 00085: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0326 - acc: 0.9893 - val_loss: 0.2399 - val_acc: 0.9555\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9874\n",
      "Epoch 00086: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0364 - acc: 0.9874 - val_loss: 0.2273 - val_acc: 0.9543\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9876\n",
      "Epoch 00087: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0345 - acc: 0.9876 - val_loss: 0.2479 - val_acc: 0.9539\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9901\n",
      "Epoch 00088: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0295 - acc: 0.9901 - val_loss: 0.2379 - val_acc: 0.9543\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9889\n",
      "Epoch 00089: val_loss did not improve from 0.18216\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0324 - acc: 0.9889 - val_loss: 0.2501 - val_acc: 0.9469\n",
      "\n",
      "1D_CNN_custom_3_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 628us/sample - loss: 0.2246 - acc: 0.9327\n",
      "Loss: 0.224630900942029 Accuracy: 0.9327103\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0712 - acc: 0.3266\n",
      "Epoch 00001: val_loss improved from inf to 1.17092, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/001-1.1709.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 2.0711 - acc: 0.3267 - val_loss: 1.1709 - val_acc: 0.6436\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1199 - acc: 0.6351\n",
      "Epoch 00002: val_loss improved from 1.17092 to 0.74508, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/002-0.7451.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 1.1199 - acc: 0.6350 - val_loss: 0.7451 - val_acc: 0.7654\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8231 - acc: 0.7346\n",
      "Epoch 00003: val_loss improved from 0.74508 to 0.53721, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/003-0.5372.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.8231 - acc: 0.7346 - val_loss: 0.5372 - val_acc: 0.8379\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6530 - acc: 0.7889\n",
      "Epoch 00004: val_loss improved from 0.53721 to 0.48932, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/004-0.4893.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.6530 - acc: 0.7889 - val_loss: 0.4893 - val_acc: 0.8421\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5489 - acc: 0.8221\n",
      "Epoch 00005: val_loss improved from 0.48932 to 0.35707, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/005-0.3571.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.5488 - acc: 0.8221 - val_loss: 0.3571 - val_acc: 0.8954\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4553 - acc: 0.8551\n",
      "Epoch 00006: val_loss improved from 0.35707 to 0.30027, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/006-0.3003.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.4552 - acc: 0.8551 - val_loss: 0.3003 - val_acc: 0.9033\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3978 - acc: 0.8729\n",
      "Epoch 00007: val_loss improved from 0.30027 to 0.26066, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/007-0.2607.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.3977 - acc: 0.8729 - val_loss: 0.2607 - val_acc: 0.9224\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3530 - acc: 0.8894\n",
      "Epoch 00008: val_loss improved from 0.26066 to 0.25434, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/008-0.2543.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.3530 - acc: 0.8894 - val_loss: 0.2543 - val_acc: 0.9222\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3188 - acc: 0.8985\n",
      "Epoch 00009: val_loss improved from 0.25434 to 0.21426, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/009-0.2143.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.3188 - acc: 0.8985 - val_loss: 0.2143 - val_acc: 0.9357\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2867 - acc: 0.9086\n",
      "Epoch 00010: val_loss improved from 0.21426 to 0.20010, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/010-0.2001.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2867 - acc: 0.9086 - val_loss: 0.2001 - val_acc: 0.9390\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2741 - acc: 0.9121\n",
      "Epoch 00011: val_loss did not improve from 0.20010\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2741 - acc: 0.9121 - val_loss: 0.2005 - val_acc: 0.9383\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2468 - acc: 0.9200\n",
      "Epoch 00012: val_loss improved from 0.20010 to 0.18295, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/012-0.1829.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2467 - acc: 0.9200 - val_loss: 0.1829 - val_acc: 0.9457\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2282 - acc: 0.9272\n",
      "Epoch 00013: val_loss improved from 0.18295 to 0.17145, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/013-0.1714.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2282 - acc: 0.9272 - val_loss: 0.1714 - val_acc: 0.9492\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9308\n",
      "Epoch 00014: val_loss improved from 0.17145 to 0.14861, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/014-0.1486.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2127 - acc: 0.9308 - val_loss: 0.1486 - val_acc: 0.9578\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2004 - acc: 0.9356\n",
      "Epoch 00015: val_loss did not improve from 0.14861\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2004 - acc: 0.9356 - val_loss: 0.1668 - val_acc: 0.9481\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1924 - acc: 0.9370\n",
      "Epoch 00016: val_loss improved from 0.14861 to 0.14784, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/016-0.1478.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1924 - acc: 0.9370 - val_loss: 0.1478 - val_acc: 0.9525\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9424\n",
      "Epoch 00017: val_loss did not improve from 0.14784\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1772 - acc: 0.9424 - val_loss: 0.1584 - val_acc: 0.9509\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1671 - acc: 0.9453\n",
      "Epoch 00018: val_loss did not improve from 0.14784\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1671 - acc: 0.9453 - val_loss: 0.1536 - val_acc: 0.9550\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9483\n",
      "Epoch 00019: val_loss did not improve from 0.14784\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1605 - acc: 0.9483 - val_loss: 0.1796 - val_acc: 0.9443\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9514\n",
      "Epoch 00020: val_loss improved from 0.14784 to 0.14230, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/020-0.1423.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1504 - acc: 0.9514 - val_loss: 0.1423 - val_acc: 0.9571\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9524\n",
      "Epoch 00021: val_loss improved from 0.14230 to 0.14224, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/021-0.1422.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1435 - acc: 0.9524 - val_loss: 0.1422 - val_acc: 0.9578\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9560\n",
      "Epoch 00022: val_loss improved from 0.14224 to 0.13247, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/022-0.1325.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1313 - acc: 0.9560 - val_loss: 0.1325 - val_acc: 0.9609\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9570\n",
      "Epoch 00023: val_loss did not improve from 0.13247\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1271 - acc: 0.9570 - val_loss: 0.1608 - val_acc: 0.9511\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9589\n",
      "Epoch 00024: val_loss did not improve from 0.13247\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1249 - acc: 0.9589 - val_loss: 0.1499 - val_acc: 0.9576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9607\n",
      "Epoch 00025: val_loss did not improve from 0.13247\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1192 - acc: 0.9607 - val_loss: 0.1452 - val_acc: 0.9541\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9621\n",
      "Epoch 00026: val_loss improved from 0.13247 to 0.12061, saving model to model/checkpoint/1D_CNN_custom_3_DO_8_conv_checkpoint/026-0.1206.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1136 - acc: 0.9622 - val_loss: 0.1206 - val_acc: 0.9623\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9656\n",
      "Epoch 00027: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1068 - acc: 0.9656 - val_loss: 0.1271 - val_acc: 0.9613\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9674\n",
      "Epoch 00028: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0973 - acc: 0.9674 - val_loss: 0.1334 - val_acc: 0.9611\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9679\n",
      "Epoch 00029: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0959 - acc: 0.9679 - val_loss: 0.1376 - val_acc: 0.9618\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9669\n",
      "Epoch 00030: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0972 - acc: 0.9669 - val_loss: 0.1345 - val_acc: 0.9651\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9700\n",
      "Epoch 00031: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0885 - acc: 0.9700 - val_loss: 0.1228 - val_acc: 0.9665\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9712\n",
      "Epoch 00032: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0834 - acc: 0.9712 - val_loss: 0.1264 - val_acc: 0.9646\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9714\n",
      "Epoch 00033: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0851 - acc: 0.9714 - val_loss: 0.1260 - val_acc: 0.9637\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9737\n",
      "Epoch 00034: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0787 - acc: 0.9737 - val_loss: 0.1297 - val_acc: 0.9639\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9745\n",
      "Epoch 00035: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0751 - acc: 0.9745 - val_loss: 0.1295 - val_acc: 0.9637\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9758\n",
      "Epoch 00036: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0729 - acc: 0.9758 - val_loss: 0.1382 - val_acc: 0.9630\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9766\n",
      "Epoch 00037: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0686 - acc: 0.9766 - val_loss: 0.1371 - val_acc: 0.9648\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9765\n",
      "Epoch 00038: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0699 - acc: 0.9765 - val_loss: 0.1328 - val_acc: 0.9620\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9765\n",
      "Epoch 00039: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0678 - acc: 0.9765 - val_loss: 0.1289 - val_acc: 0.9637\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9790\n",
      "Epoch 00040: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0638 - acc: 0.9790 - val_loss: 0.1331 - val_acc: 0.9648\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9812\n",
      "Epoch 00041: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0553 - acc: 0.9812 - val_loss: 0.1646 - val_acc: 0.9606\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9796\n",
      "Epoch 00042: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0588 - acc: 0.9796 - val_loss: 0.1336 - val_acc: 0.9646\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9795\n",
      "Epoch 00043: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0627 - acc: 0.9795 - val_loss: 0.1454 - val_acc: 0.9648\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9808\n",
      "Epoch 00044: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0550 - acc: 0.9808 - val_loss: 0.1364 - val_acc: 0.9672\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9811\n",
      "Epoch 00045: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0558 - acc: 0.9811 - val_loss: 0.1428 - val_acc: 0.9637\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9829\n",
      "Epoch 00046: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0510 - acc: 0.9829 - val_loss: 0.1390 - val_acc: 0.9644\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9831\n",
      "Epoch 00047: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0487 - acc: 0.9831 - val_loss: 0.1267 - val_acc: 0.9683\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9832\n",
      "Epoch 00048: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0492 - acc: 0.9832 - val_loss: 0.1532 - val_acc: 0.9632\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9848\n",
      "Epoch 00049: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0460 - acc: 0.9848 - val_loss: 0.1571 - val_acc: 0.9644\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9824\n",
      "Epoch 00050: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0494 - acc: 0.9824 - val_loss: 0.1357 - val_acc: 0.9653\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9854\n",
      "Epoch 00051: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0432 - acc: 0.9854 - val_loss: 0.1448 - val_acc: 0.9651\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9848\n",
      "Epoch 00052: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0459 - acc: 0.9848 - val_loss: 0.1405 - val_acc: 0.9655\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9869\n",
      "Epoch 00053: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0397 - acc: 0.9869 - val_loss: 0.1833 - val_acc: 0.9627\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9854\n",
      "Epoch 00054: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0420 - acc: 0.9854 - val_loss: 0.1326 - val_acc: 0.9651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9867\n",
      "Epoch 00055: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0407 - acc: 0.9867 - val_loss: 0.1279 - val_acc: 0.9669\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9852\n",
      "Epoch 00056: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0409 - acc: 0.9852 - val_loss: 0.1487 - val_acc: 0.9653\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9876\n",
      "Epoch 00057: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0360 - acc: 0.9875 - val_loss: 0.1361 - val_acc: 0.9679\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9871\n",
      "Epoch 00058: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0374 - acc: 0.9871 - val_loss: 0.1586 - val_acc: 0.9641\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9876\n",
      "Epoch 00059: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0365 - acc: 0.9875 - val_loss: 0.1510 - val_acc: 0.9658\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9869\n",
      "Epoch 00060: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0378 - acc: 0.9869 - val_loss: 0.1547 - val_acc: 0.9676\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9885\n",
      "Epoch 00061: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0347 - acc: 0.9885 - val_loss: 0.1309 - val_acc: 0.9704\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9876\n",
      "Epoch 00062: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0357 - acc: 0.9876 - val_loss: 0.1555 - val_acc: 0.9630\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9884\n",
      "Epoch 00063: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0348 - acc: 0.9884 - val_loss: 0.1620 - val_acc: 0.9616\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9893\n",
      "Epoch 00064: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0328 - acc: 0.9893 - val_loss: 0.1521 - val_acc: 0.9653\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9892\n",
      "Epoch 00065: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0331 - acc: 0.9892 - val_loss: 0.1367 - val_acc: 0.9700\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9894\n",
      "Epoch 00066: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0298 - acc: 0.9894 - val_loss: 0.1524 - val_acc: 0.9667\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9903\n",
      "Epoch 00067: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0303 - acc: 0.9903 - val_loss: 0.1402 - val_acc: 0.9704\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9895\n",
      "Epoch 00068: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0304 - acc: 0.9895 - val_loss: 0.1438 - val_acc: 0.9674\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9909\n",
      "Epoch 00069: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0266 - acc: 0.9909 - val_loss: 0.1820 - val_acc: 0.9639\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9900\n",
      "Epoch 00070: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0302 - acc: 0.9900 - val_loss: 0.1557 - val_acc: 0.9667\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9907\n",
      "Epoch 00071: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0276 - acc: 0.9907 - val_loss: 0.1449 - val_acc: 0.9660\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9907\n",
      "Epoch 00072: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0279 - acc: 0.9907 - val_loss: 0.1582 - val_acc: 0.9669\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9914\n",
      "Epoch 00073: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0256 - acc: 0.9914 - val_loss: 0.1720 - val_acc: 0.9651\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9907\n",
      "Epoch 00074: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0278 - acc: 0.9907 - val_loss: 0.1609 - val_acc: 0.9669\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9918\n",
      "Epoch 00075: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0271 - acc: 0.9918 - val_loss: 0.1660 - val_acc: 0.9639\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9910\n",
      "Epoch 00076: val_loss did not improve from 0.12061\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0300 - acc: 0.9910 - val_loss: 0.1506 - val_acc: 0.9672\n",
      "\n",
      "1D_CNN_custom_3_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 652us/sample - loss: 0.1654 - acc: 0.9470\n",
      "Loss: 0.16538701458589433 Accuracy: 0.9470405\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8831 - acc: 0.3923\n",
      "Epoch 00001: val_loss improved from inf to 0.90783, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/001-0.9078.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 1.8832 - acc: 0.3922 - val_loss: 0.9078 - val_acc: 0.7135\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8713 - acc: 0.7207\n",
      "Epoch 00002: val_loss improved from 0.90783 to 0.58937, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/002-0.5894.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.8713 - acc: 0.7207 - val_loss: 0.5894 - val_acc: 0.8157\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6064 - acc: 0.8050\n",
      "Epoch 00003: val_loss improved from 0.58937 to 0.37902, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/003-0.3790.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.6064 - acc: 0.8049 - val_loss: 0.3790 - val_acc: 0.8849\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4720 - acc: 0.8480\n",
      "Epoch 00004: val_loss improved from 0.37902 to 0.28340, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/004-0.2834.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.4720 - acc: 0.8480 - val_loss: 0.2834 - val_acc: 0.9101\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3920 - acc: 0.8757\n",
      "Epoch 00005: val_loss improved from 0.28340 to 0.24265, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/005-0.2427.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.3921 - acc: 0.8757 - val_loss: 0.2427 - val_acc: 0.9255\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3369 - acc: 0.8915\n",
      "Epoch 00006: val_loss improved from 0.24265 to 0.23505, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/006-0.2351.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.3369 - acc: 0.8915 - val_loss: 0.2351 - val_acc: 0.9259\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2975 - acc: 0.9060\n",
      "Epoch 00007: val_loss improved from 0.23505 to 0.19714, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/007-0.1971.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.2975 - acc: 0.9060 - val_loss: 0.1971 - val_acc: 0.9376\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2705 - acc: 0.9143\n",
      "Epoch 00008: val_loss did not improve from 0.19714\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.2705 - acc: 0.9143 - val_loss: 0.2089 - val_acc: 0.9341\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2399 - acc: 0.9233\n",
      "Epoch 00009: val_loss improved from 0.19714 to 0.17106, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/009-0.1711.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.2399 - acc: 0.9234 - val_loss: 0.1711 - val_acc: 0.9453\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9298\n",
      "Epoch 00010: val_loss improved from 0.17106 to 0.17004, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/010-0.1700.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.2190 - acc: 0.9298 - val_loss: 0.1700 - val_acc: 0.9478\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9348\n",
      "Epoch 00011: val_loss did not improve from 0.17004\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1982 - acc: 0.9348 - val_loss: 0.1712 - val_acc: 0.9446\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9399\n",
      "Epoch 00012: val_loss improved from 0.17004 to 0.15654, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/012-0.1565.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1842 - acc: 0.9399 - val_loss: 0.1565 - val_acc: 0.9502\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9447\n",
      "Epoch 00013: val_loss improved from 0.15654 to 0.15147, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/013-0.1515.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1722 - acc: 0.9447 - val_loss: 0.1515 - val_acc: 0.9522\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1571 - acc: 0.9489\n",
      "Epoch 00014: val_loss did not improve from 0.15147\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1572 - acc: 0.9489 - val_loss: 0.1604 - val_acc: 0.9520\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9530\n",
      "Epoch 00015: val_loss improved from 0.15147 to 0.14337, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/015-0.1434.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1444 - acc: 0.9530 - val_loss: 0.1434 - val_acc: 0.9555\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9542\n",
      "Epoch 00016: val_loss did not improve from 0.14337\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1344 - acc: 0.9542 - val_loss: 0.1462 - val_acc: 0.9541\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9583\n",
      "Epoch 00017: val_loss did not improve from 0.14337\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1284 - acc: 0.9583 - val_loss: 0.1503 - val_acc: 0.9532\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9601\n",
      "Epoch 00018: val_loss did not improve from 0.14337\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1206 - acc: 0.9601 - val_loss: 0.1481 - val_acc: 0.9550\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9625\n",
      "Epoch 00019: val_loss did not improve from 0.14337\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1112 - acc: 0.9625 - val_loss: 0.1552 - val_acc: 0.9515\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9654\n",
      "Epoch 00020: val_loss did not improve from 0.14337\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1008 - acc: 0.9654 - val_loss: 0.1627 - val_acc: 0.9560\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9647\n",
      "Epoch 00021: val_loss improved from 0.14337 to 0.13144, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/021-0.1314.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1026 - acc: 0.9647 - val_loss: 0.1314 - val_acc: 0.9599\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9682\n",
      "Epoch 00022: val_loss did not improve from 0.13144\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0927 - acc: 0.9682 - val_loss: 0.1355 - val_acc: 0.9595\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9708\n",
      "Epoch 00023: val_loss improved from 0.13144 to 0.12694, saving model to model/checkpoint/1D_CNN_custom_3_DO_9_conv_checkpoint/023-0.1269.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0863 - acc: 0.9708 - val_loss: 0.1269 - val_acc: 0.9595\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9730\n",
      "Epoch 00024: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0808 - acc: 0.9730 - val_loss: 0.1796 - val_acc: 0.9525\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9745\n",
      "Epoch 00025: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0779 - acc: 0.9745 - val_loss: 0.1456 - val_acc: 0.9616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9758\n",
      "Epoch 00026: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0713 - acc: 0.9758 - val_loss: 0.1428 - val_acc: 0.9604\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9766\n",
      "Epoch 00027: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0684 - acc: 0.9766 - val_loss: 0.1627 - val_acc: 0.9543\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9779\n",
      "Epoch 00028: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0648 - acc: 0.9779 - val_loss: 0.1457 - val_acc: 0.9604\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9779\n",
      "Epoch 00029: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0649 - acc: 0.9779 - val_loss: 0.1392 - val_acc: 0.9613\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9798\n",
      "Epoch 00030: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0590 - acc: 0.9798 - val_loss: 0.1557 - val_acc: 0.9592\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9812\n",
      "Epoch 00031: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0553 - acc: 0.9812 - val_loss: 0.1496 - val_acc: 0.9630\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9814\n",
      "Epoch 00032: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0540 - acc: 0.9814 - val_loss: 0.1669 - val_acc: 0.9588\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9827\n",
      "Epoch 00033: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0522 - acc: 0.9827 - val_loss: 0.1479 - val_acc: 0.9616\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9832\n",
      "Epoch 00034: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0511 - acc: 0.9832 - val_loss: 0.1389 - val_acc: 0.9639\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9853\n",
      "Epoch 00035: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0443 - acc: 0.9853 - val_loss: 0.1556 - val_acc: 0.9639\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9845\n",
      "Epoch 00036: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0454 - acc: 0.9845 - val_loss: 0.2001 - val_acc: 0.9567\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9849\n",
      "Epoch 00037: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0461 - acc: 0.9849 - val_loss: 0.1446 - val_acc: 0.9611\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9860\n",
      "Epoch 00038: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0411 - acc: 0.9860 - val_loss: 0.1502 - val_acc: 0.9667\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9870\n",
      "Epoch 00039: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0394 - acc: 0.9869 - val_loss: 0.1523 - val_acc: 0.9620\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9875\n",
      "Epoch 00040: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0364 - acc: 0.9875 - val_loss: 0.1620 - val_acc: 0.9627\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9876\n",
      "Epoch 00041: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0364 - acc: 0.9876 - val_loss: 0.1818 - val_acc: 0.9613\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9874\n",
      "Epoch 00042: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0368 - acc: 0.9874 - val_loss: 0.1516 - val_acc: 0.9639\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9892\n",
      "Epoch 00043: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0343 - acc: 0.9892 - val_loss: 0.1729 - val_acc: 0.9630\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9884\n",
      "Epoch 00044: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0350 - acc: 0.9884 - val_loss: 0.1565 - val_acc: 0.9665\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9898\n",
      "Epoch 00045: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0312 - acc: 0.9898 - val_loss: 0.1461 - val_acc: 0.9679\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9890\n",
      "Epoch 00046: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0328 - acc: 0.9890 - val_loss: 0.1746 - val_acc: 0.9634\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9905\n",
      "Epoch 00047: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0291 - acc: 0.9905 - val_loss: 0.1768 - val_acc: 0.9581\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9904\n",
      "Epoch 00048: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0309 - acc: 0.9904 - val_loss: 0.1655 - val_acc: 0.9602\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9891\n",
      "Epoch 00049: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0333 - acc: 0.9891 - val_loss: 0.1693 - val_acc: 0.9627\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9896\n",
      "Epoch 00050: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0303 - acc: 0.9896 - val_loss: 0.2132 - val_acc: 0.9511\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9912\n",
      "Epoch 00051: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0258 - acc: 0.9912 - val_loss: 0.1747 - val_acc: 0.9630\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9915\n",
      "Epoch 00052: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0266 - acc: 0.9916 - val_loss: 0.1751 - val_acc: 0.9623\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9902\n",
      "Epoch 00053: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0287 - acc: 0.9902 - val_loss: 0.2011 - val_acc: 0.9590\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9919\n",
      "Epoch 00054: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0235 - acc: 0.9919 - val_loss: 0.1829 - val_acc: 0.9648\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9920\n",
      "Epoch 00055: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0267 - acc: 0.9920 - val_loss: 0.1638 - val_acc: 0.9641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9925\n",
      "Epoch 00056: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0237 - acc: 0.9925 - val_loss: 0.1847 - val_acc: 0.9616\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9920\n",
      "Epoch 00057: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0256 - acc: 0.9920 - val_loss: 0.1537 - val_acc: 0.9634\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9928\n",
      "Epoch 00058: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0227 - acc: 0.9928 - val_loss: 0.1876 - val_acc: 0.9644\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9922\n",
      "Epoch 00059: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0239 - acc: 0.9922 - val_loss: 0.1853 - val_acc: 0.9620\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9936\n",
      "Epoch 00060: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0200 - acc: 0.9936 - val_loss: 0.1772 - val_acc: 0.9662\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9915\n",
      "Epoch 00061: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0247 - acc: 0.9916 - val_loss: 0.1778 - val_acc: 0.9641\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9943\n",
      "Epoch 00062: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0194 - acc: 0.9943 - val_loss: 0.1776 - val_acc: 0.9658\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9935\n",
      "Epoch 00063: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0203 - acc: 0.9935 - val_loss: 0.1851 - val_acc: 0.9606\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9938\n",
      "Epoch 00064: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0201 - acc: 0.9938 - val_loss: 0.1649 - val_acc: 0.9667\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9943\n",
      "Epoch 00065: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0180 - acc: 0.9943 - val_loss: 0.2164 - val_acc: 0.9625\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9936\n",
      "Epoch 00066: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0201 - acc: 0.9936 - val_loss: 0.1788 - val_acc: 0.9648\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9939\n",
      "Epoch 00067: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0181 - acc: 0.9939 - val_loss: 0.1897 - val_acc: 0.9637\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9943\n",
      "Epoch 00068: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0175 - acc: 0.9943 - val_loss: 0.1721 - val_acc: 0.9655\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9939\n",
      "Epoch 00069: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0186 - acc: 0.9939 - val_loss: 0.1742 - val_acc: 0.9660\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9940\n",
      "Epoch 00070: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0181 - acc: 0.9940 - val_loss: 0.1813 - val_acc: 0.9630\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9941\n",
      "Epoch 00071: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0178 - acc: 0.9941 - val_loss: 0.1855 - val_acc: 0.9662\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9942\n",
      "Epoch 00072: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0184 - acc: 0.9942 - val_loss: 0.1755 - val_acc: 0.9648\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9945\n",
      "Epoch 00073: val_loss did not improve from 0.12694\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0159 - acc: 0.9945 - val_loss: 0.1816 - val_acc: 0.9651\n",
      "\n",
      "1D_CNN_custom_3_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 685us/sample - loss: 0.1985 - acc: 0.9402\n",
      "Loss: 0.19848673819861185 Accuracy: 0.9401869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 10):\n",
    "    base = '1D_CNN_custom_3_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_3_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,294,992\n",
      "Trainable params: 1,294,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 634us/sample - loss: 1.1352 - acc: 0.6540\n",
      "Loss: 1.135193683920372 Accuracy: 0.6539979\n",
      "\n",
      "1D_CNN_custom_3_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 568,080\n",
      "Trainable params: 568,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 666us/sample - loss: 0.8078 - acc: 0.7724\n",
      "Loss: 0.8077790394255182 Accuracy: 0.77237797\n",
      "\n",
      "1D_CNN_custom_3_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 379,792\n",
      "Trainable params: 379,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 660us/sample - loss: 0.4158 - acc: 0.8862\n",
      "Loss: 0.4157717520202803 Accuracy: 0.886189\n",
      "\n",
      "1D_CNN_custom_3_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 496,784\n",
      "Trainable params: 496,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 670us/sample - loss: 0.2246 - acc: 0.9327\n",
      "Loss: 0.224630900942029 Accuracy: 0.9327103\n",
      "\n",
      "1D_CNN_custom_3_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 767,376\n",
      "Trainable params: 767,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 702us/sample - loss: 0.1654 - acc: 0.9470\n",
      "Loss: 0.16538701458589433 Accuracy: 0.9470405\n",
      "\n",
      "1D_CNN_custom_3_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 256)            327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,074,832\n",
      "Trainable params: 1,074,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 729us/sample - loss: 0.1985 - acc: 0.9402\n",
      "Loss: 0.19848673819861185 Accuracy: 0.9401869\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_3_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(4, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_3_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,294,992\n",
      "Trainable params: 1,294,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 684us/sample - loss: 1.8625 - acc: 0.6976\n",
      "Loss: 1.8625344471025318 Accuracy: 0.69761163\n",
      "\n",
      "1D_CNN_custom_3_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 568,080\n",
      "Trainable params: 568,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 696us/sample - loss: 1.1456 - acc: 0.7975\n",
      "Loss: 1.1455812873870042 Accuracy: 0.79750776\n",
      "\n",
      "1D_CNN_custom_3_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 379,792\n",
      "Trainable params: 379,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 722us/sample - loss: 0.5039 - acc: 0.8922\n",
      "Loss: 0.5039262147212202 Accuracy: 0.89221185\n",
      "\n",
      "1D_CNN_custom_3_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 496,784\n",
      "Trainable params: 496,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 730us/sample - loss: 0.3232 - acc: 0.9323\n",
      "Loss: 0.32320576873825535 Accuracy: 0.9322949\n",
      "\n",
      "1D_CNN_custom_3_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 767,376\n",
      "Trainable params: 767,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 748us/sample - loss: 0.1679 - acc: 0.9585\n",
      "Loss: 0.16788525292004927 Accuracy: 0.95846313\n",
      "\n",
      "1D_CNN_custom_3_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 256)            327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,074,832\n",
      "Trainable params: 1,074,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 768us/sample - loss: 0.2599 - acc: 0.9512\n",
      "Loss: 0.2599220522187366 Accuracy: 0.95119417\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(4, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
