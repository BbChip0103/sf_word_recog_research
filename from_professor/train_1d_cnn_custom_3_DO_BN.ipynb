{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO_BN(conv_num=1):\n",
    "    init_channel = 64\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=init_channel, strides=1, \n",
    "                      padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=int(init_channel*(2**int((i+1)/3))), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,296,272\n",
      "Trainable params: 1,295,632\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 569,872\n",
      "Trainable params: 568,976\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 382,096\n",
      "Trainable params: 380,944\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 500,112\n",
      "Trainable params: 498,448\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 771,728\n",
      "Trainable params: 769,552\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,080,208\n",
      "Trainable params: 1,077,520\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1826 - acc: 0.3753\n",
      "Epoch 00001: val_loss improved from inf to 1.52981, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_4_conv_checkpoint/001-1.5298.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 2.1825 - acc: 0.3753 - val_loss: 1.5298 - val_acc: 0.4990\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3878 - acc: 0.5745\n",
      "Epoch 00002: val_loss improved from 1.52981 to 1.20548, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_4_conv_checkpoint/002-1.2055.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.3878 - acc: 0.5745 - val_loss: 1.2055 - val_acc: 0.6348\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1196 - acc: 0.6542\n",
      "Epoch 00003: val_loss improved from 1.20548 to 1.19680, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_4_conv_checkpoint/003-1.1968.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.1197 - acc: 0.6542 - val_loss: 1.1968 - val_acc: 0.6539\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9762 - acc: 0.7019\n",
      "Epoch 00004: val_loss improved from 1.19680 to 0.96305, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_4_conv_checkpoint/004-0.9631.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9762 - acc: 0.7019 - val_loss: 0.9631 - val_acc: 0.7191\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8514 - acc: 0.7351\n",
      "Epoch 00005: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8514 - acc: 0.7350 - val_loss: 1.0689 - val_acc: 0.6897\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7441 - acc: 0.7680\n",
      "Epoch 00006: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7441 - acc: 0.7680 - val_loss: 1.2152 - val_acc: 0.6403\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6483 - acc: 0.7947\n",
      "Epoch 00007: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6483 - acc: 0.7947 - val_loss: 1.0061 - val_acc: 0.7119\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5629 - acc: 0.8200\n",
      "Epoch 00008: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5629 - acc: 0.8200 - val_loss: 1.0328 - val_acc: 0.7109\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5085 - acc: 0.8377\n",
      "Epoch 00009: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5086 - acc: 0.8377 - val_loss: 1.1524 - val_acc: 0.6879\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4531 - acc: 0.8545\n",
      "Epoch 00010: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4530 - acc: 0.8545 - val_loss: 1.1896 - val_acc: 0.6853\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4037 - acc: 0.8702\n",
      "Epoch 00011: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4037 - acc: 0.8702 - val_loss: 1.1462 - val_acc: 0.7011\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3668 - acc: 0.8804\n",
      "Epoch 00012: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3668 - acc: 0.8803 - val_loss: 1.0575 - val_acc: 0.7181\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3493 - acc: 0.8860\n",
      "Epoch 00013: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3493 - acc: 0.8860 - val_loss: 1.1900 - val_acc: 0.6951\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3106 - acc: 0.8992\n",
      "Epoch 00014: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3106 - acc: 0.8993 - val_loss: 1.2436 - val_acc: 0.6907\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2876 - acc: 0.9059\n",
      "Epoch 00015: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2877 - acc: 0.9059 - val_loss: 1.2537 - val_acc: 0.6872\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2676 - acc: 0.9125\n",
      "Epoch 00016: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2676 - acc: 0.9125 - val_loss: 1.0047 - val_acc: 0.7501\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2468 - acc: 0.9198\n",
      "Epoch 00017: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2468 - acc: 0.9198 - val_loss: 1.2590 - val_acc: 0.7018\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2317 - acc: 0.9256\n",
      "Epoch 00018: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2318 - acc: 0.9256 - val_loss: 1.1415 - val_acc: 0.7314\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9280\n",
      "Epoch 00019: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2195 - acc: 0.9279 - val_loss: 1.3334 - val_acc: 0.6969\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2097 - acc: 0.9324\n",
      "Epoch 00020: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2097 - acc: 0.9325 - val_loss: 1.0974 - val_acc: 0.7396\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1889 - acc: 0.9386\n",
      "Epoch 00021: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1891 - acc: 0.9385 - val_loss: 1.2430 - val_acc: 0.7109\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9401\n",
      "Epoch 00022: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1844 - acc: 0.9400 - val_loss: 1.2775 - val_acc: 0.7181\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1858 - acc: 0.9412\n",
      "Epoch 00023: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1859 - acc: 0.9412 - val_loss: 1.3452 - val_acc: 0.7158\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1660 - acc: 0.9457\n",
      "Epoch 00024: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1660 - acc: 0.9457 - val_loss: 1.2436 - val_acc: 0.7247\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9481\n",
      "Epoch 00025: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1628 - acc: 0.9481 - val_loss: 1.4963 - val_acc: 0.7021\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9492\n",
      "Epoch 00026: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1571 - acc: 0.9491 - val_loss: 1.2061 - val_acc: 0.7466\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1540 - acc: 0.9516\n",
      "Epoch 00027: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1540 - acc: 0.9516 - val_loss: 1.1670 - val_acc: 0.7470\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9519\n",
      "Epoch 00028: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1491 - acc: 0.9519 - val_loss: 1.2593 - val_acc: 0.7272\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9563\n",
      "Epoch 00029: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1373 - acc: 0.9563 - val_loss: 1.3812 - val_acc: 0.7212\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9579\n",
      "Epoch 00030: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1305 - acc: 0.9579 - val_loss: 1.4110 - val_acc: 0.7167\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9557\n",
      "Epoch 00031: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1390 - acc: 0.9557 - val_loss: 1.2589 - val_acc: 0.7382\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9604\n",
      "Epoch 00032: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1245 - acc: 0.9604 - val_loss: 1.2821 - val_acc: 0.7419\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9615\n",
      "Epoch 00033: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1228 - acc: 0.9615 - val_loss: 1.3325 - val_acc: 0.7277\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9607\n",
      "Epoch 00034: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1222 - acc: 0.9607 - val_loss: 1.3769 - val_acc: 0.7261\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9620\n",
      "Epoch 00035: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1196 - acc: 0.9620 - val_loss: 1.3621 - val_acc: 0.7193\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9659\n",
      "Epoch 00036: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1067 - acc: 0.9658 - val_loss: 1.4889 - val_acc: 0.7121\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9606\n",
      "Epoch 00037: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1243 - acc: 0.9606 - val_loss: 1.4721 - val_acc: 0.7177\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9661\n",
      "Epoch 00038: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1097 - acc: 0.9661 - val_loss: 1.2526 - val_acc: 0.7482\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9672\n",
      "Epoch 00039: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1037 - acc: 0.9672 - val_loss: 1.4053 - val_acc: 0.7365\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9670\n",
      "Epoch 00040: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1073 - acc: 0.9670 - val_loss: 1.4451 - val_acc: 0.7209\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9690\n",
      "Epoch 00041: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0973 - acc: 0.9690 - val_loss: 1.5008 - val_acc: 0.7181\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9694\n",
      "Epoch 00042: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1000 - acc: 0.9694 - val_loss: 1.2543 - val_acc: 0.7601\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9681\n",
      "Epoch 00043: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1010 - acc: 0.9681 - val_loss: 1.4081 - val_acc: 0.7244\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9704\n",
      "Epoch 00044: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0949 - acc: 0.9704 - val_loss: 1.2418 - val_acc: 0.7538\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9712\n",
      "Epoch 00045: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0928 - acc: 0.9713 - val_loss: 1.3301 - val_acc: 0.7433\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9753\n",
      "Epoch 00046: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0823 - acc: 0.9753 - val_loss: 1.2935 - val_acc: 0.7596\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9735\n",
      "Epoch 00047: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0869 - acc: 0.9735 - val_loss: 1.4030 - val_acc: 0.7468\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9749\n",
      "Epoch 00048: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0814 - acc: 0.9749 - val_loss: 1.6253 - val_acc: 0.7133\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9754\n",
      "Epoch 00049: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0847 - acc: 0.9754 - val_loss: 1.3176 - val_acc: 0.7505\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9745\n",
      "Epoch 00050: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0838 - acc: 0.9745 - val_loss: 1.3143 - val_acc: 0.7543\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9752\n",
      "Epoch 00051: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0821 - acc: 0.9752 - val_loss: 1.5432 - val_acc: 0.7331\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9768\n",
      "Epoch 00052: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0755 - acc: 0.9768 - val_loss: 1.2962 - val_acc: 0.7543\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9753\n",
      "Epoch 00053: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0805 - acc: 0.9753 - val_loss: 1.3634 - val_acc: 0.7407\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9767\n",
      "Epoch 00054: val_loss did not improve from 0.96305\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0736 - acc: 0.9767 - val_loss: 1.4215 - val_acc: 0.7501\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 5.6159 - acc: 0.4974\n",
      "Loss: 5.615899310503174 Accuracy: 0.49740395\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0991 - acc: 0.3745\n",
      "Epoch 00001: val_loss improved from inf to 1.50678, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_5_conv_checkpoint/001-1.5068.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 2.0992 - acc: 0.3744 - val_loss: 1.5068 - val_acc: 0.5083\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3306 - acc: 0.5855\n",
      "Epoch 00002: val_loss improved from 1.50678 to 1.08817, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_5_conv_checkpoint/002-1.0882.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 1.3307 - acc: 0.5854 - val_loss: 1.0882 - val_acc: 0.6697\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0784 - acc: 0.6684\n",
      "Epoch 00003: val_loss improved from 1.08817 to 0.91497, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_5_conv_checkpoint/003-0.9150.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 1.0789 - acc: 0.6684 - val_loss: 0.9150 - val_acc: 0.7228\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9553 - acc: 0.7082\n",
      "Epoch 00004: val_loss did not improve from 0.91497\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.9553 - acc: 0.7082 - val_loss: 1.1018 - val_acc: 0.6748\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8630 - acc: 0.7371\n",
      "Epoch 00005: val_loss improved from 0.91497 to 0.84046, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_5_conv_checkpoint/005-0.8405.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.8630 - acc: 0.7371 - val_loss: 0.8405 - val_acc: 0.7482\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7835 - acc: 0.7598\n",
      "Epoch 00006: val_loss improved from 0.84046 to 0.74042, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_5_conv_checkpoint/006-0.7404.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.7835 - acc: 0.7598 - val_loss: 0.7404 - val_acc: 0.7803\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7272 - acc: 0.7782\n",
      "Epoch 00007: val_loss did not improve from 0.74042\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.7274 - acc: 0.7782 - val_loss: 0.8156 - val_acc: 0.7529\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6824 - acc: 0.7933\n",
      "Epoch 00008: val_loss did not improve from 0.74042\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.6824 - acc: 0.7933 - val_loss: 0.8092 - val_acc: 0.7661\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6261 - acc: 0.8096\n",
      "Epoch 00009: val_loss did not improve from 0.74042\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.6261 - acc: 0.8096 - val_loss: 0.9362 - val_acc: 0.7230\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5854 - acc: 0.8198\n",
      "Epoch 00010: val_loss did not improve from 0.74042\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.5854 - acc: 0.8197 - val_loss: 0.7963 - val_acc: 0.7603\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5571 - acc: 0.8299\n",
      "Epoch 00011: val_loss did not improve from 0.74042\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.5572 - acc: 0.8299 - val_loss: 0.7426 - val_acc: 0.7950\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5225 - acc: 0.8387\n",
      "Epoch 00012: val_loss improved from 0.74042 to 0.64540, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_5_conv_checkpoint/012-0.6454.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.5227 - acc: 0.8387 - val_loss: 0.6454 - val_acc: 0.8132\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4915 - acc: 0.8479\n",
      "Epoch 00013: val_loss did not improve from 0.64540\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4915 - acc: 0.8479 - val_loss: 0.6915 - val_acc: 0.8097\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4651 - acc: 0.8557\n",
      "Epoch 00014: val_loss improved from 0.64540 to 0.64220, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_5_conv_checkpoint/014-0.6422.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4652 - acc: 0.8557 - val_loss: 0.6422 - val_acc: 0.8244\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4408 - acc: 0.8637\n",
      "Epoch 00015: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4408 - acc: 0.8637 - val_loss: 0.7472 - val_acc: 0.7957\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4155 - acc: 0.8692\n",
      "Epoch 00016: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4154 - acc: 0.8692 - val_loss: 0.6567 - val_acc: 0.8064\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3948 - acc: 0.8763\n",
      "Epoch 00017: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3949 - acc: 0.8762 - val_loss: 0.6864 - val_acc: 0.8120\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3782 - acc: 0.8807\n",
      "Epoch 00018: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3786 - acc: 0.8806 - val_loss: 0.7281 - val_acc: 0.7941\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3590 - acc: 0.8887\n",
      "Epoch 00019: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3590 - acc: 0.8887 - val_loss: 0.6924 - val_acc: 0.8069\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3380 - acc: 0.8948\n",
      "Epoch 00020: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3380 - acc: 0.8948 - val_loss: 0.7500 - val_acc: 0.7925\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3143 - acc: 0.9004\n",
      "Epoch 00021: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3144 - acc: 0.9004 - val_loss: 0.6987 - val_acc: 0.8060\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3097 - acc: 0.9020\n",
      "Epoch 00022: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3097 - acc: 0.9019 - val_loss: 0.6895 - val_acc: 0.8153\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3013 - acc: 0.9051\n",
      "Epoch 00023: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3012 - acc: 0.9051 - val_loss: 0.6593 - val_acc: 0.8262\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2755 - acc: 0.9129\n",
      "Epoch 00024: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2756 - acc: 0.9128 - val_loss: 0.9641 - val_acc: 0.7519\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2785 - acc: 0.9115\n",
      "Epoch 00025: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2785 - acc: 0.9115 - val_loss: 0.7138 - val_acc: 0.8176\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2550 - acc: 0.9186\n",
      "Epoch 00026: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2551 - acc: 0.9186 - val_loss: 0.6700 - val_acc: 0.8279\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2429 - acc: 0.9222\n",
      "Epoch 00027: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2429 - acc: 0.9222 - val_loss: 0.7360 - val_acc: 0.8164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2359 - acc: 0.9232\n",
      "Epoch 00028: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2359 - acc: 0.9231 - val_loss: 0.7162 - val_acc: 0.8134\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2309 - acc: 0.9255\n",
      "Epoch 00029: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2309 - acc: 0.9255 - val_loss: 0.7840 - val_acc: 0.8001\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2161 - acc: 0.9306\n",
      "Epoch 00030: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2161 - acc: 0.9306 - val_loss: 0.7178 - val_acc: 0.8150\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2125 - acc: 0.9315\n",
      "Epoch 00031: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2125 - acc: 0.9316 - val_loss: 0.6624 - val_acc: 0.8323\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1890 - acc: 0.9402\n",
      "Epoch 00032: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1890 - acc: 0.9402 - val_loss: 0.6973 - val_acc: 0.8267\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1949 - acc: 0.9371\n",
      "Epoch 00033: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1949 - acc: 0.9372 - val_loss: 0.6719 - val_acc: 0.8334\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1848 - acc: 0.9421\n",
      "Epoch 00034: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1848 - acc: 0.9421 - val_loss: 0.7686 - val_acc: 0.8132\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9385\n",
      "Epoch 00035: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1868 - acc: 0.9385 - val_loss: 0.7010 - val_acc: 0.8237\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1796 - acc: 0.9407\n",
      "Epoch 00036: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1798 - acc: 0.9407 - val_loss: 0.7889 - val_acc: 0.8132\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1787 - acc: 0.9410\n",
      "Epoch 00037: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1787 - acc: 0.9410 - val_loss: 0.7436 - val_acc: 0.8286\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1647 - acc: 0.9463\n",
      "Epoch 00038: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1648 - acc: 0.9462 - val_loss: 0.6991 - val_acc: 0.8407\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9477\n",
      "Epoch 00039: val_loss did not improve from 0.64220\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1627 - acc: 0.9476 - val_loss: 0.6721 - val_acc: 0.8411\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9508\n",
      "Epoch 00040: val_loss improved from 0.64220 to 0.61870, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_5_conv_checkpoint/040-0.6187.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1527 - acc: 0.9508 - val_loss: 0.6187 - val_acc: 0.8509\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9507\n",
      "Epoch 00041: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1547 - acc: 0.9507 - val_loss: 0.7595 - val_acc: 0.8216\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9527\n",
      "Epoch 00042: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1466 - acc: 0.9528 - val_loss: 0.7769 - val_acc: 0.8255\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9507\n",
      "Epoch 00043: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1507 - acc: 0.9506 - val_loss: 0.6903 - val_acc: 0.8314\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9564\n",
      "Epoch 00044: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1369 - acc: 0.9563 - val_loss: 0.7059 - val_acc: 0.8353\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9557\n",
      "Epoch 00045: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1366 - acc: 0.9557 - val_loss: 0.7398 - val_acc: 0.8351\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9598\n",
      "Epoch 00046: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1276 - acc: 0.9598 - val_loss: 0.8111 - val_acc: 0.8048\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9583\n",
      "Epoch 00047: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1304 - acc: 0.9583 - val_loss: 0.8505 - val_acc: 0.8204\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9563\n",
      "Epoch 00048: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1312 - acc: 0.9563 - val_loss: 0.7713 - val_acc: 0.8346\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9592\n",
      "Epoch 00049: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1245 - acc: 0.9592 - val_loss: 0.7395 - val_acc: 0.8344\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9634\n",
      "Epoch 00050: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1189 - acc: 0.9633 - val_loss: 0.8199 - val_acc: 0.8183\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9598\n",
      "Epoch 00051: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1251 - acc: 0.9598 - val_loss: 0.7886 - val_acc: 0.8162\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9641\n",
      "Epoch 00052: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1139 - acc: 0.9641 - val_loss: 0.8527 - val_acc: 0.8090\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9638\n",
      "Epoch 00053: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1124 - acc: 0.9638 - val_loss: 0.7838 - val_acc: 0.8253\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9647\n",
      "Epoch 00054: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1096 - acc: 0.9647 - val_loss: 0.7638 - val_acc: 0.8355\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9635\n",
      "Epoch 00055: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1169 - acc: 0.9635 - val_loss: 0.6761 - val_acc: 0.8549\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9680\n",
      "Epoch 00056: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1021 - acc: 0.9680 - val_loss: 0.7533 - val_acc: 0.8358\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9661\n",
      "Epoch 00057: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1056 - acc: 0.9661 - val_loss: 0.9532 - val_acc: 0.8043\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9697\n",
      "Epoch 00058: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0968 - acc: 0.9697 - val_loss: 0.7687 - val_acc: 0.8369\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9679\n",
      "Epoch 00059: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1024 - acc: 0.9679 - val_loss: 0.7135 - val_acc: 0.8418\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9691\n",
      "Epoch 00060: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0965 - acc: 0.9691 - val_loss: 0.7455 - val_acc: 0.8383\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9711\n",
      "Epoch 00061: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0915 - acc: 0.9711 - val_loss: 0.7071 - val_acc: 0.8502\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9707\n",
      "Epoch 00062: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0950 - acc: 0.9707 - val_loss: 0.8018 - val_acc: 0.8332\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9693\n",
      "Epoch 00063: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1004 - acc: 0.9693 - val_loss: 0.8542 - val_acc: 0.8255\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9712\n",
      "Epoch 00064: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0934 - acc: 0.9712 - val_loss: 0.7417 - val_acc: 0.8400\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9718\n",
      "Epoch 00065: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0908 - acc: 0.9717 - val_loss: 0.6950 - val_acc: 0.8532\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9711\n",
      "Epoch 00066: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0915 - acc: 0.9711 - val_loss: 0.7949 - val_acc: 0.8376\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9727\n",
      "Epoch 00067: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0882 - acc: 0.9726 - val_loss: 0.7764 - val_acc: 0.8339\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9718\n",
      "Epoch 00068: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0882 - acc: 0.9719 - val_loss: 0.7349 - val_acc: 0.8502\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9735\n",
      "Epoch 00069: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0848 - acc: 0.9735 - val_loss: 0.7766 - val_acc: 0.8379\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9756\n",
      "Epoch 00070: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0803 - acc: 0.9756 - val_loss: 0.8272 - val_acc: 0.8374\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9757\n",
      "Epoch 00071: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0805 - acc: 0.9757 - val_loss: 0.8294 - val_acc: 0.8311\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9743\n",
      "Epoch 00072: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0808 - acc: 0.9743 - val_loss: 0.9350 - val_acc: 0.8148\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9734\n",
      "Epoch 00073: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0831 - acc: 0.9734 - val_loss: 0.7198 - val_acc: 0.8542\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9751\n",
      "Epoch 00074: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0797 - acc: 0.9751 - val_loss: 0.7127 - val_acc: 0.8537\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9742\n",
      "Epoch 00075: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0818 - acc: 0.9742 - val_loss: 0.7163 - val_acc: 0.8551\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9757\n",
      "Epoch 00076: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0781 - acc: 0.9757 - val_loss: 0.7939 - val_acc: 0.8395\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9755\n",
      "Epoch 00077: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0787 - acc: 0.9755 - val_loss: 0.7300 - val_acc: 0.8463\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9784\n",
      "Epoch 00078: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0702 - acc: 0.9783 - val_loss: 0.8504 - val_acc: 0.8316\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9741\n",
      "Epoch 00079: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0832 - acc: 0.9741 - val_loss: 0.7235 - val_acc: 0.8523\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9772\n",
      "Epoch 00080: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0736 - acc: 0.9772 - val_loss: 0.7585 - val_acc: 0.8491\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9787\n",
      "Epoch 00081: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0702 - acc: 0.9787 - val_loss: 0.9183 - val_acc: 0.8162\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9761\n",
      "Epoch 00082: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0765 - acc: 0.9761 - val_loss: 0.7316 - val_acc: 0.8549\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9812\n",
      "Epoch 00083: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0638 - acc: 0.9812 - val_loss: 0.8832 - val_acc: 0.8232\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9783\n",
      "Epoch 00084: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0706 - acc: 0.9783 - val_loss: 0.8985 - val_acc: 0.8318\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9791\n",
      "Epoch 00085: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0673 - acc: 0.9791 - val_loss: 0.6884 - val_acc: 0.8621\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9792\n",
      "Epoch 00086: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0673 - acc: 0.9792 - val_loss: 0.9035 - val_acc: 0.8169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9804\n",
      "Epoch 00087: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0640 - acc: 0.9804 - val_loss: 0.8938 - val_acc: 0.8293\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9807\n",
      "Epoch 00088: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0643 - acc: 0.9807 - val_loss: 0.8453 - val_acc: 0.8318\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9806\n",
      "Epoch 00089: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0659 - acc: 0.9806 - val_loss: 0.7579 - val_acc: 0.8481\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9777\n",
      "Epoch 00090: val_loss did not improve from 0.61870\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0741 - acc: 0.9777 - val_loss: 0.7008 - val_acc: 0.8593\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 942us/sample - loss: 0.7763 - acc: 0.8108\n",
      "Loss: 0.7762671216626034 Accuracy: 0.8107996\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1807 - acc: 0.3402\n",
      "Epoch 00001: val_loss improved from inf to 1.61615, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/001-1.6162.hdf5\n",
      "36805/36805 [==============================] - 100s 3ms/sample - loss: 2.1806 - acc: 0.3402 - val_loss: 1.6162 - val_acc: 0.4694\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3191 - acc: 0.5850\n",
      "Epoch 00002: val_loss improved from 1.61615 to 1.14666, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/002-1.1467.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 1.3193 - acc: 0.5850 - val_loss: 1.1467 - val_acc: 0.6434\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0560 - acc: 0.6702\n",
      "Epoch 00003: val_loss improved from 1.14666 to 0.81146, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/003-0.8115.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 1.0562 - acc: 0.6702 - val_loss: 0.8115 - val_acc: 0.7643\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8917 - acc: 0.7260\n",
      "Epoch 00004: val_loss did not improve from 0.81146\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.8918 - acc: 0.7259 - val_loss: 0.8777 - val_acc: 0.7501\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7913 - acc: 0.7568\n",
      "Epoch 00005: val_loss improved from 0.81146 to 0.76062, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/005-0.7606.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.7915 - acc: 0.7568 - val_loss: 0.7606 - val_acc: 0.7720\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7113 - acc: 0.7852\n",
      "Epoch 00006: val_loss improved from 0.76062 to 0.65542, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/006-0.6554.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.7114 - acc: 0.7852 - val_loss: 0.6554 - val_acc: 0.8081\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6443 - acc: 0.8064\n",
      "Epoch 00007: val_loss did not improve from 0.65542\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.6443 - acc: 0.8063 - val_loss: 0.7552 - val_acc: 0.7820\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6005 - acc: 0.8196\n",
      "Epoch 00008: val_loss improved from 0.65542 to 0.65300, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/008-0.6530.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.6008 - acc: 0.8195 - val_loss: 0.6530 - val_acc: 0.8130\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5596 - acc: 0.8305\n",
      "Epoch 00009: val_loss improved from 0.65300 to 0.54399, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/009-0.5440.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.5596 - acc: 0.8305 - val_loss: 0.5440 - val_acc: 0.8442\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5222 - acc: 0.8428\n",
      "Epoch 00010: val_loss did not improve from 0.54399\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.5225 - acc: 0.8427 - val_loss: 0.5695 - val_acc: 0.8369\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4918 - acc: 0.8541\n",
      "Epoch 00011: val_loss improved from 0.54399 to 0.53752, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/011-0.5375.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.4918 - acc: 0.8541 - val_loss: 0.5375 - val_acc: 0.8526\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4550 - acc: 0.8654\n",
      "Epoch 00012: val_loss improved from 0.53752 to 0.50957, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/012-0.5096.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.4550 - acc: 0.8654 - val_loss: 0.5096 - val_acc: 0.8600\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4325 - acc: 0.8687\n",
      "Epoch 00013: val_loss improved from 0.50957 to 0.48331, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/013-0.4833.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.4326 - acc: 0.8687 - val_loss: 0.4833 - val_acc: 0.8777\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4078 - acc: 0.8776\n",
      "Epoch 00014: val_loss did not improve from 0.48331\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.4079 - acc: 0.8775 - val_loss: 0.4989 - val_acc: 0.8672\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3887 - acc: 0.8840\n",
      "Epoch 00015: val_loss improved from 0.48331 to 0.47853, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/015-0.4785.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3888 - acc: 0.8839 - val_loss: 0.4785 - val_acc: 0.8649\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3785 - acc: 0.8856\n",
      "Epoch 00016: val_loss improved from 0.47853 to 0.45781, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/016-0.4578.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3785 - acc: 0.8856 - val_loss: 0.4578 - val_acc: 0.8726\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3571 - acc: 0.8907\n",
      "Epoch 00017: val_loss did not improve from 0.45781\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3570 - acc: 0.8907 - val_loss: 0.5393 - val_acc: 0.8449\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3304 - acc: 0.9005\n",
      "Epoch 00018: val_loss did not improve from 0.45781\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3304 - acc: 0.9005 - val_loss: 0.5017 - val_acc: 0.8656\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3203 - acc: 0.9024\n",
      "Epoch 00019: val_loss did not improve from 0.45781\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3204 - acc: 0.9024 - val_loss: 0.4923 - val_acc: 0.8658\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3079 - acc: 0.9061\n",
      "Epoch 00020: val_loss did not improve from 0.45781\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3080 - acc: 0.9062 - val_loss: 0.5029 - val_acc: 0.8672\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2960 - acc: 0.9080\n",
      "Epoch 00021: val_loss improved from 0.45781 to 0.42158, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/021-0.4216.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2962 - acc: 0.9080 - val_loss: 0.4216 - val_acc: 0.8908\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2889 - acc: 0.9136\n",
      "Epoch 00022: val_loss did not improve from 0.42158\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2890 - acc: 0.9136 - val_loss: 0.4879 - val_acc: 0.8710\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2750 - acc: 0.9149\n",
      "Epoch 00023: val_loss did not improve from 0.42158\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2751 - acc: 0.9149 - val_loss: 0.4491 - val_acc: 0.8793\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2595 - acc: 0.9200\n",
      "Epoch 00024: val_loss did not improve from 0.42158\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2596 - acc: 0.9200 - val_loss: 0.4589 - val_acc: 0.8758\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2537 - acc: 0.9203\n",
      "Epoch 00025: val_loss improved from 0.42158 to 0.41949, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/025-0.4195.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2537 - acc: 0.9203 - val_loss: 0.4195 - val_acc: 0.8854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2408 - acc: 0.9248\n",
      "Epoch 00026: val_loss did not improve from 0.41949\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2408 - acc: 0.9248 - val_loss: 0.4366 - val_acc: 0.8861\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2353 - acc: 0.9266\n",
      "Epoch 00027: val_loss did not improve from 0.41949\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2353 - acc: 0.9266 - val_loss: 0.4365 - val_acc: 0.8796\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2285 - acc: 0.9287\n",
      "Epoch 00028: val_loss did not improve from 0.41949\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2285 - acc: 0.9288 - val_loss: 0.4628 - val_acc: 0.8912\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2201 - acc: 0.9304\n",
      "Epoch 00029: val_loss improved from 0.41949 to 0.38609, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/029-0.3861.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2202 - acc: 0.9304 - val_loss: 0.3861 - val_acc: 0.8935\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9337\n",
      "Epoch 00030: val_loss did not improve from 0.38609\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2109 - acc: 0.9338 - val_loss: 0.4304 - val_acc: 0.8828\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1943 - acc: 0.9389\n",
      "Epoch 00031: val_loss did not improve from 0.38609\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1943 - acc: 0.9389 - val_loss: 0.3883 - val_acc: 0.9012\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1971 - acc: 0.9385\n",
      "Epoch 00032: val_loss did not improve from 0.38609\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1971 - acc: 0.9385 - val_loss: 0.4045 - val_acc: 0.8989\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1891 - acc: 0.9409\n",
      "Epoch 00033: val_loss did not improve from 0.38609\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1891 - acc: 0.9409 - val_loss: 0.4822 - val_acc: 0.8735\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9411\n",
      "Epoch 00034: val_loss did not improve from 0.38609\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1860 - acc: 0.9411 - val_loss: 0.3920 - val_acc: 0.8970\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1802 - acc: 0.9425\n",
      "Epoch 00035: val_loss improved from 0.38609 to 0.36418, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_6_conv_checkpoint/035-0.3642.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1802 - acc: 0.9425 - val_loss: 0.3642 - val_acc: 0.9068\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1659 - acc: 0.9464\n",
      "Epoch 00036: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1659 - acc: 0.9464 - val_loss: 0.4775 - val_acc: 0.8791\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9442\n",
      "Epoch 00037: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1726 - acc: 0.9441 - val_loss: 0.4538 - val_acc: 0.8826\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9448\n",
      "Epoch 00038: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1740 - acc: 0.9447 - val_loss: 0.3952 - val_acc: 0.9026\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9525\n",
      "Epoch 00039: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1521 - acc: 0.9525 - val_loss: 0.5172 - val_acc: 0.8798\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9524\n",
      "Epoch 00040: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1493 - acc: 0.9524 - val_loss: 0.4800 - val_acc: 0.8866\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9516\n",
      "Epoch 00041: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1501 - acc: 0.9516 - val_loss: 0.4242 - val_acc: 0.8938\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9508\n",
      "Epoch 00042: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1508 - acc: 0.9507 - val_loss: 0.3994 - val_acc: 0.9059\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9545\n",
      "Epoch 00043: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1426 - acc: 0.9545 - val_loss: 0.4175 - val_acc: 0.8966\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1404 - acc: 0.9555\n",
      "Epoch 00044: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1404 - acc: 0.9555 - val_loss: 0.4400 - val_acc: 0.9017\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9576\n",
      "Epoch 00045: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1330 - acc: 0.9576 - val_loss: 0.4479 - val_acc: 0.8952\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9597\n",
      "Epoch 00046: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1288 - acc: 0.9597 - val_loss: 0.4465 - val_acc: 0.8961\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9576\n",
      "Epoch 00047: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1312 - acc: 0.9576 - val_loss: 0.4470 - val_acc: 0.8984\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9607\n",
      "Epoch 00048: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1234 - acc: 0.9607 - val_loss: 0.3823 - val_acc: 0.9073\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9602\n",
      "Epoch 00049: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1256 - acc: 0.9601 - val_loss: 0.4835 - val_acc: 0.8880\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9590\n",
      "Epoch 00050: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1251 - acc: 0.9591 - val_loss: 0.4061 - val_acc: 0.8970\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9649\n",
      "Epoch 00051: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1102 - acc: 0.9650 - val_loss: 0.4222 - val_acc: 0.8901\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9655\n",
      "Epoch 00052: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1113 - acc: 0.9655 - val_loss: 0.4067 - val_acc: 0.9045\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9673\n",
      "Epoch 00053: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1061 - acc: 0.9673 - val_loss: 0.4906 - val_acc: 0.8945\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9665\n",
      "Epoch 00054: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1062 - acc: 0.9666 - val_loss: 0.5330 - val_acc: 0.8744\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9684\n",
      "Epoch 00055: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1007 - acc: 0.9684 - val_loss: 0.4619 - val_acc: 0.8915\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9673\n",
      "Epoch 00056: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1025 - acc: 0.9673 - val_loss: 0.4146 - val_acc: 0.8954\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9681\n",
      "Epoch 00057: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0973 - acc: 0.9681 - val_loss: 0.4187 - val_acc: 0.9024\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9672\n",
      "Epoch 00058: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1022 - acc: 0.9672 - val_loss: 0.4574 - val_acc: 0.8901\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9669\n",
      "Epoch 00059: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1019 - acc: 0.9669 - val_loss: 0.3927 - val_acc: 0.9101\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9729\n",
      "Epoch 00060: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0867 - acc: 0.9729 - val_loss: 0.4364 - val_acc: 0.9040\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9712\n",
      "Epoch 00061: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0913 - acc: 0.9713 - val_loss: 0.5115 - val_acc: 0.8926\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9727\n",
      "Epoch 00062: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0862 - acc: 0.9726 - val_loss: 0.4342 - val_acc: 0.9050\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9701\n",
      "Epoch 00063: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0927 - acc: 0.9701 - val_loss: 0.4105 - val_acc: 0.9078\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9737\n",
      "Epoch 00064: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0831 - acc: 0.9738 - val_loss: 0.4579 - val_acc: 0.9008\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9735\n",
      "Epoch 00065: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0836 - acc: 0.9735 - val_loss: 0.4481 - val_acc: 0.8987\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9737\n",
      "Epoch 00066: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0826 - acc: 0.9737 - val_loss: 0.4469 - val_acc: 0.8945\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9743\n",
      "Epoch 00067: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0803 - acc: 0.9743 - val_loss: 0.4268 - val_acc: 0.8982\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9734\n",
      "Epoch 00068: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0808 - acc: 0.9734 - val_loss: 0.3662 - val_acc: 0.9189\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9758\n",
      "Epoch 00069: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0787 - acc: 0.9758 - val_loss: 0.5665 - val_acc: 0.8749\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9762\n",
      "Epoch 00070: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0755 - acc: 0.9762 - val_loss: 0.4076 - val_acc: 0.9089\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9755\n",
      "Epoch 00071: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0765 - acc: 0.9755 - val_loss: 0.5310 - val_acc: 0.8810\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9764\n",
      "Epoch 00072: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0767 - acc: 0.9764 - val_loss: 0.4164 - val_acc: 0.9019\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9755\n",
      "Epoch 00073: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0782 - acc: 0.9755 - val_loss: 0.4830 - val_acc: 0.9015\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9795\n",
      "Epoch 00074: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0677 - acc: 0.9795 - val_loss: 0.5428 - val_acc: 0.8796\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9781\n",
      "Epoch 00075: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0697 - acc: 0.9781 - val_loss: 0.4223 - val_acc: 0.9038\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9768\n",
      "Epoch 00076: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0734 - acc: 0.9768 - val_loss: 0.4669 - val_acc: 0.8924\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9773\n",
      "Epoch 00077: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0729 - acc: 0.9772 - val_loss: 0.4508 - val_acc: 0.9061\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9768\n",
      "Epoch 00078: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0712 - acc: 0.9769 - val_loss: 0.4796 - val_acc: 0.9019\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9793\n",
      "Epoch 00079: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0651 - acc: 0.9793 - val_loss: 0.5452 - val_acc: 0.8910\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9735\n",
      "Epoch 00080: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0811 - acc: 0.9735 - val_loss: 0.4429 - val_acc: 0.9089\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9811\n",
      "Epoch 00081: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0608 - acc: 0.9811 - val_loss: 0.4070 - val_acc: 0.9113\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9807\n",
      "Epoch 00082: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0617 - acc: 0.9807 - val_loss: 0.4095 - val_acc: 0.9103\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9811\n",
      "Epoch 00083: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0608 - acc: 0.9811 - val_loss: 0.3658 - val_acc: 0.9168\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9795\n",
      "Epoch 00084: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0645 - acc: 0.9795 - val_loss: 0.4229 - val_acc: 0.9094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9810\n",
      "Epoch 00085: val_loss did not improve from 0.36418\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0611 - acc: 0.9810 - val_loss: 0.4412 - val_acc: 0.9024\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 990us/sample - loss: 0.4635 - acc: 0.8719\n",
      "Loss: 0.4635198420081926 Accuracy: 0.8718588\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0321 - acc: 0.3764\n",
      "Epoch 00001: val_loss improved from inf to 1.30052, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/001-1.3005.hdf5\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 2.0319 - acc: 0.3764 - val_loss: 1.3005 - val_acc: 0.6026\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1452 - acc: 0.6374\n",
      "Epoch 00002: val_loss improved from 1.30052 to 0.78826, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/002-0.7883.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 1.1451 - acc: 0.6374 - val_loss: 0.7883 - val_acc: 0.7757\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8466 - acc: 0.7430\n",
      "Epoch 00003: val_loss improved from 0.78826 to 0.59535, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/003-0.5954.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.8466 - acc: 0.7431 - val_loss: 0.5954 - val_acc: 0.8323\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6803 - acc: 0.7930\n",
      "Epoch 00004: val_loss improved from 0.59535 to 0.54662, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/004-0.5466.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.6805 - acc: 0.7930 - val_loss: 0.5466 - val_acc: 0.8456\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5740 - acc: 0.8264\n",
      "Epoch 00005: val_loss improved from 0.54662 to 0.46472, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/005-0.4647.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.5739 - acc: 0.8264 - val_loss: 0.4647 - val_acc: 0.8635\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4916 - acc: 0.8515\n",
      "Epoch 00006: val_loss improved from 0.46472 to 0.40617, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/006-0.4062.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.4916 - acc: 0.8515 - val_loss: 0.4062 - val_acc: 0.8814\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4423 - acc: 0.8652\n",
      "Epoch 00007: val_loss did not improve from 0.40617\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.4423 - acc: 0.8652 - val_loss: 0.7285 - val_acc: 0.7806\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3851 - acc: 0.8822\n",
      "Epoch 00008: val_loss improved from 0.40617 to 0.35559, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/008-0.3556.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.3850 - acc: 0.8822 - val_loss: 0.3556 - val_acc: 0.9015\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3457 - acc: 0.8960\n",
      "Epoch 00009: val_loss did not improve from 0.35559\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.3457 - acc: 0.8960 - val_loss: 0.3573 - val_acc: 0.9029\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3254 - acc: 0.9000\n",
      "Epoch 00010: val_loss improved from 0.35559 to 0.33095, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/010-0.3309.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.3254 - acc: 0.9000 - val_loss: 0.3309 - val_acc: 0.9073\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2961 - acc: 0.9090\n",
      "Epoch 00011: val_loss did not improve from 0.33095\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.2960 - acc: 0.9090 - val_loss: 0.3463 - val_acc: 0.9040\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2703 - acc: 0.9169\n",
      "Epoch 00012: val_loss improved from 0.33095 to 0.27824, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/012-0.2782.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.2704 - acc: 0.9169 - val_loss: 0.2782 - val_acc: 0.9210\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2495 - acc: 0.9229\n",
      "Epoch 00013: val_loss did not improve from 0.27824\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.2495 - acc: 0.9229 - val_loss: 0.3021 - val_acc: 0.9157\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2344 - acc: 0.9277\n",
      "Epoch 00014: val_loss did not improve from 0.27824\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.2345 - acc: 0.9276 - val_loss: 0.3577 - val_acc: 0.8961\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2193 - acc: 0.9310\n",
      "Epoch 00015: val_loss improved from 0.27824 to 0.25063, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/015-0.2506.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.2193 - acc: 0.9309 - val_loss: 0.2506 - val_acc: 0.9313\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2004 - acc: 0.9381\n",
      "Epoch 00016: val_loss did not improve from 0.25063\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.2005 - acc: 0.9381 - val_loss: 0.3048 - val_acc: 0.9126\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9390\n",
      "Epoch 00017: val_loss improved from 0.25063 to 0.22916, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/017-0.2292.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1965 - acc: 0.9391 - val_loss: 0.2292 - val_acc: 0.9345\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1794 - acc: 0.9420\n",
      "Epoch 00018: val_loss did not improve from 0.22916\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1793 - acc: 0.9420 - val_loss: 0.2877 - val_acc: 0.9152\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9473\n",
      "Epoch 00019: val_loss did not improve from 0.22916\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1690 - acc: 0.9473 - val_loss: 0.3005 - val_acc: 0.9203\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9481\n",
      "Epoch 00020: val_loss did not improve from 0.22916\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1653 - acc: 0.9481 - val_loss: 0.2819 - val_acc: 0.9269\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9490\n",
      "Epoch 00021: val_loss did not improve from 0.22916\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1596 - acc: 0.9490 - val_loss: 0.3226 - val_acc: 0.9133\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9527\n",
      "Epoch 00022: val_loss did not improve from 0.22916\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1481 - acc: 0.9527 - val_loss: 0.2331 - val_acc: 0.9376\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1446 - acc: 0.9545\n",
      "Epoch 00023: val_loss did not improve from 0.22916\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.1445 - acc: 0.9545 - val_loss: 0.2974 - val_acc: 0.9187\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9593\n",
      "Epoch 00024: val_loss did not improve from 0.22916\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1297 - acc: 0.9593 - val_loss: 0.2703 - val_acc: 0.9271\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9586\n",
      "Epoch 00025: val_loss improved from 0.22916 to 0.22856, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/025-0.2286.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1275 - acc: 0.9586 - val_loss: 0.2286 - val_acc: 0.9364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9603\n",
      "Epoch 00026: val_loss did not improve from 0.22856\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1226 - acc: 0.9603 - val_loss: 0.2800 - val_acc: 0.9255\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9601\n",
      "Epoch 00027: val_loss did not improve from 0.22856\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1220 - acc: 0.9601 - val_loss: 0.2776 - val_acc: 0.9297\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9644\n",
      "Epoch 00028: val_loss improved from 0.22856 to 0.22080, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_7_conv_checkpoint/028-0.2208.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1103 - acc: 0.9644 - val_loss: 0.2208 - val_acc: 0.9378\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9677\n",
      "Epoch 00029: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1021 - acc: 0.9677 - val_loss: 0.2795 - val_acc: 0.9311\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9691\n",
      "Epoch 00030: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0985 - acc: 0.9691 - val_loss: 0.3400 - val_acc: 0.9106\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9696\n",
      "Epoch 00031: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0958 - acc: 0.9696 - val_loss: 0.2415 - val_acc: 0.9362\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9711\n",
      "Epoch 00032: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0913 - acc: 0.9711 - val_loss: 0.2398 - val_acc: 0.9436\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9703\n",
      "Epoch 00033: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0903 - acc: 0.9703 - val_loss: 0.2739 - val_acc: 0.9287\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9737\n",
      "Epoch 00034: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0857 - acc: 0.9736 - val_loss: 0.2546 - val_acc: 0.9355\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9725\n",
      "Epoch 00035: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0859 - acc: 0.9725 - val_loss: 0.3053 - val_acc: 0.9241\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9714\n",
      "Epoch 00036: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0872 - acc: 0.9714 - val_loss: 0.2307 - val_acc: 0.9464\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9757\n",
      "Epoch 00037: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0743 - acc: 0.9757 - val_loss: 0.3212 - val_acc: 0.9320\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9743\n",
      "Epoch 00038: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0774 - acc: 0.9743 - val_loss: 0.2406 - val_acc: 0.9373\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9795\n",
      "Epoch 00039: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0661 - acc: 0.9795 - val_loss: 0.3149 - val_acc: 0.9273\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9761\n",
      "Epoch 00040: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0738 - acc: 0.9761 - val_loss: 0.2268 - val_acc: 0.9462\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9777\n",
      "Epoch 00041: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0699 - acc: 0.9777 - val_loss: 0.2736 - val_acc: 0.9378\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9798\n",
      "Epoch 00042: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0635 - acc: 0.9798 - val_loss: 0.2355 - val_acc: 0.9387\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9786\n",
      "Epoch 00043: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0669 - acc: 0.9786 - val_loss: 0.2903 - val_acc: 0.9366\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9808\n",
      "Epoch 00044: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0594 - acc: 0.9808 - val_loss: 0.2629 - val_acc: 0.9373\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9812\n",
      "Epoch 00045: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0594 - acc: 0.9812 - val_loss: 0.2515 - val_acc: 0.9378\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9820\n",
      "Epoch 00046: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0556 - acc: 0.9820 - val_loss: 0.2674 - val_acc: 0.9378\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9825\n",
      "Epoch 00047: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0560 - acc: 0.9825 - val_loss: 0.2859 - val_acc: 0.9369\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9845\n",
      "Epoch 00048: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0498 - acc: 0.9845 - val_loss: 0.2891 - val_acc: 0.9359\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9814\n",
      "Epoch 00049: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0571 - acc: 0.9814 - val_loss: 0.2359 - val_acc: 0.9425\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9840\n",
      "Epoch 00050: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0507 - acc: 0.9840 - val_loss: 0.2559 - val_acc: 0.9418\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9859\n",
      "Epoch 00051: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0442 - acc: 0.9859 - val_loss: 0.2666 - val_acc: 0.9432\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9871\n",
      "Epoch 00052: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0416 - acc: 0.9871 - val_loss: 0.2922 - val_acc: 0.9311\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9851\n",
      "Epoch 00053: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0461 - acc: 0.9851 - val_loss: 0.2576 - val_acc: 0.9434\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9845\n",
      "Epoch 00054: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0471 - acc: 0.9845 - val_loss: 0.2684 - val_acc: 0.9411\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9864\n",
      "Epoch 00055: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0440 - acc: 0.9863 - val_loss: 0.2378 - val_acc: 0.9432\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9844\n",
      "Epoch 00056: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0471 - acc: 0.9844 - val_loss: 0.2796 - val_acc: 0.9373\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9842\n",
      "Epoch 00057: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0496 - acc: 0.9842 - val_loss: 0.2506 - val_acc: 0.9439\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9887\n",
      "Epoch 00058: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0357 - acc: 0.9886 - val_loss: 0.2307 - val_acc: 0.9488\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9840\n",
      "Epoch 00059: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0499 - acc: 0.9840 - val_loss: 0.3141 - val_acc: 0.9301\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9897\n",
      "Epoch 00060: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0329 - acc: 0.9897 - val_loss: 0.2444 - val_acc: 0.9483\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9887\n",
      "Epoch 00061: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0353 - acc: 0.9887 - val_loss: 0.2726 - val_acc: 0.9429\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9892\n",
      "Epoch 00062: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0333 - acc: 0.9892 - val_loss: 0.3021 - val_acc: 0.9369\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9883\n",
      "Epoch 00063: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0368 - acc: 0.9883 - val_loss: 0.2511 - val_acc: 0.9469\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9888\n",
      "Epoch 00064: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0353 - acc: 0.9888 - val_loss: 0.2558 - val_acc: 0.9513\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9885\n",
      "Epoch 00065: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0387 - acc: 0.9885 - val_loss: 0.3036 - val_acc: 0.9371\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9872\n",
      "Epoch 00066: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0377 - acc: 0.9872 - val_loss: 0.3984 - val_acc: 0.9222\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9910\n",
      "Epoch 00067: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0304 - acc: 0.9909 - val_loss: 0.2405 - val_acc: 0.9509\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9867\n",
      "Epoch 00068: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0407 - acc: 0.9867 - val_loss: 0.2352 - val_acc: 0.9509\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9916\n",
      "Epoch 00069: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0271 - acc: 0.9916 - val_loss: 0.4376 - val_acc: 0.9143\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9901\n",
      "Epoch 00070: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0315 - acc: 0.9901 - val_loss: 0.2866 - val_acc: 0.9422\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9901\n",
      "Epoch 00071: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0309 - acc: 0.9901 - val_loss: 0.2430 - val_acc: 0.9488\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9904\n",
      "Epoch 00072: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0301 - acc: 0.9904 - val_loss: 0.3332 - val_acc: 0.9245\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9916\n",
      "Epoch 00073: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0264 - acc: 0.9916 - val_loss: 0.2807 - val_acc: 0.9380\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9907\n",
      "Epoch 00074: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0299 - acc: 0.9907 - val_loss: 0.2912 - val_acc: 0.9357\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9908\n",
      "Epoch 00075: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0296 - acc: 0.9907 - val_loss: 0.3869 - val_acc: 0.9255\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9874\n",
      "Epoch 00076: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0374 - acc: 0.9874 - val_loss: 0.2764 - val_acc: 0.9406\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9860\n",
      "Epoch 00077: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0456 - acc: 0.9860 - val_loss: 0.2358 - val_acc: 0.9513\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9934\n",
      "Epoch 00078: val_loss did not improve from 0.22080\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0217 - acc: 0.9934 - val_loss: 0.2810 - val_acc: 0.9422\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2783 - acc: 0.9250\n",
      "Loss: 0.27825931191815767 Accuracy: 0.92502594\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9280 - acc: 0.4151\n",
      "Epoch 00001: val_loss improved from inf to 1.18389, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/001-1.1839.hdf5\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 1.9281 - acc: 0.4150 - val_loss: 1.1839 - val_acc: 0.6138\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9250 - acc: 0.7091\n",
      "Epoch 00002: val_loss improved from 1.18389 to 0.55814, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/002-0.5581.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.9249 - acc: 0.7091 - val_loss: 0.5581 - val_acc: 0.8372\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6224 - acc: 0.8072\n",
      "Epoch 00003: val_loss improved from 0.55814 to 0.41306, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/003-0.4131.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.6224 - acc: 0.8073 - val_loss: 0.4131 - val_acc: 0.8842\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4786 - acc: 0.8539\n",
      "Epoch 00004: val_loss improved from 0.41306 to 0.29528, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/004-0.2953.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.4786 - acc: 0.8539 - val_loss: 0.2953 - val_acc: 0.9143\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3889 - acc: 0.8816\n",
      "Epoch 00005: val_loss did not improve from 0.29528\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.3889 - acc: 0.8816 - val_loss: 0.3194 - val_acc: 0.9012\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3270 - acc: 0.8998\n",
      "Epoch 00006: val_loss improved from 0.29528 to 0.28592, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/006-0.2859.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.3271 - acc: 0.8998 - val_loss: 0.2859 - val_acc: 0.9161\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2873 - acc: 0.9121\n",
      "Epoch 00007: val_loss improved from 0.28592 to 0.20957, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/007-0.2096.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.2872 - acc: 0.9121 - val_loss: 0.2096 - val_acc: 0.9392\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2489 - acc: 0.9237\n",
      "Epoch 00008: val_loss improved from 0.20957 to 0.20518, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/008-0.2052.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.2488 - acc: 0.9237 - val_loss: 0.2052 - val_acc: 0.9415\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2294 - acc: 0.9301\n",
      "Epoch 00009: val_loss did not improve from 0.20518\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.2293 - acc: 0.9301 - val_loss: 0.2114 - val_acc: 0.9401\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9375\n",
      "Epoch 00010: val_loss improved from 0.20518 to 0.18170, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/010-0.1817.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1982 - acc: 0.9375 - val_loss: 0.1817 - val_acc: 0.9450\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9426\n",
      "Epoch 00011: val_loss did not improve from 0.18170\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1842 - acc: 0.9426 - val_loss: 0.2015 - val_acc: 0.9369\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1699 - acc: 0.9454\n",
      "Epoch 00012: val_loss improved from 0.18170 to 0.15401, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/012-0.1540.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1699 - acc: 0.9454 - val_loss: 0.1540 - val_acc: 0.9555\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9515\n",
      "Epoch 00013: val_loss did not improve from 0.15401\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1543 - acc: 0.9515 - val_loss: 0.1832 - val_acc: 0.9453\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9549\n",
      "Epoch 00014: val_loss did not improve from 0.15401\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1426 - acc: 0.9548 - val_loss: 0.2185 - val_acc: 0.9439\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9554\n",
      "Epoch 00015: val_loss did not improve from 0.15401\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1364 - acc: 0.9554 - val_loss: 0.1897 - val_acc: 0.9448\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9620\n",
      "Epoch 00016: val_loss did not improve from 0.15401\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1196 - acc: 0.9620 - val_loss: 0.2093 - val_acc: 0.9373\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9643\n",
      "Epoch 00017: val_loss did not improve from 0.15401\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1126 - acc: 0.9644 - val_loss: 0.1551 - val_acc: 0.9529\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9665\n",
      "Epoch 00018: val_loss improved from 0.15401 to 0.15330, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/018-0.1533.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1045 - acc: 0.9664 - val_loss: 0.1533 - val_acc: 0.9532\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9682\n",
      "Epoch 00019: val_loss did not improve from 0.15330\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0982 - acc: 0.9682 - val_loss: 0.1554 - val_acc: 0.9536\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9699\n",
      "Epoch 00020: val_loss improved from 0.15330 to 0.14950, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/020-0.1495.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0959 - acc: 0.9699 - val_loss: 0.1495 - val_acc: 0.9583\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9736\n",
      "Epoch 00021: val_loss did not improve from 0.14950\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0827 - acc: 0.9735 - val_loss: 0.1559 - val_acc: 0.9564\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9746\n",
      "Epoch 00022: val_loss did not improve from 0.14950\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0817 - acc: 0.9746 - val_loss: 0.1652 - val_acc: 0.9555\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9744\n",
      "Epoch 00023: val_loss improved from 0.14950 to 0.14442, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/023-0.1444.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0803 - acc: 0.9744 - val_loss: 0.1444 - val_acc: 0.9602\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9771\n",
      "Epoch 00024: val_loss did not improve from 0.14442\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0712 - acc: 0.9771 - val_loss: 0.1598 - val_acc: 0.9502\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9789\n",
      "Epoch 00025: val_loss did not improve from 0.14442\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0673 - acc: 0.9789 - val_loss: 0.1768 - val_acc: 0.9560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9800\n",
      "Epoch 00026: val_loss did not improve from 0.14442\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0636 - acc: 0.9800 - val_loss: 0.1805 - val_acc: 0.9495\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9819\n",
      "Epoch 00027: val_loss improved from 0.14442 to 0.13733, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/027-0.1373.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0576 - acc: 0.9819 - val_loss: 0.1373 - val_acc: 0.9604\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9818\n",
      "Epoch 00028: val_loss improved from 0.13733 to 0.12918, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/028-0.1292.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0581 - acc: 0.9818 - val_loss: 0.1292 - val_acc: 0.9632\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9835\n",
      "Epoch 00029: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0528 - acc: 0.9835 - val_loss: 0.1521 - val_acc: 0.9564\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9835\n",
      "Epoch 00030: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0512 - acc: 0.9835 - val_loss: 0.1872 - val_acc: 0.9527\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9846\n",
      "Epoch 00031: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0475 - acc: 0.9846 - val_loss: 0.1387 - val_acc: 0.9620\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9850\n",
      "Epoch 00032: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0461 - acc: 0.9850 - val_loss: 0.1730 - val_acc: 0.9518\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9856\n",
      "Epoch 00033: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0440 - acc: 0.9855 - val_loss: 0.1513 - val_acc: 0.9597\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9842\n",
      "Epoch 00034: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0503 - acc: 0.9842 - val_loss: 0.1757 - val_acc: 0.9557\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9862\n",
      "Epoch 00035: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0462 - acc: 0.9863 - val_loss: 0.1664 - val_acc: 0.9618\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9885\n",
      "Epoch 00036: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0367 - acc: 0.9885 - val_loss: 0.1652 - val_acc: 0.9588\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9863\n",
      "Epoch 00037: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0410 - acc: 0.9863 - val_loss: 0.1708 - val_acc: 0.9578\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9886\n",
      "Epoch 00038: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0352 - acc: 0.9886 - val_loss: 0.1768 - val_acc: 0.9588\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9869\n",
      "Epoch 00039: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0429 - acc: 0.9869 - val_loss: 0.1529 - val_acc: 0.9581\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9893\n",
      "Epoch 00040: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0344 - acc: 0.9893 - val_loss: 0.1504 - val_acc: 0.9609\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9873\n",
      "Epoch 00041: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0391 - acc: 0.9873 - val_loss: 0.1786 - val_acc: 0.9574\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9925\n",
      "Epoch 00042: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0271 - acc: 0.9925 - val_loss: 0.1703 - val_acc: 0.9581\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9907\n",
      "Epoch 00043: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0297 - acc: 0.9907 - val_loss: 0.1795 - val_acc: 0.9609\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9906\n",
      "Epoch 00044: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0301 - acc: 0.9906 - val_loss: 0.1712 - val_acc: 0.9623\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9891\n",
      "Epoch 00045: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0330 - acc: 0.9891 - val_loss: 0.1525 - val_acc: 0.9639\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9926\n",
      "Epoch 00046: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0248 - acc: 0.9926 - val_loss: 0.1978 - val_acc: 0.9604\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9881\n",
      "Epoch 00047: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0374 - acc: 0.9880 - val_loss: 0.1621 - val_acc: 0.9583\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9878\n",
      "Epoch 00048: val_loss improved from 0.12918 to 0.12767, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_8_conv_checkpoint/048-0.1277.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0396 - acc: 0.9878 - val_loss: 0.1277 - val_acc: 0.9646\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9929\n",
      "Epoch 00049: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0237 - acc: 0.9929 - val_loss: 0.1437 - val_acc: 0.9662\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9935\n",
      "Epoch 00050: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0206 - acc: 0.9935 - val_loss: 0.1632 - val_acc: 0.9658\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9937\n",
      "Epoch 00051: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0215 - acc: 0.9937 - val_loss: 0.2595 - val_acc: 0.9436\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9926\n",
      "Epoch 00052: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0246 - acc: 0.9925 - val_loss: 0.1619 - val_acc: 0.9639\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9891\n",
      "Epoch 00053: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0343 - acc: 0.9891 - val_loss: 0.1542 - val_acc: 0.9641\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9946\n",
      "Epoch 00054: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0179 - acc: 0.9946 - val_loss: 0.1454 - val_acc: 0.9681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9958\n",
      "Epoch 00055: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0160 - acc: 0.9958 - val_loss: 0.1756 - val_acc: 0.9616\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9941\n",
      "Epoch 00056: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0192 - acc: 0.9941 - val_loss: 0.2026 - val_acc: 0.9488\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9943\n",
      "Epoch 00057: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0191 - acc: 0.9943 - val_loss: 0.1674 - val_acc: 0.9590\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9927\n",
      "Epoch 00058: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0214 - acc: 0.9927 - val_loss: 0.2092 - val_acc: 0.9546\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9943\n",
      "Epoch 00059: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0187 - acc: 0.9943 - val_loss: 0.1893 - val_acc: 0.9553\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9943\n",
      "Epoch 00060: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0190 - acc: 0.9943 - val_loss: 0.1991 - val_acc: 0.9560\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9918\n",
      "Epoch 00061: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0257 - acc: 0.9918 - val_loss: 0.1767 - val_acc: 0.9620\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9957\n",
      "Epoch 00062: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0150 - acc: 0.9957 - val_loss: 0.2106 - val_acc: 0.9534\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9942\n",
      "Epoch 00063: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0193 - acc: 0.9942 - val_loss: 0.1528 - val_acc: 0.9632\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9926\n",
      "Epoch 00064: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0216 - acc: 0.9926 - val_loss: 0.1456 - val_acc: 0.9655\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9957\n",
      "Epoch 00065: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0139 - acc: 0.9957 - val_loss: 0.1499 - val_acc: 0.9655\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9962\n",
      "Epoch 00066: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0123 - acc: 0.9962 - val_loss: 0.2195 - val_acc: 0.9532\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9921\n",
      "Epoch 00067: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0273 - acc: 0.9921 - val_loss: 0.1385 - val_acc: 0.9669\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 00068: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0127 - acc: 0.9960 - val_loss: 0.1563 - val_acc: 0.9651\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9955\n",
      "Epoch 00069: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0144 - acc: 0.9955 - val_loss: 0.1670 - val_acc: 0.9651\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9948\n",
      "Epoch 00070: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0171 - acc: 0.9948 - val_loss: 0.1700 - val_acc: 0.9648\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9967\n",
      "Epoch 00071: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0117 - acc: 0.9967 - val_loss: 0.1768 - val_acc: 0.9641\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9957\n",
      "Epoch 00072: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0139 - acc: 0.9957 - val_loss: 0.2177 - val_acc: 0.9536\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9950\n",
      "Epoch 00073: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0163 - acc: 0.9950 - val_loss: 0.2177 - val_acc: 0.9562\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9954\n",
      "Epoch 00074: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0149 - acc: 0.9954 - val_loss: 0.2404 - val_acc: 0.9518\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9957\n",
      "Epoch 00075: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0138 - acc: 0.9957 - val_loss: 0.1557 - val_acc: 0.9625\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9961\n",
      "Epoch 00076: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0129 - acc: 0.9961 - val_loss: 0.1549 - val_acc: 0.9651\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9957\n",
      "Epoch 00077: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0135 - acc: 0.9957 - val_loss: 0.2806 - val_acc: 0.9455\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9968\n",
      "Epoch 00078: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0108 - acc: 0.9968 - val_loss: 0.3043 - val_acc: 0.9436\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9933\n",
      "Epoch 00079: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0200 - acc: 0.9933 - val_loss: 0.1658 - val_acc: 0.9660\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9968\n",
      "Epoch 00080: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0110 - acc: 0.9968 - val_loss: 0.1660 - val_acc: 0.9632\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9979\n",
      "Epoch 00081: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0080 - acc: 0.9979 - val_loss: 0.1767 - val_acc: 0.9620\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9932\n",
      "Epoch 00082: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0216 - acc: 0.9932 - val_loss: 0.1418 - val_acc: 0.9679\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9965\n",
      "Epoch 00083: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0113 - acc: 0.9965 - val_loss: 0.1608 - val_acc: 0.9627\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9970\n",
      "Epoch 00084: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0097 - acc: 0.9970 - val_loss: 0.2120 - val_acc: 0.9569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9968\n",
      "Epoch 00085: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0106 - acc: 0.9968 - val_loss: 0.1727 - val_acc: 0.9651\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9963\n",
      "Epoch 00086: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0122 - acc: 0.9963 - val_loss: 0.1953 - val_acc: 0.9592\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9965\n",
      "Epoch 00087: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0118 - acc: 0.9965 - val_loss: 0.2999 - val_acc: 0.9413\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9902\n",
      "Epoch 00088: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0314 - acc: 0.9902 - val_loss: 0.1597 - val_acc: 0.9660\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9976\n",
      "Epoch 00089: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0081 - acc: 0.9976 - val_loss: 0.1697 - val_acc: 0.9646\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9982\n",
      "Epoch 00090: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0064 - acc: 0.9982 - val_loss: 0.1535 - val_acc: 0.9681\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9978\n",
      "Epoch 00091: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0083 - acc: 0.9978 - val_loss: 0.1561 - val_acc: 0.9660\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9963\n",
      "Epoch 00092: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0118 - acc: 0.9963 - val_loss: 0.1995 - val_acc: 0.9611\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9967\n",
      "Epoch 00093: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0102 - acc: 0.9967 - val_loss: 0.1712 - val_acc: 0.9632\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 00094: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0108 - acc: 0.9966 - val_loss: 0.1909 - val_acc: 0.9639\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9939\n",
      "Epoch 00095: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0195 - acc: 0.9939 - val_loss: 0.1445 - val_acc: 0.9695\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9982\n",
      "Epoch 00096: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0067 - acc: 0.9982 - val_loss: 0.1401 - val_acc: 0.9718\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9967\n",
      "Epoch 00097: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0094 - acc: 0.9967 - val_loss: 0.1971 - val_acc: 0.9567\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9977\n",
      "Epoch 00098: val_loss did not improve from 0.12767\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0080 - acc: 0.9976 - val_loss: 0.1780 - val_acc: 0.9630\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1704 - acc: 0.9516\n",
      "Loss: 0.1703981090382492 Accuracy: 0.95160955\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5356 - acc: 0.5458\n",
      "Epoch 00001: val_loss improved from inf to 0.99463, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/001-0.9946.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 1.5357 - acc: 0.5458 - val_loss: 0.9946 - val_acc: 0.6716\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6330 - acc: 0.8024\n",
      "Epoch 00002: val_loss improved from 0.99463 to 0.33392, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/002-0.3339.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.6334 - acc: 0.8024 - val_loss: 0.3339 - val_acc: 0.9040\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4204 - acc: 0.8705\n",
      "Epoch 00003: val_loss improved from 0.33392 to 0.32605, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/003-0.3260.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.4204 - acc: 0.8705 - val_loss: 0.3260 - val_acc: 0.9052\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3265 - acc: 0.8998\n",
      "Epoch 00004: val_loss improved from 0.32605 to 0.28408, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/004-0.2841.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.3265 - acc: 0.8998 - val_loss: 0.2841 - val_acc: 0.9157\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2687 - acc: 0.9170\n",
      "Epoch 00005: val_loss improved from 0.28408 to 0.20597, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/005-0.2060.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.2688 - acc: 0.9170 - val_loss: 0.2060 - val_acc: 0.9413\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2335 - acc: 0.9285\n",
      "Epoch 00006: val_loss improved from 0.20597 to 0.19357, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/006-0.1936.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.2335 - acc: 0.9285 - val_loss: 0.1936 - val_acc: 0.9397\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1943 - acc: 0.9395\n",
      "Epoch 00007: val_loss improved from 0.19357 to 0.16207, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/007-0.1621.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1943 - acc: 0.9395 - val_loss: 0.1621 - val_acc: 0.9532\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9484\n",
      "Epoch 00008: val_loss did not improve from 0.16207\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1716 - acc: 0.9484 - val_loss: 0.2034 - val_acc: 0.9362\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9509\n",
      "Epoch 00009: val_loss did not improve from 0.16207\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1583 - acc: 0.9509 - val_loss: 0.1673 - val_acc: 0.9502\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9567\n",
      "Epoch 00010: val_loss improved from 0.16207 to 0.14247, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/010-0.1425.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1379 - acc: 0.9567 - val_loss: 0.1425 - val_acc: 0.9595\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9631\n",
      "Epoch 00011: val_loss did not improve from 0.14247\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1219 - acc: 0.9631 - val_loss: 0.2141 - val_acc: 0.9364\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9634\n",
      "Epoch 00012: val_loss did not improve from 0.14247\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1165 - acc: 0.9633 - val_loss: 0.1493 - val_acc: 0.9583\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9620\n",
      "Epoch 00013: val_loss improved from 0.14247 to 0.14085, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/013-0.1409.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1176 - acc: 0.9620 - val_loss: 0.1409 - val_acc: 0.9578\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9698\n",
      "Epoch 00014: val_loss did not improve from 0.14085\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0970 - acc: 0.9698 - val_loss: 0.1547 - val_acc: 0.9534\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9743\n",
      "Epoch 00015: val_loss improved from 0.14085 to 0.13800, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/015-0.1380.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0831 - acc: 0.9742 - val_loss: 0.1380 - val_acc: 0.9590\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9724\n",
      "Epoch 00016: val_loss did not improve from 0.13800\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0841 - acc: 0.9723 - val_loss: 0.1436 - val_acc: 0.9602\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9772\n",
      "Epoch 00017: val_loss did not improve from 0.13800\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0742 - acc: 0.9772 - val_loss: 0.1658 - val_acc: 0.9525\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9776\n",
      "Epoch 00018: val_loss improved from 0.13800 to 0.13211, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/018-0.1321.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0749 - acc: 0.9776 - val_loss: 0.1321 - val_acc: 0.9627\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9823\n",
      "Epoch 00019: val_loss did not improve from 0.13211\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0602 - acc: 0.9823 - val_loss: 0.1476 - val_acc: 0.9576\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9821\n",
      "Epoch 00020: val_loss did not improve from 0.13211\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0578 - acc: 0.9821 - val_loss: 0.1387 - val_acc: 0.9630\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9836\n",
      "Epoch 00021: val_loss did not improve from 0.13211\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0532 - acc: 0.9836 - val_loss: 0.2184 - val_acc: 0.9488\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9847\n",
      "Epoch 00022: val_loss improved from 0.13211 to 0.12497, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/022-0.1250.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0508 - acc: 0.9847 - val_loss: 0.1250 - val_acc: 0.9637\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9842\n",
      "Epoch 00023: val_loss did not improve from 0.12497\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0511 - acc: 0.9842 - val_loss: 0.1622 - val_acc: 0.9557\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9878\n",
      "Epoch 00024: val_loss did not improve from 0.12497\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0409 - acc: 0.9878 - val_loss: 0.1379 - val_acc: 0.9632\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9881\n",
      "Epoch 00025: val_loss did not improve from 0.12497\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0392 - acc: 0.9881 - val_loss: 0.1717 - val_acc: 0.9602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9882\n",
      "Epoch 00026: val_loss did not improve from 0.12497\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0391 - acc: 0.9882 - val_loss: 0.1859 - val_acc: 0.9520\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9872\n",
      "Epoch 00027: val_loss did not improve from 0.12497\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0415 - acc: 0.9872 - val_loss: 0.1559 - val_acc: 0.9583\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9895\n",
      "Epoch 00028: val_loss did not improve from 0.12497\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0352 - acc: 0.9895 - val_loss: 0.1359 - val_acc: 0.9651\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9892\n",
      "Epoch 00029: val_loss did not improve from 0.12497\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0355 - acc: 0.9892 - val_loss: 0.1693 - val_acc: 0.9590\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9872\n",
      "Epoch 00030: val_loss did not improve from 0.12497\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0414 - acc: 0.9872 - val_loss: 0.1261 - val_acc: 0.9669\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9916\n",
      "Epoch 00031: val_loss did not improve from 0.12497\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0270 - acc: 0.9916 - val_loss: 0.1574 - val_acc: 0.9620\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9921\n",
      "Epoch 00032: val_loss did not improve from 0.12497\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0271 - acc: 0.9921 - val_loss: 0.1250 - val_acc: 0.9688\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9932\n",
      "Epoch 00033: val_loss did not improve from 0.12497\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0219 - acc: 0.9932 - val_loss: 0.1639 - val_acc: 0.9634\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9926\n",
      "Epoch 00034: val_loss did not improve from 0.12497\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0246 - acc: 0.9925 - val_loss: 0.1509 - val_acc: 0.9604\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9860\n",
      "Epoch 00035: val_loss improved from 0.12497 to 0.12434, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/035-0.1243.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0454 - acc: 0.9860 - val_loss: 0.1243 - val_acc: 0.9700\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9940\n",
      "Epoch 00036: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0204 - acc: 0.9940 - val_loss: 0.1400 - val_acc: 0.9653\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9909\n",
      "Epoch 00037: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0302 - acc: 0.9908 - val_loss: 0.1554 - val_acc: 0.9623\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9933\n",
      "Epoch 00038: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0223 - acc: 0.9933 - val_loss: 0.1594 - val_acc: 0.9578\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9893\n",
      "Epoch 00039: val_loss improved from 0.12434 to 0.11871, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/039-0.1187.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0338 - acc: 0.9893 - val_loss: 0.1187 - val_acc: 0.9681\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9958\n",
      "Epoch 00040: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0152 - acc: 0.9958 - val_loss: 0.1342 - val_acc: 0.9679\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9932\n",
      "Epoch 00041: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0227 - acc: 0.9932 - val_loss: 0.1443 - val_acc: 0.9674\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9954\n",
      "Epoch 00042: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0160 - acc: 0.9954 - val_loss: 0.1614 - val_acc: 0.9574\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9958\n",
      "Epoch 00043: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0151 - acc: 0.9958 - val_loss: 0.1460 - val_acc: 0.9667\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9912\n",
      "Epoch 00044: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0291 - acc: 0.9912 - val_loss: 0.1203 - val_acc: 0.9695\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9965\n",
      "Epoch 00045: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0124 - acc: 0.9965 - val_loss: 0.1424 - val_acc: 0.9674\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9960\n",
      "Epoch 00046: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0138 - acc: 0.9960 - val_loss: 0.1902 - val_acc: 0.9546\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9950\n",
      "Epoch 00047: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0169 - acc: 0.9949 - val_loss: 0.2017 - val_acc: 0.9560\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 00048: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0283 - acc: 0.9917 - val_loss: 0.1451 - val_acc: 0.9637\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9967\n",
      "Epoch 00049: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0120 - acc: 0.9967 - val_loss: 0.1470 - val_acc: 0.9660\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9908\n",
      "Epoch 00050: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0300 - acc: 0.9908 - val_loss: 0.1310 - val_acc: 0.9693\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9970\n",
      "Epoch 00051: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0104 - acc: 0.9970 - val_loss: 0.1290 - val_acc: 0.9690\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9974\n",
      "Epoch 00052: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0092 - acc: 0.9974 - val_loss: 0.1335 - val_acc: 0.9706\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9963\n",
      "Epoch 00053: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0122 - acc: 0.9963 - val_loss: 0.1417 - val_acc: 0.9651\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9958\n",
      "Epoch 00054: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0139 - acc: 0.9958 - val_loss: 0.2232 - val_acc: 0.9492\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9918\n",
      "Epoch 00055: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0271 - acc: 0.9918 - val_loss: 0.1257 - val_acc: 0.9697\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9973\n",
      "Epoch 00056: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0093 - acc: 0.9973 - val_loss: 0.1616 - val_acc: 0.9630\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9973\n",
      "Epoch 00057: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0102 - acc: 0.9973 - val_loss: 0.1342 - val_acc: 0.9693\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9955\n",
      "Epoch 00058: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0151 - acc: 0.9955 - val_loss: 0.1331 - val_acc: 0.9662\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9968\n",
      "Epoch 00059: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0114 - acc: 0.9968 - val_loss: 0.1746 - val_acc: 0.9595\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9950\n",
      "Epoch 00060: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0154 - acc: 0.9950 - val_loss: 0.1630 - val_acc: 0.9634\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9941\n",
      "Epoch 00061: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0196 - acc: 0.9941 - val_loss: 0.1369 - val_acc: 0.9655\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9972\n",
      "Epoch 00062: val_loss did not improve from 0.11871\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0090 - acc: 0.9972 - val_loss: 0.1299 - val_acc: 0.9704\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9984\n",
      "Epoch 00063: val_loss improved from 0.11871 to 0.11614, saving model to model/checkpoint/1D_CNN_custom_3_DO_BN_9_conv_checkpoint/063-0.1161.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0068 - acc: 0.9984 - val_loss: 0.1161 - val_acc: 0.9727\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9949\n",
      "Epoch 00064: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0161 - acc: 0.9949 - val_loss: 0.1403 - val_acc: 0.9669\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9964\n",
      "Epoch 00065: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0117 - acc: 0.9964 - val_loss: 0.2174 - val_acc: 0.9564\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9925\n",
      "Epoch 00066: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0245 - acc: 0.9925 - val_loss: 0.1455 - val_acc: 0.9674\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9985\n",
      "Epoch 00067: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0060 - acc: 0.9985 - val_loss: 0.1191 - val_acc: 0.9700\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9986\n",
      "Epoch 00068: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0053 - acc: 0.9986 - val_loss: 0.1377 - val_acc: 0.9697\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9992\n",
      "Epoch 00069: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0041 - acc: 0.9992 - val_loss: 0.1642 - val_acc: 0.9644\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9953\n",
      "Epoch 00070: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0158 - acc: 0.9953 - val_loss: 0.1322 - val_acc: 0.9679\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9971\n",
      "Epoch 00071: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0100 - acc: 0.9971 - val_loss: 0.1305 - val_acc: 0.9706\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9943\n",
      "Epoch 00072: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0184 - acc: 0.9943 - val_loss: 0.1339 - val_acc: 0.9688\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9992\n",
      "Epoch 00073: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0043 - acc: 0.9992 - val_loss: 0.1345 - val_acc: 0.9718\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9974\n",
      "Epoch 00074: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0088 - acc: 0.9974 - val_loss: 0.1889 - val_acc: 0.9555\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9972\n",
      "Epoch 00075: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0100 - acc: 0.9972 - val_loss: 0.1509 - val_acc: 0.9674\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9965\n",
      "Epoch 00076: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0108 - acc: 0.9965 - val_loss: 0.1871 - val_acc: 0.9618\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9986\n",
      "Epoch 00077: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0059 - acc: 0.9986 - val_loss: 0.2113 - val_acc: 0.9550\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 00078: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0112 - acc: 0.9966 - val_loss: 0.1764 - val_acc: 0.9623\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9965\n",
      "Epoch 00079: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0110 - acc: 0.9965 - val_loss: 0.1420 - val_acc: 0.9693\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 00080: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0039 - acc: 0.9993 - val_loss: 0.1650 - val_acc: 0.9653\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9929\n",
      "Epoch 00081: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0221 - acc: 0.9929 - val_loss: 0.1354 - val_acc: 0.9695\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9980\n",
      "Epoch 00082: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0069 - acc: 0.9980 - val_loss: 0.1342 - val_acc: 0.9672\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 00083: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0042 - acc: 0.9990 - val_loss: 0.1286 - val_acc: 0.9706\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9980\n",
      "Epoch 00084: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0068 - acc: 0.9980 - val_loss: 0.1445 - val_acc: 0.9683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9973\n",
      "Epoch 00085: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0087 - acc: 0.9973 - val_loss: 0.1321 - val_acc: 0.9674\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9977\n",
      "Epoch 00086: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0081 - acc: 0.9977 - val_loss: 0.1360 - val_acc: 0.9700\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9978\n",
      "Epoch 00087: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0068 - acc: 0.9978 - val_loss: 0.1340 - val_acc: 0.9697\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9971\n",
      "Epoch 00088: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0095 - acc: 0.9971 - val_loss: 0.1579 - val_acc: 0.9679\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9969\n",
      "Epoch 00089: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0091 - acc: 0.9969 - val_loss: 0.1320 - val_acc: 0.9697\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9980\n",
      "Epoch 00090: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0066 - acc: 0.9980 - val_loss: 0.1499 - val_acc: 0.9672\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9971\n",
      "Epoch 00091: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0102 - acc: 0.9971 - val_loss: 0.1369 - val_acc: 0.9683\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9978\n",
      "Epoch 00092: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0065 - acc: 0.9978 - val_loss: 0.1463 - val_acc: 0.9686\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9979\n",
      "Epoch 00093: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0065 - acc: 0.9979 - val_loss: 0.1410 - val_acc: 0.9700\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9981\n",
      "Epoch 00094: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0065 - acc: 0.9981 - val_loss: 0.1527 - val_acc: 0.9679\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9961\n",
      "Epoch 00095: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0124 - acc: 0.9961 - val_loss: 0.1443 - val_acc: 0.9706\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9988\n",
      "Epoch 00096: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0042 - acc: 0.9988 - val_loss: 0.1556 - val_acc: 0.9669\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9986\n",
      "Epoch 00097: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0051 - acc: 0.9986 - val_loss: 0.1470 - val_acc: 0.9674\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9974\n",
      "Epoch 00098: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0087 - acc: 0.9974 - val_loss: 0.1543 - val_acc: 0.9683\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9977\n",
      "Epoch 00099: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0077 - acc: 0.9977 - val_loss: 0.1769 - val_acc: 0.9660\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9946\n",
      "Epoch 00100: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0177 - acc: 0.9946 - val_loss: 0.1292 - val_acc: 0.9716\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9975\n",
      "Epoch 00101: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0092 - acc: 0.9975 - val_loss: 0.1317 - val_acc: 0.9723\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9992\n",
      "Epoch 00102: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0030 - acc: 0.9992 - val_loss: 0.1349 - val_acc: 0.9734\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 00103: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0027 - acc: 0.9993 - val_loss: 0.1538 - val_acc: 0.9688\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9976\n",
      "Epoch 00104: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0085 - acc: 0.9976 - val_loss: 0.1345 - val_acc: 0.9725\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9982\n",
      "Epoch 00105: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0058 - acc: 0.9982 - val_loss: 0.1874 - val_acc: 0.9637\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9983\n",
      "Epoch 00106: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0059 - acc: 0.9983 - val_loss: 0.1476 - val_acc: 0.9704\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9979\n",
      "Epoch 00107: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0060 - acc: 0.9979 - val_loss: 0.2037 - val_acc: 0.9595\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9979\n",
      "Epoch 00108: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0070 - acc: 0.9979 - val_loss: 0.1503 - val_acc: 0.9695\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9986\n",
      "Epoch 00109: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0052 - acc: 0.9986 - val_loss: 0.1498 - val_acc: 0.9697\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9978\n",
      "Epoch 00110: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0073 - acc: 0.9978 - val_loss: 0.2508 - val_acc: 0.9536\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9969\n",
      "Epoch 00111: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0098 - acc: 0.9969 - val_loss: 0.1889 - val_acc: 0.9602\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9978\n",
      "Epoch 00112: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0069 - acc: 0.9978 - val_loss: 0.1452 - val_acc: 0.9658\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 00113: val_loss did not improve from 0.11614\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0033 - acc: 0.9992 - val_loss: 0.1333 - val_acc: 0.9697\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1603 - acc: 0.9626\n",
      "Loss: 0.16025737308663038 Accuracy: 0.9626168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 10):\n",
    "    base = '1D_CNN_custom_3_DO_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_3_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 512)         655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 512)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 303104)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 303104)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                4849680   \n",
      "=================================================================\n",
      "Total params: 6,168,080\n",
      "Trainable params: 6,165,520\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 5.6159 - acc: 0.4974\n",
      "Loss: 5.615899310503174 Accuracy: 0.49740395\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 569,872\n",
      "Trainable params: 568,976\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.7763 - acc: 0.8108\n",
      "Loss: 0.7762671216626034 Accuracy: 0.8107996\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 382,096\n",
      "Trainable params: 380,944\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.4635 - acc: 0.8719\n",
      "Loss: 0.4635198420081926 Accuracy: 0.8718588\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 500,112\n",
      "Trainable params: 498,448\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2783 - acc: 0.9250\n",
      "Loss: 0.27825931191815767 Accuracy: 0.92502594\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 771,728\n",
      "Trainable params: 769,552\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1704 - acc: 0.9516\n",
      "Loss: 0.1703981090382492 Accuracy: 0.95160955\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 256)            327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,080,208\n",
      "Trainable params: 1,077,520\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1603 - acc: 0.9626\n",
      "Loss: 0.16025737308663038 Accuracy: 0.9626168\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_3_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(4, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_3_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,296,272\n",
      "Trainable params: 1,295,632\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.6261 - acc: 0.7040\n",
      "Loss: 1.626097090989506 Accuracy: 0.7040498\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 569,872\n",
      "Trainable params: 568,976\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.8804 - acc: 0.8193\n",
      "Loss: 0.8803764018809437 Accuracy: 0.81931466\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 382,096\n",
      "Trainable params: 380,944\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.5852 - acc: 0.8690\n",
      "Loss: 0.5851801105253669 Accuracy: 0.8689512\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 500,112\n",
      "Trainable params: 498,448\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3362 - acc: 0.9283\n",
      "Loss: 0.33621548338380264 Accuracy: 0.9283489\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 771,728\n",
      "Trainable params: 769,552\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2241 - acc: 0.9545\n",
      "Loss: 0.22413124301273044 Accuracy: 0.9545171\n",
      "\n",
      "1D_CNN_custom_3_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 256)            327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,080,208\n",
      "Trainable params: 1,077,520\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1914 - acc: 0.9570\n",
      "Loss: 0.19139208179542666 Accuracy: 0.9570094\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(4, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
