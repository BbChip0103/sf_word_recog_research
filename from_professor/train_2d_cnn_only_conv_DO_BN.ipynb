{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(os.path.join(data_dir, 'train_data.npz'))\n",
    "val_data = np.load(os.path.join(data_dir, 'validation_data.npz'))\n",
    "test_data = np.load(os.path.join(data_dir, 'test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 25443),\n",
       " (36805,),\n",
       " (4293, 25443),\n",
       " (4293,),\n",
       " (4815, 25443),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x_data):\n",
    "    x_data = np.reshape(x_data, [x_data.shape[0], 99, 257, 1])\n",
    "    x_data = np.rot90(x_data, 1, (1, 2))\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_2d = preprocess(x_train)\n",
    "mean_vals = np.mean(x_train_2d, axis=0)\n",
    "std_val = np.std(x_train_2d)\n",
    "x_train_2d_norm = (x_train_2d-mean_vals) / std_val\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_2d = preprocess(x_val)\n",
    "x_val_2d_norm = (x_val_2d-mean_vals) / std_val\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_2d = preprocess(x_test)\n",
    "x_test_2d_norm = (x_test_2d-mean_vals) / std_val\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test_2d_norm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_only_conv_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D (kernel_size=5, filters=8, strides=(1,1), padding='valid', \n",
    "                      activation='relu', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=(2,2), padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv2D (kernel_size=5, filters=8*(2**(i+1)), strides=(1,1), padding='valid', \n",
    "                          activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=2, strides=(2,2), padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    model = build_2d_cnn_only_conv_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3278 - acc: 0.3895\n",
      "Epoch 00001: val_loss improved from inf to 1.58937, saving model to model/checkpoint/2D_CNN_1_only_conv_DO_BN_checkpoint/01-1.5894.hdf5\n",
      "36805/36805 [==============================] - 13s 343us/sample - loss: 2.3277 - acc: 0.3895 - val_loss: 1.5894 - val_acc: 0.5348\n",
      "Epoch 2/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5904 - acc: 0.5468\n",
      "Epoch 00002: val_loss improved from 1.58937 to 1.24968, saving model to model/checkpoint/2D_CNN_1_only_conv_DO_BN_checkpoint/02-1.2497.hdf5\n",
      "36805/36805 [==============================] - 11s 297us/sample - loss: 1.5904 - acc: 0.5468 - val_loss: 1.2497 - val_acc: 0.6490\n",
      "Epoch 3/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 1.3345 - acc: 0.6081\n",
      "Epoch 00003: val_loss improved from 1.24968 to 1.20603, saving model to model/checkpoint/2D_CNN_1_only_conv_DO_BN_checkpoint/03-1.2060.hdf5\n",
      "36805/36805 [==============================] - 11s 300us/sample - loss: 1.3337 - acc: 0.6083 - val_loss: 1.2060 - val_acc: 0.6776\n",
      "Epoch 4/200\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 1.1538 - acc: 0.6534\n",
      "Epoch 00004: val_loss improved from 1.20603 to 1.19429, saving model to model/checkpoint/2D_CNN_1_only_conv_DO_BN_checkpoint/04-1.1943.hdf5\n",
      "36805/36805 [==============================] - 11s 293us/sample - loss: 1.1542 - acc: 0.6534 - val_loss: 1.1943 - val_acc: 0.6720\n",
      "Epoch 5/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0095 - acc: 0.6907\n",
      "Epoch 00005: val_loss did not improve from 1.19429\n",
      "36805/36805 [==============================] - 11s 299us/sample - loss: 1.0091 - acc: 0.6907 - val_loss: 1.2096 - val_acc: 0.6844\n",
      "Epoch 6/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.9138 - acc: 0.7173\n",
      "Epoch 00006: val_loss improved from 1.19429 to 1.18488, saving model to model/checkpoint/2D_CNN_1_only_conv_DO_BN_checkpoint/06-1.1849.hdf5\n",
      "36805/36805 [==============================] - 11s 296us/sample - loss: 0.9141 - acc: 0.7173 - val_loss: 1.1849 - val_acc: 0.6925\n",
      "Epoch 7/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8293 - acc: 0.7371\n",
      "Epoch 00007: val_loss did not improve from 1.18488\n",
      "36805/36805 [==============================] - 11s 293us/sample - loss: 0.8289 - acc: 0.7371 - val_loss: 1.2439 - val_acc: 0.6674\n",
      "Epoch 8/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7689 - acc: 0.7563\n",
      "Epoch 00008: val_loss improved from 1.18488 to 1.15500, saving model to model/checkpoint/2D_CNN_1_only_conv_DO_BN_checkpoint/08-1.1550.hdf5\n",
      "36805/36805 [==============================] - 11s 302us/sample - loss: 0.7683 - acc: 0.7565 - val_loss: 1.1550 - val_acc: 0.7023\n",
      "Epoch 9/200\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.7089 - acc: 0.7744\n",
      "Epoch 00009: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 295us/sample - loss: 0.7101 - acc: 0.7742 - val_loss: 1.2074 - val_acc: 0.7004\n",
      "Epoch 10/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6780 - acc: 0.7831\n",
      "Epoch 00010: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 295us/sample - loss: 0.6780 - acc: 0.7831 - val_loss: 1.2262 - val_acc: 0.6865\n",
      "Epoch 11/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6359 - acc: 0.7975\n",
      "Epoch 00011: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 293us/sample - loss: 0.6359 - acc: 0.7975 - val_loss: 1.2163 - val_acc: 0.7011\n",
      "Epoch 12/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6163 - acc: 0.8038\n",
      "Epoch 00012: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 293us/sample - loss: 0.6162 - acc: 0.8038 - val_loss: 1.2102 - val_acc: 0.7044\n",
      "Epoch 13/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.5785 - acc: 0.8152\n",
      "Epoch 00013: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 298us/sample - loss: 0.5788 - acc: 0.8151 - val_loss: 1.2361 - val_acc: 0.7109\n",
      "Epoch 14/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5602 - acc: 0.8190\n",
      "Epoch 00014: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 295us/sample - loss: 0.5604 - acc: 0.8190 - val_loss: 1.2160 - val_acc: 0.7200\n",
      "Epoch 15/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.5459 - acc: 0.8242\n",
      "Epoch 00015: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 295us/sample - loss: 0.5456 - acc: 0.8243 - val_loss: 1.2079 - val_acc: 0.7284\n",
      "Epoch 16/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.5278 - acc: 0.8322\n",
      "Epoch 00016: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 294us/sample - loss: 0.5282 - acc: 0.8319 - val_loss: 1.2536 - val_acc: 0.7130\n",
      "Epoch 17/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5121 - acc: 0.8348\n",
      "Epoch 00017: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 295us/sample - loss: 0.5122 - acc: 0.8348 - val_loss: 1.2795 - val_acc: 0.7105\n",
      "Epoch 18/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4967 - acc: 0.8399\n",
      "Epoch 00018: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 290us/sample - loss: 0.4967 - acc: 0.8399 - val_loss: 1.2656 - val_acc: 0.7233\n",
      "Epoch 19/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4868 - acc: 0.8442\n",
      "Epoch 00019: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 296us/sample - loss: 0.4867 - acc: 0.8442 - val_loss: 1.2860 - val_acc: 0.7226\n",
      "Epoch 20/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4743 - acc: 0.8479\n",
      "Epoch 00020: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 294us/sample - loss: 0.4743 - acc: 0.8479 - val_loss: 1.3106 - val_acc: 0.7130\n",
      "Epoch 21/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4525 - acc: 0.8542\n",
      "Epoch 00021: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 304us/sample - loss: 0.4525 - acc: 0.8542 - val_loss: 1.3124 - val_acc: 0.7256\n",
      "Epoch 22/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.8544\n",
      "Epoch 00022: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 294us/sample - loss: 0.4501 - acc: 0.8544 - val_loss: 1.3188 - val_acc: 0.7261\n",
      "Epoch 23/200\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.4439 - acc: 0.8562\n",
      "Epoch 00023: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 296us/sample - loss: 0.4438 - acc: 0.8562 - val_loss: 1.2835 - val_acc: 0.7268\n",
      "Epoch 24/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.4355 - acc: 0.8600\n",
      "Epoch 00024: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 292us/sample - loss: 0.4350 - acc: 0.8600 - val_loss: 1.3686 - val_acc: 0.7130\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4181 - acc: 0.8636\n",
      "Epoch 00025: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 293us/sample - loss: 0.4180 - acc: 0.8636 - val_loss: 1.3771 - val_acc: 0.7151\n",
      "Epoch 26/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4179 - acc: 0.8651\n",
      "Epoch 00026: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 294us/sample - loss: 0.4179 - acc: 0.8651 - val_loss: 1.3571 - val_acc: 0.7172\n",
      "Epoch 27/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4211 - acc: 0.8627\n",
      "Epoch 00027: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 292us/sample - loss: 0.4211 - acc: 0.8627 - val_loss: 1.3621 - val_acc: 0.7235\n",
      "Epoch 28/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.4116 - acc: 0.8669\n",
      "Epoch 00028: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 297us/sample - loss: 0.4118 - acc: 0.8669 - val_loss: 1.3340 - val_acc: 0.7321\n",
      "Epoch 29/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4069 - acc: 0.8695\n",
      "Epoch 00029: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 288us/sample - loss: 0.4069 - acc: 0.8694 - val_loss: 1.3904 - val_acc: 0.7167\n",
      "Epoch 30/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3970 - acc: 0.8723\n",
      "Epoch 00030: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 295us/sample - loss: 0.3970 - acc: 0.8723 - val_loss: 1.3894 - val_acc: 0.7144\n",
      "Epoch 31/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3873 - acc: 0.8734\n",
      "Epoch 00031: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 297us/sample - loss: 0.3879 - acc: 0.8732 - val_loss: 1.3853 - val_acc: 0.7261\n",
      "Epoch 32/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3862 - acc: 0.8770\n",
      "Epoch 00032: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 291us/sample - loss: 0.3862 - acc: 0.8770 - val_loss: 1.3927 - val_acc: 0.7207\n",
      "Epoch 33/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3729 - acc: 0.8795\n",
      "Epoch 00033: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 294us/sample - loss: 0.3734 - acc: 0.8792 - val_loss: 1.4084 - val_acc: 0.7205\n",
      "Epoch 34/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3746 - acc: 0.8793\n",
      "Epoch 00034: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 301us/sample - loss: 0.3746 - acc: 0.8793 - val_loss: 1.3737 - val_acc: 0.7349\n",
      "Epoch 35/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3714 - acc: 0.8816\n",
      "Epoch 00035: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 294us/sample - loss: 0.3711 - acc: 0.8816 - val_loss: 1.4189 - val_acc: 0.7226\n",
      "Epoch 36/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3637 - acc: 0.8827\n",
      "Epoch 00036: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 295us/sample - loss: 0.3643 - acc: 0.8825 - val_loss: 1.4353 - val_acc: 0.7130\n",
      "Epoch 37/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3670 - acc: 0.8825\n",
      "Epoch 00037: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 298us/sample - loss: 0.3670 - acc: 0.8825 - val_loss: 1.3956 - val_acc: 0.7254\n",
      "Epoch 38/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3496 - acc: 0.8875\n",
      "Epoch 00038: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 295us/sample - loss: 0.3494 - acc: 0.8875 - val_loss: 1.4416 - val_acc: 0.7233\n",
      "Epoch 39/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3578 - acc: 0.8847\n",
      "Epoch 00039: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 292us/sample - loss: 0.3574 - acc: 0.8848 - val_loss: 1.3870 - val_acc: 0.7379\n",
      "Epoch 40/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3497 - acc: 0.8876\n",
      "Epoch 00040: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 299us/sample - loss: 0.3495 - acc: 0.8877 - val_loss: 1.4105 - val_acc: 0.7307\n",
      "Epoch 41/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3481 - acc: 0.8884\n",
      "Epoch 00041: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 291us/sample - loss: 0.3478 - acc: 0.8885 - val_loss: 1.4358 - val_acc: 0.7279\n",
      "Epoch 42/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3393 - acc: 0.8916\n",
      "Epoch 00042: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 292us/sample - loss: 0.3388 - acc: 0.8917 - val_loss: 1.4289 - val_acc: 0.7244\n",
      "Epoch 43/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3353 - acc: 0.8950\n",
      "Epoch 00043: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 294us/sample - loss: 0.3355 - acc: 0.8950 - val_loss: 1.4316 - val_acc: 0.7335\n",
      "Epoch 44/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3382 - acc: 0.8916\n",
      "Epoch 00044: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 295us/sample - loss: 0.3382 - acc: 0.8916 - val_loss: 1.4292 - val_acc: 0.7291\n",
      "Epoch 45/200\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.3379 - acc: 0.8918\n",
      "Epoch 00045: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 289us/sample - loss: 0.3376 - acc: 0.8919 - val_loss: 1.4296 - val_acc: 0.7314\n",
      "Epoch 46/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3289 - acc: 0.8950\n",
      "Epoch 00046: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 292us/sample - loss: 0.3289 - acc: 0.8950 - val_loss: 1.5165 - val_acc: 0.7184\n",
      "Epoch 47/200\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.3238 - acc: 0.8937\n",
      "Epoch 00047: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 294us/sample - loss: 0.3240 - acc: 0.8937 - val_loss: 1.4511 - val_acc: 0.7312\n",
      "Epoch 48/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3267 - acc: 0.8958\n",
      "Epoch 00048: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 294us/sample - loss: 0.3267 - acc: 0.8958 - val_loss: 1.4978 - val_acc: 0.7240\n",
      "Epoch 49/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3246 - acc: 0.8951\n",
      "Epoch 00049: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 290us/sample - loss: 0.3246 - acc: 0.8950 - val_loss: 1.4931 - val_acc: 0.7314\n",
      "Epoch 50/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3219 - acc: 0.8991\n",
      "Epoch 00050: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 10s 285us/sample - loss: 0.3219 - acc: 0.8991 - val_loss: 1.5038 - val_acc: 0.7244\n",
      "Epoch 51/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3120 - acc: 0.8998\n",
      "Epoch 00051: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 294us/sample - loss: 0.3120 - acc: 0.8998 - val_loss: 1.4677 - val_acc: 0.7379\n",
      "Epoch 52/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3129 - acc: 0.8999\n",
      "Epoch 00052: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 294us/sample - loss: 0.3133 - acc: 0.8998 - val_loss: 1.4934 - val_acc: 0.7284\n",
      "Epoch 53/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3111 - acc: 0.9015\n",
      "Epoch 00053: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 292us/sample - loss: 0.3112 - acc: 0.9015 - val_loss: 1.5379 - val_acc: 0.7207\n",
      "Epoch 54/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3217 - acc: 0.8945\n",
      "Epoch 00054: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 290us/sample - loss: 0.3216 - acc: 0.8945 - val_loss: 1.4738 - val_acc: 0.7358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3097 - acc: 0.9020\n",
      "Epoch 00055: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 294us/sample - loss: 0.3097 - acc: 0.9020 - val_loss: 1.4886 - val_acc: 0.7221\n",
      "Epoch 56/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3054 - acc: 0.9023\n",
      "Epoch 00056: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 295us/sample - loss: 0.3058 - acc: 0.9023 - val_loss: 1.4733 - val_acc: 0.7370\n",
      "Epoch 57/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3030 - acc: 0.9027\n",
      "Epoch 00057: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 292us/sample - loss: 0.3030 - acc: 0.9027 - val_loss: 1.4737 - val_acc: 0.7338\n",
      "Epoch 58/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2972 - acc: 0.9032\n",
      "Epoch 00058: val_loss did not improve from 1.15500\n",
      "36805/36805 [==============================] - 11s 290us/sample - loss: 0.2974 - acc: 0.9031 - val_loss: 1.4997 - val_acc: 0.7275\n",
      "\n",
      "1 Only Conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 260us/sample - loss: 1.2750 - acc: 0.6598\n",
      "Loss: 1.2749793017764701 Accuracy: 0.6598131\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3710 - acc: 0.3895\n",
      "Epoch 00001: val_loss improved from inf to 1.35675, saving model to model/checkpoint/2D_CNN_2_only_conv_DO_BN_checkpoint/01-1.3568.hdf5\n",
      "36805/36805 [==============================] - 14s 393us/sample - loss: 2.3715 - acc: 0.3895 - val_loss: 1.3568 - val_acc: 0.6087\n",
      "Epoch 2/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 1.5333 - acc: 0.5706\n",
      "Epoch 00002: val_loss improved from 1.35675 to 1.04623, saving model to model/checkpoint/2D_CNN_2_only_conv_DO_BN_checkpoint/02-1.0462.hdf5\n",
      "36805/36805 [==============================] - 13s 360us/sample - loss: 1.5329 - acc: 0.5707 - val_loss: 1.0462 - val_acc: 0.7077\n",
      "Epoch 3/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 1.2197 - acc: 0.6519\n",
      "Epoch 00003: val_loss improved from 1.04623 to 0.87736, saving model to model/checkpoint/2D_CNN_2_only_conv_DO_BN_checkpoint/03-0.8774.hdf5\n",
      "36805/36805 [==============================] - 13s 354us/sample - loss: 1.2191 - acc: 0.6521 - val_loss: 0.8774 - val_acc: 0.7633\n",
      "Epoch 4/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 1.0150 - acc: 0.7077\n",
      "Epoch 00004: val_loss improved from 0.87736 to 0.78823, saving model to model/checkpoint/2D_CNN_2_only_conv_DO_BN_checkpoint/04-0.7882.hdf5\n",
      "36805/36805 [==============================] - 13s 359us/sample - loss: 1.0142 - acc: 0.7079 - val_loss: 0.7882 - val_acc: 0.7952\n",
      "Epoch 5/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8641 - acc: 0.7444\n",
      "Epoch 00005: val_loss improved from 0.78823 to 0.73135, saving model to model/checkpoint/2D_CNN_2_only_conv_DO_BN_checkpoint/05-0.7314.hdf5\n",
      "36805/36805 [==============================] - 13s 362us/sample - loss: 0.8643 - acc: 0.7445 - val_loss: 0.7314 - val_acc: 0.8104\n",
      "Epoch 6/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7501 - acc: 0.7762\n",
      "Epoch 00006: val_loss improved from 0.73135 to 0.66242, saving model to model/checkpoint/2D_CNN_2_only_conv_DO_BN_checkpoint/06-0.6624.hdf5\n",
      "36805/36805 [==============================] - 13s 361us/sample - loss: 0.7501 - acc: 0.7762 - val_loss: 0.6624 - val_acc: 0.8286\n",
      "Epoch 7/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6578 - acc: 0.8013\n",
      "Epoch 00007: val_loss improved from 0.66242 to 0.62740, saving model to model/checkpoint/2D_CNN_2_only_conv_DO_BN_checkpoint/07-0.6274.hdf5\n",
      "36805/36805 [==============================] - 13s 364us/sample - loss: 0.6584 - acc: 0.8012 - val_loss: 0.6274 - val_acc: 0.8374\n",
      "Epoch 8/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.5890 - acc: 0.8210\n",
      "Epoch 00008: val_loss improved from 0.62740 to 0.60232, saving model to model/checkpoint/2D_CNN_2_only_conv_DO_BN_checkpoint/08-0.6023.hdf5\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.5890 - acc: 0.8211 - val_loss: 0.6023 - val_acc: 0.8495\n",
      "Epoch 9/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5327 - acc: 0.8357\n",
      "Epoch 00009: val_loss improved from 0.60232 to 0.58146, saving model to model/checkpoint/2D_CNN_2_only_conv_DO_BN_checkpoint/09-0.5815.hdf5\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.5329 - acc: 0.8356 - val_loss: 0.5815 - val_acc: 0.8607\n",
      "Epoch 10/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4861 - acc: 0.8506\n",
      "Epoch 00010: val_loss improved from 0.58146 to 0.56336, saving model to model/checkpoint/2D_CNN_2_only_conv_DO_BN_checkpoint/10-0.5634.hdf5\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.4862 - acc: 0.8506 - val_loss: 0.5634 - val_acc: 0.8586\n",
      "Epoch 11/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.4554 - acc: 0.8582\n",
      "Epoch 00011: val_loss improved from 0.56336 to 0.55650, saving model to model/checkpoint/2D_CNN_2_only_conv_DO_BN_checkpoint/11-0.5565.hdf5\n",
      "36805/36805 [==============================] - 13s 365us/sample - loss: 0.4551 - acc: 0.8584 - val_loss: 0.5565 - val_acc: 0.8672\n",
      "Epoch 12/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.4093 - acc: 0.8718\n",
      "Epoch 00012: val_loss improved from 0.55650 to 0.54094, saving model to model/checkpoint/2D_CNN_2_only_conv_DO_BN_checkpoint/12-0.5409.hdf5\n",
      "36805/36805 [==============================] - 14s 370us/sample - loss: 0.4093 - acc: 0.8717 - val_loss: 0.5409 - val_acc: 0.8677\n",
      "Epoch 13/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3838 - acc: 0.8786\n",
      "Epoch 00013: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 362us/sample - loss: 0.3838 - acc: 0.8786 - val_loss: 0.5528 - val_acc: 0.8665\n",
      "Epoch 14/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3592 - acc: 0.8864\n",
      "Epoch 00014: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.3594 - acc: 0.8863 - val_loss: 0.5630 - val_acc: 0.8644\n",
      "Epoch 15/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3413 - acc: 0.8921\n",
      "Epoch 00015: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 354us/sample - loss: 0.3418 - acc: 0.8919 - val_loss: 0.5530 - val_acc: 0.8717\n",
      "Epoch 16/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3183 - acc: 0.8988\n",
      "Epoch 00016: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 356us/sample - loss: 0.3182 - acc: 0.8989 - val_loss: 0.5432 - val_acc: 0.8756\n",
      "Epoch 17/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2995 - acc: 0.9026\n",
      "Epoch 00017: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 358us/sample - loss: 0.2998 - acc: 0.9026 - val_loss: 0.5536 - val_acc: 0.8742\n",
      "Epoch 18/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2916 - acc: 0.9054\n",
      "Epoch 00018: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 361us/sample - loss: 0.2916 - acc: 0.9054 - val_loss: 0.5528 - val_acc: 0.8791\n",
      "Epoch 19/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2772 - acc: 0.9103\n",
      "Epoch 00019: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 347us/sample - loss: 0.2771 - acc: 0.9104 - val_loss: 0.5534 - val_acc: 0.8707\n",
      "Epoch 20/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2647 - acc: 0.9139\n",
      "Epoch 00020: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 349us/sample - loss: 0.2648 - acc: 0.9139 - val_loss: 0.5635 - val_acc: 0.8751\n",
      "Epoch 21/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2532 - acc: 0.9192\n",
      "Epoch 00021: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 357us/sample - loss: 0.2535 - acc: 0.9190 - val_loss: 0.5576 - val_acc: 0.8796\n",
      "Epoch 22/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2439 - acc: 0.9217\n",
      "Epoch 00022: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 360us/sample - loss: 0.2438 - acc: 0.9217 - val_loss: 0.5485 - val_acc: 0.8772\n",
      "Epoch 23/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2338 - acc: 0.9236\n",
      "Epoch 00023: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 347us/sample - loss: 0.2337 - acc: 0.9237 - val_loss: 0.5686 - val_acc: 0.8740\n",
      "Epoch 24/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2284 - acc: 0.9256\n",
      "Epoch 00024: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 348us/sample - loss: 0.2284 - acc: 0.9256 - val_loss: 0.5515 - val_acc: 0.8791\n",
      "Epoch 25/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9288\n",
      "Epoch 00025: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 359us/sample - loss: 0.2199 - acc: 0.9288 - val_loss: 0.5615 - val_acc: 0.8786\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2105 - acc: 0.9310\n",
      "Epoch 00026: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 357us/sample - loss: 0.2105 - acc: 0.9310 - val_loss: 0.5851 - val_acc: 0.8714\n",
      "Epoch 27/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2080 - acc: 0.9312\n",
      "Epoch 00027: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 351us/sample - loss: 0.2082 - acc: 0.9311 - val_loss: 0.5729 - val_acc: 0.8749\n",
      "Epoch 28/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1929 - acc: 0.9364\n",
      "Epoch 00028: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 346us/sample - loss: 0.1929 - acc: 0.9364 - val_loss: 0.5647 - val_acc: 0.8819\n",
      "Epoch 29/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1883 - acc: 0.9395\n",
      "Epoch 00029: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 358us/sample - loss: 0.1886 - acc: 0.9394 - val_loss: 0.5564 - val_acc: 0.8803\n",
      "Epoch 30/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1812 - acc: 0.9398\n",
      "Epoch 00030: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 355us/sample - loss: 0.1811 - acc: 0.9398 - val_loss: 0.5775 - val_acc: 0.8856\n",
      "Epoch 31/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9416\n",
      "Epoch 00031: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 348us/sample - loss: 0.1833 - acc: 0.9416 - val_loss: 0.5715 - val_acc: 0.8842\n",
      "Epoch 32/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1721 - acc: 0.9420\n",
      "Epoch 00032: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 348us/sample - loss: 0.1725 - acc: 0.9419 - val_loss: 0.5801 - val_acc: 0.8791\n",
      "Epoch 33/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1699 - acc: 0.9437\n",
      "Epoch 00033: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 348us/sample - loss: 0.1700 - acc: 0.9436 - val_loss: 0.5801 - val_acc: 0.8779\n",
      "Epoch 34/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1663 - acc: 0.9441\n",
      "Epoch 00034: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 341us/sample - loss: 0.1664 - acc: 0.9440 - val_loss: 0.5796 - val_acc: 0.8847\n",
      "Epoch 35/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1637 - acc: 0.9466\n",
      "Epoch 00035: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 349us/sample - loss: 0.1638 - acc: 0.9466 - val_loss: 0.5741 - val_acc: 0.8840\n",
      "Epoch 36/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1564 - acc: 0.9498\n",
      "Epoch 00036: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 358us/sample - loss: 0.1566 - acc: 0.9497 - val_loss: 0.6024 - val_acc: 0.8812\n",
      "Epoch 37/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9503\n",
      "Epoch 00037: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 355us/sample - loss: 0.1505 - acc: 0.9504 - val_loss: 0.6167 - val_acc: 0.8742\n",
      "Epoch 38/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9510\n",
      "Epoch 00038: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 346us/sample - loss: 0.1492 - acc: 0.9511 - val_loss: 0.6088 - val_acc: 0.8824\n",
      "Epoch 39/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9496\n",
      "Epoch 00039: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 346us/sample - loss: 0.1511 - acc: 0.9496 - val_loss: 0.5956 - val_acc: 0.8775\n",
      "Epoch 40/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9517\n",
      "Epoch 00040: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 358us/sample - loss: 0.1453 - acc: 0.9517 - val_loss: 0.6005 - val_acc: 0.8826\n",
      "Epoch 41/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9544\n",
      "Epoch 00041: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 358us/sample - loss: 0.1405 - acc: 0.9544 - val_loss: 0.5973 - val_acc: 0.8819\n",
      "Epoch 42/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9538\n",
      "Epoch 00042: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 348us/sample - loss: 0.1404 - acc: 0.9537 - val_loss: 0.6014 - val_acc: 0.8833\n",
      "Epoch 43/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9530\n",
      "Epoch 00043: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 346us/sample - loss: 0.1395 - acc: 0.9529 - val_loss: 0.6090 - val_acc: 0.8791\n",
      "Epoch 44/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9540\n",
      "Epoch 00044: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 359us/sample - loss: 0.1376 - acc: 0.9539 - val_loss: 0.6099 - val_acc: 0.8789\n",
      "Epoch 45/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9569\n",
      "Epoch 00045: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 356us/sample - loss: 0.1323 - acc: 0.9570 - val_loss: 0.6535 - val_acc: 0.8782\n",
      "Epoch 46/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9565\n",
      "Epoch 00046: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 350us/sample - loss: 0.1339 - acc: 0.9565 - val_loss: 0.6254 - val_acc: 0.8868\n",
      "Epoch 47/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9575\n",
      "Epoch 00047: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 349us/sample - loss: 0.1292 - acc: 0.9576 - val_loss: 0.6190 - val_acc: 0.8831\n",
      "Epoch 48/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9590\n",
      "Epoch 00048: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 355us/sample - loss: 0.1258 - acc: 0.9589 - val_loss: 0.6191 - val_acc: 0.8826\n",
      "Epoch 49/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9594\n",
      "Epoch 00049: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 358us/sample - loss: 0.1230 - acc: 0.9595 - val_loss: 0.6520 - val_acc: 0.8763\n",
      "Epoch 50/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9586\n",
      "Epoch 00050: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 347us/sample - loss: 0.1236 - acc: 0.9586 - val_loss: 0.6495 - val_acc: 0.8793\n",
      "Epoch 51/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9622\n",
      "Epoch 00051: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 349us/sample - loss: 0.1194 - acc: 0.9622 - val_loss: 0.6237 - val_acc: 0.8833\n",
      "Epoch 52/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9614\n",
      "Epoch 00052: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 356us/sample - loss: 0.1167 - acc: 0.9614 - val_loss: 0.6138 - val_acc: 0.8831\n",
      "Epoch 53/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9609\n",
      "Epoch 00053: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 349us/sample - loss: 0.1200 - acc: 0.9609 - val_loss: 0.6280 - val_acc: 0.8847\n",
      "Epoch 54/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9625\n",
      "Epoch 00054: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 348us/sample - loss: 0.1171 - acc: 0.9625 - val_loss: 0.6086 - val_acc: 0.8863\n",
      "Epoch 55/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9622\n",
      "Epoch 00055: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 347us/sample - loss: 0.1155 - acc: 0.9622 - val_loss: 0.6332 - val_acc: 0.8849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9646\n",
      "Epoch 00056: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 347us/sample - loss: 0.1081 - acc: 0.9646 - val_loss: 0.6370 - val_acc: 0.8903\n",
      "Epoch 57/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9643\n",
      "Epoch 00057: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 364us/sample - loss: 0.1095 - acc: 0.9644 - val_loss: 0.6458 - val_acc: 0.8835\n",
      "Epoch 58/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9638\n",
      "Epoch 00058: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 359us/sample - loss: 0.1134 - acc: 0.9637 - val_loss: 0.6369 - val_acc: 0.8882\n",
      "Epoch 59/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9652\n",
      "Epoch 00059: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 346us/sample - loss: 0.1112 - acc: 0.9652 - val_loss: 0.6207 - val_acc: 0.8875\n",
      "Epoch 60/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9665\n",
      "Epoch 00060: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 347us/sample - loss: 0.1022 - acc: 0.9666 - val_loss: 0.6411 - val_acc: 0.8873\n",
      "Epoch 61/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9649\n",
      "Epoch 00061: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 358us/sample - loss: 0.1114 - acc: 0.9649 - val_loss: 0.6455 - val_acc: 0.8882\n",
      "Epoch 62/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9662\n",
      "Epoch 00062: val_loss did not improve from 0.54094\n",
      "36805/36805 [==============================] - 13s 359us/sample - loss: 0.1050 - acc: 0.9662 - val_loss: 0.6441 - val_acc: 0.8875\n",
      "\n",
      "2 Only Conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 237us/sample - loss: 0.6045 - acc: 0.8390\n",
      "Loss: 0.6045244734111481 Accuracy: 0.83904463\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.5483 - acc: 0.3335\n",
      "Epoch 00001: val_loss improved from inf to 1.37637, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/01-1.3764.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 2.5474 - acc: 0.3336 - val_loss: 1.3764 - val_acc: 0.5791\n",
      "Epoch 2/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6482 - acc: 0.5292\n",
      "Epoch 00002: val_loss improved from 1.37637 to 1.01576, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/02-1.0158.hdf5\n",
      "36805/36805 [==============================] - 14s 389us/sample - loss: 1.6482 - acc: 0.5291 - val_loss: 1.0158 - val_acc: 0.7079\n",
      "Epoch 3/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 1.2343 - acc: 0.6379\n",
      "Epoch 00003: val_loss improved from 1.01576 to 0.80336, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/03-0.8034.hdf5\n",
      "36805/36805 [==============================] - 14s 390us/sample - loss: 1.2344 - acc: 0.6379 - val_loss: 0.8034 - val_acc: 0.7773\n",
      "Epoch 4/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9666 - acc: 0.7136\n",
      "Epoch 00004: val_loss improved from 0.80336 to 0.66021, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/04-0.6602.hdf5\n",
      "36805/36805 [==============================] - 14s 394us/sample - loss: 0.9672 - acc: 0.7134 - val_loss: 0.6602 - val_acc: 0.8220\n",
      "Epoch 5/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8157 - acc: 0.7556\n",
      "Epoch 00005: val_loss improved from 0.66021 to 0.60019, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/05-0.6002.hdf5\n",
      "36805/36805 [==============================] - 14s 387us/sample - loss: 0.8157 - acc: 0.7555 - val_loss: 0.6002 - val_acc: 0.8369\n",
      "Epoch 6/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6860 - acc: 0.7966\n",
      "Epoch 00006: val_loss improved from 0.60019 to 0.52287, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/06-0.5229.hdf5\n",
      "36805/36805 [==============================] - 15s 394us/sample - loss: 0.6862 - acc: 0.7966 - val_loss: 0.5229 - val_acc: 0.8635\n",
      "Epoch 7/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.6047 - acc: 0.8166\n",
      "Epoch 00007: val_loss improved from 0.52287 to 0.48568, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/07-0.4857.hdf5\n",
      "36805/36805 [==============================] - 14s 391us/sample - loss: 0.6045 - acc: 0.8167 - val_loss: 0.4857 - val_acc: 0.8656\n",
      "Epoch 8/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5368 - acc: 0.8355\n",
      "Epoch 00008: val_loss improved from 0.48568 to 0.44786, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/08-0.4479.hdf5\n",
      "36805/36805 [==============================] - 14s 391us/sample - loss: 0.5368 - acc: 0.8355 - val_loss: 0.4479 - val_acc: 0.8793\n",
      "Epoch 9/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.4809 - acc: 0.8521\n",
      "Epoch 00009: val_loss improved from 0.44786 to 0.42462, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/09-0.4246.hdf5\n",
      "36805/36805 [==============================] - 14s 393us/sample - loss: 0.4806 - acc: 0.8521 - val_loss: 0.4246 - val_acc: 0.8814\n",
      "Epoch 10/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.4369 - acc: 0.8629\n",
      "Epoch 00010: val_loss improved from 0.42462 to 0.39582, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/10-0.3958.hdf5\n",
      "36805/36805 [==============================] - 14s 392us/sample - loss: 0.4371 - acc: 0.8628 - val_loss: 0.3958 - val_acc: 0.8896\n",
      "Epoch 11/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4021 - acc: 0.8758\n",
      "Epoch 00011: val_loss improved from 0.39582 to 0.38598, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/11-0.3860.hdf5\n",
      "36805/36805 [==============================] - 14s 389us/sample - loss: 0.4023 - acc: 0.8758 - val_loss: 0.3860 - val_acc: 0.8921\n",
      "Epoch 12/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3699 - acc: 0.8847\n",
      "Epoch 00012: val_loss improved from 0.38598 to 0.37446, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/12-0.3745.hdf5\n",
      "36805/36805 [==============================] - 15s 394us/sample - loss: 0.3700 - acc: 0.8847 - val_loss: 0.3745 - val_acc: 0.8959\n",
      "Epoch 13/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3444 - acc: 0.8911\n",
      "Epoch 00013: val_loss improved from 0.37446 to 0.36399, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/13-0.3640.hdf5\n",
      "36805/36805 [==============================] - 14s 392us/sample - loss: 0.3444 - acc: 0.8912 - val_loss: 0.3640 - val_acc: 0.8977\n",
      "Epoch 14/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3183 - acc: 0.8991\n",
      "Epoch 00014: val_loss improved from 0.36399 to 0.34722, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/14-0.3472.hdf5\n",
      "36805/36805 [==============================] - 15s 396us/sample - loss: 0.3181 - acc: 0.8990 - val_loss: 0.3472 - val_acc: 0.9045\n",
      "Epoch 15/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2978 - acc: 0.9065\n",
      "Epoch 00015: val_loss improved from 0.34722 to 0.33530, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/15-0.3353.hdf5\n",
      "36805/36805 [==============================] - 14s 394us/sample - loss: 0.2978 - acc: 0.9065 - val_loss: 0.3353 - val_acc: 0.9096\n",
      "Epoch 16/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.9093\n",
      "Epoch 00016: val_loss improved from 0.33530 to 0.32333, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/16-0.3233.hdf5\n",
      "36805/36805 [==============================] - 14s 388us/sample - loss: 0.2799 - acc: 0.9094 - val_loss: 0.3233 - val_acc: 0.9136\n",
      "Epoch 17/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2604 - acc: 0.9165\n",
      "Epoch 00017: val_loss did not improve from 0.32333\n",
      "36805/36805 [==============================] - 14s 393us/sample - loss: 0.2606 - acc: 0.9164 - val_loss: 0.3379 - val_acc: 0.9078\n",
      "Epoch 18/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2519 - acc: 0.9194\n",
      "Epoch 00018: val_loss did not improve from 0.32333\n",
      "36805/36805 [==============================] - 14s 389us/sample - loss: 0.2519 - acc: 0.9194 - val_loss: 0.3554 - val_acc: 0.8963\n",
      "Epoch 19/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2366 - acc: 0.9232\n",
      "Epoch 00019: val_loss improved from 0.32333 to 0.32115, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/19-0.3211.hdf5\n",
      "36805/36805 [==============================] - 14s 393us/sample - loss: 0.2365 - acc: 0.9232 - val_loss: 0.3211 - val_acc: 0.9096\n",
      "Epoch 20/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2245 - acc: 0.9280\n",
      "Epoch 00020: val_loss improved from 0.32115 to 0.29518, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/20-0.2952.hdf5\n",
      "36805/36805 [==============================] - 15s 395us/sample - loss: 0.2245 - acc: 0.9279 - val_loss: 0.2952 - val_acc: 0.9185\n",
      "Epoch 21/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2145 - acc: 0.9300\n",
      "Epoch 00021: val_loss did not improve from 0.29518\n",
      "36805/36805 [==============================] - 14s 390us/sample - loss: 0.2145 - acc: 0.9300 - val_loss: 0.3028 - val_acc: 0.9189\n",
      "Epoch 22/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2009 - acc: 0.9346\n",
      "Epoch 00022: val_loss did not improve from 0.29518\n",
      "36805/36805 [==============================] - 14s 390us/sample - loss: 0.2009 - acc: 0.9346 - val_loss: 0.3083 - val_acc: 0.9210\n",
      "Epoch 23/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1931 - acc: 0.9364\n",
      "Epoch 00023: val_loss did not improve from 0.29518\n",
      "36805/36805 [==============================] - 14s 393us/sample - loss: 0.1931 - acc: 0.9365 - val_loss: 0.3109 - val_acc: 0.9175\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1881 - acc: 0.9402\n",
      "Epoch 00024: val_loss did not improve from 0.29518\n",
      "36805/36805 [==============================] - 14s 394us/sample - loss: 0.1881 - acc: 0.9403 - val_loss: 0.3096 - val_acc: 0.9217\n",
      "Epoch 25/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9427\n",
      "Epoch 00025: val_loss did not improve from 0.29518\n",
      "36805/36805 [==============================] - 14s 389us/sample - loss: 0.1792 - acc: 0.9427 - val_loss: 0.3164 - val_acc: 0.9199\n",
      "Epoch 26/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1767 - acc: 0.9417\n",
      "Epoch 00026: val_loss did not improve from 0.29518\n",
      "36805/36805 [==============================] - 14s 390us/sample - loss: 0.1767 - acc: 0.9417 - val_loss: 0.3085 - val_acc: 0.9241\n",
      "Epoch 27/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1647 - acc: 0.9461\n",
      "Epoch 00027: val_loss improved from 0.29518 to 0.29510, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/27-0.2951.hdf5\n",
      "36805/36805 [==============================] - 15s 397us/sample - loss: 0.1648 - acc: 0.9462 - val_loss: 0.2951 - val_acc: 0.9236\n",
      "Epoch 28/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1642 - acc: 0.9460\n",
      "Epoch 00028: val_loss improved from 0.29510 to 0.29158, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/28-0.2916.hdf5\n",
      "36805/36805 [==============================] - 15s 396us/sample - loss: 0.1642 - acc: 0.9460 - val_loss: 0.2916 - val_acc: 0.9255\n",
      "Epoch 29/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1523 - acc: 0.9502\n",
      "Epoch 00029: val_loss improved from 0.29158 to 0.28776, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/29-0.2878.hdf5\n",
      "36805/36805 [==============================] - 14s 391us/sample - loss: 0.1522 - acc: 0.9502 - val_loss: 0.2878 - val_acc: 0.9264\n",
      "Epoch 30/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9505\n",
      "Epoch 00030: val_loss did not improve from 0.28776\n",
      "36805/36805 [==============================] - 14s 391us/sample - loss: 0.1493 - acc: 0.9505 - val_loss: 0.3119 - val_acc: 0.9236\n",
      "Epoch 31/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9532\n",
      "Epoch 00031: val_loss improved from 0.28776 to 0.28441, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/31-0.2844.hdf5\n",
      "36805/36805 [==============================] - 14s 391us/sample - loss: 0.1439 - acc: 0.9532 - val_loss: 0.2844 - val_acc: 0.9290\n",
      "Epoch 32/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9527\n",
      "Epoch 00032: val_loss did not improve from 0.28441\n",
      "36805/36805 [==============================] - 14s 391us/sample - loss: 0.1402 - acc: 0.9528 - val_loss: 0.3075 - val_acc: 0.9264\n",
      "Epoch 33/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9537\n",
      "Epoch 00033: val_loss did not improve from 0.28441\n",
      "36805/36805 [==============================] - 14s 391us/sample - loss: 0.1386 - acc: 0.9537 - val_loss: 0.3001 - val_acc: 0.9287\n",
      "Epoch 34/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9575\n",
      "Epoch 00034: val_loss did not improve from 0.28441\n",
      "36805/36805 [==============================] - 14s 394us/sample - loss: 0.1293 - acc: 0.9575 - val_loss: 0.2908 - val_acc: 0.9294\n",
      "Epoch 35/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9587\n",
      "Epoch 00035: val_loss did not improve from 0.28441\n",
      "36805/36805 [==============================] - 14s 392us/sample - loss: 0.1271 - acc: 0.9587 - val_loss: 0.2951 - val_acc: 0.9255\n",
      "Epoch 36/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9585\n",
      "Epoch 00036: val_loss did not improve from 0.28441\n",
      "36805/36805 [==============================] - 15s 396us/sample - loss: 0.1255 - acc: 0.9585 - val_loss: 0.2937 - val_acc: 0.9297\n",
      "Epoch 37/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9594\n",
      "Epoch 00037: val_loss did not improve from 0.28441\n",
      "36805/36805 [==============================] - 14s 390us/sample - loss: 0.1233 - acc: 0.9594 - val_loss: 0.2911 - val_acc: 0.9271\n",
      "Epoch 38/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9609\n",
      "Epoch 00038: val_loss did not improve from 0.28441\n",
      "36805/36805 [==============================] - 14s 389us/sample - loss: 0.1178 - acc: 0.9609 - val_loss: 0.3032 - val_acc: 0.9301\n",
      "Epoch 39/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9608\n",
      "Epoch 00039: val_loss improved from 0.28441 to 0.28228, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/39-0.2823.hdf5\n",
      "36805/36805 [==============================] - 15s 394us/sample - loss: 0.1158 - acc: 0.9608 - val_loss: 0.2823 - val_acc: 0.9301\n",
      "Epoch 40/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9629\n",
      "Epoch 00040: val_loss did not improve from 0.28228\n",
      "36805/36805 [==============================] - 14s 389us/sample - loss: 0.1125 - acc: 0.9629 - val_loss: 0.2974 - val_acc: 0.9297\n",
      "Epoch 41/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9632\n",
      "Epoch 00041: val_loss did not improve from 0.28228\n",
      "36805/36805 [==============================] - 14s 393us/sample - loss: 0.1124 - acc: 0.9633 - val_loss: 0.2884 - val_acc: 0.9273\n",
      "Epoch 42/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9633\n",
      "Epoch 00042: val_loss did not improve from 0.28228\n",
      "36805/36805 [==============================] - 14s 394us/sample - loss: 0.1125 - acc: 0.9633 - val_loss: 0.2986 - val_acc: 0.9338\n",
      "Epoch 43/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9619\n",
      "Epoch 00043: val_loss did not improve from 0.28228\n",
      "36805/36805 [==============================] - 14s 392us/sample - loss: 0.1143 - acc: 0.9619 - val_loss: 0.2832 - val_acc: 0.9380\n",
      "Epoch 44/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9664\n",
      "Epoch 00044: val_loss did not improve from 0.28228\n",
      "36805/36805 [==============================] - 14s 389us/sample - loss: 0.1056 - acc: 0.9664 - val_loss: 0.2851 - val_acc: 0.9331\n",
      "Epoch 45/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9660\n",
      "Epoch 00045: val_loss did not improve from 0.28228\n",
      "36805/36805 [==============================] - 14s 391us/sample - loss: 0.1021 - acc: 0.9660 - val_loss: 0.2966 - val_acc: 0.9311\n",
      "Epoch 46/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9674\n",
      "Epoch 00046: val_loss did not improve from 0.28228\n",
      "36805/36805 [==============================] - 14s 392us/sample - loss: 0.1010 - acc: 0.9674 - val_loss: 0.3013 - val_acc: 0.9292\n",
      "Epoch 47/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9687\n",
      "Epoch 00047: val_loss did not improve from 0.28228\n",
      "36805/36805 [==============================] - 15s 395us/sample - loss: 0.0964 - acc: 0.9687 - val_loss: 0.2923 - val_acc: 0.9343\n",
      "Epoch 48/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9679\n",
      "Epoch 00048: val_loss did not improve from 0.28228\n",
      "36805/36805 [==============================] - 14s 392us/sample - loss: 0.0978 - acc: 0.9679 - val_loss: 0.2919 - val_acc: 0.9334\n",
      "Epoch 49/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9677\n",
      "Epoch 00049: val_loss did not improve from 0.28228\n",
      "36805/36805 [==============================] - 14s 394us/sample - loss: 0.0952 - acc: 0.9677 - val_loss: 0.3259 - val_acc: 0.9285\n",
      "Epoch 50/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9675\n",
      "Epoch 00050: val_loss did not improve from 0.28228\n",
      "36805/36805 [==============================] - 14s 390us/sample - loss: 0.0960 - acc: 0.9675 - val_loss: 0.3023 - val_acc: 0.9343\n",
      "Epoch 51/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9684\n",
      "Epoch 00051: val_loss improved from 0.28228 to 0.27751, saving model to model/checkpoint/2D_CNN_3_only_conv_DO_BN_checkpoint/51-0.2775.hdf5\n",
      "36805/36805 [==============================] - 14s 392us/sample - loss: 0.0971 - acc: 0.9684 - val_loss: 0.2775 - val_acc: 0.9322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9692\n",
      "Epoch 00052: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 14s 393us/sample - loss: 0.0932 - acc: 0.9692 - val_loss: 0.2853 - val_acc: 0.9355\n",
      "Epoch 53/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9708\n",
      "Epoch 00053: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 395us/sample - loss: 0.0897 - acc: 0.9708 - val_loss: 0.2846 - val_acc: 0.9352\n",
      "Epoch 54/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9700\n",
      "Epoch 00054: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 14s 391us/sample - loss: 0.0890 - acc: 0.9700 - val_loss: 0.2973 - val_acc: 0.9343\n",
      "Epoch 55/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9693\n",
      "Epoch 00055: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 14s 392us/sample - loss: 0.0906 - acc: 0.9692 - val_loss: 0.3084 - val_acc: 0.9334\n",
      "Epoch 56/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9697\n",
      "Epoch 00056: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 14s 393us/sample - loss: 0.0890 - acc: 0.9697 - val_loss: 0.3169 - val_acc: 0.9357\n",
      "Epoch 57/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9720\n",
      "Epoch 00057: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 14s 390us/sample - loss: 0.0848 - acc: 0.9720 - val_loss: 0.2903 - val_acc: 0.9378\n",
      "Epoch 58/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9713\n",
      "Epoch 00058: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 394us/sample - loss: 0.0868 - acc: 0.9713 - val_loss: 0.3067 - val_acc: 0.9348\n",
      "Epoch 59/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9717\n",
      "Epoch 00059: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 394us/sample - loss: 0.0833 - acc: 0.9717 - val_loss: 0.2931 - val_acc: 0.9322\n",
      "Epoch 60/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9734\n",
      "Epoch 00060: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 14s 390us/sample - loss: 0.0817 - acc: 0.9734 - val_loss: 0.2921 - val_acc: 0.9366\n",
      "Epoch 61/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9739\n",
      "Epoch 00061: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 14s 389us/sample - loss: 0.0793 - acc: 0.9739 - val_loss: 0.3050 - val_acc: 0.9355\n",
      "Epoch 62/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9736\n",
      "Epoch 00062: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 14s 391us/sample - loss: 0.0784 - acc: 0.9736 - val_loss: 0.2972 - val_acc: 0.9343\n",
      "Epoch 63/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9732\n",
      "Epoch 00063: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 14s 392us/sample - loss: 0.0787 - acc: 0.9733 - val_loss: 0.2902 - val_acc: 0.9350\n",
      "Epoch 64/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9742\n",
      "Epoch 00064: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 14s 390us/sample - loss: 0.0765 - acc: 0.9741 - val_loss: 0.3149 - val_acc: 0.9336\n",
      "Epoch 65/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9738\n",
      "Epoch 00065: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 14s 392us/sample - loss: 0.0767 - acc: 0.9739 - val_loss: 0.3059 - val_acc: 0.9357\n",
      "Epoch 66/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9752\n",
      "Epoch 00066: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 14s 389us/sample - loss: 0.0738 - acc: 0.9752 - val_loss: 0.2921 - val_acc: 0.9415\n",
      "Epoch 67/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9749\n",
      "Epoch 00067: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 403us/sample - loss: 0.0753 - acc: 0.9748 - val_loss: 0.2970 - val_acc: 0.9359\n",
      "Epoch 68/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9747\n",
      "Epoch 00068: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 395us/sample - loss: 0.0762 - acc: 0.9747 - val_loss: 0.3000 - val_acc: 0.9385\n",
      "Epoch 69/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9748\n",
      "Epoch 00069: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 395us/sample - loss: 0.0736 - acc: 0.9748 - val_loss: 0.2963 - val_acc: 0.9411\n",
      "Epoch 70/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9746\n",
      "Epoch 00070: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 412us/sample - loss: 0.0759 - acc: 0.9746 - val_loss: 0.3165 - val_acc: 0.9385\n",
      "Epoch 71/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9759\n",
      "Epoch 00071: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 409us/sample - loss: 0.0753 - acc: 0.9758 - val_loss: 0.3097 - val_acc: 0.9369\n",
      "Epoch 72/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9751\n",
      "Epoch 00072: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 419us/sample - loss: 0.0736 - acc: 0.9751 - val_loss: 0.3038 - val_acc: 0.9373\n",
      "Epoch 73/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9763\n",
      "Epoch 00073: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 412us/sample - loss: 0.0714 - acc: 0.9763 - val_loss: 0.2982 - val_acc: 0.9378\n",
      "Epoch 74/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9785\n",
      "Epoch 00074: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 413us/sample - loss: 0.0663 - acc: 0.9785 - val_loss: 0.3021 - val_acc: 0.9385\n",
      "Epoch 75/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9774\n",
      "Epoch 00075: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 414us/sample - loss: 0.0675 - acc: 0.9774 - val_loss: 0.3099 - val_acc: 0.9336\n",
      "Epoch 76/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9769\n",
      "Epoch 00076: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 415us/sample - loss: 0.0684 - acc: 0.9768 - val_loss: 0.2859 - val_acc: 0.9385\n",
      "Epoch 77/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9784\n",
      "Epoch 00077: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 411us/sample - loss: 0.0673 - acc: 0.9784 - val_loss: 0.3053 - val_acc: 0.9383\n",
      "Epoch 78/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9772\n",
      "Epoch 00078: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 412us/sample - loss: 0.0683 - acc: 0.9772 - val_loss: 0.3244 - val_acc: 0.9320\n",
      "Epoch 79/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9773\n",
      "Epoch 00079: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 415us/sample - loss: 0.0660 - acc: 0.9773 - val_loss: 0.3025 - val_acc: 0.9350\n",
      "Epoch 80/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9785\n",
      "Epoch 00080: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 412us/sample - loss: 0.0639 - acc: 0.9786 - val_loss: 0.3002 - val_acc: 0.9385\n",
      "Epoch 81/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9776\n",
      "Epoch 00081: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 411us/sample - loss: 0.0679 - acc: 0.9776 - val_loss: 0.3178 - val_acc: 0.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9791\n",
      "Epoch 00082: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 409us/sample - loss: 0.0653 - acc: 0.9791 - val_loss: 0.2976 - val_acc: 0.9408\n",
      "Epoch 83/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9792\n",
      "Epoch 00083: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 412us/sample - loss: 0.0633 - acc: 0.9792 - val_loss: 0.3106 - val_acc: 0.9366\n",
      "Epoch 84/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9787\n",
      "Epoch 00084: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 398us/sample - loss: 0.0641 - acc: 0.9787 - val_loss: 0.3382 - val_acc: 0.9390\n",
      "Epoch 85/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9765\n",
      "Epoch 00085: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 408us/sample - loss: 0.0708 - acc: 0.9765 - val_loss: 0.3215 - val_acc: 0.9366\n",
      "Epoch 86/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9790\n",
      "Epoch 00086: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 417us/sample - loss: 0.0637 - acc: 0.9790 - val_loss: 0.3095 - val_acc: 0.9362\n",
      "Epoch 87/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9773\n",
      "Epoch 00087: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 404us/sample - loss: 0.0658 - acc: 0.9772 - val_loss: 0.3119 - val_acc: 0.9376\n",
      "Epoch 88/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9792\n",
      "Epoch 00088: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 411us/sample - loss: 0.0642 - acc: 0.9792 - val_loss: 0.3064 - val_acc: 0.9418\n",
      "Epoch 89/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9778\n",
      "Epoch 00089: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 412us/sample - loss: 0.0662 - acc: 0.9778 - val_loss: 0.3139 - val_acc: 0.9348\n",
      "Epoch 90/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9803\n",
      "Epoch 00090: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 409us/sample - loss: 0.0612 - acc: 0.9803 - val_loss: 0.3119 - val_acc: 0.9390\n",
      "Epoch 91/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9805\n",
      "Epoch 00091: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 410us/sample - loss: 0.0613 - acc: 0.9805 - val_loss: 0.3204 - val_acc: 0.9399\n",
      "Epoch 92/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9793\n",
      "Epoch 00092: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 404us/sample - loss: 0.0620 - acc: 0.9794 - val_loss: 0.3140 - val_acc: 0.9387\n",
      "Epoch 93/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9806\n",
      "Epoch 00093: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 408us/sample - loss: 0.0588 - acc: 0.9807 - val_loss: 0.3192 - val_acc: 0.9387\n",
      "Epoch 94/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9792\n",
      "Epoch 00094: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 415us/sample - loss: 0.0612 - acc: 0.9792 - val_loss: 0.3043 - val_acc: 0.9404\n",
      "Epoch 95/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9814\n",
      "Epoch 00095: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 414us/sample - loss: 0.0608 - acc: 0.9814 - val_loss: 0.3388 - val_acc: 0.9308\n",
      "Epoch 96/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9819\n",
      "Epoch 00096: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 415us/sample - loss: 0.0545 - acc: 0.9819 - val_loss: 0.3150 - val_acc: 0.9371\n",
      "Epoch 97/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9801\n",
      "Epoch 00097: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 412us/sample - loss: 0.0576 - acc: 0.9802 - val_loss: 0.3170 - val_acc: 0.9383\n",
      "Epoch 98/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9796\n",
      "Epoch 00098: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 409us/sample - loss: 0.0613 - acc: 0.9796 - val_loss: 0.3140 - val_acc: 0.9390\n",
      "Epoch 99/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9825\n",
      "Epoch 00099: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 412us/sample - loss: 0.0524 - acc: 0.9825 - val_loss: 0.3437 - val_acc: 0.9355\n",
      "Epoch 100/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9817\n",
      "Epoch 00100: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 412us/sample - loss: 0.0562 - acc: 0.9817 - val_loss: 0.3213 - val_acc: 0.9425\n",
      "Epoch 101/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9815\n",
      "Epoch 00101: val_loss did not improve from 0.27751\n",
      "36805/36805 [==============================] - 15s 411us/sample - loss: 0.0582 - acc: 0.9815 - val_loss: 0.3287 - val_acc: 0.9385\n",
      "\n",
      "3 Only Conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 312us/sample - loss: 0.3583 - acc: 0.9142\n",
      "Loss: 0.3582825439896044 Accuracy: 0.91422635\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7526 - acc: 0.2901\n",
      "Epoch 00001: val_loss improved from inf to 1.36044, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/01-1.3604.hdf5\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 2.7526 - acc: 0.2901 - val_loss: 1.3604 - val_acc: 0.5775\n",
      "Epoch 2/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6616 - acc: 0.5148\n",
      "Epoch 00002: val_loss improved from 1.36044 to 0.90515, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/02-0.9052.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.6607 - acc: 0.5150 - val_loss: 0.9052 - val_acc: 0.7277\n",
      "Epoch 3/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1590 - acc: 0.6512\n",
      "Epoch 00003: val_loss improved from 0.90515 to 0.66357, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/03-0.6636.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1592 - acc: 0.6512 - val_loss: 0.6636 - val_acc: 0.8064\n",
      "Epoch 4/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8973 - acc: 0.7257\n",
      "Epoch 00004: val_loss improved from 0.66357 to 0.53157, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/04-0.5316.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8974 - acc: 0.7256 - val_loss: 0.5316 - val_acc: 0.8428\n",
      "Epoch 5/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7292 - acc: 0.7736\n",
      "Epoch 00005: val_loss improved from 0.53157 to 0.45429, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/05-0.4543.hdf5\n",
      "36805/36805 [==============================] - 15s 404us/sample - loss: 0.7292 - acc: 0.7736 - val_loss: 0.4543 - val_acc: 0.8672\n",
      "Epoch 6/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6152 - acc: 0.8076\n",
      "Epoch 00006: val_loss improved from 0.45429 to 0.39517, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/06-0.3952.hdf5\n",
      "36805/36805 [==============================] - 15s 404us/sample - loss: 0.6152 - acc: 0.8077 - val_loss: 0.3952 - val_acc: 0.8833\n",
      "Epoch 7/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5295 - acc: 0.8337\n",
      "Epoch 00007: val_loss improved from 0.39517 to 0.36544, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/07-0.3654.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.5296 - acc: 0.8337 - val_loss: 0.3654 - val_acc: 0.8915\n",
      "Epoch 8/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4714 - acc: 0.8537\n",
      "Epoch 00008: val_loss improved from 0.36544 to 0.34064, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/08-0.3406.hdf5\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.4713 - acc: 0.8537 - val_loss: 0.3406 - val_acc: 0.9045\n",
      "Epoch 9/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4195 - acc: 0.8667\n",
      "Epoch 00009: val_loss improved from 0.34064 to 0.30308, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/09-0.3031.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.4194 - acc: 0.8667 - val_loss: 0.3031 - val_acc: 0.9173\n",
      "Epoch 10/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3864 - acc: 0.8771\n",
      "Epoch 00010: val_loss improved from 0.30308 to 0.28718, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/10-0.2872.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.3864 - acc: 0.8771 - val_loss: 0.2872 - val_acc: 0.9178\n",
      "Epoch 11/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3498 - acc: 0.8873\n",
      "Epoch 00011: val_loss improved from 0.28718 to 0.26881, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/11-0.2688.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.3497 - acc: 0.8873 - val_loss: 0.2688 - val_acc: 0.9252\n",
      "Epoch 12/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3263 - acc: 0.8962\n",
      "Epoch 00012: val_loss improved from 0.26881 to 0.26142, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/12-0.2614.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.3262 - acc: 0.8963 - val_loss: 0.2614 - val_acc: 0.9250\n",
      "Epoch 13/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3034 - acc: 0.9039\n",
      "Epoch 00013: val_loss did not improve from 0.26142\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.3034 - acc: 0.9039 - val_loss: 0.2637 - val_acc: 0.9222\n",
      "Epoch 14/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2882 - acc: 0.9080\n",
      "Epoch 00014: val_loss improved from 0.26142 to 0.24029, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/14-0.2403.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.2881 - acc: 0.9081 - val_loss: 0.2403 - val_acc: 0.9329\n",
      "Epoch 15/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2650 - acc: 0.9157\n",
      "Epoch 00015: val_loss did not improve from 0.24029\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 0.2651 - acc: 0.9157 - val_loss: 0.2460 - val_acc: 0.9334\n",
      "Epoch 16/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2532 - acc: 0.9196\n",
      "Epoch 00016: val_loss improved from 0.24029 to 0.22612, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/16-0.2261.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.2530 - acc: 0.9197 - val_loss: 0.2261 - val_acc: 0.9324\n",
      "Epoch 17/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2361 - acc: 0.9230\n",
      "Epoch 00017: val_loss improved from 0.22612 to 0.21689, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/17-0.2169.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.2361 - acc: 0.9231 - val_loss: 0.2169 - val_acc: 0.9385\n",
      "Epoch 18/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2179 - acc: 0.9308\n",
      "Epoch 00018: val_loss improved from 0.21689 to 0.20954, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/18-0.2095.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.2182 - acc: 0.9306 - val_loss: 0.2095 - val_acc: 0.9378\n",
      "Epoch 19/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2143 - acc: 0.9317\n",
      "Epoch 00019: val_loss improved from 0.20954 to 0.20267, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/19-0.2027.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.2144 - acc: 0.9317 - val_loss: 0.2027 - val_acc: 0.9418\n",
      "Epoch 20/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2049 - acc: 0.9343\n",
      "Epoch 00020: val_loss improved from 0.20267 to 0.20226, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/20-0.2023.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 0.2052 - acc: 0.9342 - val_loss: 0.2023 - val_acc: 0.9420\n",
      "Epoch 21/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1940 - acc: 0.9384\n",
      "Epoch 00021: val_loss did not improve from 0.20226\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.1941 - acc: 0.9384 - val_loss: 0.2057 - val_acc: 0.9432\n",
      "Epoch 22/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1892 - acc: 0.9388\n",
      "Epoch 00022: val_loss did not improve from 0.20226\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 0.1891 - acc: 0.9388 - val_loss: 0.2031 - val_acc: 0.9469\n",
      "Epoch 23/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1741 - acc: 0.9436\n",
      "Epoch 00023: val_loss did not improve from 0.20226\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.1742 - acc: 0.9435 - val_loss: 0.2069 - val_acc: 0.9376\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9459\n",
      "Epoch 00024: val_loss improved from 0.20226 to 0.19471, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/24-0.1947.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.1695 - acc: 0.9458 - val_loss: 0.1947 - val_acc: 0.9448\n",
      "Epoch 25/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1646 - acc: 0.9467\n",
      "Epoch 00025: val_loss improved from 0.19471 to 0.18825, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/25-0.1883.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.1646 - acc: 0.9466 - val_loss: 0.1883 - val_acc: 0.9485\n",
      "Epoch 26/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1555 - acc: 0.9500\n",
      "Epoch 00026: val_loss did not improve from 0.18825\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.1554 - acc: 0.9500 - val_loss: 0.1935 - val_acc: 0.9464\n",
      "Epoch 27/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9501\n",
      "Epoch 00027: val_loss improved from 0.18825 to 0.18417, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/27-0.1842.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.1547 - acc: 0.9501 - val_loss: 0.1842 - val_acc: 0.9460\n",
      "Epoch 28/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9535\n",
      "Epoch 00028: val_loss did not improve from 0.18417\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.1432 - acc: 0.9535 - val_loss: 0.1936 - val_acc: 0.9455\n",
      "Epoch 29/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1391 - acc: 0.9543\n",
      "Epoch 00029: val_loss did not improve from 0.18417\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.1391 - acc: 0.9543 - val_loss: 0.1890 - val_acc: 0.9478\n",
      "Epoch 30/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9545\n",
      "Epoch 00030: val_loss improved from 0.18417 to 0.18255, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/30-0.1826.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.1379 - acc: 0.9544 - val_loss: 0.1826 - val_acc: 0.9478\n",
      "Epoch 31/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9569\n",
      "Epoch 00031: val_loss did not improve from 0.18255\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.1329 - acc: 0.9570 - val_loss: 0.1834 - val_acc: 0.9483\n",
      "Epoch 32/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9565\n",
      "Epoch 00032: val_loss improved from 0.18255 to 0.18231, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/32-0.1823.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.1303 - acc: 0.9565 - val_loss: 0.1823 - val_acc: 0.9464\n",
      "Epoch 33/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9576\n",
      "Epoch 00033: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.1300 - acc: 0.9576 - val_loss: 0.1910 - val_acc: 0.9474\n",
      "Epoch 34/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9604\n",
      "Epoch 00034: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 0.1202 - acc: 0.9604 - val_loss: 0.2148 - val_acc: 0.9474\n",
      "Epoch 35/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9609\n",
      "Epoch 00035: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.1199 - acc: 0.9609 - val_loss: 0.1933 - val_acc: 0.9462\n",
      "Epoch 36/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9609\n",
      "Epoch 00036: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.1169 - acc: 0.9609 - val_loss: 0.2019 - val_acc: 0.9495\n",
      "Epoch 37/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9635\n",
      "Epoch 00037: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.1123 - acc: 0.9635 - val_loss: 0.1949 - val_acc: 0.9520\n",
      "Epoch 38/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9643\n",
      "Epoch 00038: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.1091 - acc: 0.9643 - val_loss: 0.1920 - val_acc: 0.9497\n",
      "Epoch 39/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9671\n",
      "Epoch 00039: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.1018 - acc: 0.9671 - val_loss: 0.2000 - val_acc: 0.9490\n",
      "Epoch 40/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9663\n",
      "Epoch 00040: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.1041 - acc: 0.9663 - val_loss: 0.2008 - val_acc: 0.9446\n",
      "Epoch 41/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9668\n",
      "Epoch 00041: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.0994 - acc: 0.9669 - val_loss: 0.1931 - val_acc: 0.9511\n",
      "Epoch 42/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9674\n",
      "Epoch 00042: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.0985 - acc: 0.9674 - val_loss: 0.1944 - val_acc: 0.9509\n",
      "Epoch 43/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9670\n",
      "Epoch 00043: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.0992 - acc: 0.9671 - val_loss: 0.2013 - val_acc: 0.9474\n",
      "Epoch 44/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9684\n",
      "Epoch 00044: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.0966 - acc: 0.9684 - val_loss: 0.1904 - val_acc: 0.9520\n",
      "Epoch 45/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9693\n",
      "Epoch 00045: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.0930 - acc: 0.9693 - val_loss: 0.1885 - val_acc: 0.9529\n",
      "Epoch 46/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9705\n",
      "Epoch 00046: val_loss did not improve from 0.18231\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.0905 - acc: 0.9705 - val_loss: 0.1960 - val_acc: 0.9506\n",
      "Epoch 47/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9710\n",
      "Epoch 00047: val_loss improved from 0.18231 to 0.17971, saving model to model/checkpoint/2D_CNN_4_only_conv_DO_BN_checkpoint/47-0.1797.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.0897 - acc: 0.9710 - val_loss: 0.1797 - val_acc: 0.9506\n",
      "Epoch 48/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9711\n",
      "Epoch 00048: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 0.0867 - acc: 0.9711 - val_loss: 0.2026 - val_acc: 0.9499\n",
      "Epoch 49/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9718\n",
      "Epoch 00049: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.0841 - acc: 0.9718 - val_loss: 0.1893 - val_acc: 0.9518\n",
      "Epoch 50/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9707\n",
      "Epoch 00050: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 0.0858 - acc: 0.9708 - val_loss: 0.2065 - val_acc: 0.9509\n",
      "Epoch 51/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9724\n",
      "Epoch 00051: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 0.0837 - acc: 0.9724 - val_loss: 0.2163 - val_acc: 0.9497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9723\n",
      "Epoch 00052: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.0828 - acc: 0.9723 - val_loss: 0.2002 - val_acc: 0.9532\n",
      "Epoch 53/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9726\n",
      "Epoch 00053: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.0824 - acc: 0.9726 - val_loss: 0.1970 - val_acc: 0.9513\n",
      "Epoch 54/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9737\n",
      "Epoch 00054: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.0792 - acc: 0.9737 - val_loss: 0.2112 - val_acc: 0.9497\n",
      "Epoch 55/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9748\n",
      "Epoch 00055: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.0749 - acc: 0.9748 - val_loss: 0.1969 - val_acc: 0.9515\n",
      "Epoch 56/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9745\n",
      "Epoch 00056: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.0773 - acc: 0.9745 - val_loss: 0.1943 - val_acc: 0.9520\n",
      "Epoch 57/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9758\n",
      "Epoch 00057: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.0734 - acc: 0.9757 - val_loss: 0.1977 - val_acc: 0.9539\n",
      "Epoch 58/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9742\n",
      "Epoch 00058: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.0784 - acc: 0.9742 - val_loss: 0.2069 - val_acc: 0.9509\n",
      "Epoch 59/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9764\n",
      "Epoch 00059: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 0.0717 - acc: 0.9764 - val_loss: 0.2039 - val_acc: 0.9518\n",
      "Epoch 60/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9763\n",
      "Epoch 00060: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.0714 - acc: 0.9763 - val_loss: 0.2049 - val_acc: 0.9541\n",
      "Epoch 61/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9765\n",
      "Epoch 00061: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 0.0700 - acc: 0.9765 - val_loss: 0.2008 - val_acc: 0.9536\n",
      "Epoch 62/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9773\n",
      "Epoch 00062: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.0687 - acc: 0.9773 - val_loss: 0.1991 - val_acc: 0.9546\n",
      "Epoch 63/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9787\n",
      "Epoch 00063: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.0651 - acc: 0.9786 - val_loss: 0.2066 - val_acc: 0.9555\n",
      "Epoch 64/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9779\n",
      "Epoch 00064: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.0646 - acc: 0.9779 - val_loss: 0.1998 - val_acc: 0.9520\n",
      "Epoch 65/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9783\n",
      "Epoch 00065: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 0.0647 - acc: 0.9782 - val_loss: 0.2038 - val_acc: 0.9492\n",
      "Epoch 66/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9797\n",
      "Epoch 00066: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.0622 - acc: 0.9797 - val_loss: 0.2068 - val_acc: 0.9513\n",
      "Epoch 67/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9792\n",
      "Epoch 00067: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 0.0628 - acc: 0.9792 - val_loss: 0.1969 - val_acc: 0.9541\n",
      "Epoch 68/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9783\n",
      "Epoch 00068: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 0.0638 - acc: 0.9783 - val_loss: 0.2079 - val_acc: 0.9499\n",
      "Epoch 69/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9780\n",
      "Epoch 00069: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 0.0654 - acc: 0.9780 - val_loss: 0.1950 - val_acc: 0.9541\n",
      "Epoch 70/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9799\n",
      "Epoch 00070: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 0.0616 - acc: 0.9799 - val_loss: 0.2119 - val_acc: 0.9522\n",
      "Epoch 71/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9790\n",
      "Epoch 00071: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 0.0616 - acc: 0.9790 - val_loss: 0.1988 - val_acc: 0.9539\n",
      "Epoch 72/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9778\n",
      "Epoch 00072: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 428us/sample - loss: 0.0652 - acc: 0.9778 - val_loss: 0.2253 - val_acc: 0.9504\n",
      "Epoch 73/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9800\n",
      "Epoch 00073: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 431us/sample - loss: 0.0593 - acc: 0.9800 - val_loss: 0.1977 - val_acc: 0.9546\n",
      "Epoch 74/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9794\n",
      "Epoch 00074: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 0.0604 - acc: 0.9795 - val_loss: 0.2056 - val_acc: 0.9522\n",
      "Epoch 75/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9827\n",
      "Epoch 00075: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.0538 - acc: 0.9826 - val_loss: 0.2042 - val_acc: 0.9534\n",
      "Epoch 76/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9786\n",
      "Epoch 00076: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 0.0636 - acc: 0.9786 - val_loss: 0.2022 - val_acc: 0.9520\n",
      "Epoch 77/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9819\n",
      "Epoch 00077: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.0544 - acc: 0.9819 - val_loss: 0.2205 - val_acc: 0.9515\n",
      "Epoch 78/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9821\n",
      "Epoch 00078: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 0.0537 - acc: 0.9821 - val_loss: 0.2131 - val_acc: 0.9511\n",
      "Epoch 79/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9807\n",
      "Epoch 00079: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.0575 - acc: 0.9807 - val_loss: 0.2122 - val_acc: 0.9525\n",
      "Epoch 80/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9824\n",
      "Epoch 00080: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.0545 - acc: 0.9824 - val_loss: 0.2189 - val_acc: 0.9497\n",
      "Epoch 81/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9820\n",
      "Epoch 00081: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.0530 - acc: 0.9820 - val_loss: 0.2245 - val_acc: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9817\n",
      "Epoch 00082: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.0541 - acc: 0.9816 - val_loss: 0.2097 - val_acc: 0.9527\n",
      "Epoch 83/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9803\n",
      "Epoch 00083: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.0577 - acc: 0.9803 - val_loss: 0.2129 - val_acc: 0.9513\n",
      "Epoch 84/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9831\n",
      "Epoch 00084: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.0504 - acc: 0.9830 - val_loss: 0.2169 - val_acc: 0.9506\n",
      "Epoch 85/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9810\n",
      "Epoch 00085: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.0585 - acc: 0.9810 - val_loss: 0.2052 - val_acc: 0.9525\n",
      "Epoch 86/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9830\n",
      "Epoch 00086: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 0.0506 - acc: 0.9829 - val_loss: 0.2012 - val_acc: 0.9497\n",
      "Epoch 87/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9819\n",
      "Epoch 00087: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 0.0545 - acc: 0.9819 - val_loss: 0.2283 - val_acc: 0.9513\n",
      "Epoch 88/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9835\n",
      "Epoch 00088: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.0508 - acc: 0.9835 - val_loss: 0.2069 - val_acc: 0.9560\n",
      "Epoch 89/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9821\n",
      "Epoch 00089: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.0515 - acc: 0.9821 - val_loss: 0.2158 - val_acc: 0.9522\n",
      "Epoch 90/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9812\n",
      "Epoch 00090: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.0550 - acc: 0.9813 - val_loss: 0.2054 - val_acc: 0.9536\n",
      "Epoch 91/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9834\n",
      "Epoch 00091: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.0509 - acc: 0.9833 - val_loss: 0.2140 - val_acc: 0.9529\n",
      "Epoch 92/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9839\n",
      "Epoch 00092: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.0479 - acc: 0.9838 - val_loss: 0.2204 - val_acc: 0.9525\n",
      "Epoch 93/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9843\n",
      "Epoch 00093: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.0468 - acc: 0.9844 - val_loss: 0.2057 - val_acc: 0.9527\n",
      "Epoch 94/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9842\n",
      "Epoch 00094: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.0482 - acc: 0.9842 - val_loss: 0.2017 - val_acc: 0.9525\n",
      "Epoch 95/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9840\n",
      "Epoch 00095: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.0485 - acc: 0.9841 - val_loss: 0.2245 - val_acc: 0.9518\n",
      "Epoch 96/200\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9841\n",
      "Epoch 00096: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.0484 - acc: 0.9841 - val_loss: 0.2318 - val_acc: 0.9488\n",
      "Epoch 97/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9851\n",
      "Epoch 00097: val_loss did not improve from 0.17971\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 0.0450 - acc: 0.9851 - val_loss: 0.2351 - val_acc: 0.9513\n",
      "\n",
      "4 Only Conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8HVXd+PHPd+auuVmbLkn3lrX7XiqVUgQRC1aUpfiACCo8+sMFUR4RNx6X50HlUR8UHkREQVktoKBVEKUUkCJtKbSlha7QdMnSJmmSe3O3Ob8/zs3SNknTNrdJc7/v12teyZ07d+bMzL3nO+ecmXPEGINSSinVEae3E6CUUqrv0iChlFKqUxoklFJKdUqDhFJKqU5pkFBKKdUpDRJKKaU6pUFCKaVUpzRIKKWU6pQGCaWUUp3y9XYCDtfAgQPN6NGjezsZSil1XFm5cmWNMWbQ4X7uuAsSo0ePZsWKFb2dDKWUOq6IyDtH8jmtblJKKdUpDRJKKaU6pUFCKaVUp467NomOJJNJKioqaG5u7u2kHLdCoRDDhw/H7/f3dlKUUn1IvwgSFRUVFBQUMHr0aESkt5Nz3DHGsGfPHioqKhgzZkxvJ0cp1Yf0i+qm5uZmSktLNUAcIRGhtLRUS2JKqYP0iyABaIA4Snr8lFId6TdB4lDS6Rjx+A48L9nbSVFKqeNGzgQJz2smkdiFMT0fJOrq6rjzzjuP6LMLFiygrq6u28vfcsst3HbbbUe0LaWUOlw5EyREWnbV6/F1dxUkUqlUl59dsmQJxcXFPZ4mpZTqCTkTJFp21ZieDxI33XQTmzdvZurUqdx4440sXbqUM844g4ULFzJ+/HgALrzwQmbMmMGECRO4++67Wz87evRoampq2LZtG+PGjeOaa65hwoQJnHvuucRisS63u3r1aubMmcPkyZP5yEc+Qm1tLQC3334748ePZ/LkyVx22WUAPP/880ydOpWpU6cybdo0Ghoaevw4KKX6n35xC2x7GzdeT2Pj6g7eSZNOR3GcMCKHt9v5+VM56aSfdvr+rbfeytq1a1m92m536dKlrFq1irVr17beUnrvvfcyYMAAYrEYs2bN4qKLLqK0tPSAtG/koYce4pe//CWXXnopjz32GFdccUWn273yyiv52c9+xplnnsm3vvUt/vM//5Of/vSn3HrrrWzdupVgMNhalXXbbbdxxx13MHfuXBobGwmFQod1DJRSuSmHShLH9u6d2bNn7/fMwe23386UKVOYM2cO27dvZ+PGjQd9ZsyYMUydOhWAGTNmsG3btk7XX19fT11dHWeeeSYAn/jEJ1i2bBkAkydP5vLLL+d3v/sdPp8NiHPnzuWGG27g9ttvp66urnW+Ukp1pd/lFJ1d8XtenKamNQSDowkEBmY9HZFIpPX/pUuX8uyzz/Lyyy+Tl5fH/PnzO3wmIRgMtv7vuu4hq5s68+c//5lly5bx1FNP8f3vf581a9Zw0003cf7557NkyRLmzp3L008/zamnnnpE61dK5Y4cKklkr+G6oKCgyzr++vp6SkpKyMvLY8OGDSxfvvyot1lUVERJSQkvvPACAL/97W8588wz8TyP7du3c9ZZZ/GDH/yA+vp6Ghsb2bx5M5MmTeKrX/0qs2bNYsOGDUedBqVU/9fvShKdabm7KRsN16WlpcydO5eJEyfywQ9+kPPPP3+/98877zzuuusuxo0bxymnnMKcOXN6ZLv33Xcfn/nMZ4hGo4wdO5Zf//rXpNNprrjiCurr6zHG8IUvfIHi4mK++c1v8txzz+E4DhMmTOCDH/xgj6RBKdW/iTGmt9NwWGbOnGkOHHRo/fr1jBs3rsvPGWNobFxJIDCUYHBoNpN43OrOcVRKHZ9EZKUxZubhfi5nqptstxOSlZKEUkr1VzkTJCyXbLRJKKVUf5VTQULE0ZKEUkodhpwKEnZ3NUgopVR35VSQ0JKEUkodnpwKEnZ3072dCKWUOm5kLUiIyAgReU5E3hSRdSLyxQ6WmS8i9SKyOjN9K1vpsdvrOyWJ/Pz8w5qvlFK9IZsP06WALxtjVolIAbBSRP5mjHnzgOVeMMZckMV0tOMAOuiQUkp1V9ZKEsaYXcaYVZn/G4D1wLBsba87slWSuOmmm7jjjjtaX7cMDNTY2MjZZ5/N9OnTmTRpEn/84x+7vU5jDDfeeCMTJ05k0qRJPPLIIwDs2rWLefPmMXXqVCZOnMgLL7xAOp3mqquual32Jz/5SY/vo1IqNx2TbjlEZDQwDXilg7ffIyKvAzuBrxhj1h3Vxq6/HlZ31FU4BL1mjEmBe5hVOlOnwk877yp80aJFXH/99Vx33XUAPProozz99NOEQiGeeOIJCgsLqampYc6cOSxcuLBb40k//vjjrF69mtdff52amhpmzZrFvHnzePDBB/nABz7A17/+ddLpNNFolNWrV7Njxw7Wrl0LcFgj3SmlVFeyHiREJB94DLjeGLPvgLdXAaOMMY0isgD4A3BSB+u4FrgWYOTIkUeTGrLRCcm0adOoqqpi586dVFdXU1JSwogRI0gmk9x8880sW7YMx3HYsWMHlZWVlJWVHXKdL774Ih/72MdwXZchQ4Zw5pln8uqrrzJr1iw++clPkkwmufDCC5k6dSpjx45ly5YtfP7zn+f888/n3HPPzcJeKqVyUVaDhIj4sQHiAWPM4we+3z5oGGOWiMidIjLQGFNzwHJ3A3eD7bupy412ccWfjFeQSFRSUDDjsPajOy655BIWL17M7t27WbRoEQAPPPAA1dXVrFy5Er/fz+jRozvsIvxwzJs3j2XLlvHnP/+Zq666ihtuuIErr7yS119/naeffpq77rqLRx99lHvvvbcndkspleOyeXeTAL8C1htjftzJMmWZ5RCR2Zn07MlWmuzqDdno1HDRokU8/PDDLF68mEsuuQSwXYQPHjwYv9/Pc889xzvvvNPt9Z1xxhk88sgjpNNpqqurWbZsGbNnz+add95hyJAhXHPNNXz6059m1apV1NTU4HkeF110Ed/73vdYtWpVj++fUio3ZbMkMRf4OLBGRFoaCW4GRgIYY+4CLgY+KyIpIAZcZrLYLW1Ld+H2qWu3R9c9YcIEGhoaGDZsGOXl5QBcfvnlfOhDH2LSpEnMnDnzsAb5+chHPsLLL7/MlClTEBF++MMfUlZWxn333cePfvQj/H4/+fn53H///ezYsYOrr74az7ON8v/93//do/umlMpdOdNVOEAiUUU8/i6RyBQcx5+tJB63tKtwpfov7Sq8G/YvSSillDqUnAoSLbvbV566Vkqpvi6ngoRISzuEBgmllOqOnAoSWpJQSqnDk1NBQtsklFLq8ORUkGgrSWh34Uop1R05FSSyVZKoq6vjzjvvPKLPLliwQPtaUkr1WTkVJLLVJtFVkEilUl1+dsmSJRQXF/doepRSqqfkVJDIVknipptuYvPmzUydOpUbb7yRpUuXcsYZZ7Bw4ULGjx8PwIUXXsiMGTOYMGECd999d+tnR48eTU1NDdu2bWPcuHFcc801TJgwgXPPPZdYLHbQtp566ilOO+00pk2bxjnnnENlZSUAjY2NXH311UyaNInJkyfz2GOPAfDXv/6V6dOnM2XKFM4+++we3W+lVP93TLoKP5a66CkccEinT0EkgHMY4fEQPYVz6623snbtWlZnNrx06VJWrVrF2rVrGTNmDAD33nsvAwYMIBaLMWvWLC666CJKS0v3W8/GjRt56KGH+OUvf8mll17KY489xhVXXLHfMu9973tZvnw5IsI999zDD3/4Q/7nf/6H7373uxQVFbFmzRoAamtrqa6u5pprrmHZsmWMGTOGvXv3dn+nlVKKfhgkunbocRx6yuzZs1sDBMDtt9/OE088AcD27dvZuHHjQUFizJgxTJ06FYAZM2awbdu2g9ZbUVHBokWL2LVrF4lEonUbzz77LA8//HDrciUlJTz11FPMmzevdZkBAwb06D4qpfq/fhckurriB2ho2ITfX0oodDTjUhxaJBJp/X/p0qU8++yzvPzyy+Tl5TF//vwOuwwPBoOt/7uu22F10+c//3luuOEGFi5cyNKlS7nllluykn6llIIca5OA7AxhWlBQQENDQ6fv19fXU1JSQl5eHhs2bGD58uVHvK36+nqGDbOjwN53332t89///vfvN4RqbW0tc+bMYdmyZWzduhVAq5uUUoct54KE3eWeDRKlpaXMnTuXiRMncuONNx70/nnnnUcqlWLcuHHcdNNNzJkz54i3dcstt3DJJZcwY8YMBg4c2Dr/G9/4BrW1tUycOJEpU6bw3HPPMWjQIO6++24++tGPMmXKlNbBkJRSqrtyqqtwgKamdYgEycs7MRvJO65pV+FK9V/aVXi39XxJQiml+qucCxLZaJNQSqn+KueChB22VIOEUkp1R84FCS1JKKVU9+VckNA2CaWU6r6cCxJaklBKqe7LuSBhd7n3x5PIz8/v7SQopdQh5VyQsD3BGo6350OUUqo35FyQaNvlnqtyuummm/brEuOWW27htttuo7GxkbPPPpvp06czadIk/vjHPx5yXZ11Kd5Rl9+ddQ+ulFI9pd918Hf9X69n9e5O+wrHmCSe14zr5tPdXmGnlk3lp+d13nPgokWLuP7667nuuusAePTRR3n66acJhUI88cQTFBYWUlNTw5w5c1i4cCEinW+3oy7FPc/rsMvvjroHV0qpntTvgkT3GXqq6/Bp06ZRVVXFzp07qa6upqSkhBEjRpBMJrn55ptZtmwZjuOwY8cOKisrKSsr63RdHXUpXl1d3WGX3x11D66UUj2p3wWJrq74AZLJvTQ3byEvbwKuG+6x7V5yySUsXryY3bt3t3ak98ADD1BdXc3KlSvx+/2MHj26wy7CW3S3S3GllDpWtE2ihyxatIiHH36YxYsXc8kllwC2W+/Bgwfj9/t57rnneOedd7pcR2ddinfW5XdH3YMrpVRPylqQEJERIvKciLwpIutE5IsdLCMicruIbBKRN0RkerbS07ZNu8s9/azEhAkTaGhoYNiwYZSXlwNw+eWXs2LFCiZNmsT999/Pqaee2uU6OutSvLMuvzvqHlwppXpS1roKF5FyoNwYs0pECoCVwIXGmDfbLbMA+DywADgN+F9jzGldrfdouwpPpxuJRjcQDp+Ez1d0WPvU32lX4Ur1X32uq3BjzC5jzKrM/w3AemDYAYt9GLjfWMuB4kxwyaLslCSUUqo/OiZtEiIyGpgGvHLAW8OA7e1eV3BwIEFErhWRFSKyorq6+ijTkp02CaWU6o+yHiREJB94DLjeGLPvSNZhjLnbGDPTGDNz0KBBnS3TzbVpSaIj+gS6UqojWQ0SIuLHBogHjDGPd7DIDmBEu9fDM/MOSygUYs+ePd3K6LQkcTBjDHv27CEUCvV2UpRSfUzWnpMQ+1jxr4D1xpgfd7LYk8DnRORhbMN1vTFm1+Fua/jw4VRUVNCdqihjDPF4DT5fCp9v7+Fuqt8KhUIMHz68t5OhlOpjsvkw3Vzg48AaEWnpJ+NmYCSAMeYuYAn2zqZNQBS4+kg25Pf7W59G7o7nn5/KiBFfYezY/zqSzSmlVM7IWpAwxrzIIfq9MLZ+6LpspaEzjpNHOh091ptVSqnjTg4+cQ2um4fnaZBQSqlDyckgoSUJpZTqnpwMErYk0dTbyVBKqT4vR4NEREsSSinVDTkZJBxH2ySUUqo7cjJIuK62SSilVHfkZJDQkoRSSnVPTgYJLUkopVT35GSQcJwI6bTe3aSUUoeSk0FCH6ZTSqnuyckgYdskYtpduFJKHUJOBgnXzQPA85p7OSVKKdW35WSQcBwbJLTxWimlupaTQaKtJKGN10op1ZUcDRIRQEsSSil1KDkZJFqqm/QOJ6WU6lpOBomW6iYtSSilVNdyMkhoSUIppbonJ4NEW0lCG66VUqorORkkfL5iAFKp2l5OiVJK9W05GST8/sEAJBJVvZwSpZTq23IySLhuGNctIJnUIKGUUl3JySABtjShJQmllOpazgaJQGCwliSUUuoQcjZI2JJEZW8nQyml+rScDRKBgFY3KaXUoeRwkBhCMlmtY0oopVQXshYkROReEakSkbWdvD9fROpFZHVm+la20tIRexusRzK591huVimljivZLEn8BjjvEMu8YIyZmpm+k8W0HCQQsM9KaOO1Ukp1LmtBwhizDOizl+n6QJ1SSh1ab7dJvEdEXheRv4jIhGO54baShN7hpJRSnelWkBCRL4pIoVi/EpFVInLuUW57FTDKGDMF+Bnwhy62f62IrBCRFdXV1Ue5WcvvHwJoSUIppbrS3ZLEJ40x+4BzgRLg48CtR7NhY8w+Y0xj5v8lgF9EBnay7N3GmJnGmJmDBg06ms228vsHAI62SSilVBe6GyQk83cB8FtjzLp2846IiJSJiGT+n51Jy56jWefhbd/B7x+kJQmllOqCr5vLrRSRZ4AxwNdEpADo8gEDEXkImA8MFJEK4NuAH8AYcxdwMfBZEUkBMeAyY4w5or04Qto1h1JKda27QeJTwFRgizEmKiIDgKu7+oAx5mOHeP/nwM+7uf2s0K45lFKqa92tbnoP8JYxpk5ErgC+AdRnL1nHhnbNoZRSXetukPg/ICoiU4AvA5uB+7OWqmPEds2hQUIppTrT3SCRyrQXfBj4uTHmDqAge8k6Nvz+waTTDaTTsd5OilJK9UndDRINIvI17K2vfxYRh0wj9PGs7YG6nnn2Qiml+pvuBolFQBz7vMRuYDjwo6ylKhv+9CcYORK2bm2dpV1zKKVU17oVJDKB4QGgSEQuAJqNMcdXm4TfD9u3w86drbO0aw6llOpad7vluBT4F3AJcCnwiohcnM2E9biyMvt39+7WWVqSUEqprnX3OYmvA7OMMVUAIjIIeBZYnK2E9bjycvt3167WWdpduFJKda27bRJOS4DI2HMYn+0bBg4E192vJOG6ERwnoiUJpZTqRHdLEn8VkaeBhzKvFwFLspOkLHEcGDJkvyAB2jWHUkp1pVtBwhhzo4hcBMzNzLrbGPNE9pKVJWVl+1U3QUvXHBoklFKqI90tSWCMeQx4LItpyb6ysg5LEs3N7/ZSgpRSqm/rMkiISAPQUc+sAhhjTGFWUpUt5eXw2mv7zQoEhtDQsKKXEqSUUn1bl0HCGHPcd72xn7IyqKqCdNo2YmOrm5LJaozxsA+SK6WUapFbuWJ5uQ0QNTWtswKBwRiTIpWq68WEKaVU35RbQUIfqFNKqcOS80FCu+ZQSqnO5VaQ6OCpay1JKKVU53IrSHRYkhgCaNccSinVkdwKEnl5UFh4QEmiFHCJx3d2/jmllMpRuRUk4KAH6kRcwuETiEbf6sVEKaVU35TzQQIgEhlPNLqulxKklFJ9V+4FifLyg/pvysubQDS6Ec9L9FKilFKqb8q9INFJSQLSRKNv906alFKqj8rNINHQAE1NrbMikQkARKNv9laqlFKqT8q9INHyrES70kQ4fDLg0NSk7RJKKdVe7gWJlmcl2rVLuG6YcHisliSUUuoAuRckOihJgG28bmrSIKGUUu1lLUiIyL0iUiUiazt5X0TkdhHZJCJviMj0bKVlPx08dQ228ToWe1vvcFJKqXayWZL4DXBeF+9/EDgpM10L/F8W09Jm4EA7lsQBt8FGIhMwJkUstumYJEMppY4HWQsSxphlwN4uFvkwcL+xlgPFIlKerfS0chwYMqSD6qbxANp4rZRS7XR7jOssGAZsb/e6IjNv14ELisi12NIGI0eOPPotl5V18EDdqYBo47VSGZ4Hzc0Qj4OIvb5yXfD77SRy8GeSSXt3eTLZttyByxsDsRg0NtrXrmunpibYs8dOIvZnWlZmu1xrmV9fb9PlefazwSCEQnZKJCAatZPn2fS2TK5r//p8bZ/x+WDfPqirs39DIcjPh0jEpr+x0abJGAgE7OeMseuPxewyLdsOhdr203Xb9q+x0aYrnT54Msbu54FTe8bY7SQSdpo9G846K3vnvCO9GSS6zRhzN3A3wMyZMzsac/vwlJfDzv079HPdMKHQWC1JHIfS6bYfeyplf6g+n80UUin7fsvfdLotA2n5USYSNiNsbm77MSaTdl7Le8lk23paMiho+xG3vO/z2QwlELDzYjGbqaTTdvmWTKAlo0un7fpbttWyvUSiLX2O05aeeNy+DoftBPaxn4YGu5322zCmbUql2tKZSLRl/p5n09xyvDxv/+W74rptn3OctuPWERGbyfr9+x8PdXj+4z9yK0jsAEa0ez08My/7yspg1aqDZkcieodTdxljr5JqauzfVKotI26fMbVk3i1XjS1XdalUW4bY0AC1tXa5lgykJTNv0bqueo/6aIxkLEQq4bZe8fUIXzP4o+AmwEmC54d4ISTDQAeXzfsfEfs544Dn22/5lqDlkYLwHowvhpuO4KQjOF6YUFAIBtuuVgMB8AdTGEmRNmmM8XCCMXzhJtzCJlJpH3VNA6jZUQKen/wCw6CyJMFInJTTQNLZR0qaEBEccRBcHF8Kx59A3CRuIIEvkMQJJPBLiGB6IMHUIAKpUgJOuDXTbwlEPn+amKmnKV1HU7oef7qIYLIckmFSaUPMq6OBXeAmKApHKMqLEAr4iCZjRJNREsk0vuQAnOaBeMkAgUgME9lNOlSJ3/Hj8wrxewVE8oRIUZyC4gSeB/V7QtTVhElEA5SWOgwc4FJS5OL3O7jiICI0xZI0xJppiMWJBMOURPLIyxN7vL32wdjQlGqkMd6ESYZIx0NIOkhRkVBcDAUF0Nxs2NsQY29DlPxgmAEFeeTnC47TFribUvtodHawz1TQbBqIyCAiDCaQLqE5kaQpEaM5GScv7FCY7yM/4iMUcPH7XAI+1x5b1+A4xgZzI4AgODj47PFwAoR8wdbvT8tFh99vcP1pjnW23ZtB4kngcyLyMHAaUG+MOaiqKSvKyqCy0uZErts6OxIZz969f8HzkjiO/5gk5UikvTQNiQZ8jg+f4yPtpalqqmJ3425qojWZjMXgGY9EOkE8HaexOU51Qy1VTVVUR6sImEKGO7MpaZpNonYIWxvWUxF/k6r0RpqoIuZU0Sx78RIhvFg+yWg+Ju0HzwXPJZlw8VL2f9wkBPfZyRdrS6gYkDQ4acBAKgyJCCTz7HtO0masYvD5wB8EN+zgmCCOF0Qcj1RgD6nAHtL+vXiBOlLuPvtZwG8iBEwhxRLE5/rwOz4ibjFF7lCKZBhpk6Yq/RaVqbeoS+9CEEQcXHzku6UUuAOJuCU0ejXsTVbQkO64Cc0Vl6AbQjKX6I4IrthjLyLEklGiqSieaYtqASdAwA0Q9AUJuAFiqRh1zQePoy4IaX8Yzxcm7QbYm4rRlGgi6R3iMj7D5/hIealufnM6WwmQyZOCbpDiUDF5/jyiySgNiQaisejBnxEoLCgknooTT8fb5hugKTO15wIRCPvCxFIxSGCn9hqBzoZ1qc5M+yVBMOxfseB3/BSHign7w7ji4jousWSMmmjN/ulsSZa4+Bxf63Lt19eyLkccosko0WSUtDk2RaCQL8SA8ACKgkXEUjHqm+vZF9/HV+d+le+f/f1jkoYWWQsSIvIQMB8YKCIVwLcBP4Ax5i5gCbAA2AREgauzlZaDlJfby4uaGtuInZGXNwFjksRim4hExvXoJhPpBHuie1qv7vyOn8JgIa7jYoxhQ80Gnn/neZZXLKcp2UTaS5M2aVxx8bt+Am6AvbG9bNq7ia21W7udiRyckAg0DYbwHgi1u6HMBfKAVBA3VoYvNhhfsgQ3GMcpqiQwcBNICk/SGNL4JI04aXA8fI6PiFtEnltIwA3hZK6iRSDg9xPwhfD5hOZ0jGhyB7FUFBEh6Abwu358Pqf1ujtt0q0ZjyCU5pVSGh7KgPBEikPFFAWLyA/kE0vFaIg3sC++j4SXIOWlSKaT7I3tZWfDejY2PIsjDicPPJmZpWcxvHA4guAZj6SXZE9sD9VN1dQ21zI2PIrhhXMZWjCUgkABgUy6kukk++L72BffR3OqufVQecYjbdKkvBSe8cjz5xHxRwj7w3b96SSJdKI1QMdTcYK+IIPyBjEoMoiQL0Q0GaUx0UhToolYKkYsGSOejhP2hYkEIuT58/A7flzHxRGndX7EHyHlpdgb28ve2F5iqRh+x98akAoCBRQGC4kEIvZ4emk8Y8+R3/W3Ltvyf3OqmZpoTetU11xHbXMt0WSUiD9CQbCA/EA+xaFiSkIlFAYLqWuuY1fjLnY37ibkC1GWX0Z5fjkhX4imZFNrkMvz55Hnz8MVt/V418frKQ2XUpZfxpD8IaS8VOsxBux+uDZiNaeaaU41E0/H7THP/CZa/veMR9AXJOQLEXSDRJPR1vQ3p5pblw269tgPzBtIfiCfeDreuu6Ul2qd2h/7WDLWui6APH8eYV+Y4lAxwwqHMbxwOAWBAmqiNVQ1VVHbXEvQzaTFF8QYY7+TXrI13WkvnfldCJL5xhtM6wVdSzri6Th1zXXsje2lrrmOPH8eRcEiikJFzB89/8h+90cha0HCGPOxQ7xvgOuytf0utX/qul2QsB392TucDjdIGGNYW7WWpzc/TU20pvWLXNFQwdqqtby95+0Or/gKg4U44rReZQ6JDGFAuJRUwiXe7BBPpkmkbKYjiULc+skEqz9KqmowhjQ4dp1ObAj++BACqUHkh33k5zvkR4SBAwKUlQYpGxSkNL+IPF8E14VIvgelb7Hb9wqpwB6mDB3HxCHjGVk0Ekdy7xlLpVTHjouG6x7X6VPXh3eHU3Oqmee2Psef3v4Tf9r4J96tfxewV0OOOLjiMjgymElDJnHhKRcyvHA4YK8eGqJxNlXUs3V3LTW1cU7eMxN5Zz57N5/A25tlv4a9ggIYWgaDBtmptBSGTYKJE+100km23vvwOMC4zKSUUh3LzSDRchvtpv0fnHPdPEKhMTQ2vtHhx3Y37mb17tWs3r2a5RXLeXbLszQlm8jz5/H+se/nm/O+yYKTFjC0YOh+n0smYfVqWL4cXn0VVqyADRts4y7Y2+eGDrWxa/IkuPQSmJQJAqNH21vylFKqN+RmkBg2DEpKYM2ag94qKjqdvXufxhiDiFDdVM2Dax7k/jfuZ9WutjtbZmGBAAAenUlEQVSixpaM5copV/Khkz/EWWPOIuQLtb7X1GQDwgsvwIsv2v9beiYvK4NZs2DRIpg82QaDsWPt3SRKKdXX5GaQELE59BsHlxiKi99HZeXveGvX3/mvV+7nobUPkfJSTC+fzg/P+SGzh81mStkUikPFrZ8xxq7qqafgz3+2pYVUqm0zV18NZ5wBp59u41NHDyEppVRflJtBAmzufe+9bU9WZfgjp3HvVnj0xQWAw+dmfY5PTf8UEwdPPGgVDQ1wzz3ws5/B1q123syZcOONbUGhqOgY7Y9SSmVBbgeJpiabu59wAgBrq9ay8KGFbK2DDw4fzP9d9BKjikcd9NHaWrjtNrjzTvsA2Lx5cPPNcP75bW3iSinVH+R2kABbT3TCCSzZuITLFl9GJBDhd++7gJG8wMii4ft9xPPgvvvgq1+1j1h89KO21HDaab2QfqWUOgZyN0hMmGAbB954g9uHbudLT3+JKUOm8OTHnsQfe5H16/9EQ8NrFBbOBGD9evjkJ20j9OmnwzPPwNSpvbwPSimVZbkbJCIROPFEVmx8ni/yHAtPWciDH32QSCBCImR70Kqr+zuFhTP5/e9t43M4DL/5DXz843o3klIqN+R0VmcmT+IrhS8zKG8Qv/3Ib1u7MggEhpCXN4Hq6qV85Stw6aW2dur11+ETn9AAoZTKHblbkgD+NCnE8zTz8znfpzBYuN97BQXncM015/DSS3DddfDjH9ueGJVSKpfk7DVxykvxH8HnObkGrvXt3/JsDHzve1/ipZcu4Ac/2MTPf64BQimVm3I2SPxq1a/YEN/BD54F/9r9+2r6xjfgwQdHceWV3+HSSx/opRQqpVTvy8kg0ZRo4ttLv817R7yXD1dE9nvy+o474L/+C669Fj73uSeprX22F1OqlFK9KyeDxDObn6GyqZJb5t+CTGrrnmPLFvjyl+1DcXfcAQMHXkB9/Us0N7/byylWSqnekZNBYsnGJRQFi5g3al5bH07G8OUv22Emf/EL+7es7BOAYffu+3o7yUop1StyLkgYY1iyaQnnnnAuftdvg0RdHX97sJo//AG+/nXbCR9AODyG4uL3sXv3bzDthqZUSqlckXNB4o3KN9jZsJMFJy2wM6ZMIYmPL34tzAknwJe+tP/yZWVX09y8hbq6Zcc+sUop1ctyLkgs2bgEgPNOPM/OmDiRO/l/rN9ewI9/bAcAam/QoI/iuoXs3v3rY5xSpZTqfbkXJDYtYUb5DMry7TjXzcEibnG/y7mFL/OhDx28vOvmMXjwZVRXLyaV2neMU6uUUr0rp4JEbayWf27/Z1tVE/C3v0FdupAb9t2CvLOtw8+Vl38Sz4tSVfXoMUqpUkr1DTkVJJ7Z/Aye8fYLEo8/DkUFac7iOXjssQ4/V1Awm7y8cezefe+xSqpSSvUJORUklmxaQmm4lFlDZwF2iNEnn4QLFroEpk+C3/++w8+JCOXln2bfvpepr19+LJOslFK9KmeChGc8/rLxL5x34nm4jgvAsmWwd68dPIiLL4ZXXoF3O35wrrz8Wvz+QWzb9u1jmGqllOpdORMkVu5cSXW0er+qpieesGNEfOAD2CABtv6pAz5fPiNHfpXa2meoq3vxGKRYKaV6X84Eib2xvZw68FTOPeFcwA5F+sQTNkBEIsBJJ8GUKbB4cafrGDr0s/j9Q7Q0oZTKGTkTJD5w4gdYf916BuYNBGDFCtixI1PV1OLii+Gll+wbHXDdPEaN+hp1df+gtnZp9hOtlFK9LKtBQkTOE5G3RGSTiNzUwftXiUi1iKzOTJ/OZnrae/xx2z/TBRe0m3mIKiewbROBwFC2bfs2xpjsJlIppXpZ1oKEiLjAHcAHgfHAx0RkfAeLPmKMmZqZ7slWetozxsaBs86CkpJ2b5x6qu3L6c477a1PHXDdMKNG3Ux9/TKqqh46FslVSqlek82SxGxgkzFmizEmATwMfDiL2+u2jRvtdOGFHbz5ne/Ahg3wy192+vny8n+nsHAub7/970Sjb2cvoUop1cuyGSSGAdvbva7IzDvQRSLyhogsFpERWUxPqxUr7N/3vreDNxcuhDPPhG99C+rrO/y84/gYP/4hRAK8+eYi0unm7CVWKaV6UW83XD8FjDbGTAb+BnQ4cIOIXCsiK0RkRXV19VFvdNUqCAZh3LgONwY//jHs2WOHqOtEKDSCcePup7FxNZs3f/mo06SUUn1RNoPEDqB9yWB4Zl4rY8weY0w88/IeYEZHKzLG3G2MmWmMmTlo0KCjTthrr8GkSeD3d7LA9Olw5ZXw05/C1q2drqe09HxGjPgKO3feSWXlg0edLqWU6muyGSReBU4SkTEiEgAuA55sv4CIlLd7uRBYn8X0ALbR+rXXbBzo0ve/D64LN97Y5WJjxvwXRUXz2LDhk+zb90rPJVQppfqArAUJY0wK+BzwNDbzf9QYs05EviMiCzOLfUFE1onI68AXgKuylZ4W77wDtbUwbdohFhw2DL7xDdvp332dD1/qOH4mTHiMYHAYa9Z8WMfDVkr1K3K83es/c+ZMs6Kl5fkIPPGEfYDulVdg9uxDLJxOw9lnw6uv2oaMU07pdNGmpjdZteo9hEJjmDbtRXy+/CNOo1JK9TQRWWmMmXm4n+vthutjbtUqW4s0aVI3FnZdeOAB28HTokXQ3PldTJHIeMaPf4SmpjW8/vpZxGLbeizNSinVW3IuSLz2mr2rKRzu5geGDbPVTa+/bgfA7qLkVVp6HhMnPk40upGVK6dRU/NUzyRaKaV6Sc4FiVWrutEecaDzz4cvfxnuugsWLOi0byeAgQM/zMyZKwmFxrJ27UK2bLkZY7yjS7RSSvWSnAoSlZWwa9cRBAmAH/4Qfv5zeP55W1f14IOdlirC4ROYNu0lysuv4d13/5t16y4hnW46usQrpVQvyKkg8dpr9u8hb3/tiOPAddfB6tW2Afvyy+Gcc+CNNzpc3HVDnHzyLzjxxJ9SU/MHXnvtTOLxnUeeeKWU6gU5FSRWrbJ/p049ipWcfDK88AL87Gc2YEybBv/+71BXd9CiIsLw4V9k0qQnicXe4tVXJ7N9+0/xvHgHK1ZKqb4np4LEa6/BCSdAUdFRrsjng899zvYS+PnPw69+BXPn2ocwOlBaej7Tp79CQcF0Nm/+Ev/616lUVj6gbRVKqT4vp4LEETVad2XAANt1x9/+ZhuzTzutrffAA0Qi45ky5RkmT34Gn6+E9euvYMWKqdTUPKXjUiil+qycCRJ1dbBlyxG2RxzKWWfByy/b+2rnzYNbb+30DqgBA97PjBkrGDfuITwvxtq1C1m16j3s2vVrUqmOe51VSqnekjNBYvVq+7dHSxLtjRsHy5fbaqevfQ1GjID3vx8eeggSif0WFXEYMuQyZs16k5NP/iWp1B7eeuuTvPTSENauvYj6+n9mKZFKKXV4ciZIJJO2FJG1IAEwZIitenr7bfjmN2HzZvi3f4ORI+Hb37av21UtOY6foUM/zezZbzN9+r8YOvQz1Ne/wGuvzWXNmg/R2NjxnVNKKXWs5FzfTceU58Ezz9g7of7yFxsg8vNhwgQYNQqamqChwc7/7Gdh0SLSJkZFxe28++4PSKf3UVw8nwEDzmPAgA8QiUxGRHp7r5RSx6Ej7btJg8SxsnkzPPssrFsHa9dCRQUUFNipstIOmTptmu2ifMAAUm+/wb41D1M9aiu7xm8FgVBoDOXln6Ks7CqCwY4G+VNKqY5pkDieeZ59gvsb3+jwNlpvygTqrzmdd2a/TV3T84BDaekChg79LAMGfAAR99inWalc09gI8TiUlmZ3O55n84E337QXj5WVUFNjp498BK6++ohWe6RBwndEW1M9y3Hgiivgkkvgj3+0d0mNHQtDh8ITT+D86EeUfO6XlEQipKfPpuFUh8oRL7B5xJ/YdOIoBg+7klBoDIHAYAKBcvLyxuO6od7eq8NXV2cbj3pg9ME+o7HRdjVfWgqTJ/d2anpPLGbv+rvjDvjMZ+wFUegwvqOJhB3b5bnn7G9j4kR7s0h+vh1i0nXh3Xfhrbdsxrplix1VcutWKCyEiy+2PTm3dPff3Gwz3cpK2L3bfvemT4dTT7VDGLdnDNx/P3zlK3bc+6uugptvhtGj7Xtbt8K2bTBlyv4BpOW9DRtsO+XGjVBWBpde2vGwAzU19hj94hf2e9MiGLS/iYEDIRrt/jHrIVqSOB54nm3TePppOxDG6tWtd0x5PiE23BAdCU2jIDYUTMglGB5FOHwS+elR5MUG4auN24cAi4rslErZH0hVFQQC9k6s973PVn8da01N8D//Az/6kb1Su/pqe4dYy49w2zY7nXCCvWuss3aZqio7NnkyafevqAjGjLFB+EDGQHW1Xe+pp9qM5HA1Ntpbn2fMsM/MtHjjDfjNb2DpUtt7sJd5aHLyZPjEJ2yHkYMGQXGxzXSefBIWL7bBZN48m6EtWGAzwI7SXVEB//qXnXbvhpISO+Xn2/1OJOxYKIMG2UyprMzuX16evQCpqLBVnmvX2vWdeqqdSkvbMs3qati7107RqE376afb7go2bbKZ9Qsv2Js1LrgAzjzTnscHHoB77rFXwh/4AHzoQxCJ2A4yt2yBmTPts0QnnWQzw+HD7TFas8ZuJxy2wSMvz+5Pfj6sX2+Xray038+GhkOfm6FD7bkfPdoGjxdftPtaVgb79nWe2Q4bZn8Lp55qly0uts9CLV0Kc+bY/b/3XntOTzvNpm3v3rbPT5hg9/Hdd+2DWfXtbmsvKrLbNsYGlHPPhfJyu5233oIf/9gew8sug/nz7brGjbNp6IG2SK1uyiXxuC2KrlsH69Zh1q3BrF+HbHkX8Tp+itsLCOIJkmp73zgOMmiQzeyammwQOe00++U8+WSbIVdV2R/8jh32R3faaXa0pro6G7D+9S/7xR82zP4wR460nz3hBHsF1JnGRhvs/vlP+MlPbMZ00UUweLB9gt3z7HbWr7dDCbaIROxV2ODBNmMsLLRXa6+/bjORA+Xltd0okEzaY7dvn726a/lxO47N6OfPt+nPz7fb2b27LTMNhWxp7+KLbVC9+2743vfs8XFdOOMMm8H/9a/2mAQC9vXpp9vMZcsW2+X8q6+2pa0leHme3e7pp9vMt7LSfr68vC2ox2L2SrO62p4rsFfQZWX2XHQn4zxQOGwzn84yTBF7jP3+tmPrOG1Bb9gwG5Sbm23mnUjY4ztjhj3mf/2rPT5gz9mdd9oLkWeftV3ZbNmy/7EIBu1+dpSOBQtsLwfnnmv3dd06m7HGYva8JpM24Jxyiv3+RSL7r2PHDvj9720ALymxAbG01B6/IUPs8i+/bNP2j3/Y/WpRVAQ/+AFcc41N544d9vXy5TZ4zpplfxsrVtjAuWqVDU4tt1NOnGjTVFoKO3fadDzyCKxcadPd4qMfhe9+F8aPP6zT2F0aJJT9gb77rv3ipdN4qQRN/grqfG9Qm/gn0aa3STZsx21MYhxwBo5gcPlllBacS/i1GgL/WIm8+E9bNK6paVtvMGh/TBUV9gq1vcJC+6PbuXP/L7zj2M94XtuVvd9vMz/Xtetq+e6dfrotRZx+un1dUWF73X31VfsjnD7d/gi3brVB46237I+4ttZmkMOH2yu8KVNsxurz2W3V1Ngr1DVr7A87ELD7kp9vr2THjbOZ8+rV9kpx+fL99wHsvk2aZLsP3rjRBp2SEru++fNttywrV9pqwnXr7A/8mmvg4x/vuO56/XqbmezZYyfHsVfiM2fazDCdhpdegj//2Qap+nq7j+FwW5XD2LE2WE+e3BaIUykbPAIBO4Hd/9277dTYaINBNGrPy8SJNiMTscd7wwa7nSFD7DR4sL2CbQlkO3bYTHTVKnsBcNZZ9pzEYvD3v9v0BoO2KqblPnPPs+dw61Zbl97+oiEahV//2h7PyZPtcQuH7XcikbD70tRk011YaAPSsdTY2FbSbsnge5ox9phXVtrv7Ikn9vw22tEgobrFGI9Eoora2mepqnqY2tqnscORW37/EILB4eTFhxDZW0x41GwiY84hL38cEmu2mcSKFfaHO2eOLZa3XF3W1Njqm40bbaCpqLABoSUwpFI2kCWTNqObMcNO5eW9d0Dai8dtptySQQ0YYNMmYn/Qy5fbjO3dd+GGG2y1RPtqgNraHqsaUKqnaZBQRySZ3MO+fa+SSOwgHq8gHq+guXl75u82PM9WbbhuPj5fCSI+RHzk5Z1CSck5lJScQ17eeH1+Q6k+Tu9uUkfE7y+ltPS8Dt8zJk00+hb79v2LxsaVpNONGJPC8+I0Nr7Gnj1/AsBxwgQCZQQCZfj9A3GcICJBXDdCMDiMYHAEweBw/P4B+HzFuG4RjhMAHEQcHCesQUapPkqDhOqUiEskMp5IZDxw1UHvNze/Q23tszQ1rSeR2E0isZt4vALPi+N5cdLpBpLJqkNux+8fSGHheygsPJ1w+ERE3MwUwO8vwecbgN9fminJaDBR6ljSIKGOWCg0ivLyT3W5jOfFicdtVVYqVUsqVU8qVYcxqcx4Gmmi0Q3U17/Mnj1PdbkukSDB4FCCwWH4/QPx+Urx+wcSDp9AJDKBSGQCjhMhnW4gnd4HuAQCZTiOfs2VOlL661FZ5ThBwuGxhMNjD7lsMrmHeHxHJnh4eF4zqVQtyWQtyWQ1icQu4vEdJBI7icU2k0y+QjJZgzHJLtbqEAiUEwgMQiSAiB8RH5DGmDTGeJn2liJ8viL8/lL8/kGZaQCua+e7bqT1s44TwucrxnH8PXWYlOqzNEioPsNm0Id3q6ExHs3N79DUtI5odB2el8B1C/D5CvG8RKZBfgfJZDWel8SYJMakEPHjOGFASKcbiUZ3k0rVkUrtwfOau7XtlsZ8n684E0gKMSZJOh3F82I4TgDXzcd1C3CcUGabgUyQsu0xtkptQGupKBAoIxgsx+8fklnXPlKpfbhuhEBgCK4bwRhDMllNc/O7GJMkL+/kwz5uSnWXBgl1XBNxCIfHEA6PAS446vUZY0inm0gmqzPVY3WkUvV4XjRTRZYinY5l3qslmdxLOl1PKlVPIrEbxwngOHn4fMUYkyCdbiSR2I3nNWeCVCJzy7HBGC8zv/tdLThOJJOO/cdJ9/lKCYVGZ0o3DiIujhPEcUIHTT5fcWtpyXULWtuA7MgBpvW4um5hJvgVZNKbypS+EnheItP2ZNPveTFEAgQCg/H7h+DzFbe2H3legmSyJnNM6wgGhxEKjcXnO/TT/alUPcnkXkKh0doe1Us0SCjVjojg8+Xj8+UDY47JNj0vTjK5N1Oltpt4fCfJZCUiQXy+Qly3IBNsKjPz/QSDIwmFRgAOsdjbRKNvEY9vb62qs8GsiWRyD54Xa72ZwPNimREQe398db9/ICI+PC+BMYlM+9LJ5OWdguc1U1//T6LRNwGDz1dCQcEs8vMn4zh5mdKYkErtIZGoIpmszgTAAZlqwnwcJ5wpwTmZfbdBO5msJpmswfOihMMnkpc3gXD4BJqbt9DY+DpNTWvx+weRnz+ZSGQKjhMkmawikajEmBR+/2ACgcG4biGQzgT/OMnknsy6a/H7SzJ3/JW33nTh85Vk0hVo7ZTT81J4XnPm4sHDBun2jyVIr1dt6nMSSuUYY9Kt7TzpdBO2fablRgJBRDAmRSq1L1Pd1ZCpGnMBN1NaCrZW2bluHo4TzgQ7m5m2H4pXxJepSrMZazxeQSy2mebmrYCHSBDH8ZNIVBKNvkUs9jYiPgoL51BYeDqBwGAaGlbS0PAqTU1vYkzbSI+um4/fPwS/f2Amo64lldpDOt144G63S4stRTlOiGj0LdLptrT6fAOIRCaSTNYQjb4FpDtcT1ccJ9SNKksHkG6v33WL8PsHMmzY/2PEiBsOO03QR5+TEJHzgP8FXOAeY8ytB7wfBO4HZgB7gEXGmG3ZTJNSuU7EJRAYSCAwsLeT0qGWC9fOqpfs+x7GpDPP23S8TEvJqS0QBTMPg8p+y9kbIbYQCo0mGBze+n463Uw0+ibGpAkEhuD3D0LEl6k6qyKV2tf6cKnjBDMlhlJcN0Q63UwyWUk8votUak8meNVmquZsqQZMu2rAtueGbPBoSV+aVKous80aAoGyHjjChydrQULsZccdwPuBCuBVEXnSGPNmu8U+BdQaY04UkcuAHwCLspUmpVTfd6i2B/u+S1fjqIgIrhs6ZJf5IpJ54PPgvqFcN0RBwfSD5geD5QSDXXclY7c9ilBoVJfLHQ+yOcb1bGCTMWaLseXDh4EPH7DMh4H7Mv8vBs4WbZ1SSqk+I5tBYhiwvd3risy8Dpcx9paPeuCge/lE5FoRWSEiK6qrq7OUXKWUUgfKZpDoMcaYu40xM40xMwf1p1HLlFKqj8tmkNgBjGj3enhmXofLiL2nrQjbgK2UUqoPyGaQeBU4SUTGiEgAuAx48oBlngQ+kfn/YuAf5ni7J1cppfqxrN3dZIxJicjngKext8Dea4xZJyLfAVYYY54EfgX8VkQ2AXuxgUQppVQfkdXnJIwxS4AlB8z7Vrv/m4FLspkGpZRSR+64aLhWSinVO467bjlEpBp45wg/PhCo6cHkHG9yef9zed8ht/df990aZYw57NtDj7sgcTREZMWR9F3SX+Ty/ufyvkNu77/u+9Htu1Y3KaWU6pQGCaWUUp3KtSBxd28noJfl8v7n8r5Dbu+/7vtRyKk2CaWUUocn10oSSimlDkPOBAkROU9E3hKRTSJyU2+nJ5tEZISIPCcib4rIOhH5Ymb+ABH5m4hszPwt6e20ZouIuCLymoj8KfN6jIi8kjn/j2S6iumXRKRYRBaLyAYRWS8i78mVcy8iX8p859eKyEMiEurP515E7hWRKhFZ225eh+darNszx+ENETl4sIwO5ESQaDcA0geB8cDHRGR876Yqq1LAl40x44E5wHWZ/b0J+Lsx5iTg75nX/dUXgfXtXv8A+Ikx5kSgFjvgVX/1v8BfjTGnAlOwx6Hfn3sRGQZ8AZhpjJmI7Q6oZTCz/nrufwOcd8C8zs71B4GTMtO1wP91ZwM5ESTo3gBI/YYxZpcxZlXm/wZsJjGM/Qd5ug+4sHdSmF0iMhw4H7gn81qA92EHtoL+ve9FwDxsv2gYYxLGmDpy5NxjuxoKZ3qVzgN20Y/PvTFmGbbfu/Y6O9cfBu431nKgWES6HmKP3AkS3RkAqV8SkdHANOAVYIgxZlfmrd3AkF5KVrb9FPgPwMu8LgXqMgNbQf8+/2OAauDXmeq2e0QkQg6ce2PMDuA24F1scKgHVpI7575FZ+f6iPLBXAkSOUlE8oHHgOuNMfvav5fpkr3f3domIhcAVcaYlb2dll7iA6YD/2eMmQY0cUDVUj8+9yXYq+UxwFAgwsFVMTmlJ851rgSJ7gyA1K+IiB8bIB4wxjyemV3ZUrzM/K3qrfRl0VxgoYhsw1Yrvg9bR1+cqYKA/n3+K4AKY8wrmdeLsUEjF879OcBWY0y1MSYJPI79PuTKuW/R2bk+onwwV4JEdwZA6jcydfC/AtYbY37c7q32gzx9AvjjsU5bthljvmaMGW6MGY09z/8wxlwOPIcd2Ar66b4DGGN2A9tF5JTMrLOBN8mBc4+tZpojInmZ30DLvufEuW+ns3P9JHBl5i6nOUB9u2qpTuXMw3QisgBbV90yANL3ezlJWSMi7wVeANbQVi9/M7Zd4lFgJLYn3UuNMQc2evUbIjIf+Iox5gIRGYstWQwAXgOuMMbEezN92SIiU7GN9gFgC3A19oKw3597EflPYBH2Dr/XgE9j69375bkXkYeA+djeXiuBbwN/oINznQmcP8dWwUWBq40xKw65jVwJEkoppQ5frlQ3KaWUOgIaJJRSSnVKg4RSSqlOaZBQSinVKQ0SSimlOqVBQqljSETmt/RMq9TxQIOEUkqpTmmQUKoDInKFiPxLRFaLyC8y41M0ishPMuMV/F1EBmWWnSoiyzN99D/Rrv/+E0XkWRF5XURWicgJmdXntxvv4YHMQ05K9UkaJJQ6gIiMwz61O9cYMxVIA5djO4xbYYyZADyPfboV4H7gq8aYydin3FvmPwDcYYyZApyO7ZkUbK+812PHNhmL7V9IqT7Jd+hFlMo5ZwMzgFczF/lhbCdpHvBIZpnfAY9nxm8oNsY8n5l/H/B7ESkAhhljngAwxjQDZNb3L2NMReb1amA08GL2d0upw6dBQqmDCXCfMeZr+80U+eYByx1pnzbt+w1Ko79D1YdpdZNSB/s7cLGIDIbWMYNHYX8vLb2J/hvwojGmHqgVkTMy8z8OPJ8ZEbBCRC7MrCMoInnHdC+U6gF6BaPUAYwxb4rIN4BnRMQBksB12AF8Zmfeq8K2W4DtjvmuTBBo6XUVbMD4hYh8J7OOS47hbijVI7QXWKW6SUQajTH5vZ0OpY4lrW5SSinVKS1JKKWU6pSWJJRSSnVKg4RSSqlOaZBQSinVKQ0SSimlOqVBQimlVKc0SCillOrU/wcpoZUZIF0wyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 322us/sample - loss: 0.2462 - acc: 0.9333\n",
      "Loss: 0.24619878661409716 Accuracy: 0.93333334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_{}_only_conv_DO_BN'.format(i)\n",
    "    model = build_2d_cnn_only_conv_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_2d_norm, y_train_onehot, batch_size=64, epochs=200, \n",
    "                     validation_data=[x_val_2d_norm, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print('{} Only Conv Model'.format(i))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2D_CNN_1_only_conv_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 253, 95, 8)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 253, 95, 8)        32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 48, 8)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 48768)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 48768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                780304    \n",
      "=================================================================\n",
      "Total params: 780,544\n",
      "Trainable params: 780,528\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 281us/sample - loss: 1.2750 - acc: 0.6598\n",
      "Loss: 1.2749793017764701 Accuracy: 0.6598131\n",
      "\n",
      "2D_CNN_2_only_conv_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 253, 95, 8)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 253, 95, 8)        32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 127, 48, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 123, 44, 16)       3216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 123, 44, 16)       64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 22, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21824)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 21824)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                349200    \n",
      "=================================================================\n",
      "Total params: 352,720\n",
      "Trainable params: 352,672\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 296us/sample - loss: 0.6045 - acc: 0.8390\n",
      "Loss: 0.6045244734111481 Accuracy: 0.83904463\n",
      "\n",
      "2D_CNN_3_only_conv_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 253, 95, 8)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 253, 95, 8)        32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 127, 48, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 123, 44, 16)       3216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 123, 44, 16)       64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 62, 22, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 58, 18, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 58, 18, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 29, 9, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8352)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8352)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                133648    \n",
      "=================================================================\n",
      "Total params: 150,128\n",
      "Trainable params: 150,016\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 330us/sample - loss: 0.3583 - acc: 0.9142\n",
      "Loss: 0.3582825439896044 Accuracy: 0.91422635\n",
      "\n",
      "2D_CNN_4_only_conv_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 253, 95, 8)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 253, 95, 8)        32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 127, 48, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 123, 44, 16)       3216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 123, 44, 16)       64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 62, 22, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 58, 18, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 58, 18, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 29, 9, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 25, 5, 64)         51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 25, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 3, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                39952     \n",
      "=================================================================\n",
      "Total params: 107,952\n",
      "Trainable params: 107,712\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 324us/sample - loss: 0.2462 - acc: 0.9333\n",
      "Loss: 0.24619878661409716 Accuracy: 0.93333334\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_{}_only_conv_DO_BN'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
