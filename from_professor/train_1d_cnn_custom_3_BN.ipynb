{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_BN(conv_num=1):\n",
    "    init_channel = 64\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=init_channel, strides=1, \n",
    "                      padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=int(init_channel*(2**int((i+1)/3))), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,480,656\n",
      "Trainable params: 18,432,528\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 6,847,696\n",
      "Trainable params: 6,164,816\n",
      "Non-trainable params: 682,880\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,316,816\n",
      "Trainable params: 2,088,976\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 75776)             303104    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,599,376\n",
      "Trainable params: 1,447,184\n",
      "Non-trainable params: 152,192\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 670,736\n",
      "Trainable params: 619,408\n",
      "Non-trainable params: 51,328\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 415,376\n",
      "Trainable params: 397,584\n",
      "Non-trainable params: 17,792\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 5376)              21504     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 521,616\n",
      "Trainable params: 509,200\n",
      "Non-trainable params: 12,416\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 1792)              7168      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 778,896\n",
      "Trainable params: 773,136\n",
      "Non-trainable params: 5,760\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,082,256\n",
      "Trainable params: 1,078,544\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8639 - acc: 0.4998\n",
      "Epoch 00001: val_loss improved from inf to 1.61969, saving model to model/checkpoint/1D_CNN_custom_3_BN_4_conv_checkpoint/001-1.6197.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 1.8642 - acc: 0.4997 - val_loss: 1.6197 - val_acc: 0.5229\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8715 - acc: 0.7499\n",
      "Epoch 00002: val_loss improved from 1.61969 to 1.36392, saving model to model/checkpoint/1D_CNN_custom_3_BN_4_conv_checkpoint/002-1.3639.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8715 - acc: 0.7498 - val_loss: 1.3639 - val_acc: 0.6410\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4380 - acc: 0.8737\n",
      "Epoch 00003: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4380 - acc: 0.8738 - val_loss: 1.4337 - val_acc: 0.6268\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2306 - acc: 0.9448\n",
      "Epoch 00004: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2306 - acc: 0.9448 - val_loss: 1.4250 - val_acc: 0.6487\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9677\n",
      "Epoch 00005: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1603 - acc: 0.9676 - val_loss: 1.7129 - val_acc: 0.6070\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9750\n",
      "Epoch 00006: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1255 - acc: 0.9750 - val_loss: 1.5000 - val_acc: 0.6539\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9820\n",
      "Epoch 00007: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0951 - acc: 0.9820 - val_loss: 1.8393 - val_acc: 0.6080\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9833\n",
      "Epoch 00008: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0912 - acc: 0.9833 - val_loss: 1.6017 - val_acc: 0.6508\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9857\n",
      "Epoch 00009: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0780 - acc: 0.9856 - val_loss: 1.9125 - val_acc: 0.6014\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9772\n",
      "Epoch 00010: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0972 - acc: 0.9772 - val_loss: 1.8013 - val_acc: 0.6357\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9848\n",
      "Epoch 00011: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0755 - acc: 0.9848 - val_loss: 1.8231 - val_acc: 0.6441\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9860\n",
      "Epoch 00012: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0695 - acc: 0.9859 - val_loss: 2.1587 - val_acc: 0.5868\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9805\n",
      "Epoch 00013: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0826 - acc: 0.9805 - val_loss: 1.9183 - val_acc: 0.6459\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9848\n",
      "Epoch 00014: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0711 - acc: 0.9848 - val_loss: 2.0637 - val_acc: 0.6215\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9882\n",
      "Epoch 00015: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0593 - acc: 0.9882 - val_loss: 2.1046 - val_acc: 0.6308\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9895\n",
      "Epoch 00016: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0557 - acc: 0.9894 - val_loss: 2.1710 - val_acc: 0.6154\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9842\n",
      "Epoch 00017: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0706 - acc: 0.9842 - val_loss: 2.5433 - val_acc: 0.5770\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9899\n",
      "Epoch 00018: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0493 - acc: 0.9899 - val_loss: 2.5106 - val_acc: 0.5996\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9881\n",
      "Epoch 00019: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0554 - acc: 0.9881 - val_loss: 2.2481 - val_acc: 0.6261\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9885\n",
      "Epoch 00020: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0549 - acc: 0.9884 - val_loss: 2.4570 - val_acc: 0.6145\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9823\n",
      "Epoch 00021: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0738 - acc: 0.9822 - val_loss: 2.2268 - val_acc: 0.6392\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9898\n",
      "Epoch 00022: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0507 - acc: 0.9898 - val_loss: 2.4052 - val_acc: 0.6229\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9928\n",
      "Epoch 00023: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0421 - acc: 0.9928 - val_loss: 2.2583 - val_acc: 0.6427\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9907\n",
      "Epoch 00024: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0490 - acc: 0.9907 - val_loss: 2.3197 - val_acc: 0.6355\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9931\n",
      "Epoch 00025: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0390 - acc: 0.9930 - val_loss: 2.8096 - val_acc: 0.5954\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9876\n",
      "Epoch 00026: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0563 - acc: 0.9876 - val_loss: 2.3789 - val_acc: 0.6380\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9920\n",
      "Epoch 00027: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0433 - acc: 0.9919 - val_loss: 2.9019 - val_acc: 0.5905\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9846\n",
      "Epoch 00028: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0710 - acc: 0.9846 - val_loss: 2.5720 - val_acc: 0.6266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9888\n",
      "Epoch 00029: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0522 - acc: 0.9888 - val_loss: 2.5319 - val_acc: 0.6252\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9957\n",
      "Epoch 00030: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0289 - acc: 0.9957 - val_loss: 2.4202 - val_acc: 0.6508\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9939\n",
      "Epoch 00031: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0371 - acc: 0.9939 - val_loss: 2.9780 - val_acc: 0.5819\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9926\n",
      "Epoch 00032: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0385 - acc: 0.9926 - val_loss: 2.6622 - val_acc: 0.6259\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9894\n",
      "Epoch 00033: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0503 - acc: 0.9894 - val_loss: 2.4506 - val_acc: 0.6518\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9930\n",
      "Epoch 00034: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0358 - acc: 0.9930 - val_loss: 2.7748 - val_acc: 0.6196\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9931\n",
      "Epoch 00035: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0377 - acc: 0.9931 - val_loss: 2.7726 - val_acc: 0.6180\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9884\n",
      "Epoch 00036: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0517 - acc: 0.9884 - val_loss: 2.8587 - val_acc: 0.6212\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9914\n",
      "Epoch 00037: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0447 - acc: 0.9913 - val_loss: 2.7378 - val_acc: 0.6287\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9866\n",
      "Epoch 00038: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0609 - acc: 0.9865 - val_loss: 2.4904 - val_acc: 0.6518\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9909\n",
      "Epoch 00039: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0449 - acc: 0.9909 - val_loss: 2.8245 - val_acc: 0.6224\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9936\n",
      "Epoch 00040: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0371 - acc: 0.9935 - val_loss: 2.7848 - val_acc: 0.6292\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9921\n",
      "Epoch 00041: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0424 - acc: 0.9921 - val_loss: 2.7667 - val_acc: 0.6348\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9951\n",
      "Epoch 00042: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0310 - acc: 0.9950 - val_loss: 2.7930 - val_acc: 0.6392\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9910\n",
      "Epoch 00043: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0444 - acc: 0.9910 - val_loss: 2.8328 - val_acc: 0.6273\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9933\n",
      "Epoch 00044: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0346 - acc: 0.9933 - val_loss: 2.7776 - val_acc: 0.6341\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9940\n",
      "Epoch 00045: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0329 - acc: 0.9940 - val_loss: 2.8932 - val_acc: 0.6324\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9905\n",
      "Epoch 00046: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0481 - acc: 0.9904 - val_loss: 2.8018 - val_acc: 0.6331\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9924\n",
      "Epoch 00047: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0407 - acc: 0.9924 - val_loss: 2.6384 - val_acc: 0.6464\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9937\n",
      "Epoch 00048: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0339 - acc: 0.9937 - val_loss: 3.0270 - val_acc: 0.6264\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9892\n",
      "Epoch 00049: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0510 - acc: 0.9892 - val_loss: 2.7300 - val_acc: 0.6462\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9911\n",
      "Epoch 00050: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0424 - acc: 0.9911 - val_loss: 2.6389 - val_acc: 0.6569\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9961\n",
      "Epoch 00051: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0265 - acc: 0.9961 - val_loss: 2.8245 - val_acc: 0.6399\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9958\n",
      "Epoch 00052: val_loss did not improve from 1.36392\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0285 - acc: 0.9958 - val_loss: 2.8384 - val_acc: 0.6406\n",
      "\n",
      "1D_CNN_custom_3_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd4lFX2x793WuqkNyABAiKQRqgG6b24YkEExcqKa11dFBdd18XeWFexrD9csWABBbHRDAoGlFCEAKGXBAgQMuk9mXJ/f5xMMklmkkkyk0mY83me+7zvvHPfe8+8M3PPveeee66QUoJhGIZhAEDhagEYhmGYjgMrBYZhGKYWVgoMwzBMLawUGIZhmFpYKTAMwzC1sFJgGIZhamGlwDAMw9TCSoFhGIaphZUCwzAMU4vK1QK0lJCQENmzZ09Xi8EwDNOp+OOPP3KllKHN5et0SqFnz57Ys2ePq8VgGIbpVAghztiTj81HDMMwTC2sFBiGYZhaWCkwDMMwtXS6OQVr6PV6ZGVlobKy0tWidFo8PT0RGRkJtVrtalEYhnEhl4VSyMrKglarRc+ePSGEcLU4nQ4pJfLy8pCVlYXo6GhXi8MwjAu5LMxHlZWVCA4OZoXQSoQQCA4O5pEWwzDOUwpCCE8hxC4hxH4hxCEhxLNW8ngIIVYJIU4KIXYKIXq2ob62iOv28PNjGAZw7kihCsB4KeUAAIkApgohkhrk+TOAAinlFQD+A+BVJ8rDMAzjPH7+GThwwNVStBmnKQVJlNa8VNekhhtCXwfgk5rz1QAmiE7YZS0sLMR7773XqnunT5+OwsJCu/MvXrwYS5YsaVVdDMM4CSmBOXOAv/zF1ZK0GafOKQghlEKINAA5AJKllDsbZOkG4BwASCkNAIoABDtTJmfQlFIwGAxN3rt+/XoEBAQ4QyyGYdqLY8eA3Fxg507g0iVXS9MmnKoUpJRGKWUigEgAw4QQca0pRwhxrxBijxBij06nc6yQDmDRokU4deoUEhMTsXDhQmzduhWjRo3CjBkzEBMTAwC4/vrrMXjwYMTGxmLZsmW19/bs2RO5ubnIzMxE//79MX/+fMTGxmLy5MmoqKhost60tDQkJSUhISEBN9xwAwoKCgAAS5cuRUxMDBISEjBnzhwAwK+//orExEQkJiZi4MCBKCkpcdLTYJyOlMDhw66WgrHkt9/oKCWwbp1rZWkj7eKSKqUsFEJsATAVQLrFW+cBRAHIEkKoAPgDyLNy/zIAywBgyJAhDU1Q9Thx4lGUlqY5SnQAgK9vIvr0edPm+6+88grS09ORlkb1bt26FXv37kV6enqti+fy5csRFBSEiooKDB06FDNnzkRwcP1B0YkTJ/Dll1/igw8+wM0334w1a9bgtttus1nvHXfcgbfffhtjxozBM888g2effRZvvvkmXnnlFWRkZMDDw6PWNLVkyRK8++67GDFiBEpLS+Hp6dnWx8K4ip9+AqZOBX7/HRg+3NXSMACwfTsQHAx4ewPffw/Mm+dqiVqNM72PQoUQATXnXgAmATjaINv3AO6sOb8JwC9SyiYb/c7CsGHD6vn8L126FAMGDEBSUhLOnTuHEydONLonOjoaiYmJAIDBgwcjMzPTZvlFRUUoLCzEmDFjAAB33nknUlJSAAAJCQmYO3cuPvvsM6hUpPdHjBiBBQsWYOnSpSgsLKy9znRC9u6l4/ffu1YOpo7t24GRI4EZM0hpNzPK78g4s2XoAuATIYQSpHy+klL+KIR4DsAeKeX3AD4EsEIIcRJAPoA5ba20qR59e+Lj41N7vnXrVmzevBk7duyAt7c3xo4da3VNgIeHR+25Uqls1nxki3Xr1iElJQU//PADXnzxRRw8eBCLFi3CNddcg/Xr12PEiBHYtGkT+vXr16ryGRdjNh2tXw+8/LJrZWFoDuHkSZpkTkgA3n2XPJH+9CdXS9YqnKYUpJQHAAy0cv0Zi/NKALOcJUN7odVqm7TRFxUVITAwEN7e3jh69ChSU1PbXKe/vz8CAwOxbds2jBo1CitWrMCYMWNgMplw7tw5jBs3DiNHjsTKlStRWlqKvLw8xMfHIz4+Hrt378bRo0dZKXRWzErhwAHg/HmgWzfXyuPumOcTRowABg0CtFoaxXVSpXBZrGh2NcHBwRgxYgTi4uKwcOHCRu9PnToVBoMB/fv3x6JFi5CU1HC5Ruv45JNPsHDhQiQkJCAtLQ3PPPMMjEYjbrvtNsTHx2PgwIH461//ioCAALz55puIi4tDQkIC1Go1pk2b5hAZGBscO0aTjo7GZAKOHgUmTqTXGzY4vg6mZWzfDnh6kkLw8KD5nh9+oO+qEyI6mwl/yJAhsuEmO0eOHEH//v1dJNHlAz9HB3H0KNC/P/Dll+S77kgyM4HoaOD994EXXgCGDQPWrHFsHe7Ghx8ClZXAgw+27v5hwwAvL+DXX+n1Z58Bt99O7qnDhjlOzjYihPhDSjmkuXw8UmAYR/PHH3T88UfHl33kCB1jYoDp04HkZKC62vH1uAs//ADccw/w0EPAs40i8TRPWRmwbx+ZjsxMnw4olZ3WEYCVAsM4moMH6Zic7HgTgnk+ISYGmDYNKCkh19T2QKcDNm5sn7rag5MnqUc/eDBw553A4sXAc8+1rIxduwCDgTyPzAQFAaNGAd9951Bx2wtWCgzjaNJrluLk5Dg+Fs6RI0BYGPnET5gAqNXkheRszpyhNRHTppF5pLNTVgbceCP16NesIRPSHXcA//oX8OKL9pezfTsgROP1IjNm0O/g9GnHyVxSAuTnO648G7BSYBhHk54OjB1L55s2Obbsw4dpvgIgL5dRo5w/2Xz8ONWTl0eTqffdR/MmrcVgAFoQ76tFnDsHPPUU8OSTQM0K/0ZICdx7L31PX34J9OhBymH5cuC224Cnn7bf1fe334C4OCAwsP71GTPo+MMPLf8MeXk0InvzTeD++4Hx44GuXQE/P+CNN1peXkuRUnaqNHjwYNmQw4cPN7rGtBx+jk2g00lpMjWfr6hISkDKF1+UMj5eyvHjHSeDySSlv7+U999fd23JEqrv7FnH1WPJgQNShodLGRoqZVqalFlZUoaESBkXJ2VZWevK/Mc/pFQqpZw1S8rffrPvuTZHaqqUs2dTuQoFpbAwKT/9tHH5b71V9x01xGCQ8tZb6f1XXmm6ToNBSq1Wyvvus/5+TEzLv/+iIikjIqh+QMrAQCmTkqS8804pX36ZPmcrAa0Pa7aNdXkj39LESsF58HO0QXa2lJ6eUn7+efN5f/+d/lbffSflY49JqdFIWVrqGDkuXKCyly6tu3boEF37v/9zTB2W7N4tZVCQlF27SnnkSN31jRupznvuaV25sbFSRkZKGRBA5QwbJuUXX0hZXd2ycvR6Kb/6Ssrhw6kcf38pH39cysxMKffulfKqq+j6mDH0nKSUcts2KVUqKWfMkNJotF3uLbfQvW+/bbv+ffsoz2efWX9/0SJSUvn59n+ml16iMr/6SsqcHMcozBpYKXRwfHx8WnS9PeiMz7FdWLeO/ip//nPzeZcto7ynT0v50090vn69Y+TYvJnK27y57prJJGX37lJef71j6jCTkkK94OhoKU+davz+U0813SDa4vx5uu+110hZvvuulFdeSde6daNRxPffUz5rXLok5Sef0KjArFR69yZFWVxcP6/RSN9HYCApggULqBfep4+UhYVNy6nXS3nNNVJ6edHoyBpvv031Z2Zaf9/cQfjii6brMlNaSqOwqVPty99CWCl0cFgpdCJefJH+KvHxzed9+GEpfXyoQSovpxHGI484Rg5zI3ThQv3r990npa+vlFVVLStv2zZq9KOjpezXT8qEBCmHDpVyxAhqDPv2lfLcOev36vVSjhpFn/XoUfvr/Phj+gxpaXXXjEZSvBMnSimErDWdRERQw/zMM1L+6180ojC/Hx4u5d13S/nDD2TGaYqcHCnnzaP7vL2lPHjQPllPn6aR3rx51t+fM4cUma3evMFAJqw5c+yrz2wK/O03+/K3EHuVAk80O4BFixbh3XffrX1t3gintLQUEyZMwKBBgxAfH4/vWuCiJqXEwoULERcXh/j4eKxatQoAcPHiRYwePRqJiYmIi4vDtm3bYDQacdddd9Xm/c9//uPwz+jW7N9Px0OHyGulKdLTgdhYQKGgBU2jR1OANEdw+DDg7w9ERNS/Pm0aUFpKnjAt4dNPyUNq5EiK2dOrFxASQqtzr70WSEkBIiOt36tSAV98QZ9x1iz7A8AlJ5P3VHx83TWFom7NRXExsG0bTbJOmgRkZNAiveeeo3zPPkvrQC5coInhP/2JJombIjSUvIt276YFZnF2RvCPjgYefhj46KPGXmRSkpwjR5L3kTWUSpJvw4bm15JUVABLltCk8tVX2yefs7BHc3Sk1OxI4ZFHyIboyNRMT2/v3r1y9OjRta/79+8vz549K/V6vSwqKpJSSqnT6WTv3r2lqaZX0dxIYfXq1XLixInSYDDI7OxsGRUVJS9cuCCXLFkiX3jhBSmllAaDQRYXF8s9e/bIiRMn1pZRUFDQpLy24JGCDfr2JXs1QGaVpggNrW9m+ve/pcMmgseOJft5Q0pKqEf72GP2l2UySRkVJeUNN7RNpg0b6PPNn998XqORes633tqyOkpKWmaXdyT5+WR+mjy5/vXMTNnsnIOUUn77rWxk8rOGeRS4ZUubxG0K8Eih/Rg4cCBycnJw4cIF7N+/H4GBgYiKioKUEk899RQSEhIwceJEnD9/Hpfs3JVp+/btuOWWW6BUKhEeHo4xY8Zg9+7dGDp0KD766CMsXrwYBw8ehFarRa9evXD69Gk8/PDD2LhxI/z8/Jz8id2IsjJyyZw7l17v2mU776VLtMDLsic6eTIdk5PbLoulO6olvr40ImmJa+rRo+S+OXVq22SaOhV47DHggw8AK+Hg63HwII1MzM/EXnx9G7t8theBgcAzz9Boz9K92DIIXlNMnEgjr3fftb2QsaoKePVVGnXUhMJ3JZdfUP03XRM6e9asWVi9ejWys7Mxe/ZsAMDnn38OnU6HP/74A2q1Gj179rQaMrsljB49GikpKVi3bh3uuusuLFiwAHfccQf279+PTZs24f3338dXX32F5cuXO+JjMenpZCqYNIl21GpKKZgXrVmaRmJjgS5dqEFpy8YreXnUoNbs5NeIadOocT5zhvzum8O8MnnKlNbLZObRR8l//rPPmg4VYTajmYP5dRYeeAB45x3g8cdJdqWSTHVabf3v2ho+PqRUnnqKwmn8739kBrPkk0+ArCwycXWALep5pOAgZs+ejZUrV2L16tWYNYuigRcVFSEsLAxqtRpbtmzBmTNn7C5v1KhRWLVqFYxGI3Q6HVJSUjBs2DCcOXMG4eHhmD9/Pu655x7s3bsXubm5MJlMmDlzJl544QXsNW/CwrQd83zCgAEU3MwepWA5UhCCesabNwNGY+vlMMc8shWwcPp0Oto7Wti0CejXzz4F0hyRkbS6esWKpiPDJieTkuxsob41GuCVV+j7/fhjurZ9O61itmezqiefJMXw0Ue0aM5yxKDX00K5YcOo49EBYKXgIGJjY1FSUoJu3bqhS5cuAIC5c+diz549iI+Px6efftqi/QtuuOEGJCQkYMCAARg/fjxee+01REREYOvWrRgwYAAGDhyIVatW4ZFHHsH58+cxduxYJCYm4rbbbsPLvPGK40hLo5WkPXvSHzczk3rs1jh4kCZqw8LqX58yhcITtEVZW8Y8skbfviSjPSEvKipowtURowQzd9xBk8Jms4q1Ordt6zANX4uZOZOUwD//SXtYpKc3bzqyZPFiuvfDD2kzHrNi+Pxz+k39858dYpQA4DKcaGZaDT9HK1x9NbleSinlr7/SZOCPP1rPe9VVUo4b1/h6Tg7dV+Mg0CoefZTcKW0tuJJSygceIBfRysqmyzIvPtuwofXyNKSkhOSzNeHs6DUbrsC87mDkSDr+/HPL7jeZaB0GIOW999JivT59pBw40KGL1GwBnmhmmDZiMpEr4oAB9HrQILIH795tPe+hQ9bdHUND6d62xEE6fJjMPQ3t0ZZcey1NjDfn+rxxI20GM3p06+VpiK8v9aa/+or2JmhIcjKZYRxZZ3szfDi5327fTvMKV13VsvuFAJ5/nsxJy5bRxPKJExRrqaOMEsDmI4axzenT5P9vVgq+vmQTtzavcOYM5bXlAz9lCrBjB/nht4YjR2ybjsxMmkS+9W+/3XS+TZvIy8Xbu3Wy2OKOO4CiIutB4H76ifzvLfYu75S8/DJFph00qHWfRQiKwrpoEf2OYmOB6693vJxtgJUCw9jCPMmcmFh3zTzZ3HBC1ZrnkSWTJ1N00K1bWy5HcTG5jza3K55SSZvFbN9OG79Y4+xZUjBtdUW1xrhxFM3z00/rX790iZ5lS11ROyK9e9M8wKuvtr4MIYCXXqJJ688/b3r05wI6ljQM05HYv5/+sLGxddeGDiX30IyM+nnNSsEyryXmXnJrVjebw1Q3N1IAyO3V29v2aMFswnLkJLMZpZJCT2/YUH8y/uef6dhZJ5kbMmsWKcC2IARt7GMehXYgWCkwjC3S0sirx8ur7pp5z92GJqSDB4Hu3clTyRoaDTUkrZlXsNyCszkCAsiM88UXtJCuIRs3AlFRzY86Wsvtt5Pr7cqVddd++ok2BRo40Dl1Mg6FlQLD2GL//vqmI4DmDDw9G082p6c3v5Bp8mTaArKlMYoOHyal0quXffkffphWyf7vf/Wv6/W0XmLKFOdNbMbFkb3dbEKSkiaZJ0xoPkYR0yFgpeAACgsL8d5777Xq3unTp6PQWbtQMa2noIDs7w2H9+ZJRsuRgl5PJp7mAq1ddx315EeNokbyxx/t28P5yBHgyivtWygF0Ihi4kTgvfdoHsPMzp00P+GM+QRLbr+dgtYdPkzpwoXLYz7BTXCaUhBCRAkhtgghDgshDgkhHrGSZ6wQokgIkVaTnnGWPM6kKaVgsPxTWmH9+vUICAhwhlgdi48/plWhLVjV7VIsVzI3ZNgwavTM3+3x46QYmlMK3buTR9Orr9I9115LZpz//rfp6Ku2Yh41xcMPU+iEb7+tu7ZpE/XWJ0xoWVkt5ZZbqJ4VK+piPl0u8wlugDNHCgYAj0kpYwAkAXhQCGHNKLpNSplYk55zojxOY9GiRTh16hQSExOxcOFCbN26FaNGjcKMGTMQU2MHvv766zF48GDExsZi2bJltff27NkTubm5yMzMRP/+/TF//nzExsZi8uTJqLASjviHH37AVVddhYEDB2LixIm1AfZKS0tx9913Iz4+HgkJCVizZg0AYOPGjRg0aBAGDBiACc5uDGxhMJBXzJNP0qrbsWPJtNGRR0jWPI/MDBtGK3QPHaLXzXkeWRIYCDzxBCmHL76gOYgHHqBwEzt3Ns5fUUGT2vbMJ1hyzTXknrp0ad21jRuBpCQarTiT8HAajXz2GdV55ZWkEJnOgT0r3ByRAHwHYFKDa2MB/NiScppb0eyCyNkyIyNDxsbG1r7esmWL9Pb2lqdPn669lpeXJ6WUsry8XMbGxsrc3FwppZQ9evSQOp1OZmRkSKVSKfft2yellHLWrFlyxYoVjerKz8+vDb/9wQcfyAULFkgppXziiSfkIxaC5ufny5ycHBkZGVkrh1kGWzhtRfOuXbSK8/XXpXz++bqdtjw8pJw5s/5Wjx2Fu++mMM/WOHmS5F+2jF6b9xyuqGh5PSYTbXbTq5eUXbo03nEsLY3qWrWq5WWbw3bv20erqoWQ8rnnWl5Oa1i1StZulvPQQ+1TJ9Mk6EgrmoUQPQEMBGClK4ThQoj9QogNQggb/nydj2HDhiE6Orr29dKlSzFgwAAkJSXh3LlzOGElzHB0dDQSa3qmgwcPRmZmZqM8WVlZmDJlCuLj4/H666/jUE1vdfPmzXjwwQdr8wUGBiI1NRWjR4+ulSMoKMiRH9F+UlLoOHcurd48epQmav/yFzIv3Hefa+RqirQ02+6CvXoBQUF18wrp6UCfPjQB3VKEoJWt331H9v4bb6y/Itgc86g13kKW7qnJydREO3s+wcy119Z5YrHpqFPh9NDZQghfAGsAPCqlbLiccy+AHlLKUiHEdADfAuhjpYx7AdwLAN2bGYa6KHJ2I3wsVjtu3boVmzdvxo4dO+Dt7Y2xY8daDaHt4eFRe65UKq2ajx5++GEsWLAAM2bMwNatW7F48WKnyO9Qfv2VGs2aQIEQAhgyhFJQEIVbPn++40TP1OvJNPRIo2kwQghar2D2QEpPp8nnthAXRzb4G28kJfnRR1TPkSO0VuLKK1teptk99aOPgOxscgttq5z24uUFzJ5NYaHHjm2fOhmH4NSRghBCDVIIn0spv2n4vpSyWEpZWnO+HoBaCBFiJd8yKeUQKeWQ0NBQZ4rcKrRaLUpKSmy+X1RUhMDAQHh7e+Po0aNITU1tdV1FRUXoVtN4fvLJJ7XXJ02aVG9L0IKCAiQlJSElJQUZNQut8vPzW11vqzGZKDqmrZg3c+ZQD/brr9tXrqY4doy2T2xqYdGwYaQMdDqaH7B3i8emuOEG4F//oobUPBdw+DCtorXoMLQIs3vq+vXkAdSebqGvvw6kptpeu8F0SJzpfSQAfAjgiJTyDRt5ImryQQgxrEaePGfJ5CyCg4MxYsQIxMXFYeHChY3enzp1KgwGA/r3749FixYhKSmp1XUtXrwYs2bNwuDBgxESUqc/n376aRQUFCAuLg4DBgzAli1bEBoaimXLluHGG2/EgAEDajf/aVfS02lC2ZZS6NuXFjVZLnayhdFIMXta6f5rN2lpdGxOKRiNNJkqpWOUAkBx96+/njbM+fln+2IeNUVMTJ23UXuZjsz4+/OCtc6IPRMPrUkARgKQAA4ASKtJ0wHcB+C+mjwPATgEYD+AVABXN1cuh852Hk55jkuX0mRjZqbtPK++SnlOnWq6rG++oXxRUVIaDI6V05LHH6dJ8Opq23mys0mWuDg6Hj/uuPqLi6WMjZUyKEhKlUrKJ59sW3m//EKT+zk5jpGP6ZTA1RPNUsrtUkohpUyQdS6n66WU70sp36/J846UMlZKOUBKmSSl/N1Z8jAuIiWF3BGb2uHLPIJZtarpst56ixaPnTvXuhhC9rJ/P8UwUqtt5wkPp8+Unk4TzPauNrYHrZYmnqUkd962hqQYN45MYh3Q9Mp0PHhFM+M8pCSl0FwM/R49KGBcUyaktDSasF68mHY3++AD+2T44ouWLZiTsmnPI0vMcZBiYhxvq+/dm/Ym6NGjZTt8MUwbYaXAOI/jxyla5pgxzeedM4c2tDG7YDZk6VJyr7z/foou+cMP5FHTFFu3khvsTTfZvz9ydjZNHltbtNaQoUPpaM+itdYwcSJt1ejIUQjDNAMrBcZ5/PorHe3ZbWvWLHK9tDZa0Omox3/nnbQi+J57yKxi4X3VCCnJk8fTE9izB3j/fftkbiq8RUPMIwVHTTIzTAeAlQLjPFJSyPbep9HSk8ZERJDte+XKxhvY/N//kVvlX/9Kr/v1o6By//tf47xmfvmF6n/tNVo89dRTwMWLzcth9jxKSGg+7/DhtJbBFV5dDOMkWCkwzkFKGimMGWN/mOY5c2jP2r17665VV5ML6pQppAzMzJ9PYajNo5GGdT/zDBAZSfnefZeUyoIFzcuwfz/Z8QMDm8+r0dBqyaio5vMyTCeBlYKL8PX1dbUIziUzk6J0tmSj9htvJI8fSxPS6tXUw2+4unjmTPKDtzbh/NNPwO+/A//4B5mP+vShkcLKlc17Le3f3yF3w2KY9oKVAuMczPGOWqIUgoJoRLByZd0+A2+9RSEeGm4f6e1NWz+uWQNYrtQ2jxK6d6fYP2b+/ncq54EHKPKoNZKTyXWTlQLjxrBScACLFi2qF2Ji8eLFWLJkCUpLSzFhwgQMGjQI8fHx+O6775oty1aIbWshsG2Fy+4QpKRQI29rz2JbzJlDI4zff6cQCbt20VyCtc3N588ns9CKFXXX1q+ne/75TzLvmPHwIDPUqVO0r4MlpaXk1TR5MimOP/+5ZTIzzGWEkLYm6jooQ4YMkXv27Kl37ciRI+hfs8Dn0Y2PIi07zaF1JkYk4s2ptiPt7du3D48++ih+rbFvx8TEYNOmTejSpQvKy8vh5+eH3NxcJCUl4cSJExBCwNfXF6WlpY3Kys/PR1BQECoqKjB06FD8+uuvMJlMGDRoEFJSUhAdHV2b5+9//zuqqqrwZk0UwIKCAgTaYwu3geVzbDN9+pBCsNzkxR5KS4GwMOrl5+XRJvBZWYAtc5t5b4MDB+j1kCG0a9qxY9YXn82dSyapAwcoxEZKCnD33bRnwYIFwPPP19+TmWEuE4QQf0gphzSXz+lRUt2BgQMHIicnBxcuXIBOp0NgYCCioqKg1+vx1FNPISUlBQqFAufPn8elS5cQERFhs6ylS5di7dq1AFAbYlun01kNgb1582astLC/t0UhOJQLF2gS+P77W36vry/wpz+RC2pJCY0Smpp/ueceCsG9cydw6RJNUn/0ke3VyP/+N7BuHcmWmEgTxb16kXIYObLl8jLMZcZlpxSa6tE7k1mzZmH16tXIzs6uDTz3+eefQ6fT4Y8//oBarUbPnj2thsw2Y2+I7Q6PeT7BnkVr1pgzh6KmKhS0Y1tT3HIL9fCXLSOFcMUVNNdgi4gI4OWXaW5hyxbgwQdpe0yLUOcM485cdkrBVcyePRvz589Hbm5urRmpqKgIYWFhUKvV2LJlC840E27BVojtpKQkPPDAA8jIyKhnPjKHy3aU+chhpKRQ/J7WTthOn057AYwfT1tKNoVWS0pk+XKaZF6xovkN7u+9lxbEjRjh/P2KGaaTwRPNDiI2NhYlJSXo1q0butRsJjN37lzs2bMH8fHx+PTTT9HP0s/eCrZCbNsKgW0tXHaHICWFGtzmGmdbeHrSZPGHH9qXf/58Ugh9+9LIoTmUSvJQYoXAMI247CaamdbjkOeYm0vROF9+GVi0yDGCNYeUVNf06a03WTHMZQ5PNDOuYds2OrZkfUJbEYLmBRiGaTNsPmIcS0oKuXQOabZDwjBMB+SyUQqdzQzmMvR6iifUAIc8vy2ktFnWAAAgAElEQVRbaHvKq6+uv3CMYZhOw2WhFDw9PZGXl8eKwR4yM2lhl8WzklIiLy8Pnp6erSvTYKibuA0Ortt0nmGYTsdlMacQGRmJrKws6HQ6V4vSsZGStrI0b/NooQQ8PT0RGRnZ8jLPnqVVwtu308rgt99mn3+G6cRcFkpBrVbXrvZlmiA5GZg6lc5vu61+zKDWsHYtxQnS68lsNHdu22VkGMalXBbmI8ZOkpMp/MPtt1N00aKi1pVz9Chw110U6rpXL2DfPlYIDHOZwErBnUhOpknghx6iIHJff23/vVLSnsd/+hPQvz+wahXwxBMUzfSKK5wmMsMw7QsrBXchJ4e2mpw0iTac79+fAsc1h14PfPkluZiOG0crjRcvprmEV19lLyOGucxgpeAubN5Mx8mTabHX3XdTL//4cdv3mEy0SvjWW4GyMtor+cwZ4F//olXLDMNcdjhNKQghooQQW4QQh4UQh4QQj1jJI4QQS4UQJ4UQB4QQg5wlj9uTnEz7Dg+qecS33UZRSD/+2PY9H39MymTJEuDwYQokx3sNMMxljTNHCgYAj0kpYwAkAXhQCBHTIM80AH1q0r0A/utEedwXKUkpTJhAweAAoEsX8kT69FPAaGx8j04HLFwIjBoF/O1v1nc+YxjmssNp/3Qp5UUp5d6a8xIARwB0a5DtOgCfSiIVQIAQoouzZHJbjh4Fzp+n+QRL7r6brptNS5Y8/jhtcvP++6wQGMaNaJd/uxCiJ4CBAHY2eKsbgHMWr7PQWHEwbSU5mY4NlcK119I+yg1NSFu20AjiiSeAmIaDO4ZhLmecrhSEEL4A1gB4VEpZ3Moy7hVC7BFC7OFVy60gORno3bvxhjUeHjSJvHYt7WsMAFVVwH33Uf5//KP9ZWUYxqU4VSkIIdQghfC5lPIbK1nOA4iyeB1Zc60eUsplUsohUsohoez10jL0elpf0HCUYOauu0gRrFpFr195hTyS3nuPJ5UZxg1xpveRAPAhgCNSyjdsZPsewB01XkhJAIqklBedJZNbkpoKlJbaVgqDBgHx8bRm4dgx4KWXaPeyyZPbV06GYToEzox9NALA7QAOCiHSaq49BaA7AEgp3wewHsB0ACcBlAO424nyuCfJyTRRPH689feFoNHCY48BN90EeHsDb9jS4QzDXO5cFttxugXmyKZqdcvuGz6cjjt22M6TkwN060blv/8+8Je/tF5OhmE6JPZux8m+hp2Fp5+mGEMXW2BdKyigsBS2TEdmwsJownn8eGD+/LbJyTBMp+ayCJ192SMlsHIlxRu68UZyGbVnQ5wtWyhURXNKAQA++YTqEaLt8jIM02nhkUJn4Ngx4PRpWleQmgrcf3+9ndNskpwM+PoCSUn21cMKgWHcHrdRCrm53+G338JRUXHK1aK0nHXr6PjOO7Tt5ccf27flZXIyMHZsy+chGIZxW9xGKQjhAb0+B9XV2a4WhaiooIij9rB+PRAXB3TvThFKr7+evIWshacwk5EBnDpln+mIYRimBrdRChpNBACguvqSiyWp4dlngdjYupXEtiguBlJSgGuuodcKBYWg6NcPuPlmavitsWkTHVkpMAzTAtxIKYQDQMcZKaxbR3sUrFzZdL7kZHIVnT697ppWC3z/Pc0BXHcdBa7LyqLNcO6/n5TN/fdTWIt+/Zz7ORiGuaxwG+8jtToUgOgYI4XsbCA9nc6XL6cG3Bbr1wP+/rSNpiW9egFffQVMmQJERtKIAiCFMXIk7cM8ezZPHjMM0yLcRikoFCqo1SEdQyn8/DMdb78dWLECOHiQQk00xGQipTBlCqCy8lVNmAB8+CGNOkaMAEaPBhIS6vZMYBiGaSFuYz4CyITUIcxHyckUsnrJEvIMsrVXcloajSrM8wnWuPNOGjE88ggwcCArBIZh2oRbKQW1Ohx6vYtHClKS19CECbSSeMYM4LPPgOrqxnnXrSPzz9Sp7S8nwzBuiVspBY0mwvXmI/MuaBMn0ut582jrS/NaBEvWrQOGDiXlwTAM0w64mVIg85FLgwCa1xaYXUUnT6b9kpcvr59Pp6O4RU2ZjhiGYRyMmymFCJhMFTAaSx1f+HffAVddBZSXN51v82byHDLvgqZS0bzAhg31g91t3EimJktXVIZhGCfjZkrBiWsV3n+fevaff247j15PQeoaLii7+27AaCRPJDPr1gHh4bQJDsMwTDvhpkrBwfMKRUV1bqZvv207WN3u3bTQzDyfYObKK8mldPnyun0TNm0Cpk2jFcwMwzDthFu1OOZQFw73QNqwgUYB8+bRmoOUFOv5Nm8mb6Jx4xq/N28eRUNNTaUNcQoLeT6BYZh2x62UglrtJPPR2rVk6lm6lNYfvP229XzJycDgwUBwcOP3Zs0CfHxotLBuHc01cNwihmHaGTdTCiFweKiLqipadTxjBjXqf/4z8O23wLlz9fOVlNAooKHpyIxWS4ph1SpSMiNHUngLhmGYdsQupSCEeEQI4SeID4UQe4UQk50tnEPZuBGKmDh4lQc7Vin8/DNQWgrccAO9fuABmhf473/r5/v1V5oraKr3P28eKY/jx9l0xDCMS7B3pDBPSlkMYDKAQAC3A3jFaVI5g/Bw4NgxhKdoHGs++vZb6uWPH0+ve/akHdI++ACorKzLt3kzbaHZMLCdJSNH0j7MALuiMgzjEuxVCuZQm9MBrJBSHrK41jlITAT690dIcrnjRgpGI61PmD4d8PCou/7ww0Bubv2w2Js3A6NGNb23shDA00/TJjr9+ztGRoZhmBZgr1L4QwjxE0gpbBJCaAGYnCeWExACmDsXvnsLIc6ed0yZqalATg414paMHw/ExNS5p164ABw6ZN/E8Z130pwCh7xmGMYF2KsU/gxgEYChUspyAGoAdztNKmdx660AgMCNDgp1sXYtRTltaOoRAnjoIWDvXlIc5jUMtiaZGYZhOgj2KoXhAI5JKQuFELcBeBpAUVM3CCGWCyFyhBDpNt4fK4QoEkKk1aRnWiZ6K4iORtWgHgjdbIDRWNK2sqSk+YQJEwA/v8bv3347eQ+9/TaZjkJCgAED2lYnwzCMk7FXKfwXQLkQYgCAxwCcAvBpM/d8DKC5mM/bpJSJNek5O2VpE1U3jYHvaUC/18YCM3tJT6f9kc1eRw3x9aXwFV9/TesOJkzg1ckMw3R47G2lDJLsLdcBeEdK+S4AbVM3SClTAOS3UT6HY5x5DaQCEF982baCvv2WzEQzZtjO8+CDNBmdl8emI4ZhOgX2KoUSIcSTIFfUdUIIBWheoa0MF0LsF0JsEELEOqC8ZlF37Yf8oYB6zU+03WVrWbsWGD4ciIiwneeKKyh+EcCrkxmG6RTYqxRmA6gCrVfIBhAJ4PU21r0XQA8p5QAAbwP41lZGIcS9Qog9Qog9Op2uTZVqNOG4NAFQZuUCv/3WukLOnAH27WvsdWSNN96geYUePVpXF8MwTDtil1KoUQSfA/AXQvwJQKWUsrk5hebKLJZSltacrwegFkKE2Mi7TEo5REo5JDQ0tC3VQq0OQd5IAZOXuukw103xbY3+skcp9O1LnkgMwzCdAHvDXNwMYBeAWQBuBrBTCHFTWyoWQkQIQc74QohhNbLktaVM++pVQuEXhtLx3WkS2NreyM2xdi0QGwv06eN4ARmGYVyIys58/wCtUcgBACFEKIDNAFbbukEI8SWAsQBChBBZAP6FmnkIKeX7AG4CcL8QwgCgAsAc2U77ZGo04cif5gm/dado34Jrr22c6eRJ4LPPgIAA2i4zIoKOGg2wbRvw1FPtISrDMEy7Yq9SUJgVQg15aGaUIaW8pZn33wHwjp31OxSNJgJ5Q/LRMzgY+OKLxkph7VrgrruA4mLbhdhjOmIYhulk2KsUNgohNgEw+3HOBrDeOSI5H40mHOXlx4CbbwY+/pgik2q1tFHOU08BS5YAQ4cCX31F17Ozaf/kixfp3MuLt8lkGOayxC6lIKVcKISYCWBEzaVlUsq1zhPLuWg04aiuzoa89VaI//6XJo4nTgRmzybT0AMPkNeQOchdcDDNITAMw1zm2DtSgJRyDYA1TpSl3dBoIiBlFYxXxUHVsyfw+uvAwoU0YvjsM2DuXFeLyDAM4xKanBcQQpQIIYqtpBIhRBMG945N7bac+hzglltoX+WAAGDXLlYIDMO4NU2OFKSUTYay6KxoNHV7NXs//jgFq7vnHuuB7RiGYdwIt4zQptFQaIrq6ktAUBCwYAErBIZhGLitUqgbKTAMwzB1uKVSUKuDASgdty0nwzDMZYJbKgUhlNBoQqHXs1JgGIaxxC2VAkAeSGw+YhiGqY/bKgWNJoLNRwzDMA1wY6UQzkqBYRimAW6uFLLRToFZGYZhOgVurBQiIGU1DIYiV4vCMAzTYXBjpUBrFdgDiWEYpg43VgrmVc3sgcQwDGPGbZVCbVA8nmxmGIapxW2VQl2oC1YKDMMwZtxWKdSFumDzEcMwjBm3VQpCKKDRhPFIgWEYxgK3VQpA3VoFhmEYhnBzpRDBLqkMwzAWuLVSoKB4rBQYhmHMuLVSMAfF41AXDMMwhNOUghBiuRAiRwiRbuN9IYRYKoQ4KYQ4IIQY5CxZbKHRhNeEuihs76oZhmE6JM4cKXwMYGoT708D0Kcm3Qvgv06UxSq8VoFhGKY+TlMKUsoUAPlNZLkOwKeSSAUQIITo4ix5rMGhLhiGYeqjcmHd3QCcs3idVXPtYnsJ0JmC4klJSdFKNW4yAUYjJZWKUkvqrq4GKiqA8nJKFRVAVVVdmQZD3blGA/j7A35+dUdzfZWVQGFh/WQ0Amp146RQ1H1ucwIAHx8gMJCSh0djeSsrAZ2uLpWW0rWKCjqak0JBslomtZrkqaqiVF1NR70e8Pamz+PvDwQE0FGrpTylpUBJCR1LS6kuf38gJAQIDaUUEkKym0z0vjmv+d68PEq5uZTy8uj5KBTWn4/5e1SpAKWy7tzLq3HSaOp/f+ZUWVn3XC1RKABfX/rutFpKfn6Apyc9j4bP0misn898rtEAZWX1n01pKV2rrKSyLI+Wv0/LJGXj77Ciou734OND8pqPSmXdd2d5NBjo+TdMKhV9v97eVIb5XAj67qurKZnP9fr6v3vzUa2u++xaLcmi1dLztLzXfCwrA4qKgOLi+slgoLobppkzgTvuaNl/v6W4UinYjRDiXpCJCd27d3dYuc6Kf1RdTX9oy4bJ8s9uTuYv35zMPy7LH6H5x6zX0w89LAyIiKhL4eHUMOp0QE5O3TEnh/6I5oa6IT4+jRs4pbL+n9d8XlZGf5y24O1d19g6EksFUV5e97k7KhoNfZ/25AsJoe9GSvr+GybL34zBYL1xtwchGl9zhe+FWbmZP5M11GpSTOYE0O+zrKz535ZSWZcUirokBNVXXt6637lZbrMisiV7U6jVdR0ocyeqYYdISqCgoOVltxRXKoXzAKIsXkfWXGuElHIZgGUAMGTIEIf9XNXqIAiharX5SErg2DFg61ZgyxZg3z5qlIqa2KIhMBAIDqY/fGBgXY/PsqenUlFDb+69ms/1euDSJSA7m9KBA/TaYKAyQ0NJacTEAGPH0o/L8o9gTno9yVhURD3RoiJSUiYT9Wq6dKnr4fj61vWevLzqelBeXiSXWW7L8qur68ovLq47V6mokbNM/v503VqjZ26YLHtKADUA+fn0BzEfCwpIprCwup55WBg9Z622rsfs6Vknu3kE1DCpVHXP3ZxUKmo0LJ+Z+fN5etJzskyenvS+TkfP1nzMz6/Lb+7VmlNwcN1vw8fHemPdFCYTPTdzL9oyVVfXfXeWSaOxXo/JVNcxsEwVFXXP0LJxVijq8hQX151XVdX/LZmTj0/dveZnrFTW/2+ZTHUKD6C8lnkaYm7YS0tJsZj/N+ZjU/ea66yurhtFlZXRNctRpPlo/t82HLlLSZ/Z3KEyPwcp699vPpo7Z9ZGvK7ClUrhewAPCSFWArgKQJGUst1MRwCFulCrWxbqorQU+PJL4JdfSBlk1+iTbt2A4cOpQTWbCizNBqGhQFBQy8w29mA5/GVajkZjf16zmaJrV/vyh4UBffq0Tq7WoFDUNbD+/m0vy9xrdQVC1HUy7G0wVaq2ySxE3fMLDGx9GWZlFxraujJcjdOaEiHElwDGAggRQmQB+BcANQBIKd8HsB7AdAAnAZQDuNtZsjQFrVWwb6Rw5Ahw443A0aPU+I8fTz3yceOA3r1b3rNzBOYhMMMwjCNwmlKQUt7SzPsSwIPOqt9eKP5R8yOFNWuAu+6iYXNyMjBhgmuUAMMwjDNx+z6mRhPepPeRwQA88QRw001AXBywdy8wcSIrBIZhLk/c3hJtGepCNGjpc3KAOXNoEvmBB4A33uhYE0IMwzCOxu2VglodDin1MBgKoFYH1V4/fBiYMoU8Rj75xPm+wQzDMB0Bt1cKnp7kFVtRcapWKZSXk7lIrwd+/x0YONCVEjIMw7Qfbj+noNUOAQCUlOyuvfboo+Rh9NlnrBAYhnEv3F4peHh0h1odWqsUvv4a+OAD4O9/pwllhmEYd8LtlYIQAlrtMBQX70JmJjB/PpCUBDz3nKslYxiGaX/cXikAgJ/fUBQXn8CcOUZICXzxBS1BZxiGcTfcfqIZALTaYfjoo2exc6cSq1YB0dGulohhGMY1sFIAsGvX1fjyyymYM2c/br55gKvFYRiGcRlubz7S6YB58/zRo8cpPPbYa64Wh2EYxqW4/Ujh3Xcp/PTq1cug1//manEYhmFciluPFKSktQjjxwNDh0agquoMqqtzXC0WwzCMy3BrpbBjB3DqFHDbbYBWOxRA/UVsDMMw7oZbK4UVKygU9syZgK/vIAAKFBfvcrVYDMMwLsNt5xSqq4FVq4Drr6etAgFf+PjE8EiBYRi3xm2Vwvr1tK/v7bfXXdNqhyE39zurYbRbi8FkQFl1Gfw927g/IsMwnR6TNCGnLAdni87iXNE5BHkFYUDEAAR5BTV/czvhtkphxQraQ3fcBANSzvyOMJ8wePoMgiF7OSorM+HlVbeCzSRNOKI7gpQzKUg5m4JLpZcwb+A8zI6dDbXS+tJnkzRhZfpKLN66GKcKTuH2hNvxz9H/RO+g3lbzSymRciYFr/z2CrKKs7BoxCLcEn8LFKJ5C5/BZICuTIfs0mxkl2bjUtklZJdmI8ovyq4yjCYjPtj7ATILMzE+ejxGdR8FL7VXs/V2FKSUyCzMhNZDixDvkCbzGk1GHNIdwh8X/oBSoUSIdwhCvUMR4h2CEO8Q+Gp8W9QhqDRUwkPp4bBOhJQSJ/JPYMOJDdh4aiOO6I7gn6P/iXkD57WoDoPJgNSsVGw4sQEbTm7A0dyjmHrFVMyNn4trrrwGnipPh8jbkAslF7AlYwu2ZFLSlekwvc903BRzE6ZdMQ0+Gp82lV9trEZJVQlKq0tRUl0CjVKDHv494KFy3kYn5fpynMw/iRN5J3A87zhO5J+AVqNFUmQShkcNRw//Ho2+G5M04UTeCaRmpSI1KxXH84/XKoIqY1WjOrr7d0diRCISwxORGJGIQK9AmKSpUeoV2Av9Qvo57bMCgKBdMTsPQ4YMkXv27GlTGQUFQEQEcP/9QMm4P2N52nIAgEqhRFdPI2LDh2JA1wkI9ArEjqwd2HZmG/Iq8gAAXbVd4aP2wYn8E4jyi8KC4Qtwz6B74KvxBUB/6m+Pfotntj6D9Jx0JIQnYETUCHyU9hH0Rj3uHHAnnh79NKIDo2vzrzuxDi9tewk7snYgzCcM4T7hOJhzEAMjBuK1Sa9hYq/GkfkKKwuxMn0lPk77GLvO74KE9e9xRNQILLt2GWJCY6y+f1h3GPO+m4ed53dCKZQwSiM8lB4Y2X0kJvWahEm9JyHSLxLni8/jQskFnC+h44WSC/BSeSE2LBZxYXGIDY112GioylCF38/9DgmJngE9EeUX1Uj55lfk4+fTP+OnUz/hp9M/4WzRWQBAF98uSAhPqE0xoTE4V3QOO8/vRGpWKnZf2I3S6lKbdXuqPDGj7wz8LelvSIpMsplv9/ndeOW3V7D2yFqM6jEKL41/CSO6j2jycxVXFWPTyU2oNlZDpVDVSxWGCvyS8Qs2ntyIjMIMAEDf4L7w8/DD7gu7ceeAO/HeNe/BW+1ts/yy6jJ8ffhrrD+xHsmnk1FYWQilUOLqqKvRL6Qffjj+A7JLs+Hv4Y+Z/WdibsJcjOkxBkqFskm5zUgpUWmohK5cB12Zrt7xeN5xbMncguN5xwEAAZ4BGNNjDIK8gvDj8R+hK9fBS+WFqVdMxcz+MzE8ajiKKouQV5GH3PJc5JXnIa8iD/kV+SiqKkJhZWFtKqosQlFVEUqrS1FtrG4kl4BAV21X9ArshejAaEQHRMNX41tbZl5FXu15paESaoUaaqUaKoWq9lxAWG2EL5VdQlZxVr36InwjUFxVjHJ9ee3rpMgkDI8cjnJ9OXae34mdWTtRUFkAAPDz8ENMaAx6+PdAd//utSnKLwq6ch3SstNq07G8YzBJk83v4O8j/o5XJr5i1/fV6DkJ8YeUckiz+dxRKSxbBvzlL8A/v1mO5w/8GQ8PexhDuw7FEd0hbD/2Oi5UB+BMaTEMJgN6B/bGqB6jMLr7aIzuMRq9AntBQmLDiQ147ffXkHImBYGegXhg6AMY3GUwXtz2Iv64+Af6BvfFs2OfxazYWVAIBS6WXMSrv72K9/e8D6M0Yl7iPCRFJuE/qf/BwZyD6OHfAwuvXoh5A+fBQ+WBLw9+iX/88g+cKTqDKb2n4NWJryIuLA6/ZPyCj9I+wtqja1FpqERcWBxmXDkDkX6RCPcNR4RvBCJ8IxDmE4Y1h9dgwU8LUFJVgidHPoknRz1Z20PUG/V49bdX8XzK89BqtFg6bSmu63sdUs6kIPl0MpJPJyM9J93q8xMQCPUJRVl1Gcr0ZbXXu2m7IS4sDhOiJ2DewHkI9g62+zu5UHIB60+sx7oT65B8KrleuUqhRKRfJKIDo9HdvzuO6I5gz4U9kJDw8/DDhOgJmBA9AVXGKhy4dAAHLh3AId2heg2ISqFCYkQikrolISkyCUO7DYVCKJBbngtdmQ655bnILc9FRmEGvjj4BYqqijA8cjj+lvQ33ND/BqgUKkgp8XPGz3hl+yv4OeNnBHgG4OaYm/Hdse9wqewSrulzDV4Y/wISIxJr65VSYveF3Vj2xzJ8mf5lbUNiDR+1Dyb0moBpV0zDlN5TEB0YDaPJiOdTnsdzvz6H2LBYfD3r60Y9xeKqYryz6x38J/U/yC3PRRffLph6xVRMu2IaJvWehADPAAA0Svol4xd8fvBzfHPkG5RUl8Dfwx9aD21tA6lSqGobyQpDBSr0FfWOthosrUaL0T1GY1zPcRgXPQ4DwgfUKhuDyYDtZ7djzeE1+OboN7hQcsHmM/DV+CLQMxABngH1kp+HH7QaLXw1vvDV+ELrQeeVhkpkFGQgozADpwtOI6MwA+eLz0NCQqVQIcgrCMFewQj2DkawVzC81F4wmAzQG/V0NNHRaDJCqVBCKZRQCAUUQgEhBIK9gnFl8JXoE9QHVwZfiSuCroDWQwuDyYCDlw5iR9YOpGalYkfWDpzMPwmFUCAuLK72d5YUmYS+IX3tGvEDNCo5lHMIZfqyWjlq5alRflH+UXaV1RBWCk0wahSQZUhD9p+GY0TUCGy6bVPtD3jv3uEQQo24hJ9RXFXcbMOWmpWK139/HWuPrK3t2S4esxhzE+ZCpWhsnTtffB4vb38ZH+z9ANXGasSExmDRiEWYEzenUW+40lCJ93a/hxdSXkBhZSHCfMJwqewSAjwDcGvcrbh74N0Y3GVwk2aFnLIcLNi0AJ8f/Bx9g/ti2bXLoNVoMe/7eUjLTsPNsTfj7WlvI8wnrNG9F0su4ueMn1FQUYBuft3QVdsV3bTdEOEbAbVSDZM04WzRWaTnpONQziGk69JrG2VPlSfmxs/FQ8MeqtdImimrLsPv537H1syt2HByA/Zl7wMARPlF4Zo+12B6n+nw0fggszCz9k+fUZiBM4Vn0N2/O6b0noLJvSdjaLehVp+z3qjHifwTOJRzCF21XTGoyyC7TWIlVSX4OO1jvLXzLZwqOIUe/j1wx4A7sOHkBuy5sAddfLtgwfAFuHfwvfDz8ENZdRne2fUOXv3tVRRUFmBO3BwsvHohUrNSseyPZdh/aT+81d64Je4W3JV4F8J8wmAwGeolhVAgITwBGqXGqkw/nfoJc7+Zi0pDJT649gPMiZuD/Ip8vJX6FpbuWorCykJMu2Ianhr1FEZEjWjW1FShr8APx3/A1sytqDJUQW/S1zaQeqMeJmmCl9oLXioveKu94aXygpfaC74aX4R4hyDMJwyh3qEI9QlFqHco/Dz87DJvmaQJO7N24kjukXoNdpBXEIK8gmx+/pZQaahElaHKbpkcRV55HjRKDbQe2narsyWwUrBBRgbQq38Rgp4cDE9tBfb9ZV+9BvHEib/i4sUPMXJkERRWGhtbHM87jiO6I5jWZ5pdP+xzReeQWZiJEd1HNNuLKKgowGu/vYbj+ccxO3Y2ZvSd0WKb8KaTm3D/uvuRUZgBpVAi1CcU/73mv7i+3/UtKsceDl46iHd2vYMVB1agwlCBkd1H4uFhDyPAMwBbM7fi1zO/Ytf5XTCYDFAKJYZHDcc1fa7BNX2uQVxYXLv+kZvCaDLix+M/4o3UN5ByJgVXBF2BJ65+AncMuMOqDbuwshBLfl+CN1PfrB3pDIwYiL8M/gtuib8Ffh5+bZInqzgLs1fPxu/nfsfUK6Zi+9ntKK0uxfX9rsfTo57G4K6D21Q+c3nDSsEGzz8v8cyhG6GM+QG/3vVrIztwdvZnOHr0dgwZcgC+vvFtFbdDUa4vx4spL6KwshAvjH8BgV6BTq2voKIAH6V9hHd3v4vTBacBkBlnaNehGNNjDMb2HIsR3UfUzsd0ZC6WXESYT5hd9vdLpZfw9RCy12oAABKASURBVOGvkRSZhCFdm/0Ptgi9UY8nf34Sb6a+iZtibsI/Rv0D8eGX1++UcQ6sFKwgJRB2/b+RO+hx/Hvyv7Fg+IJGecrLj2HXrn7o2/dDdOkyr63iMqizZUtIXB11dadQAh2dKkOVUz1umMsPe5WCU1c0CyGmCiGOCSFOCiEWWXn/LiGETgiRVpPucaY8H2zajtzEv2OQ5434W9LfrObx8uoDpdKfVzY7EKVCiUm9J2Fy78msEBwEKwTGWThtnYIQQgngXQCTAGQB2C2E+F5KebhB1lVSyoecJYeZS6WXsGDHzRCF0fjmgeU27dZCKKDVDuGVzQzDuCXOHCkMA3BSSnlaSlkNYCWA65xYX5P8cjoF5YYSTMxfjR7hTfvT+/kNQ1nZARiNle0kHcMwTMfAmUqhG4BzFq+zaq41ZKYQ4oAQYrUQonUOuHagPTsL8j+ZeNiOndW02qGQ0oDS0jRnicMwDNMhcXWU1B8A9JRSJgBIBvCJtUxCiHuFEHuEEHt0Ol2rKurTB3j8wWBMmdJ8Xj+/YQCAkhKeV2AYxr1wplI4D8Cy5x9Zc60WKWWelNIcCOR/AKw6Wkspl0kph0gph4SGhrZKmL59gddfBzR2rI3x8OgGjaYLzyswDON2OFMp7AbQRwgRLYTQAJgD4HvLDEKILhYvZwA44kR5WoRWO4w9kBiGcTucphSklAYADwHYBGrsv5JSHhJCPCeEmFGT7a9CiENCiP0A/grgLmfJ01L8/IaiouI4qqtbZ65iGIbpjLjV4rWWUFZ2CLt3xyE6+iX06PGk0+tjGIZxJh1i8VpnxscnFoGBk3D+/DswmfSuFodhGKZdYKXQBJGRj6K6+gJ0utWuFoVhGKZdYKXQBEFBU+HldSWyst50tSgMwzDtAiuFJhBCgcjIv6KkZBeKilJdLQ7DMIzTYaXQDOHhd0Kp9OfRAsMwbgErhWZQqXzRtet86HSrUVl5rvkbGIZhOjGsFOygW7eHAEicP/+uq0VhGIZxKqwU7MDTswdCQm7AxYvLYDSWNX8DwzBMJ4WVgp1ERj4Kg6EAly595mpRGIZhnAYrBTvx9x8BX9/ByMp6E1KaXC0OwzCMU2ClYCdCCERGPoLy8qMoKEh2tTgMwzBOgZVCCwgLuxkaTQS7pzIMc9nCSqEFKBQe6NbtIeTnb8SJE49yTCSGYS47VK4WoLMRFfUEqqt1OH/+LZSU7EFs7Ffw8OjqarEYhmEcAo8UWohCoUafPm+if/8vUVqahj17BqKgYKurxWIYhnEIrBRaSXj4HAwevAsqVSD275+Is2dfR2fbm4JhGKYhrBTagI9PDAYP3oXQ0Btw+vQTSE+fgcLC7awcGIbptLBSaCMqlR9iYr5C795voLBwK9LSRmHXrn44e/ZVVFVddLV4DMMwLYKVggMQQiAq6m+4+ups9Ov3MTSaCJw+vQg7dkTh4MFrodN9A6Ox0tViMgzDNAt7HzkQpdIHERF3IiLiTpSXn0B29kfIzv4YeXk/Qqn0RXDwdQgLuxmBgZOhVHq6WlyGYZhGiM5m/x4yZIjcs2ePq8WwG5PJgMLCLdDpvoZO9w0MhjwolVqEhFyHwMApUKn8oVT6QKn0gUJBR7U6GCqVX5PlSmlCeflRFBfvgslUAX//q+HjEw8hePDHMExjhBB/SCmHNJuPlUL7YTLpUVi4BTk5XyE39xsYDAU286rVofDy6gNv7yvh5dUHXl59IIQKJSW7UFy8CyUlu2E0ltS7R6n0h7//CAQEjIa//yj4+g6AQuENIYTVOozGClRUnEJFxQlUVJyAlEZ4evasTRpNhM17GYbpXLBS6OCYTHpUVJyE0VgGo7EUJlNZzXkZ9HodKipOoLz8BCoqjqO6um7CWggVfHwGwM9vGLTaYfDzuwoKhReKirajqCgFRUXbUF5+1CK/BipVINTqIKhUgVCpAmEyVaKi4gSqqs4BsP39KxSe8PDoAS+vaHh6UvLy6lVz3gtqdYDNe43GcpSXH0N5+WGUlR1GefkRqFT+8PcfCX//kfDyurJNCqe6OhclJbtRUrIbxcW7UFq6Dx4eXREQMB4BAePg7z8SKpVvq8t3JFJKlJUdQl7edygq2g5Pz2hotUOh1Q6Fj09/CKF0tYhOwWQywGQqb3bUy7QPrBQuIwyGUlRUnISUVfDxGdDsfER1tQ5FRdtRXn4MBkNBbdLr6SiEqtEoxNubRiKVlWdQWZmJysoMVFZmoqIio+Y8o9HIRgg1FApvKJXe9Y56vQ6VlRkwKxwhVPD07A29PhcGQx4AGgmZFYRKFVBPPnMymfQ1ikMBQNSYxiTKy4/VlA8AAt7e/aHVDkJl5RkUF6dCSj2EUEGrHYqAgHHw9u4PjSYCHh5doNFEQKUKqlVIUppq6s6rka8AKlUAPDyioNF0gUKhrveZjcZylJYeQGnpPpSW7kN5+ZHaUR2lK+Dt3QdqdRiKirYjN/c75OV9Xyuvt3cMqqrO1Y7yFAofaLWDoNUOQ0DAGAQEjIZK5d/q30p9WStqvsvT0Ovz4OnZCz4+/aFWB7eoHL0+D+XlR1FefhTV1ZegUgVBrQ6plwCgrCwdZWUHUFp6AGVlB1BWdhhSVkGj6QZf3wT4+MTXHr29+0Kh8HDI52yIuU1rS6fDaKxERcUxmEyVUKtDoVaHQKnUtqhMo7Gy5pnsh5QSGk2ERQpv9NtyNh1CKQghpgJ4C4ASwP+klK80eN8DwKcABgPIAzBbSpnZVJnuqBQ6Cnp9Ya2CqKg4DYMhH0ZjGUymchiN5TXHMqhUgfDxiYW3dwx8fGLg5XUFFAoNpKQGnUY121FUtA2VlactalDUjGoCoVIFQAgNSLHImnDldO7p2RNa7bCa3vZgqFTa2hKMxjIUFf2OwsItKCj4BSUlewAY630OIdRQq8NgMlXWKDpbodBFjTKJgkYThoqK0zWjMMqvUgXA2zsWBkMeKipOQ8rqevcCEkJ4IDBwIkJCZiA4+E//3969x8hVlnEc//7mcvY2bXe73dbSQku5CCWUEhFBMMEasCgRTEBAIMSYECMmEDUKxiuRGP8R/YNEiBCrooJIlRgSxEJQErkUqJS2UAtiaG27i9DW3dnOZefxj/Pu6ex2W7ZlZ6c983ySk3PZM2ffZ/ed85zznpn3pa3tmPA8aHNypxNPL2JWAjLMmHEWPT0r6O5ewcyZ51KrFSmXd1Iu76Bc3kmlspNyeQCzCmZVzEbCPL4yjxP765TLOyaMKp/vo7PzVDo7T6Wj43jMaphVqNXK4ZhlqtU94U7vlSSRT1YUzaeraxmFwjJyudkUixsZHHyJYnHTmL9RLtcdTrhziaK55PNzyWY7qFb3UK3uZmRkd7IsZWhvXzSmebO9fTGQDc2fm5M762JxM7XaXtraFoRpYTKPLwjyZDJ5pH1TpTLA0NAGisUNDA1tYHj4tf3qhRSRz/cRRXGSyOV6yed7Q2KMl8vlneGCYR1DQ5sYX/fG/h/m0N5+AoXC6XR17ZuiaM4h/b0nq+lJQfE98WbgQmAr8BxwtZltrNvni8AyM/uCpKuAT5vZlQc7rieFdCmVdoSrsZ5wJTa1D8pHRoYolbaFE+p2yuUdlErbqVR2ksl01L2hR9/kPVQq71AqvUmptDWZyuXttLcvolA4M5na2xfV3XGMsHfvm8nzmVJpKzNmfJCengsn1Yw1MrKXPXueZteux0Myewaz6gH3j09sbUg5IIuUQ8qRybSFk+fY5r58fjbDw69RLG5iaGgTxWI8jb37y4TjRmSzhXAHeQqdne8P81OIovlUq7uoVN4aM5lV6Oo6ja6uZURR34RljptMNzM4uJ7h4S1UKgNUKv2Uy/3JvFYrks3OIpebFT6EMZNcbhZm1ZDs/kW1+vZEfxHa2o4Ld78nk812UiptC/+/eB4n3YPJ0tl5Ep2dp4VYlpLNFiiXB0Kc4+f77i7rm2Gj6JhQR5aH6QwymbZQB/dNpdJ/GB5+lcHB9WMSbz4/j1xu5pgkXavF84ULv8ySJd9/lzgmdiQkhXOB75rZx8P6rQBm9oO6fR4N+/xdce3eAfTZQQrlScG1gmp1kN27n2Jw8Hmy2VlE0byk2SGK3nfITRkTMTNqtSKQDVfOR8ezjWp1T9LMaVaho+NkOjpOIJvtOOBrzCycwHeHE20l3B3F81yuh87Ok8lkokMuj9lIaPr8L7lcD1E09xBfb5TLOxgaWh+ml6nV9iJFSZKWIjKZPN3dK+jtvfiQywiTTwqN/J7CAuDNuvWtwIcOtI+ZVSXtBnqBtxpYLueOeLlcgd7elfT2rmzY75BENtvVsOM3Si43k0LhdAqF0yf9GklEUd8B72LeCylLFM057GYfSbS1zaetbT6zZ180xaU7dEfFh9ol3SBpraS1AwMDzS6Oc86lViOTwjbg2Lr1hWHbhPuE5qNZxA+cxzCzu83sLDM7q69v6jO9c865WCOTwnPASZKOV/wxkquAh8ft8zBwfVi+HHj8YM8TnHPONVbDnimEZwRfAh4l/kjqvWa2QdJtwFozexi4B/ilpC3A28SJwznnXJM0tEM8M3sEeGTctm/XLe8FrmhkGZxzzk3eUfGg2Tnn3PTwpOCccy7hScE551ziqOsQT9IA8O/DfPkcWuuLcR5verVSrODxToVFZvaun+k/6pLCeyFp7WS+5p0WHm96tVKs4PFOJ28+cs45l/Ck4JxzLtFqSeHuZhdgmnm86dVKsYLHO21a6pmCc865g2u1OwXnnHMH0TJJQdJKSa9K2iLplmaXZ6pJuldSv6SX67bNlvSYpH+GeU8zyzhVJB0r6QlJGyVtkHRT2J7WeNslPSvpHyHe74Xtx0t6JtTp+0PHk6kgKSvpRUl/CutpjvUNSeslrZO0NmxrWl1uiaQQhga9E7gYWApcLWlpc0s15X4OjB+R5RZgjZmdBKwJ62lQBb5iZkuBc4Abw/8zrfGWgBVmdgawHFgp6Rzgh8AdZnYi8A7w+SaWcardBGyqW09zrAAfNbPldR9DbVpdbomkAJwNbDGz1y0eOfy3wKVNLtOUMrO/Evc0W+9SYFVYXgVcNq2FahAz225mL4Tl/xGfPBaQ3njNzAbDaj5MBqwAHgzbUxOvpIXAJ4GfhXWR0lgPoml1uVWSwkRDgy5oUlmm0zwz2x6WdwDzmlmYRpC0GDgTeIYUxxuaU9YB/cBjwGvALjOrhl3SVKd/DHwNqIX1XtIbK8QJ/s+Snpd0Q9jWtLrc0K6z3ZHDzExSqj5qJqkA/B642cz21A9kn7Z4zWwEWC6pG1gNnNLkIjWEpEuAfjN7XtIFzS7PNDnfzLZJmgs8JumV+h9Od11ulTuFyQwNmkY7Jc0HCPP+JpdnykjKEyeE+8zsobA5tfGOMrNdwBPAuUB3GMYW0lOnzwM+JekN4mbeFcBPSGesAJjZtjDvJ074Z9PEutwqSWEyQ4OmUf1wp9cDf2xiWaZMaGO+B9hkZj+q+1Fa4+0LdwhI6gAuJH6O8gTxMLaQknjN7FYzW2hmi4nfp4+b2TWkMFYASV2SZowuAxcBL9PEutwyX16T9AnitsrRoUFvb3KRppSk3wAXEPeuuBP4DvAH4AHgOOKeZT9jZuMfRh91JJ0P/A1Yz752528QP1dIY7zLiB82Zokv5B4ws9skLSG+mp4NvAhca2al5pV0aoXmo6+a2SVpjTXEtTqs5oBfm9ntknppUl1umaTgnHPu3bVK85FzzrlJ8KTgnHMu4UnBOedcwpOCc865hCcF55xzCU8Kzk0jSReM9vzp3JHIk4JzzrmEJwXnJiDp2jCGwTpJd4UO6QYl3RHGNFgjqS/su1zS05JekrR6tO97SSdK+ksYB+EFSSeEwxckPSjpFUn3qb7TJueazJOCc+NIOhW4EjjPzJYDI8A1QBew1sxOA54k/tY4wC+Ar5vZMuJvWY9uvw+4M4yD8GFgtNfLM4Gbicf2WELc349zRwTvJdW5/X0M+ADwXLiI7yDukKwG3B/2+RXwkKRZQLeZPRm2rwJ+F/qzWWBmqwHMbC9AON6zZrY1rK8DFgNPNT4s596dJwXn9idglZndOmaj9K1x+x1uHzH1ffaM4O9DdwTx5iPn9rcGuDz0bz86Xu4i4vfLaE+dnwWeMrPdwDuSPhK2Xwc8GUaE2yrpsnCMNkmd0xqFc4fBr1CcG8fMNkr6JvFoWBmgAtwIDAFnh5/1Ez93gLhr45+Gk/7rwOfC9uuAuyTdFo5xxTSG4dxh8V5SnZskSYNmVmh2OZxrJG8+cs45l/A7Beeccwm/U3DOOZfwpOCccy7hScE551zCk4JzzrmEJwXnnHMJTwrOOecS/wf0rOKJMf1sTwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 929us/sample - loss: 1.4429 - acc: 0.6108\n",
      "Loss: 1.4428655887813706 Accuracy: 0.6107996\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6780 - acc: 0.5036\n",
      "Epoch 00001: val_loss improved from inf to 1.50669, saving model to model/checkpoint/1D_CNN_custom_3_BN_5_conv_checkpoint/001-1.5067.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 1.6781 - acc: 0.5036 - val_loss: 1.5067 - val_acc: 0.5288\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0418 - acc: 0.6892\n",
      "Epoch 00002: val_loss improved from 1.50669 to 1.20731, saving model to model/checkpoint/1D_CNN_custom_3_BN_5_conv_checkpoint/002-1.2073.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 1.0419 - acc: 0.6891 - val_loss: 1.2073 - val_acc: 0.6408\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7980 - acc: 0.7622\n",
      "Epoch 00003: val_loss improved from 1.20731 to 1.03114, saving model to model/checkpoint/1D_CNN_custom_3_BN_5_conv_checkpoint/003-1.0311.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.7981 - acc: 0.7622 - val_loss: 1.0311 - val_acc: 0.7000\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6211 - acc: 0.8134\n",
      "Epoch 00004: val_loss improved from 1.03114 to 0.99411, saving model to model/checkpoint/1D_CNN_custom_3_BN_5_conv_checkpoint/004-0.9941.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.6211 - acc: 0.8133 - val_loss: 0.9941 - val_acc: 0.7247\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4706 - acc: 0.8621\n",
      "Epoch 00005: val_loss did not improve from 0.99411\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4706 - acc: 0.8621 - val_loss: 1.0673 - val_acc: 0.6967\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3642 - acc: 0.8944\n",
      "Epoch 00006: val_loss did not improve from 0.99411\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3641 - acc: 0.8944 - val_loss: 1.1156 - val_acc: 0.7011\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2845 - acc: 0.9209\n",
      "Epoch 00007: val_loss did not improve from 0.99411\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2845 - acc: 0.9209 - val_loss: 1.0055 - val_acc: 0.7372\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2153 - acc: 0.9455\n",
      "Epoch 00008: val_loss improved from 0.99411 to 0.97113, saving model to model/checkpoint/1D_CNN_custom_3_BN_5_conv_checkpoint/008-0.9711.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.2158 - acc: 0.9454 - val_loss: 0.9711 - val_acc: 0.7414\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9552\n",
      "Epoch 00009: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1780 - acc: 0.9552 - val_loss: 1.0643 - val_acc: 0.7256\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9694\n",
      "Epoch 00010: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1377 - acc: 0.9694 - val_loss: 1.1213 - val_acc: 0.7223\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1348 - acc: 0.9696\n",
      "Epoch 00011: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1351 - acc: 0.9695 - val_loss: 1.2013 - val_acc: 0.6888\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9741\n",
      "Epoch 00012: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1191 - acc: 0.9741 - val_loss: 1.1912 - val_acc: 0.7060\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9781\n",
      "Epoch 00013: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1036 - acc: 0.9780 - val_loss: 1.0755 - val_acc: 0.7314\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9810\n",
      "Epoch 00014: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0927 - acc: 0.9809 - val_loss: 1.1485 - val_acc: 0.7403\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9892\n",
      "Epoch 00015: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0647 - acc: 0.9891 - val_loss: 1.4422 - val_acc: 0.6869\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9814\n",
      "Epoch 00016: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0849 - acc: 0.9814 - val_loss: 1.1906 - val_acc: 0.7235\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9862\n",
      "Epoch 00017: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0669 - acc: 0.9862 - val_loss: 1.1266 - val_acc: 0.7386\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9858\n",
      "Epoch 00018: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0693 - acc: 0.9858 - val_loss: 1.1282 - val_acc: 0.7435\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9939\n",
      "Epoch 00019: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0407 - acc: 0.9939 - val_loss: 1.2149 - val_acc: 0.7384\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9880\n",
      "Epoch 00020: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0599 - acc: 0.9879 - val_loss: 1.1925 - val_acc: 0.7303\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9865\n",
      "Epoch 00021: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0612 - acc: 0.9865 - val_loss: 1.2258 - val_acc: 0.7331\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9885\n",
      "Epoch 00022: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0550 - acc: 0.9885 - val_loss: 1.2930 - val_acc: 0.7275\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9931\n",
      "Epoch 00023: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0407 - acc: 0.9931 - val_loss: 1.5517 - val_acc: 0.6797\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9882\n",
      "Epoch 00024: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0550 - acc: 0.9882 - val_loss: 1.2239 - val_acc: 0.7417\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9937\n",
      "Epoch 00025: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0363 - acc: 0.9937 - val_loss: 1.3180 - val_acc: 0.7258\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9918\n",
      "Epoch 00026: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0413 - acc: 0.9917 - val_loss: 1.2635 - val_acc: 0.7377\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9910\n",
      "Epoch 00027: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0425 - acc: 0.9910 - val_loss: 1.3410 - val_acc: 0.7170\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9923\n",
      "Epoch 00028: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0388 - acc: 0.9922 - val_loss: 1.2517 - val_acc: 0.7405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9912\n",
      "Epoch 00029: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0422 - acc: 0.9912 - val_loss: 1.3711 - val_acc: 0.7170\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9939\n",
      "Epoch 00030: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0318 - acc: 0.9939 - val_loss: 1.3030 - val_acc: 0.7410\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9927\n",
      "Epoch 00031: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0347 - acc: 0.9927 - val_loss: 1.4465 - val_acc: 0.7102\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9944\n",
      "Epoch 00032: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0295 - acc: 0.9943 - val_loss: 1.5175 - val_acc: 0.7135\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9915\n",
      "Epoch 00033: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0384 - acc: 0.9915 - val_loss: 1.3987 - val_acc: 0.7342\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9895\n",
      "Epoch 00034: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0475 - acc: 0.9895 - val_loss: 1.3621 - val_acc: 0.7363\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9953\n",
      "Epoch 00035: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0279 - acc: 0.9952 - val_loss: 1.5977 - val_acc: 0.7035\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9875\n",
      "Epoch 00036: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0519 - acc: 0.9875 - val_loss: 1.3140 - val_acc: 0.7424\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9961\n",
      "Epoch 00037: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0231 - acc: 0.9960 - val_loss: 1.3235 - val_acc: 0.7435\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9941\n",
      "Epoch 00038: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0297 - acc: 0.9941 - val_loss: 1.3978 - val_acc: 0.7293\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9916\n",
      "Epoch 00039: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0380 - acc: 0.9915 - val_loss: 1.5067 - val_acc: 0.7207\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9882\n",
      "Epoch 00040: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0434 - acc: 0.9882 - val_loss: 1.3150 - val_acc: 0.7577\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9979\n",
      "Epoch 00041: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0179 - acc: 0.9979 - val_loss: 1.3286 - val_acc: 0.7440\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9966\n",
      "Epoch 00042: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0219 - acc: 0.9966 - val_loss: 1.4603 - val_acc: 0.7317\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9911\n",
      "Epoch 00043: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0401 - acc: 0.9911 - val_loss: 1.6315 - val_acc: 0.6993\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9957\n",
      "Epoch 00044: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0224 - acc: 0.9957 - val_loss: 1.3662 - val_acc: 0.7473\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9905\n",
      "Epoch 00045: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0384 - acc: 0.9905 - val_loss: 1.5379 - val_acc: 0.7244\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 00046: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0356 - acc: 0.9916 - val_loss: 1.3659 - val_acc: 0.7543\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9935\n",
      "Epoch 00047: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0293 - acc: 0.9934 - val_loss: 1.4075 - val_acc: 0.7445\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9923\n",
      "Epoch 00048: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0335 - acc: 0.9923 - val_loss: 1.4602 - val_acc: 0.7477\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9962\n",
      "Epoch 00049: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0222 - acc: 0.9961 - val_loss: 1.4824 - val_acc: 0.7335\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9964\n",
      "Epoch 00050: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0196 - acc: 0.9963 - val_loss: 1.3941 - val_acc: 0.7522\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9937\n",
      "Epoch 00051: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0292 - acc: 0.9937 - val_loss: 1.6485 - val_acc: 0.7093\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9975\n",
      "Epoch 00052: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0162 - acc: 0.9975 - val_loss: 1.6001 - val_acc: 0.7228\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9954\n",
      "Epoch 00053: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0226 - acc: 0.9953 - val_loss: 1.6653 - val_acc: 0.7067\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9893\n",
      "Epoch 00054: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0443 - acc: 0.9893 - val_loss: 1.6655 - val_acc: 0.7123\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9976\n",
      "Epoch 00055: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0160 - acc: 0.9975 - val_loss: 1.5693 - val_acc: 0.7289\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9931\n",
      "Epoch 00056: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0311 - acc: 0.9930 - val_loss: 1.4494 - val_acc: 0.7424\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9936\n",
      "Epoch 00057: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0260 - acc: 0.9936 - val_loss: 1.6947 - val_acc: 0.7100\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9910\n",
      "Epoch 00058: val_loss did not improve from 0.97113\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0372 - acc: 0.9910 - val_loss: 1.4463 - val_acc: 0.7473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_3_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 979us/sample - loss: 1.0920 - acc: 0.7007\n",
      "Loss: 1.0920349958158357 Accuracy: 0.70072687\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6809 - acc: 0.4862\n",
      "Epoch 00001: val_loss improved from inf to 1.41706, saving model to model/checkpoint/1D_CNN_custom_3_BN_6_conv_checkpoint/001-1.4171.hdf5\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 1.6808 - acc: 0.4862 - val_loss: 1.4171 - val_acc: 0.5316\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0358 - acc: 0.6897\n",
      "Epoch 00002: val_loss improved from 1.41706 to 0.99197, saving model to model/checkpoint/1D_CNN_custom_3_BN_6_conv_checkpoint/002-0.9920.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 1.0358 - acc: 0.6897 - val_loss: 0.9920 - val_acc: 0.7095\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8235 - acc: 0.7575\n",
      "Epoch 00003: val_loss improved from 0.99197 to 0.78642, saving model to model/checkpoint/1D_CNN_custom_3_BN_6_conv_checkpoint/003-0.7864.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.8235 - acc: 0.7575 - val_loss: 0.7864 - val_acc: 0.7717\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6950 - acc: 0.7983\n",
      "Epoch 00004: val_loss did not improve from 0.78642\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.6952 - acc: 0.7983 - val_loss: 0.7937 - val_acc: 0.7703\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6000 - acc: 0.8259\n",
      "Epoch 00005: val_loss improved from 0.78642 to 0.72623, saving model to model/checkpoint/1D_CNN_custom_3_BN_6_conv_checkpoint/005-0.7262.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.6000 - acc: 0.8259 - val_loss: 0.7262 - val_acc: 0.7780\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5218 - acc: 0.8496\n",
      "Epoch 00006: val_loss did not improve from 0.72623\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.5219 - acc: 0.8496 - val_loss: 0.7303 - val_acc: 0.7873\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4596 - acc: 0.8675\n",
      "Epoch 00007: val_loss improved from 0.72623 to 0.69218, saving model to model/checkpoint/1D_CNN_custom_3_BN_6_conv_checkpoint/007-0.6922.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.4596 - acc: 0.8675 - val_loss: 0.6922 - val_acc: 0.7969\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4015 - acc: 0.8830\n",
      "Epoch 00008: val_loss did not improve from 0.69218\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.4016 - acc: 0.8830 - val_loss: 0.8055 - val_acc: 0.7789\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3528 - acc: 0.8989\n",
      "Epoch 00009: val_loss improved from 0.69218 to 0.67583, saving model to model/checkpoint/1D_CNN_custom_3_BN_6_conv_checkpoint/009-0.6758.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3528 - acc: 0.8989 - val_loss: 0.6758 - val_acc: 0.8143\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3016 - acc: 0.9154\n",
      "Epoch 00010: val_loss did not improve from 0.67583\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3017 - acc: 0.9154 - val_loss: 0.7183 - val_acc: 0.7978\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2819 - acc: 0.9211\n",
      "Epoch 00011: val_loss improved from 0.67583 to 0.57749, saving model to model/checkpoint/1D_CNN_custom_3_BN_6_conv_checkpoint/011-0.5775.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.2821 - acc: 0.9211 - val_loss: 0.5775 - val_acc: 0.8374\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2402 - acc: 0.9333\n",
      "Epoch 00012: val_loss improved from 0.57749 to 0.57161, saving model to model/checkpoint/1D_CNN_custom_3_BN_6_conv_checkpoint/012-0.5716.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.2402 - acc: 0.9334 - val_loss: 0.5716 - val_acc: 0.8435\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2082 - acc: 0.9445\n",
      "Epoch 00013: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.2083 - acc: 0.9445 - val_loss: 0.6088 - val_acc: 0.8332\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1876 - acc: 0.9504\n",
      "Epoch 00014: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1877 - acc: 0.9503 - val_loss: 0.5961 - val_acc: 0.8360\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9561\n",
      "Epoch 00015: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1690 - acc: 0.9561 - val_loss: 0.5900 - val_acc: 0.8344\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9661\n",
      "Epoch 00016: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1376 - acc: 0.9661 - val_loss: 0.6107 - val_acc: 0.8388\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9686\n",
      "Epoch 00017: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1283 - acc: 0.9685 - val_loss: 0.6146 - val_acc: 0.8458\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9714\n",
      "Epoch 00018: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1218 - acc: 0.9714 - val_loss: 0.6960 - val_acc: 0.8060\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9781\n",
      "Epoch 00019: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0999 - acc: 0.9781 - val_loss: 0.5789 - val_acc: 0.8402\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9812\n",
      "Epoch 00020: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0882 - acc: 0.9812 - val_loss: 0.9177 - val_acc: 0.7764\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9822\n",
      "Epoch 00021: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0857 - acc: 0.9822 - val_loss: 0.7841 - val_acc: 0.8008\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9799\n",
      "Epoch 00022: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0887 - acc: 0.9799 - val_loss: 0.7435 - val_acc: 0.8204\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9792\n",
      "Epoch 00023: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0877 - acc: 0.9791 - val_loss: 0.6511 - val_acc: 0.8367\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9808\n",
      "Epoch 00024: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0840 - acc: 0.9807 - val_loss: 0.6266 - val_acc: 0.8423\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9862\n",
      "Epoch 00025: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0688 - acc: 0.9863 - val_loss: 0.6237 - val_acc: 0.8360\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9908\n",
      "Epoch 00026: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0534 - acc: 0.9907 - val_loss: 0.6208 - val_acc: 0.8414\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9861\n",
      "Epoch 00027: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0646 - acc: 0.9861 - val_loss: 0.6306 - val_acc: 0.8484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9878\n",
      "Epoch 00028: val_loss did not improve from 0.57161\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0598 - acc: 0.9878 - val_loss: 0.7107 - val_acc: 0.8295\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9856\n",
      "Epoch 00029: val_loss improved from 0.57161 to 0.53848, saving model to model/checkpoint/1D_CNN_custom_3_BN_6_conv_checkpoint/029-0.5385.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0651 - acc: 0.9856 - val_loss: 0.5385 - val_acc: 0.8647\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9932\n",
      "Epoch 00030: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0398 - acc: 0.9932 - val_loss: 0.6666 - val_acc: 0.8374\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9855\n",
      "Epoch 00031: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0629 - acc: 0.9855 - val_loss: 0.8474 - val_acc: 0.8127\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9891\n",
      "Epoch 00032: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0522 - acc: 0.9891 - val_loss: 0.6358 - val_acc: 0.8421\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9898\n",
      "Epoch 00033: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0486 - acc: 0.9898 - val_loss: 0.7733 - val_acc: 0.8244\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9897\n",
      "Epoch 00034: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0492 - acc: 0.9897 - val_loss: 0.6446 - val_acc: 0.8425\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9956\n",
      "Epoch 00035: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0311 - acc: 0.9956 - val_loss: 0.5730 - val_acc: 0.8560\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9945\n",
      "Epoch 00036: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0349 - acc: 0.9945 - val_loss: 0.6488 - val_acc: 0.8532\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9949\n",
      "Epoch 00037: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0314 - acc: 0.9949 - val_loss: 0.7359 - val_acc: 0.8381\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9880\n",
      "Epoch 00038: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0519 - acc: 0.9880 - val_loss: 0.6396 - val_acc: 0.8514\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9947\n",
      "Epoch 00039: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0310 - acc: 0.9946 - val_loss: 0.7323 - val_acc: 0.8344\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9890\n",
      "Epoch 00040: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0485 - acc: 0.9890 - val_loss: 0.7377 - val_acc: 0.8321\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9945\n",
      "Epoch 00041: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0317 - acc: 0.9945 - val_loss: 0.6609 - val_acc: 0.8474\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9962\n",
      "Epoch 00042: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0260 - acc: 0.9963 - val_loss: 0.6640 - val_acc: 0.8516\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9946\n",
      "Epoch 00043: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0300 - acc: 0.9946 - val_loss: 0.8757 - val_acc: 0.8169\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9907\n",
      "Epoch 00044: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0429 - acc: 0.9906 - val_loss: 0.8294 - val_acc: 0.8267\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9885\n",
      "Epoch 00045: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0492 - acc: 0.9884 - val_loss: 0.6479 - val_acc: 0.8498\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9927\n",
      "Epoch 00046: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0350 - acc: 0.9927 - val_loss: 0.6097 - val_acc: 0.8621\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9959\n",
      "Epoch 00047: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0244 - acc: 0.9959 - val_loss: 0.7334 - val_acc: 0.8374\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9899\n",
      "Epoch 00048: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0426 - acc: 0.9899 - val_loss: 0.6063 - val_acc: 0.8637\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9980\n",
      "Epoch 00049: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0183 - acc: 0.9979 - val_loss: 0.6717 - val_acc: 0.8581\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9918\n",
      "Epoch 00050: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0371 - acc: 0.9917 - val_loss: 0.6982 - val_acc: 0.8470\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9909\n",
      "Epoch 00051: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0391 - acc: 0.9908 - val_loss: 0.7349 - val_acc: 0.8421\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9914\n",
      "Epoch 00052: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0405 - acc: 0.9913 - val_loss: 0.5967 - val_acc: 0.8679\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9948\n",
      "Epoch 00053: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0268 - acc: 0.9948 - val_loss: 0.5955 - val_acc: 0.8712\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9979\n",
      "Epoch 00054: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0160 - acc: 0.9979 - val_loss: 0.6813 - val_acc: 0.8479\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9963\n",
      "Epoch 00055: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0225 - acc: 0.9963 - val_loss: 1.0081 - val_acc: 0.7971\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9871\n",
      "Epoch 00056: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0523 - acc: 0.9871 - val_loss: 0.7496 - val_acc: 0.8404\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9908\n",
      "Epoch 00057: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0398 - acc: 0.9907 - val_loss: 0.7794 - val_acc: 0.8425\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9964\n",
      "Epoch 00058: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0213 - acc: 0.9964 - val_loss: 0.6161 - val_acc: 0.8689\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9964\n",
      "Epoch 00059: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0208 - acc: 0.9964 - val_loss: 0.7320 - val_acc: 0.8581\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9904\n",
      "Epoch 00060: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0385 - acc: 0.9903 - val_loss: 0.6678 - val_acc: 0.8605\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9946\n",
      "Epoch 00061: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0271 - acc: 0.9946 - val_loss: 0.6729 - val_acc: 0.8560\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9980\n",
      "Epoch 00062: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0151 - acc: 0.9980 - val_loss: 0.7909 - val_acc: 0.8397\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9982\n",
      "Epoch 00063: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0145 - acc: 0.9982 - val_loss: 0.8697 - val_acc: 0.8351\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9952\n",
      "Epoch 00064: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0243 - acc: 0.9951 - val_loss: 1.1763 - val_acc: 0.7673\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9907\n",
      "Epoch 00065: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0380 - acc: 0.9907 - val_loss: 0.7692 - val_acc: 0.8358\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9933\n",
      "Epoch 00066: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0308 - acc: 0.9932 - val_loss: 0.6551 - val_acc: 0.8633\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9960\n",
      "Epoch 00067: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0224 - acc: 0.9960 - val_loss: 0.6637 - val_acc: 0.8689\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9952\n",
      "Epoch 00068: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0244 - acc: 0.9952 - val_loss: 0.6588 - val_acc: 0.8642\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9974\n",
      "Epoch 00069: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0172 - acc: 0.9974 - val_loss: 0.9386 - val_acc: 0.8048\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9967\n",
      "Epoch 00070: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0203 - acc: 0.9967 - val_loss: 0.7140 - val_acc: 0.8551\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9966\n",
      "Epoch 00071: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0199 - acc: 0.9966 - val_loss: 0.6952 - val_acc: 0.8519\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9979\n",
      "Epoch 00072: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0155 - acc: 0.9979 - val_loss: 0.6356 - val_acc: 0.8649\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9939\n",
      "Epoch 00073: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0277 - acc: 0.9939 - val_loss: 0.8063 - val_acc: 0.8360\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9908\n",
      "Epoch 00074: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0369 - acc: 0.9908 - val_loss: 0.7999 - val_acc: 0.8355\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9933\n",
      "Epoch 00075: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0297 - acc: 0.9933 - val_loss: 0.7196 - val_acc: 0.8502\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9966\n",
      "Epoch 00076: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0189 - acc: 0.9965 - val_loss: 0.6347 - val_acc: 0.8635\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9910\n",
      "Epoch 00077: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0374 - acc: 0.9910 - val_loss: 0.6811 - val_acc: 0.8616\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9986\n",
      "Epoch 00078: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0131 - acc: 0.9986 - val_loss: 0.6078 - val_acc: 0.8765\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9990\n",
      "Epoch 00079: val_loss did not improve from 0.53848\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0122 - acc: 0.9989 - val_loss: 0.7786 - val_acc: 0.8474\n",
      "\n",
      "1D_CNN_custom_3_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 992us/sample - loss: 0.6660 - acc: 0.8336\n",
      "Loss: 0.6659552693738373 Accuracy: 0.83364487\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5492 - acc: 0.5335\n",
      "Epoch 00001: val_loss improved from inf to 1.26278, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/001-1.2628.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 1.5494 - acc: 0.5334 - val_loss: 1.2628 - val_acc: 0.6052\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8123 - acc: 0.7654\n",
      "Epoch 00002: val_loss improved from 1.26278 to 0.69695, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/002-0.6969.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.8125 - acc: 0.7653 - val_loss: 0.6969 - val_acc: 0.8025\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5872 - acc: 0.8342\n",
      "Epoch 00003: val_loss improved from 0.69695 to 0.64261, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/003-0.6426.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.5872 - acc: 0.8342 - val_loss: 0.6426 - val_acc: 0.8192\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4588 - acc: 0.8701\n",
      "Epoch 00004: val_loss improved from 0.64261 to 0.50405, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/004-0.5040.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.4589 - acc: 0.8701 - val_loss: 0.5040 - val_acc: 0.8595\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3807 - acc: 0.8919\n",
      "Epoch 00005: val_loss improved from 0.50405 to 0.47464, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/005-0.4746.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.3809 - acc: 0.8919 - val_loss: 0.4746 - val_acc: 0.8682\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.9077\n",
      "Epoch 00006: val_loss improved from 0.47464 to 0.40415, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/006-0.4041.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.3237 - acc: 0.9077 - val_loss: 0.4041 - val_acc: 0.8875\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2760 - acc: 0.9217\n",
      "Epoch 00007: val_loss improved from 0.40415 to 0.36807, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/007-0.3681.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.2760 - acc: 0.9217 - val_loss: 0.3681 - val_acc: 0.8940\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2398 - acc: 0.9325\n",
      "Epoch 00008: val_loss did not improve from 0.36807\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.2399 - acc: 0.9325 - val_loss: 0.4847 - val_acc: 0.8623\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2085 - acc: 0.9416\n",
      "Epoch 00009: val_loss improved from 0.36807 to 0.33348, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/009-0.3335.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.2086 - acc: 0.9416 - val_loss: 0.3335 - val_acc: 0.9010\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1851 - acc: 0.9488\n",
      "Epoch 00010: val_loss did not improve from 0.33348\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1852 - acc: 0.9488 - val_loss: 0.3779 - val_acc: 0.8935\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1642 - acc: 0.9547\n",
      "Epoch 00011: val_loss improved from 0.33348 to 0.32885, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/011-0.3288.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1642 - acc: 0.9547 - val_loss: 0.3288 - val_acc: 0.9136\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9624\n",
      "Epoch 00012: val_loss did not improve from 0.32885\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1386 - acc: 0.9624 - val_loss: 0.3453 - val_acc: 0.9012\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1539 - acc: 0.9579\n",
      "Epoch 00013: val_loss did not improve from 0.32885\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1539 - acc: 0.9579 - val_loss: 0.3522 - val_acc: 0.8973\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9707\n",
      "Epoch 00014: val_loss improved from 0.32885 to 0.29151, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/014-0.2915.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.1077 - acc: 0.9706 - val_loss: 0.2915 - val_acc: 0.9164\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9752\n",
      "Epoch 00015: val_loss did not improve from 0.29151\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0977 - acc: 0.9752 - val_loss: 0.3277 - val_acc: 0.9099\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9776\n",
      "Epoch 00016: val_loss did not improve from 0.29151\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0885 - acc: 0.9776 - val_loss: 0.3256 - val_acc: 0.9094\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9807\n",
      "Epoch 00017: val_loss did not improve from 0.29151\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0766 - acc: 0.9807 - val_loss: 0.3143 - val_acc: 0.9103\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9807\n",
      "Epoch 00018: val_loss did not improve from 0.29151\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0750 - acc: 0.9806 - val_loss: 0.3334 - val_acc: 0.9129\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9819\n",
      "Epoch 00019: val_loss improved from 0.29151 to 0.28051, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/019-0.2805.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0702 - acc: 0.9819 - val_loss: 0.2805 - val_acc: 0.9276\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9876\n",
      "Epoch 00020: val_loss did not improve from 0.28051\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0544 - acc: 0.9876 - val_loss: 0.4173 - val_acc: 0.8963\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9899\n",
      "Epoch 00021: val_loss did not improve from 0.28051\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0471 - acc: 0.9899 - val_loss: 0.3000 - val_acc: 0.9215\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9871\n",
      "Epoch 00022: val_loss did not improve from 0.28051\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0542 - acc: 0.9870 - val_loss: 0.2916 - val_acc: 0.9171\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9901\n",
      "Epoch 00023: val_loss did not improve from 0.28051\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0448 - acc: 0.9900 - val_loss: 0.3199 - val_acc: 0.9192\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9891\n",
      "Epoch 00024: val_loss did not improve from 0.28051\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0458 - acc: 0.9891 - val_loss: 0.3695 - val_acc: 0.9003\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9884\n",
      "Epoch 00025: val_loss did not improve from 0.28051\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0463 - acc: 0.9884 - val_loss: 0.2918 - val_acc: 0.9276\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9891\n",
      "Epoch 00026: val_loss improved from 0.28051 to 0.27991, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/026-0.2799.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0448 - acc: 0.9891 - val_loss: 0.2799 - val_acc: 0.9290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9923\n",
      "Epoch 00027: val_loss improved from 0.27991 to 0.27921, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/027-0.2792.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0352 - acc: 0.9923 - val_loss: 0.2792 - val_acc: 0.9283\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9954\n",
      "Epoch 00028: val_loss improved from 0.27921 to 0.27402, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/028-0.2740.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0254 - acc: 0.9954 - val_loss: 0.2740 - val_acc: 0.9299\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9942\n",
      "Epoch 00029: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0278 - acc: 0.9941 - val_loss: 0.3239 - val_acc: 0.9250\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9882\n",
      "Epoch 00030: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0455 - acc: 0.9882 - val_loss: 0.3112 - val_acc: 0.9194\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9948\n",
      "Epoch 00031: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0258 - acc: 0.9947 - val_loss: 0.3660 - val_acc: 0.9161\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9898\n",
      "Epoch 00032: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0415 - acc: 0.9898 - val_loss: 0.4466 - val_acc: 0.8931\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 00033: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0351 - acc: 0.9917 - val_loss: 0.2990 - val_acc: 0.9203\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9971\n",
      "Epoch 00034: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0181 - acc: 0.9971 - val_loss: 0.3558 - val_acc: 0.9185\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9947\n",
      "Epoch 00035: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0235 - acc: 0.9947 - val_loss: 0.3080 - val_acc: 0.9262\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9927\n",
      "Epoch 00036: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0282 - acc: 0.9926 - val_loss: 0.3409 - val_acc: 0.9192\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9903\n",
      "Epoch 00037: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0378 - acc: 0.9903 - val_loss: 0.3150 - val_acc: 0.9243\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9978\n",
      "Epoch 00038: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0144 - acc: 0.9977 - val_loss: 0.2840 - val_acc: 0.9331\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9928\n",
      "Epoch 00039: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0297 - acc: 0.9927 - val_loss: 0.3505 - val_acc: 0.9208\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9919\n",
      "Epoch 00040: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0313 - acc: 0.9919 - val_loss: 0.3133 - val_acc: 0.9220\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9965\n",
      "Epoch 00041: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0174 - acc: 0.9964 - val_loss: 0.4018 - val_acc: 0.9180\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9911\n",
      "Epoch 00042: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0333 - acc: 0.9911 - val_loss: 0.2975 - val_acc: 0.9262\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9958\n",
      "Epoch 00043: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0206 - acc: 0.9958 - val_loss: 0.2866 - val_acc: 0.9352\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9987\n",
      "Epoch 00044: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0097 - acc: 0.9987 - val_loss: 0.4344 - val_acc: 0.8996\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9918\n",
      "Epoch 00045: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0319 - acc: 0.9918 - val_loss: 0.3206 - val_acc: 0.9287\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9941\n",
      "Epoch 00046: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0240 - acc: 0.9941 - val_loss: 0.3001 - val_acc: 0.9292\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9987\n",
      "Epoch 00047: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0090 - acc: 0.9987 - val_loss: 0.2839 - val_acc: 0.9371\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9974\n",
      "Epoch 00048: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0130 - acc: 0.9974 - val_loss: 0.3744 - val_acc: 0.9113\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9913\n",
      "Epoch 00049: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0312 - acc: 0.9913 - val_loss: 0.2980 - val_acc: 0.9266\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9937\n",
      "Epoch 00050: val_loss did not improve from 0.27402\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0245 - acc: 0.9936 - val_loss: 0.3649 - val_acc: 0.9187\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9960\n",
      "Epoch 00051: val_loss improved from 0.27402 to 0.26672, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/051-0.2667.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0175 - acc: 0.9960 - val_loss: 0.2667 - val_acc: 0.9392\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9986\n",
      "Epoch 00052: val_loss did not improve from 0.26672\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0088 - acc: 0.9986 - val_loss: 0.2827 - val_acc: 0.9338\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9935\n",
      "Epoch 00053: val_loss did not improve from 0.26672\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0248 - acc: 0.9935 - val_loss: 0.3050 - val_acc: 0.9315\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9922\n",
      "Epoch 00054: val_loss did not improve from 0.26672\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0311 - acc: 0.9921 - val_loss: 0.3417 - val_acc: 0.9220\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9951\n",
      "Epoch 00055: val_loss did not improve from 0.26672\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0198 - acc: 0.9951 - val_loss: 0.2908 - val_acc: 0.9348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9974\n",
      "Epoch 00056: val_loss did not improve from 0.26672\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0130 - acc: 0.9974 - val_loss: 0.2911 - val_acc: 0.9336\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9948\n",
      "Epoch 00057: val_loss did not improve from 0.26672\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0199 - acc: 0.9948 - val_loss: 0.2748 - val_acc: 0.9352\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9990\n",
      "Epoch 00058: val_loss did not improve from 0.26672\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0066 - acc: 0.9990 - val_loss: 0.3062 - val_acc: 0.9292\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9923\n",
      "Epoch 00059: val_loss did not improve from 0.26672\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0290 - acc: 0.9923 - val_loss: 0.2738 - val_acc: 0.9413\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9931\n",
      "Epoch 00060: val_loss did not improve from 0.26672\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0259 - acc: 0.9931 - val_loss: 0.3285 - val_acc: 0.9306\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9987\n",
      "Epoch 00061: val_loss did not improve from 0.26672\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0078 - acc: 0.9987 - val_loss: 0.2713 - val_acc: 0.9394\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9990\n",
      "Epoch 00062: val_loss did not improve from 0.26672\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0066 - acc: 0.9990 - val_loss: 0.3062 - val_acc: 0.9317\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9952\n",
      "Epoch 00063: val_loss improved from 0.26672 to 0.25585, saving model to model/checkpoint/1D_CNN_custom_3_BN_7_conv_checkpoint/063-0.2558.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0185 - acc: 0.9952 - val_loss: 0.2558 - val_acc: 0.9397\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9989\n",
      "Epoch 00064: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0070 - acc: 0.9989 - val_loss: 0.2836 - val_acc: 0.9317\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9980\n",
      "Epoch 00065: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0095 - acc: 0.9980 - val_loss: 0.3159 - val_acc: 0.9322\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9980\n",
      "Epoch 00066: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0101 - acc: 0.9979 - val_loss: 0.4929 - val_acc: 0.8982\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9908\n",
      "Epoch 00067: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0312 - acc: 0.9908 - val_loss: 0.2774 - val_acc: 0.9392\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9983\n",
      "Epoch 00068: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0086 - acc: 0.9983 - val_loss: 0.2748 - val_acc: 0.9390\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9992\n",
      "Epoch 00069: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0059 - acc: 0.9992 - val_loss: 0.3066 - val_acc: 0.9271\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9921\n",
      "Epoch 00070: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0293 - acc: 0.9921 - val_loss: 0.3183 - val_acc: 0.9313\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9993\n",
      "Epoch 00071: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0054 - acc: 0.9993 - val_loss: 0.3387 - val_acc: 0.9243\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9957\n",
      "Epoch 00072: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0167 - acc: 0.9957 - val_loss: 0.3112 - val_acc: 0.9276\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9961\n",
      "Epoch 00073: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0142 - acc: 0.9961 - val_loss: 0.3135 - val_acc: 0.9278\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9990\n",
      "Epoch 00074: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0062 - acc: 0.9990 - val_loss: 0.2950 - val_acc: 0.9313\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9940\n",
      "Epoch 00075: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0212 - acc: 0.9940 - val_loss: 0.3048 - val_acc: 0.9315\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9989\n",
      "Epoch 00076: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0075 - acc: 0.9989 - val_loss: 0.2939 - val_acc: 0.9387\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9989\n",
      "Epoch 00077: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0061 - acc: 0.9989 - val_loss: 0.3450 - val_acc: 0.9273\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9927\n",
      "Epoch 00078: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0251 - acc: 0.9927 - val_loss: 0.3178 - val_acc: 0.9299\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9958\n",
      "Epoch 00079: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0161 - acc: 0.9958 - val_loss: 0.3181 - val_acc: 0.9308\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9962\n",
      "Epoch 00080: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0143 - acc: 0.9962 - val_loss: 0.2934 - val_acc: 0.9401\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9944\n",
      "Epoch 00081: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0207 - acc: 0.9944 - val_loss: 0.2932 - val_acc: 0.9418\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9979\n",
      "Epoch 00082: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0097 - acc: 0.9979 - val_loss: 0.2713 - val_acc: 0.9441\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9997\n",
      "Epoch 00083: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0033 - acc: 0.9997 - val_loss: 0.2766 - val_acc: 0.9413\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9954\n",
      "Epoch 00084: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0182 - acc: 0.9954 - val_loss: 0.3276 - val_acc: 0.9352\n",
      "Epoch 85/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9993\n",
      "Epoch 00085: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0050 - acc: 0.9993 - val_loss: 0.2862 - val_acc: 0.9399\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9972\n",
      "Epoch 00086: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0113 - acc: 0.9972 - val_loss: 0.3116 - val_acc: 0.9327\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9951\n",
      "Epoch 00087: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0178 - acc: 0.9951 - val_loss: 0.2898 - val_acc: 0.9390\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9994\n",
      "Epoch 00088: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0041 - acc: 0.9994 - val_loss: 0.3187 - val_acc: 0.9341\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9991\n",
      "Epoch 00089: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0057 - acc: 0.9990 - val_loss: 0.3542 - val_acc: 0.9313\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9956\n",
      "Epoch 00090: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0165 - acc: 0.9956 - val_loss: 0.3110 - val_acc: 0.9331\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 00091: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0035 - acc: 0.9996 - val_loss: 0.3179 - val_acc: 0.9355\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9976\n",
      "Epoch 00092: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0100 - acc: 0.9976 - val_loss: 0.3869 - val_acc: 0.9182\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9942\n",
      "Epoch 00093: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0208 - acc: 0.9942 - val_loss: 0.3033 - val_acc: 0.9397\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9991\n",
      "Epoch 00094: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0054 - acc: 0.9991 - val_loss: 0.2885 - val_acc: 0.9425\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9994\n",
      "Epoch 00095: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0042 - acc: 0.9994 - val_loss: 0.3740 - val_acc: 0.9224\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9992\n",
      "Epoch 00096: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0048 - acc: 0.9992 - val_loss: 0.3296 - val_acc: 0.9327\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9936\n",
      "Epoch 00097: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0227 - acc: 0.9936 - val_loss: 0.3804 - val_acc: 0.9271\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9964\n",
      "Epoch 00098: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0134 - acc: 0.9964 - val_loss: 0.3020 - val_acc: 0.9350\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9970\n",
      "Epoch 00099: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0109 - acc: 0.9969 - val_loss: 0.2822 - val_acc: 0.9413\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9978\n",
      "Epoch 00100: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0088 - acc: 0.9977 - val_loss: 0.3177 - val_acc: 0.9338\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9957\n",
      "Epoch 00101: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0162 - acc: 0.9957 - val_loss: 0.3568 - val_acc: 0.9269\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9992\n",
      "Epoch 00102: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0052 - acc: 0.9992 - val_loss: 0.3422 - val_acc: 0.9341\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9957\n",
      "Epoch 00103: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0155 - acc: 0.9957 - val_loss: 0.2788 - val_acc: 0.9425\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 00104: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0029 - acc: 0.9998 - val_loss: 0.2653 - val_acc: 0.9443\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9995\n",
      "Epoch 00105: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0033 - acc: 0.9995 - val_loss: 0.2908 - val_acc: 0.9427\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9979\n",
      "Epoch 00106: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0087 - acc: 0.9979 - val_loss: 0.4111 - val_acc: 0.9234\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9947\n",
      "Epoch 00107: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0192 - acc: 0.9947 - val_loss: 0.3028 - val_acc: 0.9397\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9969\n",
      "Epoch 00108: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0131 - acc: 0.9968 - val_loss: 0.4933 - val_acc: 0.9075\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9958\n",
      "Epoch 00109: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0146 - acc: 0.9958 - val_loss: 0.2839 - val_acc: 0.9436\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9969\n",
      "Epoch 00110: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0110 - acc: 0.9969 - val_loss: 0.3330 - val_acc: 0.9371\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9991\n",
      "Epoch 00111: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0050 - acc: 0.9991 - val_loss: 0.2813 - val_acc: 0.9471\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9978\n",
      "Epoch 00112: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0093 - acc: 0.9978 - val_loss: 0.2868 - val_acc: 0.9453\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9994\n",
      "Epoch 00113: val_loss did not improve from 0.25585\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0037 - acc: 0.9994 - val_loss: 0.3223 - val_acc: 0.9373\n",
      "\n",
      "1D_CNN_custom_3_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.3075 - acc: 0.9259\n",
      "Loss: 0.3074763776527511 Accuracy: 0.9258567\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2694 - acc: 0.6167\n",
      "Epoch 00001: val_loss improved from inf to 0.93888, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/001-0.9389.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 1.2694 - acc: 0.6167 - val_loss: 0.9389 - val_acc: 0.7310\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5333 - acc: 0.8477\n",
      "Epoch 00002: val_loss improved from 0.93888 to 0.44495, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/002-0.4450.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.5335 - acc: 0.8477 - val_loss: 0.4450 - val_acc: 0.8754\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3635 - acc: 0.8960\n",
      "Epoch 00003: val_loss improved from 0.44495 to 0.37817, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/003-0.3782.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.3635 - acc: 0.8960 - val_loss: 0.3782 - val_acc: 0.8863\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2739 - acc: 0.9232\n",
      "Epoch 00004: val_loss improved from 0.37817 to 0.27455, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/004-0.2746.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.2739 - acc: 0.9231 - val_loss: 0.2746 - val_acc: 0.9157\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2191 - acc: 0.9382\n",
      "Epoch 00005: val_loss improved from 0.27455 to 0.27048, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/005-0.2705.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.2191 - acc: 0.9382 - val_loss: 0.2705 - val_acc: 0.9182\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1849 - acc: 0.9469\n",
      "Epoch 00006: val_loss improved from 0.27048 to 0.24421, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/006-0.2442.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1849 - acc: 0.9469 - val_loss: 0.2442 - val_acc: 0.9320\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9571\n",
      "Epoch 00007: val_loss did not improve from 0.24421\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1549 - acc: 0.9572 - val_loss: 0.3154 - val_acc: 0.9019\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9652\n",
      "Epoch 00008: val_loss improved from 0.24421 to 0.19598, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/008-0.1960.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1250 - acc: 0.9652 - val_loss: 0.1960 - val_acc: 0.9422\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9713\n",
      "Epoch 00009: val_loss did not improve from 0.19598\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1062 - acc: 0.9713 - val_loss: 0.2163 - val_acc: 0.9401\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9757\n",
      "Epoch 00010: val_loss did not improve from 0.19598\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0916 - acc: 0.9757 - val_loss: 0.2001 - val_acc: 0.9385\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9788\n",
      "Epoch 00011: val_loss did not improve from 0.19598\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0796 - acc: 0.9788 - val_loss: 0.2156 - val_acc: 0.9390\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9780\n",
      "Epoch 00012: val_loss did not improve from 0.19598\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0784 - acc: 0.9779 - val_loss: 0.2361 - val_acc: 0.9320\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9781\n",
      "Epoch 00013: val_loss improved from 0.19598 to 0.18816, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/013-0.1882.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0789 - acc: 0.9781 - val_loss: 0.1882 - val_acc: 0.9448\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9899\n",
      "Epoch 00014: val_loss did not improve from 0.18816\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0458 - acc: 0.9899 - val_loss: 0.2145 - val_acc: 0.9343\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9910\n",
      "Epoch 00015: val_loss did not improve from 0.18816\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0427 - acc: 0.9910 - val_loss: 0.1984 - val_acc: 0.9443\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9908\n",
      "Epoch 00016: val_loss improved from 0.18816 to 0.18232, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/016-0.1823.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0401 - acc: 0.9907 - val_loss: 0.1823 - val_acc: 0.9474\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9897\n",
      "Epoch 00017: val_loss did not improve from 0.18232\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0433 - acc: 0.9896 - val_loss: 0.1839 - val_acc: 0.9476\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9869\n",
      "Epoch 00018: val_loss did not improve from 0.18232\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0518 - acc: 0.9869 - val_loss: 0.2210 - val_acc: 0.9359\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9958\n",
      "Epoch 00019: val_loss did not improve from 0.18232\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0231 - acc: 0.9957 - val_loss: 0.1974 - val_acc: 0.9422\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9914\n",
      "Epoch 00020: val_loss improved from 0.18232 to 0.16309, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/020-0.1631.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0349 - acc: 0.9914 - val_loss: 0.1631 - val_acc: 0.9560\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9957\n",
      "Epoch 00021: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0220 - acc: 0.9957 - val_loss: 0.1994 - val_acc: 0.9448\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 00022: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0330 - acc: 0.9917 - val_loss: 0.1815 - val_acc: 0.9502\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9968\n",
      "Epoch 00023: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0168 - acc: 0.9968 - val_loss: 0.1799 - val_acc: 0.9485\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9956\n",
      "Epoch 00024: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0210 - acc: 0.9956 - val_loss: 0.1949 - val_acc: 0.9490\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9957\n",
      "Epoch 00025: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0205 - acc: 0.9957 - val_loss: 0.2061 - val_acc: 0.9397\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9964\n",
      "Epoch 00026: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0174 - acc: 0.9963 - val_loss: 0.2217 - val_acc: 0.9443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9890\n",
      "Epoch 00027: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0384 - acc: 0.9890 - val_loss: 0.1782 - val_acc: 0.9495\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9976\n",
      "Epoch 00028: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0139 - acc: 0.9975 - val_loss: 0.1748 - val_acc: 0.9525\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9935\n",
      "Epoch 00029: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0250 - acc: 0.9935 - val_loss: 0.1704 - val_acc: 0.9553\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9982\n",
      "Epoch 00030: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0107 - acc: 0.9982 - val_loss: 0.2015 - val_acc: 0.9471\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9967\n",
      "Epoch 00031: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0152 - acc: 0.9967 - val_loss: 0.2497 - val_acc: 0.9336\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9973\n",
      "Epoch 00032: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0136 - acc: 0.9973 - val_loss: 0.2194 - val_acc: 0.9441\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9940\n",
      "Epoch 00033: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0249 - acc: 0.9940 - val_loss: 0.1645 - val_acc: 0.9588\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9949\n",
      "Epoch 00034: val_loss did not improve from 0.16309\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0212 - acc: 0.9949 - val_loss: 0.1836 - val_acc: 0.9553\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9971\n",
      "Epoch 00035: val_loss improved from 0.16309 to 0.16082, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/035-0.1608.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0130 - acc: 0.9971 - val_loss: 0.1608 - val_acc: 0.9578\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9982\n",
      "Epoch 00036: val_loss did not improve from 0.16082\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0100 - acc: 0.9982 - val_loss: 0.2141 - val_acc: 0.9455\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9947\n",
      "Epoch 00037: val_loss improved from 0.16082 to 0.14822, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/037-0.1482.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0221 - acc: 0.9947 - val_loss: 0.1482 - val_acc: 0.9609\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9990\n",
      "Epoch 00038: val_loss did not improve from 0.14822\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0069 - acc: 0.9990 - val_loss: 0.1876 - val_acc: 0.9567\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9976\n",
      "Epoch 00039: val_loss did not improve from 0.14822\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0119 - acc: 0.9976 - val_loss: 0.1769 - val_acc: 0.9527\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9973\n",
      "Epoch 00040: val_loss did not improve from 0.14822\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0123 - acc: 0.9973 - val_loss: 0.1748 - val_acc: 0.9562\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9985\n",
      "Epoch 00041: val_loss did not improve from 0.14822\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0085 - acc: 0.9984 - val_loss: 0.2132 - val_acc: 0.9478\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9913\n",
      "Epoch 00042: val_loss did not improve from 0.14822\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0307 - acc: 0.9913 - val_loss: 0.1710 - val_acc: 0.9534\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9984\n",
      "Epoch 00043: val_loss improved from 0.14822 to 0.14779, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/043-0.1478.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0090 - acc: 0.9984 - val_loss: 0.1478 - val_acc: 0.9616\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9992\n",
      "Epoch 00044: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0053 - acc: 0.9992 - val_loss: 0.1743 - val_acc: 0.9576\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9988\n",
      "Epoch 00045: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0068 - acc: 0.9988 - val_loss: 0.1674 - val_acc: 0.9529\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9977\n",
      "Epoch 00046: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0112 - acc: 0.9977 - val_loss: 0.3028 - val_acc: 0.9304\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9972\n",
      "Epoch 00047: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0125 - acc: 0.9972 - val_loss: 0.1832 - val_acc: 0.9504\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9949\n",
      "Epoch 00048: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0188 - acc: 0.9949 - val_loss: 0.1585 - val_acc: 0.9574\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 00049: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0036 - acc: 0.9996 - val_loss: 0.1752 - val_acc: 0.9581\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9971\n",
      "Epoch 00050: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0121 - acc: 0.9971 - val_loss: 0.1592 - val_acc: 0.9569\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9993\n",
      "Epoch 00051: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0046 - acc: 0.9993 - val_loss: 0.1983 - val_acc: 0.9534\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9969\n",
      "Epoch 00052: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0119 - acc: 0.9969 - val_loss: 0.1812 - val_acc: 0.9555\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9985\n",
      "Epoch 00053: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0074 - acc: 0.9985 - val_loss: 0.2077 - val_acc: 0.9522\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9931\n",
      "Epoch 00054: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0240 - acc: 0.9930 - val_loss: 0.1915 - val_acc: 0.9564\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9976\n",
      "Epoch 00055: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0100 - acc: 0.9976 - val_loss: 0.1560 - val_acc: 0.9592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9986\n",
      "Epoch 00056: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0075 - acc: 0.9986 - val_loss: 0.1496 - val_acc: 0.9611\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9996\n",
      "Epoch 00057: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0027 - acc: 0.9996 - val_loss: 0.1688 - val_acc: 0.9571\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9954\n",
      "Epoch 00058: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0177 - acc: 0.9954 - val_loss: 0.1779 - val_acc: 0.9555\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9994\n",
      "Epoch 00059: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0035 - acc: 0.9994 - val_loss: 0.2032 - val_acc: 0.9525\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9975\n",
      "Epoch 00060: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0112 - acc: 0.9974 - val_loss: 0.1876 - val_acc: 0.9569\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9944\n",
      "Epoch 00061: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0197 - acc: 0.9943 - val_loss: 0.1722 - val_acc: 0.9569\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9983\n",
      "Epoch 00062: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0078 - acc: 0.9983 - val_loss: 0.1581 - val_acc: 0.9609\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 00063: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0028 - acc: 0.9997 - val_loss: 0.1830 - val_acc: 0.9592\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9995\n",
      "Epoch 00064: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0032 - acc: 0.9995 - val_loss: 0.1717 - val_acc: 0.9592\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9972\n",
      "Epoch 00065: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0105 - acc: 0.9972 - val_loss: 0.1932 - val_acc: 0.9520\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9993\n",
      "Epoch 00066: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0042 - acc: 0.9993 - val_loss: 0.1533 - val_acc: 0.9620\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9993\n",
      "Epoch 00067: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0035 - acc: 0.9993 - val_loss: 0.1951 - val_acc: 0.9536\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9961\n",
      "Epoch 00068: val_loss did not improve from 0.14779\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0131 - acc: 0.9961 - val_loss: 0.1727 - val_acc: 0.9550\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9961\n",
      "Epoch 00069: val_loss improved from 0.14779 to 0.14726, saving model to model/checkpoint/1D_CNN_custom_3_BN_8_conv_checkpoint/069-0.1473.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0151 - acc: 0.9961 - val_loss: 0.1473 - val_acc: 0.9604\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9989\n",
      "Epoch 00070: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0054 - acc: 0.9989 - val_loss: 0.1817 - val_acc: 0.9562\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9969\n",
      "Epoch 00071: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0113 - acc: 0.9969 - val_loss: 0.1570 - val_acc: 0.9620\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9996\n",
      "Epoch 00072: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0028 - acc: 0.9996 - val_loss: 0.1755 - val_acc: 0.9571\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9987\n",
      "Epoch 00073: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0056 - acc: 0.9987 - val_loss: 0.2636 - val_acc: 0.9434\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9993\n",
      "Epoch 00074: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0038 - acc: 0.9993 - val_loss: 0.1818 - val_acc: 0.9557\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9992\n",
      "Epoch 00075: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0044 - acc: 0.9992 - val_loss: 0.1742 - val_acc: 0.9588\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9943\n",
      "Epoch 00076: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0193 - acc: 0.9943 - val_loss: 0.1785 - val_acc: 0.9574\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9996\n",
      "Epoch 00077: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0029 - acc: 0.9996 - val_loss: 0.1889 - val_acc: 0.9541\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 00078: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0039 - acc: 0.9992 - val_loss: 0.2410 - val_acc: 0.9448\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9961\n",
      "Epoch 00079: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0144 - acc: 0.9961 - val_loss: 0.1876 - val_acc: 0.9562\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 00080: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0022 - acc: 0.9998 - val_loss: 0.1812 - val_acc: 0.9564\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 00081: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0033 - acc: 0.9996 - val_loss: 0.1962 - val_acc: 0.9578\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9986\n",
      "Epoch 00082: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0051 - acc: 0.9986 - val_loss: 0.2535 - val_acc: 0.9432\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9974\n",
      "Epoch 00083: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0089 - acc: 0.9974 - val_loss: 0.1970 - val_acc: 0.9548\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9991\n",
      "Epoch 00084: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0040 - acc: 0.9991 - val_loss: 0.2121 - val_acc: 0.9527\n",
      "Epoch 85/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9993\n",
      "Epoch 00085: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0033 - acc: 0.9993 - val_loss: 0.2029 - val_acc: 0.9522\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9970\n",
      "Epoch 00086: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0111 - acc: 0.9970 - val_loss: 0.2875 - val_acc: 0.9394\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9970\n",
      "Epoch 00087: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0113 - acc: 0.9970 - val_loss: 0.1810 - val_acc: 0.9564\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9990\n",
      "Epoch 00088: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0043 - acc: 0.9990 - val_loss: 0.1771 - val_acc: 0.9588\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 00089: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0038 - acc: 0.9992 - val_loss: 0.1893 - val_acc: 0.9571\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 00090: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0017 - acc: 0.9998 - val_loss: 0.1811 - val_acc: 0.9576\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9983\n",
      "Epoch 00091: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0073 - acc: 0.9983 - val_loss: 0.1926 - val_acc: 0.9581\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9978\n",
      "Epoch 00092: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0079 - acc: 0.9978 - val_loss: 0.1847 - val_acc: 0.9555\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9995\n",
      "Epoch 00093: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0028 - acc: 0.9995 - val_loss: 0.1768 - val_acc: 0.9578\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9994\n",
      "Epoch 00094: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0028 - acc: 0.9994 - val_loss: 0.1820 - val_acc: 0.9578\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9987\n",
      "Epoch 00095: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0053 - acc: 0.9986 - val_loss: 0.1999 - val_acc: 0.9571\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9967\n",
      "Epoch 00096: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0121 - acc: 0.9967 - val_loss: 0.1689 - val_acc: 0.9613\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9982\n",
      "Epoch 00097: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0071 - acc: 0.9982 - val_loss: 0.1749 - val_acc: 0.9557\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9973\n",
      "Epoch 00098: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0084 - acc: 0.9973 - val_loss: 0.1797 - val_acc: 0.9567\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9985\n",
      "Epoch 00099: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0056 - acc: 0.9985 - val_loss: 0.1759 - val_acc: 0.9606\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 00100: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0014 - acc: 0.9999 - val_loss: 0.1637 - val_acc: 0.9620\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 00101: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0015 - acc: 0.9998 - val_loss: 0.1698 - val_acc: 0.9620\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9987\n",
      "Epoch 00102: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0055 - acc: 0.9988 - val_loss: 0.1782 - val_acc: 0.9609\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9976\n",
      "Epoch 00103: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0087 - acc: 0.9976 - val_loss: 0.1695 - val_acc: 0.9632\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 00104: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0018 - acc: 0.9998 - val_loss: 0.1694 - val_acc: 0.9639\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 00105: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0016 - acc: 0.9997 - val_loss: 0.2031 - val_acc: 0.9553\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9975\n",
      "Epoch 00106: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0096 - acc: 0.9975 - val_loss: 0.1893 - val_acc: 0.9604\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 00107: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0012 - acc: 0.9999 - val_loss: 0.1818 - val_acc: 0.9592\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 00108: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0036 - acc: 0.9990 - val_loss: 0.2453 - val_acc: 0.9478\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9977\n",
      "Epoch 00109: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0081 - acc: 0.9977 - val_loss: 0.2073 - val_acc: 0.9550\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9982\n",
      "Epoch 00110: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0069 - acc: 0.9982 - val_loss: 0.1696 - val_acc: 0.9627\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 00111: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0017 - acc: 0.9997 - val_loss: 0.1790 - val_acc: 0.9616\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 00112: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0016 - acc: 0.9998 - val_loss: 0.1824 - val_acc: 0.9613\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9976\n",
      "Epoch 00113: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0082 - acc: 0.9976 - val_loss: 0.2456 - val_acc: 0.9499\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 00114: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0038 - acc: 0.9992 - val_loss: 0.2091 - val_acc: 0.9555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9996\n",
      "Epoch 00115: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1806 - val_acc: 0.9604\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9982\n",
      "Epoch 00116: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0064 - acc: 0.9982 - val_loss: 0.1678 - val_acc: 0.9634\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9988\n",
      "Epoch 00117: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0050 - acc: 0.9988 - val_loss: 0.1927 - val_acc: 0.9599\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00118: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1749 - val_acc: 0.9630\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 00119: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1903 - val_acc: 0.9597\n",
      "\n",
      "1D_CNN_custom_3_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXecVNX5/99ntvdOXWAXQTosVQwCGpUAGiESRGNP1J/RGI0lYtSIGhMVE40txkKixq7xG1EURSk2lCK9LX1ZFrb3MrMzz++Ps7OzC9sowy67z/v1mtfMvfecc5975t7zOc9zzr3XiAiKoiiKAuBobQMURVGUtoOKgqIoilKLioKiKIpSi4qCoiiKUouKgqIoilKLioKiKIpSi4qCoiiKUouKgqIoilKLioKiKIpSS2BrG3CkJCYmSkpKSmuboSiKclKxatWqXBFJai7dSScKKSkprFy5srXNUBRFOakwxuxpSToNHymKoii1qCgoiqIotagoKIqiKLWcdGMKDeFyudi3bx+VlZWtbcpJS2hoKMnJyQQFBbW2KYqitCLtQhT27dtHVFQUKSkpGGNa25yTDhEhLy+Pffv2kZqa2trmKIrSirSL8FFlZSUJCQkqCEeJMYaEhAT1tBRFaR+iAKggHCNaf4qiQDsSheZwuyuoqsrE43G1timKoihtlg4jCh5PBU5nFiLHXxQKCwt59tlnjyrv1KlTKSwsbHH6OXPm8Nhjjx3VvhRFUZqjw4iC71DluJfclChUV1c3mXfBggXExsYed5sURVGOhg4jCt6YucjxF4XZs2ezY8cO0tLSuOOOO1iyZAnjx4/nggsuYODAgQBMnz6dkSNHMmjQIJ5//vnavCkpKeTm5rJ7924GDBjAtddey6BBg5g0aRIVFRVN7nfNmjWMHTuWoUOH8rOf/YyCggIAnnzySQYOHMjQoUO5+OKLAVi6dClpaWmkpaUxfPhwSkpKjns9KIpy8tMupqTWJT39FkpL1xy2XsSNx1OOwxGOMQFHVGZkZBp9+z7R6PaHH36YDRs2sGaN3e+SJUtYvXo1GzZsqJ3iOW/ePOLj46moqGD06NHMmDGDhISEQ2xP54033uCFF17goosu4r333uOyyy5rdL9XXHEFTz31FBMnTuSPf/wj999/P0888QQPP/wwu3btIiQkpDY09dhjj/HMM88wbtw4SktLCQ0NPaI6UBSlY9BhPIUTzZgxY+rN+X/yyScZNmwYY8eOJSMjg/T09MPypKamkpaWBsDIkSPZvXt3o+UXFRVRWFjIxIkTAbjyyitZtmwZAEOHDuXSSy/lP//5D4GBVvfHjRvHrbfeypNPPklhYWHtekVRlLq0u5ahsR69211KefkWwsL6EhgY43c7IiIian8vWbKERYsW8e233xIeHs6ZZ57Z4D0BISEhtb8DAgKaDR81xkcffcSyZcuYP38+Dz30EOvXr2f27Nmcd955LFiwgHHjxrFw4UL69+9/VOUritJ+6UCegj1Uf4wpREVFNRmjLyoqIi4ujvDwcLZs2cLy5cuPeZ8xMTHExcXx5ZdfAvDqq68yceJEPB4PGRkZnHXWWTzyyCMUFRVRWlrKjh07GDJkCHfeeSejR49my5Ytx2yDoijtD795CsaYecD5QLaIDG5g+6XAnYABSoBfi8haf9ljdwPgOe4lJyQkMG7cOAYPHsyUKVM477zz6m2fPHkyzz33HAMGDKBfv36MHTv2uOz35Zdf5vrrr6e8vJzevXvzr3/9C7fbzWWXXUZRUREiwm9/+1tiY2O59957Wbx4MQ6Hg0GDBjFlypTjYoOiKO0L44+eM4AxZgJQCrzSiCj8CNgsIgXGmCnAHBE5rblyR40aJYe+ZGfz5s0MGDCgyXxudyXl5RsIDU0lKCihybQdlZbUo6IoJyfGmFUiMqq5dH7zFERkmTEmpYnt39RZXA4k+8sW8O+UVEVRlPZCWxlT+BXwsX934Q0fqSgoiqI0RqvPPjLGnIUVhTOaSHMdcB1Az549j3ZPNd8qCoqiKI3Rqp6CMWYo8CIwTUTyGksnIs+LyCgRGZWUlHS0+6r5dfwHmhVFUdoLrSYKxpiewH+By0Vkm//36L8pqYqiKO0Ff05JfQM4E0g0xuwD7gOCAETkOeCPQALwbE0vvrolI+PHYFHNt4qCoihKY/hz9tElzWy/BrjGX/s/FF/4qG2IQmRkJKWlpS1eryiKciJoK7OPThBGw0eKoihN0OFEwR+ewuzZs3nmmWdql70vwiktLeXss89mxIgRDBkyhP/9738tLlNEuOOOOxg8eDBDhgzhrbfeAiArK4sJEyaQlpbG4MGD+fLLL3G73Vx11VW1aR9//PHjfoyKonQMWn1K6nHnlltgzeGPzgYIc5fiMEHgCGlwe6OkpcETjT86e9asWdxyyy3ceOONALz99tssXLiQ0NBQ3n//faKjo8nNzWXs2LFccMEFLXof8n//+1/WrFnD2rVryc3NZfTo0UyYMIHXX3+dn/zkJ9x999243W7Ky8tZs2YNmZmZbNiwAeCI3uSmKIpSl/YnCk1Qc0/zcS93+PDhZGdns3//fnJycoiLi6NHjx64XC7+8Ic/sGzZMhwOB5mZmRw8eJAuXbo0W+ZXX33FJZdcQkBAAJ07d2bixImsWLGC0aNH88tf/hKXy8X06dNJS0ujd+/e7Ny5k5tuuonzzjuPSZMmHfdjVBSlY9D+RKGJHn1F6ToCAqIIC0ttNM3RMnPmTN59910OHDjArFmzAHjttdfIyclh1apVBAUFkZKS0uAjs4+ECRMmsGzZMj766COuuuoqbr31Vq644grWrl3LwoULee6553j77beZN2/e8TgsRVE6GDqmcJyYNWsWb775Ju+++y4zZ84E7COzO3XqRFBQEIsXL2bPnj0tLm/8+PG89dZbuN1ucnJyWLZsGWPGjGHPnj107tyZa6+9lmuuuYbVq1eTm5uLx+NhxowZ/OlPf2L16tV+OUZFUdo/7c9TaAIby/ePKAwaNIiSkhK6d+9O165dAbj00kv56U9/ypAhQxg1atQRvdTmZz/7Gd9++y3Dhg3DGMOjjz5Kly5dePnll5k7dy5BQUFERkbyyiuvkJmZydVXX43HY+/W/stf/uKXY1QUpf3jt0dn+4ujfXQ2QFnZJowJJjy8j7/MO6nRR2crSvulpY/O7oDhI332kaIoSmN0QFE4uTwjRVGUE0mHEgV/jikoiqK0BzqUKOhjLhRFUZqmw4mCegqKoiiN06FEQcNHiqIoTdOhRAEcfgkfFRYW8uyzzx5V3qlTp+qzihRFaTN0MFHwz5TUpkShurq6ybwLFiwgNjb2uNukKIpyNHRAUfDPo7N37NhBWload9xxB0uWLGH8+PFccMEFDBw4EIDp06czcuRIBg0axPPPP1+bNyUlhdzcXHbv3s2AAQO49tprGTRoEJMmTaKiouKwfc2fP5/TTjuN4cOHc84553Dw4EEASktLufrqqxkyZAhDhw7lvffeA+CTTz5hxIgRDBs2jLPPPvu4H7uiKO2LdveYiyaenI3H0wWRRAICjqzMZp6czcMPP8yGDRtYU7PjJUuWsHr1ajZs2EBqqn343rx584iPj6eiooLRo0czY8YMEhIS6pWTnp7OG2+8wQsvvMBFF13Ee++9x2WXXVYvzRlnnMHy5csxxvDiiy/y6KOP8te//pUHH3yQmJgY1q9fD0BBQQE5OTlce+21LFu2jNTUVPLz84/swBVF6XC0O1FonhMz0DxmzJhaQQB48sknef/99wHIyMggPT39MFFITU0lLS0NgJEjR7J79+7Dyt23bx+zZs0iKysLp9NZu49Fixbx5ptv1qaLi4tj/vz5TJgwoTZNfHz8cT1GRVHaH+1OFJrq0VdW5uJyZRMVNcLvdkRERNT+XrJkCYsWLeLbb78lPDycM888s8FHaIeE+F7+ExAQ0GD46KabbuLWW2/lggsuYMmSJcyZM8cv9iuK0jHpUGMKdkrq8R9ojoqKoqSkpNHtRUVFxMXFER4ezpYtW1i+fPlR76uoqIju3bsD8PLLL9euP/fcc+u9ErSgoICxY8eybNkydu3aBaDhI0VRmqVDiULtu9eO87TUhIQExo0bx+DBg7njjjsO2z558mSqq6sZMGAAs2fPZuzYsUe9rzlz5jBz5kxGjhxJYmJi7fp77rmHgoICBg8ezLBhw1i8eDFJSUk8//zzXHjhhQwbNqz25T+KoiiN0aEenV1VlYXTmUlk5AiM6WB62AL00dmK0n5p9UdnG2PmGWOyjTEbGtlujDFPGmO2G2PWGWP8Hui34SPQu5oVRVEaxp/d5X8Dk5vYPgXoW/O5DviHH22pwT/hI0VRlPaC32YficgyY0xKE0mmAa+IbaGXG2NijTFdRSTLXzZ5RaE9ewoiUOsQtQCPx+ape+9GTg7s3AlJSdC5MzgcUFlpy23s5mu32+YrKICiIkhNtXkBiovhq69sGZ06QUICBAfbj9Np85SXw5gxEBrqO441a2DvXigpsXmDgiAkBKKiIC7O2hIaaj9xcRAWZvOWl8PSpbBrF5xyCpx6ql23c6e1sVcv6NvXlpeVBYWFMHq0LddLZqZvW2GhPabiYujZEyZOhMREOHgQvvzS2terF6Sk2I+jpqvldNpjyMiw+y0qsnXocNj8ffpAcrItZ9cuWw/e/69vXxgxAurOIi4rg02bYN8+6NLF2lJRYdft2GHrJibG1mtFha0zj8eWFx0NZ59t699bt8uW2W3BwXZ9Wpq1f88e+PZba5PDAYGBEB5uy46JsTbFx0NVFezfb+2vrrb7ioy0dd67t83jtXvPHvspLbXnSnW1tbGiwv5/nTtbGyIi7HE4nbbsrCxwuWw5gYG2/MhIm7ZXL5svP9/a4HLZ/zAiwu4nPx9ycyE729a/0+k7nthY+/EeS2SkrdedO20+sGm7dbPHEh1t63j7dmt/TIwvv/d8rqy0x5OTY+0pLrZ1AtbOU06x11R2tj2ukhJbhx6PLaNzZ3vs5eW2zsrK7HFUVVlbHA57np5xRsuv76OhNaekdgcy6izvq1l3mCgYY67DehP07NnzGHbpdYxa9+1rIvZEcLvtsjH2ExBweINeUmJPILAnZliYPVm8k50iI33rCgvtCRQY6CvL6xR5PPYTHm4vqOhoe8EcOGAvprAw2yiNGQMrV/ryHUpysm2sEhJsI5efbxvuvXvthV6XXr3sRfDDD75jbYrERLjuOnsRPvssrF7dsvr00rWrvYg3bLD1cCSEhsLkydC9O3z2GWzb1nT6bt1so3Uo4eEwZIitz+++s43EsZCYaP9Lj8c2NseCMbZRyc6GBm6BAaxQehthpe1x553tWxRajIg8DzwPdqD5aMvxjim0VviostJejKWljacJDLS9hdBQe3EWF9sLNSDA9mS8eHthXsEwxteD9nhsA13Xa3A47O+iItvj8QpGVJRteMrKbA8lKAjuvx+GDYO8PNuAiPjsWbMGVq2yx+DtLY0ZA7NmWcHw9rq2boXvv7c9ptmz4cc/trbl5FghcTpteUFBPpv//W94+GH7e+BAKwynnWZtDAuzeaqqrCAWFNhPZaVdl5NjjysjA264wTbwAwfadenp1qbeva2Y7dlj17ndVkjCwuDjj+Hdd22ZZ54Jv/617dl5e8exsdaOrVth8WIrPMOHw4QJVvj27LH7Wr8e1q2z9XPddfYC7tvXpvF6WW63rZft2329/pQU+z8YY/+7zZutKO7c6fvPu3eHwYOth3DwoBXi4GB7nH362HKLi219hIXZ/8zrtWRmwoIF8MknMGgQ3HMPTJliz7WqKmvH2rWwZYu1d+xY6N/f5q2utudGcbHteOTn23MjONja1Lmz/e1w2O07dli7nU6bPzTUdhB69bKdkYAAe557baystJ2T7GwrolVV9rzo1s3WTWioPQerq229lpTY9Hv32nqIj/f1sktKbJqoKJ8X0Lmzrf/gYFuOy2WvA+85lJdn83Xvbs+RpCTf/+D1HoqK7Png9TC9dZGXZz9Op+94vB52bKytExHbgdi503bEOnWyxxUTY212OOz6gwftsUdE2Ovb6xWFhPg6ksHBR9/+tBS/zj6qCR99KCKDG9j2T2CJiLxRs7wVOLO58NGxzD5yufKprNxJePggAgLCWnwcLcV7wrlc9sT3NsQi9iTau9cuJyX5evPefF7PobraXiSVlXa9160OCLAnXmWlPWECa+Tc7bYXUlgYLXp8h4i9EIqL7QUTFeUTjrYw+2j3bntxjBlzZGGw44HXmwo8KbpKinJktHT2UWue/h8AvzHGvAmcBhT5dzwBjveYgojtQZWU2Ea2vPzwEEpdvL3V4GCIjIyktCmXgcPHB7xx+LoEBNhyW4oxvh5UW8Qbl28NvHFbRenI+E0UjDFvAGcCicaYfcB9QBCAiDwHLACmAtuBcuBqf9lSx6aaX8cmChUVPrfRG38NC7PuYliYdffc7vpx9MBAGyY5kt7vie4pK4qi+HP20SXNbBfgRn/tv2Ec3n0fVe7SUhvDLyqyy96ZGA8/PJuUlB7ceKM9nDlz5hAZGcn111/PtGnTKCgowOVy8ac//Ylp06Y1uY/p06eTkZFBZWUlN998M9dddx1gH4H9hz/8AbfbTWJiIp9//jmlpaXcdNNNrFy5EmMM9913HzNmzDiqYzsSPOKh2lNNcEDTAc7ssmyW7F7CyK4j6R3Xu44oN09BRQGvrnuV6JBoJvSaQGps6hHlPxbcHje7Cnexu3A3GUUZVLmrOK37aQztPJQAR8sesSsibM/fzvJ9y3EYB12jupIUnoSj5qbJlNgUIoLt87E84uGN9W+QW57LL4f/kqiQqHplVVVX8dXer4gNjSWtSxoBjgB2Fuzk7Y1v4xEP5/U9j6GdhzZaP26Pm6KqImJCYlpsvz8oriomyBFEWNCxh25LnaV8vfdrNudu5qyUsw47/srqSr7P/J4N2RvILssmpywHl8f24AJMALGhscSHxVNcVcz2gu3sLtxNSVUJZa4yesX04r6J93FW6lkAbMndwobsDcSGxpIQlsCgToMOO/c94mFB+gJeWfsKAY4A4kPjiQqJIsgRRHBAMBcNuoh+if0OO479JftZtHMRaw6sYd3BdQjC6G6jGdZ5GJklmaw7uI7CykKGdR7GyG4jGdN9DN2iuh1z/TVFu7uj+ZZPbmHNgYafnS3ixuMpx+EIx5iWXxyDE9P47alPUFxse/ydO9tBwaAgu/2HH37glltuYenSpQAMHDiQhQsX0rVrV8rLy4mOjiY3N5exY8eSnp6OMabR8FF+fn69R2wvXboUj8fDiBEj+PTzT4noHEFgVSDdOnXjzjvvpKqqiidqngJYUFBAXFxci48LbINRWV1JRXUF6VvTcSQ5OC35tEbTb8/fznmvn8fuwt0M6zyMIZ2GkFWaxZbcLXSJ7MK/pv2Lfon9SM9L59xXz2VP0R4AekT3YGLKRMb3HM/gToPZmL2RFftXkBSexC1jbyEpIgmAg6UHefr7p3ny+ycpriqu3W9ydDKTek/iJ31+wvmnnk94UHg9u/LK85j3wzxeWfcKB0oPUO4qx+1xEx8WT3xYPP0S+zGm2xj6JfbjQOkBdhfuJiwwjBFdR9A3oS8/ZP3Akt1L+H7/92zJ3UJl9eEPLIwOiaZ/Yn+6RXWje1R3BncazNDOQyl1lrJo5yK+zviaCpedbpRVmsWB0gON1mNMSAzXjLiGSadMYs6SOXy771sAEsIS+N3Y39E9ujs5ZTmsPbiW+dvm19ZFTEgMvWJ7se7gunrl9YzpyT/O+wdT+04FbAP8wNIH+GrvV6zPXk+5qxyHcZAQlkDfhL6M6DKC05JPY+bAmYQEhtT+t/cvvZ+88jzc4qbMWUZOeQ4FFQVcnXY1fznnL7WitiB9AbsLd5Mam0rPmJ5EBEcQEhBCYngiQQFBtXZ9uO1D/vzln0nPTye3PBeA2NBYEsMTcbldVLmrqKyupKq6Cre46RXTi/6J/YkMjmRHwQ52Fuys/S8cxkF4UDjhQeHsLdpLtccXqz014VSGdxlOibOE3PJc1hxYg9PtrN0eHxZPSIA9TpfHRWFlIdWeahzGQUpsCqmxqcSExhARFMHi3YvZV7yPM3qeQU5ZDlvzttar6wGJA3j1Z68ysttIqqqreHPDm8z9Zi4bczbSJbILkcGR5FfkU1JVglvceMRDaGAoD5/9MDeddhNbcrfwzsZ3+GDbB6zOslPsQgNDGdxpMCLCuoPragWse1R3YkJj2JK7BY94uO3023hs0mONnldN0dIxhQ4qCmEY0zInyemElNA07hjyBF272kHihgZ0BwwYwOeff05OTg433HADX3/9NS6Xi9/97ncsW7YMh8PB1q1b2bVrF126dKkVBbfHTUV1BS63C0F45E+P8PGHH2Mw7N69m4ULF5KTk8Mrr73CXY/fhUc8OIyD5OhkJo+fzDPzniGxRyIO4yAoIIgAE4AgiAgxoTFEh0TXs9PldlFUVURRZREV1RX1Gr/cPblM+XQKk06ZxP1n3s/Y5PrPaPo+83vOe/08AC4fejk/HPiBjdkb6R7dnVMTTuWLXV9Q4arg3gn38vjyx3GLm3kXzCOjOIPFuxfz5Z4vOVh2sLa8uNA4iqqKCAsM48phV7IlbwtLdi/BIx5mDJjB3ePvJjggmGV7lvHF7i9YtHMRhZWFnJ58OkuvWlrb+Dzy1SPMWTqHyupKxvccz6CkQUQER+AwDgoqCsityGX9wfXsKNhRu+/ggODaOvcSHRLN6cmnM7jTYAYmDaR3XG96RPfAYRx8k/ENX+39ih0FO8gqzWJv0d56ohXkCOK05NOIC7WiHBsayxk9z2Bcj3EEOgLZX7KfvIo8RIRqTzUfbPuAdza+g1vcJIUnMffcuQxIGsD9S+9nQfqC2nITwhKY1m8a0/tPp9RZyuLdi9mev50pfaZw8eCLCQoI4uP0j/n7d39n3cF1zD13LmelnsWsd2exs2AnE3pNYFjnYfSK6UVBZQEHSw+yKXcTP2T9QJmrjN5xvXnknEfILc/ltk9vI9ARyKkJpxLoCCQ0MJROEZ2ocFUwf9t8Lhp0EU9OfpJbP72V19e/3uD10jOmJ+/MfIcx3ccwf+t8Lnz7Qk6JO4WJvSZySvwpVHuqySrJIq8ij6CAIEICQggNDCUkIARjDLsKd7EldwtlzjL6xPehd1xvIoKsR+UWN+WucspcZfSM7slZqWfRP7E/H6d/zNub3iajKIOY0BhiQmIY3mU443uNZ1S3UXSK6ESgo/71LiKUOksJCQw5rNdfWV3Jcyuf4+nvnyY1LpXp/aZzeo/TKXOWsatwF3/4/A8cLDvIJYMvYeGOhWSXZTO402B+/6Pf1/4ndTlQeoBrPriGj9I/olNEJ7LLsjEYftTjR5x/6vlM6TOFQZ0G1dpYWV3JtrxtdIvqRmK4fb5ZuaucdQfXER8Wz6kJpzZY983RYUWhKdzVZZSXbyY0rA9BQY2/AlPEjhfs329FIS4OevSwg7xuj5vssmwCHYGEBNgTKiggiDn3zSEpKYmsrCy6dOnCzTffzL///W8+/vhj/vrcXylyFTFl9BSWLllKSkoKUVFRLN+5vF6jvOqbVfzj0X/wz7f+yYBuA7jgJxdwz733sC93H2++9SZ/++ff6BnTk/0l+ymuKubyyZfz0LMPceqp9iRxuV24xW3daAFBiA2NJSk8iXJXOUVVRZQ6rXcS5AgiIjiC8KBwwgLDCAsMY0f6DhYULGDuN3PJq8jjkXMe4bbTbwPgpR9e4uZPbqZLZBc+ufQT+ib0PazeMoszueS9S/hy75ckRyfz2eWf0T+xf516FdLz09mSu4VBSYPoHdebrXlbeWDpA7y54U36JvRl1qBZ/GLIL+rl81Ltqebfa/7NtfOv5a4z7uLPZ/+Z/6z7D5e/fznT+k3jwbMeZEjnIY3+r3nleewo2EH3qO50jepKuauctQfWsjVvK0M7D2V4l+FHFB7aW7SXtQfXEhwQzPie42vDQS0loyiDJbuXcP6p5xMX5vPwduRb8eoU0YnI4MgWhc3KnGVc+X9X8t7m92y4KrIrb8x4g/G9xjeY3u1xs2jnIm7/7HY2ZNsn0Zzb+1zmTZtHcnTyYcf62DeP8ftFvyfQEYiIcN/E+7h6+NXsLdpLRlEGFdUVlDnLmPvNXLJKs7hx9I08s+IZhnUexmeXf0ZMaMwR1U1bpqCigBsX3MibG95kat+p3HzazZzT+5wm/ycR4aUfXmL+tvmc2/tcZgyYQdeorifQ6paLAiJyUn1Gjhwph7Jp06bD1h1GXp7IihVSmrNCnM78RpNVVops2CCyYoXIpk0iRUX1t2eVZMmKzBWHfd5e/LYMHTlUeqb2lE/XfCoZRRky969z5fJrLpcVmSvk+XefF0C+WP2FbMnZImHhYbIxe6NkFmdKQXmBlDnL5K1335LJUyfL+oPr5Z2l70hwSLA8985z8um6T6VLty6Svj1dRERyc3MltyxXfvO738iNN91Ya1t+fr54PB4REXG73bK/eL+s2r+q1saN2RtlX9E+Ka0qrU3XUD2WVJXIz9/+uTAHueTdS2TivyYKc5CJ/5ooB0oONFnNLrdLXl7zsmQUZTT/n9ShzFnWoE0Ncc3/rhEzx8jDXz4sIQ+GyMR/TZSq6qoj2l97xO1xy0PLHpLL/nuZ5JTltCiPy+2SeavnyUurXxK3x91k2jfWvyE/fvnH8t2+7xpNk1uWK5P/M1mYg6Q9lyb55Y1fayc7zmpna5twRAArpQVtbKs38kf6OWpRKCiwopC9QpzOvAaTlJWJrFkjsnq1SH6+R/YXZ8mm7E3icrtERMTj8ci6A+tkc85mqXRVSnFlseSW5UpWSZbsLdwr/Qb2k9PHny7peemyInOFfLb+MxkyYoj0H9hfrrrqKul7al+Z/918Wb1/tYRHhB/WCFZWVsrkyZOlf//+cu7Uc2XU6aPkrflvSbmzXBYsWCBpaWkydOhQOeecc0REpKSkRK644goZNGiQDB06VN57773DjslZ7ZSC8oIWncB169Hj8cgDSx4Q5iCxD8fKi6tebLbROFGUOctkwNMDhDlI6hOpLW4AlROD2+PGtXjNAAAgAElEQVSW9ze/364F4WSkpaLQccJHRUWQnk5ZTwiOSyUoqP6rMEtL7V2uAQHQp4+HA1W7ya+wD0HpEtmF5OhkiiuL2Za/jdTYVBLCExraSy1V1VUUVBYQGRRJZIjvRgKX24Ux5rAYZ1ugoXpcnbWaHtE9ageC2wobszdy+2e3M/fcuQzudNi9kYqiHMLJcPPaiaXmriTjAZH6zz5yu2HnbhcmMp/IhEp2lpZQWV1J96juVFZXcrD0IEnhSWSX27GEuvHfxggJDKFLZJfD1h86CNXWGdHV/68uPRoGdRrEx5d+3NpmKEq7o8OJgp1sUt87OnBAcEZuh+Ayip121sUpcacQFxaH0+0kvzKfPUV7KK4qpktkl9ppeYqiKO2NdiMKItL0LI2abeYQUaishKyiAoi1N60cGiYJDgimc0Tn2jnnSeFtK4xyvDjZwoiKoviHdtHlDQ0NJS8vr+mGzespeHwNoAjs2euBqH2EBYbXzgk+lC6RXQh0BBITElN7o097QkTIy8sj1PsyA0VROiztwlNITk5m37595DT1wPnqasjNxeUEU1BNYGABlZVwsLAIQgvpHNmZLXlbGs0e4AnAaZxszt7shyNofUJDQ0lOTm4+oaIo7Zp2IQpBQUGkpqY2nSgvD4YOJf03EHjrfaSmzmH6LUv4X/hPOW/g2Xx42f+dGGMVRVHaMO0ifNQiakIjAS4HJc4Sfv3hjfwv7iwi6MyT5/2tlY1TFEVpG7QLT6FF1IiCwxnAXd9+xMd7tsG3t/DCNQ/ROy68mcyKoigdg47jKQQEQFAQAU4HG/MOkFL+c6K+eZzp56kgKIqieOk4ngJAWBgOp5Os8lLMphRmTrMvxVEURVEsHcdTAAgLo8DjwOlxU5Xdg4svbm2DFEVR2hYdSxRCQzlQc+NahLsH557byvYoiqK0MTqWKISFsT/AisLQXj0JbvptkoqiKB2OjiUKoaG1otA9skcrG6MoitL26FiiEBbG/iAPuELpGtvwIy0URVE6Mh1LFEJD2RcMFPcgIb75VxwqiqJ0NPwqCsaYycaYrcaY7caY2Q1s72mMWWyM+cEYs84YM9Wf9hAWxp4QBxT1IKHpd+QoiqJ0SPwmCsaYAOAZYAowELjEGDPwkGT3AG+LyHDgYuBZf9kDQFgYmWEeKO5BfLxf96QoinJS4k9PYQywXUR2iogTeBOYdkgaAaJrfscA+/1oD9WhweSEu6Cop4qCoihKA/hTFLoDGXWW99Wsq8sc4DJjzD5gAXBTQwUZY64zxqw0xqxs8vHYzbA/UvA40PCRoihKI7T2QPMlwL9FJBmYCrxqzOHvuhSR50VklIiMSko6+jef7Q1z2h8aPlIURWkQf4pCJlD3ZoDkmnV1+RXwNoCIfAuEAn6bK5oRWiMKGj5SFEVpEH+KwgqgrzEm1RgTjB1I/uCQNHuBswGMMQOwonD08aFmyAiuAMCUdCMmxl97URRFOXnxmyiISDXwG2AhsBk7y2ijMeYBY8wFNcluA641xqwF3gCuEj++QX5vYBnBlWFEB7trX9msKIqi+PDro7NFZAF2ALnuuj/W+b0JGOdPG+qS4SglrCiR6MgCQEeaFUVRDqVD9ZczKCKoqCsxkXmtbYqiKEqbpEOJwl5PARQnEx2uoqAoitIQHUYUyl3l5HlKcRelEh2Whx+HLhRFUU5aOowoZBTZ++gqivoSG5aHiLuVLVIURWl7dBxRKLaiUFncj9iQfOyTNxRFUZS6dBhRKHWWEhsQBUU9iA3Jx+NRUVAURTmUDiMK0/tP59v+30DBKcQG56mnoCiK0gAdRhQA8ivDAIgLykfE1crWKIqitD06lCjklYcDEBuo4SNFUZSG6FCikF8eCkC8Q8NHiqIoDdGxRKEsGIC4APUUFEVRGqJDiUJecTAO3MRQrGMKiqIoDdChRCG/OJB48gl0iXoKiqIoDdAiUTDG3GyMiTaWl4wxq40xk/xt3PEmv8AQTwGOKnRMQVEUpQFa6in8UkSKgUlAHHA58LDfrPITeXkQH1CIw4l6CoqiKA3QUlEwNd9TgVdFZGOddScN+fk1olCFjikoiqI0QEtFYZUx5lOsKCw0xkQBHv+Z5R/y8yE+qBiHU8NHiqIoDdHSN6/9CkgDdopIuTEmHrjaf2b5h7w8iA8u0fCRoihKI7TUUzgd2CoihcaYy4B7gCL/mXX8cbmgpAQSQkoJ0IFmRVGUBmmpKPwDKDfGDANuA3YAr/jNKj9QUGC/40LLazwFHVNQFEU5lJaKQrXYV5VNA54WkWeAKP+ZdfzJq3kDZ3xYhU5JVRRFaYSWjimUGGPuwk5FHW+McQBB/jPr+JOfb78TIqpwFOmYgqIoSkO01FOYBVRh71c4ACQDc5vLZIyZbIzZaozZboyZ3Uiai4wxm4wxG40xr7fY8iPEKwrx0U6dfaQoitIILfIUROSAMeY1YLQx5nzgexFpckzBGBMAPAOcC+wDVhhjPhCRTXXS9AXuAsaJSIExptPRHkhzREfDuedCl8gqvU9BURSlEVr6mIuLgO+BmcBFwHfGmJ83k20MsF1Edortlr+JHZOoy7XAMyJSACAi2Udi/JEwcSJ8+in0SKjSKamKoiiN0NIxhbuB0d5G2xiTBCwC3m0iT3cgo87yPuC0Q9KcWlPe10AAMEdEPmmhTUeFCQvTKamKoiiN0FJRcBzSi8/j+DxhNRDoC5yJHadYZowZIiKFdRMZY64DrgPo2bPnse0xLAyHSz0FRVGUhmhpw/6JMWahMeYqY8xVwEfAgmbyZAI96iwn16yryz7gAxFxicguYBtWJOohIs+LyCgRGZWUlNRCkxshNNQONLtVFBRFUQ6lRaIgIncAzwNDaz7Pi8idzWRbAfQ1xqQaY4KBi4EPDknzf1gvAWNMIjactLPF1h8NYWEASGWFX3ejKIpyMtLS8BEi8h7w3hGkrzbG/AZYiB0vmCciG40xDwArReSDmm2TjDGbADdwh4jkHdERHCk1okBFuV93oyiKcjLSpCgYY0oAaWgTICIS3VR+EVnAIWEmEfljnd8C3FrzOTGEhtrvCvUUFEVRDqVJURCRk+pRFi3C6ylUVrWuHYqiKG2QDvWOZqDWUzCVla1siKIoStuj44mCegqKoiiN0vFEwTumoJ6CoijKYXQ8Uaj1FPQ+BUVRlEPpsKIgZcWtbIiiKErbo+OJQk34yFPm39shFEVRTkY6nijUeAqe8mJE3K1sjKIoStui44lCjacQ4BScTr89qVtRFOWkpOOJQo2n4HCC05nVysYoiqK0LTqeKNR4Co4qFQVFUZRD6dCiUFWloqAoilKXjicKxiAhITXhowOtbY2iKEqbosWPzm5PmLAwAl1QquEjRVGUenRIUSAsjEC3jikoiqIcSscUhdBQglyioqAoinIIHVMUwsIIqHbrQLOiKMohdLyBZoDQUAKcgTidWdiXvymKoijQUUUhPJyAChBxUl1d0NrWKIqitBk6pigMGkTwxiyMDjYriqLUo2OKwpln4iitIHK73sCmKIpSl44pChMnAhC7Rj0FRVGUuvhVFIwxk40xW40x240xs5tIN8MYI8aYUf60p5auXZFT+xCzVkVBURSlLn4TBWNMAPAMMAUYCFxijBnYQLoo4GbgO3/Z0qB9E88idh04KzJP5G4VRVHaNP70FMYA20Vkp4g4gTeBaQ2kexB4BKj0oy2HM3EigWVg1m0+obtVFEVpy/hTFLoDGXWW99Wsq8UYMwLoISIf+dGOhqkZVwhZvvOE71pRFKWt0moDzcYYB/A34LYWpL3OGLPSGLMyJyfn+BiQnExVj0giVuiTUhVFUbz4UxQygR51lpNr1nmJAgYDS4wxu4GxwAcNDTaLyPMiMkpERiUlJR03AytP60nkmjLweI5bmYqiKCcz/hSFFUBfY0yqMSYYuBj4wLtRRIpEJFFEUkQkBVgOXCAiK/1oUz1cPxpEUAm4fzihY9yKoihtFr+JgohUA78BFgKbgbdFZKMx5gFjzAX+2u+RIKePBqD6u8WtbImiKErbwK9PSRWRBcCCQ9b9sZG0Z/rTloYIOGUw7mCQTWtP9K4VRVHaJB3zjuYaQsJ7UtEDzOatrW2KoihKm6BDi0JYWF/Kexkc23a3timKoihtgg4tCg5HMK4+nQnMLILy8tY2R1EUpdXp0KIAIP36YQTYqiEkRVGUDi8KgUNqZiCtX97KliiKorQ+HV4UQoacjTjAtf6r1jZFURSl1fHrlNSTgciE0VR0BTatb21TFEVRWp0O7ykEBSVQmRqKY9vephPefTf85z8nxihFUZRWosOLAkB1n24E7y6G6uqGE1RUwNy58MorJ9YwRVGUE4yKAsCAgTiqBXd6I+9WWLECXC7Yvv3E2qU0TlYWnHsuHDzY2pYoSrtCRQEIHHI6AM61nzWc4Ouv7feePeB0niCrlCZZtgwWLYIvv2xtSxSlXaGiAISm/QQA17pvGk7wVc3MJI/HCoPS+uzebb937GhVM5RGeP99KCpqbSuUo0BFAQjrkkZVgoHNGw/f6PHAN9/AgAF2WRuhtoFXnPX/aHts3w4XXggvvdTalihHgYoCYEwAVb2jCFq31zYyIr6NmzZBYSFceaVd1nGFtoFXFPT/aHusWmW/N+v7z09GVBRqcI05lbCd5dCnD/TsCR9/bDd4xxNmzIDwcO2ZthU0fNR2Wb3afm/Z0rp2KEeFikINct+9fP8vKJt7E0RGwlVXQUGBHU/o3BlOOcV+tGfa+ohYT8EYyMiAqqrWtqjtsGABPPpo69qgonBSo6JQQ1z8OVT2DmX/NOD11yEvD+6803oK48bZBqhPH+2ZtgXy86GsDEaOtAKxa1drW9R2+Pvf4d57/TNLTsSGUptLs3o1BAVBbq79KCcVKgo1BASEExd3Lnl585G0NPjd7+CFF2yDc8YZNtEpp8DOnXbwuaMwbx6sW9faVtTHO57w4x/bb/XeLCLwww9WEDZsOP7lv/oqdOsG+/c3nmbvXivakyfbZX368EmHikIdEhJ+SmXlbsrKNsCcOdCrl90wbpz97tPHhioyM1vNxhNKRgb86ldw2WXgdre2NT684wlnn22/1XuzHDgAOTn298qVLc9XUtKy6aPvvGPv7v/oo8bTeENHv/iF/W6vorBunW0XjuTmyU8+gbFjobTUf3YdB1QU6pCQcD4AeXnzISLC9owuvhiGD7cJTjnFfre0Z7poke8iPRl5+237vX5923ruk9dTGDUKoqLUU/Dyww++30ciCjNnwpQpTaeprITPP7e/mxOFgAD46U8hJKT9jiu89pqdqv7ssy3P88or8N13bX6qropCHUJCuhIVNZrc3A/sivHj4Y03bHwUrKcALeuZvvWWfQzDb3/rH2NPBG++CSNGwOjRNk5dUdHaFln27LGTAeLidJynLmvW2O8xY3zTQpsjJwc++wy+/dZ6ho2xdKn9/0891XZ2GhvcX70aBg60naq+fduvKHzxhf1+7jkrmM0h4svz+OONP2etDaCicAgJCT+lpOR7nM4G3MIePaxANNczXbMGrr7a9pg++MAOih4Nx/vEKSlp2QkM9hhXroRLLrGzWTIy4Kmnjq89R8vu3Ta0Z4zOCKvLmjXQu7cda1m/vmX/9Qcf+MbI/ve/xtMtWAChofDQQ/Z8Xrq04XSrV9uOBED//u1TFAoKrOhOmADZ2bbz1BwbN9pQ07RptlPz3nv+t/Mo8asoGGMmG2O2GmO2G2NmN7D9VmPMJmPMOmPM58aYXv60pyUkJl4AiM9bqEtAAKSm+nqme/YcfoNObi5Mnw7x8XYWU3k5zJ/v2+521785rjGefBKSk4/fzJrly21DetVVLUv/1lv2+6KL4Mwz4bzz4M9/huLi42PPsbBnD6Sk2N+nnGJFoi2NebQWa9ZAWpoNq7lcVhia4/337XnRr1/TovDxx1Zspk614tBQCCkry45r1BWFnTvb3/PCliyx1/Cf/gSDBtkZX81d097Q2+OPW29r7tyWtQOtgN9EwRgTADwDTAEGApcYYwYekuwHYJSIDAXeBVp5gjVERAwlPHwQ+/Y9gUgDs4y8PdPMTDtoNGIELFxot2Vn25DRgQP2Ypsxw87W8PYkXC47k2n8+Kan9lVW2gb44EG4/PJjb/C++ALOOccOJr73nrWzOd580w6k9expl2fPtvm9N/U1RkmJFc533225fdnZdl91Y+JNsWePbxJAnz62XpsKfTRHG704j4iSEnteekUBmh9XKCmxoaOf/cx2ZJYsafi8TE+3n6lT7Q2cP/6xFQURu/7qq+055h1k9opCv3723G1v4b0vvrD1cNppcPPNVoyXLWs6z+ef27YjNRVuu816Gs3laS1ExC8f4HRgYZ3lu4C7mkg/HPi6uXJHjhwp/ubAgddk8WIkO/u/h2+86SaRyEiRUaPs9+DBIsHBIi+8IHLqqSJhYSIff+xL/7vf2e0FBSKPPioCIgEBIiNGiOTmNmzAvHk23a9+Zb///OejOxCPR+Sll0RCQqydn39uy/vrX5vOt2GDTffUU7511dUiiYkil17adN6337Z5L7qo5Xbed5/N01zZIiJFRTbtI4/Y5S++sMuffdby/dVlxQqRrl1FXnzx6PLv3y+yd+/R5T2efP21rYcPPrD/e2KiyC9/2XSeN9+0eZYtE/nmG/v79dcPT/f3v9ttO3bY5WeescuvvSaSlGR/g61HY0SKi226FSvs+v82cB2dDGzcKFJefvj6AQNEJk+2v8vKROLjRaZPb7wcl0skKkrkuuvscnm5SKdOIhMn2v/qBAGslJa03S1JdDQf4OfAi3WWLweebiL908A9zZV7IkTB7XbJ8uV9ZMWKEeI59E974gnfRfB//yeSlycycqRdjo4W+fLL+um/+85uu/deKxjTpoksWGAb6qFDRQ4erJ/e47EN+JAh9vdFF4kEBoqsWlU/3Ysvivztb42fVPv3i5x/vt33xInWThGR004TGTSo6ZPx9ttFHA6RrKz666+4QiQuzp7kjXHppXafnTq17ISvrBTp3Nk2JiEhIvn5Tadft86W/9ZbdnnvXrv83HPN7ysvT+TJJ0UqKuyyyyWSlub7P595pvky6lJSItKrl73gly49srxN4XYfeR5vQ+0VqMmTRYYNazrPrFm2Ua+utvvs3LlhMf/JT0T69fMt797tq7NevUTWrrUdnpgYkeHDfemKi4+tU9MQVVUi118v8vLLx6/Mhli1yp6TI0eK7NvnW5+ZaY9p7lzfurvusmm9onkoXsF9+23fumeftevefdc/9jfASSUKwGXAciCkke3XASuBlT179vRTldVn//6XZPFiJDd3Qf0Nn35qq+2BB3zrCgqsR/DDD4cX5PGIpKbaPJGRvov2s8+sSAwYYBtwLwsX2rT/+pddzsuzPbDx431psrNFQkMbv+C++872FENDRR5/vH4j89xzNt/33zd84JmZ1q5f/OLwbe++a/M21gA6nSKxsfYDIps2NZyuLq++6uv5g220m2L+fJtu+XK77HZbMbn99ub3dcstNu9559nG5bHHfL3jCy6Qw7yj5vjNb2xjkJJi63rBgubz1GX7dpGrrhI5cMC3bv9+keRkkaefPrKyrr3W9li9Qnz33dYjbainK2KFMTLS5qtbRlSUFWovr71my7nttvr5Tz/ddmoyM33rCgsP9367d7edibp4PId3htLTRW691f6/jXUm3G6Riy+2/1NUlL0O/MX06XYfkZH2+vNeL97ztW4nbd8+23G75ZaGy3rwQZsnJ8e3rrra1l+vXof/R6Wltqy1a+uv/9//Dq+3I6AtiEKLwkfAOcBmoFNLyj0RnoKIiNtdJd9801NWrTq9vrfgdtsT5EjcvrvuslX997/XX790qT3p+vSxgrJihe3Vd+lS/8J88sn6jfGcOXZ50iT7/c9/+tIuWCASHi7Su3fDjXJhoW3Afv3rhm29/np7gjfU6ykutqEwbwPh8Yhs3eqri0WLrD1/+1v9nrfHI3LJJbbRqesJeDw2DNe/v/09cqTPQ2qMp56yZdf1Yvr3F/nZzxrPI2J79TExtq7B9qTDw0V++lO7v6oq61kFB9cX6cZYtsyWc/PNtnEaPlwkKMjnwRyKx1O/USgvtz15EPnDH3zrH3rIrgsKsuLeUkaPFjn7bN/y++/bcr799vC02dm+xrVuqPPDD6U2jLd8ue9/nDjRnjd1qahomUfz4x+LjBnjWy4oELnwQp84f/ed7aiEh0ut9zFkiBXq6mpfPo9H5IYb7PYbbrCebGON8LGyZo3dz5w51jPt1cvub9Yse83Fxx9+7L/4hRWRoqLDyzvzTOuRHsrixYd3MEVsiNrrbW/bZtf985+2A/L//t9RH1ZbEIVAYCeQCgQDa4FBh6QZDuwA+ra03BMlCiIi+/Y9W+MtfHhsBeXm2gay7knu5ZtvbNjJe0Ec6pqK+GKQkybZ34mJtjFzOkWmTrUnyymniPzoR7ZBT0s7PPRTl8susw3kl1/amKiXbdtsr/DGGxvPO2mSHTsRsV4K2IZMxPacw8JsmT16iMycadd/9ZXv2Lp0EXnjDds79sbBveLRnBcjYj2C0ND6wjF9ug19HNpw1eUf/7Blf/21LwQYESGyZ48vzY4d9uL//e8bL0fE7qdPH+sBlpb61p1xhv0v6oq0lz/+0W674w7boF59tbWhXz/731ZW2oYmNdU2oj172t+HHtPnn9vw39atvnUul62Tur35jAxfg/7ll7a+0tPtscfHW9G577769eh02s5C3Qb65z/3hduOhhtusJ7cDTfY/6BXL3uOXnWVtcO7n3PPFdm1y4aFBgyw6/r0sXkefNCKLvj+m1/+0gr47t2+fR08aPNfc409J5csadxT8nhsJ6Yh4f35z20D7+3A5OTY/817nc6YcXge7/jJ44/bsj/80Iprv352/aGeVt19hYX5xHvpUpt+5kwb2uvVy9epnDKl/vV6hLS6KFgbmApsq2n4765Z9wBwQc3vRcBBYE3N54PmyjyRouB2O2X58r7y3XcDxe1uIo5+rGzdKvL889Y9XL264Z6yN7ziHXz2eg1lZbbBufhi2yO57LKGeyt1+fZbe0GBbQRHjLAX209+YhuEpgTF21O//377nZBgheSbb6wQTJtm011+uT2pvV6CV4TqxvDBri8psXmKiuz+64Y0ROzFffbZto7OP98nSl6WL7fH8atf2WWPx4ZP0tJsQ+/x2IZ0xAhf3b7+esPhnlmz7MXfkMA4nfb4ExPt/j7/vP72sjJ74YLIX/7i29fKlbaO+va125KT7fc994h88onUhrA++0xqB3C//trmmTnTV47HYz0CsB0AbyfD28N/9dX69jzxhLUV6jfA48bZQdTGKCqydT13bsMdmSNh1Srb4EdG2n2npPhCf8XF1sZ//7t+z9vttoPTI0b4bB471ta9ty727rViM2uW7Ux4Bdl7TnnzJSWJfPSRr2yPxy6PGuVLM3WqbdTz832N+913N1wvL7wgsmVLw8c6bpxtxM85x5bRubO9Hv70p8ZDXXv3WvEPCrKeWZ8+1ssvLbV1FxVly7r4YuvNHgNtQhT88TmRoiAikp39nixejGRmPn9C93sYxcV2kBdsw3CssxaysqwI3XOPyIQJ9qT0NlRNUXeQccIE2ztLSfE1Ot6xkJdessuLFtWPtzqd9qJ86inbe3rvvfrl//KXttfrbbTKymz5Xvu8vcpDufNOqQ2HeH8HBdmY9j//aZfnzWu+Xlavtmkffrj++sJCX2/1rLNsQ98QVVVWBMHONikttRMHunWzjc7HH9vfU6b4Bnj79LGN2syZth69PXOvJ+YNSXnHs6ZOtd+PPWbDjlFRdh/eWT91KSuzntjll9vBzS1bTuiMl1pcLjurzetZtQSPx3qNdcct6nL77b5zYsAAG+5ZudLWaW6unYk1dKjd/rvfWY/DGz5MTbXn6MMP+8bAvJ+IiMZnBjaFd8wtLs6GfJ3OluXLz7ehNO/+Fy/2bfvuO+t9HKs4i4rCccPj8ciqVePk66+7iMtVckL3fRjesYTG4tbHQkmJ7cm35EQeO9a6xd4ZTd98Y3u1Docvbr5zp+/iA19stDmysmzvbtgwG1LxNvBLltg4/lVX1Z/F4aWiQmTgQOuKgw2DrFnjmzKZkNB4KOFQJk2yvTxv4+x02t5fYKDdd3ONqtvtc/m7dbPfH9YJQXrFwMtf/2rTBATUj5O7XHacJSnJNlITJ1qRq6y0A+MhIdbOHj3qz5DpKBQXW2Fctarx/6S83J4L3gb3zDNtiKnueV5QYD2jJ56wvfW6jfKR4PHYjpb3ujgS3G7b+Dc30eIYUFE4jhQWfiOLFyO7ds054fuuR0WFyDvvHN2UxeNJUVH9gXARe1HNnu1b9nhsXBxsWOpI8M4wuvBC2xA3N9/ey/ff24by//0/Xx1t2mTdce99DS3Bez/HWWfZ+vaG7F566ciOY948661ceWXT6fLyfLPJDg3rrF1r62DMGKmNWYvYwfC4OPtpKhSkWFavth2VDoyKwnFmw4afy9KlEVJZ2YKZKYrliivsKTZ//pHnvfFGmzcx8chc+ZIGvLkjDZd4PHbevTf2f+gMoSMhK6tlrv/s2Y3f8Hfvvb66qBt+2bLFTmtVlBbQUlEwNu3Jw6hRo2TlkTwW+DhRXr6dFSsG0qXLVfTr9/wJ3/9JyfLl8PLL8PTT9rlRR0JFhX2Xw6WX2ucutQZuN3z6qX3+1PXXg6OVnh9ZVWWfQXXhhXDlla1jg3LSY4xZJSKjmk2notBy0tNvITPzKUaPXkdExKBWsUFRFOVoaKko6KOzj4CUlHsJCIhix47ft7YpiqIofkFF4QgICkqgV697yM9fwIEDL7e2OYqiKMcdFYUjJDn5t8TGns3WrdeQn/9Za5ujKIpyXFFROEIcjmAGD36P8PCBbNw4g5KSNa1tkqIoynFDRbmyVuUAABQ8SURBVOEoCAyMYejQBQQGxrB27TkUFS1vbZMURVGOCyoKR0lISHeGDVtMYGAsa9f+mNzcJl5lqCiKcpKgonAMhIf3YcSIb4iIGMKGDReyZ89DiOi7ghVFOXlRUThGgoM7kZb2BZ06XcSuXfewdu05VFbubW2zFEVRjorA1jagPRAQEMGAAa8TFzeJ9PTfsHx5LxyOUAIDEzDG4PFUEhAQzfDhXxMS0qW1zVUURWkUFYXjhDGGrl2vJibmDHJz/4vLlYvLlQcYjAkiK+tFMjIepU+fv7W2qYqiKI2ionCcCQ/vS8+edx623uOpZP/+f9Cjx+/VW1AUpc2iYwoniF697sHjcZGR8Whrm6IoitIoKgoniPDwPnTufBn79/+DqqoDTab1eKrYt+8p0tNvwuOpPkEWKoqiaPjohNKr1z0cPPgfNmz4KfHxk4mMTCM8fCBhYX0AKC/fTGHhUjIy5lJVlQFAePggune/vjXNVhSlA6GicAIJD+9Dnz6Ps3//P9mz5y+AvafBmEAgAJEqAKKiTqNfv3ns2fMgu3ffS6dOFxMUFAuAx+PE4Qg+Jjuqqg6wf/8zJCffSlBQ3DGVpShK+0JF4QSTnHwTyck34XZXUFa2kfLyzZSXb0bERWTkcCIjRxAe3g9jDEFBCaxaNZI9ex4gNfVBtm+/lQMH/kXv3n8hOflWjDEUFX3N3r0P06PHncTGntHs/j0eF5s2zaSo6CsqKnYycOBrJ+CoW05VVSYVFTuJjR3f2qYoSodERaGVCAgIIzp6FNHRjb/zIipqOF27/orMzKfIy/uQiortREaOYMeO2ykuXk5ISA/27XsCEAoKvmDIkA+Jizuryf3u2HE7RUVfERd3DtnZr5OUNIOkpAupri4mK+sFEhMvJCwstdH8IkJu7v/hdO4nOnosERFDcTiCGk3v8VThcIQ0Wx8A1dUlrFlzFhUV2xk27DPi4s5uUb7jRWXlXpzOA0RHjzmh+1WUtoRf37xmjJkM/B0IAF4UkYcP2R4CvAKMBPKAWSKyu6kyW/PNa62B05nNd9+dWnOD3KvExp5FRsZj7Nw5G/DQrduv6dHjNtavn0Zl5U569foj5eVbKCr6Co+nHIcjhICAaCIjhxIYGE9m5pMkJ99C796Psnr1WKqqMujb92l27LiDqqq9BAUlMWTIfKKjTwOsCBhjABt22rbt/5GX90GtfQ5HBN26XVsz1bZrHbtz2LLlaoqKljFo0H+Jjz+nyeMUETZvvozs7DcJCemBx1PBqFE/EBLSrcV1VVLyA7m579O58+WEh/c9glqGsrJNrFlzFi5XDr17P0qPHrfVHvehuN3lFBR8Rnz8eTgcgYdsKyMz8xkqK/eQmvqnNhWeE3Gzd+9cIiIGkph4QWubo5xgWv11nMaYAGAbcC6wD1gBXCIim+qkuQEYKiLXG2MuBn4mIrOaKrejiQJAZeU+AgOjCQyMrl1XXPw9ItXExPwIsI3w2rXnUFa2jqCgRGJiJhAUFI/HU4XLlUdp6VqczkxiYiYybNhnOBxBlJZuYNWqEYi4CAvrR2rq/ezc+Qeczv306HE7paXrKSxcDHgIDu6Cy5WL211B795/JjHxQkpKviMv7yMOHnwdYwLp1GkmkZEjCQpKYOfOO3G58gkJSaaqKoMBA14jMXEaRUVfUlT0NW53GSJVBAV1IiZmHGVlG0hPv5GUlAdJSprBqlWjiYoawbBhXxzW8IoIFRXbKCr6GqfzIC5XHoWFn1Naah9jHhT0/9u79+C46uuA49+zu9qVtFpptZIt2ZJtGbDxC4NxyrOEd2xedsLAhOBQkpIy7ZAhZDITIDSF0kwZUgaaZkigTWggMY8GE6IygWAMcUqIjQ04fkJsbMmSkfWWVq/Vvk7/uFcbybaMbJCllc5nRuO9d3979Ts663v2/nb395vC4sUvEwotJZnspqlpNYHADCKR5Yh4SKf7aW5eQzodo7j4clKpLrZsuQQRIRQ6i9bWasrLb2H27H/B7y8fUhwSiVa2bbuaaHQDxcXLWLjwf/D5Ckmlemlo+C9qax8gkWgEPAQCFcyfv3rYobB0Ok539xYKCk4/7GpKNc3Bg0/R1PQMsVgN/f31hMMXcsopj5CffyrpdJLOzvV4vUVHvdockErF2LXry7S0rAE8zJ//FGVlq4b8TVtaXqC29l+ZNu1rTJ/+98MWxYH2wBHbpNNxWltfIpFoRTVFTk6EkpIVeL25H9vPYxGNbqa9/TUKC8+hqOj8o16xfhKqKXdWguCoHP9EGQ9F4VzgPlVd5m7fDaCqDwxq81u3zR/Febf1IDBFj9KpyVgURiqd7icWqyMv7yREDv+0cTzegs8XGnICamx8mr6+3cyY8W283jzi8Sa2bVtBV9dGcnOrKC6+HK+3gHi8AVWlqupegsH5Q47b17eX/fsfoKWlmkSiCYC8vFNZuPA5AoGZbNt2DdHoW3i9haRSnQCI+PF4AqRSXZnjFBdfxuLFryDipbHxaXbtWoXfX05h4XkEgwtIJNqIxw/S1fU2/f31mcd5PPkEgwspL/8KodBn2LHjepLJdioqbqOh4YlMn/Lz5xOJLKex8Wn3xE2mLzk5EU4//Q3y8+dSU3MvtbXfA8DrLSQYXEQk8jkKC89jz57b6evbx/Tpt3LgwI/cV93X8tFHj5JItBAOX8zs2d9DJIddu26kr28vpaUrKS1dSTh8MSCk0700N6/hwIFHicc/wueLUFa2ikhkOV5vAalUNzU199LVtZn8/HkEg4vIySmlsfFp0uleSkpW0Nn5ZiauSGQ5M2d+B9UEPT3bSSY7CQQqCQQq3N/XR13dw3R2ruekkx6kre0VOjrWM3fu4xQVnUci0Upd3UO0tlbj80VIJtsoLf0Cc+c+BgjJZDvxeAP9/fX09u4mGv0D0egGvN5CSkqupLh4GX5/OV5vPh0dv6Ou7mHi8QNDniM5OaVMm3YrhYXn4vHk4vUWkJs7E7+/nFishqam52hre5lksoN0ug+fL0JJyVWUlFxDIFAJQCrVTV/fbnp6dtLUtJqurr+cB3y+MHl5p5BItJBMdhAIzCQYXERBwRmEwxdSUHBm5sWFaoqenu10dr5JNLqJ7u536OvbS0nJ1VRU3EZR0QXu9DRxGht/wf79DxCL1VBe/lVmzbqHQGAmiUQT3d1baW9fS3v7WhKJNnJySvH7pxIOX0xp6RcyV6uqadrbX6eh4XG6ut6hsPA8iosvIxRagt9fgdebT2fnH2hvX0ci0YLfPxW/v8zN/eLDXpgcr/FQFK4Dlqvq19ztm4CzVfXrg9psd9vUu9sfum1ahjuuFYXRp5oiHm86ridjPN7ovvexBK83H3CGW/buvYtUqoeSkmsoLr4Mn68AgESijc7Ot+jp2cq0aX+H3z8lc6ympudoaflfotG3iMX24fMV4/eXEQwuorj4csLhiwgEZuD15g3pQyxWz9aty+jt3Uk4fClVVffR319LXd1DdHdvIRK5gsrKb+L3T6O9/VV6e3dRWfktgsF5mWN0dm6gq2sTvb0f0NW1ia6uTYDi9RZy2mnVhMMX0ta2lh07riOVihKJXMXMmXcOuSpIJruoqbmPpqZnicc/OuxvVVz8OaZO/SLt7Wtpbn4B1XjmPr9/Oief/H2mTr0xk4N4vIm9e79DS8saiosvY+rUG+nr283+/Q+STLYdNS8iOcyb9yRlZV8ilepl27YVdHSsy9zv8eRRVXU/lZW3c+DAD9m79y5Uj/QdGSEYPM0tJi20tb1KKhUd0iIcvogZM+6koOA0wEtv7w7q63/oDjsOPd+I+DNxh0J/RSBQiceTSyy2j2h042HtB+TnL2D69H9gypRriUY30tpaTX9/A37/FLzeImKxffT0bKe/35mc0ustwOeLAEoy2ZF5MZKTU0YotBS/fxotLWtIJjvwegvxeAKk0/2kUlEKCpYSCi3h4MGnAMXjycvELJJDUdH5bqFopb+/lp6e7e6xpyDiJZ3uJ5lsx+croajofKLRP5JINB8xRzk5pSQSzUP+9h5PHiI5iPiorLyDqqrvDpPlo5tQRUFEbgVuBZg5c+bS2traUemzGb9UUzgjkiOTTEbp6/uQUGjJoGMoqVTXkGG4kYrHm+no+B2h0Jnk5Z2c2d/XV0M6HRtSUA7vu9Ld/S7R6CZEfHg8AUKhpQSDCzJtEol2envfJ53uJZ2OU1R0QaZwjiTWlpZf4/eXEwyeRk5OMf39H9Hf77xa93rzCQQq8PvLMo9JpfpoaXkREQ9ebxEFBYuHvH/T1fUebW0v4/UW4vOF8fvLCQQqyc2dMWQYxRkC+xPJZCepVDe5uTMIhZYesZ8DfUqnY6RSUWKx/cRiNeTkTGHq1OvJzZ11yN+8cUjR8XhyycubQ17enBG/YInHG+no+D2dnf9HMhlFxIPHk09h4dkUFV1Abu6szHFSqV6amp6lu/u9zBT4JSUriESWISLEYnXU1/+AdDpGfv5c8vPnUVh43mF5isX209LyIj09O9w9Qjj8WUpLr8XrzUU1TU/Pdnp7/0w8foBksoNQ6GzC4QvweoOopkkkWunt3Ul391ZisVpUk6gmiUQup7R05cfGfSTjoSjY8JExxowTIy0KoznNxSZgjojMFhE/cANQfUibauBm9/Z1wOtHKwjGGGNG16h9T0FVkyLydeC3OB9JfUJVd4jI/cBmVa0Gfgr8XET2AG04hcMYY8wYGdUvr6nqb4DfHLLvnwbdjgHXj2YfjDHGjJzNkmqMMSbDioIxxpgMKwrGGGMyrCgYY4zJsKJgjDEmY1RnSR0NItIMHO9XmkuBYafQyEIWz/g1kWKBiRXPRIoFRh7PLFWd8nGNsq4ofBIisnkk3+jLFhbP+DWRYoGJFc9EigU+/Xhs+MgYY0yGFQVjjDEZk60o/OdYd+BTZvGMXxMpFphY8UykWOBTjmdSvadgjDHm6CbblYIxxpijmDRFQUSWi8gHIrJHRO4a6/4cCxGZISJviMhOEdkhIt9w90dEZK2I7Hb/HT+rxI+AiHhF5D0Recndni0iG90cPedOuZ4VRCQsIs+LyPsisktEzs3W/IjIN93n2XYReUZEcrMpNyLyhIg0uYt4Dew7Yi7E8R9uXFtF5Myx6/mRDRPPv7nPta0i8isRCQ+67243ng9EZNmx/r5JURTEWbLrUeAKYAHwJRFZcPRHjStJ4FuqugA4B7jN7f9dwDpVnQOsc7ezyTeAXYO2HwQeUdVTgHbgljHp1fH5AfCKqs4DTseJK+vyIyIVwO3AZ1R1Ec609zeQXbn5GbD8kH3D5eIKYI77cyvw4xPUx2PxMw6PZy2wSFUXA38G7gZwzws3AAvdx/xIjmXJQiZJUQDOAvao6l51FoR9Fji+Ne3GgKo2qOq77u0unBNOBU4MT7rNngQ+PzY9PHYiUglcBfzE3RbgEuB5t0nWxCMiRcBncdYHQVXjqtpB9ubHB+S5qyHmAw1kUW5U9fc467MMNlwuVgJPqWMDEBaRaSempyNzpHhU9VX9y0LOG4BK9/ZK4FlV7VfVfcAenPPfiE2WolAB1A3arnf3ZR0RqQKWABuBMlVtcO86CJQN87Dx6N+BbwNpd7sE6Bj0RM+mHM0GmoH/dofDfiIiQbIwP6p6AHgI2I9TDDqBd8je3AwYLhcT4dzwt8DL7u1PHM9kKQoTgogUAGuAO1Q1Ovg+dxnTrPgomYhcDTSp6jtj3ZdPiQ84E/ixqi4BejhkqChb8uOOta/EKXTTgSCHD11ktWzJxUiIyD04w8urP61jTpaicACYMWi70t2XNUQkB6cgrFbVF9zdjQOXuu6/TWPVv2N0PrBCRGpwhvIuwRmTD7tDFpBdOaoH6lV1o7v9PE6RyMb8XAbsU9VmVU0AL+DkK1tzM2C4XGTtuUFEvgJcDawatLb9J45nshSFTcAc9xMUfpw3YqrHuE8j5o63/xTYpaoPD7qrGrjZvX0z8OsT3bfjoap3q2qlqlbh5OJ1VV0FvAFc5zbLpngOAnUicqq761JgJ9mZn/3AOSKS7z7vBmLJytwMMlwuqoG/cT+FdA7QOWiYadwSkeU4w68rVLV30F3VwA0iEhCR2ThvoL99TAdX1UnxA1yJ8y79h8A9Y92fY+z7X+Nc7m4Ftrg/V+KMw68DdgOvAZGx7utxxHYR8JJ7+yT3CbwH+CUQGOv+HUMcZwCb3Ry9CBRna36AfwbeB7YDPwcC2ZQb4Bmc90MSOFdxtwyXC0BwPpn4IbAN51NXYx7DCOLZg/PewcD54LFB7e9x4/kAuOJYf599o9kYY0zGZBk+MsYYMwJWFIwxxmRYUTDGGJNhRcEYY0yGFQVjjDEZVhSMOYFE5KKBWWGNGY+sKBhjjMmwomDMEYjIl0XkbRHZIiKPu2s/dIvII+5aA+tEZIrb9gwR2TBobvuBufpPEZHXRORPIvKuiJzsHr5g0NoLq91vDhszLlhRMOYQIjIf+CJwvqqeAaSAVTiTw21W1YXAeuBe9yFPAXeqM7f9tkH7VwOPqurpwHk430oFZ5bbO3DW9jgJZ24hY8YF38c3MWbSuRRYCmxyX8Tn4Uyglgaec9v8AnjBXUshrKrr3f1PAr8UkRBQoaq/AlDVGIB7vLdVtd7d3gJUAW+OfljGfDwrCsYcToAnVfXuITtFvntIu+OdI6Z/0O0U9v/QjCM2fGTM4dYB14nIVMis7zsL5//LwEyhNwJvqmon0C4iF7j7bwLWq7NCXr2IfN49RkBE8k9oFMYcB3uFYswhVHWniPwj8KqIeHBmp7wNZ/Gcs9z7mnDedwBnKubH3JP+XuCr7v6bgMdF5H73GNefwDCMOS42S6oxIyQi3apaMNb9MGY02fCRMcaYDLtSMMYYk2FXCsYYYzKsKBhjjMmwomCMMSbDioIxxpgMKwrGGGMyrCgYY4zJ+H9iPvbiko6i9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2016 - acc: 0.9504\n",
      "Loss: 0.2015724228704706 Accuracy: 0.95036346\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9442 - acc: 0.7083\n",
      "Epoch 00001: val_loss improved from inf to 0.62360, saving model to model/checkpoint/1D_CNN_custom_3_BN_9_conv_checkpoint/001-0.6236.hdf5\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.9441 - acc: 0.7084 - val_loss: 0.6236 - val_acc: 0.8321\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3586 - acc: 0.8911\n",
      "Epoch 00002: val_loss improved from 0.62360 to 0.33616, saving model to model/checkpoint/1D_CNN_custom_3_BN_9_conv_checkpoint/002-0.3362.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.3587 - acc: 0.8910 - val_loss: 0.3362 - val_acc: 0.8921\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2503 - acc: 0.9248\n",
      "Epoch 00003: val_loss improved from 0.33616 to 0.24319, saving model to model/checkpoint/1D_CNN_custom_3_BN_9_conv_checkpoint/003-0.2432.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.2502 - acc: 0.9248 - val_loss: 0.2432 - val_acc: 0.9259\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9459\n",
      "Epoch 00004: val_loss improved from 0.24319 to 0.23913, saving model to model/checkpoint/1D_CNN_custom_3_BN_9_conv_checkpoint/004-0.2391.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.1820 - acc: 0.9459 - val_loss: 0.2391 - val_acc: 0.9259\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9571\n",
      "Epoch 00005: val_loss improved from 0.23913 to 0.20954, saving model to model/checkpoint/1D_CNN_custom_3_BN_9_conv_checkpoint/005-0.2095.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.1464 - acc: 0.9571 - val_loss: 0.2095 - val_acc: 0.9408\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9665\n",
      "Epoch 00006: val_loss did not improve from 0.20954\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.1174 - acc: 0.9665 - val_loss: 0.2245 - val_acc: 0.9329\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9706\n",
      "Epoch 00007: val_loss did not improve from 0.20954\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.1015 - acc: 0.9706 - val_loss: 0.2992 - val_acc: 0.9168\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9783\n",
      "Epoch 00008: val_loss improved from 0.20954 to 0.19634, saving model to model/checkpoint/1D_CNN_custom_3_BN_9_conv_checkpoint/008-0.1963.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0782 - acc: 0.9782 - val_loss: 0.1963 - val_acc: 0.9408\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9789\n",
      "Epoch 00009: val_loss improved from 0.19634 to 0.18956, saving model to model/checkpoint/1D_CNN_custom_3_BN_9_conv_checkpoint/009-0.1896.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0737 - acc: 0.9789 - val_loss: 0.1896 - val_acc: 0.9427\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9845\n",
      "Epoch 00010: val_loss did not improve from 0.18956\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0564 - acc: 0.9845 - val_loss: 0.1965 - val_acc: 0.9411\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9882\n",
      "Epoch 00011: val_loss improved from 0.18956 to 0.17059, saving model to model/checkpoint/1D_CNN_custom_3_BN_9_conv_checkpoint/011-0.1706.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0467 - acc: 0.9882 - val_loss: 0.1706 - val_acc: 0.9462\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9859\n",
      "Epoch 00012: val_loss did not improve from 0.17059\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0521 - acc: 0.9858 - val_loss: 0.1987 - val_acc: 0.9420\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9832\n",
      "Epoch 00013: val_loss improved from 0.17059 to 0.15016, saving model to model/checkpoint/1D_CNN_custom_3_BN_9_conv_checkpoint/013-0.1502.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0590 - acc: 0.9832 - val_loss: 0.1502 - val_acc: 0.9564\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9922\n",
      "Epoch 00014: val_loss did not improve from 0.15016\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0333 - acc: 0.9921 - val_loss: 0.1536 - val_acc: 0.9543\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9906\n",
      "Epoch 00015: val_loss did not improve from 0.15016\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0367 - acc: 0.9906 - val_loss: 0.2288 - val_acc: 0.9304\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9874\n",
      "Epoch 00016: val_loss did not improve from 0.15016\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0441 - acc: 0.9874 - val_loss: 0.1734 - val_acc: 0.9455\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9952\n",
      "Epoch 00017: val_loss did not improve from 0.15016\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0215 - acc: 0.9952 - val_loss: 0.1648 - val_acc: 0.9532\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9966\n",
      "Epoch 00018: val_loss did not improve from 0.15016\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0168 - acc: 0.9966 - val_loss: 0.1877 - val_acc: 0.9506\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9946\n",
      "Epoch 00019: val_loss did not improve from 0.15016\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0215 - acc: 0.9946 - val_loss: 0.2602 - val_acc: 0.9371\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9935\n",
      "Epoch 00020: val_loss did not improve from 0.15016\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0246 - acc: 0.9935 - val_loss: 0.3136 - val_acc: 0.9164\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9879\n",
      "Epoch 00021: val_loss improved from 0.15016 to 0.14394, saving model to model/checkpoint/1D_CNN_custom_3_BN_9_conv_checkpoint/021-0.1439.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0426 - acc: 0.9879 - val_loss: 0.1439 - val_acc: 0.9550\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9975\n",
      "Epoch 00022: val_loss did not improve from 0.14394\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0125 - acc: 0.9975 - val_loss: 0.1852 - val_acc: 0.9495\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9969\n",
      "Epoch 00023: val_loss did not improve from 0.14394\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0151 - acc: 0.9969 - val_loss: 0.2034 - val_acc: 0.9467\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9969\n",
      "Epoch 00024: val_loss did not improve from 0.14394\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0132 - acc: 0.9969 - val_loss: 0.2594 - val_acc: 0.9336\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9951\n",
      "Epoch 00025: val_loss did not improve from 0.14394\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0179 - acc: 0.9951 - val_loss: 0.1742 - val_acc: 0.9525\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9943\n",
      "Epoch 00026: val_loss did not improve from 0.14394\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0199 - acc: 0.9943 - val_loss: 0.1819 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9968\n",
      "Epoch 00027: val_loss did not improve from 0.14394\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0137 - acc: 0.9968 - val_loss: 0.2691 - val_acc: 0.9299\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9931\n",
      "Epoch 00028: val_loss did not improve from 0.14394\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0245 - acc: 0.9931 - val_loss: 0.1849 - val_acc: 0.9520\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9985\n",
      "Epoch 00029: val_loss improved from 0.14394 to 0.14176, saving model to model/checkpoint/1D_CNN_custom_3_BN_9_conv_checkpoint/029-0.1418.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0076 - acc: 0.9985 - val_loss: 0.1418 - val_acc: 0.9637\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9989\n",
      "Epoch 00030: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0060 - acc: 0.9989 - val_loss: 0.1774 - val_acc: 0.9557\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9943\n",
      "Epoch 00031: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0190 - acc: 0.9943 - val_loss: 0.2843 - val_acc: 0.9290\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9967\n",
      "Epoch 00032: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0124 - acc: 0.9967 - val_loss: 0.1752 - val_acc: 0.9567\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9968\n",
      "Epoch 00033: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0125 - acc: 0.9968 - val_loss: 0.1875 - val_acc: 0.9567\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9951\n",
      "Epoch 00034: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0175 - acc: 0.9951 - val_loss: 0.1652 - val_acc: 0.9555\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9956\n",
      "Epoch 00035: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0166 - acc: 0.9955 - val_loss: 0.1772 - val_acc: 0.9564\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9952\n",
      "Epoch 00036: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0181 - acc: 0.9952 - val_loss: 0.1524 - val_acc: 0.9581\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9994\n",
      "Epoch 00037: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0037 - acc: 0.9994 - val_loss: 0.1441 - val_acc: 0.9653\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 00038: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0037 - acc: 0.9993 - val_loss: 0.2100 - val_acc: 0.9525\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9967\n",
      "Epoch 00039: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0118 - acc: 0.9967 - val_loss: 0.2008 - val_acc: 0.9522\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9957\n",
      "Epoch 00040: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0142 - acc: 0.9957 - val_loss: 0.1542 - val_acc: 0.9630\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9987\n",
      "Epoch 00041: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0056 - acc: 0.9987 - val_loss: 0.2495 - val_acc: 0.9460\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9940\n",
      "Epoch 00042: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0216 - acc: 0.9940 - val_loss: 0.1495 - val_acc: 0.9620\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9990\n",
      "Epoch 00043: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0046 - acc: 0.9990 - val_loss: 0.1462 - val_acc: 0.9639\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9994\n",
      "Epoch 00044: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0031 - acc: 0.9994 - val_loss: 0.1624 - val_acc: 0.9630\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9989\n",
      "Epoch 00045: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0052 - acc: 0.9989 - val_loss: 0.1936 - val_acc: 0.9550\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9950\n",
      "Epoch 00046: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0163 - acc: 0.9950 - val_loss: 0.1753 - val_acc: 0.9590\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9947\n",
      "Epoch 00047: val_loss did not improve from 0.14176\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0172 - acc: 0.9947 - val_loss: 0.1682 - val_acc: 0.9606\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9966\n",
      "Epoch 00048: val_loss improved from 0.14176 to 0.12473, saving model to model/checkpoint/1D_CNN_custom_3_BN_9_conv_checkpoint/048-0.1247.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0122 - acc: 0.9966 - val_loss: 0.1247 - val_acc: 0.9681\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 00049: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1340 - val_acc: 0.9665\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 00050: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1468 - val_acc: 0.9651\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00051: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1634 - val_acc: 0.9602\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9941\n",
      "Epoch 00052: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0191 - acc: 0.9940 - val_loss: 0.1762 - val_acc: 0.9567\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9957\n",
      "Epoch 00053: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0147 - acc: 0.9957 - val_loss: 0.1496 - val_acc: 0.9653\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9991\n",
      "Epoch 00054: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0043 - acc: 0.9991 - val_loss: 0.1549 - val_acc: 0.9646\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9962\n",
      "Epoch 00055: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0129 - acc: 0.9962 - val_loss: 0.1691 - val_acc: 0.9562\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9983\n",
      "Epoch 00056: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0068 - acc: 0.9983 - val_loss: 0.1691 - val_acc: 0.9588\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9982\n",
      "Epoch 00057: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0069 - acc: 0.9982 - val_loss: 0.1405 - val_acc: 0.9653\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00058: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1505 - val_acc: 0.9646\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9973\n",
      "Epoch 00059: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0098 - acc: 0.9973 - val_loss: 0.1784 - val_acc: 0.9583\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9994\n",
      "Epoch 00060: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0028 - acc: 0.9994 - val_loss: 0.1629 - val_acc: 0.9620\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9964\n",
      "Epoch 00061: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0138 - acc: 0.9964 - val_loss: 0.1492 - val_acc: 0.9658\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9996\n",
      "Epoch 00062: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0023 - acc: 0.9996 - val_loss: 0.1428 - val_acc: 0.9672\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 00063: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1392 - val_acc: 0.9695\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9958\n",
      "Epoch 00064: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0141 - acc: 0.9958 - val_loss: 0.1922 - val_acc: 0.9550\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9978\n",
      "Epoch 00065: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0078 - acc: 0.9978 - val_loss: 0.1539 - val_acc: 0.9630\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9981\n",
      "Epoch 00066: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0076 - acc: 0.9981 - val_loss: 0.1649 - val_acc: 0.9632\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9973\n",
      "Epoch 00067: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0101 - acc: 0.9973 - val_loss: 0.1424 - val_acc: 0.9658\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 00068: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0016 - acc: 0.9998 - val_loss: 0.1359 - val_acc: 0.9695\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9995\n",
      "Epoch 00069: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0021 - acc: 0.9995 - val_loss: 0.1730 - val_acc: 0.9597\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9974\n",
      "Epoch 00070: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0091 - acc: 0.9974 - val_loss: 0.2017 - val_acc: 0.9495\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9989\n",
      "Epoch 00071: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 98s 3ms/sample - loss: 0.0041 - acc: 0.9989 - val_loss: 0.1480 - val_acc: 0.9646\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 00072: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0016 - acc: 0.9997 - val_loss: 0.1563 - val_acc: 0.9653\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9996\n",
      "Epoch 00073: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1364 - val_acc: 0.9688\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9958\n",
      "Epoch 00074: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0141 - acc: 0.9958 - val_loss: 0.2013 - val_acc: 0.9581\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9993\n",
      "Epoch 00075: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0033 - acc: 0.9993 - val_loss: 0.1473 - val_acc: 0.9679\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 00076: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.1805 - val_acc: 0.9616\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9971\n",
      "Epoch 00077: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0098 - acc: 0.9971 - val_loss: 0.1873 - val_acc: 0.9609\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9978\n",
      "Epoch 00078: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0080 - acc: 0.9978 - val_loss: 0.1523 - val_acc: 0.9695\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 00079: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0016 - acc: 0.9997 - val_loss: 0.1550 - val_acc: 0.9667\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9959\n",
      "Epoch 00080: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0161 - acc: 0.9959 - val_loss: 0.1533 - val_acc: 0.9665\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 00081: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0042 - acc: 0.9990 - val_loss: 0.1541 - val_acc: 0.9653\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 00082: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0014 - acc: 0.9997 - val_loss: 0.1526 - val_acc: 0.9672\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9970\n",
      "Epoch 00083: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0113 - acc: 0.9970 - val_loss: 0.1349 - val_acc: 0.9672\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 00084: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.1360 - val_acc: 0.9697\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 00085: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.1452 - val_acc: 0.9676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9961\n",
      "Epoch 00086: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0147 - acc: 0.9961 - val_loss: 0.1387 - val_acc: 0.9672\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 00087: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0020 - acc: 0.9995 - val_loss: 0.1408 - val_acc: 0.9665\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 00088: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0016 - acc: 0.9997 - val_loss: 0.1445 - val_acc: 0.9660\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9978\n",
      "Epoch 00089: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0080 - acc: 0.9978 - val_loss: 0.1348 - val_acc: 0.9681\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 00090: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0018 - acc: 0.9997 - val_loss: 0.1372 - val_acc: 0.9683\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9997\n",
      "Epoch 00091: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0019 - acc: 0.9997 - val_loss: 0.1466 - val_acc: 0.9665\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9985\n",
      "Epoch 00092: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0056 - acc: 0.9984 - val_loss: 0.1649 - val_acc: 0.9602\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9974\n",
      "Epoch 00093: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0093 - acc: 0.9974 - val_loss: 0.1352 - val_acc: 0.9665\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9968\n",
      "Epoch 00094: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0125 - acc: 0.9968 - val_loss: 0.1442 - val_acc: 0.9651\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9981\n",
      "Epoch 00095: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0080 - acc: 0.9981 - val_loss: 0.1508 - val_acc: 0.9644\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9996\n",
      "Epoch 00096: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0024 - acc: 0.9995 - val_loss: 0.1469 - val_acc: 0.9679\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9983\n",
      "Epoch 00097: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0060 - acc: 0.9983 - val_loss: 0.1535 - val_acc: 0.9672\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9999\n",
      "Epoch 00098: val_loss did not improve from 0.12473\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0011 - acc: 0.9999 - val_loss: 0.1307 - val_acc: 0.9706\n",
      "\n",
      "1D_CNN_custom_3_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1868 - acc: 0.9551\n",
      "Loss: 0.18683712394561847 Accuracy: 0.9551402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 10):\n",
    "    base = '1D_CNN_custom_3_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_3_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 75776)             303104    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,599,376\n",
      "Trainable params: 1,447,184\n",
      "Non-trainable params: 152,192\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.4429 - acc: 0.6108\n",
      "Loss: 1.4428655887813706 Accuracy: 0.6107996\n",
      "\n",
      "1D_CNN_custom_3_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 670,736\n",
      "Trainable params: 619,408\n",
      "Non-trainable params: 51,328\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.0920 - acc: 0.7007\n",
      "Loss: 1.0920349958158357 Accuracy: 0.70072687\n",
      "\n",
      "1D_CNN_custom_3_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 415,376\n",
      "Trainable params: 397,584\n",
      "Non-trainable params: 17,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.6660 - acc: 0.8336\n",
      "Loss: 0.6659552693738373 Accuracy: 0.83364487\n",
      "\n",
      "1D_CNN_custom_3_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 5376)              21504     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 521,616\n",
      "Trainable params: 509,200\n",
      "Non-trainable params: 12,416\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.3075 - acc: 0.9259\n",
      "Loss: 0.3074763776527511 Accuracy: 0.9258567\n",
      "\n",
      "1D_CNN_custom_3_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 1792)              7168      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 778,896\n",
      "Trainable params: 773,136\n",
      "Non-trainable params: 5,760\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2016 - acc: 0.9504\n",
      "Loss: 0.2015724228704706 Accuracy: 0.95036346\n",
      "\n",
      "1D_CNN_custom_3_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 256)            327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,082,256\n",
      "Trainable params: 1,078,544\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1868 - acc: 0.9551\n",
      "Loss: 0.18683712394561847 Accuracy: 0.9551402\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_3_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(4, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_3_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 75776)             303104    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,599,376\n",
      "Trainable params: 1,447,184\n",
      "Non-trainable params: 152,192\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 3.3024 - acc: 0.5971\n",
      "Loss: 3.3023646718121267 Accuracy: 0.5970924\n",
      "\n",
      "1D_CNN_custom_3_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 670,736\n",
      "Trainable params: 619,408\n",
      "Non-trainable params: 51,328\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.6391 - acc: 0.7028\n",
      "Loss: 1.6391331536995164 Accuracy: 0.70280373\n",
      "\n",
      "1D_CNN_custom_3_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 415,376\n",
      "Trainable params: 397,584\n",
      "Non-trainable params: 17,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.9339 - acc: 0.8260\n",
      "Loss: 0.9338605107300502 Accuracy: 0.8259605\n",
      "\n",
      "1D_CNN_custom_3_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 5376)              21504     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 521,616\n",
      "Trainable params: 509,200\n",
      "Non-trainable params: 12,416\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3947 - acc: 0.9138\n",
      "Loss: 0.39471251318639344 Accuracy: 0.913811\n",
      "\n",
      "1D_CNN_custom_3_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 1792)              7168      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 778,896\n",
      "Trainable params: 773,136\n",
      "Non-trainable params: 5,760\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2214 - acc: 0.9526\n",
      "Loss: 0.22138694069509782 Accuracy: 0.952648\n",
      "\n",
      "1D_CNN_custom_3_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 256)            327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,082,256\n",
      "Trainable params: 1,078,544\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1764 - acc: 0.9568\n",
      "Loss: 0.17644793132467773 Accuracy: 0.95680165\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(4, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
