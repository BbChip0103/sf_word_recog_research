{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4,5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, \n",
    "                      padding='same', kernel_initializer='he_uniform', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, \n",
    "                      padding='same', kernel_initializer='he_uniform')) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, \n",
    "                          padding='same', kernel_initializer='he_uniform'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, \n",
    "                          padding='same', kernel_initializer='he_uniform'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,493,136\n",
      "Trainable params: 18,444,880\n",
      "Non-trainable params: 2,048,256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 6,864,592\n",
      "Trainable params: 6,181,456\n",
      "Non-trainable params: 683,136\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,338,128\n",
      "Trainable params: 2,109,904\n",
      "Non-trainable params: 228,224\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 846,544\n",
      "Trainable params: 769,744\n",
      "Non-trainable params: 76,800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 668,112\n",
      "Trainable params: 616,144\n",
      "Non-trainable params: 51,968\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 429,776\n",
      "Trainable params: 411,088\n",
      "Non-trainable params: 18,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 416,720\n",
      "Trainable params: 408,784\n",
      "Non-trainable params: 7,936\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 480,464\n",
      "Trainable params: 475,600\n",
      "Non-trainable params: 4,864\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 770,256\n",
      "Trainable params: 765,136\n",
      "Non-trainable params: 5,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4348 - acc: 0.4002\n",
      "Epoch 00001: val_loss improved from inf to 2.08632, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_3_conv_checkpoint/001-2.0863.hdf5\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 2.4348 - acc: 0.4002 - val_loss: 2.0863 - val_acc: 0.4785\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0905 - acc: 0.6925\n",
      "Epoch 00002: val_loss improved from 2.08632 to 1.92642, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_3_conv_checkpoint/002-1.9264.hdf5\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 1.0904 - acc: 0.6925 - val_loss: 1.9264 - val_acc: 0.5374\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5026 - acc: 0.8572\n",
      "Epoch 00003: val_loss improved from 1.92642 to 1.91085, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_3_conv_checkpoint/003-1.9109.hdf5\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.5026 - acc: 0.8572 - val_loss: 1.9109 - val_acc: 0.5339\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2628 - acc: 0.9323\n",
      "Epoch 00004: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.2633 - acc: 0.9322 - val_loss: 1.9990 - val_acc: 0.5453\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9569\n",
      "Epoch 00005: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.1887 - acc: 0.9569 - val_loss: 2.0554 - val_acc: 0.5542\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9682\n",
      "Epoch 00006: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.1459 - acc: 0.9681 - val_loss: 1.9781 - val_acc: 0.5646\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9735\n",
      "Epoch 00007: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.1227 - acc: 0.9734 - val_loss: 2.1637 - val_acc: 0.5642\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9697\n",
      "Epoch 00008: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.1265 - acc: 0.9697 - val_loss: 2.3033 - val_acc: 0.5504\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9754\n",
      "Epoch 00009: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.1050 - acc: 0.9753 - val_loss: 2.2571 - val_acc: 0.5623\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9782\n",
      "Epoch 00010: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0915 - acc: 0.9781 - val_loss: 2.4111 - val_acc: 0.5532\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9761\n",
      "Epoch 00011: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0972 - acc: 0.9761 - val_loss: 2.5389 - val_acc: 0.5397\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9801\n",
      "Epoch 00012: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0870 - acc: 0.9801 - val_loss: 2.6860 - val_acc: 0.5327\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9767\n",
      "Epoch 00013: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0976 - acc: 0.9767 - val_loss: 2.7783 - val_acc: 0.5320\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9811\n",
      "Epoch 00014: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0803 - acc: 0.9810 - val_loss: 2.9206 - val_acc: 0.5309\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9792\n",
      "Epoch 00015: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0841 - acc: 0.9792 - val_loss: 2.8105 - val_acc: 0.5425\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9874\n",
      "Epoch 00016: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0573 - acc: 0.9874 - val_loss: 2.7573 - val_acc: 0.5639\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9836\n",
      "Epoch 00017: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0670 - acc: 0.9836 - val_loss: 2.8787 - val_acc: 0.5560\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9858\n",
      "Epoch 00018: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0629 - acc: 0.9857 - val_loss: 3.0179 - val_acc: 0.5413\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9790\n",
      "Epoch 00019: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0841 - acc: 0.9790 - val_loss: 2.9712 - val_acc: 0.5453\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9827\n",
      "Epoch 00020: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0722 - acc: 0.9827 - val_loss: 3.0408 - val_acc: 0.5458\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9851\n",
      "Epoch 00021: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0634 - acc: 0.9851 - val_loss: 3.2418 - val_acc: 0.5406\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9829\n",
      "Epoch 00022: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0738 - acc: 0.9828 - val_loss: 3.2796 - val_acc: 0.5430\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9839\n",
      "Epoch 00023: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0704 - acc: 0.9839 - val_loss: 3.2276 - val_acc: 0.5425\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9834\n",
      "Epoch 00024: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0755 - acc: 0.9833 - val_loss: 3.2375 - val_acc: 0.5469\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9825\n",
      "Epoch 00025: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0737 - acc: 0.9824 - val_loss: 3.3912 - val_acc: 0.5355\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9858\n",
      "Epoch 00026: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0659 - acc: 0.9858 - val_loss: 3.3826 - val_acc: 0.5455\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9852\n",
      "Epoch 00027: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 136s 4ms/sample - loss: 0.0675 - acc: 0.9852 - val_loss: 3.3233 - val_acc: 0.5579\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9911\n",
      "Epoch 00028: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0453 - acc: 0.9910 - val_loss: 3.3916 - val_acc: 0.5507\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9868\n",
      "Epoch 00029: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0612 - acc: 0.9868 - val_loss: 3.4133 - val_acc: 0.5514\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9866\n",
      "Epoch 00030: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 136s 4ms/sample - loss: 0.0630 - acc: 0.9866 - val_loss: 3.5493 - val_acc: 0.5439\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9861\n",
      "Epoch 00031: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0613 - acc: 0.9861 - val_loss: 3.4482 - val_acc: 0.5497\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9921\n",
      "Epoch 00032: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 136s 4ms/sample - loss: 0.0430 - acc: 0.9920 - val_loss: 3.4706 - val_acc: 0.5537\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9844\n",
      "Epoch 00033: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0761 - acc: 0.9843 - val_loss: 3.4825 - val_acc: 0.5556\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9861\n",
      "Epoch 00034: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0655 - acc: 0.9860 - val_loss: 3.5258 - val_acc: 0.5604\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9847\n",
      "Epoch 00035: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0751 - acc: 0.9846 - val_loss: 3.6079 - val_acc: 0.5546\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9904\n",
      "Epoch 00036: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0497 - acc: 0.9904 - val_loss: 3.5467 - val_acc: 0.5604\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9903\n",
      "Epoch 00037: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0492 - acc: 0.9903 - val_loss: 3.7079 - val_acc: 0.5490\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9882\n",
      "Epoch 00038: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0593 - acc: 0.9882 - val_loss: 3.6595 - val_acc: 0.5628\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9908\n",
      "Epoch 00039: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0514 - acc: 0.9908 - val_loss: 3.6250 - val_acc: 0.5663\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9888\n",
      "Epoch 00040: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0583 - acc: 0.9888 - val_loss: 3.7845 - val_acc: 0.5455\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9901\n",
      "Epoch 00041: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0519 - acc: 0.9900 - val_loss: 3.6890 - val_acc: 0.5551\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9875\n",
      "Epoch 00042: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0639 - acc: 0.9874 - val_loss: 3.8798 - val_acc: 0.5535\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9885\n",
      "Epoch 00043: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0601 - acc: 0.9885 - val_loss: 3.8503 - val_acc: 0.5434\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9926\n",
      "Epoch 00044: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0445 - acc: 0.9926 - val_loss: 3.6834 - val_acc: 0.5688\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9930\n",
      "Epoch 00045: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0423 - acc: 0.9929 - val_loss: 3.9691 - val_acc: 0.5497\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9844\n",
      "Epoch 00046: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0752 - acc: 0.9843 - val_loss: 3.9815 - val_acc: 0.5444\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9891\n",
      "Epoch 00047: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0575 - acc: 0.9890 - val_loss: 3.8296 - val_acc: 0.5530\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9909\n",
      "Epoch 00048: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0536 - acc: 0.9908 - val_loss: 3.8083 - val_acc: 0.5558\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9917\n",
      "Epoch 00049: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0477 - acc: 0.9917 - val_loss: 3.8284 - val_acc: 0.5623\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9924\n",
      "Epoch 00050: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 136s 4ms/sample - loss: 0.0478 - acc: 0.9923 - val_loss: 3.9576 - val_acc: 0.5544\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9867\n",
      "Epoch 00051: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0719 - acc: 0.9866 - val_loss: 3.9218 - val_acc: 0.5544\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9887\n",
      "Epoch 00052: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 136s 4ms/sample - loss: 0.0644 - acc: 0.9887 - val_loss: 4.1048 - val_acc: 0.5392\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9918\n",
      "Epoch 00053: val_loss did not improve from 1.91085\n",
      "36805/36805 [==============================] - 137s 4ms/sample - loss: 0.0487 - acc: 0.9917 - val_loss: 4.0178 - val_acc: 0.5502\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 2.0421 - acc: 0.5047\n",
      "Loss: 2.0421048491914697 Accuracy: 0.5046729\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0005 - acc: 0.4248\n",
      "Epoch 00001: val_loss improved from inf to 1.51890, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_4_conv_checkpoint/001-1.5189.hdf5\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 2.0004 - acc: 0.4248 - val_loss: 1.5189 - val_acc: 0.5698\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2093 - acc: 0.6410\n",
      "Epoch 00002: val_loss improved from 1.51890 to 1.30884, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_4_conv_checkpoint/002-1.3088.hdf5\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 1.2096 - acc: 0.6409 - val_loss: 1.3088 - val_acc: 0.6287\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8602 - acc: 0.7392\n",
      "Epoch 00003: val_loss improved from 1.30884 to 1.22991, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_4_conv_checkpoint/003-1.2299.hdf5\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.8602 - acc: 0.7392 - val_loss: 1.2299 - val_acc: 0.6369\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6037 - acc: 0.8178\n",
      "Epoch 00004: val_loss did not improve from 1.22991\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.6039 - acc: 0.8178 - val_loss: 1.2436 - val_acc: 0.6527\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4366 - acc: 0.8713\n",
      "Epoch 00005: val_loss improved from 1.22991 to 1.22319, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_4_conv_checkpoint/005-1.2232.hdf5\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.4367 - acc: 0.8713 - val_loss: 1.2232 - val_acc: 0.6685\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3171 - acc: 0.9123\n",
      "Epoch 00006: val_loss did not improve from 1.22319\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.3171 - acc: 0.9123 - val_loss: 1.2567 - val_acc: 0.6692\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2380 - acc: 0.9379\n",
      "Epoch 00007: val_loss improved from 1.22319 to 1.19175, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_4_conv_checkpoint/007-1.1917.hdf5\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.2381 - acc: 0.9379 - val_loss: 1.1917 - val_acc: 0.6888\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1883 - acc: 0.9545\n",
      "Epoch 00008: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.1885 - acc: 0.9544 - val_loss: 1.2584 - val_acc: 0.6769\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1575 - acc: 0.9634\n",
      "Epoch 00009: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.1576 - acc: 0.9634 - val_loss: 1.2907 - val_acc: 0.6723\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9743\n",
      "Epoch 00010: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.1244 - acc: 0.9742 - val_loss: 1.2960 - val_acc: 0.6802\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9729\n",
      "Epoch 00011: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.1189 - acc: 0.9729 - val_loss: 1.3362 - val_acc: 0.6834\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9817\n",
      "Epoch 00012: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0908 - acc: 0.9816 - val_loss: 1.3631 - val_acc: 0.6855\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9823\n",
      "Epoch 00013: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0883 - acc: 0.9822 - val_loss: 1.4500 - val_acc: 0.6709\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9813\n",
      "Epoch 00014: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0838 - acc: 0.9813 - val_loss: 1.3958 - val_acc: 0.6837\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9848\n",
      "Epoch 00015: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0713 - acc: 0.9848 - val_loss: 1.4711 - val_acc: 0.6723\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9893\n",
      "Epoch 00016: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0566 - acc: 0.9892 - val_loss: 1.4121 - val_acc: 0.6911\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9830\n",
      "Epoch 00017: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0725 - acc: 0.9830 - val_loss: 1.4283 - val_acc: 0.6923\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9880\n",
      "Epoch 00018: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0550 - acc: 0.9879 - val_loss: 1.5322 - val_acc: 0.6813\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9871\n",
      "Epoch 00019: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0592 - acc: 0.9871 - val_loss: 1.5606 - val_acc: 0.6758\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9920\n",
      "Epoch 00020: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0405 - acc: 0.9920 - val_loss: 1.4887 - val_acc: 0.6956\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9916\n",
      "Epoch 00021: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0455 - acc: 0.9916 - val_loss: 1.5945 - val_acc: 0.6744\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9866\n",
      "Epoch 00022: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0580 - acc: 0.9866 - val_loss: 1.5553 - val_acc: 0.6879\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9924\n",
      "Epoch 00023: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0383 - acc: 0.9924 - val_loss: 1.5336 - val_acc: 0.6844\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9895\n",
      "Epoch 00024: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0463 - acc: 0.9894 - val_loss: 1.6319 - val_acc: 0.6778\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9889\n",
      "Epoch 00025: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0469 - acc: 0.9889 - val_loss: 1.5743 - val_acc: 0.6865\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9915\n",
      "Epoch 00026: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0380 - acc: 0.9914 - val_loss: 1.6393 - val_acc: 0.6732\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9900\n",
      "Epoch 00027: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0444 - acc: 0.9899 - val_loss: 1.6718 - val_acc: 0.6778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9887\n",
      "Epoch 00028: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0478 - acc: 0.9886 - val_loss: 1.6828 - val_acc: 0.6837\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9916\n",
      "Epoch 00029: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0386 - acc: 0.9915 - val_loss: 1.6762 - val_acc: 0.6841\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9906\n",
      "Epoch 00030: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0401 - acc: 0.9906 - val_loss: 1.7034 - val_acc: 0.6790\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9915\n",
      "Epoch 00031: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0379 - acc: 0.9915 - val_loss: 1.8275 - val_acc: 0.6667\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9943\n",
      "Epoch 00032: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0285 - acc: 0.9943 - val_loss: 1.7363 - val_acc: 0.6776\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9874\n",
      "Epoch 00033: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0532 - acc: 0.9874 - val_loss: 1.7516 - val_acc: 0.6792\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 00034: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0357 - acc: 0.9916 - val_loss: 1.7977 - val_acc: 0.6688\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9914\n",
      "Epoch 00035: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0373 - acc: 0.9914 - val_loss: 1.8294 - val_acc: 0.6790\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9967\n",
      "Epoch 00036: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0202 - acc: 0.9967 - val_loss: 1.7597 - val_acc: 0.6858\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9949\n",
      "Epoch 00037: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0252 - acc: 0.9948 - val_loss: 1.9525 - val_acc: 0.6571\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9924\n",
      "Epoch 00038: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0335 - acc: 0.9924 - val_loss: 1.8517 - val_acc: 0.6709\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9911\n",
      "Epoch 00039: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0372 - acc: 0.9910 - val_loss: 1.9330 - val_acc: 0.6615\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9904\n",
      "Epoch 00040: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0370 - acc: 0.9904 - val_loss: 1.8813 - val_acc: 0.6664\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9935\n",
      "Epoch 00041: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0282 - acc: 0.9934 - val_loss: 1.9320 - val_acc: 0.6650\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9912\n",
      "Epoch 00042: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0354 - acc: 0.9911 - val_loss: 1.8818 - val_acc: 0.6737\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9939\n",
      "Epoch 00043: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0291 - acc: 0.9939 - val_loss: 1.8916 - val_acc: 0.6806\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9912\n",
      "Epoch 00044: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0364 - acc: 0.9911 - val_loss: 1.9136 - val_acc: 0.6676\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9903\n",
      "Epoch 00045: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0401 - acc: 0.9902 - val_loss: 1.9974 - val_acc: 0.6580\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9919\n",
      "Epoch 00046: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0357 - acc: 0.9919 - val_loss: 1.8932 - val_acc: 0.6692\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9953\n",
      "Epoch 00047: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0242 - acc: 0.9952 - val_loss: 1.9353 - val_acc: 0.6765\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9912\n",
      "Epoch 00048: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0337 - acc: 0.9911 - val_loss: 2.0220 - val_acc: 0.6716\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9926\n",
      "Epoch 00049: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0308 - acc: 0.9925 - val_loss: 2.0044 - val_acc: 0.6744\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9939\n",
      "Epoch 00050: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0259 - acc: 0.9939 - val_loss: 1.9445 - val_acc: 0.6876\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9959\n",
      "Epoch 00051: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0203 - acc: 0.9958 - val_loss: 1.9611 - val_acc: 0.6816\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9911\n",
      "Epoch 00052: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 142s 4ms/sample - loss: 0.0356 - acc: 0.9910 - val_loss: 2.1248 - val_acc: 0.6539\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9912\n",
      "Epoch 00053: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0350 - acc: 0.9912 - val_loss: 2.0245 - val_acc: 0.6697\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9920\n",
      "Epoch 00054: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0341 - acc: 0.9920 - val_loss: 2.0343 - val_acc: 0.6716\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9934\n",
      "Epoch 00055: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0272 - acc: 0.9934 - val_loss: 2.0886 - val_acc: 0.6585\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9951\n",
      "Epoch 00056: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0221 - acc: 0.9951 - val_loss: 2.0413 - val_acc: 0.6648\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9947\n",
      "Epoch 00057: val_loss did not improve from 1.19175\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 0.0248 - acc: 0.9947 - val_loss: 2.0031 - val_acc: 0.6653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 1.3333 - acc: 0.6442 1s - loss: 1.3\n",
      "Loss: 1.333261698552505 Accuracy: 0.64423674\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9095 - acc: 0.4346\n",
      "Epoch 00001: val_loss improved from inf to 1.36379, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_5_conv_checkpoint/001-1.3638.hdf5\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 1.9095 - acc: 0.4346 - val_loss: 1.3638 - val_acc: 0.5966\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2052 - acc: 0.6367\n",
      "Epoch 00002: val_loss improved from 1.36379 to 1.16764, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_5_conv_checkpoint/002-1.1676.hdf5\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 1.2052 - acc: 0.6367 - val_loss: 1.1676 - val_acc: 0.6518\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9400 - acc: 0.7155\n",
      "Epoch 00003: val_loss improved from 1.16764 to 1.02796, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_5_conv_checkpoint/003-1.0280.hdf5\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.9403 - acc: 0.7154 - val_loss: 1.0280 - val_acc: 0.6962\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7652 - acc: 0.7651\n",
      "Epoch 00004: val_loss improved from 1.02796 to 0.99741, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_5_conv_checkpoint/004-0.9974.hdf5\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.7652 - acc: 0.7650 - val_loss: 0.9974 - val_acc: 0.7135\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6174 - acc: 0.8114\n",
      "Epoch 00005: val_loss improved from 0.99741 to 0.97340, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_5_conv_checkpoint/005-0.9734.hdf5\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.6175 - acc: 0.8114 - val_loss: 0.9734 - val_acc: 0.7289\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4955 - acc: 0.8493\n",
      "Epoch 00006: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.4958 - acc: 0.8492 - val_loss: 0.9800 - val_acc: 0.7347\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4010 - acc: 0.8796\n",
      "Epoch 00007: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.4012 - acc: 0.8796 - val_loss: 1.0018 - val_acc: 0.7300\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3284 - acc: 0.9038\n",
      "Epoch 00008: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.3285 - acc: 0.9038 - val_loss: 1.0251 - val_acc: 0.7324\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2695 - acc: 0.9222\n",
      "Epoch 00009: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.2697 - acc: 0.9221 - val_loss: 1.0126 - val_acc: 0.7405\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2245 - acc: 0.9383\n",
      "Epoch 00010: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.2250 - acc: 0.9383 - val_loss: 1.0029 - val_acc: 0.7361\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1962 - acc: 0.9470\n",
      "Epoch 00011: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1965 - acc: 0.9469 - val_loss: 1.0443 - val_acc: 0.7356\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9603\n",
      "Epoch 00012: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1592 - acc: 0.9602 - val_loss: 1.0200 - val_acc: 0.7414\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1396 - acc: 0.9648\n",
      "Epoch 00013: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1396 - acc: 0.9648 - val_loss: 1.0570 - val_acc: 0.7393\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9736\n",
      "Epoch 00014: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.1148 - acc: 0.9735 - val_loss: 1.0777 - val_acc: 0.7410\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9727\n",
      "Epoch 00015: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1145 - acc: 0.9726 - val_loss: 1.0637 - val_acc: 0.7459\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9723\n",
      "Epoch 00016: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1096 - acc: 0.9723 - val_loss: 1.1015 - val_acc: 0.7356\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9826\n",
      "Epoch 00017: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0790 - acc: 0.9826 - val_loss: 1.1902 - val_acc: 0.7312\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9780\n",
      "Epoch 00018: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0878 - acc: 0.9779 - val_loss: 1.1474 - val_acc: 0.7421\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9801\n",
      "Epoch 00019: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0838 - acc: 0.9800 - val_loss: 1.1194 - val_acc: 0.7447\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9824\n",
      "Epoch 00020: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0761 - acc: 0.9824 - val_loss: 1.1334 - val_acc: 0.7345\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9837\n",
      "Epoch 00021: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0686 - acc: 0.9837 - val_loss: 1.2112 - val_acc: 0.7298\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9837\n",
      "Epoch 00022: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0688 - acc: 0.9836 - val_loss: 1.1815 - val_acc: 0.7403\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9828\n",
      "Epoch 00023: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0703 - acc: 0.9827 - val_loss: 1.2126 - val_acc: 0.7384\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9823\n",
      "Epoch 00024: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0704 - acc: 0.9822 - val_loss: 1.2467 - val_acc: 0.7405\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9824\n",
      "Epoch 00025: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0702 - acc: 0.9823 - val_loss: 1.1832 - val_acc: 0.7461\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9862\n",
      "Epoch 00026: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0593 - acc: 0.9861 - val_loss: 1.2232 - val_acc: 0.7440\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9871\n",
      "Epoch 00027: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0526 - acc: 0.9870 - val_loss: 1.2250 - val_acc: 0.7442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9837\n",
      "Epoch 00028: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0629 - acc: 0.9837 - val_loss: 1.2142 - val_acc: 0.7447\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9926\n",
      "Epoch 00029: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0391 - acc: 0.9925 - val_loss: 1.1638 - val_acc: 0.7538\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9866\n",
      "Epoch 00030: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0542 - acc: 0.9866 - val_loss: 1.3112 - val_acc: 0.7428\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 00031: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0386 - acc: 0.9917 - val_loss: 1.2527 - val_acc: 0.7531\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9880\n",
      "Epoch 00032: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0488 - acc: 0.9880 - val_loss: 1.2932 - val_acc: 0.7368\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9880\n",
      "Epoch 00033: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0486 - acc: 0.9879 - val_loss: 1.3187 - val_acc: 0.7445\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9856\n",
      "Epoch 00034: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0550 - acc: 0.9856 - val_loss: 1.3254 - val_acc: 0.7480\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9866\n",
      "Epoch 00035: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0522 - acc: 0.9866 - val_loss: 1.3476 - val_acc: 0.7419\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9905\n",
      "Epoch 00036: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0408 - acc: 0.9904 - val_loss: 1.3178 - val_acc: 0.7510\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9869\n",
      "Epoch 00037: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0531 - acc: 0.9869 - val_loss: 1.3674 - val_acc: 0.7407\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9915\n",
      "Epoch 00038: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0352 - acc: 0.9915 - val_loss: 1.3162 - val_acc: 0.7463\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9948\n",
      "Epoch 00039: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0267 - acc: 0.9947 - val_loss: 1.3785 - val_acc: 0.7445\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9920\n",
      "Epoch 00040: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0366 - acc: 0.9919 - val_loss: 1.4244 - val_acc: 0.7384\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9840\n",
      "Epoch 00041: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0575 - acc: 0.9840 - val_loss: 1.3915 - val_acc: 0.7342\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9932\n",
      "Epoch 00042: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0300 - acc: 0.9931 - val_loss: 1.3974 - val_acc: 0.7384\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9889\n",
      "Epoch 00043: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0421 - acc: 0.9889 - val_loss: 1.3465 - val_acc: 0.7405\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9948\n",
      "Epoch 00044: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0261 - acc: 0.9948 - val_loss: 1.4012 - val_acc: 0.7459\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9903\n",
      "Epoch 00045: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0375 - acc: 0.9902 - val_loss: 1.4129 - val_acc: 0.7379\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9874\n",
      "Epoch 00046: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0440 - acc: 0.9873 - val_loss: 1.4031 - val_acc: 0.7412\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9899\n",
      "Epoch 00047: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0394 - acc: 0.9899 - val_loss: 1.4244 - val_acc: 0.7328\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9921\n",
      "Epoch 00048: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0317 - acc: 0.9921 - val_loss: 1.4496 - val_acc: 0.7347\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9938\n",
      "Epoch 00049: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0280 - acc: 0.9938 - val_loss: 1.4611 - val_acc: 0.7372\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9889\n",
      "Epoch 00050: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0449 - acc: 0.9889 - val_loss: 1.4481 - val_acc: 0.7459\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9928\n",
      "Epoch 00051: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0323 - acc: 0.9927 - val_loss: 1.4595 - val_acc: 0.7377\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9893\n",
      "Epoch 00052: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0415 - acc: 0.9892 - val_loss: 1.4748 - val_acc: 0.7403\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9893\n",
      "Epoch 00053: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0399 - acc: 0.9892 - val_loss: 1.4483 - val_acc: 0.7412\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9915\n",
      "Epoch 00054: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0324 - acc: 0.9915 - val_loss: 1.4508 - val_acc: 0.7426\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9921\n",
      "Epoch 00055: val_loss did not improve from 0.97340\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0324 - acc: 0.9921 - val_loss: 1.4739 - val_acc: 0.7435\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 1.0375 - acc: 0.6947\n",
      "Loss: 1.0374559034563422 Accuracy: 0.69470406\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9402 - acc: 0.4085\n",
      "Epoch 00001: val_loss improved from inf to 1.32773, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/001-1.3277.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 1.9402 - acc: 0.4085 - val_loss: 1.3277 - val_acc: 0.5919\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2529 - acc: 0.6231\n",
      "Epoch 00002: val_loss improved from 1.32773 to 1.08502, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/002-1.0850.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 1.2529 - acc: 0.6231 - val_loss: 1.0850 - val_acc: 0.6774\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0132 - acc: 0.6972\n",
      "Epoch 00003: val_loss improved from 1.08502 to 0.88033, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/003-0.8803.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 1.0132 - acc: 0.6972 - val_loss: 0.8803 - val_acc: 0.7461\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8606 - acc: 0.7457\n",
      "Epoch 00004: val_loss improved from 0.88033 to 0.80934, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/004-0.8093.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.8606 - acc: 0.7457 - val_loss: 0.8093 - val_acc: 0.7643\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7501 - acc: 0.7803\n",
      "Epoch 00005: val_loss improved from 0.80934 to 0.78824, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/005-0.7882.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.7503 - acc: 0.7802 - val_loss: 0.7882 - val_acc: 0.7859\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6822 - acc: 0.8006\n",
      "Epoch 00006: val_loss improved from 0.78824 to 0.72414, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/006-0.7241.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.6825 - acc: 0.8005 - val_loss: 0.7241 - val_acc: 0.7957\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.8232\n",
      "Epoch 00007: val_loss did not improve from 0.72414\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.6138 - acc: 0.8232 - val_loss: 0.7862 - val_acc: 0.7890\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5489 - acc: 0.8416\n",
      "Epoch 00008: val_loss improved from 0.72414 to 0.64927, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/008-0.6493.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.5490 - acc: 0.8416 - val_loss: 0.6493 - val_acc: 0.8220\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4965 - acc: 0.8569\n",
      "Epoch 00009: val_loss improved from 0.64927 to 0.61374, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/009-0.6137.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.4967 - acc: 0.8569 - val_loss: 0.6137 - val_acc: 0.8314\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4538 - acc: 0.8674\n",
      "Epoch 00010: val_loss did not improve from 0.61374\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.4545 - acc: 0.8674 - val_loss: 0.6506 - val_acc: 0.8202\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4070 - acc: 0.8805\n",
      "Epoch 00011: val_loss improved from 0.61374 to 0.60448, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/011-0.6045.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.4072 - acc: 0.8805 - val_loss: 0.6045 - val_acc: 0.8355\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3694 - acc: 0.8920\n",
      "Epoch 00012: val_loss did not improve from 0.60448\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.3696 - acc: 0.8919 - val_loss: 0.6480 - val_acc: 0.8237\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3343 - acc: 0.9037\n",
      "Epoch 00013: val_loss improved from 0.60448 to 0.60025, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/013-0.6002.hdf5\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.3345 - acc: 0.9037 - val_loss: 0.6002 - val_acc: 0.8411\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3073 - acc: 0.9114\n",
      "Epoch 00014: val_loss improved from 0.60025 to 0.56738, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/014-0.5674.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.3074 - acc: 0.9114 - val_loss: 0.5674 - val_acc: 0.8416\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2727 - acc: 0.9220\n",
      "Epoch 00015: val_loss improved from 0.56738 to 0.56608, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/015-0.5661.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.2732 - acc: 0.9219 - val_loss: 0.5661 - val_acc: 0.8432\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2652 - acc: 0.9238\n",
      "Epoch 00016: val_loss did not improve from 0.56608\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.2653 - acc: 0.9237 - val_loss: 0.5956 - val_acc: 0.8369\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2323 - acc: 0.9348\n",
      "Epoch 00017: val_loss did not improve from 0.56608\n",
      "36805/36805 [==============================] - 152s 4ms/sample - loss: 0.2326 - acc: 0.9347 - val_loss: 0.6665 - val_acc: 0.8311\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9393\n",
      "Epoch 00018: val_loss improved from 0.56608 to 0.56496, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/018-0.5650.hdf5\n",
      "36805/36805 [==============================] - 152s 4ms/sample - loss: 0.2107 - acc: 0.9393 - val_loss: 0.5650 - val_acc: 0.8472\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1889 - acc: 0.9466\n",
      "Epoch 00019: val_loss improved from 0.56496 to 0.56031, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/019-0.5603.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.1890 - acc: 0.9466 - val_loss: 0.5603 - val_acc: 0.8512\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1685 - acc: 0.9536\n",
      "Epoch 00020: val_loss did not improve from 0.56031\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.1688 - acc: 0.9535 - val_loss: 0.6067 - val_acc: 0.8381\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9491\n",
      "Epoch 00021: val_loss improved from 0.56031 to 0.55007, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/021-0.5501.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.1754 - acc: 0.9491 - val_loss: 0.5501 - val_acc: 0.8593\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1667 - acc: 0.9521\n",
      "Epoch 00022: val_loss did not improve from 0.55007\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.1669 - acc: 0.9520 - val_loss: 0.5595 - val_acc: 0.8556\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9590\n",
      "Epoch 00023: val_loss improved from 0.55007 to 0.54898, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv_checkpoint/023-0.5490.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.1490 - acc: 0.9590 - val_loss: 0.5490 - val_acc: 0.8544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9665\n",
      "Epoch 00024: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.1250 - acc: 0.9665 - val_loss: 0.5522 - val_acc: 0.8581\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9627\n",
      "Epoch 00025: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.1297 - acc: 0.9626 - val_loss: 0.5787 - val_acc: 0.8556\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9663\n",
      "Epoch 00026: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.1216 - acc: 0.9662 - val_loss: 0.5631 - val_acc: 0.8551\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9723\n",
      "Epoch 00027: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.1063 - acc: 0.9723 - val_loss: 0.5974 - val_acc: 0.8493\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9689\n",
      "Epoch 00028: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.1163 - acc: 0.9688 - val_loss: 0.5812 - val_acc: 0.8602\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9767\n",
      "Epoch 00029: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0912 - acc: 0.9766 - val_loss: 0.6090 - val_acc: 0.8493\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9710\n",
      "Epoch 00030: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.1059 - acc: 0.9710 - val_loss: 0.5708 - val_acc: 0.8607\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9764\n",
      "Epoch 00031: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0897 - acc: 0.9764 - val_loss: 0.5782 - val_acc: 0.8591\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9835\n",
      "Epoch 00032: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0721 - acc: 0.9835 - val_loss: 0.5758 - val_acc: 0.8574\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9754\n",
      "Epoch 00033: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0912 - acc: 0.9754 - val_loss: 0.5867 - val_acc: 0.8581\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9809\n",
      "Epoch 00034: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0736 - acc: 0.9808 - val_loss: 0.5586 - val_acc: 0.8600\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9800\n",
      "Epoch 00035: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0785 - acc: 0.9800 - val_loss: 0.5603 - val_acc: 0.8630\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9813\n",
      "Epoch 00036: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0732 - acc: 0.9813 - val_loss: 0.5780 - val_acc: 0.8572\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9830\n",
      "Epoch 00037: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0707 - acc: 0.9829 - val_loss: 0.6396 - val_acc: 0.8523\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9802\n",
      "Epoch 00038: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0765 - acc: 0.9802 - val_loss: 0.5993 - val_acc: 0.8628\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9832\n",
      "Epoch 00039: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0650 - acc: 0.9832 - val_loss: 0.6047 - val_acc: 0.8635\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9848\n",
      "Epoch 00040: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0602 - acc: 0.9846 - val_loss: 0.6094 - val_acc: 0.8644\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9774\n",
      "Epoch 00041: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0811 - acc: 0.9773 - val_loss: 0.6288 - val_acc: 0.8584\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9826\n",
      "Epoch 00042: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0663 - acc: 0.9825 - val_loss: 0.5809 - val_acc: 0.8623\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9868\n",
      "Epoch 00043: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0536 - acc: 0.9867 - val_loss: 0.5536 - val_acc: 0.8707\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9846\n",
      "Epoch 00044: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0612 - acc: 0.9846 - val_loss: 0.5745 - val_acc: 0.8686\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9872\n",
      "Epoch 00045: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0523 - acc: 0.9871 - val_loss: 0.5878 - val_acc: 0.8630\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9835\n",
      "Epoch 00046: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0634 - acc: 0.9835 - val_loss: 0.5936 - val_acc: 0.8677\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9855\n",
      "Epoch 00047: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0552 - acc: 0.9855 - val_loss: 0.5858 - val_acc: 0.8626\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9918\n",
      "Epoch 00048: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0379 - acc: 0.9918 - val_loss: 0.6513 - val_acc: 0.8616\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9846\n",
      "Epoch 00049: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0581 - acc: 0.9845 - val_loss: 0.6759 - val_acc: 0.8535\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9841\n",
      "Epoch 00050: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0595 - acc: 0.9840 - val_loss: 0.6154 - val_acc: 0.8609\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9830\n",
      "Epoch 00051: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0624 - acc: 0.9830 - val_loss: 0.5879 - val_acc: 0.8661\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9924\n",
      "Epoch 00052: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0366 - acc: 0.9923 - val_loss: 0.5900 - val_acc: 0.8663\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9827\n",
      "Epoch 00053: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0635 - acc: 0.9827 - val_loss: 0.6240 - val_acc: 0.8563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9890\n",
      "Epoch 00054: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0450 - acc: 0.9890 - val_loss: 0.6093 - val_acc: 0.8658\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9929\n",
      "Epoch 00055: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0320 - acc: 0.9929 - val_loss: 0.5943 - val_acc: 0.8703\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9851\n",
      "Epoch 00056: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0557 - acc: 0.9851 - val_loss: 0.6443 - val_acc: 0.8651\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9927\n",
      "Epoch 00057: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0328 - acc: 0.9927 - val_loss: 0.7073 - val_acc: 0.8493\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9880\n",
      "Epoch 00058: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0444 - acc: 0.9879 - val_loss: 0.6122 - val_acc: 0.8637\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9875\n",
      "Epoch 00059: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0460 - acc: 0.9875 - val_loss: 0.6128 - val_acc: 0.8635\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9905\n",
      "Epoch 00060: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0387 - acc: 0.9905 - val_loss: 0.5917 - val_acc: 0.8677\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9914\n",
      "Epoch 00061: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0360 - acc: 0.9913 - val_loss: 0.5936 - val_acc: 0.8670\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9908\n",
      "Epoch 00062: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0384 - acc: 0.9907 - val_loss: 0.5918 - val_acc: 0.8744\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9875\n",
      "Epoch 00063: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0446 - acc: 0.9875 - val_loss: 0.6326 - val_acc: 0.8656\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9900\n",
      "Epoch 00064: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0387 - acc: 0.9899 - val_loss: 0.6074 - val_acc: 0.8656\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9891\n",
      "Epoch 00065: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0413 - acc: 0.9890 - val_loss: 0.6646 - val_acc: 0.8556\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9912\n",
      "Epoch 00066: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0354 - acc: 0.9911 - val_loss: 0.6370 - val_acc: 0.8609\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9875\n",
      "Epoch 00067: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0478 - acc: 0.9875 - val_loss: 0.6343 - val_acc: 0.8654\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9907\n",
      "Epoch 00068: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0361 - acc: 0.9906 - val_loss: 0.6257 - val_acc: 0.8654\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9867\n",
      "Epoch 00069: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0470 - acc: 0.9867 - val_loss: 0.6427 - val_acc: 0.8614\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9946\n",
      "Epoch 00070: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0253 - acc: 0.9946 - val_loss: 0.6632 - val_acc: 0.8637\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9915\n",
      "Epoch 00071: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0343 - acc: 0.9914 - val_loss: 0.6697 - val_acc: 0.8628\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9920\n",
      "Epoch 00072: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0334 - acc: 0.9919 - val_loss: 0.6049 - val_acc: 0.8710\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9900\n",
      "Epoch 00073: val_loss did not improve from 0.54898\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0386 - acc: 0.9899 - val_loss: 0.6239 - val_acc: 0.8693\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.6110 - acc: 0.8368\n",
      "Loss: 0.6109846885825738 Accuracy: 0.8367601\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1114 - acc: 0.3599\n",
      "Epoch 00001: val_loss improved from inf to 1.38866, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/001-1.3887.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 2.1115 - acc: 0.3599 - val_loss: 1.3887 - val_acc: 0.5865\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2814 - acc: 0.6145\n",
      "Epoch 00002: val_loss improved from 1.38866 to 0.98260, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/002-0.9826.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 1.2813 - acc: 0.6145 - val_loss: 0.9826 - val_acc: 0.7121\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9671 - acc: 0.7163\n",
      "Epoch 00003: val_loss improved from 0.98260 to 0.76736, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/003-0.7674.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.9674 - acc: 0.7163 - val_loss: 0.7674 - val_acc: 0.7859\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7729 - acc: 0.7765\n",
      "Epoch 00004: val_loss improved from 0.76736 to 0.64152, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/004-0.6415.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.7730 - acc: 0.7765 - val_loss: 0.6415 - val_acc: 0.8160\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6443 - acc: 0.8160\n",
      "Epoch 00005: val_loss improved from 0.64152 to 0.55620, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/005-0.5562.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.6444 - acc: 0.8160 - val_loss: 0.5562 - val_acc: 0.8444\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5485 - acc: 0.8437\n",
      "Epoch 00006: val_loss improved from 0.55620 to 0.51139, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/006-0.5114.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.5486 - acc: 0.8436 - val_loss: 0.5114 - val_acc: 0.8570\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4776 - acc: 0.8620\n",
      "Epoch 00007: val_loss improved from 0.51139 to 0.43650, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/007-0.4365.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.4778 - acc: 0.8618 - val_loss: 0.4365 - val_acc: 0.8777\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4305 - acc: 0.8774\n",
      "Epoch 00008: val_loss improved from 0.43650 to 0.37905, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/008-0.3791.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.4306 - acc: 0.8774 - val_loss: 0.3791 - val_acc: 0.8896\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3788 - acc: 0.8907\n",
      "Epoch 00009: val_loss improved from 0.37905 to 0.36658, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/009-0.3666.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.3790 - acc: 0.8907 - val_loss: 0.3666 - val_acc: 0.8994\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3411 - acc: 0.9011\n",
      "Epoch 00010: val_loss improved from 0.36658 to 0.36292, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/010-0.3629.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.3412 - acc: 0.9011 - val_loss: 0.3629 - val_acc: 0.8998\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3076 - acc: 0.9114\n",
      "Epoch 00011: val_loss improved from 0.36292 to 0.31953, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/011-0.3195.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.3076 - acc: 0.9114 - val_loss: 0.3195 - val_acc: 0.9106\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2783 - acc: 0.9181\n",
      "Epoch 00012: val_loss improved from 0.31953 to 0.31016, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/012-0.3102.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.2784 - acc: 0.9180 - val_loss: 0.3102 - val_acc: 0.9147\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2630 - acc: 0.9236\n",
      "Epoch 00013: val_loss did not improve from 0.31016\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.2631 - acc: 0.9236 - val_loss: 0.3207 - val_acc: 0.9115\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2425 - acc: 0.9286\n",
      "Epoch 00014: val_loss did not improve from 0.31016\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.2426 - acc: 0.9285 - val_loss: 0.3139 - val_acc: 0.9131\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2267 - acc: 0.9324\n",
      "Epoch 00015: val_loss improved from 0.31016 to 0.27437, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/015-0.2744.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.2268 - acc: 0.9324 - val_loss: 0.2744 - val_acc: 0.9248\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1973 - acc: 0.9423\n",
      "Epoch 00016: val_loss did not improve from 0.27437\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1973 - acc: 0.9423 - val_loss: 0.2815 - val_acc: 0.9229\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9451\n",
      "Epoch 00017: val_loss improved from 0.27437 to 0.26918, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/017-0.2692.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1863 - acc: 0.9450 - val_loss: 0.2692 - val_acc: 0.9276\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1913 - acc: 0.9427\n",
      "Epoch 00018: val_loss improved from 0.26918 to 0.26112, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/018-0.2611.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1913 - acc: 0.9427 - val_loss: 0.2611 - val_acc: 0.9262\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9538\n",
      "Epoch 00019: val_loss did not improve from 0.26112\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1551 - acc: 0.9537 - val_loss: 0.2964 - val_acc: 0.9210\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9534\n",
      "Epoch 00020: val_loss did not improve from 0.26112\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1606 - acc: 0.9533 - val_loss: 0.2643 - val_acc: 0.9266\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9589\n",
      "Epoch 00021: val_loss improved from 0.26112 to 0.25920, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/021-0.2592.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1421 - acc: 0.9588 - val_loss: 0.2592 - val_acc: 0.9257\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9569\n",
      "Epoch 00022: val_loss did not improve from 0.25920\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1441 - acc: 0.9569 - val_loss: 0.2617 - val_acc: 0.9257\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9586\n",
      "Epoch 00023: val_loss improved from 0.25920 to 0.25392, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/023-0.2539.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1383 - acc: 0.9586 - val_loss: 0.2539 - val_acc: 0.9304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9663\n",
      "Epoch 00024: val_loss did not improve from 0.25392\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1181 - acc: 0.9663 - val_loss: 0.2595 - val_acc: 0.9250\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9651\n",
      "Epoch 00025: val_loss did not improve from 0.25392\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1190 - acc: 0.9651 - val_loss: 0.2778 - val_acc: 0.9243\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9688\n",
      "Epoch 00026: val_loss improved from 0.25392 to 0.25069, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/026-0.2507.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1059 - acc: 0.9688 - val_loss: 0.2507 - val_acc: 0.9294\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9703\n",
      "Epoch 00027: val_loss did not improve from 0.25069\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1049 - acc: 0.9703 - val_loss: 0.2546 - val_acc: 0.9297\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9751\n",
      "Epoch 00028: val_loss did not improve from 0.25069\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0880 - acc: 0.9750 - val_loss: 0.2642 - val_acc: 0.9276\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9736\n",
      "Epoch 00029: val_loss did not improve from 0.25069\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0914 - acc: 0.9735 - val_loss: 0.2588 - val_acc: 0.9315\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9740\n",
      "Epoch 00030: val_loss did not improve from 0.25069\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0908 - acc: 0.9740 - val_loss: 0.2710 - val_acc: 0.9276\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9797\n",
      "Epoch 00031: val_loss did not improve from 0.25069\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0743 - acc: 0.9796 - val_loss: 0.2509 - val_acc: 0.9320\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9746\n",
      "Epoch 00032: val_loss did not improve from 0.25069\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0865 - acc: 0.9745 - val_loss: 0.2562 - val_acc: 0.9320\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9765\n",
      "Epoch 00033: val_loss did not improve from 0.25069\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0798 - acc: 0.9764 - val_loss: 0.2610 - val_acc: 0.9297\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9767\n",
      "Epoch 00034: val_loss improved from 0.25069 to 0.24690, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/034-0.2469.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0828 - acc: 0.9767 - val_loss: 0.2469 - val_acc: 0.9352\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9809\n",
      "Epoch 00035: val_loss did not improve from 0.24690\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0688 - acc: 0.9808 - val_loss: 0.2623 - val_acc: 0.9304\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9784\n",
      "Epoch 00036: val_loss improved from 0.24690 to 0.24178, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/036-0.2418.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0737 - acc: 0.9784 - val_loss: 0.2418 - val_acc: 0.9341\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9876\n",
      "Epoch 00037: val_loss did not improve from 0.24178\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0502 - acc: 0.9875 - val_loss: 0.2563 - val_acc: 0.9331\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9807\n",
      "Epoch 00038: val_loss improved from 0.24178 to 0.23540, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv_checkpoint/038-0.2354.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0673 - acc: 0.9806 - val_loss: 0.2354 - val_acc: 0.9359\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9823\n",
      "Epoch 00039: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0643 - acc: 0.9823 - val_loss: 0.2629 - val_acc: 0.9317\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9843\n",
      "Epoch 00040: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0544 - acc: 0.9843 - val_loss: 0.2592 - val_acc: 0.9336\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9856\n",
      "Epoch 00041: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0511 - acc: 0.9856 - val_loss: 0.2664 - val_acc: 0.9322\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9830\n",
      "Epoch 00042: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0582 - acc: 0.9830 - val_loss: 0.2608 - val_acc: 0.9341\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9845\n",
      "Epoch 00043: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0543 - acc: 0.9844 - val_loss: 0.2562 - val_acc: 0.9343\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9821\n",
      "Epoch 00044: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0613 - acc: 0.9821 - val_loss: 0.2479 - val_acc: 0.9348\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9870\n",
      "Epoch 00045: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0493 - acc: 0.9870 - val_loss: 0.2480 - val_acc: 0.9357\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9906\n",
      "Epoch 00046: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0382 - acc: 0.9906 - val_loss: 0.2514 - val_acc: 0.9366\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9889\n",
      "Epoch 00047: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0425 - acc: 0.9888 - val_loss: 0.2695 - val_acc: 0.9317\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9885\n",
      "Epoch 00048: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0430 - acc: 0.9885 - val_loss: 0.2476 - val_acc: 0.9383\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9935\n",
      "Epoch 00049: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0279 - acc: 0.9935 - val_loss: 0.2840 - val_acc: 0.9329\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9829\n",
      "Epoch 00050: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 154s 4ms/sample - loss: 0.0578 - acc: 0.9829 - val_loss: 0.2626 - val_acc: 0.9359\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9896\n",
      "Epoch 00051: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0402 - acc: 0.9896 - val_loss: 0.2841 - val_acc: 0.9324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9860\n",
      "Epoch 00052: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0496 - acc: 0.9860 - val_loss: 0.2680 - val_acc: 0.9324\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9896\n",
      "Epoch 00053: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0379 - acc: 0.9896 - val_loss: 0.2557 - val_acc: 0.9357\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9911\n",
      "Epoch 00054: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0340 - acc: 0.9910 - val_loss: 0.2618 - val_acc: 0.9383\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9874\n",
      "Epoch 00055: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0439 - acc: 0.9874 - val_loss: 0.2699 - val_acc: 0.9322\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9873\n",
      "Epoch 00056: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0438 - acc: 0.9873 - val_loss: 0.2615 - val_acc: 0.9331\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9925\n",
      "Epoch 00057: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0297 - acc: 0.9925 - val_loss: 0.2564 - val_acc: 0.9383\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9905\n",
      "Epoch 00058: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0360 - acc: 0.9905 - val_loss: 0.2980 - val_acc: 0.9327\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9896\n",
      "Epoch 00059: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0389 - acc: 0.9896 - val_loss: 0.3387 - val_acc: 0.9243\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9905\n",
      "Epoch 00060: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0359 - acc: 0.9905 - val_loss: 0.2585 - val_acc: 0.9378\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9946\n",
      "Epoch 00061: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0232 - acc: 0.9946 - val_loss: 0.2773 - val_acc: 0.9376\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9927\n",
      "Epoch 00062: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0286 - acc: 0.9927 - val_loss: 0.2714 - val_acc: 0.9357\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9907\n",
      "Epoch 00063: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0332 - acc: 0.9907 - val_loss: 0.2725 - val_acc: 0.9355\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9920\n",
      "Epoch 00064: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0305 - acc: 0.9920 - val_loss: 0.2510 - val_acc: 0.9383\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9945\n",
      "Epoch 00065: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 154s 4ms/sample - loss: 0.0221 - acc: 0.9945 - val_loss: 0.2725 - val_acc: 0.9362\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9935\n",
      "Epoch 00066: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 154s 4ms/sample - loss: 0.0260 - acc: 0.9935 - val_loss: 0.2894 - val_acc: 0.9315\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9889\n",
      "Epoch 00067: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 154s 4ms/sample - loss: 0.0397 - acc: 0.9888 - val_loss: 0.2818 - val_acc: 0.9359\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9876\n",
      "Epoch 00068: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 154s 4ms/sample - loss: 0.0417 - acc: 0.9876 - val_loss: 0.2422 - val_acc: 0.9387\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9933\n",
      "Epoch 00069: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.0254 - acc: 0.9933 - val_loss: 0.2506 - val_acc: 0.9397\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9941\n",
      "Epoch 00070: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0222 - acc: 0.9941 - val_loss: 0.2615 - val_acc: 0.9397\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9909\n",
      "Epoch 00071: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0308 - acc: 0.9908 - val_loss: 0.3012 - val_acc: 0.9331\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9861\n",
      "Epoch 00072: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0487 - acc: 0.9861 - val_loss: 0.2625 - val_acc: 0.9383\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9920\n",
      "Epoch 00073: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0295 - acc: 0.9919 - val_loss: 0.2698 - val_acc: 0.9378\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9934\n",
      "Epoch 00074: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0246 - acc: 0.9934 - val_loss: 0.2583 - val_acc: 0.9397\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9925\n",
      "Epoch 00075: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0266 - acc: 0.9925 - val_loss: 0.2549 - val_acc: 0.9373\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9958\n",
      "Epoch 00076: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0181 - acc: 0.9958 - val_loss: 0.2559 - val_acc: 0.9352\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9962\n",
      "Epoch 00077: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0163 - acc: 0.9963 - val_loss: 0.2607 - val_acc: 0.9394\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9957\n",
      "Epoch 00078: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0172 - acc: 0.9957 - val_loss: 0.2909 - val_acc: 0.9336\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9936\n",
      "Epoch 00079: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0251 - acc: 0.9935 - val_loss: 0.2820 - val_acc: 0.9313\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9886\n",
      "Epoch 00080: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 154s 4ms/sample - loss: 0.0396 - acc: 0.9886 - val_loss: 0.2773 - val_acc: 0.9357\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9927\n",
      "Epoch 00081: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0261 - acc: 0.9926 - val_loss: 0.2693 - val_acc: 0.9378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9936\n",
      "Epoch 00082: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0232 - acc: 0.9936 - val_loss: 0.2753 - val_acc: 0.9359\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9935\n",
      "Epoch 00083: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0236 - acc: 0.9935 - val_loss: 0.2561 - val_acc: 0.9406\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9947\n",
      "Epoch 00084: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0216 - acc: 0.9947 - val_loss: 0.2755 - val_acc: 0.9390\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9939\n",
      "Epoch 00085: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0231 - acc: 0.9939 - val_loss: 0.2508 - val_acc: 0.9404\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9954\n",
      "Epoch 00086: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0177 - acc: 0.9954 - val_loss: 0.3087 - val_acc: 0.9336\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9944\n",
      "Epoch 00087: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0213 - acc: 0.9944 - val_loss: 0.2579 - val_acc: 0.9401\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9965\n",
      "Epoch 00088: val_loss did not improve from 0.23540\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0149 - acc: 0.9965 - val_loss: 0.2795 - val_acc: 0.9350\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.3086 - acc: 0.9178\n",
      "Loss: 0.30864812238596434 Accuracy: 0.91775703\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1736 - acc: 0.3390\n",
      "Epoch 00001: val_loss improved from inf to 1.46105, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/001-1.4610.hdf5\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 2.1736 - acc: 0.3390 - val_loss: 1.4610 - val_acc: 0.5579\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2069 - acc: 0.6347\n",
      "Epoch 00002: val_loss improved from 1.46105 to 0.85685, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/002-0.8569.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 1.2071 - acc: 0.6346 - val_loss: 0.8569 - val_acc: 0.7536\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8015 - acc: 0.7638\n",
      "Epoch 00003: val_loss improved from 0.85685 to 0.56836, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/003-0.5684.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.8016 - acc: 0.7638 - val_loss: 0.5684 - val_acc: 0.8437\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5925 - acc: 0.8245\n",
      "Epoch 00004: val_loss improved from 0.56836 to 0.46572, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/004-0.4657.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.5926 - acc: 0.8244 - val_loss: 0.4657 - val_acc: 0.8675\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4919 - acc: 0.8540\n",
      "Epoch 00005: val_loss improved from 0.46572 to 0.37765, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/005-0.3777.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.4923 - acc: 0.8539 - val_loss: 0.3777 - val_acc: 0.8905\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4139 - acc: 0.8776\n",
      "Epoch 00006: val_loss did not improve from 0.37765\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.4139 - acc: 0.8776 - val_loss: 0.3833 - val_acc: 0.8838\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3527 - acc: 0.8945\n",
      "Epoch 00007: val_loss improved from 0.37765 to 0.30671, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/007-0.3067.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.3529 - acc: 0.8944 - val_loss: 0.3067 - val_acc: 0.9124\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3185 - acc: 0.9063\n",
      "Epoch 00008: val_loss improved from 0.30671 to 0.29916, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/008-0.2992.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.3185 - acc: 0.9063 - val_loss: 0.2992 - val_acc: 0.9099\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2774 - acc: 0.9183\n",
      "Epoch 00009: val_loss improved from 0.29916 to 0.27199, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/009-0.2720.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.2776 - acc: 0.9182 - val_loss: 0.2720 - val_acc: 0.9231\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2539 - acc: 0.9242\n",
      "Epoch 00010: val_loss improved from 0.27199 to 0.26667, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/010-0.2667.hdf5\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.2539 - acc: 0.9242 - val_loss: 0.2667 - val_acc: 0.9257\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2201 - acc: 0.9348\n",
      "Epoch 00011: val_loss improved from 0.26667 to 0.24078, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/011-0.2408.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.2201 - acc: 0.9348 - val_loss: 0.2408 - val_acc: 0.9341\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9368\n",
      "Epoch 00012: val_loss improved from 0.24078 to 0.23744, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/012-0.2374.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.2079 - acc: 0.9367 - val_loss: 0.2374 - val_acc: 0.9280\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9360\n",
      "Epoch 00013: val_loss improved from 0.23744 to 0.20670, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/013-0.2067.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.2078 - acc: 0.9359 - val_loss: 0.2067 - val_acc: 0.9432\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9483\n",
      "Epoch 00014: val_loss did not improve from 0.20670\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 0.1756 - acc: 0.9483 - val_loss: 0.2069 - val_acc: 0.9390\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9520\n",
      "Epoch 00015: val_loss did not improve from 0.20670\n",
      "36805/36805 [==============================] - 152s 4ms/sample - loss: 0.1557 - acc: 0.9519 - val_loss: 0.2158 - val_acc: 0.9362\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9532\n",
      "Epoch 00016: val_loss did not improve from 0.20670\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1545 - acc: 0.9531 - val_loss: 0.2193 - val_acc: 0.9378\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9593\n",
      "Epoch 00017: val_loss did not improve from 0.20670\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1383 - acc: 0.9592 - val_loss: 0.2079 - val_acc: 0.9394\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9556\n",
      "Epoch 00018: val_loss improved from 0.20670 to 0.20033, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/018-0.2003.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1434 - acc: 0.9556 - val_loss: 0.2003 - val_acc: 0.9436\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9635\n",
      "Epoch 00019: val_loss improved from 0.20033 to 0.18011, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/019-0.1801.hdf5\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1212 - acc: 0.9634 - val_loss: 0.1801 - val_acc: 0.9492\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9626\n",
      "Epoch 00020: val_loss did not improve from 0.18011\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1219 - acc: 0.9626 - val_loss: 0.1914 - val_acc: 0.9441\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9691\n",
      "Epoch 00021: val_loss did not improve from 0.18011\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1034 - acc: 0.9691 - val_loss: 0.1977 - val_acc: 0.9425\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9712\n",
      "Epoch 00022: val_loss did not improve from 0.18011\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0950 - acc: 0.9712 - val_loss: 0.1988 - val_acc: 0.9427\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9710\n",
      "Epoch 00023: val_loss did not improve from 0.18011\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0981 - acc: 0.9709 - val_loss: 0.2012 - val_acc: 0.9434\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9709\n",
      "Epoch 00024: val_loss improved from 0.18011 to 0.16513, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/024-0.1651.hdf5\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0974 - acc: 0.9709 - val_loss: 0.1651 - val_acc: 0.9546\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9781\n",
      "Epoch 00025: val_loss did not improve from 0.16513\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0770 - acc: 0.9781 - val_loss: 0.1740 - val_acc: 0.9511\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9766\n",
      "Epoch 00026: val_loss did not improve from 0.16513\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0799 - acc: 0.9766 - val_loss: 0.1779 - val_acc: 0.9485\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9766\n",
      "Epoch 00027: val_loss improved from 0.16513 to 0.16503, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/027-0.1650.hdf5\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0822 - acc: 0.9766 - val_loss: 0.1650 - val_acc: 0.9541\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9823\n",
      "Epoch 00028: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0618 - acc: 0.9823 - val_loss: 0.1863 - val_acc: 0.9525\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9804\n",
      "Epoch 00029: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0688 - acc: 0.9804 - val_loss: 0.1805 - val_acc: 0.9509\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9782\n",
      "Epoch 00030: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0739 - acc: 0.9782 - val_loss: 0.1692 - val_acc: 0.9541\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9836\n",
      "Epoch 00031: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0564 - acc: 0.9835 - val_loss: 0.1785 - val_acc: 0.9548\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9816\n",
      "Epoch 00032: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0632 - acc: 0.9816 - val_loss: 0.1851 - val_acc: 0.9490\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9840\n",
      "Epoch 00033: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0530 - acc: 0.9841 - val_loss: 0.1796 - val_acc: 0.9525\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9878\n",
      "Epoch 00034: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0464 - acc: 0.9878 - val_loss: 0.1877 - val_acc: 0.9527\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9830\n",
      "Epoch 00035: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0573 - acc: 0.9830 - val_loss: 0.1779 - val_acc: 0.9557\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9897\n",
      "Epoch 00036: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0389 - acc: 0.9896 - val_loss: 0.1790 - val_acc: 0.9527\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9839\n",
      "Epoch 00037: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0530 - acc: 0.9839 - val_loss: 0.1731 - val_acc: 0.9567\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9852\n",
      "Epoch 00038: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0512 - acc: 0.9852 - val_loss: 0.1699 - val_acc: 0.9536\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9878\n",
      "Epoch 00039: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0447 - acc: 0.9877 - val_loss: 0.1823 - val_acc: 0.9534\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9843\n",
      "Epoch 00040: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0500 - acc: 0.9843 - val_loss: 0.1721 - val_acc: 0.9527\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9935\n",
      "Epoch 00041: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0280 - acc: 0.9935 - val_loss: 0.1817 - val_acc: 0.9536\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9860\n",
      "Epoch 00042: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0479 - acc: 0.9859 - val_loss: 0.1859 - val_acc: 0.9515\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9866\n",
      "Epoch 00043: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0454 - acc: 0.9866 - val_loss: 0.1697 - val_acc: 0.9541\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9912\n",
      "Epoch 00044: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0347 - acc: 0.9912 - val_loss: 0.1801 - val_acc: 0.9504\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9906\n",
      "Epoch 00045: val_loss did not improve from 0.16503\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0341 - acc: 0.9906 - val_loss: 0.1677 - val_acc: 0.9569\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9908\n",
      "Epoch 00046: val_loss improved from 0.16503 to 0.16479, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/046-0.1648.hdf5\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0348 - acc: 0.9907 - val_loss: 0.1648 - val_acc: 0.9541\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9907\n",
      "Epoch 00047: val_loss did not improve from 0.16479\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0354 - acc: 0.9906 - val_loss: 0.1648 - val_acc: 0.9567\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9882\n",
      "Epoch 00048: val_loss improved from 0.16479 to 0.16437, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/048-0.1644.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0397 - acc: 0.9882 - val_loss: 0.1644 - val_acc: 0.9560\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9907\n",
      "Epoch 00049: val_loss did not improve from 0.16437\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0332 - acc: 0.9906 - val_loss: 0.1748 - val_acc: 0.9555\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9892\n",
      "Epoch 00050: val_loss did not improve from 0.16437\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0377 - acc: 0.9891 - val_loss: 0.1770 - val_acc: 0.9578\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9899\n",
      "Epoch 00051: val_loss did not improve from 0.16437\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0339 - acc: 0.9899 - val_loss: 0.1730 - val_acc: 0.9567\n",
      "Epoch 52/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9941\n",
      "Epoch 00052: val_loss did not improve from 0.16437\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0234 - acc: 0.9941 - val_loss: 0.1758 - val_acc: 0.9574\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9954\n",
      "Epoch 00053: val_loss did not improve from 0.16437\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0178 - acc: 0.9954 - val_loss: 0.2087 - val_acc: 0.9522\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9942\n",
      "Epoch 00054: val_loss did not improve from 0.16437\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0235 - acc: 0.9942 - val_loss: 0.1909 - val_acc: 0.9548\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9935\n",
      "Epoch 00055: val_loss did not improve from 0.16437\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0257 - acc: 0.9935 - val_loss: 0.2194 - val_acc: 0.9441\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9904\n",
      "Epoch 00056: val_loss improved from 0.16437 to 0.15979, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv_checkpoint/056-0.1598.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0340 - acc: 0.9904 - val_loss: 0.1598 - val_acc: 0.9569\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9915\n",
      "Epoch 00057: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0300 - acc: 0.9915 - val_loss: 0.1807 - val_acc: 0.9532\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9908\n",
      "Epoch 00058: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0327 - acc: 0.9907 - val_loss: 0.1685 - val_acc: 0.9571\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 00059: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0293 - acc: 0.9917 - val_loss: 0.1873 - val_acc: 0.9529\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9960\n",
      "Epoch 00060: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0173 - acc: 0.9960 - val_loss: 0.1734 - val_acc: 0.9581\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 00061: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 152s 4ms/sample - loss: 0.0297 - acc: 0.9916 - val_loss: 0.1751 - val_acc: 0.9543\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9895\n",
      "Epoch 00062: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0366 - acc: 0.9895 - val_loss: 0.1676 - val_acc: 0.9557\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9951\n",
      "Epoch 00063: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0199 - acc: 0.9951 - val_loss: 0.1787 - val_acc: 0.9536\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9962\n",
      "Epoch 00064: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0157 - acc: 0.9961 - val_loss: 0.1825 - val_acc: 0.9550\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9893\n",
      "Epoch 00065: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0362 - acc: 0.9892 - val_loss: 0.1703 - val_acc: 0.9548\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9906\n",
      "Epoch 00066: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0322 - acc: 0.9906 - val_loss: 0.1792 - val_acc: 0.9546\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9941\n",
      "Epoch 00067: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0219 - acc: 0.9940 - val_loss: 0.1762 - val_acc: 0.9550\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9937\n",
      "Epoch 00068: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0225 - acc: 0.9936 - val_loss: 0.1837 - val_acc: 0.9518\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9916\n",
      "Epoch 00069: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0286 - acc: 0.9916 - val_loss: 0.1781 - val_acc: 0.9574\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9973\n",
      "Epoch 00070: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0127 - acc: 0.9973 - val_loss: 0.1810 - val_acc: 0.9550\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9964\n",
      "Epoch 00071: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0150 - acc: 0.9963 - val_loss: 0.2013 - val_acc: 0.9515\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9937\n",
      "Epoch 00072: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0227 - acc: 0.9936 - val_loss: 0.1942 - val_acc: 0.9518\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9926\n",
      "Epoch 00073: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0251 - acc: 0.9926 - val_loss: 0.1833 - val_acc: 0.9550\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9941\n",
      "Epoch 00074: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0205 - acc: 0.9941 - val_loss: 0.1796 - val_acc: 0.9520\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9955\n",
      "Epoch 00075: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0170 - acc: 0.9954 - val_loss: 0.2066 - val_acc: 0.9520\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9933\n",
      "Epoch 00076: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0212 - acc: 0.9933 - val_loss: 0.1982 - val_acc: 0.9492\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9903\n",
      "Epoch 00077: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0317 - acc: 0.9903 - val_loss: 0.1858 - val_acc: 0.9539\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9972\n",
      "Epoch 00078: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0122 - acc: 0.9971 - val_loss: 0.1910 - val_acc: 0.9546\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9931\n",
      "Epoch 00079: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0234 - acc: 0.9930 - val_loss: 0.1949 - val_acc: 0.9534\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9939\n",
      "Epoch 00080: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0223 - acc: 0.9938 - val_loss: 0.1868 - val_acc: 0.9583\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9923\n",
      "Epoch 00081: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0264 - acc: 0.9922 - val_loss: 0.1817 - val_acc: 0.9569\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9931\n",
      "Epoch 00082: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0246 - acc: 0.9931 - val_loss: 0.1856 - val_acc: 0.9592\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9974\n",
      "Epoch 00083: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0106 - acc: 0.9974 - val_loss: 0.1821 - val_acc: 0.9569\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9977\n",
      "Epoch 00084: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0094 - acc: 0.9977 - val_loss: 0.1960 - val_acc: 0.9550\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9958\n",
      "Epoch 00085: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0156 - acc: 0.9957 - val_loss: 0.1770 - val_acc: 0.9567\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9941\n",
      "Epoch 00086: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0202 - acc: 0.9940 - val_loss: 0.1974 - val_acc: 0.9539\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9920\n",
      "Epoch 00087: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0274 - acc: 0.9919 - val_loss: 0.1809 - val_acc: 0.9571\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9955\n",
      "Epoch 00088: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0155 - acc: 0.9955 - val_loss: 0.1777 - val_acc: 0.9569\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9979\n",
      "Epoch 00089: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0101 - acc: 0.9979 - val_loss: 0.1747 - val_acc: 0.9569\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9960\n",
      "Epoch 00090: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0151 - acc: 0.9959 - val_loss: 0.1749 - val_acc: 0.9578\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9964\n",
      "Epoch 00091: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0137 - acc: 0.9964 - val_loss: 0.1938 - val_acc: 0.9557\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9967\n",
      "Epoch 00092: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0121 - acc: 0.9967 - val_loss: 0.1831 - val_acc: 0.9571\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9962\n",
      "Epoch 00093: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0136 - acc: 0.9961 - val_loss: 0.1957 - val_acc: 0.9564\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9929\n",
      "Epoch 00094: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0233 - acc: 0.9929 - val_loss: 0.1840 - val_acc: 0.9555\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9939\n",
      "Epoch 00095: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0210 - acc: 0.9939 - val_loss: 0.1889 - val_acc: 0.9576\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9981\n",
      "Epoch 00096: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0089 - acc: 0.9981 - val_loss: 0.1798 - val_acc: 0.9553\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9978\n",
      "Epoch 00097: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0079 - acc: 0.9978 - val_loss: 0.1667 - val_acc: 0.9574\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9950\n",
      "Epoch 00098: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0166 - acc: 0.9950 - val_loss: 0.1674 - val_acc: 0.9583\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9945\n",
      "Epoch 00099: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0184 - acc: 0.9945 - val_loss: 0.1736 - val_acc: 0.9574\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9979\n",
      "Epoch 00100: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0088 - acc: 0.9979 - val_loss: 0.1819 - val_acc: 0.9557\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9971\n",
      "Epoch 00101: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0113 - acc: 0.9971 - val_loss: 0.2073 - val_acc: 0.9534\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9944\n",
      "Epoch 00102: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0183 - acc: 0.9944 - val_loss: 0.1750 - val_acc: 0.9574\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9950\n",
      "Epoch 00103: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0182 - acc: 0.9950 - val_loss: 0.1706 - val_acc: 0.9592\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9976\n",
      "Epoch 00104: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0086 - acc: 0.9976 - val_loss: 0.1664 - val_acc: 0.9581\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9980\n",
      "Epoch 00105: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0081 - acc: 0.9980 - val_loss: 0.1898 - val_acc: 0.9564\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9964\n",
      "Epoch 00106: val_loss did not improve from 0.15979\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0123 - acc: 0.9964 - val_loss: 0.1858 - val_acc: 0.9560\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8nFW9+PHPmSWzZbKvbVrSjdI9XS1gWxTZkdVSFFS4WvW6Ileudbn3ol5/InJduKJcQBAQ2WUVQdGWglKkLS2UtnRNmqRp9mUms8+c3x9nMknbJE3bDGkz3/frNa9knnmWc57lfJ9znuc5j9JaI4QQQgBYRjoBQgghThwSFIQQQqRIUBBCCJEiQUEIIUSKBAUhhBApEhSEEEKkSFAQQgiRIkFBCCFEigQFIYQQKbaRTsDRKioq0pWVlSOdDCGEOKls2LChRWtdfKTxTrqgUFlZyfr160c6GUIIcVJRStUMZTxpPhJCCJEiQUEIIUSKBAUhhBApJ901hf5Eo1Hq6uoIhUIjnZSTltPppKKiArvdPtJJEUKMoFERFOrq6vB6vVRWVqKUGunknHS01rS2tlJXV8eECRNGOjlCiBE0KpqPQqEQhYWFEhCOkVKKwsJCqWkJIUZHUAAkIBwnWX9CCBhFQeFI4vEg4XA9iUR0pJMihBAnrIwJColEiEikAa2HPyh0dHTwq1/96pimvfDCC+no6Bjy+DfffDO33XbbMS1LCCGOJGOCQm/ziB72eQ8WFGKx2KDTvvDCC+Tl5Q17moQQ4lhkTFDoyarWiWGf86pVq9i9ezdVVVXcdNNNrFmzhiVLlnDJJZcwffp0AC677DLmz5/PjBkzuOuuu1LTVlZW0tLSQnV1NdOmTWPlypXMmDGDc889l2AwOOhyN23axOLFi5k9ezaXX3457e3tANx+++1Mnz6d2bNnc/XVVwPwyiuvUFVVRVVVFXPnzsXn8w37ehBCnPxGxS2pfe3ceQN+/6bDhmsdJ5EIYLG4UOrosp2dXcWUKT8f8PdbbrmFLVu2sGmTWe6aNWvYuHEjW7ZsSd3iee+991JQUEAwGGThwoVceeWVFBYWHpL2nTz88MPcfffdXHXVVTz55JNce+21Ay73U5/6FP/7v//LsmXL+M///E++973v8fOf/5xbbrmFvXv34nA4Uk1Tt912G3fccQdnnnkmfr8fp9N5VOtACJEZMqam8H7fXLNo0aKD7vm//fbbmTNnDosXL6a2tpadO3ceNs2ECROoqqoCYP78+VRXVw84/87OTjo6Oli2bBkAn/70p1m7di0As2fP5pprruF3v/sdNpsJgGeeeSY33ngjt99+Ox0dHanhQgjR16grGQY6o4/HgwQC7+J0TsRuL0h7OjweT+r/NWvW8PLLL/P666/jdrs566yz+n0mwOFwpP63Wq1HbD4ayB//+EfWrl3Lc889xw9/+EPeeecdVq1axUUXXcQLL7zAmWeeyUsvvcRpp512TPMXQoxeGVRTSN81Ba/XO2gbfWdnJ/n5+bjdbrZv3866deuOe5m5ubnk5+fz6quvAvDggw+ybNkyEokEtbW1fOhDH+LHP/4xnZ2d+P1+du/ezaxZs/jmN7/JwoUL2b59+3GnQQgx+oy6msLAetqPhj8oFBYWcuaZZzJz5kwuuOACLrroooN+P//887nzzjuZNm0aU6dOZfHixcOy3Pvvv58vfOELBAIBJk6cyH333Uc8Hufaa6+ls7MTrTVf/epXycvL4z/+4z9YvXo1FouFGTNmcMEFFwxLGoQQo4vSevhv0UynBQsW6ENfsrNt2zamTZs26HSJRIzu7k04HOPIyipNZxJPWkNZj0KIk5NSaoPWesGRxpPmIyGEECkZExTS2XwkhBCjRcYEBfNEs+Jkay4TQoj3U9qCglJqnFJqtVJqq1LqXaXU1/oZRymlbldK7VJKva2Umpeu9BgWpKYghBADS+fdRzHg37TWG5VSXmCDUuovWuutfca5AJiS/HwA+HXyb1qY6woSFIQQYiBpqylorRu01huT//uAbcDYQ0a7FHhAG+uAPKVUebrSBBa50CyEEIN4X64pKKUqgbnAG4f8NBao7fO9jsMDx3Cmg3T0knossrOzj2q4EEK8H9IeFJRS2cCTwA1a665jnMfnlFLrlVLrm5ubjyM1UlMQQojBpDUoKKXsmIDwkNb6D/2MUg+M6/O9IjnsIFrru7TWC7TWC4qLi48jRem5prBq1SruuOOO1PeeF+H4/X7OPvts5s2bx6xZs3jmmWeGPE+tNTfddBMzZ85k1qxZPProowA0NDSwdOlSqqqqmDlzJq+++irxeJzrrrsuNe7PfvazYc+jECIzpO1CszJtNb8BtmmtfzrAaM8CX1ZKPYK5wNyptW44rgXfcANsOrzrbABnImBaj6zuo5tnVRX8fOCus1esWMENN9zAl770JQAee+wxXnrpJZxOJ0899RQ5OTm0tLSwePFiLrnkkiG9D/kPf/gDmzZtYvPmzbS0tLBw4UKWLl3K73//e8477zy+853vEI/HCQQCbNq0ifr6erZs2QJwVG9yE0KIvtJ599GZwCeBd5RSPaX0t4HxAFrrO4EXgAuBXUAAuD6N6cE8wDb81xTmzp1LU1MT+/fvp7m5mfz8fMaNG0c0GuXb3/42a9euxWKxUF9fT2NjI2VlZUec52uvvcbHP/5xrFYrpaWlLFu2jDfffJOFCxfyL//yL0SjUS677DKqqqqYOHEie/bs4Stf+QoXXXQR55577rDnUQiRGdIWFLTWr9H7GPFA42jgS8O64EHO6CPB3SQSQTyemcO6SIDly5fzxBNPcODAAVasWAHAQw89RHNzMxs2bMBut1NZWdlvl9lHY+nSpaxdu5Y//vGPXHfdddx444186lOfYvPmzbz00kvceeedPPbYY9x7773DkS0hRIbJmCeajfQ90bxixQoeeeQRnnjiCZYvXw6YLrNLSkqw2+2sXr2ampqaIc9vyZIlPProo8TjcZqbm1m7di2LFi2ipqaG0tJSVq5cyWc/+1k2btxIS0sLiUSCK6+8kv/+7/9m48aNacmjEGL0y6Cus9P78NqMGTPw+XyMHTuW8nLzqMU111zDRz/6UWbNmsWCBQuO6qU2l19+Oa+//jpz5sxBKcWtt95KWVkZ999/Pz/5yU+w2+1kZ2fzwAMPUF9fz/XXX08iYfL2ox/9KC15FEKMfhnTdTZAKLSPaLQVr3duupJ3UpOus4UYvaTr7H5JNxdCCDGYjAoKPU80n2y1IyGEeL9kVFDoza4EBSGE6E9GBQV5+5oQQgwuo4KCvH1NCCEGl2FBQZqPhBBiMBkVFNLVfNTR0cGvfvWrY5r2wgsvlL6KhBAnjIwKCr3Zff+CQiwWG3TaF154gby8vGFNjxBCHKuMCgo9vZMO9y2pq1atYvfu3VRVVXHTTTexZs0alixZwiWXXML06dMBuOyyy5g/fz4zZszgrrvuSk1bWVlJS0sL1dXVTJs2jZUrVzJjxgzOPfdcgsHgYct67rnn+MAHPsDcuXP5yEc+QmNjIwB+v5/rr7+eWbNmMXv2bJ588kkAXnzxRebNm8ecOXM4++yzhzXfQojRZ9R1czFIz9lo7SGRmIrF4mQIvVenHKHnbG655Ra2bNnCpuSC16xZw8aNG9myZQsTJkwA4N5776WgoIBgMMjChQu58sorKSwsPGg+O3fu5OGHH+buu+/mqquu4sknn+Taa689aJwPfvCDrFu3DqUU99xzD7feeiv/8z//ww9+8ANyc3N55513AGhvb6e5uZmVK1eydu1aJkyYQFtb29AzLYTISKMuKAzuKCLBcVq0aFEqIADcfvvtPPXUUwDU1tayc+fOw4LChAkTqKqqAmD+/PlUV1cfNt+6ujpWrFhBQ0MDkUgktYyXX36ZRx55JDVefn4+zz33HEuXLk2NU1BQMKx5FEKMPqMuKAx2Rh+PhwkE3sPpnIjdnt4C0uPxpP5fs2YNL7/8Mq+//jput5uzzjqr3y60HQ5H6n+r1dpv89FXvvIVbrzxRi655BLWrFnDzTffnJb0CyEyU0ZdU0jXLalerxefzzfg752dneTn5+N2u9m+fTvr1q075mV1dnYyduxYAO6///7U8HPOOeegV4K2t7ezePFi1q5dy969ewGk+UgIcUQZFRTSdUtqYWEhZ555JjNnzuSmm2467Pfzzz+fWCzGtGnTWLVqFYsXLz7mZd18880sX76c+fPnU1RUlBr+3e9+l/b2dmbOnMmcOXNYvXo1xcXF3HXXXVxxxRXMmTMn9fIfIYQYSEZ1nZ1IROnu3ozDMY6srNJ0JfGkJV1nCzF6SdfZ/eitKZxcgVAIId4vGRUU0vXwmhBCjBYZFRTMw2sKCQpCCNG/jAoKhpLmIyGEGEDGBQVzXUFqCkII0Z+MCwpgkZfsCCHEADIyKJwINYXs7OyRToIQQhwm44KCUnJNQQghBpJxQSEdNYVVq1Yd1MXEzTffzG233Ybf7+fss89m3rx5zJo1i2eeeeaI8xqoi+3+usAeqLtsIYQ4VqOuQ7wbXryBTQcG6DsbSCQCAFgs7iHPs6qsip+fP3BPeytWrOCGG27gS1/6EgCPPfYYL730Ek6nk6eeeoqcnBxaWlpYvHgxl1xySeq9Dv3pr4vtRCLRbxfY/XWXLYQQx2PUBYUjG/7mo7lz59LU1MT+/ftpbm4mPz+fcePGEY1G+fa3v83atWuxWCzU19fT2NhIWVnZgPPqr4vt5ubmfrvA7q+7bCGEOB6jLigMdkYPEAzuIpEI4/HMGNblLl++nCeeeIIDBw6kOp576KGHaG5uZsOGDdjtdiorK/vtMrvHULvYFkKIdMnIawrpuCV1xYoVPPLIIzzxxBMsX74cMN1cl5SUYLfbWb16NTU1NYPOY6AutgfqAru/7rKFEOJ4ZGRQGO73KQDMmDEDn8/H2LFjKS8vB+Caa65h/fr1zJo1iwceeIDTTjtt0HkM1MX2QF1g99ddthBCHI+M6jobIBSqIRZrJzu7Kh3JO6lJ19lCjF7SdfaA5IlmIYQYSMYFBen7SAghBjZqgsLQm8HUUY6fGWR9CCFglAQFp9NJa2vrEAs2edHOobTWtLa24nQ6RzopQogRlrbnFJRS9wIXA01a65n9/H4W8AywNznoD1rr7x/LsioqKqirq6O5ufmI48ZiPmKxNhyObShlPZbFjUpOp5OKioqRToYQYoSl8+G13wK/BB4YZJxXtdYXH++C7HZ76mnfI2lo+A3vvfdZFi+uwekcf7yLFkKIUSVtzUda67VAW7rmf6wsFtNEkkjIk8JCCHGokb6mcLpSarNS6k9KqeHtd2IAEhSEEGJgI9n30UbgFK21Xyl1IfA0MKW/EZVSnwM+BzB+/PE1+VgsLgASieBxzUcIIUajEaspaK27tNb+5P8vAHalVNEA496ltV6gtV5QXFx8XMuVmoIQQgxsxIKCUqpMJV8soJRalExLa9oWuG0b/L//h7UjAkA8LjUFIYQ4VDpvSX0YOAsoUkrVAf8F2AG01ncCHwP+VSkVA4LA1TqdT1Bt3Qrf+Q7WD5n3D0hNQQghDpe2oKC1/vgRfv8l5pbV94fXC4DFHwW7BAUhhOjPSN999P7JyQHA0h0D5EKzEEL0J3OCQqqmEAakpiCEEP3JnKCQqimYC81SUxBCiMNlTlBI1hSU3wQDqSkIIcThMi8o+AKAkqAghBD9yJygYLWC243y+bBYnNJ8JIQQ/cicoACmtpAKClJTEEKIQ2VWUMjJSQYFlzzRLIQQ/cisoOD1QleX1BSEEGIAmRUUUjUFCQpCCNGfzAoKqZqCSy40CyFEPzIrKEhNQQghBpVZQSFZU7BapaYghBD9yaygIDUFIYQYVGYFBa8XwmGs8SypKQghRD9G8h3N779kp3i2oI2EkpqCEEIcKvNqCoAtIH0fCSFEfzIrKCRrCtaAVZ5oFkKIfmRWUEjVFKTrbCGE6E9mBYVUTUGjdRitEyOcICGEOLFkVlBI1hSsAfM1kQiPYGKEEOLEk6FBQQMQj3ePZGqEEOKEk1lBIdl8ZA9aAYjF2kYyNUIIccLJrKCQnQ2ANaAAiEZbRjI1QghxwsmsoGCzgduNLXlNQYKCEEIcbEhBQSn1NaVUjjJ+o5TaqJQ6N92JSwuvF0t3HJCgIIQQhxpqTeFftNZdwLlAPvBJ4Ja0pSqdcnKwdEcBCQpCCHGooQYFlfx7IfCg1vrdPsNOLl4vyhfAYnFKUBBCiEMMNShsUEr9GRMUXlJKeYGT88mvnByUz4fdXiRBQQghDjHUXlI/A1QBe7TWAaVUAXB9+pKVRl4v7NuXDArNI50aIYQ4oQy1pnA68J7WukMpdS3wXaAzfclKo+SLdqSmIIQQhxtqUPg1EFBKzQH+DdgNPJC2VKWT1ytBQQghBjDUoBDTWmvgUuCXWus7AG/6kpVGOTnQ1SVBQQgh+jHUawo+pdS3MLeiLlFKWQB7+pKVRslXctp1HrFYB4lEFIvl5MyKEEIMt6HWFFYAYczzCgeACuAnaUtVOiX7P3JETJcX0v+REEL0GlJQSAaCh4BcpdTFQEhrffJeUwDsITcgD7AJIURfQ+3m4irgn8By4CrgDaXUx9KZsLRJBoWskBOQoCCEEH0N9ZrCd4CFWusmAKVUMfAy8MRAEyil7gUuBpq01jP7+V0Bv8A8EBcArtNabzy65B+DZPORLWgHuwQFIYToa6jXFCw9ASGpdQjT/hY4f5DfLwCmJD+fw9z2mn49zUfJdypIUBBCiF5DrSm8qJR6CXg4+X0F8MJgE2it1yqlKgcZ5VLggeStruuUUnlKqXKtdcMQ03RsUu9pVpAjQUGcmLQGNcTexWIxsFjM51hFo1BXZ3qXdzrB4wG3+9jn15fW0NQEublm3kczXUuL+SQS5pOVBXl55uNwHHn67m4zfVeXyVNennmtSiJh1lss1jtvMPlP9rCP1dr/fH0+2LsXwmGzzq1WyM+HkhJwuQ4eNxaDAwdMGmw2k2a3G4qKDk+/1mbezc3g90M8bj5ZWabY8nrN36ysoa/DYzGkoKC1vkkpdSVwZnLQXVrrp45z2WOB2j7f65LDDgsKSqnPYWoTjB8//viWmqwpWPwhrNZsCQpplkiYAmHfPvP/qadCQYHZ2bduhQ0bTEExe7b5zWYzB0c4DK2t5gDp6IDCQhg71oy7ejX86U9m+nnzYMkSmDPHzD8ahbY22LkTduyA9naw281HKTPvHkqZg9rrNQdpfn5vIdLRYZaVnW0O4ljMpKmnQNizB/bvNwdvd7fJj9ttCh6n0ywvK8sUhOXl5mOzQTAIoZBZblaW+USjZpjfDzU1sHu3WWdjxsCkSVBZafLfs962bIG334baWjNdImHysGgRLF5sCqeedDU2msJ+/36zHKvVpCMnx+TX6YT33jPrMho9eNu53VBaapbrdJqPUmbePl/vMgIBk9/8fDNucTGUlZl1unMnvPGGSQeYPI0fb7ZDJGLy4/GY9LtcZlg4bLbh7t1mOQNxOEw+cnLMes7PN/+3tZk819eb9XMsLBaT9zFjTPpCIfNpaDD75ECys8166tmPm5t7A86hegr6nuDk95u8D+Yb34CfpPm+T6X7HiXDPXNTU3h+gGsKzwO3aK1fS37/K/BNrfX6wea5YMECvX79oKMMrqPD7D0//SnrTr+d3NwPMm3ag8c+v5NYSwu8/ropOL1es0Pb7WZnTiRMwff227BtmylMcnN7D76eAmXnTnj3XVNAZWeb37OyzIHZ0mIKt0jk4OUWFprCMRA4eHhPIRkIDHwg9XC7Ydo0U0AOdCBZrebMMBo1n56z757g0JPPQ9PXM2083v98x46FiRNh3DiTZ4/HjB8ImE8w2LvM9nZTkDQ0mGX1FK49hWIkYta502kKxfHjTSAoLTUF2549JlC0tfWur0mTTBCdMMGsB4fDzH/dOti8uTfdVqspoCsqTOHmcJjfolFz5tzRYQr1yZNNUD31VJOungDV3GwK87a23kJR6959xePprVH05LWtzUx34IDZ9qecYgLV3LlmmXv3mn3FYjHpsVhMGnw+M3+Ho7ewnzjRpK201OTFYjHbuqPDfLq6zKez03za283wggKT54oKEyALC838AgHzu9/fGxyt1t55a91bQHd2mkDaE1hcLpOu0lKTrgkTTN57ahxtbSa/zc1mm/bsb2VlZn8pLjbrPhIx+W1uNuP7fL0nLW63SW9xsVm/PemLREw+fT6oqjInQcdCKbVBa73gSOMNWlNQSvmA/qKGArTWOufYkgdAPTCuz/eK5LD0Sr6S0zzVXHxS1xR6CsOes80tW+DNN00h3dpqDhK/v7dpoadABHNg7thx5GVkZ8P06Wa6ffvMQdXe3rvs3FyYMQNOP90cdJ2d5iAaN84UBCUlpqDrOTvcscN8nE5YuBAWLDA7/dtvwzvvmAPM7TafnrPOvDwTYOrrzfI/+EFzYDidZlnr15uzXZutt6o9ZYo5cO1DeC6xp1bS1mbyW1ho/sbjZv31nAk7HGaZ6a6+D5bOnhrJQIJB8/F4TDqH2gQlRI9Bg4LWOp1dWTwLfFkp9QjwAaAz7dcToLfBMNX/0YnTU6rWpnAPBs3ZxK5dsGmTOfuz201BW1pqCv9XXjHDeyp6fZtGvF5TmObn98bAnrZTgEjWAcrm1bH8+grOOaOEirGWVJNALAZxHaM+uIvS8jhTK73kOr14HV5sFrO7xBIxqlsa2dfaiMMTIpaIYrVYmVY0jUJ3YSo/CZ3AH/GT0InU/6XzDjDZ14BSivLsctzZpehIN4Wuaiaetg+nzUm5t5xSTylOmxOlFBZlYZLFTpY1C5vFRiQeoT4QIt4dJ9eRy6LT8znjTBvtwXZaAi3EdZzynHHY7V7iiThbm7eyfv96grEgJZ4SSj2lRBNRWgIttARaSOgEWdYs7BY79i47Vp8Vi7LQEeqgNdhKV7gLh9WBy+7CYXUQTUSJxCNkWbOYWjiVacXTKHYX0xJooTnQTLG7mCmFU1LrIRAN8PT2pwlGg4zPHU9FTgWd4U5qOmqo66qjyF3ExPyJlHvLqemoYVvLNmo7aynLLmN87niKPcUEo0G6o93EE3FynbnkO/Nx2Bx0R7rpjnYTjZttYFEWFApLpwWLspDQCWKJGHEdp8BVwBjvGIrdxVR3VPNO0zvsbN2J2+6m0F1IsbuYsTljqcipINeRi0pGlHAsTIO/gf2+/YRjYcqyyyj3luPN8qbGUajU/z3TVHdU44/4icQjxBIxHDYHLpsLq8XKnvY9bG/ZTm1nLQ6bA4/dg81ioz3UTmuwlXAsTIGrgEJXIfmufHIdueQ6c7EoC13hLnxhH06bkxJPCSWeErqj3ez37afB10AsEcOiTP570pTQCSLxCKFYiFgiRq4jl3xXPm67m0A0QHekm0g8gt1q9rMsaxZOmxOnzUkkHqEj1EF7sB2bxUahu5ACV0FqeEeog0A0QCgWMvOw2FPTZmdl43V4yXHkpPJjt9rZ17mP6o5q9vv20xnqpDPcSSwRw21347K58GR58GaZ485pc2Kz2LAqK7NLZzN/zPxhL3v6GuqF5qOmlHoYOAsoUkrVAf9FsmsMrfWdmAvVFwK7MLekvn9dcffpFC8Q2Pa+LbZHMBqkuqMa1TWexx7y8Npr5sy9ttYEg0MVF0M8oWkLN0L+bmxj3qV04TtMuGQn+bYx5MenUZCYyrQJ+SyY5eXUSg8ojdaauI4TiUeIxqNsadrC77f8ntf3/o2ETrA2DD9+xUapp5RiTzFF7iKau5vZ1rKNSPzwNhWXzYXb7qY91E5C99++M9Y7lnG542jwmUIkmoj2O95wUyj0IZXaPGcekXiEQDQwwFRDY7fYjzofs0tns3z6cpq6m3hg8wN0ho+uU2GbxUYsETuqaYaTPdn1S0IniOsB2tH6cNlclHhKKPYU0xZso7qjesB9pC9vlpdoIkooFkrNp9BdiMPqoC3YRkeo47DtejwsyoJVWYd9v7Rb7DhsDrKsWUTjUcLxcL/H0KGsykquM5dcRy52q51gNGiCVLQ7tU76WnXmqrQHhbReU0iH476mAKbxdP58dv2gnIaGu1myZJCrWccokdA8+4/tPPP6Fhz+qdg6puEPBdie8yvedv+MoCVZQ/GX4o6OJ8daSqGjFI/TTszaRdTiA4cPHF0EE13Ud9UTjAVT88/OymZKwRQa/A0c8B8Ycrom5U/iE7M+wdyyuez37ae2q5bG7kaau5tpCbSQ78pnVsksZpbMxGF14Iv48IV9qb+BaIBCdyFjvWMpzS7FZXORZc0iHA+zpWkLmxs3s9+3nzHeMVR4KyhyF6XOYN12N+XZ5ZRml6K15oD/AAf8B/BkeajMq2R87vjUWWmjv5FIPJIqlGKJWOqMs+cszqIsdIY6aQ+1E46FU2e7FmWhtquWmo4a7FY7C8YsYOGYheQ6c2n0N9LU3YTdaqfYXUyhuzBVSPTMP5aIkdAJch25FLoLcdqcaK17zwStduwWO4FogO0t29nWso22YBvFbhNYd7bt5NF3H+Uftf8gy5rFldOu5PPzP88peaewr3MfdV115DhyqMyrZKx3LC2BFvZ27KW+q57xueOZXjydsuwyOkId7OvcR3OgGbfdjcfuwWqxps5aw/EwHruH7Kxs7Fa7WVeJOJreEwKrsmKz2LAoC63BVvb79tPU3cS4nHHMKp3F1MKphGIhWoOtNHc3U++rp7azluZAc+ps22lzMsY7hjHeMWRZs2j0N9Lgb8Af8QOgtcYf8dPYbdZtviufKQVTmFwwmTxn3kE1vEA0QDQepTKvkqlFUylwFQAQT8RTtYm+4ok4neHO1Nm01pocRw7ZWdmEYqHUMrOzshnjHUNZdhkOq6PfYNZzxg3mxKwj1EF3tBuP3YMny5Mq0KOJKOFYmHA8TDAaxG61k+/MJ9eZSywRoy3YRluwjSxrFvnOfPKcedith7dTxhNxuqPd+MI+OsOdtAXbaA20Eo6HGZ87nsq8Sko8JVhU/7eNReNR/BE/4Xg4tV96s7wH1caPxlCvKWRmUJg/H8rLqbnjDPbu/Q5LlgSxWo/iXrlDBKIBnnvved6trWXbvmbdYnIKAAAgAElEQVS27d/H9tAa4u4+rWExB0rb0PZubHsvILduObPPbKB46h46ErU0dTfR6G80G97hxZtlqpw9/4/1jmVC/gQm5E1gevF0Tsk7JbUztQfb2dW2i45QB76IKbgVKnVQ91SHy73lzC2be1A1X6RPg68Bh82RKviEGEnDcqF51OrTfTZALNaK1Tp2SJO+WvMq9b56it3FuOwufrXmcZ7Y9VvClg4zQtwO/lJKwks5p/Rsrjl7Lq3sYHPjW3SFu/j8gs8zr3zesGYn35XPwrELh3We4viVe8tHOglCHLXMDApeL9TWpoJCNNqCwzF4UNBa86PXfsR3/vadg3+I27Bs/xhLnF/gowuqWDw3hzlzVM8zckkLuJZPDG8ehBAiDTIzKBxSU+jvttQtTVvY076HhWMWUuIp4YYXb+CXb/6Sce3XsP/RbxF3tDJpZjufOW8Rn7+hnAJpIRBCjAKZGRT63H0EBweFeCLOLa/dwn+t+a/UharcrHw6I+3wj3+jY92tfP1zFq67ztyfL4QQo0nmBoV+agr1XfV88qlPsrp6NVfPvJp/XfCv3P38Wzz8ynps+5Zy47KVfPNhpFYghBi1MjMo5ORAOIwtYZ7sikSaeXHXi3zyqU8SiAa479L7WD7l03zta4rf/WYpH/wgPPSYeSpXCCFGs8wMCrm5AFi6/GDJ45Y3n+Oubd9jVsksHlv+GIX6NJYuhbfegm9/G773PfMgtBBCjHaZWdSNTd5ptH8/D+yzcN/ujayct5JfnP8LmhtcLDnX9PPz7LNw8cUjm1QhhHg/ZWZQqKgAILGvhhfq/ZxZUshdH72LHTvgIx8xPRL++c+m4zUhhMgkx/FajpNYMii8tvcVGkMRziv3oDVcc43pdfOVVyQgCCEyU2bWFEpLwWbj961rcGXZOL0gytNPmy6Y77vP9C0vhBCZKDNrClYrkYpyHuddzhl3KpZYG9/9rua00+Daa0c6cUIIMXIys6YA/Hm2hzZrhCunns3Lz85j61bF44/LXUZCiMyWsUXgQ5O6KQxZOPuUK1j12/HMnt3JFVfkjnSyhBBiRGVk85E/4ueZnAaWb1M8+9RcGhom8o1vrMaSkWtDCCF6ZWQx+PyO5wmqGJ94K84fn3ZRUbGLRYv+PNLJEkKIEZeRzUdv1r+JU9n5QG2MV9usnH3OOwSD7410soQQYsRlZFDY1rKN07IreVd76PJbWbz4AIGABAUhhMjI5qOtzVuZVjydV1gGwNKlUSKRemIx/winTAghRlbGBYXuSDc1nTVMHzePVziLifltTJw4BoBgcMcIp04IIUZWxgWF7S3bAZhaPIO1ahnLCt/F7Z4KIE1IQoiMl3FBYVvLNgCyOqbTpvNZlvU6LtdkQElQEEJkvIwLClubt2Kz2KjeOBmAZaGXsFpdOJ2nSPORECLjZVxQ2NayjSkFU3htrZ3x3jYqG98ArXG5pkpNQQiR8TIuKGxt3sr04umsXQvLTm2A7m7o6sLtnkowuAOt9UgnUQghRkxGBYVwLMyutl0UM42mJlg2v9v8UFeH230q8bifSGT/yCZSCCFGUEYFhZ1tO0noBLGG6QAs/ZDV/FBbi8sldyAJIURGBYWtzVsBiDdOw2aDSR8oMj/U1cltqUIIQYYFhW3N21AoQvVTGTMGLGPLQSmoq8PhGIvF4pagIITIaBkVFLa2bGVC/gQO1LoYOxbIyjKv5qyrQykLbvep0jGeECKjZVRQ2Na8jenF06mvh4qK5MBx46CuDgC3exp+/2a5A0kIkbEyJijEEjHea32PaUXTqavD1BTARIdkUMjPP5dIpAGfb8PIJVQIIUZQxgSFve17icQjVHqmEQj0qSlUVEBNDcTjFBV9FLDS0vLUSCZVCCFGTMYEhZ47jwri5nbUVFA44wzw+2HdOuz2QvLylkpQEEJkrIwJClOLpvL9s76PwzcN6NN8dMEFYLfDM88AUFR0OYHANrkLSQiRkdIaFJRS5yul3lNK7VJKrern9+uUUs1KqU3Jz2fTlZbTik7jP5b9B+0HvECfmkJuLnzoQ32CwmUANDdLbUEIkXnSFhSUUlbgDuACYDrwcaXU9H5GfVRrXZX83JOu9PRIXlNmzJg+Ay+9FHbsgO3bcTrH4fUulCYkIURGSmdNYRGwS2u9R2sdAR4BLk3j8oakvh5KSswjCimXXGL+Pv00YJqQfL5/Eg7Xv/8JFEKIEZTOoDAWqO3zvS457FBXKqXeVko9oZQal8b0mET0vR21R0UFzJ9/0HUFgJaWp9OdHCGEOKGM9IXm54BKrfVs4C/A/f2NpJT6nFJqvVJqfXNz83Et8KAH1/q69FJ44w04cACP5zTc7tNoanr8uJYlhBAnm3QGhXqg75l/RXJYita6VWsdTn69B5jf34y01ndprRdorRcUFxcfV6L6rSkAXHYZaA3PPQdAaemn6Ox8hUBA3sYmhMgc6QwKbwJTlFITlFJZwNXAs31HUEqV9/l6CbAtjekhFILW1gFqCjNnwoQJqesKZWXXo5SN/fvvSmeShBDihJK2oKC1jgFfBl7CFPaPaa3fVUp9XymVvLLLV5VS7yqlNgNfBa5LV3rANB3BADUFpeCKK+Avf4G2NhyOMoqKLufAgfuIx0PpTJYQQpww0npNQWv9gtb6VK31JK31D5PD/lNr/Wzy/29prWdoredorT+ktd6ezvT0BIV+awoA11wD0Sg89hgAY8Z8nlisjebmJ9KZLCGEOGGM9IXm91XPMwr91hQAqqpgxgz43e8AyMv7EC7XFPbvv/P9SaAQQoywjAoKR6wpKAXXXgt//zvs2YNSFsaM+TxdXX/H73/nfUunEEKMlIwKCnV14PWaz4A+8Qnz96GHACgt/TRKZbF//6/Sn0AhhBhhGRUUBnxGoa/x4+Gss0wTktZkZRVRVnYdDQ2/IRSqeT+SKYQQIyajgkJd3RCCApgmpB07YP16AE4puhHiUF39/fQmUAghRlhGBYX6+kEuMvf1sY+Bw2GCw8SJOItOY+7/TubAgfulS20hxKiWMUEhHoeGhiHWFHJz4StfAasVFi6ED38Y7/M7cbZnsXfvf6U9rUIIMVIyJig0NprAMKSaAsBPfgJbt8Kjj8Kdd6JiMU5du5Dm5kfx+zenNa1CCDFSMiYo9DyjMKSawqGmTIHzziP/8Z3YyGPr1k8QjbYOa/qEEOJEkDFBYdAuLobii19E1TdQVft1gsHdvP32RcRi/mFLnxBCnAgyJijMmAG33goTJx7jDC66CMaPJ/uBV5k+/RF8vjd5990rSCTCR55WCCFOEhkTFE49FW66yVxDPiZWK3z+8/DyyxS3TWPq1Htob/8LO3Z8cVjTKYQQIyljgsKw+MxnzHs858+n/FO/Z/YzS2nbei8NDb8Z6ZQJIcSwkKBwNEpL4a9/heuvh+Zm8n/xKgu+6KD+T/+Kz7dhpFMnhBDHTYLC0frgB+F//xc2bUJt3IjdVsDcr8Sov+dCIpHGkU6dEEIcFwkKx6OqCvXGmzD5VKZ+o4nIrHFEVpwL//M/4Jc7k4QQJx8JCsdr7Fisf19P9N8+S6zATmLNX+Ab30CfcQbs3TvSqRNCiKMiQWE4ZGeTdevdZL96gD2rP87mWyFRswO9cKF5vWciMdIpFEKIIZGgMIxsNi/Tpj2E5/IbWX9HmGi+gnPPNZ3rjR8PH/0oNDWNdDKFEGJAtpFOwGijlGLSpNuIx7t44+f3MGPzZeT7TkPV18OTT8KyZeYOpjFjBp5JImGCR36+CSji5BSJmL9ZWSObDiGOgtQU0kApxamn3klB5QrePuNp3rz8afb99yzCT9+LrqtFLzmTRPXO3gl27YJf/hIuvhgqK00gKC83t8B+9rOwZo3pzU+cmKJRaG8/eNiWLTBpElx2GWg9MukSJ6YTvDlZ6ZNsh12wYIFen3z5zYkukYjS2PggDQ330tX1dwBytsLsfwdbN2ilUH3X/+TJ8IEPmKam8nLzkp8nn4TubvMo9hlnwNKlcN11UFbW/0JDIdizx0wTCpm7oFpbzaeyEi69NO35zih+P5x3HmzcCF//OqxaBZs2mfUcCJjawp//DOecM9IpHbpdu+BPf4JZs0zX8R7PwOPW1cE118CBA3D22fCRj5i8DvrO22EWjYLFYnodOJGFQvClL8Hzz8MLL8D8+e/r4pVSG7TWC444otb6pPrMnz9fn4z8/m26vv5OXVf3K93wl2/pfddl632fduvwN7+g9R13aL1z50ATav3II1p/7nNaT5umNWidl6f13XdrnUhoHY1q/ac/ab1ypdZVVVrbbGacgT7/939Hn/iuLq0jkeNbAXv2DJzH4xWNah0Mpmfeg+nu1vqss7S2WLS+4AKzfktKtHY4tJ46Vev33tO6slLrefO0jscHn1cioXVNzZHHS6doVOtbbtHa6ezdX6xWrRcv1vq227Tet+/g8dev13rMGK29XpP/7Gwzjcej9Wc+o/Vrr2m9bp3W996r9U03af2xj2m9cKFZJ5dfrvXtt2u9ebPW4fDB843HtQ6Fer/7fFr/8pdaT5+u9fz5Wr/yihkei2n9s59p7XZrPXmy1g89NPT1Fw5r/ZOfaH3++Vr/9Kcmb52dWt95p1nGpElaf+c7ZhtGIlpv3671c89p/cYbZrlHa98+rRcsMOunsFDr/Hyt33rryNP95S9a//a3Wq9Zo3V1tdlGxwhYr4dQxkpNYYQEAjvYtGkZWmuqqtbg8Zw2tAnfe8/0wfTKK+ZMo7bWXH/IyTG1jPnzzRleTg64XOYsr6AA8vLg0582d0M9+yxceKGZn9bQ1gY1NWZeU6bA9Onmt2gUbrkFfvADUMoMr6qCSy4x0zscZvrNm+Hll+HNN82noQGmToWZM8FmM81fNcn3W0+das6ip02DYNCcPZWWwpw55jdbn8tcPh88/DD88Y8wdy5ceaWZ55Yt8NxzZr579ph52+3wxS/CN78JxcUmDU8/bZrdrr4aioqObgN1dkJzs1k3gYC5BjR+PDidZr00NZluT/78Z3jwQXO2/M9/muUrBY8/DoWF5rdPfcq8l+Oqq8x8f/lLM7/lyyE722zTr37VzGvyZPP/ddeB221qIlqb7dcjkYC1a+Ef/4B9+0z+i4rMcs4+25w179ljrl3FYqZWWVRk3g/y6quwYYMZNmuWWed+v3nhyF//Cm+/DZdfDj/8obml+h//gBdfNNOAmWbCBDP9735n5vv882Z4NAqvvw4PPACPPGJqqz0cDlNTPeUUc63sn//svWXbZjNNbeXlpjvjffsgHDbrr6ICqqvNelu40Kz3mhqzTXfvNvvbueeamsrbb5v945xzTHfIY8aYfauszOwTFotZdxs3wg03wPbtZpvu22fS4XSa/XH27N7eCxIJk75YrDcvhYVmmVdfbTrKHKiGEgqZ9fe3v8Hdd5v9/cEHzfyXLTP71V//avb9QwUC8LWvwT33HDz8hhvgZz87ih2511BrChIURlB393Y2bTqLRCLEpEk/prx8JUoN4TJPIgH33We6fZ092xRIF1xw5IvSfr/ZGbdvN9Nu2AAvvQT79x883pIl8IlPmB1540ZTmJ1yijno1q83TVF5eXDWWeag7OmXvLISFiwwB/J778G775qde+lS+NCHzDjPPgurVx98kPVwOMxyxowxzWUvv2wKlnHjTDOF1mZ4Z6cZv6oKTjvNFFK1tfD735tAOGsWvPFGb1u+3W4KuvPOMwVEWZkZr+d3i8Uc+NGoWR+PP24O5v70XT6Yg/Yznxl4ncfjJp2hEPz0pyZw9bzcIzvbrJcXXzTp+fKXzbp5/XVT0PS9jjRlitkuXi888UTvOi8qMgXb3r3musb48WY97tx5eFrAFHaLFpnCdcuW3oLb4zHb7/vfhyuuOHy6XbtMYHv9dbOua2pMYfboo/03ZXZ1mWDh8ZguiidMOLzwrK6Gv//dBKtt20xgqqgw6fB6TR7r6sy+9qUvweLFZn+65Raz/+bkwC9+YQpnrc16+fGPzf4dCAy8TcAEoZ//3FzH27EDHnvMrJNrrzXBRylzXDz8sNnfp041vWpWV5umtRdfNCcN48fDypUmf9GoWe4775jjZvNmE9ysVtMTwp13mv21Z30uW2aWUVxs0jNpkplPRYXJ1/btpjnyuutM4KquNidmZ5wxeN4GIEHhJBEM7ua991bS0bGanJwzGDfuRqxWLxaLC49nFnZ73pFncjQOHDAHV02NOdjOOcd8r6w0O+PatfB//2d22uJi+PWvzRl6j1jMnN387nemtrJokTlbOv98c6Y3FF1d0NJiCkKn0xz4mzeboFNTYw6UpiZTCK5c2VuIPf00rFtnDoqLLz58edu3m1rNe++Z23+XLzcB9J57zBlaW9vQ0jdnjrlAPGmSqWW5XKaAqq42BUFREZSUmPFOP/3I83vuOVO7AnNQ33efudZw772m4LzwQlOYlZaacd54A555xhTuOTmmYPnHP+C110xgv+AC+PjHzXQ5OWaaUMhM88AD5vt555lPbq7Z5o2Npt/4yZNNgQdm3TQ2mnkMdt3gRLR/v0lzf90ea232sf37e/Pe3Gx+U8pMs3y52feOVTRqTnB+/WtzPPSVmwvz5pla+7Jl5qSoZzv1tW+fCTq7d5vPnj1mWCJh9oUHHxzWa1ESFE4iWmsaGx9k164bicV63+hmteYwbtyNVFTcgM2WSzweJBzeh9M5CYvlOO4mbmgwO9/8+Qc31/ToqWJPnGgKxdEgEjEFe2OjKSjCfd6DkUiYYJdImIAzZcrwLltr887voiL41reO/TbjRMKk2+Ua3vSJ41Nfb2pcdrvZtmVlpvZ5LKJRc2yWlpqa5DCSoHASisW6CAZ3kUgEicU6aGi4h5aWp7HZ8rHZ8gmF9gIar3ch06Y9iNs9daSTLIQ4SUhQGCV8vg3U1t6G1gnc7mnYbLnU1Pw3iUSQiRNvJTf3dBKJCErZ8Xrno3qaBoQQoo+hBgV5ovkE5/XOZ/r0hw8aVlKygu3b/4Vdu75y0PCcnNOZPPl2cnKOfCuyEEL0R4LCScjhGMPs2X+io2M18Xg3FksWweAeqqtvZuPGRZSWfoqSkhXk5i7BZjPtkolElHjch1JZWCxZKGWXWoUQ4jASFE5SSiny8z980LDS0k9QXf0D6ut/SWPj/Shlx+WaQjTaQjTaDPQ2FbpcUzn11DvJzz/r/U24EOKEJtcURqF4PEhn599pb3+ZQGA7WVmlOBxjsFpz0TpGIhHiwIH7CIX2UF7+WcrLVxKNthCJNCYDSCvxeCcFBRdRVHTxSGdHCDEM5EKzGFQ8HqC6+mZqa/8HOLiDLqXsWCxO4nEfxcVXMWXK7djtRXR3b8Xn+yfd3e/S3b2VaLSJ8vKVlJevPL5bZIUQaSdBQQxJd/dWAoEdZGWVkZVVit1ejNXqQeso+/bdSk3ND7BYHIAmHjevGLVYXLjdpwEW/P4NuN2nUVFxA6FQDV1d64hGWygouIDi4ivwehce9JS21gl8vjex2fJxu08dmUwLkYEkKIhh0d29nZqaH2Cz5ZGTczo5OR/A5ZqEUha01rS2Psvu3d8kGHwPpWx4PHOw2XLp7FyL1jHs9hJychbh9S4iHu+iqelRwuFawMKYMV9gwoTvAxYaGu5m//7/Ix73YbPlYrXm4vFMx+tdgMczk3C4nu7ud4lGWxg37kY8nul90vgura0vYLPlYbcX4XJNxuOZKRfShehDgoJ43yQSUQKB7bhck7FazdO20Wg7ra3P0d7+V3y+NwkEtqOUlfz88ygpuQqf703q63+NzeYlkYiSSHSTl/ch3O6pxGKdRKOtdHe/TSRyILUcc8dUFlrHmDjxFsaMWUlNzQ+prf0JWh/cl5LLdSolJVeRk3Nm8m4rG6BJJCJoHSGRiKJ1DK0jhMP1BIO7CYdrcTorU4EoGm0mGNxFJNKA3V6K03nKMQUcrTXB4C4AnM7xyZoXJBIxYrEObLYcLJbBX8QTDjfQ1bWORCJEcfGVA47f0bGWUGgfTmclTmclDsdYCY4COEGCglLqfOAXgBW4R2t9yyG/O4AHgPlAK7BCa1092DwlKJycYjHTiZzN1ttXjd+/hZqa72G15lBR8VWysw/vLTIc3k9397s4HBW4XJOJRlvZsWMlra3PY7F4SCS6KS39NBMn/hCtNdFoCz7fmzQ1PUpHx2oOvV4yEJutEIejglBoL/F41yG/WoHezumczkqKiz9GYeGlZGdX9bntN0Ig8B6hUDWxWBvRaCt+/1u0t/+NSKS308GsrDISiQixWG9fTHZ7CU7neAoLL6Ws7FM4nePx+7dw4MBvaG7+A+Hwvj7Ln0Bl5fcoLf0ESplO5iKRZnbtuoGmpt8flHKHYzzFxVdQVHQFDsdYtI4SjwcJBLbi979FMLiXkpIVFBdf2W9njLGYj0BgW+oGBKUsuFyTcbkmY7cXHjZ+PB6gre1Fmpsfp63tz+Tnn83kyT/D4RibXEdRfD7T42rPCUQotI9QqJpotBmrNRurNQeXawL5+R9J5W8wWmtCoT10dv4Dv38j2dlVFBVdmdouxyMYNOmy2wuw2Qqw2fJO2iA74kFBma25AzgHqAPeBD6utd7aZ5wvArO11l9QSl0NXK61XjHYfCUoCK01DQ2/oanp95xyyncPuzW3RyTSRDC4M3nHVRSlrMmL6KbG0fN/VlZZKlhpnSAY3El397tkZZUlC79iYrE2QqEa/P63aG5+kvb2v6RqJ07nBKzWbAKB7WgdPSgNdnsxeXkfJj//w1gsTkKhakKhfVgsDuz2Yuz2AmKx9mTz2Nbky5gULtdkgsGdKGWnsPAicnOXkZPzAWKxdvbu/S5+/1vY7SW43aficJxCW9uLxONdjB//bUpKVhAK1RAM7qK9/SXa2v6M1pHD1o9SDuz2fCKRA3g8M6mo+DpKZRGLtRIKVdPZ+Ro+31v0DYh9Wa05OBwVOBxjSSTChEJ7CIfrAY3dXkRe3lm0tj6PUjbGj19FOFxHU9PjB/XvNRincxIVFV+luPgqbLZcLBYn0WgzPt9G/P63CAS2EQjsIBjcmQqwStnROorF4qG4+Epyc5fg8czE5ZpAKLSPQGBbcv07kwHIg9XqxWbzopSdeLybeNyP37+Z1tZn6O7eclCaXK7JlJVdT1nZp1OBzuxrjbS1/ZmOjleIRluIx7tIJCLk5S2lsPCj5OQsSp20hEJ76ep6g66u15Nd1wAosrLKKSy8mMLCi3E4enueNdO1EgrtxW4vwOWaNKT1d6gTISicDtystT4v+f1bAFrrH/UZ56XkOK8rU78/ABTrQRIlQUGcCKLRdjo71+L3v0N39zvE4348nllkZ8/B5ZqE3V54TGeWweBeDhy4n66uv1NQcCGlpdeSlVV80DhaJ2hu/gOtrc8TCu0lFNqL0zmRU0+9A49nxmHzjMW6aG9/mXjcj1I2lMrC7T4Vt3saSlloanqMmprvEwhsT02jlIOcnMXk5S3B612A3V6C3V6E1jGCwV0EgzsJhaoJh+sIh+uwWBw4nRNxOieQl7eE3NxlWCw2gsE97Nz5Zdra/oTF4qao6BKKiq7Aas0mkQihdRyncxxOZyV2e3Gy3y8fnZ2vUlf3c7q6BujCHHA4xuFyTcHlmoLXO5ecnDNwu6fR1bWOxsb7aWp6nHi8c8DpB2clL28JhYWX4HJNIRZrIxJporX1eTo7XwEs2O3FWCxOlLKkCveeGqfNloPWcbq63gDiWCxOEonQIekfn9wGCq01gcC2VI0wK6ss2VxqTQYZc5PHuHH/zqRJPz6mHJ0IQeFjwPla688mv38S+IDW+st9xtmSHKcu+X13cpyWgeYrQUGI4ad1HL//baxWTzKg5Q2p6WZo89YEAltxOE456iadrq5/0tX1BolEgHi8G5stD693frLZrp9usw9aboJQqIbu7i2EQntShbDLNYFEIpKqFcTjPuJxH1pHk7WHbLKyxg7YbX0wuJvGxt8TDtcnA1sYj2c2BQXnkZ1ddVAzXDTaTlvbi/h8/0zeCFGMwzEWr3chDseYw9ZTd/c7tLQ8Szhcg9ZxtI5is+XjdE7E5ZqAxzMHl6vyqNZhj1EVFJRSnwM+BzB+/Pj5NT1v8RJCCDEkQw0Kx9jp95DUA+P6fK9IDut3nGTzUS7mgvNBtNZ3aa0XaK0XFBcXH/qzEEKIYZLOoPAmMEUpNUEplQVcDTx7yDjPAp9O/v8x4G+DXU8QQgiRXmnrm0BrHVNKfRl4CXNP371a63eVUt8H1mutnwV+AzyolNoFtGEChxBCiBGS1g5rtNYvAC8cMuw/+/wfApanMw1CCCGGLp3NR0IIIU4yEhSEEEKkSFAQQgiRIkFBCCFEyknXS6pSqhk41qfXioABn5YeRSSfo4vkc3QZqXyeorU+4oNeJ11QOB5KqfVDeaLvZCf5HF0kn6PLiZ5PaT4SQgiRIkFBCCFESqYFhbtGOgHvE8nn6CL5HF1O6Hxm1DUFIYQQg8u0moIQQohBZExQUEqdr5R6Tym1Sym1aqTTM1yUUuOUUquVUluVUu8qpb6WHF6glPqLUmpn8m/+SKd1OCilrEqpt5RSzye/T1BKvZHcro8me+Q9qSml8pRSTyiltiultimlTh+N21Mp9fXkPrtFKfWwUso5GranUupepVRT8n0xPcP63X7KuD2Z37eVUvNGLuVGRgSF5Pui7wAuAKYDH1dKTR/ZVA2bGPBvWuvpwGLgS8m8rQL+qrWeAvw1+X00+Bqwrc/3HwM/01pPBtqBz4xIqobXL4AXtdanAXMw+R1V21MpNRb4KrBAaz0T05Py1YyO7flb4PxDhg20/S4ApiQ/nwN+/T6lcUAZERSARcAurfUebd5g/ghw6QinaVhorRu01huT//swBchYTP7uT452P3DZyKRw+CilKoCLgHuS3xXwYeCJ5CgnfT6VUrnAUky38mitI1rrDkbh9sT00vv4b6IAAAQfSURBVOxKvmDLDTQwCran1not5lUAfQ20/S4FHtDGOiBPKVX+/qS0f5kSFMYCtX2+1yWHjSpKqUpgLvAGUKq1bkj+dAAoHaFkDaefA/8OJJLfC4EOrXUs+X00bNcJQDNwX7KZ7B6llIdRtj211vXAbcA+TDDoBDYw+rZnj4G23wlXNmVKUBj1lFLZwJPADVrrrr6/Jd9md1LfZqaUuhho0lpvGOm0pJkNmAf8Wms9F+jmkKaiUbI98zFnyROAMYCHw5tcRqUTfftlSlAYyvuiT1pKKTsmIDyktf5DcnBjTzU0+bdppNI3TM4ELlFKVWOa/z6MaXvPSzY/wOjYrnVAnf7/7d09iFRXGMbx/xOCIbKCBGKTYBYjiASShYCIibCglVikSBTUKAvpbFIEgiEiEWy1UdDCQlGCRjRJGfxg0UKN+EFAOy20UFMEQUQR81icM9fJquyy0Z3ZmefXzZnL5V7emXnvPXfO+9rn6usjlCTRa/FcDtyw/bftx8BRSox7LZ4tL4tf1/029UtSmEi/6GmpzqvvBa7Z3t72Vnv/6w3Ab1N9bK+S7U2237c9SInfSdtrgVOU/t7QG+d5G7gpaUEdWgZcpcfiSZk2WixpZv0Mt86zp+LZ5mXx+x1YX/+FtBi41zbN1BF9s3hN0grKnHSrX/S2Dh/SKyHpc+A08BfP5tp/oDxXOAzMpVSVXWV77MOvaUnSMPCd7ZWS5lHuHN4BLgHrbD/q5PH9X5KGKA/TZwDXgRHKBVxPxVPST8Bqyj/oLgHfUObTp3U8Jf0MDFOqod4BtgC/8oL41YS4kzJ19gAYsX2hE8fd0jdJISIixtcv00cRETEBSQoREdFIUoiIiEaSQkRENJIUIiKikaQQMYUkDbcqvEZ0oySFiIhoJClEvICkdZLOS7osaU/t43Bf0o7aA+CEpHfrtkOSztZ6+MfaauXPl3Rc0hVJFyV9WHc/0NYv4WBdwBTRFZIUIsaQtJCy0vYz20PAE2AtpWjbBdsfAaOUlaoA+4HvbX9MWVneGj8I7LL9CbCEUg0USiXbbym9PeZRav5EdIU3x98kou8sAz4F/qwX8W9TCpj9Cxyq2xwAjtb+B7Ntj9bxfcAvkmYB79k+BmD7IUDd33nbt+rry8AgcOb1n1bE+JIUIp4nYJ/tTf8ZlDaP2W6yNWLaa/k8Id/D6CKZPop43gngS0lzoOmv+wHl+9Kq4LkGOGP7HvCPpKV1/GtgtHbBuyXpi7qPtyTNnNKziJiEXKFEjGH7qqQfgT8kvQE8BjZSGt4squ/dpTx3gFIKeXf90W9VNYWSIPZI2lr38dUUnkbEpKRKasQESbpve6DTxxHxOmX6KCIiGrlTiIiIRu4UIiKikaQQERGNJIWIiGgkKURERCNJISIiGkkKERHReArsCy9EbmCXRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.2257 - acc: 0.9398\n",
      "Loss: 0.22574864176188056 Accuracy: 0.93977153\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7060 - acc: 0.4686\n",
      "Epoch 00001: val_loss improved from inf to 0.83909, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/001-0.8391.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 1.7060 - acc: 0.4686 - val_loss: 0.8391 - val_acc: 0.7370\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7354 - acc: 0.7702\n",
      "Epoch 00002: val_loss improved from 0.83909 to 0.51322, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/002-0.5132.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.7356 - acc: 0.7701 - val_loss: 0.5132 - val_acc: 0.8418\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4941 - acc: 0.8462\n",
      "Epoch 00003: val_loss improved from 0.51322 to 0.35453, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/003-0.3545.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.4941 - acc: 0.8462 - val_loss: 0.3545 - val_acc: 0.8887\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3770 - acc: 0.8818\n",
      "Epoch 00004: val_loss improved from 0.35453 to 0.30038, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/004-0.3004.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.3771 - acc: 0.8818 - val_loss: 0.3004 - val_acc: 0.9115\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3090 - acc: 0.9033\n",
      "Epoch 00005: val_loss improved from 0.30038 to 0.26835, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/005-0.2683.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.3092 - acc: 0.9033 - val_loss: 0.2683 - val_acc: 0.9147\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2617 - acc: 0.9173\n",
      "Epoch 00006: val_loss improved from 0.26835 to 0.23525, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/006-0.2352.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.2617 - acc: 0.9173 - val_loss: 0.2352 - val_acc: 0.9294\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9298\n",
      "Epoch 00007: val_loss improved from 0.23525 to 0.21635, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/007-0.2163.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.2244 - acc: 0.9297 - val_loss: 0.2163 - val_acc: 0.9336\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2028 - acc: 0.9356\n",
      "Epoch 00008: val_loss improved from 0.21635 to 0.21112, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/008-0.2111.hdf5\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.2027 - acc: 0.9356 - val_loss: 0.2111 - val_acc: 0.9359\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9453\n",
      "Epoch 00009: val_loss improved from 0.21112 to 0.20202, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/009-0.2020.hdf5\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1729 - acc: 0.9452 - val_loss: 0.2020 - val_acc: 0.9415\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1630 - acc: 0.9495\n",
      "Epoch 00010: val_loss improved from 0.20202 to 0.19505, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/010-0.1951.hdf5\n",
      "36805/36805 [==============================] - 155s 4ms/sample - loss: 0.1631 - acc: 0.9495 - val_loss: 0.1951 - val_acc: 0.9436\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9522\n",
      "Epoch 00011: val_loss improved from 0.19505 to 0.17638, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/011-0.1764.hdf5\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1501 - acc: 0.9522 - val_loss: 0.1764 - val_acc: 0.9469\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9605\n",
      "Epoch 00012: val_loss improved from 0.17638 to 0.17418, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/012-0.1742.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.1262 - acc: 0.9604 - val_loss: 0.1742 - val_acc: 0.9478\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9633\n",
      "Epoch 00013: val_loss did not improve from 0.17418\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.1178 - acc: 0.9633 - val_loss: 0.1818 - val_acc: 0.9418\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9680\n",
      "Epoch 00014: val_loss did not improve from 0.17418\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.1027 - acc: 0.9680 - val_loss: 0.1901 - val_acc: 0.9450\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9739\n",
      "Epoch 00015: val_loss did not improve from 0.17418\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0870 - acc: 0.9739 - val_loss: 0.1803 - val_acc: 0.9492\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9723\n",
      "Epoch 00016: val_loss did not improve from 0.17418\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0887 - acc: 0.9723 - val_loss: 0.1800 - val_acc: 0.9497\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9694\n",
      "Epoch 00017: val_loss did not improve from 0.17418\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0968 - acc: 0.9693 - val_loss: 0.1778 - val_acc: 0.9490\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9736\n",
      "Epoch 00018: val_loss improved from 0.17418 to 0.16836, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/018-0.1684.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0874 - acc: 0.9736 - val_loss: 0.1684 - val_acc: 0.9504\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9795\n",
      "Epoch 00019: val_loss improved from 0.16836 to 0.16685, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/019-0.1668.hdf5\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0698 - acc: 0.9794 - val_loss: 0.1668 - val_acc: 0.9532\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9827\n",
      "Epoch 00020: val_loss improved from 0.16685 to 0.16459, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv_checkpoint/020-0.1646.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0616 - acc: 0.9827 - val_loss: 0.1646 - val_acc: 0.9518\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9858\n",
      "Epoch 00021: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0509 - acc: 0.9858 - val_loss: 0.1801 - val_acc: 0.9497\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9868\n",
      "Epoch 00022: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0462 - acc: 0.9868 - val_loss: 0.2010 - val_acc: 0.9439\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9877\n",
      "Epoch 00023: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0435 - acc: 0.9877 - val_loss: 0.1788 - val_acc: 0.9520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9865\n",
      "Epoch 00024: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0463 - acc: 0.9865 - val_loss: 0.1825 - val_acc: 0.9522\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9854\n",
      "Epoch 00025: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0504 - acc: 0.9854 - val_loss: 0.1871 - val_acc: 0.9499\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9875\n",
      "Epoch 00026: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0424 - acc: 0.9874 - val_loss: 0.1940 - val_acc: 0.9509\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9882\n",
      "Epoch 00027: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0413 - acc: 0.9881 - val_loss: 0.1817 - val_acc: 0.9483\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9921\n",
      "Epoch 00028: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0309 - acc: 0.9921 - val_loss: 0.1786 - val_acc: 0.9504\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9899\n",
      "Epoch 00029: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0347 - acc: 0.9899 - val_loss: 0.1782 - val_acc: 0.9529\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9921\n",
      "Epoch 00030: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0281 - acc: 0.9920 - val_loss: 0.1811 - val_acc: 0.9509\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9845\n",
      "Epoch 00031: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0493 - acc: 0.9844 - val_loss: 0.1789 - val_acc: 0.9532\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9875\n",
      "Epoch 00032: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0420 - acc: 0.9875 - val_loss: 0.1659 - val_acc: 0.9539\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9898\n",
      "Epoch 00033: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0361 - acc: 0.9898 - val_loss: 0.1947 - val_acc: 0.9536\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9908\n",
      "Epoch 00034: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0312 - acc: 0.9908 - val_loss: 0.1726 - val_acc: 0.9541\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9914\n",
      "Epoch 00035: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0302 - acc: 0.9914 - val_loss: 0.1764 - val_acc: 0.9574\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9928\n",
      "Epoch 00036: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0254 - acc: 0.9928 - val_loss: 0.1803 - val_acc: 0.9553\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9965\n",
      "Epoch 00037: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0152 - acc: 0.9965 - val_loss: 0.1759 - val_acc: 0.9557\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9879\n",
      "Epoch 00038: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0397 - acc: 0.9879 - val_loss: 0.1908 - val_acc: 0.9506\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9952\n",
      "Epoch 00039: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0193 - acc: 0.9952 - val_loss: 0.1954 - val_acc: 0.9499\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9968\n",
      "Epoch 00040: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0136 - acc: 0.9968 - val_loss: 0.1818 - val_acc: 0.9543\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9964\n",
      "Epoch 00041: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0146 - acc: 0.9964 - val_loss: 0.1888 - val_acc: 0.9548\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9904\n",
      "Epoch 00042: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0319 - acc: 0.9904 - val_loss: 0.1926 - val_acc: 0.9543\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9929\n",
      "Epoch 00043: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0236 - acc: 0.9929 - val_loss: 0.1830 - val_acc: 0.9553\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9944\n",
      "Epoch 00044: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0196 - acc: 0.9944 - val_loss: 0.1806 - val_acc: 0.9550\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9964\n",
      "Epoch 00045: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0139 - acc: 0.9964 - val_loss: 0.1881 - val_acc: 0.9539\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9915\n",
      "Epoch 00046: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0270 - acc: 0.9915 - val_loss: 0.2053 - val_acc: 0.9520\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9923\n",
      "Epoch 00047: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0261 - acc: 0.9923 - val_loss: 0.2033 - val_acc: 0.9534\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9920\n",
      "Epoch 00048: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0270 - acc: 0.9919 - val_loss: 0.1971 - val_acc: 0.9511\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9934\n",
      "Epoch 00049: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0225 - acc: 0.9934 - val_loss: 0.1738 - val_acc: 0.9592\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9967\n",
      "Epoch 00050: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0130 - acc: 0.9967 - val_loss: 0.1938 - val_acc: 0.9534\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9946\n",
      "Epoch 00051: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0188 - acc: 0.9945 - val_loss: 0.1794 - val_acc: 0.9583\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9933\n",
      "Epoch 00052: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0230 - acc: 0.9932 - val_loss: 0.1899 - val_acc: 0.9548\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9954\n",
      "Epoch 00053: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0165 - acc: 0.9954 - val_loss: 0.1898 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9974\n",
      "Epoch 00054: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0103 - acc: 0.9974 - val_loss: 0.1762 - val_acc: 0.9592\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9912\n",
      "Epoch 00055: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0278 - acc: 0.9911 - val_loss: 0.1752 - val_acc: 0.9588\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9921\n",
      "Epoch 00056: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0255 - acc: 0.9921 - val_loss: 0.1728 - val_acc: 0.9590\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9960\n",
      "Epoch 00057: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0148 - acc: 0.9960 - val_loss: 0.1822 - val_acc: 0.9557\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9944\n",
      "Epoch 00058: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0195 - acc: 0.9943 - val_loss: 0.1938 - val_acc: 0.9515\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9944\n",
      "Epoch 00059: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0196 - acc: 0.9944 - val_loss: 0.1773 - val_acc: 0.9574\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9973\n",
      "Epoch 00060: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0112 - acc: 0.9973 - val_loss: 0.1894 - val_acc: 0.9588\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9977\n",
      "Epoch 00061: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0096 - acc: 0.9976 - val_loss: 0.1983 - val_acc: 0.9550\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9927\n",
      "Epoch 00062: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0248 - acc: 0.9926 - val_loss: 0.1837 - val_acc: 0.9574\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9954\n",
      "Epoch 00063: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0157 - acc: 0.9954 - val_loss: 0.2066 - val_acc: 0.9543\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9961\n",
      "Epoch 00064: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0145 - acc: 0.9960 - val_loss: 0.1964 - val_acc: 0.9571\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9929\n",
      "Epoch 00065: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0227 - acc: 0.9929 - val_loss: 0.1774 - val_acc: 0.9562\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9977\n",
      "Epoch 00066: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0089 - acc: 0.9977 - val_loss: 0.1967 - val_acc: 0.9550\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9928\n",
      "Epoch 00067: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0231 - acc: 0.9927 - val_loss: 0.1784 - val_acc: 0.9595\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9956\n",
      "Epoch 00068: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0158 - acc: 0.9955 - val_loss: 0.1826 - val_acc: 0.9560\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9946\n",
      "Epoch 00069: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0183 - acc: 0.9946 - val_loss: 0.1768 - val_acc: 0.9590\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9951\n",
      "Epoch 00070: val_loss did not improve from 0.16459\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0177 - acc: 0.9950 - val_loss: 0.1987 - val_acc: 0.9548\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.2108 - acc: 0.9387\n",
      "Loss: 0.2108305070166276 Accuracy: 0.9387331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_conv_3_VGG_he-uniform_BN'\n",
    "\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_BN(conv_num=i)\n",
    "        \n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "    \n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_90_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 16000, 1)     0           conv1d_90_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16000, 1)     0           conv1d_90_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 16)           2338128     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Concatenate)           (None, 16)           0           sequential_9[1][0]               \n",
      "                                                                 sequential_9[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,338,128\n",
      "Trainable params: 2,109,904\n",
      "Non-trainable params: 228,224\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 2.0421 - acc: 0.5047\n",
      "Loss: 2.0421048491914697 Accuracy: 0.5046729\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_96_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16000, 1)     0           conv1d_96_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16000, 1)     0           conv1d_96_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 16)           846544      lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Concatenate)          (None, 16)           0           sequential_10[1][0]              \n",
      "                                                                 sequential_10[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 846,544\n",
      "Trainable params: 769,744\n",
      "Non-trainable params: 76,800\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 1.3333 - acc: 0.6442\n",
      "Loss: 1.333261698552505 Accuracy: 0.64423674\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_104_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 16000, 1)     0           conv1d_104_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16000, 1)     0           conv1d_104_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 16)           668112      lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Concatenate)          (None, 16)           0           sequential_11[1][0]              \n",
      "                                                                 sequential_11[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 668,112\n",
      "Trainable params: 616,144\n",
      "Non-trainable params: 51,968\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 1.0375 - acc: 0.6947\n",
      "Loss: 1.0374559034563422 Accuracy: 0.69470406\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_114_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16000, 1)     0           conv1d_114_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 16000, 1)     0           conv1d_114_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 16)           429776      lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Concatenate)          (None, 16)           0           sequential_12[1][0]              \n",
      "                                                                 sequential_12[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 429,776\n",
      "Trainable params: 411,088\n",
      "Non-trainable params: 18,688\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.6110 - acc: 0.8368\n",
      "Loss: 0.6109846885825738 Accuracy: 0.8367601\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_126_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 16000, 1)     0           conv1d_126_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 16000, 1)     0           conv1d_126_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 16)           416720      lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Concatenate)          (None, 16)           0           sequential_13[1][0]              \n",
      "                                                                 sequential_13[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 416,720\n",
      "Trainable params: 408,784\n",
      "Non-trainable params: 7,936\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.3086 - acc: 0.9178\n",
      "Loss: 0.30864812238596434 Accuracy: 0.91775703\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_140_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 16000, 1)     0           conv1d_140_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 16000, 1)     0           conv1d_140_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_14 (Sequential)      (None, 16)           480464      lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Concatenate)          (None, 16)           0           sequential_14[1][0]              \n",
      "                                                                 sequential_14[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 480,464\n",
      "Trainable params: 475,600\n",
      "Non-trainable params: 4,864\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 3ms/sample - loss: 0.2257 - acc: 0.9398\n",
      "Loss: 0.22574864176188056 Accuracy: 0.93977153\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_156_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 16000, 1)     0           conv1d_156_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 16000, 1)     0           conv1d_156_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_15 (Sequential)      (None, 16)           770256      lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Concatenate)          (None, 16)           0           sequential_15[1][0]              \n",
      "                                                                 sequential_15[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 770,256\n",
      "Trainable params: 765,136\n",
      "Non-trainable params: 5,120\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.2108 - acc: 0.9387\n",
      "Loss: 0.2108305070166276 Accuracy: 0.9387331\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_he-uniform_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_90_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 16000, 1)     0           conv1d_90_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16000, 1)     0           conv1d_90_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 16)           2338128     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Concatenate)           (None, 16)           0           sequential_9[1][0]               \n",
      "                                                                 sequential_9[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,338,128\n",
      "Trainable params: 2,109,904\n",
      "Non-trainable params: 228,224\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 4.3983 - acc: 0.5148\n",
      "Loss: 4.39828358241207 Accuracy: 0.5148494\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_96_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16000, 1)     0           conv1d_96_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16000, 1)     0           conv1d_96_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 16)           846544      lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Concatenate)          (None, 16)           0           sequential_10[1][0]              \n",
      "                                                                 sequential_10[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 846,544\n",
      "Trainable params: 769,744\n",
      "Non-trainable params: 76,800\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 3ms/sample - loss: 2.2056 - acc: 0.6397\n",
      "Loss: 2.2055781162416452 Accuracy: 0.6396677\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_104_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 16000, 1)     0           conv1d_104_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16000, 1)     0           conv1d_104_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 16)           668112      lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Concatenate)          (None, 16)           0           sequential_11[1][0]              \n",
      "                                                                 sequential_11[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 668,112\n",
      "Trainable params: 616,144\n",
      "Non-trainable params: 51,968\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 1.6535 - acc: 0.6999\n",
      "Loss: 1.6535161700946892 Accuracy: 0.69989616\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_114_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16000, 1)     0           conv1d_114_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 16000, 1)     0           conv1d_114_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 16)           429776      lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Concatenate)          (None, 16)           0           sequential_12[1][0]              \n",
      "                                                                 sequential_12[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 429,776\n",
      "Trainable params: 411,088\n",
      "Non-trainable params: 18,688\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.7762 - acc: 0.8401\n",
      "Loss: 0.7762258824343994 Accuracy: 0.84008306\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_126_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 16000, 1)     0           conv1d_126_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 16000, 1)     0           conv1d_126_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 16)           416720      lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Concatenate)          (None, 16)           0           sequential_13[1][0]              \n",
      "                                                                 sequential_13[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 416,720\n",
      "Trainable params: 408,784\n",
      "Non-trainable params: 7,936\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 14s 3ms/sample - loss: 0.3292 - acc: 0.9196\n",
      "Loss: 0.3291866436121001 Accuracy: 0.9196262\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_140_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 16000, 1)     0           conv1d_140_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 16000, 1)     0           conv1d_140_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_14 (Sequential)      (None, 16)           480464      lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Concatenate)          (None, 16)           0           sequential_14[1][0]              \n",
      "                                                                 sequential_14[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 480,464\n",
      "Trainable params: 475,600\n",
      "Non-trainable params: 4,864\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 14s 3ms/sample - loss: 0.2268 - acc: 0.9506\n",
      "Loss: 0.22682516525406682 Accuracy: 0.9505711\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_he-uniform_BN_9_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_156_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 16000, 1)     0           conv1d_156_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 16000, 1)     0           conv1d_156_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_15 (Sequential)      (None, 16)           770256      lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Concatenate)          (None, 16)           0           sequential_15[1][0]              \n",
      "                                                                 sequential_15[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 770,256\n",
      "Trainable params: 765,136\n",
      "Non-trainable params: 5,120\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 14s 3ms/sample - loss: 0.2246 - acc: 0.9450\n",
      "Loss: 0.2245732779959884 Accuracy: 0.94496363\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
