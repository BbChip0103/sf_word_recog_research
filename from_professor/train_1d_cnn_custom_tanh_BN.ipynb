{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_BN_2(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, \n",
    "                      padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())    \n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,480,656\n",
      "Trainable params: 18,432,528\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 6,847,696\n",
      "Trainable params: 6,164,816\n",
      "Non-trainable params: 682,880\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,316,816\n",
      "Trainable params: 2,088,976\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 820,816\n",
      "Trainable params: 744,528\n",
      "Non-trainable params: 76,288\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 608,976\n",
      "Trainable params: 557,776\n",
      "Non-trainable params: 51,200\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 353,616\n",
      "Trainable params: 335,952\n",
      "Non-trainable params: 17,664\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 323,536\n",
      "Trainable params: 316,880\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 370,256\n",
      "Trainable params: 366,928\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 527,696\n",
      "Trainable params: 524,624\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_BN_2(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 12.4819 - acc: 0.1001\n",
      "Epoch 00001: val_loss improved from inf to 11.91867, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_1_conv_checkpoint/001-11.9187.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 12.4817 - acc: 0.1001 - val_loss: 11.9187 - val_acc: 0.1020\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 10.8724 - acc: 0.2380\n",
      "Epoch 00002: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 10.8730 - acc: 0.2380 - val_loss: 13.2146 - val_acc: 0.1076\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.9487 - acc: 0.3188\n",
      "Epoch 00003: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 9.9483 - acc: 0.3188 - val_loss: 13.4207 - val_acc: 0.1092\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.4428 - acc: 0.3608\n",
      "Epoch 00004: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 9.4424 - acc: 0.3608 - val_loss: 13.4729 - val_acc: 0.1104\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.0700 - acc: 0.3930\n",
      "Epoch 00005: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 9.0701 - acc: 0.3930 - val_loss: 13.4840 - val_acc: 0.1141\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.8154 - acc: 0.4158\n",
      "Epoch 00006: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 8.8155 - acc: 0.4158 - val_loss: 13.6320 - val_acc: 0.1081\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.6452 - acc: 0.4276\n",
      "Epoch 00007: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 8.6452 - acc: 0.4276 - val_loss: 13.5225 - val_acc: 0.1186\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.5026 - acc: 0.4406\n",
      "Epoch 00008: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 8.5037 - acc: 0.4405 - val_loss: 13.7210 - val_acc: 0.1118\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.3710 - acc: 0.4533\n",
      "Epoch 00009: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 8.3707 - acc: 0.4533 - val_loss: 13.5893 - val_acc: 0.1195\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.2411 - acc: 0.4630\n",
      "Epoch 00010: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 8.2416 - acc: 0.4629 - val_loss: 13.5456 - val_acc: 0.1251\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.1325 - acc: 0.4702\n",
      "Epoch 00011: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 8.1323 - acc: 0.4702 - val_loss: 13.7612 - val_acc: 0.1167\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.0286 - acc: 0.4793\n",
      "Epoch 00012: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 8.0296 - acc: 0.4792 - val_loss: 13.7116 - val_acc: 0.1242\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.9386 - acc: 0.4876\n",
      "Epoch 00013: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.9391 - acc: 0.4875 - val_loss: 13.5588 - val_acc: 0.1314\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.8247 - acc: 0.4951\n",
      "Epoch 00014: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.8245 - acc: 0.4951 - val_loss: 13.4906 - val_acc: 0.1358\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.7245 - acc: 0.5023\n",
      "Epoch 00015: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.7256 - acc: 0.5023 - val_loss: 13.4302 - val_acc: 0.1372\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.6525 - acc: 0.5075\n",
      "Epoch 00016: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.6532 - acc: 0.5074 - val_loss: 13.4471 - val_acc: 0.1419\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.5759 - acc: 0.5116\n",
      "Epoch 00017: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.5753 - acc: 0.5116 - val_loss: 13.3363 - val_acc: 0.1470\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.4487 - acc: 0.5213\n",
      "Epoch 00018: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.4481 - acc: 0.5213 - val_loss: 13.3527 - val_acc: 0.1461\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.3629 - acc: 0.5272\n",
      "Epoch 00019: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.3628 - acc: 0.5272 - val_loss: 13.1303 - val_acc: 0.1631\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.2770 - acc: 0.5330\n",
      "Epoch 00020: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.2781 - acc: 0.5329 - val_loss: 13.5863 - val_acc: 0.1381\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.2232 - acc: 0.5372\n",
      "Epoch 00021: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.2234 - acc: 0.5372 - val_loss: 13.1751 - val_acc: 0.1577\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.1811 - acc: 0.5404\n",
      "Epoch 00022: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.1814 - acc: 0.5404 - val_loss: 13.1050 - val_acc: 0.1638\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.1183 - acc: 0.5458\n",
      "Epoch 00023: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.1191 - acc: 0.5457 - val_loss: 13.1182 - val_acc: 0.1631\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.0722 - acc: 0.5474\n",
      "Epoch 00024: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 7.0721 - acc: 0.5474 - val_loss: 13.1515 - val_acc: 0.1617\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.9695 - acc: 0.5551\n",
      "Epoch 00025: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.9694 - acc: 0.5551 - val_loss: 12.9785 - val_acc: 0.1745\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.9432 - acc: 0.5560\n",
      "Epoch 00026: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 6.9440 - acc: 0.5560 - val_loss: 13.3656 - val_acc: 0.1537\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.8993 - acc: 0.5596\n",
      "Epoch 00027: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.8996 - acc: 0.5595 - val_loss: 13.2223 - val_acc: 0.1638\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.8350 - acc: 0.5641\n",
      "Epoch 00028: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 6.8349 - acc: 0.5641 - val_loss: 13.1278 - val_acc: 0.1656\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.7847 - acc: 0.5685\n",
      "Epoch 00029: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.7851 - acc: 0.5685 - val_loss: 13.0238 - val_acc: 0.1689\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.7168 - acc: 0.5732\n",
      "Epoch 00030: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 6.7181 - acc: 0.5731 - val_loss: 13.4514 - val_acc: 0.1502\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.6532 - acc: 0.5774\n",
      "Epoch 00031: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.6540 - acc: 0.5773 - val_loss: 13.1132 - val_acc: 0.1703\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.6409 - acc: 0.5778\n",
      "Epoch 00032: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 6.6413 - acc: 0.5778 - val_loss: 13.0827 - val_acc: 0.1684\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.5837 - acc: 0.5824\n",
      "Epoch 00033: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.5833 - acc: 0.5825 - val_loss: 13.2707 - val_acc: 0.1626\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.5584 - acc: 0.5829\n",
      "Epoch 00034: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.5584 - acc: 0.5829 - val_loss: 12.9635 - val_acc: 0.1763\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.5690 - acc: 0.5828\n",
      "Epoch 00035: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.5691 - acc: 0.5828 - val_loss: 13.3196 - val_acc: 0.1551\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.5240 - acc: 0.5858\n",
      "Epoch 00036: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.5244 - acc: 0.5858 - val_loss: 13.0036 - val_acc: 0.1766\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.4788 - acc: 0.5888\n",
      "Epoch 00037: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.4784 - acc: 0.5888 - val_loss: 12.9707 - val_acc: 0.1801\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.4663 - acc: 0.5900\n",
      "Epoch 00038: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.4667 - acc: 0.5899 - val_loss: 12.8111 - val_acc: 0.1880\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.4260 - acc: 0.5929\n",
      "Epoch 00039: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.4256 - acc: 0.5929 - val_loss: 12.9542 - val_acc: 0.1773\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.3860 - acc: 0.5955\n",
      "Epoch 00040: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.3856 - acc: 0.5956 - val_loss: 12.7331 - val_acc: 0.1952\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.3516 - acc: 0.5970\n",
      "Epoch 00041: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.3521 - acc: 0.5970 - val_loss: 13.2150 - val_acc: 0.1649\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.3249 - acc: 0.5992\n",
      "Epoch 00042: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.3250 - acc: 0.5992 - val_loss: 12.8360 - val_acc: 0.1863\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.3146 - acc: 0.6006\n",
      "Epoch 00043: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.3150 - acc: 0.6006 - val_loss: 12.8434 - val_acc: 0.1877\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.2388 - acc: 0.6057\n",
      "Epoch 00044: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.2393 - acc: 0.6057 - val_loss: 12.7745 - val_acc: 0.1929\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.2306 - acc: 0.6060\n",
      "Epoch 00045: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.2315 - acc: 0.6059 - val_loss: 12.8673 - val_acc: 0.1840\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.1740 - acc: 0.6103\n",
      "Epoch 00046: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.1741 - acc: 0.6103 - val_loss: 12.8905 - val_acc: 0.1824\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.1775 - acc: 0.6092\n",
      "Epoch 00047: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 6.1771 - acc: 0.6093 - val_loss: 12.8217 - val_acc: 0.1873\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.1339 - acc: 0.6125\n",
      "Epoch 00048: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.1339 - acc: 0.6125 - val_loss: 12.6608 - val_acc: 0.1966\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.1272 - acc: 0.6132\n",
      "Epoch 00049: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 6.1272 - acc: 0.6132 - val_loss: 12.8360 - val_acc: 0.1891\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.0761 - acc: 0.6158\n",
      "Epoch 00050: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 6.0761 - acc: 0.6158 - val_loss: 12.7485 - val_acc: 0.1926\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.0775 - acc: 0.6158\n",
      "Epoch 00051: val_loss did not improve from 11.91867\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.0772 - acc: 0.6158 - val_loss: 12.5313 - val_acc: 0.2073\n",
      "\n",
      "1D_CNN_custom_tanh_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 562us/sample - loss: 11.9385 - acc: 0.0976\n",
      "Loss: 11.93846916642392 Accuracy: 0.09761163\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.2808 - acc: 0.2287\n",
      "Epoch 00001: val_loss improved from inf to 5.80252, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_2_conv_checkpoint/001-5.8025.hdf5\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 5.2814 - acc: 0.2287 - val_loss: 5.8025 - val_acc: 0.2416\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.6279 - acc: 0.4417\n",
      "Epoch 00002: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 3.6283 - acc: 0.4417 - val_loss: 6.1157 - val_acc: 0.2835\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5722 - acc: 0.5854\n",
      "Epoch 00003: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 2.5723 - acc: 0.5854 - val_loss: 5.8624 - val_acc: 0.3107\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8112 - acc: 0.6996\n",
      "Epoch 00004: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.8111 - acc: 0.6996 - val_loss: 8.4770 - val_acc: 0.2518\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3977 - acc: 0.7695\n",
      "Epoch 00005: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.3976 - acc: 0.7695 - val_loss: 6.1649 - val_acc: 0.3506\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1575 - acc: 0.8155\n",
      "Epoch 00006: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.1579 - acc: 0.8155 - val_loss: 8.2975 - val_acc: 0.2823\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0266 - acc: 0.8387\n",
      "Epoch 00007: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.0269 - acc: 0.8386 - val_loss: 7.1354 - val_acc: 0.3387\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9837 - acc: 0.8514\n",
      "Epoch 00008: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.9840 - acc: 0.8514 - val_loss: 7.0971 - val_acc: 0.3371\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9138 - acc: 0.8666\n",
      "Epoch 00009: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.9137 - acc: 0.8666 - val_loss: 8.6411 - val_acc: 0.2725\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7908 - acc: 0.8912\n",
      "Epoch 00010: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.7907 - acc: 0.8912 - val_loss: 8.4352 - val_acc: 0.2891\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8015 - acc: 0.8912\n",
      "Epoch 00011: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.8016 - acc: 0.8912 - val_loss: 7.9121 - val_acc: 0.3457\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7894 - acc: 0.8963\n",
      "Epoch 00012: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.7899 - acc: 0.8963 - val_loss: 7.3143 - val_acc: 0.3788\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7415 - acc: 0.9047\n",
      "Epoch 00013: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.7422 - acc: 0.9047 - val_loss: 8.6287 - val_acc: 0.3212\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7427 - acc: 0.9063\n",
      "Epoch 00014: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.7427 - acc: 0.9063 - val_loss: 8.0353 - val_acc: 0.3562\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6988 - acc: 0.9161\n",
      "Epoch 00015: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.6987 - acc: 0.9161 - val_loss: 8.1776 - val_acc: 0.3508\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6321 - acc: 0.9243\n",
      "Epoch 00016: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.6324 - acc: 0.9242 - val_loss: 8.9545 - val_acc: 0.3242\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6545 - acc: 0.9222\n",
      "Epoch 00017: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.6551 - acc: 0.9222 - val_loss: 8.8653 - val_acc: 0.3280\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6835 - acc: 0.9204\n",
      "Epoch 00018: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.6835 - acc: 0.9204 - val_loss: 8.3677 - val_acc: 0.3631\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6379 - acc: 0.9279\n",
      "Epoch 00019: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.6380 - acc: 0.9279 - val_loss: 9.7307 - val_acc: 0.2905\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6011 - acc: 0.9333\n",
      "Epoch 00020: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.6015 - acc: 0.9332 - val_loss: 9.2760 - val_acc: 0.3168\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5619 - acc: 0.9383\n",
      "Epoch 00021: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5621 - acc: 0.9383 - val_loss: 8.7996 - val_acc: 0.3378\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5954 - acc: 0.9346\n",
      "Epoch 00022: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5955 - acc: 0.9346 - val_loss: 8.3730 - val_acc: 0.3631\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5832 - acc: 0.9374\n",
      "Epoch 00023: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5831 - acc: 0.9374 - val_loss: 9.3321 - val_acc: 0.3173\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5665 - acc: 0.9386\n",
      "Epoch 00024: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5668 - acc: 0.9386 - val_loss: 8.6434 - val_acc: 0.3652\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5807 - acc: 0.9384\n",
      "Epoch 00025: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5813 - acc: 0.9383 - val_loss: 8.4166 - val_acc: 0.3708\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5661 - acc: 0.9406\n",
      "Epoch 00026: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5666 - acc: 0.9405 - val_loss: 8.6447 - val_acc: 0.3543\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5446 - acc: 0.9446\n",
      "Epoch 00027: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5449 - acc: 0.9446 - val_loss: 9.3858 - val_acc: 0.3280\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5771 - acc: 0.9408\n",
      "Epoch 00028: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5775 - acc: 0.9407 - val_loss: 8.2915 - val_acc: 0.3932\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5396 - acc: 0.9458\n",
      "Epoch 00029: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5404 - acc: 0.9458 - val_loss: 8.1228 - val_acc: 0.3944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4952 - acc: 0.9513\n",
      "Epoch 00030: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4969 - acc: 0.9512 - val_loss: 8.1856 - val_acc: 0.4032\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5106 - acc: 0.9514\n",
      "Epoch 00031: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5105 - acc: 0.9514 - val_loss: 8.8245 - val_acc: 0.3636\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4745 - acc: 0.9538\n",
      "Epoch 00032: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4744 - acc: 0.9538 - val_loss: 8.3205 - val_acc: 0.3823\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5008 - acc: 0.9514\n",
      "Epoch 00033: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5016 - acc: 0.9513 - val_loss: 10.2984 - val_acc: 0.2805\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4966 - acc: 0.9529\n",
      "Epoch 00034: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4978 - acc: 0.9528 - val_loss: 9.0554 - val_acc: 0.3410\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5410 - acc: 0.9477\n",
      "Epoch 00035: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5410 - acc: 0.9478 - val_loss: 8.4432 - val_acc: 0.3832\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4919 - acc: 0.9533\n",
      "Epoch 00036: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4921 - acc: 0.9533 - val_loss: 9.9919 - val_acc: 0.3024\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4697 - acc: 0.9551\n",
      "Epoch 00037: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4696 - acc: 0.9551 - val_loss: 9.3034 - val_acc: 0.3538\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.9558\n",
      "Epoch 00038: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4693 - acc: 0.9558 - val_loss: 9.2172 - val_acc: 0.3415\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4785 - acc: 0.9563\n",
      "Epoch 00039: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4785 - acc: 0.9563 - val_loss: 8.2773 - val_acc: 0.4065\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4637 - acc: 0.9577\n",
      "Epoch 00040: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4637 - acc: 0.9577 - val_loss: 8.9732 - val_acc: 0.3713\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4495 - acc: 0.9590\n",
      "Epoch 00041: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4495 - acc: 0.9591 - val_loss: 9.4250 - val_acc: 0.3461\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4372 - acc: 0.9600\n",
      "Epoch 00042: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4372 - acc: 0.9600 - val_loss: 9.5564 - val_acc: 0.3399\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4492 - acc: 0.9590\n",
      "Epoch 00043: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4491 - acc: 0.9591 - val_loss: 9.1439 - val_acc: 0.3590\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4284 - acc: 0.9617\n",
      "Epoch 00044: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4284 - acc: 0.9617 - val_loss: 9.2577 - val_acc: 0.3548\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4770 - acc: 0.9569\n",
      "Epoch 00045: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4778 - acc: 0.9569 - val_loss: 8.9261 - val_acc: 0.3764\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4809 - acc: 0.9559\n",
      "Epoch 00046: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4812 - acc: 0.9559 - val_loss: 8.7227 - val_acc: 0.3855\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4451 - acc: 0.9601\n",
      "Epoch 00047: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4450 - acc: 0.9601 - val_loss: 9.2217 - val_acc: 0.3620\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4232 - acc: 0.9634\n",
      "Epoch 00048: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4240 - acc: 0.9633 - val_loss: 8.3854 - val_acc: 0.4027\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4327 - acc: 0.9626\n",
      "Epoch 00049: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4331 - acc: 0.9625 - val_loss: 10.0105 - val_acc: 0.3277\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4388 - acc: 0.9622\n",
      "Epoch 00050: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4388 - acc: 0.9622 - val_loss: 9.3352 - val_acc: 0.3608\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.9602\n",
      "Epoch 00051: val_loss did not improve from 5.80252\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4618 - acc: 0.9602 - val_loss: 9.1743 - val_acc: 0.3625\n",
      "\n",
      "1D_CNN_custom_tanh_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 756us/sample - loss: 5.7383 - acc: 0.2517\n",
      "Loss: 5.738269213798262 Accuracy: 0.2517134\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5055 - acc: 0.3839\n",
      "Epoch 00001: val_loss improved from inf to 2.79580, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_3_conv_checkpoint/001-2.7958.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 2.5056 - acc: 0.3839 - val_loss: 2.7958 - val_acc: 0.3757\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1748 - acc: 0.6809\n",
      "Epoch 00002: val_loss did not improve from 2.79580\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 1.1748 - acc: 0.6809 - val_loss: 2.9568 - val_acc: 0.3927\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5607 - acc: 0.8490\n",
      "Epoch 00003: val_loss improved from 2.79580 to 2.45399, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_3_conv_checkpoint/003-2.4540.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.5609 - acc: 0.8490 - val_loss: 2.4540 - val_acc: 0.4868\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3297 - acc: 0.9242\n",
      "Epoch 00004: val_loss improved from 2.45399 to 2.08229, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_3_conv_checkpoint/004-2.0823.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.3298 - acc: 0.9242 - val_loss: 2.0823 - val_acc: 0.5453\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2251 - acc: 0.9552\n",
      "Epoch 00005: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.2251 - acc: 0.9552 - val_loss: 2.4325 - val_acc: 0.5232\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9709\n",
      "Epoch 00006: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1669 - acc: 0.9708 - val_loss: 2.2898 - val_acc: 0.5367\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9713\n",
      "Epoch 00007: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1535 - acc: 0.9713 - val_loss: 2.8603 - val_acc: 0.4955\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9699\n",
      "Epoch 00008: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1579 - acc: 0.9698 - val_loss: 2.8370 - val_acc: 0.4969\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1544 - acc: 0.9668\n",
      "Epoch 00009: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1544 - acc: 0.9668 - val_loss: 3.1477 - val_acc: 0.4864\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9755\n",
      "Epoch 00010: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1217 - acc: 0.9755 - val_loss: 3.3527 - val_acc: 0.4810\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9782\n",
      "Epoch 00011: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1088 - acc: 0.9781 - val_loss: 3.4929 - val_acc: 0.4745\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9688\n",
      "Epoch 00012: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1395 - acc: 0.9688 - val_loss: 3.5081 - val_acc: 0.4962\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9840\n",
      "Epoch 00013: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0859 - acc: 0.9840 - val_loss: 3.7480 - val_acc: 0.4836\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9799\n",
      "Epoch 00014: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0964 - acc: 0.9799 - val_loss: 4.0452 - val_acc: 0.4717\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9828\n",
      "Epoch 00015: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0860 - acc: 0.9828 - val_loss: 3.3475 - val_acc: 0.5111\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9817\n",
      "Epoch 00016: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0833 - acc: 0.9817 - val_loss: 4.3398 - val_acc: 0.4603\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9823\n",
      "Epoch 00017: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0853 - acc: 0.9823 - val_loss: 5.0419 - val_acc: 0.3890\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9811\n",
      "Epoch 00018: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0814 - acc: 0.9811 - val_loss: 4.5889 - val_acc: 0.4356\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9853\n",
      "Epoch 00019: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0757 - acc: 0.9853 - val_loss: 7.1573 - val_acc: 0.3427\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9840\n",
      "Epoch 00020: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0790 - acc: 0.9840 - val_loss: 4.0159 - val_acc: 0.4920\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9852\n",
      "Epoch 00021: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0707 - acc: 0.9852 - val_loss: 4.0804 - val_acc: 0.4864\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9873\n",
      "Epoch 00022: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0597 - acc: 0.9873 - val_loss: 4.2249 - val_acc: 0.4782\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9863\n",
      "Epoch 00023: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0646 - acc: 0.9863 - val_loss: 4.3253 - val_acc: 0.4822\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9878\n",
      "Epoch 00024: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0625 - acc: 0.9878 - val_loss: 4.3863 - val_acc: 0.4831\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9810\n",
      "Epoch 00025: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0916 - acc: 0.9810 - val_loss: 3.9707 - val_acc: 0.5174\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9846\n",
      "Epoch 00026: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0763 - acc: 0.9846 - val_loss: 4.6076 - val_acc: 0.4701\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9880\n",
      "Epoch 00027: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0606 - acc: 0.9880 - val_loss: 4.2266 - val_acc: 0.5050\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9862\n",
      "Epoch 00028: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0704 - acc: 0.9862 - val_loss: 3.9705 - val_acc: 0.5255\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9841\n",
      "Epoch 00029: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0788 - acc: 0.9841 - val_loss: 4.1735 - val_acc: 0.5064\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9904\n",
      "Epoch 00030: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0524 - acc: 0.9904 - val_loss: 4.1048 - val_acc: 0.5246\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9889\n",
      "Epoch 00031: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0657 - acc: 0.9889 - val_loss: 4.3494 - val_acc: 0.4896\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9868\n",
      "Epoch 00032: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0707 - acc: 0.9868 - val_loss: 7.1497 - val_acc: 0.3492\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9750\n",
      "Epoch 00033: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1259 - acc: 0.9750 - val_loss: 4.5062 - val_acc: 0.4936\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9931\n",
      "Epoch 00034: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0448 - acc: 0.9930 - val_loss: 4.1603 - val_acc: 0.5195\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9753\n",
      "Epoch 00035: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1273 - acc: 0.9753 - val_loss: 4.1017 - val_acc: 0.5297\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9921\n",
      "Epoch 00036: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0530 - acc: 0.9921 - val_loss: 4.2747 - val_acc: 0.5302\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9935\n",
      "Epoch 00037: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0467 - acc: 0.9934 - val_loss: 4.2563 - val_acc: 0.5199\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9913\n",
      "Epoch 00038: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0508 - acc: 0.9913 - val_loss: 4.2270 - val_acc: 0.5332\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9904\n",
      "Epoch 00039: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0578 - acc: 0.9904 - val_loss: 4.6540 - val_acc: 0.4903\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9869\n",
      "Epoch 00040: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0684 - acc: 0.9869 - val_loss: 4.8042 - val_acc: 0.4973\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9927\n",
      "Epoch 00041: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0474 - acc: 0.9927 - val_loss: 4.6257 - val_acc: 0.5073\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9899\n",
      "Epoch 00042: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0628 - acc: 0.9898 - val_loss: 4.3971 - val_acc: 0.5204\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9823\n",
      "Epoch 00043: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0956 - acc: 0.9822 - val_loss: 4.7254 - val_acc: 0.4980\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9892\n",
      "Epoch 00044: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0609 - acc: 0.9892 - val_loss: 4.6491 - val_acc: 0.5120\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9908\n",
      "Epoch 00045: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0557 - acc: 0.9908 - val_loss: 4.7294 - val_acc: 0.5190\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9916\n",
      "Epoch 00046: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0514 - acc: 0.9915 - val_loss: 4.5527 - val_acc: 0.5206\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9886\n",
      "Epoch 00047: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0595 - acc: 0.9885 - val_loss: 4.5660 - val_acc: 0.5208\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9924\n",
      "Epoch 00048: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0459 - acc: 0.9924 - val_loss: 4.5184 - val_acc: 0.5250\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9935\n",
      "Epoch 00049: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0441 - acc: 0.9935 - val_loss: 4.5736 - val_acc: 0.5309\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9917\n",
      "Epoch 00050: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0507 - acc: 0.9917 - val_loss: 4.6237 - val_acc: 0.5195\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9917\n",
      "Epoch 00051: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0487 - acc: 0.9917 - val_loss: 4.5071 - val_acc: 0.5302\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9871\n",
      "Epoch 00052: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0749 - acc: 0.9871 - val_loss: 5.0132 - val_acc: 0.5022\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9927\n",
      "Epoch 00053: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0498 - acc: 0.9927 - val_loss: 4.6538 - val_acc: 0.5327\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9935\n",
      "Epoch 00054: val_loss did not improve from 2.08229\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0457 - acc: 0.9935 - val_loss: 4.4733 - val_acc: 0.5344\n",
      "\n",
      "1D_CNN_custom_tanh_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 868us/sample - loss: 2.3179 - acc: 0.5076\n",
      "Loss: 2.3179046772969722 Accuracy: 0.50758046\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9368 - acc: 0.4386\n",
      "Epoch 00001: val_loss improved from inf to 1.68692, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_4_conv_checkpoint/001-1.6869.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.9369 - acc: 0.4386 - val_loss: 1.6869 - val_acc: 0.4955\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1744 - acc: 0.6508\n",
      "Epoch 00002: val_loss improved from 1.68692 to 1.68286, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_4_conv_checkpoint/002-1.6829.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.1744 - acc: 0.6508 - val_loss: 1.6829 - val_acc: 0.5497\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8329 - acc: 0.7537\n",
      "Epoch 00003: val_loss did not improve from 1.68286\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.8329 - acc: 0.7537 - val_loss: 1.9832 - val_acc: 0.5183\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5691 - acc: 0.8362\n",
      "Epoch 00004: val_loss did not improve from 1.68286\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5692 - acc: 0.8362 - val_loss: 3.4250 - val_acc: 0.3655\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3914 - acc: 0.8958\n",
      "Epoch 00005: val_loss improved from 1.68286 to 1.67546, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_4_conv_checkpoint/005-1.6755.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3915 - acc: 0.8958 - val_loss: 1.6755 - val_acc: 0.5849\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2818 - acc: 0.9316\n",
      "Epoch 00006: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2819 - acc: 0.9316 - val_loss: 2.3642 - val_acc: 0.4880\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2035 - acc: 0.9610\n",
      "Epoch 00007: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2036 - acc: 0.9609 - val_loss: 2.2876 - val_acc: 0.5015\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1511 - acc: 0.9757\n",
      "Epoch 00008: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1517 - acc: 0.9756 - val_loss: 2.2528 - val_acc: 0.5390\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9650\n",
      "Epoch 00009: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1811 - acc: 0.9649 - val_loss: 1.7529 - val_acc: 0.5858\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9879\n",
      "Epoch 00010: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0971 - acc: 0.9878 - val_loss: 2.0486 - val_acc: 0.5579\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9857\n",
      "Epoch 00011: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0933 - acc: 0.9857 - val_loss: 1.7924 - val_acc: 0.6010\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9793\n",
      "Epoch 00012: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1183 - acc: 0.9793 - val_loss: 1.8191 - val_acc: 0.5952\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9923\n",
      "Epoch 00013: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0623 - acc: 0.9923 - val_loss: 1.8598 - val_acc: 0.6231\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9923\n",
      "Epoch 00014: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0622 - acc: 0.9923 - val_loss: 1.9155 - val_acc: 0.6017\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9966\n",
      "Epoch 00015: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0402 - acc: 0.9966 - val_loss: 2.0200 - val_acc: 0.6021\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9895\n",
      "Epoch 00016: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0691 - acc: 0.9895 - val_loss: 2.7452 - val_acc: 0.5050\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9940\n",
      "Epoch 00017: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0449 - acc: 0.9940 - val_loss: 3.0383 - val_acc: 0.4910\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9880\n",
      "Epoch 00018: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0656 - acc: 0.9880 - val_loss: 2.3795 - val_acc: 0.5602\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9923\n",
      "Epoch 00019: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0443 - acc: 0.9923 - val_loss: 2.0847 - val_acc: 0.5984\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9923\n",
      "Epoch 00020: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0462 - acc: 0.9923 - val_loss: 1.8942 - val_acc: 0.6366\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9924\n",
      "Epoch 00021: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0465 - acc: 0.9924 - val_loss: 1.9657 - val_acc: 0.6138\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9940\n",
      "Epoch 00022: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0391 - acc: 0.9940 - val_loss: 2.0695 - val_acc: 0.6271\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9926\n",
      "Epoch 00023: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0418 - acc: 0.9925 - val_loss: 1.7758 - val_acc: 0.6594\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9948\n",
      "Epoch 00024: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0330 - acc: 0.9947 - val_loss: 1.8688 - val_acc: 0.6431\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9935\n",
      "Epoch 00025: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0369 - acc: 0.9935 - val_loss: 2.0001 - val_acc: 0.6289\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9983\n",
      "Epoch 00026: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0195 - acc: 0.9982 - val_loss: 2.1731 - val_acc: 0.6157\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9886\n",
      "Epoch 00027: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0521 - acc: 0.9886 - val_loss: 1.9608 - val_acc: 0.6352\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9959\n",
      "Epoch 00028: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0298 - acc: 0.9959 - val_loss: 2.5055 - val_acc: 0.5802\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9947\n",
      "Epoch 00029: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0321 - acc: 0.9947 - val_loss: 2.0820 - val_acc: 0.6205\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9953\n",
      "Epoch 00030: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0290 - acc: 0.9953 - val_loss: 2.2228 - val_acc: 0.6122\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9951\n",
      "Epoch 00031: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0319 - acc: 0.9950 - val_loss: 2.5284 - val_acc: 0.5730\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9948\n",
      "Epoch 00032: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0317 - acc: 0.9948 - val_loss: 2.1958 - val_acc: 0.6147\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9989\n",
      "Epoch 00033: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0140 - acc: 0.9989 - val_loss: 2.0276 - val_acc: 0.6455\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9943\n",
      "Epoch 00034: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0345 - acc: 0.9943 - val_loss: 2.2683 - val_acc: 0.6159\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9944\n",
      "Epoch 00035: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0296 - acc: 0.9943 - val_loss: 2.5462 - val_acc: 0.5966\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 00036: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0412 - acc: 0.9917 - val_loss: 2.1325 - val_acc: 0.6250\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9944\n",
      "Epoch 00037: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0287 - acc: 0.9944 - val_loss: 2.1354 - val_acc: 0.6282\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9971\n",
      "Epoch 00038: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0186 - acc: 0.9971 - val_loss: 2.1987 - val_acc: 0.6285\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9947\n",
      "Epoch 00039: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0281 - acc: 0.9947 - val_loss: 2.1266 - val_acc: 0.6378\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9976\n",
      "Epoch 00040: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0170 - acc: 0.9976 - val_loss: 2.5495 - val_acc: 0.6124\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9954\n",
      "Epoch 00041: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0285 - acc: 0.9953 - val_loss: 2.4915 - val_acc: 0.5954\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9931\n",
      "Epoch 00042: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0316 - acc: 0.9931 - val_loss: 2.4861 - val_acc: 0.6012\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9971\n",
      "Epoch 00043: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0183 - acc: 0.9970 - val_loss: 2.3542 - val_acc: 0.6217\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9933\n",
      "Epoch 00044: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0316 - acc: 0.9933 - val_loss: 2.2765 - val_acc: 0.6341\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9986\n",
      "Epoch 00045: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0151 - acc: 0.9985 - val_loss: 2.1832 - val_acc: 0.6445\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9961\n",
      "Epoch 00046: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0232 - acc: 0.9961 - val_loss: 2.4735 - val_acc: 0.6122\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9941\n",
      "Epoch 00047: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0284 - acc: 0.9941 - val_loss: 2.3945 - val_acc: 0.6205\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9988\n",
      "Epoch 00048: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0138 - acc: 0.9988 - val_loss: 2.5412 - val_acc: 0.6010\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9934\n",
      "Epoch 00049: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0308 - acc: 0.9933 - val_loss: 2.4286 - val_acc: 0.6171\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9939\n",
      "Epoch 00050: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0312 - acc: 0.9939 - val_loss: 2.4255 - val_acc: 0.6238\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9955\n",
      "Epoch 00051: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0215 - acc: 0.9955 - val_loss: 2.3135 - val_acc: 0.6371\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9976\n",
      "Epoch 00052: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0175 - acc: 0.9976 - val_loss: 2.5613 - val_acc: 0.6117\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9953\n",
      "Epoch 00053: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0229 - acc: 0.9953 - val_loss: 2.4782 - val_acc: 0.6236\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9982\n",
      "Epoch 00054: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0145 - acc: 0.9982 - val_loss: 2.4798 - val_acc: 0.6210\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9951\n",
      "Epoch 00055: val_loss did not improve from 1.67546\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0259 - acc: 0.9951 - val_loss: 2.3903 - val_acc: 0.6348\n",
      "\n",
      "1D_CNN_custom_tanh_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 904us/sample - loss: 1.7769 - acc: 0.5518\n",
      "Loss: 1.7769245119481072 Accuracy: 0.55181724\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7782 - acc: 0.4775\n",
      "Epoch 00001: val_loss improved from inf to 2.01795, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_5_conv_checkpoint/001-2.0179.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 1.7782 - acc: 0.4775 - val_loss: 2.0179 - val_acc: 0.4384\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1839 - acc: 0.6488\n",
      "Epoch 00002: val_loss did not improve from 2.01795\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.1839 - acc: 0.6488 - val_loss: 2.0855 - val_acc: 0.4556\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9284 - acc: 0.7244\n",
      "Epoch 00003: val_loss improved from 2.01795 to 1.85675, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_5_conv_checkpoint/003-1.8567.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.9286 - acc: 0.7244 - val_loss: 1.8567 - val_acc: 0.4924\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7489 - acc: 0.7760\n",
      "Epoch 00004: val_loss improved from 1.85675 to 1.70519, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_5_conv_checkpoint/004-1.7052.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7489 - acc: 0.7759 - val_loss: 1.7052 - val_acc: 0.5793\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5834 - acc: 0.8284\n",
      "Epoch 00005: val_loss did not improve from 1.70519\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5834 - acc: 0.8283 - val_loss: 2.3143 - val_acc: 0.4768\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4632 - acc: 0.8678\n",
      "Epoch 00006: val_loss did not improve from 1.70519\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4631 - acc: 0.8678 - val_loss: 3.0106 - val_acc: 0.4132\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3589 - acc: 0.9032\n",
      "Epoch 00007: val_loss did not improve from 1.70519\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3590 - acc: 0.9032 - val_loss: 2.9646 - val_acc: 0.4500\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2853 - acc: 0.9286\n",
      "Epoch 00008: val_loss improved from 1.70519 to 1.64505, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_5_conv_checkpoint/008-1.6451.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2854 - acc: 0.9286 - val_loss: 1.6451 - val_acc: 0.6138\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2273 - acc: 0.9453\n",
      "Epoch 00009: val_loss did not improve from 1.64505\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2274 - acc: 0.9453 - val_loss: 3.1423 - val_acc: 0.4004\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1743 - acc: 0.9639\n",
      "Epoch 00010: val_loss improved from 1.64505 to 1.40007, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_5_conv_checkpoint/010-1.4001.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1744 - acc: 0.9639 - val_loss: 1.4001 - val_acc: 0.6506\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9712\n",
      "Epoch 00011: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1478 - acc: 0.9712 - val_loss: 2.1012 - val_acc: 0.5600\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9792\n",
      "Epoch 00012: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1196 - acc: 0.9792 - val_loss: 1.5119 - val_acc: 0.6492\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9786\n",
      "Epoch 00013: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1178 - acc: 0.9786 - val_loss: 1.8675 - val_acc: 0.6096\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9863\n",
      "Epoch 00014: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0872 - acc: 0.9863 - val_loss: 2.0461 - val_acc: 0.5751\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9826\n",
      "Epoch 00015: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0966 - acc: 0.9826 - val_loss: 2.4697 - val_acc: 0.5199\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9888\n",
      "Epoch 00016: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0735 - acc: 0.9888 - val_loss: 1.9705 - val_acc: 0.5772\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9925\n",
      "Epoch 00017: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0568 - acc: 0.9925 - val_loss: 1.6169 - val_acc: 0.6520\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9893\n",
      "Epoch 00018: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0656 - acc: 0.9893 - val_loss: 1.6400 - val_acc: 0.6662\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9865\n",
      "Epoch 00019: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0714 - acc: 0.9864 - val_loss: 3.4488 - val_acc: 0.4442\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9904\n",
      "Epoch 00020: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0575 - acc: 0.9903 - val_loss: 1.8214 - val_acc: 0.6322\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9919\n",
      "Epoch 00021: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0527 - acc: 0.9918 - val_loss: 2.3942 - val_acc: 0.5316\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9907\n",
      "Epoch 00022: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0525 - acc: 0.9907 - val_loss: 1.7495 - val_acc: 0.6473\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9909\n",
      "Epoch 00023: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0536 - acc: 0.9909 - val_loss: 2.1731 - val_acc: 0.6215\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9928\n",
      "Epoch 00024: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0440 - acc: 0.9928 - val_loss: 1.9095 - val_acc: 0.6233\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9931\n",
      "Epoch 00025: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0440 - acc: 0.9931 - val_loss: 2.5132 - val_acc: 0.5535\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9946\n",
      "Epoch 00026: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0365 - acc: 0.9946 - val_loss: 2.4839 - val_acc: 0.5453\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9950\n",
      "Epoch 00027: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0347 - acc: 0.9950 - val_loss: 1.9941 - val_acc: 0.6159\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9916\n",
      "Epoch 00028: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0449 - acc: 0.9916 - val_loss: 2.2765 - val_acc: 0.5968\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9915\n",
      "Epoch 00029: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0461 - acc: 0.9915 - val_loss: 2.1582 - val_acc: 0.5879\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9952\n",
      "Epoch 00030: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0311 - acc: 0.9952 - val_loss: 2.5796 - val_acc: 0.5735\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9956\n",
      "Epoch 00031: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0283 - acc: 0.9956 - val_loss: 1.8705 - val_acc: 0.6585\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9902\n",
      "Epoch 00032: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0455 - acc: 0.9902 - val_loss: 2.3901 - val_acc: 0.5924\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9953\n",
      "Epoch 00033: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0309 - acc: 0.9953 - val_loss: 2.1283 - val_acc: 0.6031\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9963\n",
      "Epoch 00034: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0249 - acc: 0.9963 - val_loss: 1.6778 - val_acc: 0.6813\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9915\n",
      "Epoch 00035: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0426 - acc: 0.9915 - val_loss: 2.0293 - val_acc: 0.6359\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9943\n",
      "Epoch 00036: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0308 - acc: 0.9943 - val_loss: 1.7892 - val_acc: 0.6788\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9937\n",
      "Epoch 00037: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0314 - acc: 0.9938 - val_loss: 1.8663 - val_acc: 0.6669\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9974\n",
      "Epoch 00038: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0203 - acc: 0.9974 - val_loss: 1.6251 - val_acc: 0.6914\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9958\n",
      "Epoch 00039: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0257 - acc: 0.9957 - val_loss: 1.9494 - val_acc: 0.6450\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9916\n",
      "Epoch 00040: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0380 - acc: 0.9916 - val_loss: 2.0496 - val_acc: 0.6296\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9922\n",
      "Epoch 00041: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0365 - acc: 0.9922 - val_loss: 1.8295 - val_acc: 0.6653\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9951\n",
      "Epoch 00042: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0295 - acc: 0.9951 - val_loss: 1.8761 - val_acc: 0.6704\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9985\n",
      "Epoch 00043: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0140 - acc: 0.9985 - val_loss: 1.8042 - val_acc: 0.6790\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9962\n",
      "Epoch 00044: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0238 - acc: 0.9962 - val_loss: 2.3356 - val_acc: 0.6110\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9940\n",
      "Epoch 00045: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0303 - acc: 0.9940 - val_loss: 2.2492 - val_acc: 0.6329\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9965\n",
      "Epoch 00046: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0216 - acc: 0.9965 - val_loss: 2.9322 - val_acc: 0.5511\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9927\n",
      "Epoch 00047: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0334 - acc: 0.9927 - val_loss: 2.2728 - val_acc: 0.6327\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9963\n",
      "Epoch 00048: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0234 - acc: 0.9963 - val_loss: 2.2799 - val_acc: 0.6177\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9931\n",
      "Epoch 00049: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0332 - acc: 0.9930 - val_loss: 2.4486 - val_acc: 0.5959\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9910\n",
      "Epoch 00050: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0393 - acc: 0.9910 - val_loss: 1.8780 - val_acc: 0.6662\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9978\n",
      "Epoch 00051: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0162 - acc: 0.9978 - val_loss: 1.7349 - val_acc: 0.6851\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9989\n",
      "Epoch 00052: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0119 - acc: 0.9989 - val_loss: 2.1060 - val_acc: 0.6555\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9989\n",
      "Epoch 00053: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0125 - acc: 0.9989 - val_loss: 1.8518 - val_acc: 0.6774\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9886\n",
      "Epoch 00054: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0457 - acc: 0.9886 - val_loss: 2.0384 - val_acc: 0.6636\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9965\n",
      "Epoch 00055: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0201 - acc: 0.9965 - val_loss: 2.2023 - val_acc: 0.6357\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9953\n",
      "Epoch 00056: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0259 - acc: 0.9953 - val_loss: 2.1355 - val_acc: 0.6448\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9954\n",
      "Epoch 00057: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0248 - acc: 0.9953 - val_loss: 3.3550 - val_acc: 0.5313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9922\n",
      "Epoch 00058: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0342 - acc: 0.9922 - val_loss: 2.0751 - val_acc: 0.6567\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9961\n",
      "Epoch 00059: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0206 - acc: 0.9961 - val_loss: 1.8618 - val_acc: 0.6851\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9985\n",
      "Epoch 00060: val_loss did not improve from 1.40007\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0124 - acc: 0.9984 - val_loss: 2.1980 - val_acc: 0.6494\n",
      "\n",
      "1D_CNN_custom_tanh_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 950us/sample - loss: 1.5837 - acc: 0.6066\n",
      "Loss: 1.5837259600343239 Accuracy: 0.6066459\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7655 - acc: 0.4645\n",
      "Epoch 00001: val_loss improved from inf to 1.65785, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_6_conv_checkpoint/001-1.6579.hdf5\n",
      "36805/36805 [==============================] - 100s 3ms/sample - loss: 1.7655 - acc: 0.4645 - val_loss: 1.6579 - val_acc: 0.4948\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1922 - acc: 0.6424\n",
      "Epoch 00002: val_loss did not improve from 1.65785\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.1921 - acc: 0.6424 - val_loss: 2.0746 - val_acc: 0.4384\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9790 - acc: 0.7086\n",
      "Epoch 00003: val_loss did not improve from 1.65785\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9791 - acc: 0.7086 - val_loss: 1.6702 - val_acc: 0.5195\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8382 - acc: 0.7521\n",
      "Epoch 00004: val_loss did not improve from 1.65785\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8382 - acc: 0.7521 - val_loss: 1.8748 - val_acc: 0.5099\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7471 - acc: 0.7823\n",
      "Epoch 00005: val_loss did not improve from 1.65785\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7470 - acc: 0.7823 - val_loss: 2.0966 - val_acc: 0.4936\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6593 - acc: 0.8074\n",
      "Epoch 00006: val_loss did not improve from 1.65785\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6593 - acc: 0.8073 - val_loss: 1.7666 - val_acc: 0.5900\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5968 - acc: 0.8262\n",
      "Epoch 00007: val_loss did not improve from 1.65785\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5970 - acc: 0.8262 - val_loss: 1.8172 - val_acc: 0.5439\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5392 - acc: 0.8424\n",
      "Epoch 00008: val_loss did not improve from 1.65785\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5392 - acc: 0.8425 - val_loss: 1.6932 - val_acc: 0.5635\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4755 - acc: 0.8633\n",
      "Epoch 00009: val_loss did not improve from 1.65785\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4756 - acc: 0.8633 - val_loss: 2.0126 - val_acc: 0.5432\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4273 - acc: 0.8783\n",
      "Epoch 00010: val_loss did not improve from 1.65785\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4273 - acc: 0.8782 - val_loss: 3.9209 - val_acc: 0.3520\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3814 - acc: 0.8925\n",
      "Epoch 00011: val_loss did not improve from 1.65785\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3815 - acc: 0.8924 - val_loss: 3.6407 - val_acc: 0.3625\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3387 - acc: 0.9042\n",
      "Epoch 00012: val_loss improved from 1.65785 to 1.35798, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_6_conv_checkpoint/012-1.3580.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3388 - acc: 0.9042 - val_loss: 1.3580 - val_acc: 0.6315\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2952 - acc: 0.9180\n",
      "Epoch 00013: val_loss did not improve from 1.35798\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2952 - acc: 0.9181 - val_loss: 2.4527 - val_acc: 0.4920\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2607 - acc: 0.9312\n",
      "Epoch 00014: val_loss improved from 1.35798 to 1.34767, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_6_conv_checkpoint/014-1.3477.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2607 - acc: 0.9312 - val_loss: 1.3477 - val_acc: 0.6806\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2261 - acc: 0.9427\n",
      "Epoch 00015: val_loss did not improve from 1.34767\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2262 - acc: 0.9427 - val_loss: 3.9189 - val_acc: 0.3729\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2087 - acc: 0.9464\n",
      "Epoch 00016: val_loss did not improve from 1.34767\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2087 - acc: 0.9464 - val_loss: 2.1765 - val_acc: 0.5420\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1812 - acc: 0.9567\n",
      "Epoch 00017: val_loss did not improve from 1.34767\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1813 - acc: 0.9566 - val_loss: 2.8374 - val_acc: 0.4605\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9578\n",
      "Epoch 00018: val_loss did not improve from 1.34767\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1717 - acc: 0.9577 - val_loss: 1.5873 - val_acc: 0.6303\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9670\n",
      "Epoch 00019: val_loss did not improve from 1.34767\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1440 - acc: 0.9670 - val_loss: 2.0177 - val_acc: 0.5870\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9748\n",
      "Epoch 00020: val_loss improved from 1.34767 to 1.26385, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_6_conv_checkpoint/020-1.2639.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1213 - acc: 0.9748 - val_loss: 1.2639 - val_acc: 0.6923\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9777\n",
      "Epoch 00021: val_loss did not improve from 1.26385\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1122 - acc: 0.9777 - val_loss: 2.2973 - val_acc: 0.5381\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9777\n",
      "Epoch 00022: val_loss did not improve from 1.26385\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1064 - acc: 0.9776 - val_loss: 1.3518 - val_acc: 0.6825\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9726\n",
      "Epoch 00023: val_loss did not improve from 1.26385\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1182 - acc: 0.9726 - val_loss: 1.2931 - val_acc: 0.6904\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9854\n",
      "Epoch 00024: val_loss improved from 1.26385 to 1.25770, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_6_conv_checkpoint/024-1.2577.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0823 - acc: 0.9854 - val_loss: 1.2577 - val_acc: 0.6969\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9811\n",
      "Epoch 00025: val_loss improved from 1.25770 to 1.12154, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_6_conv_checkpoint/025-1.1215.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0896 - acc: 0.9811 - val_loss: 1.1215 - val_acc: 0.7314\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9840\n",
      "Epoch 00026: val_loss did not improve from 1.12154\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0804 - acc: 0.9840 - val_loss: 1.1914 - val_acc: 0.7074\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9879\n",
      "Epoch 00027: val_loss did not improve from 1.12154\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0674 - acc: 0.9879 - val_loss: 2.3580 - val_acc: 0.5714\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9889\n",
      "Epoch 00028: val_loss did not improve from 1.12154\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0631 - acc: 0.9888 - val_loss: 1.9846 - val_acc: 0.6040\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9769\n",
      "Epoch 00029: val_loss improved from 1.12154 to 1.09791, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_6_conv_checkpoint/029-1.0979.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0977 - acc: 0.9769 - val_loss: 1.0979 - val_acc: 0.7508\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9882\n",
      "Epoch 00030: val_loss did not improve from 1.09791\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0625 - acc: 0.9882 - val_loss: 1.1406 - val_acc: 0.7403\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9924\n",
      "Epoch 00031: val_loss did not improve from 1.09791\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0502 - acc: 0.9924 - val_loss: 2.4088 - val_acc: 0.5686\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9856\n",
      "Epoch 00032: val_loss did not improve from 1.09791\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0672 - acc: 0.9856 - val_loss: 1.1310 - val_acc: 0.7538\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9889\n",
      "Epoch 00033: val_loss did not improve from 1.09791\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0580 - acc: 0.9889 - val_loss: 1.7415 - val_acc: 0.6601\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9933\n",
      "Epoch 00034: val_loss did not improve from 1.09791\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0437 - acc: 0.9932 - val_loss: 1.3456 - val_acc: 0.7198\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9857\n",
      "Epoch 00035: val_loss did not improve from 1.09791\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0681 - acc: 0.9857 - val_loss: 1.2432 - val_acc: 0.7372\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9958\n",
      "Epoch 00036: val_loss did not improve from 1.09791\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0344 - acc: 0.9957 - val_loss: 1.3672 - val_acc: 0.7105\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9899\n",
      "Epoch 00037: val_loss did not improve from 1.09791\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0550 - acc: 0.9898 - val_loss: 1.4336 - val_acc: 0.7000\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9898\n",
      "Epoch 00038: val_loss improved from 1.09791 to 1.08825, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_6_conv_checkpoint/038-1.0883.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0503 - acc: 0.9898 - val_loss: 1.0883 - val_acc: 0.7584\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9952\n",
      "Epoch 00039: val_loss improved from 1.08825 to 1.07762, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_6_conv_checkpoint/039-1.0776.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0334 - acc: 0.9952 - val_loss: 1.0776 - val_acc: 0.7566\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9903\n",
      "Epoch 00040: val_loss did not improve from 1.07762\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0480 - acc: 0.9903 - val_loss: 1.1803 - val_acc: 0.7477\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9944\n",
      "Epoch 00041: val_loss did not improve from 1.07762\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0345 - acc: 0.9944 - val_loss: 1.9471 - val_acc: 0.6394\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9855\n",
      "Epoch 00042: val_loss did not improve from 1.07762\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0581 - acc: 0.9855 - val_loss: 1.7121 - val_acc: 0.6608\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9921\n",
      "Epoch 00043: val_loss did not improve from 1.07762\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0406 - acc: 0.9921 - val_loss: 1.2282 - val_acc: 0.7382\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9925\n",
      "Epoch 00044: val_loss improved from 1.07762 to 1.03674, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_6_conv_checkpoint/044-1.0367.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0420 - acc: 0.9925 - val_loss: 1.0367 - val_acc: 0.7785\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9960\n",
      "Epoch 00045: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0276 - acc: 0.9960 - val_loss: 1.1670 - val_acc: 0.7561\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9935\n",
      "Epoch 00046: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0337 - acc: 0.9935 - val_loss: 1.3632 - val_acc: 0.7200\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9937\n",
      "Epoch 00047: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0349 - acc: 0.9937 - val_loss: 1.7213 - val_acc: 0.6862\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9924\n",
      "Epoch 00048: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0374 - acc: 0.9924 - val_loss: 1.6295 - val_acc: 0.6958\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9867\n",
      "Epoch 00049: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0542 - acc: 0.9867 - val_loss: 1.0677 - val_acc: 0.7757\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9953\n",
      "Epoch 00050: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0281 - acc: 0.9953 - val_loss: 1.2046 - val_acc: 0.7561\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9923\n",
      "Epoch 00051: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0363 - acc: 0.9923 - val_loss: 1.0616 - val_acc: 0.7715\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9937\n",
      "Epoch 00052: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0316 - acc: 0.9937 - val_loss: 1.0624 - val_acc: 0.7720\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9934\n",
      "Epoch 00053: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0341 - acc: 0.9933 - val_loss: 2.0059 - val_acc: 0.6292\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9914\n",
      "Epoch 00054: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0412 - acc: 0.9914 - val_loss: 1.7839 - val_acc: 0.6753\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9907\n",
      "Epoch 00055: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0402 - acc: 0.9907 - val_loss: 1.0481 - val_acc: 0.7822\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9986\n",
      "Epoch 00056: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0146 - acc: 0.9986 - val_loss: 1.2330 - val_acc: 0.7622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9936\n",
      "Epoch 00057: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0325 - acc: 0.9936 - val_loss: 1.1429 - val_acc: 0.7577\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 00058: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0383 - acc: 0.9916 - val_loss: 1.0815 - val_acc: 0.7799\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9933\n",
      "Epoch 00059: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0324 - acc: 0.9933 - val_loss: 1.0879 - val_acc: 0.7843\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9914\n",
      "Epoch 00060: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0380 - acc: 0.9914 - val_loss: 1.1333 - val_acc: 0.7771\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9949\n",
      "Epoch 00061: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0266 - acc: 0.9949 - val_loss: 1.3405 - val_acc: 0.7424\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9981\n",
      "Epoch 00062: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0158 - acc: 0.9981 - val_loss: 1.0861 - val_acc: 0.7775\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9953\n",
      "Epoch 00063: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0265 - acc: 0.9953 - val_loss: 1.4637 - val_acc: 0.7228\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9948\n",
      "Epoch 00064: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0269 - acc: 0.9947 - val_loss: 2.1235 - val_acc: 0.6357\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9888\n",
      "Epoch 00065: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0456 - acc: 0.9888 - val_loss: 1.2229 - val_acc: 0.7568\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9981\n",
      "Epoch 00066: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0158 - acc: 0.9981 - val_loss: 1.2954 - val_acc: 0.7508\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9960\n",
      "Epoch 00067: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0253 - acc: 0.9960 - val_loss: 2.1753 - val_acc: 0.6324\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9934\n",
      "Epoch 00068: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0316 - acc: 0.9934 - val_loss: 1.3389 - val_acc: 0.7338\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9980\n",
      "Epoch 00069: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0154 - acc: 0.9979 - val_loss: 1.4562 - val_acc: 0.7312\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9918\n",
      "Epoch 00070: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0361 - acc: 0.9918 - val_loss: 1.2150 - val_acc: 0.7636\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9956\n",
      "Epoch 00071: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0242 - acc: 0.9956 - val_loss: 1.1715 - val_acc: 0.7743\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9925\n",
      "Epoch 00072: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0341 - acc: 0.9925 - val_loss: 1.2318 - val_acc: 0.7640\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9992\n",
      "Epoch 00073: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0108 - acc: 0.9992 - val_loss: 1.0651 - val_acc: 0.7969\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9982\n",
      "Epoch 00074: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0142 - acc: 0.9982 - val_loss: 1.2531 - val_acc: 0.7638\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9924\n",
      "Epoch 00075: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0335 - acc: 0.9924 - val_loss: 1.1042 - val_acc: 0.7878\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9981\n",
      "Epoch 00076: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0140 - acc: 0.9981 - val_loss: 1.3649 - val_acc: 0.7412\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9863\n",
      "Epoch 00077: val_loss did not improve from 1.03674\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0498 - acc: 0.9863 - val_loss: 1.0871 - val_acc: 0.7887\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9960\n",
      "Epoch 00078: val_loss improved from 1.03674 to 1.00609, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_6_conv_checkpoint/078-1.0061.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0197 - acc: 0.9960 - val_loss: 1.0061 - val_acc: 0.7987\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9945\n",
      "Epoch 00079: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0248 - acc: 0.9944 - val_loss: 1.2787 - val_acc: 0.7636\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9886\n",
      "Epoch 00080: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0450 - acc: 0.9886 - val_loss: 1.1561 - val_acc: 0.7750\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9938\n",
      "Epoch 00081: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0283 - acc: 0.9938 - val_loss: 1.0977 - val_acc: 0.7897\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9970\n",
      "Epoch 00082: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0174 - acc: 0.9970 - val_loss: 1.0227 - val_acc: 0.7973\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9983\n",
      "Epoch 00083: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0137 - acc: 0.9983 - val_loss: 1.4777 - val_acc: 0.7247\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9923\n",
      "Epoch 00084: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0315 - acc: 0.9923 - val_loss: 1.2856 - val_acc: 0.7568\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9933\n",
      "Epoch 00085: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0305 - acc: 0.9933 - val_loss: 1.1401 - val_acc: 0.7808\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9979\n",
      "Epoch 00086: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0137 - acc: 0.9979 - val_loss: 1.4077 - val_acc: 0.7326\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9927\n",
      "Epoch 00087: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0299 - acc: 0.9927 - val_loss: 1.0540 - val_acc: 0.7959\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9980\n",
      "Epoch 00088: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0132 - acc: 0.9979 - val_loss: 1.3152 - val_acc: 0.7522\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9927\n",
      "Epoch 00089: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0303 - acc: 0.9927 - val_loss: 1.4522 - val_acc: 0.7370\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9955\n",
      "Epoch 00090: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0224 - acc: 0.9954 - val_loss: 1.5908 - val_acc: 0.7165\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9898\n",
      "Epoch 00091: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0397 - acc: 0.9898 - val_loss: 1.1157 - val_acc: 0.7808\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9992\n",
      "Epoch 00092: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0095 - acc: 0.9992 - val_loss: 1.0813 - val_acc: 0.8006\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9940\n",
      "Epoch 00093: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0253 - acc: 0.9940 - val_loss: 1.0800 - val_acc: 0.7955\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9962\n",
      "Epoch 00094: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0188 - acc: 0.9961 - val_loss: 1.1747 - val_acc: 0.7892\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9939\n",
      "Epoch 00095: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0268 - acc: 0.9938 - val_loss: 1.5199 - val_acc: 0.7200\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9918\n",
      "Epoch 00096: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0324 - acc: 0.9918 - val_loss: 1.0700 - val_acc: 0.7973\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9995\n",
      "Epoch 00097: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0086 - acc: 0.9994 - val_loss: 1.1618 - val_acc: 0.7897\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9923\n",
      "Epoch 00098: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0321 - acc: 0.9923 - val_loss: 1.0635 - val_acc: 0.7966\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9987\n",
      "Epoch 00099: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0111 - acc: 0.9986 - val_loss: 1.4440 - val_acc: 0.7386\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9896\n",
      "Epoch 00100: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0406 - acc: 0.9896 - val_loss: 1.1578 - val_acc: 0.7731\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9986\n",
      "Epoch 00101: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0114 - acc: 0.9986 - val_loss: 1.4431 - val_acc: 0.7382\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9983\n",
      "Epoch 00102: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0117 - acc: 0.9983 - val_loss: 1.1330 - val_acc: 0.7929\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9946\n",
      "Epoch 00103: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0250 - acc: 0.9946 - val_loss: 1.2938 - val_acc: 0.7647\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9907\n",
      "Epoch 00104: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0345 - acc: 0.9907 - val_loss: 1.1211 - val_acc: 0.7862\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9976\n",
      "Epoch 00105: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0130 - acc: 0.9976 - val_loss: 1.1664 - val_acc: 0.7887\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9970\n",
      "Epoch 00106: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0180 - acc: 0.9970 - val_loss: 1.2369 - val_acc: 0.7631\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9964\n",
      "Epoch 00107: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0171 - acc: 0.9964 - val_loss: 1.1477 - val_acc: 0.7836\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9993\n",
      "Epoch 00108: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0084 - acc: 0.9993 - val_loss: 1.3103 - val_acc: 0.7692\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9954\n",
      "Epoch 00109: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0221 - acc: 0.9954 - val_loss: 1.1466 - val_acc: 0.7901\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9974\n",
      "Epoch 00110: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0150 - acc: 0.9973 - val_loss: 1.2381 - val_acc: 0.7824\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9880\n",
      "Epoch 00111: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0543 - acc: 0.9880 - val_loss: 1.1458 - val_acc: 0.7955\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9984\n",
      "Epoch 00112: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0117 - acc: 0.9984 - val_loss: 1.3046 - val_acc: 0.7668\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9929\n",
      "Epoch 00113: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0285 - acc: 0.9929 - val_loss: 1.1650 - val_acc: 0.7869\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9992\n",
      "Epoch 00114: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0083 - acc: 0.9992 - val_loss: 1.1713 - val_acc: 0.7834\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9912\n",
      "Epoch 00115: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0357 - acc: 0.9912 - val_loss: 1.3554 - val_acc: 0.7666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9973\n",
      "Epoch 00116: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0150 - acc: 0.9973 - val_loss: 1.2358 - val_acc: 0.7687\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9927\n",
      "Epoch 00117: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0291 - acc: 0.9927 - val_loss: 1.1059 - val_acc: 0.7990\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9987\n",
      "Epoch 00118: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0102 - acc: 0.9988 - val_loss: 1.2444 - val_acc: 0.7741\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9990\n",
      "Epoch 00119: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0088 - acc: 0.9990 - val_loss: 1.1731 - val_acc: 0.7878\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9915\n",
      "Epoch 00120: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0354 - acc: 0.9915 - val_loss: 1.2070 - val_acc: 0.7720\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9936\n",
      "Epoch 00121: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0261 - acc: 0.9936 - val_loss: 1.1667 - val_acc: 0.7941\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9937\n",
      "Epoch 00122: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0241 - acc: 0.9936 - val_loss: 1.0769 - val_acc: 0.8006\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9961\n",
      "Epoch 00123: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0198 - acc: 0.9961 - val_loss: 1.3293 - val_acc: 0.7699\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9976\n",
      "Epoch 00124: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0135 - acc: 0.9976 - val_loss: 1.0904 - val_acc: 0.8018\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9989\n",
      "Epoch 00125: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0088 - acc: 0.9989 - val_loss: 1.3094 - val_acc: 0.7617\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9929\n",
      "Epoch 00126: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0308 - acc: 0.9928 - val_loss: 1.3714 - val_acc: 0.7503\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9972\n",
      "Epoch 00127: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0149 - acc: 0.9972 - val_loss: 1.3251 - val_acc: 0.7603\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9980\n",
      "Epoch 00128: val_loss did not improve from 1.00609\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0120 - acc: 0.9979 - val_loss: 1.0881 - val_acc: 0.8001\n",
      "\n",
      "1D_CNN_custom_tanh_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 983us/sample - loss: 1.1556 - acc: 0.7583\n",
      "Loss: 1.1556077417554884 Accuracy: 0.7582554\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8327 - acc: 0.4446\n",
      "Epoch 00001: val_loss improved from inf to 2.16199, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/001-2.1620.hdf5\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 1.8326 - acc: 0.4446 - val_loss: 2.1620 - val_acc: 0.3676\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2131 - acc: 0.6402\n",
      "Epoch 00002: val_loss improved from 2.16199 to 1.47300, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/002-1.4730.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.2131 - acc: 0.6402 - val_loss: 1.4730 - val_acc: 0.5595\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9769 - acc: 0.7127\n",
      "Epoch 00003: val_loss improved from 1.47300 to 1.11672, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/003-1.1167.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.9768 - acc: 0.7128 - val_loss: 1.1167 - val_acc: 0.6655\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8312 - acc: 0.7585\n",
      "Epoch 00004: val_loss did not improve from 1.11672\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.8313 - acc: 0.7585 - val_loss: 1.1384 - val_acc: 0.6434\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7283 - acc: 0.7902\n",
      "Epoch 00005: val_loss did not improve from 1.11672\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.7284 - acc: 0.7902 - val_loss: 1.3881 - val_acc: 0.6184\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6509 - acc: 0.8127\n",
      "Epoch 00006: val_loss improved from 1.11672 to 0.87934, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/006-0.8793.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.6508 - acc: 0.8127 - val_loss: 0.8793 - val_acc: 0.7431\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5785 - acc: 0.8363\n",
      "Epoch 00007: val_loss did not improve from 0.87934\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5786 - acc: 0.8363 - val_loss: 1.2881 - val_acc: 0.6306\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5258 - acc: 0.8518\n",
      "Epoch 00008: val_loss did not improve from 0.87934\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5260 - acc: 0.8518 - val_loss: 1.1980 - val_acc: 0.6657\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4767 - acc: 0.8652\n",
      "Epoch 00009: val_loss did not improve from 0.87934\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4768 - acc: 0.8652 - val_loss: 1.1193 - val_acc: 0.6799\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4376 - acc: 0.8775\n",
      "Epoch 00010: val_loss improved from 0.87934 to 0.63953, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/010-0.6395.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4377 - acc: 0.8775 - val_loss: 0.6395 - val_acc: 0.8164\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3920 - acc: 0.8917\n",
      "Epoch 00011: val_loss did not improve from 0.63953\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3921 - acc: 0.8916 - val_loss: 1.4859 - val_acc: 0.6131\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3694 - acc: 0.8968\n",
      "Epoch 00012: val_loss did not improve from 0.63953\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3694 - acc: 0.8969 - val_loss: 1.4863 - val_acc: 0.6466\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3292 - acc: 0.9059\n",
      "Epoch 00013: val_loss did not improve from 0.63953\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3292 - acc: 0.9059 - val_loss: 1.2661 - val_acc: 0.6657\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3095 - acc: 0.9133\n",
      "Epoch 00014: val_loss did not improve from 0.63953\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3095 - acc: 0.9133 - val_loss: 0.8921 - val_acc: 0.7433\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2742 - acc: 0.9257\n",
      "Epoch 00015: val_loss did not improve from 0.63953\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2742 - acc: 0.9257 - val_loss: 0.8117 - val_acc: 0.7666\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2550 - acc: 0.9296\n",
      "Epoch 00016: val_loss did not improve from 0.63953\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2550 - acc: 0.9296 - val_loss: 0.6949 - val_acc: 0.8060\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2341 - acc: 0.9368\n",
      "Epoch 00017: val_loss did not improve from 0.63953\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2341 - acc: 0.9368 - val_loss: 1.6310 - val_acc: 0.5968\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2253 - acc: 0.9388\n",
      "Epoch 00018: val_loss improved from 0.63953 to 0.55361, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/018-0.5536.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2253 - acc: 0.9388 - val_loss: 0.5536 - val_acc: 0.8409\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9465\n",
      "Epoch 00019: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1976 - acc: 0.9465 - val_loss: 1.9068 - val_acc: 0.5761\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1852 - acc: 0.9506\n",
      "Epoch 00020: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1853 - acc: 0.9506 - val_loss: 1.1126 - val_acc: 0.7310\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9573\n",
      "Epoch 00021: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1653 - acc: 0.9573 - val_loss: 1.0622 - val_acc: 0.7018\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1582 - acc: 0.9589\n",
      "Epoch 00022: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1582 - acc: 0.9589 - val_loss: 0.7461 - val_acc: 0.8004\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1348 - acc: 0.9660\n",
      "Epoch 00023: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1348 - acc: 0.9660 - val_loss: 1.3950 - val_acc: 0.6555\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9678\n",
      "Epoch 00024: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1285 - acc: 0.9677 - val_loss: 0.7432 - val_acc: 0.7908\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9688\n",
      "Epoch 00025: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1287 - acc: 0.9688 - val_loss: 0.5767 - val_acc: 0.8369\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9731\n",
      "Epoch 00026: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1103 - acc: 0.9730 - val_loss: 0.8068 - val_acc: 0.7892\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9729\n",
      "Epoch 00027: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1120 - acc: 0.9729 - val_loss: 1.0314 - val_acc: 0.7498\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9787\n",
      "Epoch 00028: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0913 - acc: 0.9787 - val_loss: 0.6949 - val_acc: 0.8225\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9787\n",
      "Epoch 00029: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0937 - acc: 0.9787 - val_loss: 0.9705 - val_acc: 0.7631\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9804\n",
      "Epoch 00030: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0871 - acc: 0.9804 - val_loss: 0.6721 - val_acc: 0.8188\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9823\n",
      "Epoch 00031: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0761 - acc: 0.9822 - val_loss: 0.6719 - val_acc: 0.8272\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9778\n",
      "Epoch 00032: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0915 - acc: 0.9778 - val_loss: 0.9046 - val_acc: 0.7834\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9858\n",
      "Epoch 00033: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0683 - acc: 0.9858 - val_loss: 0.8188 - val_acc: 0.7955\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9877\n",
      "Epoch 00034: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0599 - acc: 0.9877 - val_loss: 1.0296 - val_acc: 0.7549\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9840\n",
      "Epoch 00035: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0692 - acc: 0.9840 - val_loss: 0.5906 - val_acc: 0.8470\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9891\n",
      "Epoch 00036: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0542 - acc: 0.9891 - val_loss: 0.8165 - val_acc: 0.8036\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9865\n",
      "Epoch 00037: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0599 - acc: 0.9866 - val_loss: 0.7117 - val_acc: 0.8120\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9870\n",
      "Epoch 00038: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0608 - acc: 0.9870 - val_loss: 0.8647 - val_acc: 0.7890\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9892\n",
      "Epoch 00039: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0515 - acc: 0.9892 - val_loss: 0.7092 - val_acc: 0.8262\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9882\n",
      "Epoch 00040: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0534 - acc: 0.9882 - val_loss: 0.6587 - val_acc: 0.8269\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9934\n",
      "Epoch 00041: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0376 - acc: 0.9934 - val_loss: 0.8607 - val_acc: 0.7913\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9888\n",
      "Epoch 00042: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0532 - acc: 0.9888 - val_loss: 1.2172 - val_acc: 0.7282\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9897\n",
      "Epoch 00043: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0481 - acc: 0.9896 - val_loss: 0.8537 - val_acc: 0.7899\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9898\n",
      "Epoch 00044: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0485 - acc: 0.9898 - val_loss: 0.8352 - val_acc: 0.7941\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9848\n",
      "Epoch 00045: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0681 - acc: 0.9848 - val_loss: 0.8289 - val_acc: 0.8027\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9960\n",
      "Epoch 00046: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0263 - acc: 0.9960 - val_loss: 0.6104 - val_acc: 0.8512\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9930\n",
      "Epoch 00047: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0360 - acc: 0.9929 - val_loss: 0.9732 - val_acc: 0.7722\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9836\n",
      "Epoch 00048: val_loss did not improve from 0.55361\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0678 - acc: 0.9835 - val_loss: 1.0834 - val_acc: 0.7601\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9858\n",
      "Epoch 00049: val_loss improved from 0.55361 to 0.52923, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/049-0.5292.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0580 - acc: 0.9858 - val_loss: 0.5292 - val_acc: 0.8705\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9924\n",
      "Epoch 00050: val_loss did not improve from 0.52923\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0388 - acc: 0.9924 - val_loss: 0.6022 - val_acc: 0.8537\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9955\n",
      "Epoch 00051: val_loss did not improve from 0.52923\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0286 - acc: 0.9955 - val_loss: 0.5971 - val_acc: 0.8621\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9954\n",
      "Epoch 00052: val_loss did not improve from 0.52923\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0275 - acc: 0.9954 - val_loss: 0.7017 - val_acc: 0.8316\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9928\n",
      "Epoch 00053: val_loss did not improve from 0.52923\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0364 - acc: 0.9928 - val_loss: 0.6248 - val_acc: 0.8553\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9941\n",
      "Epoch 00054: val_loss did not improve from 0.52923\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0297 - acc: 0.9941 - val_loss: 1.0119 - val_acc: 0.7738\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9934\n",
      "Epoch 00055: val_loss did not improve from 0.52923\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0326 - acc: 0.9933 - val_loss: 1.0680 - val_acc: 0.7570\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9872\n",
      "Epoch 00056: val_loss improved from 0.52923 to 0.50841, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/056-0.5084.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0541 - acc: 0.9871 - val_loss: 0.5084 - val_acc: 0.8810\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9934\n",
      "Epoch 00057: val_loss improved from 0.50841 to 0.45818, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/057-0.4582.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0325 - acc: 0.9934 - val_loss: 0.4582 - val_acc: 0.8870\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9956\n",
      "Epoch 00058: val_loss did not improve from 0.45818\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0240 - acc: 0.9956 - val_loss: 0.4977 - val_acc: 0.8791\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9963\n",
      "Epoch 00059: val_loss did not improve from 0.45818\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0219 - acc: 0.9963 - val_loss: 0.8667 - val_acc: 0.7969\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9908\n",
      "Epoch 00060: val_loss did not improve from 0.45818\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0415 - acc: 0.9908 - val_loss: 0.6087 - val_acc: 0.8553\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9955\n",
      "Epoch 00061: val_loss did not improve from 0.45818\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0262 - acc: 0.9955 - val_loss: 0.7344 - val_acc: 0.8302\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9961\n",
      "Epoch 00062: val_loss did not improve from 0.45818\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0224 - acc: 0.9961 - val_loss: 0.8063 - val_acc: 0.8109\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9925\n",
      "Epoch 00063: val_loss did not improve from 0.45818\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0335 - acc: 0.9925 - val_loss: 0.6065 - val_acc: 0.8542\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9933\n",
      "Epoch 00064: val_loss did not improve from 0.45818\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0302 - acc: 0.9933 - val_loss: 0.6405 - val_acc: 0.8523\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9972\n",
      "Epoch 00065: val_loss improved from 0.45818 to 0.45800, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/065-0.4580.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0179 - acc: 0.9972 - val_loss: 0.4580 - val_acc: 0.8924\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9940\n",
      "Epoch 00066: val_loss did not improve from 0.45800\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0279 - acc: 0.9940 - val_loss: 0.6528 - val_acc: 0.8479\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9982\n",
      "Epoch 00067: val_loss did not improve from 0.45800\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0148 - acc: 0.9982 - val_loss: 0.9679 - val_acc: 0.7922\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9908\n",
      "Epoch 00068: val_loss did not improve from 0.45800\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0369 - acc: 0.9908 - val_loss: 0.7590 - val_acc: 0.8311\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9987\n",
      "Epoch 00069: val_loss did not improve from 0.45800\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0118 - acc: 0.9986 - val_loss: 0.5831 - val_acc: 0.8640\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9869\n",
      "Epoch 00070: val_loss improved from 0.45800 to 0.44685, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/070-0.4468.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0499 - acc: 0.9868 - val_loss: 0.4468 - val_acc: 0.8915\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9970\n",
      "Epoch 00071: val_loss improved from 0.44685 to 0.44464, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/071-0.4446.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0185 - acc: 0.9970 - val_loss: 0.4446 - val_acc: 0.8928\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9994\n",
      "Epoch 00072: val_loss did not improve from 0.44464\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0090 - acc: 0.9993 - val_loss: 0.5532 - val_acc: 0.8651\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9897\n",
      "Epoch 00073: val_loss did not improve from 0.44464\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0406 - acc: 0.9896 - val_loss: 0.5283 - val_acc: 0.8793\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9952\n",
      "Epoch 00074: val_loss did not improve from 0.44464\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0238 - acc: 0.9952 - val_loss: 0.5320 - val_acc: 0.8733\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9945\n",
      "Epoch 00075: val_loss did not improve from 0.44464\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0281 - acc: 0.9944 - val_loss: 0.5310 - val_acc: 0.8828\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9952\n",
      "Epoch 00076: val_loss did not improve from 0.44464\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0227 - acc: 0.9952 - val_loss: 0.4893 - val_acc: 0.8896\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9947\n",
      "Epoch 00077: val_loss did not improve from 0.44464\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0251 - acc: 0.9947 - val_loss: 0.5811 - val_acc: 0.8626\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9986\n",
      "Epoch 00078: val_loss did not improve from 0.44464\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0107 - acc: 0.9986 - val_loss: 0.5098 - val_acc: 0.8840\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9938\n",
      "Epoch 00079: val_loss did not improve from 0.44464\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0262 - acc: 0.9938 - val_loss: 0.4517 - val_acc: 0.8921\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9993\n",
      "Epoch 00080: val_loss did not improve from 0.44464\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0089 - acc: 0.9993 - val_loss: 0.5595 - val_acc: 0.8782\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9914\n",
      "Epoch 00081: val_loss did not improve from 0.44464\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0337 - acc: 0.9913 - val_loss: 0.7779 - val_acc: 0.8279\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9941\n",
      "Epoch 00082: val_loss improved from 0.44464 to 0.43561, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/082-0.4356.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0253 - acc: 0.9941 - val_loss: 0.4356 - val_acc: 0.8945\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9995\n",
      "Epoch 00083: val_loss did not improve from 0.43561\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0070 - acc: 0.9995 - val_loss: 0.4390 - val_acc: 0.8996\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9955\n",
      "Epoch 00084: val_loss did not improve from 0.43561\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0216 - acc: 0.9955 - val_loss: 0.7704 - val_acc: 0.8362\n",
      "Epoch 85/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9962\n",
      "Epoch 00085: val_loss did not improve from 0.43561\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0183 - acc: 0.9962 - val_loss: 0.5218 - val_acc: 0.8796\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9964\n",
      "Epoch 00086: val_loss did not improve from 0.43561\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0188 - acc: 0.9964 - val_loss: 0.6240 - val_acc: 0.8621\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9953\n",
      "Epoch 00087: val_loss did not improve from 0.43561\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0225 - acc: 0.9953 - val_loss: 0.4549 - val_acc: 0.8977\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9989\n",
      "Epoch 00088: val_loss did not improve from 0.43561\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0091 - acc: 0.9989 - val_loss: 0.5517 - val_acc: 0.8775\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9919\n",
      "Epoch 00089: val_loss did not improve from 0.43561\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0324 - acc: 0.9918 - val_loss: 0.5184 - val_acc: 0.8791\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9926\n",
      "Epoch 00090: val_loss did not improve from 0.43561\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0310 - acc: 0.9926 - val_loss: 0.4464 - val_acc: 0.8991\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9954\n",
      "Epoch 00091: val_loss improved from 0.43561 to 0.42156, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_7_conv_checkpoint/091-0.4216.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0204 - acc: 0.9954 - val_loss: 0.4216 - val_acc: 0.9054\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9988\n",
      "Epoch 00092: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0090 - acc: 0.9988 - val_loss: 0.5569 - val_acc: 0.8735\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 00093: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0322 - acc: 0.9917 - val_loss: 0.4399 - val_acc: 0.8982\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9983\n",
      "Epoch 00094: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0120 - acc: 0.9983 - val_loss: 0.5277 - val_acc: 0.8777\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9937\n",
      "Epoch 00095: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0271 - acc: 0.9937 - val_loss: 0.4722 - val_acc: 0.8919\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9995\n",
      "Epoch 00096: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0067 - acc: 0.9995 - val_loss: 0.4877 - val_acc: 0.8891\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9967\n",
      "Epoch 00097: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0166 - acc: 0.9967 - val_loss: 0.6504 - val_acc: 0.8635\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9926\n",
      "Epoch 00098: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0307 - acc: 0.9926 - val_loss: 0.4859 - val_acc: 0.8845\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9947\n",
      "Epoch 00099: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0241 - acc: 0.9947 - val_loss: 0.4558 - val_acc: 0.8973\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9989\n",
      "Epoch 00100: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0080 - acc: 0.9989 - val_loss: 0.7762 - val_acc: 0.8400\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9932\n",
      "Epoch 00101: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0297 - acc: 0.9931 - val_loss: 0.6297 - val_acc: 0.8616\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9915\n",
      "Epoch 00102: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0332 - acc: 0.9915 - val_loss: 0.4986 - val_acc: 0.8898\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9986\n",
      "Epoch 00103: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0098 - acc: 0.9986 - val_loss: 0.5001 - val_acc: 0.8866\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9948\n",
      "Epoch 00104: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0252 - acc: 0.9948 - val_loss: 0.4450 - val_acc: 0.8991\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9994\n",
      "Epoch 00105: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0065 - acc: 0.9994 - val_loss: 0.5127 - val_acc: 0.8889\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9968\n",
      "Epoch 00106: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0162 - acc: 0.9968 - val_loss: 0.6633 - val_acc: 0.8612\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9972\n",
      "Epoch 00107: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0140 - acc: 0.9972 - val_loss: 0.7289 - val_acc: 0.8474\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9949\n",
      "Epoch 00108: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0215 - acc: 0.9949 - val_loss: 0.6354 - val_acc: 0.8628\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9983\n",
      "Epoch 00109: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0102 - acc: 0.9983 - val_loss: 0.4954 - val_acc: 0.8870\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9982\n",
      "Epoch 00110: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0109 - acc: 0.9982 - val_loss: 0.7690 - val_acc: 0.8311\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9930\n",
      "Epoch 00111: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0287 - acc: 0.9930 - val_loss: 0.4878 - val_acc: 0.8891\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9981\n",
      "Epoch 00112: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0104 - acc: 0.9980 - val_loss: 0.5756 - val_acc: 0.8719\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9954\n",
      "Epoch 00113: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0208 - acc: 0.9954 - val_loss: 0.4815 - val_acc: 0.8905\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9987\n",
      "Epoch 00114: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0101 - acc: 0.9987 - val_loss: 0.4972 - val_acc: 0.8949\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9948\n",
      "Epoch 00115: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0217 - acc: 0.9948 - val_loss: 0.4602 - val_acc: 0.8994\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9977\n",
      "Epoch 00116: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0120 - acc: 0.9977 - val_loss: 0.5771 - val_acc: 0.8772\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9977\n",
      "Epoch 00117: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0129 - acc: 0.9977 - val_loss: 0.5441 - val_acc: 0.8852\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9960\n",
      "Epoch 00118: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0169 - acc: 0.9960 - val_loss: 1.0942 - val_acc: 0.7845\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9982\n",
      "Epoch 00119: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0099 - acc: 0.9982 - val_loss: 0.4575 - val_acc: 0.8977\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9978\n",
      "Epoch 00120: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0117 - acc: 0.9978 - val_loss: 0.5454 - val_acc: 0.8847\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9963\n",
      "Epoch 00121: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0171 - acc: 0.9963 - val_loss: 0.6764 - val_acc: 0.8537\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9951\n",
      "Epoch 00122: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0217 - acc: 0.9950 - val_loss: 0.4822 - val_acc: 0.8954\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9955\n",
      "Epoch 00123: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0196 - acc: 0.9955 - val_loss: 0.6080 - val_acc: 0.8719\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9991\n",
      "Epoch 00124: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0069 - acc: 0.9991 - val_loss: 0.5021 - val_acc: 0.8873\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9951\n",
      "Epoch 00125: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0201 - acc: 0.9951 - val_loss: 0.4621 - val_acc: 0.8973\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9975\n",
      "Epoch 00126: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0133 - acc: 0.9975 - val_loss: 0.4971 - val_acc: 0.8975\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9993\n",
      "Epoch 00127: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0063 - acc: 0.9993 - val_loss: 0.4946 - val_acc: 0.8994\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9976\n",
      "Epoch 00128: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0131 - acc: 0.9975 - val_loss: 0.6320 - val_acc: 0.8728\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9920\n",
      "Epoch 00129: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0308 - acc: 0.9920 - val_loss: 0.4713 - val_acc: 0.8959\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9991\n",
      "Epoch 00130: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0071 - acc: 0.9991 - val_loss: 0.4866 - val_acc: 0.8963\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9977\n",
      "Epoch 00131: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0119 - acc: 0.9977 - val_loss: 0.5133 - val_acc: 0.8910\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9986\n",
      "Epoch 00132: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0097 - acc: 0.9985 - val_loss: 0.5911 - val_acc: 0.8758\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9919\n",
      "Epoch 00133: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0303 - acc: 0.9919 - val_loss: 0.5061 - val_acc: 0.8926\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9996\n",
      "Epoch 00134: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0050 - acc: 0.9995 - val_loss: 0.5188 - val_acc: 0.8854\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9945\n",
      "Epoch 00135: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0229 - acc: 0.9945 - val_loss: 0.5008 - val_acc: 0.8908\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9996\n",
      "Epoch 00136: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0053 - acc: 0.9995 - val_loss: 0.4656 - val_acc: 0.8987\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9937\n",
      "Epoch 00137: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0268 - acc: 0.9938 - val_loss: 0.4604 - val_acc: 0.9015\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9987\n",
      "Epoch 00138: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0080 - acc: 0.9987 - val_loss: 0.5042 - val_acc: 0.8912\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9988\n",
      "Epoch 00139: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0084 - acc: 0.9988 - val_loss: 0.4689 - val_acc: 0.8982\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9941\n",
      "Epoch 00140: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0220 - acc: 0.9941 - val_loss: 0.4554 - val_acc: 0.8959\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9995\n",
      "Epoch 00141: val_loss did not improve from 0.42156\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0046 - acc: 0.9995 - val_loss: 0.4570 - val_acc: 0.9047\n",
      "\n",
      "1D_CNN_custom_tanh_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd4VMX6xz9n03sjQCB0kBo6iCJFQEQQxAJYUMT2u14b6uWKHcsVO4gdFcWCSBWUJgohqPRm6B3SSe/JZnfn98fsyW6S3TQSEsh8nmef3bPnzJw5Z8/Od953Zt7RhBAoFAqFQgFgqOsCKBQKhaL+oERBoVAoFMUoUVAoFApFMUoUFAqFQlGMEgWFQqFQFKNEQaFQKBTFKFFQKBQKRTFKFBQKhUJRjBIFhUKhUBTjWtcFqCqNGjUSrVu3rutiKBQKxSXF7t27U4QQoRUdd8mJQuvWrdm1a1ddF0OhUCguKTRNO1uZ45T7SKFQKBTFKFFQKBQKRTFKFBQKhUJRzCXXp+CIoqIiYmNjKSgoqOuiXLJ4enoSHh6Om5tbXRdFoVDUIZeFKMTGxuLn50fr1q3RNK2ui3PJIYQgNTWV2NhY2rRpU9fFUSgUdchl4T4qKCggJCRECUI10TSNkJAQZWkpFIrLQxQAJQgXiLp/CoUCLiNRqJD8fIiLg6Kiui6JQqFQ1FsajigUFEBCQq2IQkZGBp988km10o4ePZqMjIxKHz9z5kzefffdap1LoVAoKqLhiILBeqlC1HjW5YmCyWQqN+2aNWsIDAys8TIpFApFdWg4oqD7zC2WGs96xowZnDx5kp49ezJ9+nQiIyMZNGgQ48aNo0uXLgCMHz+ePn360LVrV+bNm1ectnXr1qSkpHDmzBk6d+7Mgw8+SNeuXRk5ciT5+fnlnnffvn0MGDCA7t27c/PNN5Oeng7A3Llz6dKlC927d+f2228HYPPmzfTs2ZOePXvSq1cvsrOza/w+KBSKS5/LYkiqPcePTyMnZ1/ZHWYz5OXBUS9wqdpl+/r2pEOHOU73v/nmmxw4cIB9++R5IyMj2bNnDwcOHCge4jl//nyCg4PJz8+nX79+3HrrrYSEhJQq+3F+/PFHvvjiCyZOnMiyZcuYPHmy0/Pec889fPjhhwwZMoSXXnqJV155hTlz5vDmm29y+vRpPDw8il1T7777Lh9//DEDBw4kJycHT0/PKt0DhULRMGh4lkLNe48c0r9//xJj/ufOnUuPHj0YMGAAMTExHD9+vEyaNm3a0LNnTwD69OnDmTNnnOafmZlJRkYGQ4YMAWDKlClERUUB0L17d+666y6+//57XF2lAA4cOJCnnnqKuXPnkpGRUfy9QqFQ2HPZ1QxOW/QFBXDgALRpA6Va6LWBj49P8efIyEh+//13tm7dire3N0OHDnU4J8DDw6P4s4uLS4XuI2esXr2aqKgofvnlF/73v/8RHR3NjBkzGDNmDGvWrGHgwIGsX7+eTp06VSt/hUJx+dIALYWaNxX8/PzK9dFnZmYSFBSEt7c3R44cYdu2bRd8zoCAAIKCgtiyZQsA3333HUOGDMFisRATE8O1117LW2+9RWZmJjk5OZw8eZKIiAieeeYZ+vXrx5EjRy64DAqF4vLjsrMUnKKPPqqFjuaQkBAGDhxIt27duOGGGxgzZkyJ/aNGjeKzzz6jc+fOdOzYkQEDBtTIeRcsWMC//vUv8vLyaNu2LV9//TVms5nJkyeTmZmJEILHH3+cwMBAXnzxRTZt2oTBYKBr167ccMMNNVIGhUJxeaGJWmg51yZ9+/YVpRfZOXz4MJ07dy4/odkMe/dCeDg0bVqLJbx0qdR9VCgUlySapu0WQvSt6LiG4z6qRUtBoVAoLhcajihomnxdYpaRQqFQXExqTRQ0TWuhadomTdMOaZp2UNO0Jxwco2maNlfTtBOapv2jaVrv2iqP9YTKUlAoFIpyqM2OZhPwtBBij6ZpfsBuTdM2CCEO2R1zA9DB+roS+NT6XjsYDEoUFAqFohxqzVIQQiQIIfZYP2cDh4HmpQ67CfhWSLYBgZqmhdVWmZQoKBQKRflclD4FTdNaA72A7aV2NQdi7LZjKSscNYcSBYVCoSiXWhcFTdN8gWXANCFEVjXzeEjTtF2apu1KTk6ufmEMhnrT0ezr61ul7xUKheJiUKuioGmaG1IQfhBCLHdwSBzQwm473PpdCYQQ84QQfYUQfUNDQy+kQMpSUCgUinKozdFHGvAVcFgI8b6Tw1YB91hHIQ0AMoUQCbVVptpyH82YMYOPP/64eFtfCCcnJ4fhw4fTu3dvIiIiWLlyZaXzFEIwffp0unXrRkREBD/99BMACQkJDB48mJ49e9KtWze2bNmC2Wzm3nvvLT529uzZNX6NCoWiYVCbo48GAncD0Zqm6bGsnwNaAgghPgPWAKOBE0AeMPWCzzptGuxzEDob5JKcQoC3d9Xy7NkT5jgPnT1p0iSmTZvGI488AsDixYtZv349np6erFixAn9/f1JSUhgwYADjxo2r1HrIy5cvZ9++fezfv5+UlBT69evH4MGDWbhwIddffz3PP/88ZrOZvLw89u3bR1xcHAcOHACo0kpuCoVCYU+tiYIQ4k+g3NpPyBgbj9RWGZyctMaz7NWrF+fPnyc+Pp7k5GSCgoJo0aIFRUVFPPfcc0RFRWEwGIiLiyMpKYmmlQiz8eeff3LHHXfg4uJCkyZNGDJkCDt37qRfv37cd999FBUVMX78eHr27Enbtm05deoUjz32GGPGjGHkyJE1fo0KhaJhcPkFxCunRc+pU5CbCxERNX7aCRMmsHTpUhITE5k0aRIAP/zwA8nJyezevRs3Nzdat27tMGR2VRg8eDBRUVGsXr2ae++9l6eeeop77rmH/fv3s379ej777DMWL17M/Pnza+KyFApFA6PhhLmAWh2SOmnSJBYtWsTSpUuZMGECIENmN27cGDc3NzZt2sTZs2crnd+gQYP46aefMJvNJCcnExUVRf/+/Tl79ixNmjThwQcf5IEHHmDPnj2kpKRgsVi49dZbef3119mzZ0+tXKNCobj8ufwshfKoRVHo2rUr2dnZNG/enLAwOf/urrvuYuzYsURERNC3b9/yF7WxWGxB+4Cbb76ZrVu30qNHDzRN4+2336Zp06YsWLCAd955Bzc3N3x9ffn222+Ji4tj6tSpWKzXNmvWrFq5RoVCcfnTcEJnA8TGQlIS9OlTS6WrJkYjREdDp05gt2LbxUaFzlYoLl9U6GxH6JPX6psQGo2yTIWFdV0ShULRwGlYolCLS3JeEHp56lu5FApFg6NhiUJ9XWhHF4P6Vi6FQtHgUKJQn1CWgkKhqGOUKNQHlKWgUCjqCQ1GFCwWIyZLnr5Rt4UpjepTUCgU9YQGIwpmcw5GU5LcqOHKNyMjg08++aRaaUePHm2LVVTfxEqhUDQ4GowoaJrBFomphivf8kTBZDKVm3bNmjUE+vvLDWUpKBSKOqbBiAIYEPrV1rAozJgxg5MnT9KzZ0+mT59OZGQkgwYNYty4cXTp0gWA8ePH06dPH7p27cq8efOK07Zu3ZqUlBTOxMfTeehQHnzwQbp27crIkSPJz88vc65ffvmFK6+8kl69ejFixAiSkqT1k5OTw9SpU4mIiKB79+4sW7YMgHXr1tG7d2969OjB8OHDa/S6FQrF5cdlF+bCWeRsIXywmDriUgB4eVbpyiuInM2bb77JgQMH2Gc9cWRkJHv27OHAgQO0adMGgPnz5xMcHEx+fj79+vXj1ltvJSQkRC8cAMfPnOHHRx7hiy++YOLEiSxbtozJkyeXONc111zDtm3b0DSNL7/8krfffpv33nuP1157jYCAAKKjowFIT08nOTmZBx98kKioKNq0aUNaWlrlL1qhUDRILjtRqBQXwUvTv3//YkEAmDt3LitWrAAgJiaG48ePlxGFNuHh9OzZE4A+ffpw5syZMvnGxsYyadIkEhISMBqNxef4/fffWbRoUfFxQUFB/PLLLwwePLj4mODg4Bq/ToVCcXlx2YmCsxa92VxEfuZRfE8BrVtDo0a1Wg4fuxhGkZGR/P7772zduhVvb2+GDh1aMoS2VRQ83N2Lv3JxcXHoPnrsscd46qmnGDduHJGRkcycObPWrkGhUDQ8GkyfQm12NPv5+ZGdne10f2ZmJkFBQXh7e3PkyBG2bdtW8oAqdDBnZmbSvHlzABYsWFD8/XXXXVdiSdD09HQGDBhAVFQUp0+fBlDuI4VCUSENRhRqs6M5JCSEgQMH0q1bN6ZPn15m/6hRozCZTHTu3JkZM2YwYMCAkgdUQRRmzpzJhAkT6NOnD43srJ0XXniB9PR0unXrRo8ePdi0aROhoaHMmzePW265hR49ehQv/qNQKBTOaDChs4WwkJO9B79jQLNm8lVfSEiAuDjw84OOHeusGCp0tkJx+aJCZ5dBA83ax1xfhVBNXlMoFHVMgxEFTdMAAxi0+lf5qjAXCoWintBgRAGsnc0G6q8o1LdyKRSKBkeDEgUwIDRlKSgUCoUzGpQoKEtBoVAoyqdBiQJY5yrUtxa5shQUCkU9oUGJgqbVH/eRr6+vbUNZCgqFop7QoERBWgqi/lW+ShQUCkU9oUGJgqZZZzXXQuhs+xATM2fO5N133yUnJ4fhw4fTu3dvIiIiWLlypeMM7NxGzkJsOwqB7SxctkKhUFSXyy4g3rR109iX6CB2NmCxFKAVmNCEBjt8HB7jiJ5NezJnlPPY2ZMmTWLatGk88sgjACxevJj169fj6enJihUr8Pf3JyUlhQEDBjBu3Di0zMyS/Qd2n+d/8QXBoaElQmxbLBaHIbAdhctWKBSKC+GyE4UK0ajx0Nm9evXi/PnzxMfHk5ycTFBQEC1atKCoqIjnnnuOqKgoDAYDcXFxJCUl0dRodCoKcz/8kBVWi0IPsZ2cnOwwBLajcNkKhUJxIVx2olBei76g4ByGmGTc81yhR48aPe+ECRNYunQpiYmJxYHnfvjhB5KTk9m9ezdubm60bt1ahszWNId5RO7eze9//OE8xLZCoVDUMg2uT6G2OponTZrEokWLWLp0KRMmTABkmOvGjRvj5ubGpk2bOHv2rDy49BBU63tmTg5BgYFlQmw7C4HtKFy2QqFQXAgNShT08NmiFkSha9euZGdn07x5c8LCwgC466672LVrFxEREXz77bd06tRJHqyfv5QojLrqKkxFRWVCbDsLge0oXLZCoVBcCA0mdDaA0ZiIiIvFIxXo08epG6fWOXkS0tOhVy9wcYFjxyArS+7r0gW8veukWCp0tkJx+aJCZzvEbqGduhRDJ+4jQM1VUCgUdUqDE4XaWpKzSujnLu1GKv1ZoVAoLjKXjShUxg1Wm+s0VwlHloKLi/xcR+W61NyICoWidqg1UdA0bb6maec1TTvgZP9QTdMyNU3bZ329VN1zeXp6kpqaWomKzYCor6JgsP4UdVAuIQSpqal4enpe9HMrFIr6RW3OU/gG+Aj4tpxjtgghbrzQE4WHhxMbG0tycnK5x1ksBZizUnDLBI4eBXf3Cz119UhIAKNRdjC7uUFiohQDk0nu96n8bOuawtPTk/Dw8It+XoVCUb+oNVEQQkRpmta6tvK3x83NrXi2b3lkZm7l7Cc30Pk5YMeOGp/AVmkmTYLoaNi7Fzp3httuA09P2LMHvvkGpkypm3IpFIoGT133KVyladp+TdPWaprWtbZP5uLijUU3DvLza/t0zjEa5XtRkXw3mUAPpa1mMCsUijqkLsNc7AFaCSFyNE0bDfwMdHB0oKZpDwEPAbRs2bLaJzQYvLF4WDdqShT274evv5YVfdOm8OKLFc9/KCyU7/bioIuCvk+hUCjqgDoTBSFElt3nNZqmfaJpWiMhRIqDY+cB80BOXqvuOV1cakEUPv0U5s2T/QA5OXDPPdC6dflpHFkKfn7ys7IUFApFHVJn7iNN05pqmmxSa5rW31qW1No8p8HgjVkfYJObWzOZ5udDq1awZIncjourOI0jS0HvXFaioFAo6pBasxQ0TfsRGAo00jQtFngZcAMQQnwG3AY8rGmaCcgHbhe1PFjeYPDCpK+CmZFRM5kWFICHB+gjd2JjK06ji4H+bjLJjmZXV+U+UigUdUptjj66o4L9HyGHrF40DAYPTFYvDTUVUbSwUFbozZvL7apYCrr7qKhICoKnp7IUFApFnVLXo48uKpqmobn7YPF2q1lR8PCAwEAZyK4iS0EIx5aCm5vMR4mCQqGoQy67RXYqwsXFG7M/GGpaFDRNupAqshR06wBK9inoloJyHykUijqkQVkKYO1s9neveUsBpAupIktBFwIoOfrIzU25jxQKRZ3T4ETBxcULs79LzYmC3tEM0lKoSBTsLQGjUYa3sFikpeDh4dxSMBohKalmyqxQKBROaHCiYDB4Y/JzIgo7dsCyZVXLsLSlEB9fflA7e0vBaLTFO6rIUvjkE7kAj4pmqlAoapEGJwouLt6Y/DTHovDWW/DUU1XLUB99BNJSMJng/Pnyj9cpKrKJQkWjj+LiIC1N9TkoFIpapcGJgrQUcCwKiYlyVnJVsLcU9LkK5XU2l7YU9H4FffSRs0o/L6/ku0KhUNQCDU4UXFy8KfIVsvK3HwkEFy4K+lyF8voVSvcpVNZS0MNy1GUgP4VCcdnT4ETBYPDG5GuWG/azmoWwrXNg35qviAuxFIqKSloKShQUCkUd0wBFwQujj7V1bu9Cys62VbhViYtkP/qocWPZ4q+upVAZ95ESBYVCUYs0OFGQ7iMHopCYaPtcWReSECUtBYMBmjUrXxQu1FJQfQoKhaIWaXCiYDB4Y/SxtsbT0mw7EhJsnysrCnqFbr+2cfPm5buPVJ+CQqGoxzQ4UZCWgrUyv1BLQa/gdUsBKp7AdqGjj5QoKBSKWqTBiYLB4E2RHj67IlEwmWDFCucTxpyJQlxcxWmgavMUlPtIoVBcBBqcKLi4eDkOn+3IffT773DLLbB+vePM9ArcXhSaN5cd1ZmZjtNUxlJwJCjKUlAoFBeBBicKBoM3wg2Ej3fFlkKKdWXQDRscZ+bMUgDnLiQ9jbe34z4FcDwkVvUpKBSKi0CDEwUXF28ARKB/WVEIC5OfdVHQW/t//OE4M0eioOdhLzL26BW+r6/j0Ufg2IWk3EcKheIi0OBEwWDQRcG3rCi0by8/lxaF/fshOblsZroo2I8+CgqS786isOppfH0dz1OwP8Ye5T5SKBQXgQYnCsWWQoBP2T4FXRT0yWv2/QIbN5bNzJGloIuCszWg7S2F0n0KziyFoiIwW2dhK1FQKBS1SIMTBYPBCwBLgF2fgskkLYEWLWQFb28pBAeDv79jF5IjUQgMlO/ORMHeUnA0+gjKioK9ECj3kUKhqEUaoChIS8ES4GUTheRkOeKnaVNZWeuikJUlReHaa+VIpNI4Gn3k4wMuLhVbCj4+jkcfQVn3kb0Q1GdLISUFevaE48fruiQKhaKaNDhRcHX1B8Dk72oTBX04alhYSVHIzISAABg+HE6fhlOnSmbmyFLQNGktlNen4O4uX85GH5VnKdRnUTh4UPa/7NpV1yVRKBTVpMGJgru7HB1k8jXbwmfrI4VKWwq6KIwYIbdLD011JAog+xXKsxQ8PKQoVHb00aXiPtLDhtTUUqcKheKi0+BEwcXFC1fXQIw+1so4I6NiUejUCVq3hl9/LZmZo9FHIC2F8voUnFkKl7r7SBcDJQoKxSVLgxMFAHf3ZhR6Wyva9HSb+8iZKGgajB0r+xXsK2hnlkJ5oqBbCm5u1bMULgVRcHbtCoWi3tMgRcHDoxmF3tlyIz1dWgqBgbJSdiQKIEWhoKDkKCRHHc1QsShUtU9BFyJ39/rtPlKWgkJxyVMpUdA07QlN0/w1yVeapu3RNG1kbReutnB3b0a+p7XS1kWhaVO5rYuCxSIX3tFFYcgQ8PODX36xZVRen0J5Hc16n0JlRx/p1kFIyKVhKShRUCguWSprKdwnhMgCRgJBwN3Am7VWqlrG3T2MfM9UuZGaCidO2MJT+PhIUcjOlsNU/f31RDBqlOxXsFjkd9V1H7m729xHVRl9dKmIgnIfKRSXLJUVBc36Phr4Tghx0O67Sw4Pj2a21df+8x/Ytw/GjZPbuqWQlSW3dUsBpAspIQF275bbuii4u5c8QWCgrNgdxTAqz1KoyH10qYiCshQUikuWyorCbk3TfkOKwnpN0/wAS+0Vq3Zxd29mC5+dmAjvvgvTpsltX18Z5kJv7dqLwujRcsnNtWvltj6SyFDqNuqhLhyFz7a3FCo7+kgXguBg1aegUChqFddKHnc/0BM4JYTI0zQtGJhae8WqXTw8miHcoODe0XiOnAx33GHb6WtdgSc+Xr7bi0JICISG2vbZr89sjx7qIj0dmjQpuc/eUjCZbDOc3dzkd56echKYPZea+0iJgkJxyVJZS+Eq4KgQIkPTtMnAC4CTVWTqP/oEtvQ3bispCGATBX2dZXtR0PdnW0cuFRSULwqOfOv2o4/AVsm7uEhrYepU+P57m/CAzToIDr40RCEry9bvolDUNbNnSxexolJUVhQ+BfI0TesBPA2cBL6ttVLVMrooGI3xZXdWJAp+fjZRqMhScCQKeho3N7mdlyfdT7oL6j//kRbE7Nm2NPn5UkRKB9GrTwghRcHLS352tvJcaQoL5TU7W39CobgQhJDP1/ff13VJLhkqKwomIYQAbgI+EkJ8DPhVkKbe4uLiiatrMIWF1RQFfR6DM1EoL3x2aUshL88mEABt28Ltt8Nnn9la3vn5srL18rJt1zdyc6VYtWkjtyvrQtqyBd57D377rXrnjYmxhTpXKEpTUCCt1vr4n6mnVFYUsjVNexY5FHW1pmkGwK2CNPUad/ew6lkK9u6jwsKyIS6gcpaCvSi4luraeeYZKTyffmo7xstLLuEJ9fMB10WgbVv5Xtlhqdu3y/fqVOyZmRARAW+8UfW0ioaB/lzVx/9MPaWyojAJKETOV0gEwoF3aq1UFwEPj2YUFiaU3WHf0eziYmud61TFfeSotWw/+gjKWgoA3btD166wY4fczs+XgqCXpT6OQCotCpW1FC5EFBYskMKQlFT1tIqGgf5c1cf/TD2lUqJgFYIfgABN024ECoQQl2yfAshhqRVaCnrcI3vs3UfOOpo9PeX3ziwFe/dRbm5ZSwHkKKdU6wQ73VKoz+4jXQSq4j4SovqiYLHARx9VL62i4aAshSpT2TAXE4EdwARgIrBd07TbKkgzX9O085qmHXCyX9M0ba6maSc0TftH07TeVS38heDh0QyjMQEhSo2S0UXh/PmyriN9f0WWAjgPn20fOhscWwogh5+mpMjPuqVQkfvo6aelf746rF8Pr79evbRQPUvh7Fl5n6HqFfuGDbbFfJQoKJyhLIUqU1n30fNAPyHEFCHEPUB/4MUK0nwDjCpn/w1AB+vrIeQIp4uGu3sYQpgoKkopuUMXBSEci4JuKQhRvig4C3WhWwq6EOTnO7YUQkJslkLpjmZnD/jixbBmjeN9FfH113ISX3WpTp/Ctm22z1Wt2D/8UM4B6dtXiYLCOcpSqDKVFQWDEOK83XZqRWmFEFFAWjmH3AR8KyTbgEBN08IqWZ4LxsOjGQBGY6l+BV0UwLmloI9mqEgUnPUp2FsKubmOLYVGjeSiNUJUzn1kscgQHGnl3fJyiImR8wuEqF56/VrDw6XIVcZS2L5dutrCwqpWsaemSvF74AFpkSlRUDjjMrIUzOaLcxmVndG8TtO09cCP1u1JQDWbpMU0B2LstmOt3zno/a153N2lKBQWxuPr28O2w9NTzhmwWJxbCiBdSM5GH4EUBb2lr2M2y1fpjmZHwhISIo/NzKyc++j8eXl8dUUhNlYKQm5usTCaTI6NGLNZ7nN3l0bTzp1wemMbOjGQCPxxCwyjKCmfolQ5rSI4WB5bWCj7hv/+W2rHFb8GMa7HEAIzzxb/eY1G2LoVoqPlCqhpabJbx8MDmjeHxo0h/3QR2eI5XE5OxCuhDZ2zdzAoT/5kW7bIFUETE+XS2wUF8rJ69oT+/eX3e/dKz5zRKH/OK66QulRQIA2cI0fkyqtNmkCrVlJrDxyQ2+PHy59hyRI5FuGxx2DiRFixAr79VpY5KUkaMP/6l8z3zz+l5np6yvtZUCDvhZubfNROnZLnDA6GPn3kPfv7b/lo3HQTDBsmy3vypDSudu2SbYauXeUjajKVnL7i4yPfT56UP2u/fjBmjOymys+X16OvLnvqlLwPI0fK+/P33/DXX9CiBfToIT18W7bIdK1aQbt20K2b3J+SIvM/cACOHYMOHWDwYHk/g4Kkd2/VKnntV1whz68fGxwsf09XV1luPz8ZqNhkkumSkuTv7uUFvXvLQWbHj8OePfI+tmgh78+JE/J57NxZ/j4xMfL6LBaZ3t/YnyBWkXs0lMQu8j55e8t7pL/7+8t3s1le55kz8lwBAfIe+/rK8pw/L9+zs+Xfu3Fj+Xv17SufubVrZbsqMFBeV36+zHfECFm+9eshMlJ2u/XuLZ/FnTtl/oMGyfPt3Cl/N4tFPh/dukGXLnD0qPztn34aXnqpen/xylIpURBCTNc07VZgoPWreUKIFbVXrJJomvYQ0sVEy5YtayRPpxPYNE3+SllZlROF8voUTp4s+Z0e0qJ0n4K9daITEiLfU1Mr5z7Sh9CmpmIy2bTBaJSfU1PlKzNTLiLXtauc5LlkCRyIFqSc2whAx5tcCWoqY/4dPSpvQbNmciBWUZE0AFJS5ENrMMgKVxoXN8tXEMA5mI98WS+3Rw/bHzY0FNLSBGbzS3idMTLebyMe2S7EXicffL0f39NTHiuEvAU2jW0KvA6LALoD9+MeJI/T4wv6+cmK08tL/tl//tlmBPn4yMrazU2KwNdfl7yVYWHSC7Zvn0zXpIn8c546Bf/+tzymVSt5b+67Dx58UJ6jfXtZSQQHS0Nm0qSSP6ce/9DLyxblxGSSefXpI0Vs4UJZoVx9tbznn38Oc+fKPFxcpLjddZf8HQ4etHVJubrKd92wNJnkNVx7LURFwcqVJa/R31/u79JFlv277+TUGH9/uOYaKXizZ8trv/ZaWdGdOycr9Z9/tk1Y9/eXeYxVB2Q3AAAgAElEQVQYIYVt1iyZn063brICPHZM3s+uXeWk/cxM+chaLLYxGYcPy2eqQwdZiYI8LjJS3peQEFkBm0yyEvb0lPkbDDLt9u3QsqV8vl1dZd5ZR4uIJRwfs4kuXeS5cnPlPcrNlfc8O9s23sPdXf4eY8fKMh08KEW8SROZd79+8tnKyJD3aOlS+PJLKTDXXSeFLiND3gMvLyki8+fL87VoIRsQ587JCPxNm8o4nJmZsG6dPKZ3b7j1VlmWvDz45x+Zf4cOcOed8repbSprKSCEWAYsq8FzxwEt7LbDrd85Ovc8YB5A3759q+nfKImHhxQFhxPYfHyci4JegefkOB99BI77FOyjqpY3TwFKioKd+8iCRnaqicxzctehQ9bK4UAQGu9zJLcTfwULsrMrF8TW3x/69yikPduwYOBIws1EH4NevWDCBPnAxsfLP5irq9S6Jk3kH1I3cvr3h/YfP8nhnTkcnPYF4qOPcfNxw+3fD+HqKlulO3fKCu3bb2H4cDBv383eqx7mq6GLWLZ5AJ65RsKaweTJcP31cOWV8k9jP/iroEAKks9fv+F7+xjMm/8i96tF7FoVz8aHFqFpMu8BA2zarZORIVuZYWGy1eriYtuXlSUrB09PmU6Plg6yktU0+UEIOHJUIz9f3h+A1aulAIwfLytGfWK62QwbN8oyX3217eesCF249OvOypIVcbNm8lU6IG9l8zx2TAqrh4ds4QYHl723J05Ax442I9Zkkvep9AC8ggJZ2YWG2oxXndxcmxezcWNZQdcE6enyL1W6LBXy0XJpzvk1gqXJNVMYOywW2VgID3fuNCgslELQvr3z8uuNq9KxNeuCckVB07RswFElLP8mQvg72FdZVgGPapq2CLgSyBRCXBTXEYDB4IGHRzj5+cfL7tQrfn8Hl1dZS0HvUyiuVShpKZQ3TwHI8mxMDF1I32xmd8Y9/Prbvexc0pIsTIhHDfCo7Vg3N/B2bY6F+wknlrtuzqdrP28MkRtx/Xkpwd+8T0hzT0JC5CWdPCndM23ayArYc98+uGqyzGzBDtkcqiofHKVdeDI3PgNs+kVe++MPOT3c9dQx+rGLfnONfPb0ndI237Gr3FN4eso/H5ZUwIRbkwA8Q+B602quf6v84gUGSjeMI/z9Hf/UYPcnHjECrVcvOpfqjL/xRvkqjYuLbDlWldKVhr+/FJULQdNkZV8eeqvbHkdtFf3YVq0c7/PxkZVfTaMHCagyutlZSx3NBkPF1+vhIVv65aFp1RC8WqJcURBCVDuUhaZpPwJDgUaapsUCL2OdBS2E+AzZJzEaOAHkUQdRV729u5Cbe6jsDl0ULsR9FBgom1p5eTYnryNLQQhwdeXUKWkq7t8vl4LeurUfZg7CfwGuonNeEndOMNHoqzcJuHEwgeOHEhgInTrJlq/bq6/bhpQ+c1Da9Cd/AfOnMHC6bf4AsvU2fLhdWWNjbZ/1dSSqSnq67Z8bGCjNg4qOB9mE9vGpWmexfVhzb2+Z1l58a4Po6PoZc0pRPvYdzbX9jFwmVNp9VFWEEHdUsF8Aj9TW+SuDt3dnEhK+QAgLMnKHlfJEwd59VFGfAsgKTBcFq6WQXOjP3l3BnOcujtCJ5fsnc7idLWnv3vDM4wV0n30vwQ9NoN28/9L2sSnw/PPw1cvQ/1W4f2jJ89lHVdU7FPQ5ACkpJUShDDF2/f0XIgp6f095y5HaHw9SQKorCnpaIaRPo/Ts85rCYpG+Ovv7pLg00J8rIWwj/xTlUmuicCng49MFiyWPwsIYPD3t7OHKWAqZmbLXsLzRRwAZGZw2NmfbNjgY6U8kW/j7sYEIoQHfY8DMYI9/ePit1lx5pWzg+/oCFg/4YCn4NAdOywpP7010ZArHxdmW+CwtCskV+FJrShR0IdRFobyWWXq6bOW7u8uKvSpj7TIz5Z/b09MmuLm5tScKmZlSGGJjbT3siksD+8aGs5F+ihI0aFHw9u4CQG7uoaqLgj4Uphz30VlaMvO/jfh2naxLXFwa0YNzvDTxKNeODyDsjiGEkYBf/6vhsfUl0xsMsnLVXTt6hefl5VwUOnWSbg5HlkJ5xMTInse0tOqJgh42214UTKYSw1vLkJFhO746loL+29iLQqNGVS97ZdB/66IieU+bNq2d8yhqHvvnKj//AjonGg4Nusnj4yPHveXllepXqIz7SK9oS4lCfDy8/z4M/u8A2nKKHzc0Yto02V+Qu2knu+nLzHtOMWSQhSs4jh85znv0GjWyiYI+zMPLy/mQ1IgI+bkyonDqlK0TLiZGjhUEWwiPqpCXJytM+z4FKH9Ws72I+PhI94/9WMbyyMiwnUMXhdqc1WM/3+QycCEVmgrZfGYz+xP313VRap/SlkI9RQiBKGfiqEVY2Hh6I4eTD9d6WRq0peDmFoKbW+Oync3liYKbmxQCa0VhdvNk7y454WrdOvmyWKBHJ3de5DUeeLc74Y/fItNusXY0248+0vN0REiIHMsGNkvB27uspZCfLyvZzp2lhZGWJguhu40cuY+uugpuuw0+/lgKz3XXyais1bEU9P4Be0tB/z483HkaRxV76bGkjnAkCjU8qzmrMAt/D+uQJHtRjYkpMzorJS+F5NxkzMJM19CuaBfQmZljzMHV4Iqna0m3pBCCnw7+xMbTG4k+H82s4bMY2nqowzxOpp3kox0f8eygZ2ns07j4+1xjLo+ufZTFBxeTV5SHj5sPux7aRadGnThw/gBzts3hxcEv0iqwVfE9AGz3oRQ743ay4sgKnhv0HL7uTixCIL8on092fsKmM5uY1HUSE7tOxMP1wtw4QgjOZJxhX+I++Urah6vBlU/HfFrimu2fix+OLiXxvBsP93sYbzfbWNpCUyErj65kXMdxJe77+dzzfLXnKw6nHMYiLOSb8knJS8HX3Zcvx35JmF8YFmHhqz1fcTbzLCaLiRb+Lbi6xdVENInA1SCrV4uwEJcVR7h/ePGzkVeUx9rja1l6eCnRSdGczTxLsFcwD/d9mGFthvHHqT/YGb+TYK9gvN28WXl0Jecyz/Hvvv/m4zEfX9C9q4gGLQog+xXy8kqpb3miAODnh0hOYQ2jmf7G7Ry2DqRt2RJmzIB774UOIbkQ8goUvm1L52j0ETi3FEJCbPGB7C2F0qKgdzKHh9vcQOnptpZ3aUshO1taEb/+CnPmyIHlLVrICrmmRaG8NHrHtH3FXhlRyMws4z7Kz0oj8vhaNp7eSLYxm5s63sTwtsNxd6n6wP4NJzcwZuEYFoxfwB0Rd5RrKXy04yMeX/s4wjpye9qV05g9ajaOSM1LZfnh5aw7uY7opGi+vflbBoQPAGDN8TXM2z2PtSfW4u/hz6zhs7iv130YrAMgVhxZwR3L7iDQMxCTxcQ7f7/jUBRMFhN3Lr+THXE7WHl0JavvXE3n0M7EZcUx9sex7E/az4O9H2RIqyE8vu5xJi2dxLfjv+X6768nKTeJX4/9ypIJS9h4eiOz/pxFobmQAI8ApvSYwuxRszFoBuKy4nhy/ZMsObQEgMY+jZk2YFqJMkxdOZWos1G0DWrLibQTxGbF0sSnCauPr+a/v/+XVbevol9zx0Offzv5G7vid/HcoOcASMhOYNLSSdzX6z6m9JjCkZQjTFgygYPJci1zg2bgipArOJtxlkFfD2LD3RtIzUtl89nN3FeQiT9yXP3T/7xDkjGN2dtmM2fUHG7rImN6vrHlDV6NepVR7UexYtIKsguzmfH7DL6P/h6j2UirgFa4GlzxcPUg1DuUzWc2M3rhaDZN2cQT657g2/3fYtAMuBpcMZrlYJJ2Qe34/MbP6dSoE1N+nsIfp/+gmV8zhrUZxqn0U+yO302huZBQ71CubnE1w9oM42DyQZ7949ni+9AhuAM5xhxS81O5tvW1vDn8TcZ3Gu/wntUkDV4UvL27kJT0A0IIWwtPr3CciMJ+9348veUl/qAfHUQWCxbIWZ8t7KfiESx9/Bs2wPTp8itH8xSgfEtBnzpq36dQ2gzWZzM3b24TBd11BGVFQReRc+fkdFGLRRbe3796oqC7q6riPsrIkNOcobhiz85IwrtxKC4GF+fp9LT6zbaK5W3/PM+aLbtwd3HH3cWdz3d/TpvANuz71z6nLV1HGM1GHl37KEWWIp7941lu6XwLHrooGAwlRGHV0VU8vvZxbuhwA5MjJrPx9EbmbJ9D++D2RDSJ4Kn1T5FekM7QVkMpNBey9NBSCs2FhPuHYxEWxv44lr/v+5vFBxfzwqYXaObXjIf7Psyu+F08+MuDLD64mPWT16NpGt/98x1NfZsS82QML296mTf/epOE7ATC/MKYunIqh5IPsWD8AlYdXcWOuB08P+h5vtzzJf2+6EeIdwhJOUm4ubix6vZVjLlijPyZPAMZvXA0feb1IdgrmBWTVvDk+icZ/M1gACZ1nUSfsD7sTtjN3B1zcTG4cG/Pexn9w2jSC9J5ecjLrD2xlk92fsLjVz5eLGBPrX+K7//5nrFXjCUlL4WOIR357ubvGNJqCBtObeD/fv0/xv44lu0PbC+2SnRWH1vNzT/dTJGliBFtR9C/eX8+3fUpW85tYcu5LSw5tISos1F4uXrx8eiP6dusL90ad8PbzZs/z/3JjQtvpP3c9hRZrFPbQ5sxzd+fWLJIMqZxf6/72Ze4j0lLJ/H73b/TLrgdb//9Nl1Du7L+xHqGLRjG8bTjZBZk8n99/o9H+z9Kx0YlJ3msO7GOGxfeSLu57UjLT+PVoa/y4pAXEUJwLvMcUWejeC3qNUZ8NwIfNx8EghcGvcChlEOsP7GeDiEdeLT/o4zuMJrBrQYXWxQA0UnRRJ+PZmjroTTza1bp57ZG0X1Zl8qrT58+oiaJiflQbNqEKCiIs32ZmCjE4sVljo2LE+K++4TQMItgQ5r4gMdE4cKlzjP/z3+EcHcXIitLbi9fLicu7t0rhNGoT2IUYvJkx+mfftp2zObN8rtBg4S49tqSx/34ozzm4EEhBgwQ4rrrhIiMlN+5ugoxcGDJ4zdutOU7caJ8X7tWiJ49hRg71vn1fPmlEH/9Vfb7FStkHrt3y+2TJ+X2N984z8vfX4gnnpCfly4VRgOiyawQ0fvz3uJw8mFhtpjFn2f/FFtjtpZN27SpEA8+KD//848wawj/V73EHUvvELnGXJFflC8+3fmpYCZi2bavhRgzRv6mleDtP98WzEQ8te4pwUzEB9s+EOL554VwcRGifXshJkwQQgixO3638P6ft+g3r5/INeYKIYQwmU1i7MKxQpupCWYiWs1uJW768SYR+Gag8J/lLx5Z/YjYm7BXWCwWcSzlmAh5K0T4veEnmImYvHyyMJqMQgghLBaLmLVllmAmYvWx1SItL024v+Yupq2dJoQQ4mjKUcFMxNt/vi22nN0imIlwecVFeP/PW3i85iFu+ekWYbFYxJn0M+Len+8VU1ZMEU+te0ocSDpQ5npf2viSCHs3TOxP3C+EECIxO1E8svoR8cepP4qPsVgs4vE1jwtmItxfcxfN32tefPx3+78TzERsOLlBCCHER9s/Kr5/zjh4/qAImBUgun3STaTlpRV/v+rIKuH+mrvo/Xlv4feGX/E9CXs3TIz6fpR4ffPrwuUVF3HlF1eKmMwYh3nvS9gnHlj5gJi3a55oObuluHWqjxBt24qlnRHMRGyP3S6yC7NF5486i8bvNBajfxgtPF/3FGfSz4j5e+YLbaYm+n/RX0QnRZf7nHy992vh+qqreOvPtxzuzzPmied+f06M+n6UOJpytNy8LhbALlGJOrbOK/mqvmpaFNLS/hCbNiHS0n53ekx+vhCvvCKEt7cQbm5CPBW2UKT5t5K3b9Uq55lv2iSPWb5cbi9aJLcPHRLCYrFVzFOnOk4/a5btmJ075XcjR8qK355335XHpKcLMXq0EH36SFEDITp3FqJjx5LHf/+93KdfEAhx4IAQgwcLMWSI47KYzUJ4eQlxyy1l9335pczj9Gm5nZYmt19/vcyhqXmpYvNJqyi9/LL8cu1asTuM4srN63Uv0Wp2K8FMhNurbmJbzDYhhKyI71x2p0gJ9BBi+nSZ9uRJcSJIpp23a17xeYwmowiYFSDu//h6IUAULv1JTP15qlh3fF2ZMkWejhR3LrtTPLL6EeH7hq8Yu3CssFgsYtiCYSL07VCR9a+pQoSGCjFsmBADBoisgizR7oN2osX7LURCdkKJvLILs8Vti28TL258sYRYFJmLypz373N/i6A3g8T036YLs8VcYl+hqVC0eL+FGDR/kJi3a55gJmJX3K7i/Vd/dbXo/FFnMeDLAaLZe83E8dTjYug3Q0XTd5uKxOzKCaBO6XM7O+ahVQ+J/l/0F+cyzhV/n1+ULxq93UjcvOhmMXfbXKHN1MSNC28UJrOp3Px+P/m7cH3VVTR+p7H4bOdn4r6f7xPMRPT6rJdIzUsVj65+VLi96lYsMr8c/UUIIURsZmyxeFbE5OWTRZP/GoTlyv7imREIt1dcREFRgRBCCpP3/7wFMxHP//F8cZrYzNgKy66TZ8yr1HH1BSUKlaSgIEFs2oSIiZnrcP/WrbJeBSFuvVWIEyeErJj1ynr9eueZG41CBAQIcf/9cnvBApnmxAkhhBC5Xq5ieSdsrd7SzJtnO88BayvvppuE6N5dlt36gIsnn5QVvMUirY42bYT46CNboUNCSub79tty37332vLPzBTixhvFyhvaivD3w0VsZmzJNGfPyuO6di1bzpkzhdA0IQoL5bbZLESvXrJ1/c47slxWJi6ZKAyvGESiD0LMmSO/jIoSn/SVFfvWmK1i0pJJYvQPo8X8PfNF6zmtRfj74WLd8XUi6M0gwUzEZ33sBCcxUSzpItPujNtZolgTFk8QYa8FCguIRbPvF8xEeLzmITae2lh8TKGpULT7oJ3wfcNXBL8VLELfDhUnUuXvsyN2h2Am4n8PdxWiUychpkwRonlzcffyu4XhFYPYcnaL49+tCpRXIX+w7QPBTET4++Gi44cdhcXuPupCwUzEV3u+EkLIFn2hqfCCy1RVntnwTHFZxi8aX+nKcnf8bnH1V1cXNwae/f1ZkV+UL4QQ4kjyEcFMhOurrqLl7JaVrqjt+XzX54KZiGO3DBXXTkH0ndWmxP7lh5aL0T+MFtmF2VXO+1KksqLQoIekAri7N8HVNbDssFRkhMqrr5YjN9eulRER27WjZGdoeZNh3NxkcKHVq6Xf3r5PAfixh4FbboeTnk6GytlHUSs1TyE6KZrAtwJZemip7FNo3lxOFLPvU9A02a+RlgZmM0LIERsiPk52pt9mXTxPjwLn78+S0GRis2KZGTmzZFmOHJHvJ05gLjJyOv00h5MPk56fLuMrh4XZOs8NBtlXMX687E/p0QOmT+fwluUsObgEi7CwpgMlhqRuD4fGrgFc2fxKFt22iNV3rmZqr6ksm7iM5NxkRv0wCn8Pf5r7hLH6CkqMPtrbFFww0K1xyeA9ozuMJsGcwf6m8FnGH7QKaEW74HaMWzSOv2P+BuCzXZ9xMv0kSyYsIfW/qZyffp52wXJ6eb/m/RjRdgSfBJ6gKDQYWrRgYUg83/3zHS8OfpFrWl54yEqD5vwv+EDvB2jk3YjYrFjuirirxKimiV0n4unqSbfG3ZjSYwoAmqZVq2P9QvlX33/h6+7LA70eYMmEJXi5VW4SYe+w3vw59U9W3r6S3Q/t5o3hbxSP/unYqCMj243EZDHxUO+HKu5ncsA1LWRQ583NjOxqBv1dSkZYvrnzzay+c3W5I6caIg1eFDRNw8enO9nZe0p8P3eujIc/erSMQjrKfg05Pz8yPSDbnYpnSN54oy2Iv/3oIyAmUN7+eLcCx2ntRUEffWQdkvpS5EsUmAp4YeMLmOOtogAQHMyiFpm8kLNKznNo2pQiTfDGhpfo/HFn2nzQhvcKN8mQm0OGSOGydtoKP182Ns7FzeDG/H3zOfjP77bzW0XBYixk5PyhtJ3bli6fdKHd3HacSzpmG0mk4+8v43LPmyfLMXcu//v6PrzdvGniEcwvHSkpCs3hSo92ZYZz9g7rzdc3fc01La8h8t5Ixjcbxh9toMDfdj/2hkEX0ajMMM5R7eWP9v5VEKmd4eG+D7Ph7g008WnCsAXD+GzXZ7y6+VWGtxnO9e2ud/gTPN7/ceI8Cvm5rZHU5kE8PkpwVWhvXhj8guPfrAbxdvPmyQFP4mpw5a7ud5XYF+AZwK93/MrSCUurVWHWJK0DW5M8PZkvxn1RotO0MmiaxriO4+jRtEeZfc8Pep5ujbvxQO8HqlWuzv7tCMmDr4JOk+0B/UUdddxeYjR4UQAICLianJw9mM2yxf7OO/DEE3DLLbB8uYNRkr6+TJgI99xMxaIwapRssf/6K2mF6SR729IkWPNNcjM6Tms/Q9fOUtjlm8XPR35mYIuBHE09ymL3Y7KSB0RQEC8Phf/57+NEmwBo1IhP+sHz29+gqW9T+jXrx+vBB0ltGSqthfHjZaxp4FiAmXhfC69e+yp+Lt48+e51zP7hMYYtGMay06sB+LwPbEzcyoyBM/jmpm8wmo08FL4X0bLE0CuJpsnFBjZu5Pijd/Bji0we7vsvbg68mt/aQYGfvKYMVxNHQuFKg4M8gDsi7mDL1C20DmzN6IC+5LnDZoN1FJDBwN4w6GUqO5u5qW9T+pib8F0PcLNoTO01lWZ+zdj2wDauanEVD69+mNT8VN6+7m2ncwtGdxhNmywXPgyL4VnLBjI8YV67aVWu/KrLjGtmcOzRY7QNaltm3/C2w8uMjKkrSgtyTTC41WCiH46miW+TaqXX8vIYeA62ucgx4/2KGleQQgFKFADw9x+IECays3fy2mvw3//C7bfDokWO49cLP1+2hcPBxjiPfaQTGgo9emD8ewuDcj5k4gSKM02wWq1JLs4thUXdYM4ASsxTeLF/DiFeIay+czVdQ7vyWpcUzM3l+hAHffM4Zq0fv+xmxBISzEf9YYB/FyLvjWT+TfPJcjUzq4scZnn6szdJmCOjq270kcNYJ3S4iecCbmRDO3jqxEfsT9rPxIDfeH9MMM9cByNcr+CN4W8wpecU3h7xFuub5fFV28yy90kIzmacZc62OYwLWIu7GZ7u9hBj3buR6w6RphMA7MyWVsiVlopXY73WpT2eRbCmIBqAxJxEEn2hd77j8AWjc6VY3poUXDypqZF3I36b/BvPnmnBaydb0Tust9PzuWgGHtkJWzyT+CJ5HU9uhW7pToYQ1wIGzUCboHKCGSqck5vLIOvcT79C6FjgU7fluURQooC0FADeeMPCSy/BPffA9987nz5wztdMtgecCwBRmVVP+vXjA/PfHBLnOdqIYlFI9JETnpJcncR6Dw7mjUEw6xqKC7PTO511bS08M/C/BHgG8FLvJzncSPBTqKzQl5qj0QQMPAdfN0viV/NhToTAYwEjAegW2pUp0QY+DDrOncvupP1HHRj8zWAKTYVsdI2hZQa0dQllWl53vv4ZDu+5mrPTzjIk3p2n+6VhMsDnCX2LW9b/anUr156Gp7yiSMmT8yHMFjN3Lb+L4LeDaf1Ba55c/yQ+7j78sByaZpgYVhSOtxF+TZcT87anyTL3K6g4dpFXdj7DTsPq9O0IIdibsBeAXjmO/cK3JYXgWQSP7y35O7klJPHGNzG8sL6COPt5edy304w3boT7NuflzVwWoS4aBLm5XGMVhb6JBlzynDS+FCVQogC4uQVz8OBU3n13CHfcIZdndCnHTRvtIVvFha6QLHIqzD+2VzteuTIfF6GR6AtG5EzjBC/5nmRwXDGlmXOIbgLnfSmucDe7yYlnUzvJyOS3efWhRyI8Y1xDrjGXZVnbGXQWno+C866F3L//VZpmw21F1lU+0tN59XcLBk3j5yM/c3u32zmRdoL3tr7HJvMJhp0GLScH9/gk7t0HnSIP4Jtn4tdvjNxv6Mvnh9vR9pBtLSRDTCxz1kG2KGBh9EJAzkhdGL2Qke1G8vHojzn070PsuuZbbjkMxMbimZHDdafgl9iNCCHYnribTikQkFeJ2EcZGYw5DidzYziWeow9CbIvqGe6Yzde9yTIfQOuis6wLWsGsMy6iOD58+UvwJKSQlABrGj0KKvu/AVfT/+LKwqnT8Ozz9omMdZXvvqq4nDpF5vcXHonQIiLH0MTPWttoZ3LDSUKyH7gmTNn07LlMebNs1QYGfmAa1rx53PG8sNSW4SFxwzrMGswY78fQoP47HgswkKil1y0JUlzPPror3N/FX/WA2EdMKQQlg2NNGkKG+IT+Hg1xJpSmfLzFA7knOTWwzDyJLQkgJSCNP5vN7inWP+w8fG0yIK9bd7i9BOn+eGWHxjfaTwvR75MqiWHYaeRs5r1WdJZWbBiBd5F8GW357jb7xq5eHPxDThH9yToHdCZb/Z9A8D8ffNp5N2I727+jn/3+zedQzvbYiDFxkJ6OuOPu3AuK4YxC8fwd+zfXJnkVrn4RZmZ3HgMXA2ujP9pPKuOraJdrgf+2U76ZTIyMAhkhZBjJ+BLl9o+l1fJW2czj2w+mF5hvWSn/MUUhcWL4c03bTGw7Bk3TkZfrGvOnoUHHpCLEdckBw7I1aCqG9cqNxd3Mxzu+zUzDofU64B49QklCsD990NOjg8vv3wbmlZxFMJokYhmbXTGFJx3epzZYub+Vffzc2Ikr292YVC0DCERkxlDal4qJuvdT8LxQx91Nqr4PIeS5ZDZaJKISMLW6omPZ2AM3Nv+NpYdlq3fWw6Di4BH/Ibj4+bD/x3xsYW6sIa46NSmX3EH3nsj38NFk6bRtWewiYK+5qL+Z+/USa7rGB9vC4dhraym9pjC3sS9bDy9kZVHVnJ397tLDo+0doTronB3bDCzhs9ie9x20vLTGJDmVbk/f0YGLbMNrL1zDVmFWeyI20GvXD/nf/j0dNv6B4mJtnvw11+25eccVbg6eogLvdO/RYvyj0IwzI4AACAASURBVK9p9Ci5jlrhkZEQFXXxyuIMPeDiIQerGF4IkZFyoetjx6qX3vo8hQY2x93DW4lCJWnwohAZKRdef/HFDNq0OUhm5p8k5STJ8f9OOFAUR39rQ/pcvuNlpYUQ3L/qfr7Z9w0zh8zk6cLetLDWozFZMSTkyHSeRZCEYxdU1Lkors4OxLfIwKHkQ5gtZg6ZEog4j+0Bt7bo3xo9m0DPQK4KH0C49Tz/aXMXZ6edJcyrcRlRKK6kgbZBbZk1fBY3Nxki0+qiMGiQXH39zz+lP61dO9tiv/of9dw58PHhjv7342Zw467ld1FkKeK+XveVvBh3d5lXXBykp+MSGMyMa2Zw+onTLLxlIVNiG1VaFAgMZES764h+OJppV07j0dR2ztNmZEBb68idpCT5vny5dCU9/bTcPnvW+fl0UdCHB7duDWfOVFzOmkIXhbS0kt8bjTKwoS50dYl+jw7XcFjnyi4S5Qz9mfDxcRxdWOGQBi0KQsgVLps1g2nTZBjtzMy/+GD7B0xYMoHYrNgyaYrMRRzOj2HIGfA2wrmcOId570/az4L9C3hm4DO8PPRl6NuXFtYBOjGZMSRkS1GIOA9Jdv0Sm89sJj0/nRxjDnsS9jCk/XA6e7fkUMohTqSdoEAUSUtB/yPGxUFoKI2Dwom6N4rvb/mheGKXoUlTQrxD5Ago/Y/lQBQAnrzqSZYP+VRuZGbKyKnNm9tWjW/bVlbsuijoLqRz56BlS0J8GjGu4zgScxLp37x/mYlkgHQhxcaWWGDH38OfOyLuwNPLr9LuIz1QYbBXMLNHzWaIpaXjtELIc3XqJLf1CnTpUrl+xIgR0ooor+Wvi6kuCu3ayQq6vGB/NYnuxittKejbCY4bJRcV/Vk8dKhkv01lSU+X62mURheF886t8XLR3YW6KChLoVI0aFFYuxb+/htefBG8vTUCAq4hIyOqeETLzridZdIcTztOkTARcR5aZmmcy3LsX151dBUaGk8OeFJ+0bcvfkYIMBpKWAo9EyEPI7nGXDILMhn27TDGLBzD5jObMVlMDLruAbp0GcKh5ENEn5fDMCPOAydPynzjbBPXIppEyPHswcFyX2PruOxGjWyVW1ycrJAdLV3pb40meuqUXDTHXhT0irV9e1mR6qJw9mzxxLWpPacCcF/PUlaCji4K9msp6FR29TX7tRQqSpuTI8OH62VPSpIt7K1b4YYb5IiuZs0q5z7S72k762La+v2vbZxZCvp2YmL1KuKaRL9HmZlVt1xMJujVC558suw+3bKrCUvB2YqFijI0WFEQQopBmzZwn7UOCw4eRWHhWfYkSDHYEbejTLroJFkxdzsPLXJdOJfpuEJZeXQlA8IH2Cbe9O0LQIs8NykKVkuhh/U/lJSbxNHUo1iEha2xW5ny8xQMmoGrW1xNl9AuxGfH8+e5PzFoBjqnAMePy4Tx8bbZzDrliUJ8fBkroRhdFHQ3gCNR8PCQLpRSlgLIiV4b7t7gfAaqvSiUXhbxQkTB29txWr01rQtZYqKcmW00Qm/r3ISWLSt2HwUG2ta80F1Rp05VXNYLpajIVsmWFgW9IjYa637Uj/16E1XtV/jjD3n/16wpK24Xainoz4Svr7IUqkCDFYXoaNizB/7zH9sEtZCQG0kthPN58iHfEe9AFM5H46K50CkFWua6OhSF2KxY9iTs4aaON9m+7NIFPD1pWeBBTGYMiTmJ+JldaWv9PyflJHE0RVa0t3e7ndT8VHo17YW/hz9dQuVa0ksOLaF9cHu8mrWCE3LiF3FxZSv54GBZeetTsUu7j5yJgr7Yjb0o9O0rV2UbO9Z2XI8esoMzI0P+Ya2ioGkaI9qOcB52ITxcVm4JCVUThX/+kT+UxVJyfeaK0uounkaN5D1ISpLhRgB69pTvrVpVbCnYhxvRReFiWAoJCbaK0pmlAHXfr5CaahvDXdV+he++k+/nzsnht/bUlCh4eSlLoQo0WFFYtkw2Hm+91fadh0cYcZYrAOga2pWdcTuxiJLjww+cP0CHoPZ4mqBlvjuJOYkUmgpLHPPL0V8AGNdxnO1LV1fo04cWJu9i91GYyZMm1udWtxRcNBe+uekbnrjyCZ648gmAYlGIz44nonEEdOggLQWjUf5hSlsKTZvKil8P3dCokWwl5eWVLwoGgxQSPfhd8+ZSXH77TXY66/z737IieuMNuV067pEz9HLm5VVNFObNg/fek8uFZmY6dh8VFpZd41lvQQcGynuSmAj79skK4oorbGWPiXE+DyAlpaQo+PlJgbkYlkKsXZ9WaWvAXhTqul8hNVVajwEBVbMUcnJgxQrbs7VpU8n9NdHR7O0tn2tlKVSaBisKS5fC4MHQpFRYlViTHIZ5X49JZBuzi1vvAHFZceyM30lE0+7g6kpLo/TLx2WX7GxeeXQlHYI70KlRp5KZf/01LUZNJCUvhdMZpwkze9PE2heWlJPEkZQjtA1qi4erB3NGzeHuHncD0CqgFV6u8lwRjSOkO+TECVsLsbQovPZayXH4oaHyPTlZViDORAGkCykvTwpK6ZujM3y4tCDmzJHblRUF+/WaqyIKf1nna6xc6bxPAcr+6XVLIShIXktSkhSF7t1tLduWLaW46v7r0pS2FED2K1wMS0HvZHZ1de4+gvphKYSESGu4KpbCihXyN/vf/6Sr014UCgpsw54vxFLQnw1HlkJOjhxZpyhBgxSFQ4fkq99Nu0nOLdkKOZ4DzTyhd6Bsde6I24EQgtlbZ9Pxo46k5qVyd/e7wc+vWBTsXUiZBZlsPL2RcR3HlQ2y1qEDLdr3AWB/4n7CLD40LmUplBESwMXgUvx9RBOrKKSlSR8YlBWFli1tPnOw9S20bStb06WPt0fvV2jSxHmcD02Ti1EXFdnOVxnsRaGyncXZ2dJ9BLISyc52Lgql0+uioFsKCQlSFHTXEdjmYjhzIaWmlgxMCPI+XkxLQQ9/bk99cx+FhEDnzlUThe++kxbGNdfI9Ww3bbK5y3Qh+P/2zjw+yure/+8zk8k+2RdCAmRlXyWKoLYqKoi2al2R2uKtl7rWhWuvWmutttdqta1W6++6ISpaK7ZKbRGXor2yyCoQIJgQSEggIfu+zHJ+f5x5MpNkkgwhYSbmvF+vvDLzPOc5z3fOzHM+5/s9mxAn5ykYvw1vnsIf/6hWCu5etiOcESkK774LBDfxdOM8Tn/xdAqqCzrP5VUdYkJ0ONH2rViDrWwp28KrX73KPR/dw7np57Lvtn18Z8J3IDKSsXb1gzNEoayhjIveuAib08Y1U67xeu8xUWolUJvTRgoRWJwQZ7ZyrPEYBdUFTIj3vuqlEULqDB8BfP65+t9Xyx9Uy/6xx9RyCb/4BVzj3TbALQp9CQeo1VXHj1cPbX9pDTzTefMUWlp6djZu2aJCO4sWuTu3vfUpQE9RMEIuhqdw5IgSilmz3GkMQeuts7l7+AiUp1BS4t4fY6goLVUt3MxM76KQkKAWZAyE8JHhKVRU+FbJ1terTubrr1e/ofPOU6FNYwCFIQqZmYPrKXj+vrZvV7+tUznvZBgwYkVhykVb6HB2cLTxKOesOIdd5btoaG+gsKaQmckzaKj7lNkps1h3cB13rbuLb437FmsWr3EvYWy1kiZVR25JfQm7K3Yz+4XZ7Kvcx9+u/RtnpJ7h9d5jot3LQ6egrk+2xLD16FbaHe29LoV8QeYFTEqYpO6fna0OGqLQX6UcHq5a9r/6FTz8sDuc5A1fRcFshj/9SeXb3/LhBhER7la+N1GQsud49Y0bVaVh9F/AiXsKUVHKUzDoy1MwvB9QtjQ19fQUsrJUZTLUM5tLS5V3FRfnvU8hPl5tbnSqPIXf/EYtrdEdT08BfPMW9u9XZehatp3zzlP/jRCSIQRTp6rvYCCdxN09Bej6+zI8UC0KXRhxolBSArt2wZh5auetf9/4byxmC/Nfm89be94C4Mz0y5GynalxsRysPYjD6WDFZSu67pIVG0tomJWkiCTyq/K55p1rMJvMfHnTl1w+8fJe758W5Q6hpAhVAScHx7GzXI2K6c1TWDpzKftu26dG9mRmqopy+3Y1dKp7S/ZkMEYs+dL6nz+/a2XtC0YIyZsoQM+KfeNGNdFsxgz1B76LQm2tEgSz2S0KJhNMm+ZOExWlPI/iYnj+eZW3Ea4wKv0x3fZ5OFUjkDxFwVufQlycOyx2Kli3Tk3usdvdx4yZ1YanAL51NhvCYQx1zslRHm93UZgyRf0fSAipu6cA7hBSc7N7BF9fQ5L7Yts2/88RGQJGnCgYqzPURm5icuJkzkw7k/U/XI/FbOHmf9wMwFlZi7FYkpkQpsb2P3HhEz03OXn6aXjiCcZGj2XVnlUcqD7Aa5e/1hnm6Y3QoFASw1VLPcWsKrfkkLjOUU4+bZoSGqoqKoej6yijwcBXT2GgGKLgS8XudKqJZsZcictcQ3y7h4+MVqA3T8EQH6PTfMIEd3qDcePUeif33KMqDaNSMyoLw5swMCawDXW/QlmZWxSam90794F3T2HfPnj11aGzp6BACYKnh2SIVXy8CsWFh/smCvn5qkGT4dorQgg46yzY6pow6ukpeL4/Ebx5CobHkZfnrtAHIgobNsDpp6u1mb5hjDhRKC4GhJP8pk3MS1OVTXZcNp/c8AnxYfGMihzFaGsaiYnfY2rwDjbc+Bm35N7SM6PZs2HmTMZGq5j08rnLmZ853ycbjBDSqCBVMSaFqpZ+bGhsp2D0i9GvMNiV96kSBV88hX37VOzZEIWlS9WcCcNj6Ota6Dpz2vAUPENHBmPHqkrCWDjPGC9vVBbp6V3TjxqlhHkoPQWn0y0KRll5hpBqanp6Cv/zP2p1x/b2nvmdLM3N7tFQBe4+uC5rQ5lMqmVvDIDoi/x89Rs2JgWCEoCiInWvigpVkRuicbKegiEKhqdghI6iorqKQlubb63/Ha7te/PyTtyuAGdEioJI+Jr6jlrmjpnbeXxK0hQ2/WgT717zLkIIEhOvAtlKTlhVr1s1AlycfTELsxfy6/N/7bMNRmdziksUkl2iMCFhQp/36oLRrzDcRGHGDNVq777HqWfF/te/qmG1L76ojhmikJGh5kwYM7a7X+ttSKpRoaamqgroDC99PYYn8OqrqmIzPIDiYhV66l4WJpMKIQ2lKBw/rlrlhqcAXUXBM3xUW6uEYMOGoes4NUIt0LsogPp+d+3qv2LNz3eHjgwMr2D/fvX5k5Lc/V8n6ykY4SPDU9i9W/0G581zi0J1tbqfsddGXxjCN9AVXAOYESkKMVM3ATA3bW6XcznxOcwboyqg6OhvYbEkUFnZ+2qpADeddhNrl6wlJMjHzlbUqqSRwZHEBqswSHKY+uH31p/gleHqKdxyi6pgum9aYTy8dXVq3ZGHHoJnnlECYghgb/jiKcTEqD6YW7x4fXffrfZevfpqVQl7egqGmHQnK2tow0fGcFRPUTBCNR0dqvPVCB+B+myGGHhW4IOFpxD0JQrTp6sRW311fnd0KEHtLgpG/8HevUoEkpPdw6kHK3xkNBx27VJ9SxkZ7nLbtk2V69q1/edteAh9iUJ+/tCG84aIEScKhw9DcPZGYkJj+ozfm0xBJCRcQXX1Bzgcgzs9/r6z7+OTGz5BuEbtJIcPQBSMirK/4agnSm6uau0ZbvtgYzartWi6Yzy8f/+7Chm98QZ88onq3OzPe+pr9JFnmGr6dO8jpbKy4Npr1euMDLcoHD7csz/BwPAUTqaj0W6HBx7wHtP2FAXjMxiiYHgMhqcAXVu3QyEKRuVnzKY38CYK4A7PeKOwUPWHGaOVDLKyVD9DXp7bU4iMVN+ZET5qbOx7Fzqn033v3jwFKVWa6dPV91tbq/I1lkDZtKn3/EFd74so/PzncOONvU+MDFBGnCgUF0Nbwibmps3tOprIC4mJ1+BwNFFZ+c6g2pAUkcSctDmdk8MyotMBmDFqRh9XdWPaNNXannACQuIL553nXgriVGI8vG+9pdz6K69Uo5u69x/0da03Uejeod0fnhPTiot7F4UJE9T9Snsur+4zmzap+SPedk8z4vepqT09Bc+VWw1PYfVq1Rq2WofOU0hJUX0yvojCrl2952Uso9LdUwgKUkJheApJSapBkJSk3jc3q/6dP/6x97zfe0/9Zl54QQ0v9uYpHDmiGh4zZri/3+Ji9bsHFb7qa5HBI0eUiKSmqtfehsu2t8OHH6rXH3/ce14ByIgSBbsdjlTWUx+8r0foyBuxsecTHj6ZI0eeQg7F0DPXSnxT4yexY9kOLs6+2PdrMzPVw3nppYNvlz8wHt6qKvWZQkN9vzY4WHkgnqJgs6lQQPcO7f7IyFAdt01NXXef644xrNVbp2r3NZh6wxi5snp1z9ZvaalqNCQm9uxT8BzxY3gKJSVqzH9OzomJQlWVbyNoCgrUZMWcHOVJGfM5ampUS96odGNj1ci4vjwFYziqtwaN0VFtiAKo/5WVal5OTY3yJntjoxpqzk9+ov578xQMwZo+3T2IoLhYeQpGH8bmzb3fw/ASrrhCeQ3e+pY++8y9n4MhDsOEESUKR4+CM24/CKn22+0HIUyMGbOc5ubd1NZ+OvgGGa3YyEhmpczyvZPZwJiv8E3AeHih6yqFviBEz+Wz6107Gp2op2CEzTZsUJV795FHBkanaPfRJw6Hqux+8IP+xeFf/1JidvSouzIzyMtT4RSTSQ3BFcItBsb/uDh3axrUkE5jXSxQwpKdrcJwvfHkk2pEV3+bBn39tRKEnBz1uYw4vDFxzfN3OH1636KQn6+Ew1sYcepUZbfd7haFxEQlEkaLe+PG3kdYbdumxMv4PXnzFAzbpk1zi/7evUr4li5VZd5XCMloCFzumo/kLYS0Zo2655VXqsERfYW8AowRJQrFxUDMYQDSY9J9uiY5eQkWSzKlpU8NvkHf+576gRshgJGMZ4tu4cKBXe8pCp5LXJwIxsQ0YxJVb55CTIyK93f3FPbuVS3H11+H//xPVRnU1KiK+uhR94zalhZV8fznf6qW9jseIUopVUt1rsubNZnU/byFjywW94zrs89WInD4sGrJf/ihsuWGG3of0vnVV8pGY4ilN+rr1fWGKIA7hORtwcDp05U30FvF7W3kkYHR2QxdPQVDFCIiVGt/S89l7XE6VYf7hRfCSy+pY4Yn5Tl5betWVU5Wq+rMDg5W3oeUqgynT+9bFPLy1Hd/+unqfXdRkFKJwoIFSjgqK939FcOAIRUFIcRCIcQBIUShEOI+L+eXCiEqhRBfuf562Z1lcCguBqJVp9646F4e9m6YTCGkpd1BTc2HNDUN8phki8X94I90wsJU5bdoUVevwVeMtZMMPBfDOxEMT+Gzz9T/3kQBVEuzuygYYYcbb4QVK5QoxceryjQ1VeV/9KjyRGw2VWksXNg1hFRUpMI6xhIQ0HWpC8/wEaiKz2RS6bOz3RPMPv9cjSarrVUjuryFQA37t21T/5ub1XpEB9yrA3cKgBE+8jzmTRRmzFA2GH0HnkjpuygYEw4TE1Uob+9euOMO5ZV0X2YbVOXc1KQGS1xxhQpzGeFVw1NobFTXnn++em8yqe/Y8NRmzVLP5ObNvXt6eXnKozGWT+kuCjt3Km/nu9+Fiy5Sx9at855XADJkoiCEMAPPARcDk4HFQghv033fllLOdP29NFT2gNtTiA+Lxxpi7Te9wejRN2MyRXDkyONDZ9xIRwi1zMSjjw7s+sHyFIyJaUYl2dcKsFOnqhax57IPmzerlvvLL6sO0WuvVSGa115T72tq1Mbgn36qOlbPPlstUOgZQjJaqd1FwTN8ZDa753pkZ6uKMCrKPSqtsFBthHTRRfD44/DBB2pElyc1Ne49u43P+9FHqrP/V79yp/MceZSYqO7Tn6cA3kNIZWWq4u4+8sggI8Pdqvf0FIwK+tprVWe3IdqeGJ/Btcsh6enuoc9Gnp99ppbkvvBC93XjxilBjotTHsC8ecrGvXt73sNuV9+50ac0fnzXjndQS7ybTHDJJcr2005TnsOvf60+3zPPBPTyGEPpKZwBFEopi6SUHcCfgcv6uWZIKS4GS9JhxsX45iUYWCzxjB59MxUVb9Laeor25h2JLFvWe2XRH5GRXUMkA/UUhFAPrsOhWqp9dXhPm6bG3HtWCps3q8pcCLj9djUKZvlyFcK5/Xa48041dv3111W6iAi1q11IiKqMjTwiI7u2mj1FwZi4ZsTxX3xRVTrgXoLjk0+Ut/Dtb6tO1wkTeo6ZN7yE+Hh3hWrE7d9+2z2UsqBA3SsrS/33HJbqTRRyctTn+b//U63mIx77mBuCZ/TJdMdkcq+h5CkKoARp+nQ1Qm7jxp6LJ27bpjwCb16IxaKE9NNP1WcwPAVwe4MzZ6pzhvfuLYRUWKjCYob948d39RR27lSjyc4/391pvWABfPklPPigagjceadqCDQ29sz/wAG1T4kfRWMoRSEV8NzVvtR1rDtXCiF2CyFWCyHGeDk/aBQXgzmu2Of+BE/GjFmOEBZKSrS3EJAsWKAqCqOiM+YadJ/97AtGCKmv0BH07Gyuq1OtSM8Wfnd+9jNVWRw96q6YrFa46irVkm9qUqJwxhnujYBAeTyenoJnRRwf7w61pKSoVvFrr6n33/62quiuvlq1kj0ngRl2L1miyqumRonCtGkqtPXCC+p8QYHymAyBzM5Wx6T0LgpBQaryfvFF1UqeOdM9Euett5Stxix1b0yZomw28jUq1wsuUKJx7rmqYn77bRUeWrRIifi2bSr8422yoTEYoaNDeRKevwvjezaWVM/MVJ/35ZfdIb3HH1d2L1ig3nuKwvHj6rs/dEjZEhsLK1e681+2TIUTN2xQlf7jj6u9QW68sWvlL6VqPNx9t7vs/YC/O5r/DqRLKacDHwMrvSUSQiwTQmwTQmyrHOiGG8DhYokt4jDprnkBJ0JISAopKT+ivPxV2tpOYmy6Zmi4/XbVuv7Nb1RF9cQTams9zyWzfcUQhd5GHhlMmqQqKUOIjM7PvkQhOlqFEcBdwQDcfLMKa7zyihoy2T2P7n0KvYmdEKrSPn5cpTG8jauuUhXce++50+7ZozwpYzns1atVS/imm1Q/x/PPq/Qffti19T1+vGphHTigwinebHnlFfX39NPK3jfeUBXnP/4B113XVfC6c+utqoyMyt2YXW+U1znnqHJfulR5RGvXqtb1zp3u0JE3jBCSEec3ML5nY10sIdT9t25V3tXGjWovkpwcJXLXXOMWBaOP5YUXlFi1tany8pxUmp6uymLePGX3T3+q8n/3XTWT3mD1anXPlBS1J7m/lvSWUg7JHzAXWOfx/n7g/j7Sm4H6/vKdPXu2HAhOp5Sh8RWSh5FPb356QHm0th6Wn30WJPPzlw3oes0Qs3y5lCaTlJdeKqXZLOWePQPL58knpQQp7723/7QTJkh5+eXq9S9/KaUQUtbX932N0ynl/v09j02dKmVUlLr3mjVdzz/4oPpsDoeUM2eqz9gbV1yh8rjssq75Z2dLeeGF7mPz5kl5zjlS1taq9FlZ6v++fVL+4x/qNUg5bVrXsty/X8qICCnHj1fnX3ml7886e7aUkyZJ+fLLKv2XX/ZdPt7yWLtWSrvdfWzxYlUGhw9LuWiR+r5Bytdf7z2f9HSV5rPPuh4/dEjK3Fwpy8q63vPss6VMSFDlkp4uZUNDzzz37nWXU06OlFu2+PaZbDYp58yRMjZWyqNHpezoUN/P1KlSFhVJabVKed55Ura3+5afDwDbpC91ty+JBvIHBAFFQAYQDOwCpnRLk+Lx+gpgc3/5DlQUKiqkZPQWycPI9/PfH1AeUkpZUHCXXL9eyPp6H798zamjrEzK4GD1s77nnoHn89e/qjyefbb/tFddpR5mKaW8+GL1UA+U555zVzDHj3c997vfqeO1tVKOHSvlD37Qez733qvS/u53XY/ff7+qPKuqVKUXFSXlrbeqczk56pq0NHXO4ZDy+9+X8pFHvFdMb7/ttvX9fp6nlStVulGjVAXrdPZfFidCcbESKegptp5MmqTS+VrR7typhNibkBi0t0t5wQVS3neflC0tJ2Z3fr6UoaHKpmnT1H0++ECdMwQ0O1vK1aul3LpVynXrlGAPEL+LgrKBRcDXwEHgZ65jjwDfdb1+DNjrEoz1wMT+8hyoKGzZIiWT/yJ5GLmrfNeA8pBSSputXm7YkCK3bp0tnU57/xdoTi333KMqnv5a631RVCSlxSLlpk39p334YeUdrFunWn033TTw+9bXqwoiK6vnuRUr1ON68KCUkZFS3n137/kYFcqOHV2Pb9+ujr/0kmphg5TPP6/OLV6s3t94o+/2Ll+urtm2re90bW1SJiWptA8+6Hv+J8KKFcrrcTh6T7NggZTXXHNi+T77rG+Ng4HyxRdS3n678lQWL+4qmGvXKiEzxBek/OlPB3yrgBCFofgbqCi8846UzHtC8jCyrrVuQHkYlJe/JdevR5aW/umk8tEMAU6ncsVPltZW39J9+GHXh3bFipO77yuveA+BvP++yv+WW9T/Rx/tPY/WVlWhdMfpVB7BmDFur+SLL9S5p55S799803db7XYpN2zwreX/0EOyMzTlL1pafP9eA4WODhVKXLNGfVeeIa4TxFdRECrt8CE3N1duM4bPnQAlJfAfq29ne8cqau/rY7ErH5BSsmvXfJqb9zBnThFBQb7PedB8Azl4UA27bGhQHbSuNa0GlT173OP/U1Nh1So1suhE2blTjXqqr1cyVlfn3o703nvVTGBj+fTBpKNDfYbZswc/b41PCCG2Syn76Il3pRspogBw6ZuXUtZYxs4fn/yU84aGLezYMYf09EdJT3/wpPPTaPqlrExV4N7WDDoRNm9Wk7fi4/Wm9SMIX0XBy4Deby7F9cVkxWYNSl5RUWcQH38ZR448SWrqrVgsAxgPr9GcCIO18dGZZ8IXXyjPRqPphr/nKZwypJQcrjs8YktfeAAAFxVJREFUoIlrvZGR8SgORwNHjvx20PLUaE4JM2ao8f4aTTdGjCjUtNbQ1NHk80J4vhAZOY3k5CWUlPyWioo3By1fjUaj8RcjJnxUXK9WRx1MTwEgJ+d52ttL2b//+zgcLYwePaQLvWo0Gs2QMmI8hcN1h4HBF4WgoEimTfsncXEL+PrrZTQ0fDmo+Ws0Gs2pZMSIwozkGTyz8Bmy47IHPW+zOYzJk/9CcPAoCgruQMrhs8uSRqPReDJiRCErLos75txxQvsonAhBQVYyM5+gsXEr5eUrhuQeGo1GM9SMGFE4FSQnLyE6+myKiu6jvf2Yv83RaDSaE0aLwiAihCAn51kcjhZ27JhDY+Pw2ZdVo9FoQIvCoBMZOYNZs74AJDt3nk1d3ef+Nkmj0Wh8RovCEGC1zuK007YSEpLG/v03YLfrmaMajWZ4oEVhiAgJGcXEiStpby/j4MHl/jZHo9FofEKLwhASHX0mY8bcy7FjL1FV9b6/zdFoNJp+0aIwxKSnP0xk5Ezy8q6ktPRZhtuqtBqNZmShRWGIMZtDmTnzc+LjF1FYeAdff70Mp9Pmb7M0Go3GK1oUTgFBQVFMnfoeY8f+jGPHXiIv77vY7U3+Nkuj0Wh6oEXhFCGEiczMXzF+/IvU1HzM9u25lJY+Q0dHlb9N02g0mk60KJxiRo++ienT/4nZHElh4Z1s3jyO+vqN/jZLo9FoAC0KfiEu7iJyc7eRm7ubkJBU8vIuo7X1oL/N0mg0Gi0K/iQychrTpv0DKZ3s3n0JLS2F/jZJo9GMcLQo+Jnw8BymTn2P9vZStmyZyIEDy+joOO5vszQazQhFi0IAEBNzDnPmFJKaeivl5a+yffvpNDXt8bdZGo1mBKJFIUAICRlFTs4znHbaJqS0s3PnPEpLn6GtrcTfpmk0mhGEFoUAw2qdzezZW4iImNo5Omn37kv0vAaNRnNK0KIQgISEpDJr1kZOP30/6em/pKbmQ/bsWYTd3uhv0zQazTecIH8boPGOEIKIiIlERDxEePgE9u1bws6dZ5GcfAPR0edgMgUjhIWIiCkIobVdo9EMDloUhgFJSddiMoVSVPQARUU/7XIuPv47TJy4Eosl1k/WaTSabxJaFIYJCQmXkZBwGe3tR2ls3AZImpv3c/jwz9m+PZf4+EXYbDXExs4nJeU//G2uRqMZpmhRGGaEhIwmJOS7gBKKmJhvk5//AyoqVmEyhXD8+Js0N+8hK+spHVbSaDQnjBaFYU509FzmzCkAQEoHhYXLKS39A5WVf8PhaEJKGzEx5xIXdzHJydcTFBRFa+tBioruJzb2AkaPXubnT6DRaAIJLQrfIIQwk5PzByIiJlNTs5bg4FFI6aC29mOqq9dQVHQfCQmXU1n5F5zONior38HhaGLMmHv8bbpGowkQtCh8Axk9elkXD0BKSWPjNo4c+S0VFa8TF3cxOTl/pKjovzl4cDmtrYWMHv1jLJYEystfpbl5P2PH/jeRkdMGzaaKilU4nW2kpPyoy3GHo5nDhx8lKmoO8fHfwWTSP0mNxp+I4bY9ZG5urty2bZu/zRi2OJ02TCaL67WdgoLbOHbsZcDRmcZkikDKdkaPvhm7vY6Ghs3YbFU4HC1ERs4gJeUmoqLmYrNVYbHEERk5AwApnTQ2biMkJI2QkNGd9zh48G7Kyp4FTOTmftVFbPLzb6S8/FUAgoNTycp6guTk60/4czU35yOEIDx8wsAKRqP5hiOE2C6lzO03nRYFTUdHJZWV72CzVZGUdD1BQTEcPPhfVFSsxGJJIjr6bEJCUhEimNradTQ353W5PiXlx6Sm3kJh4d3U1a0HVAUfFBSN3V5PR0cZqam3U1HxJlbraUyf/hFCCMrLXyM//4eMHfsAUVFnUFz8GI2NXzJmzH+RmfkbhDD7ZH9V1d/Zt+8awMSUKe8SH7/Qa7q2thKCg1M6RXEwqKn5iIKC25k8+c9Yrad1OedwtCFEkPZ+NAGBFgXNSWO312M2RyGE6DymQlFbaWs7jMWSSE3NWo4ceQpwYjZbych4FICGhq1I2Y4QQcTHX0Zy8nWUlj5DYeGdTJ78Z+z2BgoL78JqPZ2ZMz9FCDNOp43Cwrs5evQ5IiNnkZZ2F4mJV2M2h9HRUcnx429SW7seqzWX2Nj5SNlBff1GDh36OVbrLKS009ycR07Os4watRSTKaTT5iNHfktR0X1ERExjwoSXiYpyPxv19RtpaNhCaGg6ERFTCA/P8VoeUkpKSh6jo+M42dlP4XS2sWXLZNrbSwgNzSQ3dwdBQdGusmtgx445OJ0dTJr0BtHRcwf0HbS3H6WycjXx8ZcQFpY1oDwAams/w2Y7jtkchdV6GsHBSV3OO53t1Nd/QUzMef2OWnM6O2hrKyYsLKtHWru9nqam3bS2FhAZObOHUA4UKZ0BO5qutfUQISFjehV/KSU2WxXBwYmn2LKuBIQoCCEWAk8DZuAlKeVvup0PAV4DZgPVwLVSysN95alFIfCor99EZeVfSEu7h9DQMb2mczptbN06jdbWAwBERs5i2rQPOkNNBhUVqygu/hUtLfkACBGMlHbASUjIWNrbuy4SGBt7EVOmvAs4yMu7grq69QQFxRAf/x1CQ8fR0nKAysp3iIu7mKamXXR0lBMbO5/w8Mk0NW2nvv6LLvnFx3+HtLQ7qa1dz/HjfyYq6gwyMh6lpOQJjh17AYBRo24kKCiO0tKnyMz8rasT/zKmTFkNwL59i6msfIeQkNG0tx8jLu5CWlsPYrNVYbXOJjJyJnZ7HTZbDcnJ15OQ8D1stmqKiu7DZAomM/MJHI4mvvrqW7S2qtFlUVFzycn5I1brbADq6v6NzVZDWFg2FkscUtqw2WppadmPw9FAUtJigoKiKC5+jEOHHuj8fEKEMGrUUsaM+S/Cw7NxOFrIy7uC2tqPSEj4HpMmvU5T004OHryXuLgFjBv3UGfDoLr6QwoLf0JrawEWSyJxcReTnv4wYWEZ1NdvYM+e72C313Z+b1OmvEtCwqVUVv6N6uo1pKc/Smhompffhp2Gho2YTCFERc3pPC6lpKzsGQ4depDU1DvJyPglQphpatqD2WwlLCwdUBVzS8s+YmLmYzaH9vob7HnfdpqadtHSsh+zOZrg4FFYrbmdFXxHRwUORzNhYZlerrVx6NDPOXLkceLiFjFlyrs97u1wtJGfv5TKyr8wceJKRo26AafTTnn5CqKjzyIiYjJOp52iop/S1lbM+PH/S3Bwgsf1rVRVvU9c3EVYLHE+fy5v+F0UhPL9vwYuBEqBrcBiKeU+jzS3AtOllDcLIa4DrpBSXttXvloUhjcNDV9SXr6S5OQlREXN6+KFeCKlpLb2UxoaNuFwNGMyhZKUdDUREVPo6DhOff0GzGYroaHjCAvL7sxHjbb6hIqKN6it/aRzb4r09IcZN+5B7PZ6iosfoa7uc1pa8rFYEhkzZjmJiVfS3l5GTc06Skufwm6vAwQxMefS0LAZp7MVgLFjH0CIIIqLHwEgJeUmJkx4kZKSJykqupfIyFlYrbkcO/YiGRn/Q2rqrRQW3kNDw0bCw6dgscTR2LiV5uY8goLiEcJMR8dRYmLOp7k5D7u9BikdhIXlIISFtrZDTJq0itbWAkpLn8ZmqyIz8zHq6/9NVdV7fZa1xZJEbOyFHD++iqSkJYwbdz82WzUVFW9QXr4SKe0kJl6JzVZJXd3nJCd/n4qKN1zCW4zZHOUSl+tJTLySsrJnqatbT1hYDqmpt9HQsJXq6veRUjJ69M0cPfocISFjyc7+PSEhYzlw4EaamnYRE/Ntams/6bRpwoQXaW7eS0XFKgCCgxNpatqD3V4NQFTUWYwatRQhBFVVf6e6+n3CwibQ2nqA6OhvI6WNhoaNgCAh4XuYzZFUVLwBOAgKiicp6RpMpjAcjkZaWg7Q0pJPaGg68fGXEho6DputmtbWgzQ2bqGp6SuktHUpt7CwCWRkPEJj4w5KS/+AlO2EheUQH38JcXGXEBExhbq69ZSVPUtDwyZiYy+ktvZj4uIWkZ7+Cxobd+BwNBAcnMyxYy9RX/+Fy/5Cxo9/noqKN6iv/zcmUxjZ2X+gpmYtVVXvIUQQwcGjmTjxFSyWZJqbd1NU9ADt7cWEhIxh0qQ3iYk5+4SfOYNAEIW5wMNSygWu9/cDSCkf80izzpVmkxAiCCgHEmUfRmlR0JwIUjpwOtsxm8O9nHMCoocw2Wx1VFd/QHT02YSFpdPWVkpJyWNEREwhNfVWpJQcOvQAVVXvM2vWF65WuuTYsZcoK3uW5ubdxMYuYPr0f/Ya8pBSIoTA6bRz9OhzHDr0c8LDJzBhwivYbNXs378Em62a6dP/QWzsfAA6OqrYv38JtbUfYTKFk57+EDEx59PaehCHox4hLJjNVsLDJ+JwNHLw4L00NGwkOfmHTJz4cpc+mvb2Y5SVPUNZ2Z9wOJqYNOk1kpOXUFW1hq+//jGJideSkfErysr+2OllhISMJS3tJ6Sm3t4ZmmtrK+HAgR9RW/sJVmsu06b9szNMYrPVsXv3QpqaviI9/WHi4xexd+/VtLZ+DUB09LewWOLp6KggNDSDhITLsdkqKCl5otMbFMJCZubjpKXdRXn5CgoKbiM4eDSpqXdgsx3n6NHncTrbGT36x8TEnE95+Uqqqz9AiCDM5nDCwnIID59Ac/NeGhu3AqpqMZsjsVpzsVrPICrqDCIipuFwNNPSsq+Ll5qcfANWay41NWuprV2PlO2dZWixJJKd/TTJyYs5evRFvv6655wfIUKYNOk14uIWsWvXBTQ2fonJFE5W1pNUVr5LXd2ngCA7+2miouayd+/3aG8/0nl9RMQM0tLupLj417S1HSI7+3ekpd3p/cfeD4EgClcBC6WUN7ne3wDMkVLe7pEmz5Wm1PX+oCtNVbe8lgHLAMaOHTu7uLh4SGzWaE4Eo2Lvfqy5OY+wsCyvQtQbDkcLJlNop4jY7fXYbNU9whZSOjh+/B2io+cSGjquX/uam/P6XDTRbm+go+NYn6O2amo+wulsIy5ukde4uZSSurp/ERV1JmZzRJdzTmcHdnt9p1DY7Q1UVr5DVNRZRERM9Ho/p9NGW1sxJlMwQUExBAVFdTknhKlT4ByOVqR0EBQU2WdZgBpQYbfXYbEkEBQU3WuZOJ12qqs/IDR0HFbrrM7jDkcztbXraWnZT0zMt7Bac7sIbV3d/9HRUYHVmovFkoDNVoHZHElwcDIANlsNJSWPM2rUUiIiJiGlg7Ky5wkNTSch4VJXmmqXV2UiKCia2Nj5CGHGbm+goOA2kpIWEx+/qN/P6o1vlCh4oj0FjUajOXF8FYWh7M4vAzx7HdNcx7ymcYWPolEdzhqNRqPxA0MpCluBHCFEhhAiGLgOWNMtzRrgh67XVwH/6qs/QaPRaDRDy5DNqpFS2oUQtwPrUENSX5FS7hVCPAJsk1KuAV4GXhdCFAI1KOHQaDQajZ8Y0qmWUsp/Av/sduwhj9dtwNVDaYNGo9FofCcwpwhqNBqNxi9oUdBoNBpNJ1oUNBqNRtOJFgWNRqPRdDLsVkkVQlQCA53SnAD0OjEuABlO9g4nW2F42TucbIXhZe9wshVOzt5xUsp+l2oddqJwMgghtvkyoy9QGE72DidbYXjZO5xsheFl73CyFU6NvTp8pNFoNJpOtChoNBqNppORJgov+NuAE2Q42TucbIXhZe9wshWGl73DyVY4BfaOqD4FjUaj0fTNSPMUNBqNRtMHI0YUhBALhRAHhBCFQoj7/G2PJ0KIMUKI9UKIfUKIvUKIO13H44QQHwshClz/Y/1tqydCCLMQYqcQ4gPX+wwhxJeuMn7btTqu3xFCxAghVgsh8oUQ+4UQcwO5bIUQd7t+B3lCiLeEEKGBVLZCiFeEEMdd+6EYx7yWp1A847J7txDitACw9beu38JuIcTfhBAxHufud9l6QAixwN+2epxbLoSQQogE1/shK9cRIQqu/aKfAy4GJgOLhRCT/WtVF+zAcinlZOBM4DaXffcBn0opc4BPXe8DiTuB/R7vHwd+L6XMBmqBH/nFqp48DXwopZwIzEDZHJBlK4RIBX4C5Eopp6JWGL6OwCrbV4GF3Y71Vp4XAzmuv2XA86fIRoNX6Wnrx8BUKeV01D7y9wO4nrnrgCmua/4kPLdWG3pepaetCCHGABcBJR6Hh6xcR4QoAGcAhVLKIillB/Bn4DI/29SJlPKYlHKH63UjqtJKRdm40pVsJXC5fyzsiRAiDbgEeMn1XgDnA6tdSQLCXiFENPAt1DLtSCk7pJR1BHDZolYvDnNtPBUOHCOAylZK+W/UUvee9FaelwGvScVmIEYIkXJqLPVuq5TyIyml3fV2M2oDMMPWP0sp26WUh4BCVN3hN1td/B74KcYG04ohK9eRIgqpwBGP96WuYwGHECIdmAV8CSRLKY+5TpUDyX4yyxt/QP1Qna738UCdx8MWKGWcAVQCK1yhrpeEEBEEaNlKKcuAJ1GtwmNAPbCdwCxbT3orz0B/9v4DWOt6HXC2CiEuA8qklLu6nRoyW0eKKAwLhBCRwLvAXVLKBs9zrh3pAmKomBDiUuC4lHK7v23xgSDgNOB5KeUsoJluoaIAK9tYVCswAxgNROAlpBDIBFJ59oUQ4meo0O0qf9viDSFEOPAA8FB/aQeTkSIKvuwX7VeEEBaUIKySUv7VdbjCcAld/4/7y75unAV8VwhxGBWKOx8Vt49xhTwgcMq4FCiVUn7per8aJRKBWrYXAIeklJVSShvwV1R5B2LZetJbeQbksyeEWApcCizx2AI40GzNQjUOdrmetTRghxBiFENo60gRBV/2i/Ybrnj8y8B+KeXvPE557mH9Q+D9U22bN6SU90sp06SU6aiy/JeUcgmwHrXXNgSIvVLKcuCIEGKC69B8YB8BWraosNGZQohw1+/CsDfgyrYbvZXnGuAHrtEyZwL1HmEmvyCEWIgKfX5XStnicWoNcJ0QIkQIkYHqxN3iDxsBpJR7pJRJUsp017NWCpzm+k0PXblKKUfEH7AINdLgIPAzf9vTzbazUe72buAr198iVJz+U6AA+ASI87etXmw/F/jA9ToT9RAVAu8AIf62z2XXTGCbq3zfA2IDuWyBXwL5QB7wOhASSGULvIXq77C5Kqof9VaegECN/DsI7EGNqvK3rYWoeLzxrP0/j/Q/c9l6ALjY37Z2O38YSBjqctUzmjUajUbTyUgJH2k0Go3GB7QoaDQajaYTLQoajUaj6USLgkaj0Wg60aKg0Wg0mk60KGg0pxAhxLnCtaqsRhOIaFHQaDQaTSdaFDQaLwghvi+E2CKE+EoI8b9C7R3RJIT4vWuvg0+FEImutDOFEJs91uc39hLIFkJ8IoTYJYTYIYTIcmUfKdz7O6xyzVzWaAICLQoaTTeEEJOAa4GzpJQzAQewBLU43TYp5RTgc+AXrkteA/5bqvX593gcXwU8J6WcAcxDzVYFtQruXai9PTJRaxtpNAFBUP9JNJoRx3xgNrDV1YgPQy3w5gTedqV5A/ira7+GGCnl567jK4F3hBBWIFVK+TcAKWUbgCu/LVLKUtf7r4B04Iuh/1gaTf9oUdBoeiKAlVLK+7scFOLn3dINdI2Ydo/XDvRzqAkgdPhIo+nJp8BVQogk6Nx/eBzqeTFWKr0e+EJKWQ/UCiHOcR2/Afhcqh30SoUQl7vyCHGtj6/RBDS6haLRdENKuU8I8SDwkRDChFq18jbUBj1nuM4dR/U7gFoq+v+5Kv0i4EbX8RuA/xVCPOLK4+pT+DE0mgGhV0nVaHxECNEkpYz0tx0azVCiw0cajUaj6UR7ChqNRqPpRHsKGo1Go+lEi4JGo9FoOtGioNFoNJpOtChoNBqNphMtChqNRqPpRIuCRqPRaDr5/06VZH8yyD8yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1000us/sample - loss: 0.5078 - acc: 0.8827\n",
      "Loss: 0.5077504219976665 Accuracy: 0.88265836\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7356 - acc: 0.4780\n",
      "Epoch 00001: val_loss improved from inf to 1.38018, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/001-1.3802.hdf5\n",
      "36805/36805 [==============================] - 108s 3ms/sample - loss: 1.7355 - acc: 0.4780 - val_loss: 1.3802 - val_acc: 0.5742\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0925 - acc: 0.6802\n",
      "Epoch 00002: val_loss improved from 1.38018 to 1.06180, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/002-1.0618.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.0924 - acc: 0.6802 - val_loss: 1.0618 - val_acc: 0.6818\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8372 - acc: 0.7592\n",
      "Epoch 00003: val_loss improved from 1.06180 to 0.87792, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/003-0.8779.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.8371 - acc: 0.7592 - val_loss: 0.8779 - val_acc: 0.7421\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6671 - acc: 0.8110\n",
      "Epoch 00004: val_loss did not improve from 0.87792\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6672 - acc: 0.8110 - val_loss: 1.3958 - val_acc: 0.5989\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5560 - acc: 0.8444\n",
      "Epoch 00005: val_loss improved from 0.87792 to 0.82548, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/005-0.8255.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5561 - acc: 0.8444 - val_loss: 0.8255 - val_acc: 0.7389\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4689 - acc: 0.8694\n",
      "Epoch 00006: val_loss improved from 0.82548 to 0.70012, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/006-0.7001.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4689 - acc: 0.8694 - val_loss: 0.7001 - val_acc: 0.7957\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4057 - acc: 0.8852\n",
      "Epoch 00007: val_loss improved from 0.70012 to 0.47251, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/007-0.4725.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4058 - acc: 0.8852 - val_loss: 0.4725 - val_acc: 0.8588\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3541 - acc: 0.9009\n",
      "Epoch 00008: val_loss did not improve from 0.47251\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3541 - acc: 0.9009 - val_loss: 0.6097 - val_acc: 0.8216\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3116 - acc: 0.9137\n",
      "Epoch 00009: val_loss did not improve from 0.47251\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3116 - acc: 0.9138 - val_loss: 0.4936 - val_acc: 0.8579\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2773 - acc: 0.9225\n",
      "Epoch 00010: val_loss did not improve from 0.47251\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2774 - acc: 0.9225 - val_loss: 0.5309 - val_acc: 0.8428\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2565 - acc: 0.9286\n",
      "Epoch 00011: val_loss did not improve from 0.47251\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2566 - acc: 0.9285 - val_loss: 0.5982 - val_acc: 0.8190\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2258 - acc: 0.9377\n",
      "Epoch 00012: val_loss improved from 0.47251 to 0.38863, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/012-0.3886.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2258 - acc: 0.9377 - val_loss: 0.3886 - val_acc: 0.8870\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1987 - acc: 0.9461\n",
      "Epoch 00013: val_loss did not improve from 0.38863\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1987 - acc: 0.9461 - val_loss: 0.8586 - val_acc: 0.7645\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1813 - acc: 0.9501\n",
      "Epoch 00014: val_loss did not improve from 0.38863\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1813 - acc: 0.9501 - val_loss: 0.4898 - val_acc: 0.8470\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1649 - acc: 0.9536\n",
      "Epoch 00015: val_loss did not improve from 0.38863\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1651 - acc: 0.9536 - val_loss: 0.3895 - val_acc: 0.8908\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9603\n",
      "Epoch 00016: val_loss did not improve from 0.38863\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1481 - acc: 0.9603 - val_loss: 0.4711 - val_acc: 0.8609\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9644\n",
      "Epoch 00017: val_loss did not improve from 0.38863\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1355 - acc: 0.9644 - val_loss: 0.7698 - val_acc: 0.8015\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9679\n",
      "Epoch 00018: val_loss did not improve from 0.38863\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1228 - acc: 0.9679 - val_loss: 0.5227 - val_acc: 0.8442\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9709\n",
      "Epoch 00019: val_loss did not improve from 0.38863\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1117 - acc: 0.9709 - val_loss: 0.4380 - val_acc: 0.8677\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9759\n",
      "Epoch 00020: val_loss improved from 0.38863 to 0.37559, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/020-0.3756.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0970 - acc: 0.9759 - val_loss: 0.3756 - val_acc: 0.8942\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9786\n",
      "Epoch 00021: val_loss did not improve from 0.37559\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0872 - acc: 0.9786 - val_loss: 0.6044 - val_acc: 0.8418\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9776\n",
      "Epoch 00022: val_loss improved from 0.37559 to 0.33540, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/022-0.3354.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0876 - acc: 0.9776 - val_loss: 0.3354 - val_acc: 0.9003\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9821\n",
      "Epoch 00023: val_loss did not improve from 0.33540\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0754 - acc: 0.9821 - val_loss: 0.3392 - val_acc: 0.9001\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9832\n",
      "Epoch 00024: val_loss improved from 0.33540 to 0.32886, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/024-0.3289.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0714 - acc: 0.9832 - val_loss: 0.3289 - val_acc: 0.9068\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9862\n",
      "Epoch 00025: val_loss improved from 0.32886 to 0.32466, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/025-0.3247.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0601 - acc: 0.9862 - val_loss: 0.3247 - val_acc: 0.9078\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9845\n",
      "Epoch 00026: val_loss did not improve from 0.32466\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0647 - acc: 0.9845 - val_loss: 0.3370 - val_acc: 0.9005\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9864\n",
      "Epoch 00027: val_loss did not improve from 0.32466\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0551 - acc: 0.9864 - val_loss: 0.3808 - val_acc: 0.8933\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9886\n",
      "Epoch 00028: val_loss did not improve from 0.32466\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0502 - acc: 0.9886 - val_loss: 0.3559 - val_acc: 0.9012\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9895\n",
      "Epoch 00029: val_loss did not improve from 0.32466\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0476 - acc: 0.9895 - val_loss: 0.5670 - val_acc: 0.8509\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9887\n",
      "Epoch 00030: val_loss improved from 0.32466 to 0.27179, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/030-0.2718.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0493 - acc: 0.9887 - val_loss: 0.2718 - val_acc: 0.9262\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9879\n",
      "Epoch 00031: val_loss did not improve from 0.27179\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0510 - acc: 0.9879 - val_loss: 0.3010 - val_acc: 0.9213\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9925\n",
      "Epoch 00032: val_loss did not improve from 0.27179\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0367 - acc: 0.9925 - val_loss: 0.4149 - val_acc: 0.8854\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9920\n",
      "Epoch 00033: val_loss did not improve from 0.27179\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0379 - acc: 0.9920 - val_loss: 0.4962 - val_acc: 0.8707\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9885\n",
      "Epoch 00034: val_loss did not improve from 0.27179\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0480 - acc: 0.9885 - val_loss: 0.4828 - val_acc: 0.8619\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9950\n",
      "Epoch 00035: val_loss did not improve from 0.27179\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0259 - acc: 0.9950 - val_loss: 0.4138 - val_acc: 0.8912\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9844\n",
      "Epoch 00036: val_loss did not improve from 0.27179\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0605 - acc: 0.9844 - val_loss: 0.3346 - val_acc: 0.9113\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9929\n",
      "Epoch 00037: val_loss did not improve from 0.27179\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0341 - acc: 0.9929 - val_loss: 0.3648 - val_acc: 0.9036\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9967\n",
      "Epoch 00038: val_loss did not improve from 0.27179\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0194 - acc: 0.9967 - val_loss: 0.6802 - val_acc: 0.8351\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9921\n",
      "Epoch 00039: val_loss did not improve from 0.27179\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0358 - acc: 0.9921 - val_loss: 0.4382 - val_acc: 0.8870\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9930\n",
      "Epoch 00040: val_loss did not improve from 0.27179\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0302 - acc: 0.9930 - val_loss: 0.3880 - val_acc: 0.8987\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9893\n",
      "Epoch 00041: val_loss did not improve from 0.27179\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0420 - acc: 0.9893 - val_loss: 0.3330 - val_acc: 0.9124\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9987\n",
      "Epoch 00042: val_loss improved from 0.27179 to 0.26471, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/042-0.2647.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0124 - acc: 0.9987 - val_loss: 0.2647 - val_acc: 0.9324\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9949\n",
      "Epoch 00043: val_loss did not improve from 0.26471\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0266 - acc: 0.9949 - val_loss: 0.4765 - val_acc: 0.8891\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9909\n",
      "Epoch 00044: val_loss did not improve from 0.26471\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0363 - acc: 0.9908 - val_loss: 0.3012 - val_acc: 0.9168\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9903\n",
      "Epoch 00045: val_loss improved from 0.26471 to 0.24530, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/045-0.2453.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0389 - acc: 0.9903 - val_loss: 0.2453 - val_acc: 0.9378\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9977\n",
      "Epoch 00046: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0150 - acc: 0.9977 - val_loss: 0.3315 - val_acc: 0.9150\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9901\n",
      "Epoch 00047: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0405 - acc: 0.9901 - val_loss: 0.3730 - val_acc: 0.9082\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9932\n",
      "Epoch 00048: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0283 - acc: 0.9932 - val_loss: 0.2640 - val_acc: 0.9334\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9979\n",
      "Epoch 00049: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0142 - acc: 0.9979 - val_loss: 0.2980 - val_acc: 0.9255\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9959\n",
      "Epoch 00050: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0194 - acc: 0.9959 - val_loss: 0.3670 - val_acc: 0.9061\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9921\n",
      "Epoch 00051: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0332 - acc: 0.9921 - val_loss: 0.4754 - val_acc: 0.8800\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9930\n",
      "Epoch 00052: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0286 - acc: 0.9930 - val_loss: 0.2777 - val_acc: 0.9276\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9978\n",
      "Epoch 00053: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0138 - acc: 0.9977 - val_loss: 0.2496 - val_acc: 0.9364\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9930\n",
      "Epoch 00054: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0291 - acc: 0.9930 - val_loss: 0.3394 - val_acc: 0.9145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9992\n",
      "Epoch 00055: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0083 - acc: 0.9992 - val_loss: 0.2596 - val_acc: 0.9376\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9940\n",
      "Epoch 00056: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0255 - acc: 0.9940 - val_loss: 0.2721 - val_acc: 0.9315\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9970\n",
      "Epoch 00057: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0149 - acc: 0.9969 - val_loss: 0.2572 - val_acc: 0.9338\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9910\n",
      "Epoch 00058: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0318 - acc: 0.9910 - val_loss: 0.3089 - val_acc: 0.9208\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9961\n",
      "Epoch 00059: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0192 - acc: 0.9961 - val_loss: 0.2595 - val_acc: 0.9336\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9989\n",
      "Epoch 00060: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0089 - acc: 0.9989 - val_loss: 0.4133 - val_acc: 0.9029\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9937\n",
      "Epoch 00061: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0256 - acc: 0.9937 - val_loss: 0.2671 - val_acc: 0.9322\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9982\n",
      "Epoch 00062: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0101 - acc: 0.9982 - val_loss: 0.3880 - val_acc: 0.9050\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9909\n",
      "Epoch 00063: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0345 - acc: 0.9908 - val_loss: 0.2857 - val_acc: 0.9262\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9949\n",
      "Epoch 00064: val_loss improved from 0.24530 to 0.24121, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/064-0.2412.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0218 - acc: 0.9949 - val_loss: 0.2412 - val_acc: 0.9401\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9977\n",
      "Epoch 00065: val_loss did not improve from 0.24121\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0129 - acc: 0.9977 - val_loss: 0.3010 - val_acc: 0.9269\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9978\n",
      "Epoch 00066: val_loss did not improve from 0.24121\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0107 - acc: 0.9978 - val_loss: 0.3564 - val_acc: 0.9159\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9962\n",
      "Epoch 00067: val_loss did not improve from 0.24121\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0160 - acc: 0.9962 - val_loss: 0.8978 - val_acc: 0.8095\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9942\n",
      "Epoch 00068: val_loss did not improve from 0.24121\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0236 - acc: 0.9941 - val_loss: 0.4431 - val_acc: 0.8933\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9946\n",
      "Epoch 00069: val_loss did not improve from 0.24121\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0236 - acc: 0.9946 - val_loss: 0.2594 - val_acc: 0.9371\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9996\n",
      "Epoch 00070: val_loss improved from 0.24121 to 0.23686, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/070-0.2369.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0045 - acc: 0.9996 - val_loss: 0.2369 - val_acc: 0.9418\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9995\n",
      "Epoch 00071: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0044 - acc: 0.9995 - val_loss: 0.4144 - val_acc: 0.9089\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9920\n",
      "Epoch 00072: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0306 - acc: 0.9920 - val_loss: 0.2836 - val_acc: 0.9259\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9968\n",
      "Epoch 00073: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0154 - acc: 0.9968 - val_loss: 0.3015 - val_acc: 0.9210\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9964\n",
      "Epoch 00074: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0155 - acc: 0.9964 - val_loss: 0.2835 - val_acc: 0.9301\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9929\n",
      "Epoch 00075: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0288 - acc: 0.9929 - val_loss: 0.3033 - val_acc: 0.9262\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9994\n",
      "Epoch 00076: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0053 - acc: 0.9994 - val_loss: 0.2379 - val_acc: 0.9429\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9996\n",
      "Epoch 00077: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0042 - acc: 0.9996 - val_loss: 0.2808 - val_acc: 0.9373\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9905\n",
      "Epoch 00078: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0349 - acc: 0.9905 - val_loss: 0.2763 - val_acc: 0.9362\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9973\n",
      "Epoch 00079: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0132 - acc: 0.9973 - val_loss: 0.2403 - val_acc: 0.9387\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9983\n",
      "Epoch 00080: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0095 - acc: 0.9983 - val_loss: 0.2911 - val_acc: 0.9341\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9974\n",
      "Epoch 00081: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0128 - acc: 0.9974 - val_loss: 0.2597 - val_acc: 0.9362\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9983\n",
      "Epoch 00082: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0096 - acc: 0.9982 - val_loss: 0.3456 - val_acc: 0.9236\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9858\n",
      "Epoch 00083: val_loss did not improve from 0.23686\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0524 - acc: 0.9858 - val_loss: 0.2769 - val_acc: 0.9322\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9990\n",
      "Epoch 00084: val_loss improved from 0.23686 to 0.23462, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/084-0.2346.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0071 - acc: 0.9990 - val_loss: 0.2346 - val_acc: 0.9450\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9993\n",
      "Epoch 00085: val_loss did not improve from 0.23462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0050 - acc: 0.9993 - val_loss: 0.2384 - val_acc: 0.9415\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9965\n",
      "Epoch 00086: val_loss did not improve from 0.23462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0141 - acc: 0.9965 - val_loss: 0.4749 - val_acc: 0.8873\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9969\n",
      "Epoch 00087: val_loss did not improve from 0.23462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0148 - acc: 0.9969 - val_loss: 0.3863 - val_acc: 0.9082\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9924\n",
      "Epoch 00088: val_loss did not improve from 0.23462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0278 - acc: 0.9924 - val_loss: 0.2415 - val_acc: 0.9420\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9996\n",
      "Epoch 00089: val_loss did not improve from 0.23462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0042 - acc: 0.9996 - val_loss: 0.2439 - val_acc: 0.9460\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9993\n",
      "Epoch 00090: val_loss did not improve from 0.23462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0051 - acc: 0.9993 - val_loss: 0.2692 - val_acc: 0.9364\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9968\n",
      "Epoch 00091: val_loss did not improve from 0.23462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0133 - acc: 0.9968 - val_loss: 0.4704 - val_acc: 0.8973\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9944\n",
      "Epoch 00092: val_loss did not improve from 0.23462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0206 - acc: 0.9944 - val_loss: 0.2562 - val_acc: 0.9383\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9960\n",
      "Epoch 00093: val_loss did not improve from 0.23462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0168 - acc: 0.9960 - val_loss: 0.3070 - val_acc: 0.9297\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9979\n",
      "Epoch 00094: val_loss did not improve from 0.23462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0102 - acc: 0.9979 - val_loss: 0.2550 - val_acc: 0.9380\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9985\n",
      "Epoch 00095: val_loss did not improve from 0.23462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0075 - acc: 0.9985 - val_loss: 0.4465 - val_acc: 0.9050\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9968\n",
      "Epoch 00096: val_loss did not improve from 0.23462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0135 - acc: 0.9968 - val_loss: 0.4570 - val_acc: 0.9040\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9973\n",
      "Epoch 00097: val_loss improved from 0.23462 to 0.22889, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/097-0.2289.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0105 - acc: 0.9973 - val_loss: 0.2289 - val_acc: 0.9474\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9961\n",
      "Epoch 00098: val_loss did not improve from 0.22889\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0136 - acc: 0.9961 - val_loss: 0.5760 - val_acc: 0.8740\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9943\n",
      "Epoch 00099: val_loss did not improve from 0.22889\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0230 - acc: 0.9943 - val_loss: 0.2369 - val_acc: 0.9420\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9996\n",
      "Epoch 00100: val_loss did not improve from 0.22889\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0036 - acc: 0.9996 - val_loss: 0.2394 - val_acc: 0.9467\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 00101: val_loss did not improve from 0.22889\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0029 - acc: 0.9997 - val_loss: 0.3692 - val_acc: 0.9241\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9949\n",
      "Epoch 00102: val_loss did not improve from 0.22889\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0202 - acc: 0.9949 - val_loss: 0.2331 - val_acc: 0.9436\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9994\n",
      "Epoch 00103: val_loss did not improve from 0.22889\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0049 - acc: 0.9994 - val_loss: 0.2335 - val_acc: 0.9455\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9961\n",
      "Epoch 00104: val_loss did not improve from 0.22889\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0155 - acc: 0.9961 - val_loss: 0.3135 - val_acc: 0.9290\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9989\n",
      "Epoch 00105: val_loss did not improve from 0.22889\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0066 - acc: 0.9989 - val_loss: 0.2588 - val_acc: 0.9436\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9989\n",
      "Epoch 00106: val_loss did not improve from 0.22889\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0060 - acc: 0.9989 - val_loss: 0.3541 - val_acc: 0.9203\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9946\n",
      "Epoch 00107: val_loss did not improve from 0.22889\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0208 - acc: 0.9946 - val_loss: 0.3217 - val_acc: 0.9196\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9972\n",
      "Epoch 00108: val_loss did not improve from 0.22889\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0129 - acc: 0.9972 - val_loss: 0.2530 - val_acc: 0.9413\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9997\n",
      "Epoch 00109: val_loss improved from 0.22889 to 0.22757, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_8_conv_checkpoint/109-0.2276.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0031 - acc: 0.9997 - val_loss: 0.2276 - val_acc: 0.9455\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 00110: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0032 - acc: 0.9996 - val_loss: 0.2756 - val_acc: 0.9331\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9933\n",
      "Epoch 00111: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0247 - acc: 0.9933 - val_loss: 0.2627 - val_acc: 0.9436\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9962\n",
      "Epoch 00112: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0145 - acc: 0.9962 - val_loss: 0.2574 - val_acc: 0.9453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9993\n",
      "Epoch 00113: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0044 - acc: 0.9993 - val_loss: 0.2504 - val_acc: 0.9478\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9993\n",
      "Epoch 00114: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0048 - acc: 0.9993 - val_loss: 0.2788 - val_acc: 0.9399\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9951\n",
      "Epoch 00115: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0190 - acc: 0.9951 - val_loss: 0.3370 - val_acc: 0.9238\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9967\n",
      "Epoch 00116: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0132 - acc: 0.9967 - val_loss: 0.2764 - val_acc: 0.9364\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9990\n",
      "Epoch 00117: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0065 - acc: 0.9990 - val_loss: 0.2679 - val_acc: 0.9418\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9952\n",
      "Epoch 00118: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0179 - acc: 0.9952 - val_loss: 0.2445 - val_acc: 0.9429\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9997\n",
      "Epoch 00119: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0032 - acc: 0.9997 - val_loss: 0.2350 - val_acc: 0.9457\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9996\n",
      "Epoch 00120: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0029 - acc: 0.9996 - val_loss: 0.2500 - val_acc: 0.9460\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 00121: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0028 - acc: 0.9998 - val_loss: 0.2687 - val_acc: 0.9425\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9914\n",
      "Epoch 00122: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0297 - acc: 0.9914 - val_loss: 0.2712 - val_acc: 0.9364\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9982\n",
      "Epoch 00123: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0087 - acc: 0.9981 - val_loss: 0.3218 - val_acc: 0.9255\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9951\n",
      "Epoch 00124: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0182 - acc: 0.9950 - val_loss: 0.2711 - val_acc: 0.9394\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9957\n",
      "Epoch 00125: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0166 - acc: 0.9957 - val_loss: 0.2383 - val_acc: 0.9427\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 00126: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0037 - acc: 0.9995 - val_loss: 0.2495 - val_acc: 0.9425\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9995\n",
      "Epoch 00127: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0034 - acc: 0.9995 - val_loss: 0.2621 - val_acc: 0.9418\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9997\n",
      "Epoch 00128: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0027 - acc: 0.9997 - val_loss: 0.2767 - val_acc: 0.9420\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9939\n",
      "Epoch 00129: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0240 - acc: 0.9939 - val_loss: 0.2630 - val_acc: 0.9413\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9992\n",
      "Epoch 00130: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0051 - acc: 0.9992 - val_loss: 0.2519 - val_acc: 0.9443\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9971\n",
      "Epoch 00131: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0122 - acc: 0.9971 - val_loss: 0.2853 - val_acc: 0.9371\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9986\n",
      "Epoch 00132: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0076 - acc: 0.9986 - val_loss: 0.2409 - val_acc: 0.9448\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9990\n",
      "Epoch 00133: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0048 - acc: 0.9990 - val_loss: 0.2814 - val_acc: 0.9371\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9990\n",
      "Epoch 00134: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0056 - acc: 0.9990 - val_loss: 0.2933 - val_acc: 0.9366\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9997\n",
      "Epoch 00135: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0025 - acc: 0.9997 - val_loss: 0.2668 - val_acc: 0.9411\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9942\n",
      "Epoch 00136: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0219 - acc: 0.9942 - val_loss: 0.3290 - val_acc: 0.9238\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9956\n",
      "Epoch 00137: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0173 - acc: 0.9956 - val_loss: 0.2473 - val_acc: 0.9464\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9989\n",
      "Epoch 00138: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0060 - acc: 0.9989 - val_loss: 0.2537 - val_acc: 0.9429\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9997\n",
      "Epoch 00139: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0025 - acc: 0.9997 - val_loss: 0.2882 - val_acc: 0.9387\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 00140: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0032 - acc: 0.9996 - val_loss: 0.2677 - val_acc: 0.9443\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9955\n",
      "Epoch 00141: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0168 - acc: 0.9955 - val_loss: 0.2822 - val_acc: 0.9345\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9990\n",
      "Epoch 00142: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0058 - acc: 0.9990 - val_loss: 0.2447 - val_acc: 0.9446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9979\n",
      "Epoch 00143: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0089 - acc: 0.9979 - val_loss: 0.4143 - val_acc: 0.9108\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9995\n",
      "Epoch 00144: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0038 - acc: 0.9995 - val_loss: 0.2585 - val_acc: 0.9434\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 00145: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0030 - acc: 0.9996 - val_loss: 0.2497 - val_acc: 0.9474\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9942\n",
      "Epoch 00146: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0194 - acc: 0.9942 - val_loss: 0.5106 - val_acc: 0.8831\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9986\n",
      "Epoch 00147: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0064 - acc: 0.9986 - val_loss: 0.3485 - val_acc: 0.9304\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9992\n",
      "Epoch 00148: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0049 - acc: 0.9992 - val_loss: 0.2761 - val_acc: 0.9376\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9948\n",
      "Epoch 00149: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0184 - acc: 0.9948 - val_loss: 0.2594 - val_acc: 0.9418\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 00150: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0027 - acc: 0.9997 - val_loss: 0.2604 - val_acc: 0.9399\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9954\n",
      "Epoch 00151: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0162 - acc: 0.9954 - val_loss: 0.2401 - val_acc: 0.9441\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 00152: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0028 - acc: 0.9998 - val_loss: 0.2432 - val_acc: 0.9446\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9997\n",
      "Epoch 00153: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0026 - acc: 0.9997 - val_loss: 0.2513 - val_acc: 0.9425\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9964\n",
      "Epoch 00154: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0131 - acc: 0.9964 - val_loss: 0.5482 - val_acc: 0.8833\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9952\n",
      "Epoch 00155: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0180 - acc: 0.9952 - val_loss: 0.2757 - val_acc: 0.9422\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 00156: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0030 - acc: 0.9996 - val_loss: 0.2456 - val_acc: 0.9436\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9994\n",
      "Epoch 00157: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0041 - acc: 0.9994 - val_loss: 0.2486 - val_acc: 0.9443\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9983\n",
      "Epoch 00158: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0078 - acc: 0.9983 - val_loss: 0.3052 - val_acc: 0.9294\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9966\n",
      "Epoch 00159: val_loss did not improve from 0.22757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0126 - acc: 0.9965 - val_loss: 0.3089 - val_acc: 0.9357\n",
      "\n",
      "1D_CNN_custom_tanh_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd4VFX6xz9nUkkPIYROaFJCSOgoAhZAQEUsgL2sit11XXXZXUsUXRuLiqL+FBsW0AXsCIKCEQWlSJUSSpAESCGkkToz7++PMzOZkJ4wJJLzeZ557sy955z73jP3nu95T7tKRDAYDAaDoSYsjW2AwWAwGP4cGMEwGAwGQ60wgmEwGAyGWmEEw2AwGAy1wgiGwWAwGGqFEQyDwWAw1AojGAaDwWCoFUYwDAaDwVArjGAYDAaDoVZ4N7YBJ5NWrVpJdHR0Y5thMBgMfxo2bNiQKSKRtQl7WglGdHQ069evb2wzDAaD4U+DUupAbcOaJimDwWAw1AojGAaDwWCoFUYwDAaDwVArPNaHoZR6G7gISBeRvpUcfxC4xs2O3kCkiGQppZKBPMAGWEVkUH3tKC0tJSUlhaKiovom0azx9/enQ4cO+Pj4NLYpBoOhkfFkp/e7wCvAvMoOisjzwPMASqmLgb+JSJZbkHNFJLOhRqSkpBAcHEx0dDRKqYYm16wQEY4ePUpKSgpdunRpbHMMBkMj47EmKRFJBLJqDKi5CpjvCTuKioqIiIgwYlEPlFJEREQY78xgMABNoA9DKRUAjAMWue0W4Ful1Aal1LSTcI6GJtFsMXlnMBicNIV5GBcDP53QHHW2iKQqpVoDy5VSOx0eSwUcgjINoFOnTvUyoLj4EF5egXh7h9YrvsFgMDQHGt3DAK7khOYoEUl1bNOBT4EhVUUWkTdEZJCIDIqMrNVkxQqUlBzBas2tV9yayM7O5tVXX61X3AkTJpCdnV3r8AkJCcycObNe5zIYDIaaaFTBUEqFAqOAz932BSqlgp3fgbHANg9bgm4FO/lUJxhWq7XauEuWLCEsLMwTZhkMBkOd8ZhgKKXmA2uAnkqpFKXUzUqp25VSt7sFuxT4VkSOu+2LAlYrpTYDvwJfi8hST9mpbbUAdo+kPX36dPbu3Ut8fDwPPvggq1atYsSIEUycOJE+ffoAMGnSJAYOHEhMTAxvvPGGK250dDSZmZkkJyfTu3dvbr31VmJiYhg7diyFhYXVnnfTpk0MGzaMfv36cemll3Ls2DEAZs+eTZ8+fejXrx9XXnklAD/88APx8fHEx8fTv39/8vLyPJIXBoPhz43H+jBE5KpahHkXPfzWfd8+IM4TNiUl3Ud+/qYK+2224yjlhcXiX+c0g4Li6dHjxSqPP/PMM2zbto1Nm/R5V61axcaNG9m2bZtrqOrbb79Ny5YtKSwsZPDgwVx++eVEREScYHsS8+fP580332TKlCksWrSIa6+9tsrzXn/99bz88suMGjWKRx99lMcff5wXX3yRZ555hv379+Pn5+dq7po5cyZz5sxh+PDh5Ofn4+9f93wwGAynP02hD6OJ4JkmqcoYMmRIuXkNs2fPJi4ujmHDhnHw4EGSkpIqxOnSpQvx8fEADBw4kOTk5CrTz8nJITs7m1GjRgFwww03kJioxwz069ePa665hg8++ABvb11fGD58OPfffz+zZ88mOzvbtd9gMBjcaVYlQ1WewPHj27FY/GjRovspsSMwMND1fdWqVaxYsYI1a9YQEBDAOeecU+m8Bz8/P9d3Ly+vGpukquLrr78mMTGRL7/8kqeeeoqtW7cyffp0LrzwQpYsWcLw4cNZtmwZvXr1qlf6BoPh9MV4GAAoRDzjYQQHB1fbJ5CTk0N4eDgBAQHs3LmTtWvXNvicoaGhhIeH8+OPPwLw/vvvM2rUKOx2OwcPHuTcc8/l2WefJScnh/z8fPbu3UtsbCz/+Mc/GDx4MDt37mywDQaD4fSjWXkYVeO5Tu+IiAiGDx9O3759GT9+PBdeeGG54+PGjeP111+nd+/e9OzZk2HDhp2U87733nvcfvvtFBQU0LVrV9555x1sNhvXXnstOTk5iAj33nsvYWFhPPLII6xcuRKLxUJMTAzjx48/KTYYDIbTC+WpmnVjMGjQIDnxBUo7duygd+/e1cYrKNgFCAEBphmmMmqThwaD4c+JUmpDbRd4NU1SgCebpAwGg+F0wQgG4MkmKYPBYDhdMIKBc4E942EYDAZDdRjBAEyTlMFgMNSMEQzANEkZDAZDzRjBwDRJGQwGQ20wggGABZGm42EEBQXVab/BYDCcCoxgAJ5c3txgMBhOF4xgUNYk5YmO7+nTpzNnzhzXb+dLjvLz8zn//PMZMGAAsbGxfP7559WkUh4R4cEHH6Rv377Exsby8ccfA3D48GFGjhxJfHw8ffv25ccff8Rms3HjjTe6wr7wwgsn/RoNBkPzoHktDXLffbCp4vLmPvYSvKQYvILrnmZ8PLxY9fLmU6dO5b777uOuu+4C4JNPPmHZsmX4+/vz6aefEhISQmZmJsOGDWPixIm1eof24sWL2bRpE5s3byYzM5PBgwczcuRIPvroIy644AL+/e9/Y7PZKCgoYNOmTaSmprJtm34HVV3e4GcwGAzuNC/BqBFBN0+dPPr37096ejqHDh0iIyOD8PBwOnbsSGlpKf/6179ITEzEYrGQmppKWloabdq0qTHN1atXc9VVV+Hl5UVUVBSjRo1i3bp1DB48mL/85S+UlpYyadIk4uPj6dq1K/v27eOee+7hwgsvZOzYsSf1+gwGQ/OheQlGFZ6AtSSN4uKDBAbGoywnP0smT57MwoULOXLkCFOnTgXgww8/JCMjgw0bNuDj40N0dHSly5rXhZEjR5KYmMjXX3/NjTfeyP3338/111/P5s2bWbZsGa+//jqffPIJb7/99sm4LIPB0MwwfRhAWTZ4ZqTU1KlTWbBgAQsXLmTy5MmAXta8devW+Pj4sHLlSg4cOFDr9EaMGMHHH3+MzWYjIyODxMREhgwZwoEDB4iKiuLWW2/llltuYePGjWRmZmK327n88st58skn2bhxo0eu0WAwnP40Lw+jSpzNUJ4ZKRUTE0NeXh7t27enbdu2AFxzzTVcfPHFxMbGMmjQoDq9sOjSSy9lzZo1xMXFoZTiueeeo02bNrz33ns8//zz+Pj4EBQUxLx580hNTeWmm27Cbtdi+PTTT3vkGg0Gw+mPx5Y3V0q9DVwEpItI30qOnwN8Dux37FosIk84jo0DXgK8gLki8kxtzlnf5c1LS49SVLSfgIC+eHmZ91mfiFne3GA4fWkqy5u/C4yrIcyPIhLv+DjFwguYA4wH+gBXKaX6eNBOPN0kZTAYDKcDHhMMEUkEsuoRdQiwR0T2iUgJsAC45KQaVwHPNkkZDAbD6UBjd3qfqZTarJT6RikV49jXHjjoFibFsc9jOOc+NKXlQQwGg6Gp0Zid3huBziKSr5SaAHwG9KhrIkqpacA0gE6dOtXTFKduGg/DYDAYqqLRPAwRyRWRfMf3JYCPUqoVkAp0dAvawbGvqnTeEJFBIjIoMjKyntaYJimDwWCoiUYTDKVUG+VoC1JKDXHYchRYB/RQSnVRSvkCVwJfeNYWnQ2mScpgMBiqxmOCoZSaD6wBeiqlUpRSNyulbldK3e4IcgWwTSm1GZgNXCkaK3A3sAzYAXwiIts9ZafDWsf25HsY2dnZvPrqq/WKO2HCBLP2k8FgaDJ4rA9DRK6q4fgrwCtVHFsCLPGEXZXjecG48847KxyzWq14e1f9FyxZcgqzwGAwGGqgsUdJNQk82SQ1ffp09u7dS3x8PA8++CCrVq1ixIgRTJw4kT599PSSSZMmMXDgQGJiYnjjjTdccaOjo8nMzCQ5OZnevXtz6623EhMTw9ixYyksLKxwri+//JKhQ4fSv39/Ro8eTVpaGgD5+fncdNNNxMbG0q9fPxYtWgTA0qVLGTBgAHFxcZx//vkn/doNBsPpRbNaGqSK1c0Bb2y2nlgsftRidfFy1LC6Oc888wzbtm1jk+PEq1atYuPGjWzbto0uXboA8Pbbb9OyZUsKCwsZPHgwl19+OREREeXSSUpKYv78+bz55ptMmTKFRYsWce2115YLc/bZZ7N27VqUUsydO5fnnnuO//73v8yYMYPQ0FC2bt0KwLFjx8jIyODWW28lMTGRLl26kJVVnykzBoOhOdGsBKNqTu6S5jUxZMgQl1gAzJ49m08//RSAgwcPkpSUVEEwunTpQnx8PAADBw4kOTm5QropKSlMnTqVw4cPU1JS4jrHihUrWLBggStceHg4X375JSNHjnSFadmy5Um9RoPBcPrRrASjKk9ARMjP34Wvb3v8/Np63I7AwEDX91WrVrFixQrWrFlDQEAA55xzTqXLnPv5+bm+e3l5Vdokdc8993D//fczceJEVq1aRUJCgkfsNxgMzRPThwF4stM7ODiYvLy8Ko/n5OQQHh5OQEAAO3fuZO3atfU+V05ODu3b60nx7733nmv/mDFjyr0m9tixYwwbNozExET279drP5omKYPBUBNGMMDttagnXzAiIiIYPnw4ffv25cEHH6xwfNy4cVitVnr37s306dMZNmxYvc+VkJDA5MmTGThwIK1atXLtf/jhhzl27Bh9+/YlLi6OlStXEhkZyRtvvMFll11GXFyc68VOBoPBUBUeW968Majv8uYAeXkb8fGJxN/fMcncbocDB6B9e/D19YS5fxrM8uYGw+lLU1ne/E+GopyHUVgIR49Cfn6jWWQwGAxNCSMYAL/9hl+GUO59GE7P6zTywAwGg6EhGMEAUApl16OlXDheaeraGgwGQzPHCAaAxeJwLoxgGAwGQ1UYwQDw8kLZoVyTlFMoTJOUwWAwAEYwNA7BKNck5fxuPAyDwWAAjGBovLyqbpJqBA8jKCjolJ/TYDAYasIIBoDFUnWTlPEwDAaDATCCofHyArtU3iTVQA9j+vTp5ZblSEhIYObMmeTn53P++eczYMAAYmNj+fzzz2tMq6pl0CtbpryqJc0NBoOhvjSrxQfvW3ofm45Usr55cTGUlmDb4IWXV4DeV1Ki9/v4gL9/lWnGt4nnxXFVr28+depU7rvvPu666y4APvnkE5YtW4a/vz+ffvopISEhZGZmMmzYMCZOnOi2TElFKlsG3W63V7pMeWVLmhsMBkNDaFaCUSVKObovKvEwGkj//v1JT0/n0KFDZGRkEB4eTseOHSktLeVf//oXiYmJWCwWUlNTSUtLo02bNlWmVdky6BkZGZUuU17ZkuYGg8HQEJqVYFTpCRw5AikpHD/Dl8CQfnrfwYOQlgbh4dCtW4POO3nyZBYuXMiRI0dci/x9+OGHZGRksGHDBnx8fIiOjq50WXMntV0G3WAwGDyF6cMA3YcBYPPMKKmpU6eyYMECFi5cyOTJkwG9FHnr1q3x8fFh5cqVHDhwoNo0qloGvaplyitb0txgMBgagscEQyn1tlIqXSm1rYrj1yiltiiltiqlflZKxbkdS3bs36SUWl9Z/JOKUzDsnhklFRMTQ15eHu3bt6dtW/2CpmuuuYb169cTGxvLvHnz6NWrV7VpVLUMelXLlFe2pLnBYDA0BI8tb66UGgnkA/NEpG8lx88CdojIMaXUeCBBRIY6jiUDg0Qksy7nrPfy5jk5kJREQScLAa0H6H379kFWFgQHQ8+edTHjtMMsb24wnL7UZXlzj/VhiEiiUiq6muM/u/1cC3TwlC014vIwzFpSBoPBUBVNpQ/jZuAbt98CfKuU2qCUmubxs1t0Nij3uRhmLSmDwWAoR6OPklJKnYsWjLPddp8tIqlKqdbAcqXUThFJrCL+NGAaQKdOnSo9h4hUO7+hzMMArVXKrCXl4HR6I6PBYGgYjephKKX6AXOBS0TkqHO/iKQ6tunAp8CQqtIQkTdEZJCIDIqMjKxw3N/fn6NHj1Zf8DkEQ7mvJ2U8DESEo0eP4l/NxEWDwdB8aDQPQynVCVgMXCciu932BwIWEclzfB8LPFHf83To0IGUlBQyMjKqDiQCmZlYi8ArfwdKecGhQ1BaqsXEu9EdsUbD39+fDh0ar3vJYDA0HTxWEiql5gPnAK2UUinAY4APgIi8DjwKRACvOpqLrI6e+ijgU8c+b+AjEVlaXzt8fHxcs6CrQwbEc3BSKVHvHcLPry1MmgS7d0PLlvrd3gaDwdDM8eQoqatqOH4LcEsl+/cBcRVjeBZ7kD9ehaXY7cV6R2Gh3prZ1AaDwQA0nVFSjY4EB+B9HEQcguEUCiMYBoPBABjBcCFBLfAqpMzDcAqF3Q5Wa+MZZjAYDE0EIxhOggPxPg52e4n+XViolzYH42UYDAYDRjBcSHAgXgWOJimrVX/CwvTB4uLGNc5gMBiaAEYwnAQH4VXgaJJyCoRTMIyHYTAYDEYwnEhICN4FjiYp5wgp42EYDAaDCyMYDlRwcFmTlNOjMB6GwWAwuDCC4SQkFK9isJcUVPQwjGAYDAZD4y8+2GQIDgFAcnOg9AQPwzRJGQwGgxEMJypUi4PKywUcghEaqrfGwzAYDAYjGC5CwwGQnBzwNZ3eBoPBcCKmD8OBCtaCQV5emUcR7thnPAyDwWAwHoYTFRqhv+TmgZdpkjIYDIYTMYLhwOIQDMk9Bv6mScpgMBhOxDRJOVBObyL3mJmHYTAYDJVgBMNJiGNYbV5ORcEwHobBYDAYwXARHIxYwJKVaybuGQwGQyUYwXDi5YU13BdLRp7xMAwGg6ESjGC4YWsVgFem29IgAQHg7W08DIPBYMDDgqGUelspla6U2lbFcaWUmq2U2qOU2qKUGuB27AalVJLjc4Mn7XRiiwzG56hj8UF/f1AK/PyMYBgMBgOe9zDeBcZVc3w80MPxmQa8BqCUagk8BgwFhgCPKaXCPWopYI8MwyfLhhQWasEAvTVNUgaDweBZwRCRRCCrmiCXAPNEsxYIU0q1BS4AlotIlogcA5ZTvfCcHHtbR+CbBVKQW14wjIdhMBgMjT5xrz1w0O13imNfVfs9S5vWWErBdjgFWrTQ+/z8mq2HIQIHDoDNBl276hY6d0pLYeFCnUXDh0NUVPnjubmwdq0+FhhYlubmzbB7N7RrB927Q5s2ZXFKSuDnn/Xr1IcOhfR0WLwYIiJg/Hj95tw9e6BPHz0SWgR+/x22bYPDh2HkSIiNhfXr4dAhmDBB/5Ui+vfvv0Namv4dHAzt20OHDtC6NXh56Wv66SdYsUKvEuPrCxddpNMtKtK2i0BQEPTsCRYLLFkCiYk6n9q3h2nTtG1JSfDbbzofRPTCAXY7HD8O550HXbro6507V9tmt0N0tE7Xy0unHR+v6yxLl8Ly5XpfUJDOtzPOgB499LmOHoWMDMjMLNv6+em89fbW5wkJ0f9RVJRO8/vvYeVK3WXn51eWdz/9BPv3Q9++EBkJO3bAkSP6/2nTBs45R48H2b0bdu3S13n8uL4/hg2DSZO0/Tt2wNatOkxJic7LIUOgf39t38GD8Mcf+vEaMkTb9/33sHevzi8Rfc74eLjB0Si9bJm+N/r109eQkwMbNuhPYaGOY7frY+PH63S//x62bNH/TViYzp/sbP1fl5TorfN7jx5w6aX6OjMyYPt2/Z/n5paFE4G4OP3ZvVt/goJ0HqalwbFj2oaWLWHiRH2fr1yp87SoCNq2hXPP1XmwfLlegWjkSP2srV6t89LbG3r10nkVFaX/99WrtS2+vvqeDgjQedaunb62+PiTXQJUpLEFo8Eopaahm7Po1KlTwxKLaqu3f/zxp/Aw7HZ983p56d9Wqy5gDx/WBVBaWlkBExSkv//0ky7EQReYcXH6IfrgA0hOhoQEuOQSeP55+N//dFoAnTrpAi4vTz9M/fvr47t3l9nToweceaYuZPLyYP58vW3ZEiZP1jb9+qu2y50uXbQg5eXpB/T48TL7jh/X1wm6QHIWIv7+uuDauhVSU8un5+2t8wK00Jx9tj6v81oqw9u7/PgGb28tcoWFMHOmLqBTUsrfCr6+Ol+zsnRh4eenC5Znn4XeveHHH6s+X1CQDvfRR/o/cf6HNlv5cL6+0KqVzjt/fx2uoKAsHxqKn5++zoICmDWrfmn4+Oj/qqQEXn5ZF2TFxWXX4uWlw5SWVry+yggP1/eqUvq/f+01eOIJnWZmZtU2BASUxTt+HP7739rZ7+ur43t56f/v3nurPoePj7apuiIhOFjbkZenn6fqcL+nQf/HwcH6WnNzK4b389N56Ly/nURG6mff0zS2YKQCHd1+d3DsSwXOOWH/qsoSEJE3gDcABg0a1KDHSLXVplgOHILuZ+idjdjpnZurC4qgIH3zffedrklnZ+vayNat2rSoKH0TpafXXJA4a61+frqG99lnOk5srK613323/nh5wWWX6UJZKV3jzsjQ50pO1rXqXr3g88/1zbp6tf58+622227X8SdN0oXiu+9Ct24wZgyMHq2F6sgRXeP/+Wd9neHhcP31cMEF+oFYsUKnffXVuta2bJl+mLp00TW2Zcu0F3LhhTBokBaHFSt0bXLYMC2Er76q8+m88/S+vn11jcxi0XampOhPaqou0Fq00LaNGaPPVVAAH36oxfHCC3XN0N9f27NxoxahK67QnoyPD6xbBw8/rOsc//mPjuNcwzI3V5/XatV5fNddurCePx+uvFLn2YED2oNSSotVYqKucU+ZovPT11cXJvv3a7FOSoL8fJ1PrVqVbVu10uGOHNHpenvr2nhamv5kZ8NZZ+l88fPThf1PP2mv4MwztZezfbsuoHv3ho6Op3TvXli1StvWs6f2cjp31veL3Q4//ACLFum8j43Vnx49dN4UFWnh3rZNVzo6dtQVEYtFV2JycmDUqLJzgb43v/tOF/6BgXDzzXq7bZu+5wMD9Tni4nTeOCko0Pfob7+V/fdpafocrVtr+3x9db64e867dul7uqBA52XPnrpy1LJlWTibTZ9/2zZ9vE8fHb6oSMfx89PhMjLgiy+093fuudpOPz/9/65apT3OsWO1TatXa0932DAdRkTfl1u26P/A6YX161d2DxUW6v/x0CFdPpwKlJysqkpVJ1AqGvhKRPpWcuxC4G5gArqDe7aIDHF0em8AnKOmNgIDRaS6/hAGDRok69evr7etBb8uImDoFfrHWWfpJ+iss3SJ/e239U63NtjtuhBYt07f6CtX6hvmRFq10jdvu3b6BgwJ0YWWxaJdXeenXTv9UIroAiU/X9/QTo/CSV6efpC6ddO/FyyATZvgttt0rb8qjh/Xhaullr1gIhWbtJozNhvMm6cLiN69G9saQ3NGKbVBRAbVJqxHPQyl1Hy0p9BKKZWCHvnkAyAirwNL0GKxBygAbnIcy1JKzQDWOZJ6oiaxOBlY2nUr++HhJqmsLFizpuyzbl1ZLSEiQtdw4+J0bev4cV1DGzWq+kK8PgQH64+Tq67Sn5pw9knUFiMW5fHygptuamwrDIa64VHBEJFqix7R7s1dVRx7G3jbE3ZVhXfrLogFlJ0ywfDzK2tUbyBZWdr1fO897aparbrgiIuD666DAQP09/79y9q0DQaDoanQ2H0YTQovnxBKWoJfJmWjpBrgYdjt8Omnuonp559h5069v1Ur+Otf9eibwYPrXls3NC1EhILSAgJ96/5Higg/HfyJAJ8AYlvH4uPlUyFMTlEOa1LWcLTgKFf0uQI/b786n2PWmllM7DmRHhE9ACgoLSDxQCJb0rZw5+A7CfINQkTYdGQTydnJBPsFM7rraABKbCUUlBYQ5h9WIe20/DTWpKyhf5v+dA7rDEBydjK/Z/xOcnYyydnJZBZkcnnvy5nQYwKqElfTLnbyivNIyU3h94zfOZx/GKvdSquAVgxqN4herXphUZW3feaX5GO1W/Gx+ODj5YOPxafcOexiJzk7mbziPPpF9UMpxcGcg2QVZrl+V8WHWz5EEM7qeBZdwrqglKLEVsKOjB3EtI7B2+JNsbWY3Ud3ExsV68rrnw7+xI8HfiTMP4w7Bt9R4/9jtVvZlr6NrMIsSmwlRAVG0SW8S7n8LrYWc6zoGNlF2WQXZRPqF0rvyFPflmkEww2lFKUtvfDLtJX3MOo4rFZEd5w98ojuGGvZUnckXned3p51VlnH2OlIkbWIeZvnMTVmKqH+oXWOv+nIJkL8QugartvfFu9YjK+XLxd0uwAfLx9KbaXlClYRqfbBdxaYW9O3MuuCWbRs0bLKsEuSlvDupndZ/cdqnh39LNfFXVetrTa7jZs+v4kPt37IOdHnMLbrWFoHtqbEVsKuo7vw9/ZnTNcxtA5szR85f9Avqh/tQ/QI8fySfG776jY+2voRAMG+way4fgVD2g9xpf9N0jdcsuASSu2lADyy8hFmj5/NRWdcBMDPB39m05FN3BB3A94Wbz7c+iE9WvZgROcRrjTWpqzlgeUPkJydzMsTXuZQ3iHiXo8js0APOdqctpkPLv2Ae765hznr5rjiPTbqMW7ufzMTPppA+vF0Nt22ibbBeiRhqa2USz++lK+TvgYgyDeIFy54gU1HNvHqulcRdN+on5cfLXxa8M6md+gX1Y+Pr/iYXq16kV2UzdyNc1m8YzG/pv6KTaoePtUuuB1X9b2KOwffSdfwrmQXZfP3ZX/n++TvSc5OrhDe2+KNj8UHXy9fSmwlFFr1Uj9xUXGcEXEGi3csxiY2hnUYxpQ+UwjwCSApK4nEA4mM7DyS58Y8x4JtC7j202tdabYJakO/qH78mvor2UXZxLaO5fZBt/Pi2hdJykpi+XXLGd11NI+sfISnfnwKAIViat+prvut2FrMoh2L+Gr3VyQeSKTUXkrboLbsz95PbnH5IVEKxdJrlzK221jWpqxlxDsjsNrLD416bvRzPHDWAxzOP8zWtK1c0P2CKvPwZOHxTu9TSUM7vQGyzwokbE2BHo4xdy7ceKMe0pCcXGPc4mL4+mt45hndJ9Gjhx4OOGVK7TuHPcHhvMO0bNGyzjXTmsgqzGLqwqlMGzCNyTGTAV043/j5jczbPI9JvSaxeMpiV2H+1sa3eGjFQ9wUfxN/G/Y3V8HpZE/WHv7+7d/5YtcXtAlqw8ZpG9lweAMXz78YgJYtWmJRFjILMrkx/ka2mKZRAAAgAElEQVReGf8Kc9bN4enVT/PZ1M8YFT2KHw/8yOM/PM4Hl31Am6A2FJYWcsuXt7gK5S5hXVg8dTHxbSoOWk/NTaXTi52ICozCx8sHq93Knnv20MKnBTlFOQT5BuFl8WLl/pUs2rGImMgYEv9IZMG2BUyJmcLmI5vZdXSXK70W3i0otZeWe9BD/EJ48+I3AXj4+4fZe2wvj458lJ6tenLbV7cxuc9k5k6cC+jacdzrcRRbi3n9otcpthbz4PIH2Zm5k31/3UeHkA70eqUXSVlJtA5sjY/Fh9S8VNoEtWHvvXsJ8AkA4ObPb+btTW/Tv01/Nt62kbc2vqXz5LKP2Jm5kycSn2B89/F8s+cb7hx0JzcPuJlXfn2Fdza9Q5BvEBZlodRWyvBOw1l27TIsysJ9S+/jpV9e4p9n/5PzupzHjMQZJB5IxKIs3DnoTq6OvZrosGiigqKw2W0s2LaAB5Y/gIgwc+xMHlv1GMnZyfRv058xXccQFRRFm6A29InsQ4eQDnhbvEnNTeXX1F/5bNdnLElagrfFm4fOeogF2xew/9h+JvWaRHybeFc+l9pKKbGVuL6X2kuxKAt9IvtgtVt5bf1r7D+2n1sH3ErnsM689MtL7Du2DwBfL1/6RPZh05FNTImZwpKkJcRFxfHy+JdZm7KWn1O0MA9sO5CBbQcya+0skrOTOSPiDPKK8+ga3pX/Tf4f3WZ3Y0KPCVzX7zomfTyJRVMWcVnvy/hk+yfc8809pB9Pp21QW0ZFjyLYN5jUvFQ6hnRkZOeRrutOy0/jps9vYnKfybw58U3uX3Y/c9bN4YULXiDcP5ww/zDe2/weH2//mPg28WxJ20KIXwhpD6Th6+U2VKyW1KXTGxGp8QP8FQgBFPAWetTS2NrEPZWfgQMHSkPJuLiVnjN09916x7RpIlFR1cfJEHnwQZHwcB21UyeRt94SKS1tsDkN5nDeYfGd4SuBTwXKZR9fJofzDp+UdIutxXLOu+cICUifOX3EbreLiMiLa14UEpAz554pJCCz184WEZG9WXsl4KkA6Tiro3g97iXB/wmW3w7/Vi7NwW8MlpCnQ+TBbx+UFk+2kDPnnikRz0ZI/Ovx8tmOz+SGT2+QW7+4VaZ9MU1UgpKwZ8KEBMTnCR/p/3p/KSotkl6v9BISkKsWXiU2u00uXXCpkIA8lfiU/PzHz9Luv+3E5wkfeXzV41JsLS53/id/eFJIQPZm7ZWV+1cKCcgLa16QOb/OEZWgpNVzrWTom0OFBMR3hq+QgJCA/CfxP640copyZP+x/XIg+4DY7DbJLcqVL3Z+IR9t+UiW713uiu/Mt+/2feeKe+XCK6X1863FarOKiMj/tv9PSEA+2vKRK8yB7ANiedwi/1j+D1m+d7mQgDz07UMy/oPxMmbeGJn500whAZn500wREcktypXApwLFd4avWB63SG5Rrly3+DqJfC5S7Ha7WG1WGTNvjJCAXP7x5WKz20RExGa3yT1L7pGeL/eULUe2yBvr3xASkGsWXSP3fXOfkID89Zu/uuyy2qzy5oY3ZX3q+irvmZ0ZO6XDrA5CAtL5hc6y5uCaWt9vKTkpcsn8S4QEpNVzrSQxObHWcavCZrdJ5vFMSc1NlYKSArHb7fLPFf8UEpCIZyPkYM7BKuMWlBTIqv2rpKi0SF799VUhARn65lDxetxL9hzdIyXWEgn6T5Dc+dWdYrVZpe3MthL7aqws27PMlcfVccUnV0j7/7YXu90uvV7pJWPfH1vB9n+t+JfEvhorD3/3sOzO3F3vfADWSy3L2NoKxmbH9gJgMRADbKztSU7V52QIxpG/dNHZ8sADese994qEhVUa1m4XeeklkaAgEaVEpkwRWbLk1AhFqa1UsgqyKhR6J7Jw+0JXYeA7w1du+/K2asPvztwtczfMldyi3GrPfcOnNwgJyMUfXSwkID//8bNsOLRBvB73kkkLJonVZpULP7xQfGf4yr1L7pXhbw2XkKdD5I/sP2R35m7pMKuDtPtvO/kj+w8R0YUJCcisn2eJiMj7m98XEpDApwJlZ8bOCjZ8k/SN9JnTR2avnS0fbP5ASEDOf+/8ctvLPr6sXJoiIun56XL1oquFBOS6xde59tvsNun6Ulc5991zXfvOf+98CXwqUEhAxr4/Vq5dfK3EvhorM3+aKYWlhbIva18F0auJEmuJPLf6Ofloy0cuYXAyf+t8IQFZfWC12Ow26ftqX+n1Sq8K4S7/+HIJfyZcxn0wTlo910oKSwvLHR89b7REPhcpecV58uaGN4UEJGFlgpCALN+7XDrO6ihXfHKFK3zm8Ux5ae1LUlBSUKXddrtdbvn8FlEJSkhARs8bLSXWkjpdu4hI8rFkefKHJyWrIKvOce12u3y377tqC/KGYrfbZe6GufJLyi+1jlNUWuQSwlu/uNW1f8KHE6Tnyz1dwv6/7f+rdZpvbXxLSEA+3/m5q+LiKTwhGFsc25eASx3ff6vtSU7V52QIxuF/9NfZ8vDDesdDD4n4+1cIl5MjcvnlOuiECSLbtzf41FVSWFooqw+slp/++EleX/e6DPi/Aa5aasSzETJ9+XQ5kH1ARPQN/9MfP7keyPuX3i9+M/yk2Fos076YJr4zfOVQ7qFKz3M477B0nNVRSEDCngmTl395uUKYzOOZrgL58VWPu2qwN352owx5c4i0fr61HCs85gp79aKrXbXxtze+7Upny5EtEvJ0iMS9FidFpUXyyPePiOVxSznbXlv3mny759sa88dmt7nyZOz7Y6WwtFB6zO7hqhE7vR93pv5vqnSY1cH12+lRvL/5fde+n//4WVSCkos/urhGYT4ZZBdmi88TPvLAsgdk9trZQgLy4ZYPK4RLTE50/f8PfftQheNrDq4REpD41+Ol7cy2EjMnRrILs0UlKLnxsxuFBOSVX16pl412u91VGzeU8c5v70jYM2GuCpCIyH9//q+QgIyZN0ZCng6pIOzVkZqbKiQg3Wd3FxKQXZm7PGG2iHhGMN4BvgWSgAAgGNhQ25Ocqs/JEIxD/x2ts+Wpp/SORx7R7oPbA5KWJhIfL+LlJTJzZrlDNZJdmF2jS5qWnyazfp7lqln++7t/uwoIEpC41+Lkke8fkVk/z5LLPr5MLI9bxPK4RSYtmCT9XusnJCA3fnajiIicOfdMGf7WcBERSTqaJJbHLZUWMgUlBTL0zaES8FSAzNs0T4a/NVx8Z/iWq3Wu3L9SOr3QSXxn+JYr/G/+/GaXbe4FrpP0/HRZsXdFhULmy11fCgnIo98/Kl1f6iqj542uZS5WZPWB1RL7aqz8nv67iIisS10nd319lxwvOV5p+KcSnxISkNy7bhF5+mm5dvG1Evp0aIVadtLRJCm1nbq2xbHvj5VWz7USr8e95OKPLq70XrHb7RL/eryoBCV7s/ZWms6TPzwpZ799tsS/Hi+fbPtERET6vdZPvJ/wFhKQrWlbPXodzZET/6tNhze5nou/fPaXOqcX91qckIB0famrRwXaE4JhQc+6DnP8bgn0q+1JTtXnZAhG6gdXi4DYZ+o2YHnqKZ1NxbqGeeCAyBlniLRooZufqmLuhrkVCs+cohxp+WxLuX/p/VXGs9vtMnH+RCEBWZq0VEREYl+NlaFvDpVle5bJb4d/q3DzJB9Lloe+fUgino2QPnP6yJlzz5TQp0MlpyhHfGf4yoPfPugKO/V/UyX4P8GSlp9WLo2/L/u7kIAs/n2xiJQV5iv3rxQRXVtSCUq6z+4uaw+uLRfXWaMd9c6oOt/Y1yy6xtXM8c5v79QpbkNY/PtiIQFZd2ZnsY0fJyFPh8jNn998ys5fFc728F6v9JKcopwqw609uFbeWP9GndK+46s7XH0AtWlHNzQMm90mkc9FCgmU66uqLdOXTxcSkLu+vssD1pVRF8Go7didM4FdIpKtlLoWeBjIqWXcPxdR7QCwOwcbOMe/FhWxa5deyC4tTa8UMn585UmICP/6/l/MWlN+NbdPtn9CVmEWs3+dza7MXZXGXbxjMV/s+gKARTsWcTDnIFvTtzK5z2TGdhtLfJv4CkNIO4d15tkxz5L5UCbb79zOo6MeJac4h2dWP0OJrYQzO5zpCvvvEf+mxFbC2W+fzd6svQDsytzFS7+8xC39b+HS3pcCcHans1Eofkj+gRJbCTMSZzC662g23baJoR2Gljv/0PZD+b+L/o/3L32/2uGtlfHiuBeJCIjA39ufy3pfVqe4DaFXq14A7GhxnD1kkVucy1kdzzpl56+KK/teybQB0/j8ys8J8QupMtzQDkO5deCtdUp7eMfhAIzqPKrKeQ2Gk4dFWZjQYwLRYdGM6jyqzvEn9ZoEcEqfi5qo7TyM14A4pVQc8HdgLjAPqHsuNHFUj+6knwuhw/vhBa75GLt/tzJiog6zalX1SwnvzNxJ+vF0CksLESmbI/DWb2/RLbwbGQUZPLD8Ab686sty8bKLsrnnm3vo36Y/XcO78tnOz+jfpj8AE3pMqPU1nN/lfML9w3lh7QsAnNmxTDBio2L57vrvuGTBJQydO5Qnz3uSL3d/SYBPAE+e96QrXJh/GPFt4ll1YBXDOgzTtg25p9LJaUoppg2cVmv73GkV0IrPpn5Gal5qtQXkyaZ7y+54W7zZGVSIl0XPRxjUrnYjCz1JeItw/u/i//NI2iM6j8BLeTG221iPpG+oyJwJcyi0FuJlqfvSDUM7DOXQ/Ydcc1+aArWtZlgdrsslwCsiMgfdj3Ha4R0Qye+PQkmPSL3D3x8rXlx3RyA2G3z53VE22N/CLnrN7YzjGfyQ/EO5NH44oH/nleSR+cMS2LmT3zN+Z23KWu4cfCcPj3iYr3Z/xff7v3fFERHu+PoO0o+n8+bFbzIlZgoZBRn8Z/V/iA6LdtWIa4OPlw+X9rqUImsRXcK60CaoTbnjwzsNZ83Na+jVqhd3fH0HS5KW8MjIR4gKKv9Ci1GdR7E2ZS0fbfuIIN8gxnQbU2sb6sLwTsOZEjPFI2lXhY+XD91bdmdHSAkbAnLx9/anT2SfU2rDqaZTaCd23LWDm/vf3NimNBsCfQNpFdCq3vGbklhA7QUjTyn1T+A64GullAXHIoKnG97eejq+1Zqtd/j58TwP8usmP+bMgW+OvswtX97CN0nfAPCXL/7COe+dw2MrH3P297AqeZUrvb2P3A0JCby18S28Ld5c2+9a7h16L6F+oa7JZADvb3mfBdsW8MS5TzCw3UAm9JiAn5cfKbkpTOhe+ZIK1eEsgKtqZukR0YMfb/qRJVcvYfrw6dw7tOJLAEZFj6LIWsQHWz7gojMuwt/bv042NHV6terFjjAr60PziW8Tj7fl9F/4oEdEj3rVdg0GqL1gTAWKgb+IyBH0+yme95hVjYi3t355gdV6DICdRyN5jMeZPDaHqVNhxb4VAMxcM5Nt6dv4avdXdAvvxhOJT3D3krsREX448IOrKWmvJQfJyWb+tvlcfMbFtA5sjZ+3H2O6jWHpnqWICKm5qdy15C5GdR7FP4b/A9BLLTin+telOcrJeV3OY2y3sVwde3WVYZRSjO8xnqdHP13pDNERnfTyEnaxc3nvy+tsQ1Ond0Qv9oQLG8OLGdh2YGObYzA0eWolGA6R+BAIVUpdBBSJyDyPWtZI+PjodV+sVr2aesKivvhSwisPJJNXksvalLW0C27HquRV3PLFLQT4BPDLLb/wt2F/49X1r/LYqsc4kn+Em+JvQqHYE1DEwdKjHM4/7FrMDWB89/Gk5qWyLX0bb258k+Mlx3lr4lvlan93DrqTIe2HcG6Xc+t+HV4+LLt2Wb3ExklEQASxrWNp4d2C8d2r6OH/E9MrrDtWL8j3lSbRf2EwNHVqJRhKqSnAr8BkYArwi1LqCk8a1lj4+LQGoKQkjW3b4JPV7biX2bRukccPyT9gExuvTniVEL8Qfkn9hVsH3EpEQATPjXmO4R2HMyNxBgAXdL+ADiEd2BtUwjq/ip2q47qPA+Cr3V/x1m9vMbbbWLq17FbOlgu6X8Avt/ziWhOoMXj8nMeZdcGseq3E2tTpHVz2chHjYRgMNVPbRtt/A4NFJB1AKRUJrAAWesqwxsLLqwXe3mEUFx/i8cchKMDO34//FzJ6szxvJS28WzCu+zjuGHQHL6x9gfvPvB/QK2R+cNkHxL0eR6BPID1a9qBbeDf2hhxkPdn4WHyIi4pznaddcDviouJ47ufnyC7K5qVxLzXWJVeLc5jt6UivAP0O+Bal0LvlGY1sjcHQ9KltH4bFKRYOjtYh7p8OX992JCXBwoXw19tLiCAL9u1jxb4VjOw8Ej9vP2acO4Pdd++mU2gnV7zosGi+vvpr3p30LkopuoVGs6clrA8rIDYqtsJqseO6jyO7KJuowCguPuPiU32ZzZ5guzftcyH+CHiXWGuOYDA0c2pb6C9VSi1TSt2olLoR+Br9etXTEl/ftixZol9BfvvfWkB4OKn7N7Mjc4erH8LHy8f1whh3zu50tmuce/fAjqQHwdrWJQxuN7hCWGe/wI3xN1b64hyDhykq4sWl8OT3QEFBY1tjMDR5atUkJSIPKqUuB4Y7dr0hIp96zqzGxc+vLcuXj+Css6B9e6BrV77N+Q0iKddxXRPdWjhelOMLgyppIx/ReQSvXfgaU2OmnizTDXWhqIgrfnd8LyxsVFMMhj8DtR54LiKLgEUetKXJcPhwX5KSYrjtNgEUdOvGV75f0z64fbl+iJro5lc2YW5QRGyF4xZl4fZBt58Mkw31wf3Vu8bDMBhqpNomKaVUnlIqt5JPnlIqt7q4jvjjlFK7lFJ7lFLTKzn+glJqk+OzWymV7XbM5nbsi/pdXv1YsUJPdps4UZtT3LUT30Yd56IeF9ZpAl03bz1b3L8UYvw7VR5o7VooLW2YwYb64S4YxsMwGGqkWg9DROq9/IdSyguYA4wBUoB1SqkvRMTZCICI/M0t/D1Af7ckCkWkmhWbPMfSpX3o2XMdbdu2AMJJbG8j/yhcFDakxrjuhFq9aXUcumeBT2El7wU/eFC/5HvBAphqmqVOOcbDMBjqhCdHOg0B9ojIPhEpARag16KqiquA+R60p1YcOQK//RbBiBGLKSk5BMBXfsn4l8J5RXVc16WggH+uhr+vAfLzKx5Pdww8O3SoQTYb6onxMAyGOuHJxXPaAwfdfqcAQysLqJTqDHQBvnfb7a+UWg9YgWdE5DNPGerOmjVAYBr94lZSUtILEeHL3PWcvx8COqfWLbHCQu5f4/h+/HjF4zmOFeKPHWuIyYb6YjwMg6FONJXV1q4EFoqIzW1fZxFJVUp1Bb5XSm0Vkb0nRlRKTQOmAXTqVEU/QR1Y/usf8LceHG5pp7j4ELuO7mJ//kH+sccCnfbVLTH3WmtlHkauoxsoK6v+Bhvqj/EwDIY64ckmqVSgo9vvDo59lXElJzRHiUiqY7sPWEX5/g33cG+IyCARGRQZGdlQm/nuj2/Au4TUUi9KSg6zNW0rAMOkA+ytoFfVU5NgGA+jcTEehsFQJzwpGOuAHkqpLkopX7QoVBjtpJTqBYQDa9z2hSul/BzfW6Hnf/x+YtyTjc0Ge9VSADJL/SgpOcwfOX8A0DmyO+xrgIdRWZOU8TAaF+NhGAx1wmOCISJW4G5gGbAD+EREtiulnlBKTXQLeiWwQJwvk9D0BtYrpTYDK9F9GB4XjC3bS7F1+g6A9GILxcWHOJBzgBC/EMKie9Xdw3CvtRoPo+lhPAyDoU54tA9DRJZwwhIiIvLoCb8TKon3M1BxppuHWbB6DfjlEeITxpFCKyUlhzmQc4DOoZ3BpytkZ+vCPTy8dgmaPoymjfEwDIY6cdouIFgfvt23FGzeXN3vKtIKCygoSuVA9gG9ZlR0tA504EDtEzR9GE2boiLw9QVvb+NhGAy1wAiGG7usywjLP5N+UbGU2u1kFZdwICdZexitHO/lPXq09gkWFoKfH7RoUX0fxrFjUK5FrglhtUJJSWNb4RmKisDfHwICjIdhMNQCIxgOMnJzKQzfSL/AMa4ly/cfh+yiHP07IkIHrKtgtGgBgYHVexg2G+TlNfAKPMS998LFp+nS607BaNHCeBgGQy0wguHgl727AIiJ7OcSjK2O8rxzaOf6CUZBgS6MgoKq78OAptuPkZQEO3c2thWewXgYBkOdMILh4LeDulDsE9mromCE1VMwCgt1YRQUVPVMb2/HuIOm2o+Rm9t0xayhGA/DYKgTRjAcbE/bATZvYjt0JdQ/lFC/UH53tBJ1Du2sO0eDgk5uk1RuLnR0zG1sqoVybq62/XTsxzAehsFQJ4xgONibsxOyutM2Sr/5rlNoJ0rs4GOxEBUUpQNFRNRPMKpqksrJKRt91ZQ9DGi69jUE42EYDHXCCIaDg4U7IbM3rVvr385mqSh/LyzKkU0nUzBEdGHsFIym6mE4O+Obqn0NwXgYBkOdMIIBlNpKybDtwZLVi9BQvc8pGK19rdjtjhcc1VUw3Du9T+zDyM/XotGUPQy7vXkIhvEwDIZaYQQD2J+9H7sqJbi4F84X6nUO7QxAa3+hqMixhpS7YIjoArU6nJ3elfVhOJt6oqL0XI2mWCC729wUBa2huHsYRjAMhhoxggHszNQjpFpbern2OT2MNn5QUKCH3JYTjPffh/btq+8Mrq5JyjkHIzRULzVSWYGclQWLGvE16u5zQ5qioDUUdw/DNEkZDDViBAPYkbEDgPZ+PV37yvowThCM7Gw90e6XX/Tr+U5cwfadd2DWLP3dXTAKCsp7JE4PIzQUWrasvEB+91244grIzDwZl1l3/gzzRBqC8TAMhjphBAPYeXQnXgVtaRcR6to3pP0Q/j3i34xqE1FeMES0N5CcrPft3l0+saefhtdf19/dh9WKlK/FOj2MkJCqPYyMDL1trMK6OQmG8TAMhhoxgoGjSSqjN+7vX/Lx8uHJ856kTWhvCgvdBAN0s5RzEcKkpLJIqan6t7Ogd+/0hvLNUrXxMJzNX9nZDbvA+tJcBKNFC920aLPVHOfPTnJy87hOg0do9oIhIuzM2IktrReVvbCvRYueFBQ4vAh3wXB6GO6CsWqV3mZn6wKouLi8YLiPlKqNh9FQwUhLg9LS+sWF5tOHERCgf5/uXsbRo3DGGbBwYWNbYviT0uwFwyY2/t7/Sdg+xTUHw52AgJ6UlqZTWppdJhi7d5cV/pUJBmhvQyfQOB5GSQn07AlvvFH3uCfaGBl5+gmGSHkPA07/foyMDF2BSElpbEsMf1KavWB4W7yZEHkXHBhVqYcREKA7wgsKdpYJxoYNehsWVr4PY+VKvYQIwB/61a6uPgwoLxhODyMoSHsYeXkVvQGnYNRnSGtmpj5HXd7fcSJOwYiOPv2G1TpHtzUnD8N5/zXVlZENTZ5mLxhQ1uVQmYcRGKhf/Hf8+OaKgnHeebq2VlAABw/qV7hecIE+5i4YVXkYwcHg5aU9DKjoSTTEw3COrHLvh6grzoKlc+fTz8Nwvm2vOXkYzv/TCMafg/37dWVm+/bGtsSFEQwgPV1vK/Mw/P2j8fYOIy9vo+5v8PaGTZv0wdGj9XbvXvjhB/19yhS9rUwwTuzDCAnR352vfHWvxYs0TDCcKuj0ZOpDbq6eVBgVdXoLRnPzMCpb18zQ9Ni9W9+TO3Y0tiUujGBQVrZWJhhKKYKCBpCf/xsopb2BwkJd2A8ZogMlJcGSJbrgP/98va+mJqncXFzrkDg9DPdC+fjxsmaThngYDRWMkBBt37FjNc9s/zPRHD0M0yT158LZOtCQZ/gk41HBUEqNU0rtUkrtUUpNr+T4jUqpDKXUJsfnFrdjNyilkhyfGzxpZ0YG+PiUld8nEhTUn/z8LXpNKWezVOfO0KOH/r5yJfzvf3D99WWvcj14UG+r6vR29zCcaTpdHSgvHg3xMBrSJOUuGCJN6sZtMM3RwzBNUn8unM9bYw2rrwSPCYZSyguYA4wH+gBXKaX6VBL0YxGJd3zmOuK2BB4DhgJDgMeUUuGesjU9XXsXznWkTiQ4eAAixeU7vqOjdWEaFaUn6tntcN99WnnCw2tuknL3MHr31iffvLnsuPsih43lYeTl6X6WyjygPzvGwzCcChYtghkz6hfXWdlrDoKBLuj3iMg+ESkBFgCX1DLuBcByEckSkWPAcmCch+wkI6PyDm8nQUEDAMjP31jewwDtZVitegkP58qzrVqVFwxnDbYqDyM4WI+Pd3amQ5lg+Pt7zsOoqYB09zDg9BWM5uZhmD6MU8dHH8FLL9UvbnPyMID2wEG33ymOfSdyuVJqi1JqoVKqYx3jopSappRar5Ran+EsJOuI08OoioCAHlgsAbrj293DgLJmqQceKIsQGVn2cLZoARaLLpSq6sMAGDiwcsHo0sUzHsaqVdrzeeSRqvsmThSM02lorfEwDKeC7Gz9LDvvt7rQzDyM2vAlEC0i/dBexHt1TUBE3hCRQSIyKLK6Ur8aavIwlPIiKChed3yf6GHceSc8/zwMHlwWwd0OZ2HUsmVZrR/KexigBSMlRc/OhjLB6Nat4R5GZYKwfLnul3jySZg0qfLlIppLk1Rz8zCMYJw6nJWsQ4fqHreZeRipQEe33x0c+1yIyFERKXb8nAsMrG3ck0lGRvUeBuh+jPz83xBn4en0MAYNKu9dQFnHN5QVRr16we+/6+9Wq67NnuhhQJmX0VDBcHoYIhVf3gSwbh3Ex2vB+PJL+PXXimGcHoZz2G9VgmG1wtixuvO/PixcCP/5T/3i1pem6mEcPw633VbzCsXFxXW/L4yHcepx/kcNEYwmNNjEk4KxDuihlOqilPIFrgS+cA+glGrr9nMi4BxwvAwYq5QKd3R2j3XsO+mIwLPPwuWXVx8uKGgANls+xX0ioW1b3edQFZV5GDExWjDs9rLaf7hbP37//nrrLhhBQbpTvaio7i5tRoaeFAgVbzgRWL9eDwueNk3vc84jcae2gpGWpmUek6EAACAASURBVD2W776rm41O/u//YPbs+sWtL5UJRlPwMH79VS/n8vnn1Yd74gkYOrRuabv3YZxOQ6SbMk4PI7Ue9d3m1CQlIlbgbnRBvwP4RES2K6WeUEpNdAS7Vym1XSm1GbgXuNERNwuYgRaddcATjn0nHaXgjjvg7LOrDxcaOgKAowNLdG3BvTnpRNw9DHfBKCjQS3U4RSE+vixcSEj5ju+jR3XzV1iY/l2XWoaIrqE6vaAT4+7dq2/kwYO1uPXpA4mJ5cOUlupCNSREL3cSFFS1YDgF8MiR2tvozs6dOo1TWYi5C4a3tx7d1hQ8DGceOyeHVsXu3bBnT/V5lpEB//ynrhxA+T60pnCtpzt2e9mzVx/BaIJNUt6eTFxElgBLTtj3qNv3fwL/rCLu28DbnrSvLrRo0Q0/v84cO7aC9u3vqD6wu4fh76+3MTF6u327foAtljKvwsnAgfDjj/p7VlZ5wcjO1t5GbcjJ0c1E3bppcThxpJSz+cnZ7zJyJHz4oY7j7bglnLXR4GC9rWqBRChrPjl8uHb2uZOXV7YYXlZWebH1JO6CAU3nnRjOpsjffqs+XHq6LpCys8v6mNxZtAhuvVVXDPLydNOpe1NUXl7ZcG+DZ8jN1ZU3qF+TVHPyME43lFKEh48mO/t7RGp4n4BTMPz9yyZ39HFMQdm2Tfcf9O5d8YF1dnynp1f0MOpy0zgL8G7d9PZED2PdOu35OEVs1ChdgLjXap03q9OTcs72rgynh1EfwXBfvNF94qKnqUwwKuvrOdU4RXnz5pq9B6i6r+Pee/UrhNu0KRMhdw/D9GN4HvfnpSEeRl6ersw1AYxg1IGWLcdgtWaTl7eh+oDOWrKzOQp0wd++vfYw1q0rP6rKibNN+qefGiYYzsKkOsHo37/Mmxg1Sm/dm6VOFIzoaC0ozhqTOw3xMHbuLPvemILRqlX5UWyNhVMw8vN1k1NVOPOqMsGw23Xz4CWX6P/NXTCc3ogRDM/j/szWtw/Dufp1Q1ZsOIkYwagDYWHnAXDs2PLqAzo9DOcIKScxMbpzOCOjcsEYMkSvO7V8eUXBqMsciBM9DPebzWqFjRvLn79tWz2fxL3j21mgOAXjssv0ZMTKRlM5z5eeXve3ue3aVfa9MQTDz09v27QpG9LcmLjP8K+qWcpqLROWykTu6FEtGlFR+h5yppmXp68TzOS9U4HzmW3Xru5NUqWlup+po2OwaBNpljKCUQd8fSMJCurPsWMrqg9YmYcB0LdvWaFUmWD4+sK558KyZfoG8YSH8fvvuq3+xPOPHKn7T5zNIE6RcfZhTJyo7fv446rP5z4CrLbs3Fl2jQ0RjKNH4a9/rX0/RFGRvh6L4xGIiqrYaV9crIVy27b621VXsrL04Adv76oF4+jRMk+vMg/DmY+tW5cJhogWiXbt9DHjYZxcNm+Gq68u/04bp2DExGgPozLvvCqcz1+nTnrbRIbWGsGoI+Hho8nJ+QmrtZoaWmBg+eGaTpx9Bj4+0K9f5XHHjIF9+/TN1dA+jC5ddB+Ku4fhnAsSG1s+ztln6xvcWeM/sUkqNBTGjdOLLJ7Ytu5eaNW1WWrnTjjrLG1nQ5qEli7VQ3N/+aV24Z1v23Pi9DDcH+qkJPj0U/jqq/rbVVeysrTHFxNT9Ugp93yqTDCclZKoKN0EdfSoFj+rVacNRjBONl9/DfPn63dYOHE+szEx+n6rSyuB8/lzThA2Hsafk5YtJyBSSlbW0qoDKaWbpaoSjLi4sqaQExkzpux7RIQu1Hx96+5hOBc9DAkpXztxdjI7lzRx4uw/cRa4JwoG6Hd9pKTA2rUVz+e8nroMrbXZtD19+mivrCEehnOklXMNr5o4UTCc813cxdUpfu6FgKfJytKFfP/+2sOorFbqnk/VCYbTw8jPL2vCMh6GZ3DeK+6vv3X3MKBuzVLOZ9bpYRjB+HMSFjYCH59IMjIWVh8wMrJiH4ZzpNT/t3fm8VFV5/9/n1mykIRMdghhi+xERBYRtYLUXRFr1epX5Wvr0var/qpWrbZqrV1sa61La11atVZsFQSUVhGq4kKrsklYE2RPQlay75mZ8/vjmZuZSSZhEkMmynm/XvOaufeee+5zz9x7Puc5a6jqKIsJEyArS36npIj4uFw99zCsarHExM6CMWJEZzEbP17EwRKMjt1qAebPF2HoWC1VUSG9vqBnHsaBA1LynTBBMre+EAxrWvl162S6+a7aVEJ5GBDcjmGJX38KhtV2deKJkh6h0vNIHoaVjlYbBviX6rU8DNOG0bdYYhAoGNXVUuU5XpZ57lHDt/EwvhooZSc19RscPvwvPJ5u6st//nP48Y+D9yUkwOLF8KMfdXcBv5dhvezhCIbWct5ttwXPdTJ4cHCpedeu0KPUbTYRMqtR2zonsOvv4MEyBcjrrweXfCsq/FVcXQlGx/XKwd9DasIEsfeLCIYlFJaHsXQpvPSSjEMJRSgPA4I9pP4WDK39HkZOjuwLtdqalU5ZWV17GA6HjNC3nqH9++XbEkbjYfQtXXkYLpe/ANgTwTAexleHtLRL8XobqKpa3XWg888Prl6yuOwyf6mhKy67TDwAa6R2OIKxfj288w489hisXRvaw9C6a8EAqZbaskUajmtrRSys6UUsFiyQTHnLFn+cFRXSm8PlCl0ltWKF2NHRJQ8UjL7yMCzBsLqkdrUecjgehpUJHDjQ895fvaGpSTyu5GT/M1JQ0DlcebkI/LhxXXsYaWkSpqOH4XLJsxUoGIcPw113+Vd4NPQc69kOFIWqKhFtqxqwJ1VSVoEtK0sKkUYwvry4XHNxOJKOXC3VW847TzJ5y0sIRzCee04ygkmT5NxQglFeLr+7EoyTTvJ3u83PD57ryuLCC+UBtuY6skaVp6ZKphvKw/j97yUz3LQpeH9urr+eva+rpCzBsBr5O9ITD6OtrXcjdXuK1f01OdlfKg0lGGVlkmYZGaE7CpSW+u+no4cRHy+ebqBgvP66zLgcqsu04choHdrDqK6Wdyg6Wv6H3ngYSUni2RvB+PJiszlJTb2YiooV3VdLfRGcTv/vIwlGY6P00LjsMqmGcThkkCAEV0l9/rl8dycYAI8+KmuUX3995zAZGXDyyeI1gD/DSk2V+vGOgrFzp398R+CYC5D9X5M5ukhPl3vsTSm3tdXvGRw4IC+wVRXVlWBUVPjXWgd5oe32zm0YVrfb/qiWshqmU1Ikk8nICN2Ib83Hn5radZWUNV9/Rw/DEozANgzr3qwwXfHgg3DVVT3rHnosUFnpf25DVUmBvI+9EYzBgyUO0632y01GxtV4PLVUVCw7+hezBKOwMHQG8tprUmK87jqYNk2qp+72LaEe6GFYPaS6EoyhQ6VqaelScaN/+MPQ4RYskEkSCwv9GVZaWmjBeOYZEb+EhOBR3QcOyOf002XbyuACM8CSkvBGuFql/0mTJCPMz/dP8xFKMMrKxH5rhDuIWKSnB3sYxcX+tpm+FIxzzoEnn+y83xIMazT2iBGh/2+ryik1Vf7bju1DZWVdexgJCZ09DOverDBdsXixrCDX21mJv6pYz7zLFdrDAHmv9u4NP87aWnlvYmJ63unlKGIEo5e4XHOJjR3DoUPPHv2LJSVJqXH4cBlbceut/ow0P1/WtBgzxl9anzrVn+kkJvrD7tolD2F3bShW99pf/jK4BB7IRb7Jhles8GfwVpVUSYm/BNrYCC++KMvXnnBCsGBY05BYmbYlGIHVUnPnwi23dG2rhfWSnnKKfFvrcuTkyDU7tj+8+abYaN2HRUZGZw/jpJOkCq6vBKOsDFavhkWLOh8LVzAsD8OqsgwcHa51cJXUoEGS6QR6GPHxwYJhZWTdCUZrq99D/PGPe+9lfPSRtM0NhFH1XdHTe7MKLDNmyP9reRuBHsasWVJ4CTfjtxZY600vyaOIEYxeopSNoUNvoKbmQxoa8o58whfh8svh29+WtYFvuEEGqGVkyKjwadMko3nmGf9Eh4EMHiz19a2tIhjHHeefQyoUN9wgn4ULuw4zYYLEs2qVv0rK8jCsBnOQRvjqavF8JkwIrpL64AN5EazeQFbmZwlGZaWE7zjteigswZg9W77fe0++L7pI7r1jZr9ihbQRBE4vD37BAzmvulrEddiwvhMMa/T2hg2dJzsMbMMAv2B0zMDKyvxVUhDsldXXi+2BS0impPhHwPfWw8jLk7aqs84SD9aqkuwpL70k4vXmm707v6Dg6E7NrrU8F/fff+SwFpaHYXWXP3RI4rEavUEGxmoNH38cXpyBSzgbwfhqMGTItSjlpLj4z0f3QtOmwfPPywykTz8tjZPf/a6UQs48U3oszZsX+lzroaup6b6HlMXZZ8sCPrZuHg2lpPT/0Uf+DN5qwwD/C7Rxo8Qze7b0RS8v95eiP/xQPCKrF1ZHDyM3V7737z9yY3hHD+P99yXe88+X7cBqqaYmKeFfdFFngQ30MCzhGDpUvLq+EgxrvRO3u3PmEdiGASIYjY3B08q3tUlGZFVJQbBgBI7ytrDis9nE2whsw2hs9J/TUTDq6vzVmFavuIcfFm/20UfDvuV2tJa2MZCR+T2lqUlmSLjzzp6fGy75+XKvPbHP8jAswSgs9BfSLA/jpJOkoLZ2bXhx1tT4393ERCMYXwWiotJJTV1ASclfu58qpK+ZMUO6z27aJL2VrG57obAeuupqafQ+kmCEy5w5knG99570zoqL83dNtTLbTZtkQN+gQeJhgLyQxcViS2AbQkfBCJwWY/36ztevrZVlEvPz5QVNSJDR6w6HZKAjR/qnXwnsWvvee5JJdqyOguDpQax7GDKka8HQuucv8qZN8n/Z7Z1XOaysDJ5Sxpp4LrBayhKHQA+jvFzaFVatCh7lbWEJRkKCiGSgh2GJRFaWXCdw2pcHHpDCSn09bN0qMw5MmiRrwH/8cc/XD9myRRp+k5LE++xpV+WVKyW9Fy8+etN9/9s3sWhubvgdMIqL5T2z3q3CQv8ob8vDiIuTwZjhCoa12iV07WHU10sPxMsvl2l7+gEjGF+QrKwf4nZXcujQU5E2JTTWQ7dhg/Tx7zglSG+xMvv33vNnXJaHYZX4N26UDAf8gpGX588orQZvkBfO6QwWjJQUKRWH6u65fDksWyaNxwUFkuHZ7f7uqGPGSMY4fHiwh7FihdThz53bOc6MDMkkqqs7exhFRTKn1OTJ/kbfO+6Q4z2pj9+0CU49VdY+6SgYhw8HL4ZkDdoK7FobWAUYKBjf+Q5ce63f7lAehjUIM1AwrPaLefPk3gMb/deulWqz1atFMCZOlP9ozhwJG+68XRaWd3H//ZKhhioIdMfixfJdUSFe5NFgtW9sVWur3HM4HDokz4HVM7GoyJ/BWx4GSLXUunXhCVGgh+FyiYB0nMPt7rulY8q6dfIs9MOKlUYwviCJiSeTlHQ2BQUP4/EMwGUvrYfu3nul9NpXJZERIyQj9Xj8GdfYsSJQ778vpa7iYskYQRo6nU4RjBdekBJw4IqDSgWPxfjsM3Hjc3JCC8ZrvjEwS5ZInbhVGre+x4yR70mT/IKhtZRSzzwz9FxegR6SVa1meRhaS8l6507pJXbrrVK6a272t5l0xRNPwFNPSSa5b5+I6Jw5kuEGltKtVRYD0xiCPYzAmWitdH/rLQlTUiJjKqB7wYiPl9Kp1n7P6Ywz5NvyOFpa/F7eG2+Id2D1GDvtNPm/Qq0D3x1vvSX3fs01cv6qVeGf29gogr1wodi/ZEnPrg1yvx17lO3cKVWZl14qGfn778s4KAgWNK3F+wg1Qr64WLzGxETxJEJ5GCDp1tzceTxSKKxGbxDB0Dr42lrL/3LxxfKfLVrUfTVyH2EEow8YNep+2trKOXTo6Uib0hlLMPbulbpfKxPqCywvw2qwdjrlZfvXv/x19ZaH4XCIoCxZIqW4O+/s3Pieni6l5eZmeZFPPFFEY9264Ibf2lqJY+xYySQ3bvR7Ftb9WYKRkyOC0dAgcRYU+DOEjliZbGmpxGtNIjl6tD/OzZtFRB5/HC64QNLXEozcXKnGeecd/3obTU3Sq+jWW8UrAhHRUKV0a1oQi7Q0EbZAwQj0MJxOuf5bb8nvqCh/KTxwmeDAKinrW2vJhPftkypDq/7dEowtW8S+1FQRoaIifxWfyyW93noiGFVV8N//SrtSSopcryftBCtXyn+4cKEMHl22rPtqqVAN4/ffD9nZ/v9myRJ5Pj/7TLqS33yzCOn118t9BwrGypXSvnfJJXLdzZvFqysv93sYSslz2JVgnHqqfIdTLdWx0RuCq6W2bJHrzJ9/5Lj6kKMqGEqpc5VS+Uqp3Uqpu0Mcv10ptUMptUUp9a5SamTAMY9SarPv08suGf1DYuKpuFzzOHDgFzQ19eNEdeFglVKysrqfw6o3WIIRuA73/PmS4T7zjGwH9kSaMEEyqLQ0+H6IddGHDZMXceNGeSmnThXBqKyUNSkeekiq1t58UzKzJ5/0d/21BKOjh7FggWQQS5f6M6iuvKxAD6OkRATM4ZCBij/9qQjBlClSJfXAA/DKK1K1ZQnGbbfBz34mPYlmzxbvy8roWltlvQ6QTOq006REGFjK7igYNpvcT1cehpX2WktmdvbZcp3k5OCBn6GqpEBKrHv3iiBa09BYgmF5dffc4+/1Fjgl/pw50o5hVa+0tcl/dcMNoTPrZ5+VKhMrgzvvPBHLm24KHrvQkaoqEcQ//EHudc4cGaBaURFasLxeqSpMSIBf/cpf0CgpgUcekWu98YbYe+ut4oHu2SP/15//LGk+b54ImiUYWsugxYQEeQYuuUQ6bLzwgjT+Wx4G+AUjVJVURoYUchYt6n58kdbBHoYlOoHPgTXlvtWxo7/QWh+VD2AH9gDZQBSQC0zqEOYMYJDv9/eBVwOO1ff0mtOnT9eRoqHhc/3RRy69bt0U7XbXR8yOTjQ1aX3CCVq/8Ubfx71vn9ag9Q9+4N93+LDWdrvsHzcuOPw998j+3/wmdHzvvivHJ02S7127tN68WX4nJsp3bKzWkydrPXSo1h6P1ldeKfuffVbiePpp2d65U7a9Xq3HjNF67lytzzpL4u6Kigo597HHtJ4/X9LtSDz+uJzzzjvy/eMfa/3oo/L71Ve1vuIKrVNTtb79dtk3cqT/3AsukPtobZXtoUO1vu664PjnzdN69mz/vSxYoPWgQXLvWms9a5bE+8ILWv/1r/J7woTgOKz98+fL9ksv+dN3yhStL7xQ9qelaX3jjfJ74UKtMzK0rq3VOipKwhcV+eNctkz2rV0r22++Kdug9fHHa/3Pf8qzp7XWBQVax8VpfdFF/vNrauRaDof8t3v2dE7b/fu1zsz0x3vXXbK/sVHOWbAgOHxdndaXXCJhc3Lk+/LLta6q0vq22+S5TEvT+pxztF6yRI6vWCHnbt+utdOp9ckny/Z992lts2ldX6/16tUS9umnJR7Qeto0eZ7i4mT797/3p9vw4Vo/8YTsLysLtnH5crnn2bO13rRJ6//8x59OFg0Ncu6vfy3blZVaJydrfeaZ8gxY//tJJ3VOs14AbNDh5uvhBuzpB5gNrArYvge4p5vwJwL/Cdj+UgmG1lofPvy2XrPGprdvvyqidvQrt9+u9UcfBe87/XR5tK64Inj/J59I5lRX13V8V1wh58bHS6bY1iaZQ2qq1n//u9YzZsjxm26S8P/8pz/D1lrifuWV4Dh/8QsJ43SKvV3h9YogXXKJXOecc458/1u3StyjR0uGVFQkdo8fL5lxXJzWN9wgL31SktaXXeY/94035Nzly+Xa0dH+TNHi2mu1HjZMfr/yioR/6CH/8QsvlPuqrJSPw6H1nDnBcVhpdOWVsr18uWxv3Kh1QoLWt9wi+2fO1Prss+X3hAl+gTn/fEl/K7PSWuvyconjl7+U7auukvt74w3JlEHu/brrtD7vPK1jYrTeu7dz+uXlyf87a5ZfOK34x4+XYytXSsYbeP2f/1yusW6dbG/ZIjYrJYLt9UrBxGYT0YmJkbS8/34Jc/zxIt5utz/Ot97Sev16+b1ihcS/eLHYlpWldXOzPI/Ll8tz9t//+sXMeuYsoZk+XfYH3pPFsmXyP1nnzp4tcVscOiT7n3rKv++xx2Tfm29qXVIi9/Dgg53j7gUDRTAuBf4SsH0N8Mduwv8RuDdg2w1sAD4BLg7nmpEWDK213rv3Xr1mDbq6+j+RNiVy/O538mj99rc9P7ewUMTi1FP9+3bu9JfU6urkRSkokG2vVwQrMDPpyMGD8oKB1v/+d/fXf/BBCWezSQZzJLxerdPT5ZzAEvRzz/kzhNWrZd+uXfKyW7S1iRice27nUqXFffeJ7W+9pXVKipQq29r8x5cv1/qRR/zbd94pXk8gVsZmeQ+WN7R0qQ4qHV96qXiF1dWy/+c/l/3792v98ced733GDMl0S0pEHKz4W1q0XrVKxGLQIInrgQe6TsNXX5Uwd9whYltcrPXUqSKgH34Y+pzaWkmPs84S+2NitB4yRLzUQNavF3GIjtZ6924RLet/6ZjWgRQX+8OB1s8/Hzrc7Nly/IMPZLu0VOuLL5Z9gwd3Hf/mzSJGlje6cKGk49Kl4uWACL1FS4vWY8fK8zJlihzftKnr+HvAl04wgKt9whAdsG+Y7zsb2A8c18W5N/qEZcOIESP6JAG/CG1tdfo//xmiN248RXu7y8S+yhw4oPVxx0mprzesXav1Z5/1rU1nny2ZV0f3vyNut9Zf/7q8GnffHV7cllcU+II3N8vLnZISnMF3xCrx3nSTDqpas3jhBX+mFRcnVSc9JT9fzre8q08/1e1VhpaHo7Vk2NHRWr/4ouxftar7eNeuFdsnTpTw77/fOUxVlXgdoUragVx/vcQxfbrWo0bJvb79dvfnPPywP23mzw8W40BaW0UALM44Q+6zvLz7+O+4Q6oY8/O7DrNypfzHpaXB+9ev13rNmu7jt/jZz4LFacQIrf/0p86FoLffFk9nzhwpSPRR/jJQBCOsKingTGAnkN5NXH8FLj3SNQeCh6G11kVFz+o1a9BlZUsjbYrBYv/+zlVnXVFSIqXnN98ML/x774lodBSGtWuPnOkeOCCZl90uVUIdM6eGBqmKW7NG2lh6g9U2c//9sn34sFTfTJsmJduqKtn/zDP+TMtul3BHwqrTHzbM367SGzwerRctkgwxPd1fNdQdjY1i/6JFPcs8d+3yV2H2BV804/Z6Je0ffVSepSOJax/TE8FQEr7vUUo5gF3A14EiYD3wP1rr7QFhTgReA87VWn8esD8JaNRatyilUoGPgQVa6y7mqhZmzJihN2zY0Pc300O8XjcbNkzF621k5sxt2O2DjnyS4djl0CF/H/6jgdcLV18tPdOsCSpD0djon5hx1Cj/dPfd0dgoPZe++U3/DMlfhNZW+QSu9Gg4qiilNmqtZ4QV9mgJhs+Q84HHkB5Tz2utf6mUehBRtBVKqXeA4wFrTuyDWuuLlFKnAM8AXqTr72Na6+eOdL2BIhgA1dUfsHnzXEaMuIfs7F9F2hyDwWAIyYARjP5mIAkGQF7etyktXcT06Z8RH58TaXMMBoOhEz0RDDPS+yiSnf0wdnsi27dfSktLiKVLDQaD4UuEEYyjSFRUKjk5r9PSUsjmzXNpaemHdaENBoPhKGEE4yjjcp3GlClv09p6iM2bzzCiYTAYvrQYwegHgkVjLi0tPVgM3mAwGAYIRjD6icTEU32iUWw8DYPB8KXECEY/0lE0mpu7maXTYDAYBhhGMPqZxMRTOf74lbS2HmLjxhM5fLgXaxsbDAZDBDCCEQFcrtOYPn0DUVFD2br1PPbuvQev9yitUWwwGAx9hBGMCDFo0HimTfuUoUNv4ODBX5ObewZNTfsjbZbBYDB0iRGMCGK3xzJ+/LNMnPgy9fWbWb8+h6KiJ/kqjb43GAxfHYxgDAAyMv6HmTO3kZh4Cp9/fjN5edfi9bZG2iyDwWAIwgjGACEmZiRTpqxi1KgHKS39G1u2nENz84FIm2UwGAztOCJtgMGPUopRo+4jJmY0u3bdyLp1Exgy5Ds4HIOJihpKZub3sNmiIm2mwWA4RjGCMQAZMuRqXK457N37Iw4degalbGjdRmnpS0yY8BJxcRMibaLBYDgGMdObD3C01iilKC9fRn7+9bjdVcTEHEda2iWMGvVT7PajtOiOwWA4JujJ9ObGwxjgKKUASEu7hMGDT6as7B9UV79PQcHvKC9fSkrK+VRVrSEmZjjZ2b8hPn7KF7pea2sZDQ1bSUr6el+YbzAYvkIYD+NLSnX1h+TlfYfW1iISE0+jrm4Tbnc1KSkXkJJyAYMHn0xs7Fi83hZaW4tpaTmEx1NHcvI5nZaMtbwYgNzcc6mqWsXUqR/gcp0eiVs7ZigpeYnExFOJjc2OtCmGYxjjYRwDuFynM2vWLrR2Y7NF0dZWxcGDv6as7FUOH/5nl+clJMwgJ2cF0dFDaWkpZu/eu6isXM0JJ7yD19tEVdUqwE5+/g3MmJGL3R4TMp66us1ER2cRFZUalr1tbYdxOlN6c6tfSRoatpOXt5C0tMuZPPnVSJtjMISF8TC+YmitaWzMo6FhK01Nn2OzDSIqaijR0Zm0tBSRn38Ddrvsa2rajdZu7PY4nM5UYmJGUVe3kfHj/8z27d8MWo+8uPgFmpsPkJp6ESUlL1JU9ASDB5/KiSd+1O6d1Ndv4+DBh6iv/4yWliImTXqFlJTzKCx8gt27f0BW1m1kZz+EzRYdZHNLSwlNTZ+TkDCzS4EKRWtrKU5nevv1Q9HUtJ/a2v+Snn4FSvW+F3mgF3Yk6uu30ty8l9TUBV2G+fzzWykqehylojnllGKczqRe22YwfBHMmt6GLqmr28z+/fcBNqKjh5GVdZtv9tx5gIdRox5k1Kj7yMu7jpKS5xk58n5stij27bs3KJ7ExDnU1HzApEmLSUmZz969d1JU9CccjsEkJs6hlVNRIAAAEyJJREFUsXEHbncNOTnLyM09E6czg5aWA8THn0hOznJiYkYCUFX1Ltu3X47bXYnNFktGxtWMHfsHPJ4m8vOvIz7+REaNuhetNeXlrxEffwKDBo3j0KFn2LXre6SkXMSECX9tz3BbWyuorHyL9PQr0drDpk0zaWjYRnLyuUyY8FKXHlFT0x5aWgoBG4MHnxQkarW169m69XyGD7+L4cPvaBeOkpIXKStbzMSJf2v3nrzeFtatm0hz8z5yclaQmjq/07U8nmY+/ngY0dGZNDRsY9y4p8nM/G5Iu6qq1lBauojjjnsEp9PVk7+6W1paSoiOHtJn8QVSVfU+cXGTiYpK65P4vF4327d/k7i4SWRnP9Sj85qa8omLm9yj62ntBVTYBYQvOwNGMJRS5wKPA3bgL1rrX3c4Hg38DZgOHAa+pbXe7zt2D3Ad4AH+n9Z61ZGuZwSj9xQW/pHi4meZOvVDnE4XXm8bu3Z9l5KSFwDIyLiG7OxfU1n5NrGxY0lMPIUNG6bjdlcTHT2U2tpPyMy8idGjf4bTmUJ9/TY2bpyB1m4cjgRmztxBXd0Gdu68Bpstmuzsh6itXUdx8V8YNGg8o0bdT1XVuxQX/5nExDm43VU0NGwBYMKEv9HYmMfBg79CqSjS0i6hrOwV4uOn0dCwlaioTMaPf5b4+BPYvHkejY07SEmZT0zMaIqKniAz8/8oLv4LDoeLkSN/Qmbmd7HZovF6W6mqepeioj9SWflWe1okJn6NKVNWY7fH4PW2snHjDBoadgAeMjO/T1LS2VRWrqS4+FkAUlIWkJOzHKUUBQWPsmfP7URHD8ftrmXGjI3Exh4XlNalpX9n586rmDJlNbt334bDMZhp0/7bfrypaR9tbYepqlrFvn33A17S069k4sSX2zMxrTU1NR9SUPAIzc0HGDx4FklJZ5GaelGQ2Hk8TSjlxGaT2ueGhjz27r2bw4ffYOTI+xg9+sH2sOXlyygsfIJx454iLm4ira0VtLYeCupI4XbXsnPnQjyeGoYPv4Pk5PODMtaSkpfIy1uIw+Fi9Ohfkpn5XZSytx+vqfmY4uK/4HLNJS3tkvZefocPr6SxMZ+srFuCwgMUFDzGnj23ATBu3DOkpMynsPAxvN4WoqOzyMi4upP4aa3Jy/s2paUvMnbsUwwb9r0un/1AWlpK+OyzU/F6m0hKOpNhw25h8OCZncK53bWUlS0mPf0yHI7ELuMrLPwDjY07yM7+DQ7HYECErKDgYWJjx5Kefilaa6qqVhMXN4Xo6KFB50sB6G2amnYzbNjNXRZ43O7a9vh7yoAQDCX/+i7gLKAQWA9cqbXeERDm/4ApWuvvKaWuAL6htf6WUmoS8A/gJCATeAcYp7X2dHdNIxh9i9aawsJHaWs7zOjRD3Z6kauq1pCbOw+bbRATJ75EWtolQccLC//A7t3/jwkTXmTIkIWAZFjbts2nqWk3Nlsc6emXMWbM4+0Pe2np38nLuxalopg8eTEFBQ9TXf0h4GXIkG/j9TZTVvYPkpMvICdnKfX1uezceTVNTZ/jcCTj9TaTmXkjhYWPA5rMzO8xbtxT1Nfnsnv3bVRXr0GpKGJiRtHaWoLHU4vTmcawYbeQmHgqDQ3b2L37B6SlXc64cU9TVPQE+/c/QE7O61RXv09h4WPt9zd8+F04nSns3fsjjjvu96SmXszGjdNJSJjJuHFPs3HjdLzeZhISZgA26us3t2fmdnscs2btpqDgEfbuvYtJk5YQFZXBwYMPUVm5sv0aaWnfIjb2OA4e/BXjxz9HcvK51NSspaDgd9TVrcfpTCM+fip1detxu6txOFJITj6XQYPGUV+/mcOH3wQUgwaNo7W1jLa2Uuz2eOLjp1FT8yHjxz/P0KHfpqLiDbZvv9Qn8MlkZf2AwsLHcLurcLnmMWzYTdhsg9i790c0Nu4gKmoILS2FJCTMZMyYx0lMnE19fS6bNs0mPv5EbLYYqqvfIz5+GmPGPM6gQROorHyL/PwbAI3WbdhscaSlXQp4KC1dBEBq6iVMnLgIuz0WgObmg6xbNwmX62toramufg+lotC6BZstFo+nDqczg0mTXiEpaW57uhUV/YnPP7+J6OjhtLQUMXr0L6ip+Q+NjTtITDwdl2sOcXE5OJ2peDwNOByJOBxJbN48l8bGnaSkXEBV1Tu43TWMGHEXWVm3EhWVAUBjYz7btl1MY2MeUVGZjB79CzyeOtraynG5vk5i4mkoZefAgQfZv/8BAGJjxzFmzGNERQ1hz547qK5+D4Ds7IdpbNxOSclfcTozmDx5CS7X1/B4Gti//2cUFj6K1m5fHGOZMuVtYmOzaW0to7b2E6qr36eyciVebyuzZu3ulVc0UARjNvCA1voc3/Y9AFrrhwLCrPKF+Vgp5QBKgDTg7sCwgeG6u6YRjP6ntPTvxMUdT3z88SGPt7QUER09LGif211Lff0WEhJmhGyzqK/fgs0W48vkysnNnUdi4mmMHfskStlobMwnJiYbm80JSDXQwYMPU1r6EuPHP4vLNYeysiWUly9l/Pi/4HDEA7RnOJWVq2hu3ofD4SIlZQFJSWcG2XHw4MPs3XtX+3Za2reYPPkVABobd+P1NmC3DyY2djRae9my5Tyqqlb7QitmzPiM+PgTqK/PpaTkr9TWfgJAfPxUvN4WGhq2MmzYzQwZ8r+0tBTz6afZeL3NADgcLoYPv5O4uONxOtMYPHgW4GXz5jOoqfmo3abY2DEMH34HGRkLsdtj0dpDVdU7FBc/T23tJ7S0HCQqaghpad/CZnPS0LCTqKh04uKmkJFxJQ5HMlu3XkhV1b9xOJJwu2tISJjBuHFPs337pTQ37yEx8XRSUs6noOAR2trKAbDbE5g8eSku11xKS19m376f0Np6CKczHY+nFocjmRkzNuF0plNevpjdu2+ntdW/uqTLNZdJk5bQ2LiTkpIXKS9fjMfTyIgRd+N0JrNnzx3Y7QnY7XEoZcfjacDrbWHmzO04HIls2XIuMTEjyM7+NbGxx1Ffv4Xt2y+nqSkfuz0emy0Gmy2GlpZikpPPZdKkV8jNPZO6uk+JihpCQsIsamo+wu2u7PTcKRWN1m3k5LxBauqFuN017N59OyUlzwMQFZWJUk5aW0twOBIYPfpXFBX9gYaGre3/PWiUcmK3x+F2VzNkyLVkZCxkx44raWsrbb/O2LF/pLJyJRUVywDIyrqNw4ffpKlpDzExo3C7q3G7DzNkyHVkZn4Pr7eJbdsW4PE0+p7llva4XK45JCefx7BhN7d7kj1hoAjGpcC5WuvrfdvXALO01jcHhNnmC1Po294DzAIeAD7RWi/y7X8OWKm1fi3EdW4EbgQYMWLE9AMHzPxLXzV60uDcV9erqHid5uYD2GzRZGRcjcOR0GV4j6eBiooVtLVVEB2dRVraN3p0vdbWUhob82htLSUp6UyczuQQYSooK/sHNlsU0dEjSU4+q5PHF2xTIzZbdLdh3O5aCgsfp7W1BJstlpEj78XpdNHaWkFd3QaSk89GKRseTwMNDTvwepuIjR1DdHRmQBz1HDr0JM3N+wE7mZnfDSo8uN11lJW9gtfbgsPhIj398qDpbTyeRjyeeqKi0gGorFxFRcXraO3xfdykp19BSsp53dxHHUVFT9LWVo7X24zX24zdnsCoUQ/gdLpoa6umtva/JCWdic0WhdYempp209CwA7e7Grs9jra2Ct/4o7M7/X91dRuprv6A+vpcAByOJIYPv42YmJF4va3U1W0gJmY0dnsCVVWrqa1dh8dTT2zsaLKybkMpG21tVdTXb6K1tZT4+BOJi5voq5r6LfHxU0lJOR+3u4YDB35BS0sxSimGDr0Rl+tr7XY0NORx6NBT2GzRPvE7iYSE6e3eWG85pgQjEONhGAwGQ8/oiWAczdlqi4DhAdtZvn0hw/iqpBKRxu9wzjUYDAZDP3I0BWM9MFYpNVopFQVcAazoEGYF8L++35cC72lxeVYAVyilopVSo4GxwLqjaKvBYDAYjsBRG+mttXYrpW4GZOgwPK+13q6UehDYoLVeATwHvKSU2g1UIqKCL9xiYAfgBm46Ug8pg8FgMBxdzMA9g8FgOIYZKG0YBoPBYPgKYQTDYDAYDGFhBMNgMBgMYWEEw2AwGAxh8ZVq9FZKlQO9HeqdClT0oTl9xUC1CwaubQPVLhi4tg1Uu2Dg2jZQ7YKe2TZSax3W1MJfKcH4IiilNoTbU6A/Gah2wcC1baDaBQPXtoFqFwxc2waqXXD0bDNVUgaDwWAICyMYBoPBYAgLIxh+no20AV0wUO2CgWvbQLULBq5tA9UuGLi2DVS74CjZZtowDAaDwRAWxsMwGAwGQ1gc84KhlDpXKZWvlNqtlLo7wrYMV0qtUUrtUEptV0r9wLc/WSn1b6XU577vpAjZZ1dKfaaU+pdve7RS6lNf2r3qm5U4Ena5lFKvKaXylFI7lVKzB0KaKaVu8/2P25RS/1BKxUQqzZRSzyulynxr0Fj7QqaREp7w2bhFKTUtArY97Ps/tyilliulXAHH7vHZlq+UOqc/7Qo49kOllFZKpfq2I55mvv23+NJtu1LqtwH7+ybNtNbH7AeZRXcPkA1EAbnApAjaMxSY5vudgKyJPgn4LXC3b//dwG8iZN/twN+Bf/m2FwNX+H4/DXw/Qna9CFzv+x0FuCKdZsAwYB8QG5BW10YqzYDTgWnAtoB9IdMIOB9Yiaw5ejLwaQRsOxtw+H7/JsC2Sb73NBoY7Xt/7f1ll2//cGQW7gNA6gBKszOAd4Bo33Z6X6fZUX9QB/IHmA2sCti+B7gn0nYF2PMGcBaQDwz17RsK5EfAlizgXWAe8C/fi1ER8FIHpWU/2pXoy5hVh/0RTTOfYBQAycgyAv8CzolkmgGjOmQwIdMIeAa4MlS4/rKtw7FvAC/7fge9o76Me3Z/2gW8BpwA7A8QjIinGVIYOTNEuD5Ls2O9Ssp6qS0KffsijlJqFHAi8CmQobUu9h0qATIiYNJjwF2A17edAlRrrd2+7Uil3WigHHjBV132F6VUHBFOM611EfA74CBQDNQAGxkYaWbRVRoNtPfiO0jpHSJsm1JqAVCktc7tcGggpNk44Gu+Ks8PlFIz+9q2Y10wBiRKqXhgKXCr1ro28JiWIkK/dm1TSl0IlGmtN/bndcPEgbjmT2mtTwQakOqVdiKUZknAAkTQMoE44Nz+tKEnRCKNwkEp9RNkEbWXB4Atg4AfA/dH2pYucCAe7cnAncBipZTqywsc64Ix4NYOV0o5EbF4WWu9zLe7VCk11Hd8KFDWz2adClyklNoPvIJUSz0OuJSsxQ6RS7tCoFBr/alv+zVEQCKdZmcC+7TW5VrrNmAZko4DIc0sukqjAfFeKKWuBS4ErvIJGkTWtuOQAkCu713IAjYppYZE2C6LQmCZFtYhtQGpfWnbsS4Y4aw73m/4SgPPATu11r8POBS49vn/Im0b/YbW+h6tdZbWehSSRu9pra8C1iBrsUfELp9tJUCBUmq8b9fXkaV9I5pmSFXUyUqpQb7/1bIr4mkWQFdptAJY6Ov5czJQE1B11S8opc5FqkAv0lo3BhxaAVyhlIpWSo0GxgLr+sMmrfVWrXW61nqU710oRDqplDAA0gx4HWn4Rik1DukAUkFfptnRbJT5MnyQ3g27kJ4DP4mwLach1QJbgM2+z/lIe8G7wOdIL4jkCNo4F38vqWzfg7cbWIKvd0YEbJoKbPCl2+tA0kBIM+BnQB6wDXgJ6aUSkTQD/oG0pbQhGd11XaUR0qHhSd87sRWYEQHbdiP17tZ78HRA+J/4bMsHzutPuzoc34+/0XsgpFkUsMj3vG0C5vV1mpmR3gaDwWAIi2O9SspgMBgMYWIEw2AwGAxhYQTDYDAYDGFhBMNgMBgMYWEEw2AwGAxhYQTDYBgAKKXmKt8swAbDQMUIhsFgMBjCwgiGwdADlFJXK6XWKaU2K6WeUbJGSL1S6lHfGgTvKqXSfGGnKqU+CVjTwVpvYoxS6h2lVK5SapNS6jhf9PHKv67Hy309D5DB8EUxgmEwhIlSaiLwLeBUrfVUwANchUwsuEFrPRn4APip75S/AT/SWk9BRv9a+18GntRanwCcgozYBZmd+FZk/YJsZO4pg2HA4DhyEIPB4OPrwHRgva/wH4tM2OcFXvWFWQQsU0olAi6t9Qe+/S8CS5RSCcAwrfVyAK11M4AvvnVa60Lf9mZkvYO1R/+2DIbwMIJhMISPAl7UWt8TtFOp+zqE6+18Oy0Bvz2Y99MwwDBVUgZD+LwLXKqUSof2NbFHIu+RNQPt/wBrtdY1QJVS6mu+/dcAH2it64BCpdTFvjiifessGAwDHlOCMRjCRGu9Qyl1L7BaKWVDZgq9CVm06STfsTKknQNkyvCnfYKwF/i2b/81wDNKqQd9cVzWj7dhMPQaM1utwfAFUUrVa63jI22HwXC0MVVSBoPBYAgL42EYDAaDISyMh2EwGAyGsDCCYTAYDIawMIJhMBgMhrAwgmEwGAyGsDCCYTAYDIawMIJhMBgMhrD4/4lrq01Y67IXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.3131 - acc: 0.9269\n",
      "Loss: 0.3130880305344318 Accuracy: 0.92689514\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4708 - acc: 0.5534\n",
      "Epoch 00001: val_loss improved from inf to 1.05278, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/001-1.0528.hdf5\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 1.4709 - acc: 0.5534 - val_loss: 1.0528 - val_acc: 0.6718\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7586 - acc: 0.7730\n",
      "Epoch 00002: val_loss improved from 1.05278 to 0.61592, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/002-0.6159.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.7585 - acc: 0.7730 - val_loss: 0.6159 - val_acc: 0.8164\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5209 - acc: 0.8442\n",
      "Epoch 00003: val_loss improved from 0.61592 to 0.46875, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/003-0.4687.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.5209 - acc: 0.8442 - val_loss: 0.4687 - val_acc: 0.8581\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4034 - acc: 0.8800\n",
      "Epoch 00004: val_loss improved from 0.46875 to 0.41179, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/004-0.4118.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.4034 - acc: 0.8800 - val_loss: 0.4118 - val_acc: 0.8761\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3289 - acc: 0.9041\n",
      "Epoch 00005: val_loss improved from 0.41179 to 0.35088, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/005-0.3509.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3289 - acc: 0.9041 - val_loss: 0.3509 - val_acc: 0.8831\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2719 - acc: 0.9206\n",
      "Epoch 00006: val_loss improved from 0.35088 to 0.31968, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/006-0.3197.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.2719 - acc: 0.9206 - val_loss: 0.3197 - val_acc: 0.9008\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2306 - acc: 0.9308\n",
      "Epoch 00007: val_loss improved from 0.31968 to 0.30235, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/007-0.3024.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2307 - acc: 0.9308 - val_loss: 0.3024 - val_acc: 0.9078\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1990 - acc: 0.9433\n",
      "Epoch 00008: val_loss did not improve from 0.30235\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1991 - acc: 0.9433 - val_loss: 0.3698 - val_acc: 0.8856\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9501\n",
      "Epoch 00009: val_loss improved from 0.30235 to 0.29910, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/009-0.2991.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1756 - acc: 0.9501 - val_loss: 0.2991 - val_acc: 0.9066\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9577\n",
      "Epoch 00010: val_loss improved from 0.29910 to 0.25613, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/010-0.2561.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1502 - acc: 0.9577 - val_loss: 0.2561 - val_acc: 0.9194\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9626\n",
      "Epoch 00011: val_loss did not improve from 0.25613\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1335 - acc: 0.9626 - val_loss: 0.3512 - val_acc: 0.8940\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9668\n",
      "Epoch 00012: val_loss improved from 0.25613 to 0.25459, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/012-0.2546.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1168 - acc: 0.9668 - val_loss: 0.2546 - val_acc: 0.9262\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9720\n",
      "Epoch 00013: val_loss improved from 0.25459 to 0.24374, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/013-0.2437.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1023 - acc: 0.9720 - val_loss: 0.2437 - val_acc: 0.9269\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9789\n",
      "Epoch 00014: val_loss improved from 0.24374 to 0.22868, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/014-0.2287.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0817 - acc: 0.9789 - val_loss: 0.2287 - val_acc: 0.9306\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9796\n",
      "Epoch 00015: val_loss did not improve from 0.22868\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0757 - acc: 0.9796 - val_loss: 0.2824 - val_acc: 0.9166\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9823\n",
      "Epoch 00016: val_loss did not improve from 0.22868\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0708 - acc: 0.9823 - val_loss: 0.3768 - val_acc: 0.8889\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9858\n",
      "Epoch 00017: val_loss improved from 0.22868 to 0.21963, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/017-0.2196.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0582 - acc: 0.9858 - val_loss: 0.2196 - val_acc: 0.9297\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9885\n",
      "Epoch 00018: val_loss did not improve from 0.21963\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0487 - acc: 0.9885 - val_loss: 0.2284 - val_acc: 0.9359\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9880\n",
      "Epoch 00019: val_loss did not improve from 0.21963\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0484 - acc: 0.9880 - val_loss: 0.3397 - val_acc: 0.8966\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9905\n",
      "Epoch 00020: val_loss did not improve from 0.21963\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0419 - acc: 0.9904 - val_loss: 0.3614 - val_acc: 0.9031\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9888\n",
      "Epoch 00021: val_loss did not improve from 0.21963\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0467 - acc: 0.9888 - val_loss: 0.3189 - val_acc: 0.9113\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9921\n",
      "Epoch 00022: val_loss did not improve from 0.21963\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0348 - acc: 0.9921 - val_loss: 0.2763 - val_acc: 0.9227\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9906\n",
      "Epoch 00023: val_loss did not improve from 0.21963\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0385 - acc: 0.9906 - val_loss: 0.2363 - val_acc: 0.9334\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9902\n",
      "Epoch 00024: val_loss improved from 0.21963 to 0.21803, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/024-0.2180.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0394 - acc: 0.9901 - val_loss: 0.2180 - val_acc: 0.9390\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9894\n",
      "Epoch 00025: val_loss did not improve from 0.21803\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0435 - acc: 0.9894 - val_loss: 0.2346 - val_acc: 0.9331\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9969\n",
      "Epoch 00026: val_loss did not improve from 0.21803\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0184 - acc: 0.9969 - val_loss: 0.2224 - val_acc: 0.9399\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9951\n",
      "Epoch 00027: val_loss did not improve from 0.21803\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0231 - acc: 0.9951 - val_loss: 0.2265 - val_acc: 0.9359\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9952\n",
      "Epoch 00028: val_loss did not improve from 0.21803\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0226 - acc: 0.9952 - val_loss: 0.2822 - val_acc: 0.9287\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9954\n",
      "Epoch 00029: val_loss did not improve from 0.21803\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0216 - acc: 0.9954 - val_loss: 0.2385 - val_acc: 0.9350\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9937\n",
      "Epoch 00030: val_loss did not improve from 0.21803\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0264 - acc: 0.9938 - val_loss: 0.2550 - val_acc: 0.9324\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9934\n",
      "Epoch 00031: val_loss did not improve from 0.21803\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0256 - acc: 0.9934 - val_loss: 0.2998 - val_acc: 0.9143\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9964\n",
      "Epoch 00032: val_loss did not improve from 0.21803\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0166 - acc: 0.9964 - val_loss: 0.2276 - val_acc: 0.9376\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9950\n",
      "Epoch 00033: val_loss did not improve from 0.21803\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0219 - acc: 0.9950 - val_loss: 0.2505 - val_acc: 0.9338\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9961\n",
      "Epoch 00034: val_loss did not improve from 0.21803\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0179 - acc: 0.9961 - val_loss: 0.2465 - val_acc: 0.9315\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9975\n",
      "Epoch 00035: val_loss did not improve from 0.21803\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0135 - acc: 0.9975 - val_loss: 0.3331 - val_acc: 0.9175\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9921\n",
      "Epoch 00036: val_loss improved from 0.21803 to 0.20968, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/036-0.2097.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0300 - acc: 0.9921 - val_loss: 0.2097 - val_acc: 0.9425\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9977\n",
      "Epoch 00037: val_loss did not improve from 0.20968\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0112 - acc: 0.9977 - val_loss: 0.2391 - val_acc: 0.9394\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9962\n",
      "Epoch 00038: val_loss did not improve from 0.20968\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0166 - acc: 0.9962 - val_loss: 0.2125 - val_acc: 0.9425\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9950\n",
      "Epoch 00039: val_loss did not improve from 0.20968\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0188 - acc: 0.9950 - val_loss: 0.2160 - val_acc: 0.9439\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9989\n",
      "Epoch 00040: val_loss did not improve from 0.20968\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0082 - acc: 0.9989 - val_loss: 0.2106 - val_acc: 0.9446\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9961\n",
      "Epoch 00041: val_loss did not improve from 0.20968\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0164 - acc: 0.9961 - val_loss: 0.3040 - val_acc: 0.9199\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9927\n",
      "Epoch 00042: val_loss did not improve from 0.20968\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0257 - acc: 0.9927 - val_loss: 0.2111 - val_acc: 0.9441\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9982\n",
      "Epoch 00043: val_loss improved from 0.20968 to 0.19444, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/043-0.1944.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0091 - acc: 0.9982 - val_loss: 0.1944 - val_acc: 0.9492\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9981\n",
      "Epoch 00044: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0099 - acc: 0.9981 - val_loss: 0.2842 - val_acc: 0.9306\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9964\n",
      "Epoch 00045: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0148 - acc: 0.9964 - val_loss: 0.2694 - val_acc: 0.9301\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9968\n",
      "Epoch 00046: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0130 - acc: 0.9968 - val_loss: 0.2729 - val_acc: 0.9345\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9948\n",
      "Epoch 00047: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0198 - acc: 0.9948 - val_loss: 0.2171 - val_acc: 0.9490\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9943\n",
      "Epoch 00048: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0223 - acc: 0.9943 - val_loss: 0.2095 - val_acc: 0.9441\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9965\n",
      "Epoch 00049: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0146 - acc: 0.9965 - val_loss: 0.1991 - val_acc: 0.9474\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9953\n",
      "Epoch 00050: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0200 - acc: 0.9953 - val_loss: 0.2135 - val_acc: 0.9464\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9980\n",
      "Epoch 00051: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0090 - acc: 0.9980 - val_loss: 0.1991 - val_acc: 0.9474\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9992\n",
      "Epoch 00052: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0048 - acc: 0.9992 - val_loss: 0.2575 - val_acc: 0.9385\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9991\n",
      "Epoch 00053: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0057 - acc: 0.9991 - val_loss: 0.1979 - val_acc: 0.9467\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9937\n",
      "Epoch 00054: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0212 - acc: 0.9937 - val_loss: 0.2606 - val_acc: 0.9290\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9954\n",
      "Epoch 00055: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0170 - acc: 0.9954 - val_loss: 0.2295 - val_acc: 0.9441\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9994\n",
      "Epoch 00056: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0046 - acc: 0.9994 - val_loss: 0.1968 - val_acc: 0.9488\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9991\n",
      "Epoch 00057: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0053 - acc: 0.9991 - val_loss: 0.2339 - val_acc: 0.9415\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9947\n",
      "Epoch 00058: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0189 - acc: 0.9947 - val_loss: 0.2106 - val_acc: 0.9485\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 00059: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0037 - acc: 0.9995 - val_loss: 0.2043 - val_acc: 0.9499\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 00060: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0024 - acc: 0.9998 - val_loss: 0.2080 - val_acc: 0.9520\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9910\n",
      "Epoch 00061: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0324 - acc: 0.9910 - val_loss: 0.2210 - val_acc: 0.9464\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9992\n",
      "Epoch 00062: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0050 - acc: 0.9992 - val_loss: 0.2055 - val_acc: 0.9483\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9974\n",
      "Epoch 00063: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0104 - acc: 0.9974 - val_loss: 0.2397 - val_acc: 0.9392\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9985\n",
      "Epoch 00064: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0077 - acc: 0.9985 - val_loss: 0.2401 - val_acc: 0.9397\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9974\n",
      "Epoch 00065: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0109 - acc: 0.9974 - val_loss: 0.2043 - val_acc: 0.9481\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9997\n",
      "Epoch 00066: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0024 - acc: 0.9997 - val_loss: 0.1959 - val_acc: 0.9532\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9980\n",
      "Epoch 00067: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0093 - acc: 0.9979 - val_loss: 0.3397 - val_acc: 0.9217\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9931\n",
      "Epoch 00068: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0249 - acc: 0.9930 - val_loss: 0.2403 - val_acc: 0.9392\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9951\n",
      "Epoch 00069: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0184 - acc: 0.9951 - val_loss: 0.1956 - val_acc: 0.9485\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9975\n",
      "Epoch 00070: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0104 - acc: 0.9975 - val_loss: 0.1944 - val_acc: 0.9515\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9997\n",
      "Epoch 00071: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0025 - acc: 0.9996 - val_loss: 0.2059 - val_acc: 0.9504\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9964\n",
      "Epoch 00072: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0145 - acc: 0.9964 - val_loss: 0.1974 - val_acc: 0.9504\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9978\n",
      "Epoch 00073: val_loss did not improve from 0.19444\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0088 - acc: 0.9978 - val_loss: 0.2018 - val_acc: 0.9529\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9995\n",
      "Epoch 00074: val_loss improved from 0.19444 to 0.18881, saving model to model/checkpoint/1D_CNN_custom_tanh_BN_9_conv_checkpoint/074-0.1888.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0034 - acc: 0.9995 - val_loss: 0.1888 - val_acc: 0.9502\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9996\n",
      "Epoch 00075: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0023 - acc: 0.9996 - val_loss: 0.2062 - val_acc: 0.9515\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9940\n",
      "Epoch 00076: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0192 - acc: 0.9940 - val_loss: 0.2447 - val_acc: 0.9413\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9980\n",
      "Epoch 00077: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0092 - acc: 0.9980 - val_loss: 0.2125 - val_acc: 0.9490\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9978\n",
      "Epoch 00078: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0084 - acc: 0.9977 - val_loss: 0.2301 - val_acc: 0.9495\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9959\n",
      "Epoch 00079: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0155 - acc: 0.9959 - val_loss: 0.2062 - val_acc: 0.9506\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9993\n",
      "Epoch 00080: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0035 - acc: 0.9993 - val_loss: 0.2031 - val_acc: 0.9525\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9995\n",
      "Epoch 00081: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0032 - acc: 0.9995 - val_loss: 0.2006 - val_acc: 0.9527\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9990\n",
      "Epoch 00082: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0049 - acc: 0.9989 - val_loss: 0.2545 - val_acc: 0.9429\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9923\n",
      "Epoch 00083: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0258 - acc: 0.9923 - val_loss: 0.2026 - val_acc: 0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9968\n",
      "Epoch 00084: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0122 - acc: 0.9968 - val_loss: 0.2106 - val_acc: 0.9499\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9974\n",
      "Epoch 00085: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0112 - acc: 0.9974 - val_loss: 0.1987 - val_acc: 0.9522\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9997\n",
      "Epoch 00086: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0023 - acc: 0.9997 - val_loss: 0.2103 - val_acc: 0.9513\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9968\n",
      "Epoch 00087: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0129 - acc: 0.9968 - val_loss: 0.2124 - val_acc: 0.9490\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9992\n",
      "Epoch 00088: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0042 - acc: 0.9992 - val_loss: 0.2025 - val_acc: 0.9546\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9999\n",
      "Epoch 00089: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0017 - acc: 0.9999 - val_loss: 0.1947 - val_acc: 0.9541\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9997\n",
      "Epoch 00090: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0024 - acc: 0.9997 - val_loss: 0.2373 - val_acc: 0.9460\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9949\n",
      "Epoch 00091: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0182 - acc: 0.9949 - val_loss: 0.2307 - val_acc: 0.9443\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9992\n",
      "Epoch 00092: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0050 - acc: 0.9992 - val_loss: 0.2409 - val_acc: 0.9460\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9991\n",
      "Epoch 00093: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0049 - acc: 0.9991 - val_loss: 0.2559 - val_acc: 0.9373\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9973\n",
      "Epoch 00094: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0110 - acc: 0.9973 - val_loss: 0.2299 - val_acc: 0.9476\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9994\n",
      "Epoch 00095: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0034 - acc: 0.9994 - val_loss: 0.2148 - val_acc: 0.9471\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 00096: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0016 - acc: 0.9998 - val_loss: 0.2437 - val_acc: 0.9478\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9949\n",
      "Epoch 00097: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0180 - acc: 0.9949 - val_loss: 0.2102 - val_acc: 0.9529\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9994\n",
      "Epoch 00098: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0035 - acc: 0.9994 - val_loss: 0.2389 - val_acc: 0.9457\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9964\n",
      "Epoch 00099: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0118 - acc: 0.9964 - val_loss: 0.2049 - val_acc: 0.9564\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9997\n",
      "Epoch 00100: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0021 - acc: 0.9997 - val_loss: 0.2018 - val_acc: 0.9546\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 00101: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0016 - acc: 0.9997 - val_loss: 0.2073 - val_acc: 0.9539\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9989\n",
      "Epoch 00102: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0051 - acc: 0.9989 - val_loss: 0.2957 - val_acc: 0.9294\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9960\n",
      "Epoch 00103: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0144 - acc: 0.9960 - val_loss: 0.2486 - val_acc: 0.9441\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9990\n",
      "Epoch 00104: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0040 - acc: 0.9990 - val_loss: 0.2144 - val_acc: 0.9527\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00105: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1939 - val_acc: 0.9574\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9965\n",
      "Epoch 00106: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0112 - acc: 0.9965 - val_loss: 0.2330 - val_acc: 0.9471\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9968\n",
      "Epoch 00107: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0118 - acc: 0.9968 - val_loss: 0.2102 - val_acc: 0.9541\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9995\n",
      "Epoch 00108: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0022 - acc: 0.9995 - val_loss: 0.2565 - val_acc: 0.9434\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9983\n",
      "Epoch 00109: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0071 - acc: 0.9983 - val_loss: 0.2272 - val_acc: 0.9464\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9986\n",
      "Epoch 00110: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0056 - acc: 0.9986 - val_loss: 0.2084 - val_acc: 0.9522\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00111: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1955 - val_acc: 0.9585\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9978\n",
      "Epoch 00112: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0083 - acc: 0.9978 - val_loss: 0.2867 - val_acc: 0.9355\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9977\n",
      "Epoch 00113: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0084 - acc: 0.9977 - val_loss: 0.2255 - val_acc: 0.9485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9995\n",
      "Epoch 00114: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0030 - acc: 0.9995 - val_loss: 0.2192 - val_acc: 0.9504\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9988\n",
      "Epoch 00115: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0052 - acc: 0.9988 - val_loss: 0.2392 - val_acc: 0.9464\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9960\n",
      "Epoch 00116: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0132 - acc: 0.9960 - val_loss: 0.2093 - val_acc: 0.9518\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9996\n",
      "Epoch 00117: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0021 - acc: 0.9996 - val_loss: 0.2168 - val_acc: 0.9527\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 00118: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0016 - acc: 0.9998 - val_loss: 0.2034 - val_acc: 0.9555\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9979\n",
      "Epoch 00119: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0083 - acc: 0.9979 - val_loss: 0.2416 - val_acc: 0.9457\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9988\n",
      "Epoch 00120: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0058 - acc: 0.9988 - val_loss: 0.2185 - val_acc: 0.9511\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9987\n",
      "Epoch 00121: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0050 - acc: 0.9987 - val_loss: 0.2313 - val_acc: 0.9520\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9997\n",
      "Epoch 00122: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0019 - acc: 0.9996 - val_loss: 0.2147 - val_acc: 0.9555\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9966\n",
      "Epoch 00123: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0117 - acc: 0.9966 - val_loss: 0.1916 - val_acc: 0.9569\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9997\n",
      "Epoch 00124: val_loss did not improve from 0.18881\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0021 - acc: 0.9997 - val_loss: 0.1959 - val_acc: 0.9550\n",
      "\n",
      "1D_CNN_custom_tanh_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2772 - acc: 0.9377\n",
      "Loss: 0.27723436721001954 Accuracy: 0.9376947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    base = '1D_CNN_custom_tanh_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_BN_2(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_tanh_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,480,656\n",
      "Trainable params: 18,432,528\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 646us/sample - loss: 11.9385 - acc: 0.0976\n",
      "Loss: 11.93846916642392 Accuracy: 0.09761163\n",
      "\n",
      "1D_CNN_custom_tanh_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 6,847,696\n",
      "Trainable params: 6,164,816\n",
      "Non-trainable params: 682,880\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 837us/sample - loss: 5.7383 - acc: 0.2517s - loss\n",
      "Loss: 5.738269213798262 Accuracy: 0.2517134\n",
      "\n",
      "1D_CNN_custom_tanh_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,316,816\n",
      "Trainable params: 2,088,976\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 921us/sample - loss: 2.3179 - acc: 0.5076\n",
      "Loss: 2.3179046772969722 Accuracy: 0.50758046\n",
      "\n",
      "1D_CNN_custom_tanh_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 820,816\n",
      "Trainable params: 744,528\n",
      "Non-trainable params: 76,288\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 954us/sample - loss: 1.7769 - acc: 0.5518\n",
      "Loss: 1.7769245119481072 Accuracy: 0.55181724\n",
      "\n",
      "1D_CNN_custom_tanh_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 608,976\n",
      "Trainable params: 557,776\n",
      "Non-trainable params: 51,200\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.5837 - acc: 0.6066\n",
      "Loss: 1.5837259600343239 Accuracy: 0.6066459\n",
      "\n",
      "1D_CNN_custom_tanh_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 353,616\n",
      "Trainable params: 335,952\n",
      "Non-trainable params: 17,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.1556 - acc: 0.7583\n",
      "Loss: 1.1556077417554884 Accuracy: 0.7582554\n",
      "\n",
      "1D_CNN_custom_tanh_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 323,536\n",
      "Trainable params: 316,880\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.5078 - acc: 0.8827\n",
      "Loss: 0.5077504219976665 Accuracy: 0.88265836\n",
      "\n",
      "1D_CNN_custom_tanh_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 370,256\n",
      "Trainable params: 366,928\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.3131 - acc: 0.9269\n",
      "Loss: 0.3130880305344318 Accuracy: 0.92689514\n",
      "\n",
      "1D_CNN_custom_tanh_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 527,696\n",
      "Trainable params: 524,624\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2772 - acc: 0.9377\n",
      "Loss: 0.27723436721001954 Accuracy: 0.9376947\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_tanh_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_tanh_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,480,656\n",
      "Trainable params: 18,432,528\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 857us/sample - loss: 12.8834 - acc: 0.1848\n",
      "Loss: 12.88339811643955 Accuracy: 0.18483904\n",
      "\n",
      "1D_CNN_custom_tanh_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 6,847,696\n",
      "Trainable params: 6,164,816\n",
      "Non-trainable params: 682,880\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 9.9547 - acc: 0.3119\n",
      "Loss: 9.95469137253172 Accuracy: 0.31194186\n",
      "\n",
      "1D_CNN_custom_tanh_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,316,816\n",
      "Trainable params: 2,088,976\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 5.0160 - acc: 0.4995\n",
      "Loss: 5.0160154222823135 Accuracy: 0.49948078\n",
      "\n",
      "1D_CNN_custom_tanh_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 820,816\n",
      "Trainable params: 744,528\n",
      "Non-trainable params: 76,288\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.6802 - acc: 0.5907\n",
      "Loss: 2.680159795866082 Accuracy: 0.5906542\n",
      "\n",
      "1D_CNN_custom_tanh_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 608,976\n",
      "Trainable params: 557,776\n",
      "Non-trainable params: 51,200\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.4285 - acc: 0.6222\n",
      "Loss: 2.4284976289279734 Accuracy: 0.62222224\n",
      "\n",
      "1D_CNN_custom_tanh_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 353,616\n",
      "Trainable params: 335,952\n",
      "Non-trainable params: 17,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.2355 - acc: 0.7726\n",
      "Loss: 1.235518296708199 Accuracy: 0.7725857\n",
      "\n",
      "1D_CNN_custom_tanh_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 323,536\n",
      "Trainable params: 316,880\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.5650 - acc: 0.8806\n",
      "Loss: 0.5649968348064403 Accuracy: 0.8805815\n",
      "\n",
      "1D_CNN_custom_tanh_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 370,256\n",
      "Trainable params: 366,928\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4040 - acc: 0.9121\n",
      "Loss: 0.4039993609873305 Accuracy: 0.91214955\n",
      "\n",
      "1D_CNN_custom_tanh_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 527,696\n",
      "Trainable params: 524,624\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2925 - acc: 0.9381\n",
      "Loss: 0.2924639905780662 Accuracy: 0.93811005\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_tanh_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
