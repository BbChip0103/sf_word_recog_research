{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_ch_128_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=128, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=128*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model = build_1d_cnn_custom_ch_128_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3955 - acc: 0.2366\n",
      "Epoch 00001: val_loss improved from inf to 2.28923, saving model to model/checkpoint/1D_CNN_1_conv_custom_DO_BN_checkpoint/001-2.2892.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 3.3952 - acc: 0.2367 - val_loss: 2.2892 - val_acc: 0.2954\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5224 - acc: 0.5422\n",
      "Epoch 00002: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 1.5225 - acc: 0.5422 - val_loss: 2.4981 - val_acc: 0.3208\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0780 - acc: 0.6749\n",
      "Epoch 00003: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.0780 - acc: 0.6749 - val_loss: 2.8146 - val_acc: 0.2893\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8124 - acc: 0.7618\n",
      "Epoch 00004: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.8125 - acc: 0.7618 - val_loss: 2.9148 - val_acc: 0.3086\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6486 - acc: 0.8152\n",
      "Epoch 00005: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.6486 - acc: 0.8152 - val_loss: 3.1045 - val_acc: 0.3000\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5312 - acc: 0.8507\n",
      "Epoch 00006: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.5312 - acc: 0.8506 - val_loss: 3.2863 - val_acc: 0.3098\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4512 - acc: 0.8737\n",
      "Epoch 00007: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4513 - acc: 0.8737 - val_loss: 3.3876 - val_acc: 0.3091\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3749 - acc: 0.8985\n",
      "Epoch 00008: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3749 - acc: 0.8985 - val_loss: 3.7119 - val_acc: 0.3000\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3278 - acc: 0.9128\n",
      "Epoch 00009: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3278 - acc: 0.9128 - val_loss: 4.4053 - val_acc: 0.2996\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2704 - acc: 0.9305\n",
      "Epoch 00010: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2704 - acc: 0.9305 - val_loss: 4.2933 - val_acc: 0.2842\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2526 - acc: 0.9339\n",
      "Epoch 00011: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2527 - acc: 0.9339 - val_loss: 4.2307 - val_acc: 0.2958\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.9351\n",
      "Epoch 00012: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2427 - acc: 0.9351 - val_loss: 4.6923 - val_acc: 0.3014\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2003 - acc: 0.9516\n",
      "Epoch 00013: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2003 - acc: 0.9516 - val_loss: 5.4676 - val_acc: 0.2683\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9582\n",
      "Epoch 00014: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1756 - acc: 0.9582 - val_loss: 5.2086 - val_acc: 0.2763\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1618 - acc: 0.9619\n",
      "Epoch 00015: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1618 - acc: 0.9619 - val_loss: 4.9423 - val_acc: 0.2879\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9660\n",
      "Epoch 00016: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1476 - acc: 0.9660 - val_loss: 5.4959 - val_acc: 0.2737\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9640\n",
      "Epoch 00017: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1556 - acc: 0.9640 - val_loss: 5.2924 - val_acc: 0.2840\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9640\n",
      "Epoch 00018: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1472 - acc: 0.9639 - val_loss: 5.7429 - val_acc: 0.2753\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.9732\n",
      "Epoch 00019: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1185 - acc: 0.9732 - val_loss: 5.6451 - val_acc: 0.2949\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9718\n",
      "Epoch 00020: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1267 - acc: 0.9718 - val_loss: 5.1225 - val_acc: 0.3047\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9742\n",
      "Epoch 00021: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1178 - acc: 0.9742 - val_loss: 5.3726 - val_acc: 0.3058\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9725\n",
      "Epoch 00022: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1201 - acc: 0.9725 - val_loss: 5.5648 - val_acc: 0.3063\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9781\n",
      "Epoch 00023: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1006 - acc: 0.9781 - val_loss: 5.3813 - val_acc: 0.3119\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9784\n",
      "Epoch 00024: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0995 - acc: 0.9784 - val_loss: 6.1375 - val_acc: 0.2730\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9777\n",
      "Epoch 00025: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1039 - acc: 0.9777 - val_loss: 6.0860 - val_acc: 0.2837\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9823\n",
      "Epoch 00026: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0889 - acc: 0.9823 - val_loss: 5.7434 - val_acc: 0.3051\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9822\n",
      "Epoch 00027: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0895 - acc: 0.9822 - val_loss: 6.1300 - val_acc: 0.3077\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9789\n",
      "Epoch 00028: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0974 - acc: 0.9789 - val_loss: 5.9827 - val_acc: 0.3033\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9809\n",
      "Epoch 00029: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0943 - acc: 0.9809 - val_loss: 5.9213 - val_acc: 0.2975\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9848\n",
      "Epoch 00030: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0794 - acc: 0.9848 - val_loss: 6.2118 - val_acc: 0.2870\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9837\n",
      "Epoch 00031: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0851 - acc: 0.9837 - val_loss: 6.5089 - val_acc: 0.2805\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9843\n",
      "Epoch 00032: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0842 - acc: 0.9843 - val_loss: 6.1779 - val_acc: 0.2970\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9884\n",
      "Epoch 00033: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0696 - acc: 0.9884 - val_loss: 6.0869 - val_acc: 0.3147\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9879\n",
      "Epoch 00034: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0697 - acc: 0.9879 - val_loss: 6.4747 - val_acc: 0.2958\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9844\n",
      "Epoch 00035: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0824 - acc: 0.9844 - val_loss: 7.1384 - val_acc: 0.2746\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9853\n",
      "Epoch 00036: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0775 - acc: 0.9853 - val_loss: 6.3447 - val_acc: 0.2961\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9883\n",
      "Epoch 00037: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0666 - acc: 0.9883 - val_loss: 6.1329 - val_acc: 0.3149\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9850\n",
      "Epoch 00038: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0792 - acc: 0.9850 - val_loss: 6.8555 - val_acc: 0.2919\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9862\n",
      "Epoch 00039: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0728 - acc: 0.9863 - val_loss: 6.6432 - val_acc: 0.3005\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9893\n",
      "Epoch 00040: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0620 - acc: 0.9893 - val_loss: 6.7327 - val_acc: 0.2986\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9879\n",
      "Epoch 00041: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0677 - acc: 0.9879 - val_loss: 6.1481 - val_acc: 0.3103\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9886\n",
      "Epoch 00042: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0664 - acc: 0.9886 - val_loss: 7.6453 - val_acc: 0.2751\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9897\n",
      "Epoch 00043: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0619 - acc: 0.9897 - val_loss: 7.4514 - val_acc: 0.2625\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9897\n",
      "Epoch 00044: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0616 - acc: 0.9897 - val_loss: 6.5166 - val_acc: 0.3010\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9879\n",
      "Epoch 00045: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0651 - acc: 0.9879 - val_loss: 7.3386 - val_acc: 0.2853\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9890\n",
      "Epoch 00046: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0641 - acc: 0.9890 - val_loss: 6.4354 - val_acc: 0.3103\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9893\n",
      "Epoch 00047: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0621 - acc: 0.9893 - val_loss: 7.0113 - val_acc: 0.2784\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9882\n",
      "Epoch 00048: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0656 - acc: 0.9882 - val_loss: 7.2792 - val_acc: 0.2784\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9882\n",
      "Epoch 00049: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0671 - acc: 0.9882 - val_loss: 7.2812 - val_acc: 0.2621\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9902\n",
      "Epoch 00050: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0598 - acc: 0.9902 - val_loss: 6.6997 - val_acc: 0.3091\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9908\n",
      "Epoch 00051: val_loss did not improve from 2.28923\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0579 - acc: 0.9908 - val_loss: 6.7159 - val_acc: 0.3072\n",
      "\n",
      "1D_CNN_1_conv_custom_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 439us/sample - loss: 2.3072 - acc: 0.2771\n",
      "Loss: 2.3071924338335807 Accuracy: 0.27705088\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.0567 - acc: 0.2694\n",
      "Epoch 00001: val_loss improved from inf to 2.96232, saving model to model/checkpoint/1D_CNN_2_conv_custom_DO_BN_checkpoint/001-2.9623.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 3.0567 - acc: 0.2694 - val_loss: 2.9623 - val_acc: 0.2604\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9926 - acc: 0.4381\n",
      "Epoch 00002: val_loss improved from 2.96232 to 2.55095, saving model to model/checkpoint/1D_CNN_2_conv_custom_DO_BN_checkpoint/002-2.5510.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.9926 - acc: 0.4381 - val_loss: 2.5510 - val_acc: 0.3373\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5743 - acc: 0.5462\n",
      "Epoch 00003: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.5742 - acc: 0.5463 - val_loss: 2.7219 - val_acc: 0.3089\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1628 - acc: 0.6457\n",
      "Epoch 00004: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.1629 - acc: 0.6456 - val_loss: 2.8679 - val_acc: 0.3618\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9269 - acc: 0.7123\n",
      "Epoch 00005: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.9268 - acc: 0.7122 - val_loss: 3.1204 - val_acc: 0.3415\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7735 - acc: 0.7585\n",
      "Epoch 00006: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.7735 - acc: 0.7585 - val_loss: 3.1374 - val_acc: 0.3918\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6141 - acc: 0.8043\n",
      "Epoch 00007: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.6142 - acc: 0.8043 - val_loss: 3.5880 - val_acc: 0.3310\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5244 - acc: 0.8328\n",
      "Epoch 00008: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.5244 - acc: 0.8328 - val_loss: 3.2519 - val_acc: 0.3748\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4813 - acc: 0.8496\n",
      "Epoch 00009: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.4812 - acc: 0.8497 - val_loss: 3.3037 - val_acc: 0.4130\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3832 - acc: 0.8796\n",
      "Epoch 00010: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3831 - acc: 0.8796 - val_loss: 3.7950 - val_acc: 0.3664\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3690 - acc: 0.8848\n",
      "Epoch 00011: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3689 - acc: 0.8848 - val_loss: 3.6061 - val_acc: 0.4016\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3382 - acc: 0.8941\n",
      "Epoch 00012: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3383 - acc: 0.8941 - val_loss: 3.8967 - val_acc: 0.3923\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3274 - acc: 0.9004\n",
      "Epoch 00013: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3273 - acc: 0.9004 - val_loss: 3.6015 - val_acc: 0.4074\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2767 - acc: 0.9162\n",
      "Epoch 00014: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2767 - acc: 0.9162 - val_loss: 4.0153 - val_acc: 0.3958\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2604 - acc: 0.9201\n",
      "Epoch 00015: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2604 - acc: 0.9200 - val_loss: 4.1222 - val_acc: 0.3802\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2684 - acc: 0.9215\n",
      "Epoch 00016: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2684 - acc: 0.9215 - val_loss: 4.5919 - val_acc: 0.3755\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2320 - acc: 0.9292\n",
      "Epoch 00017: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2320 - acc: 0.9292 - val_loss: 4.7614 - val_acc: 0.3669\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.9393\n",
      "Epoch 00018: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2038 - acc: 0.9393 - val_loss: 4.1341 - val_acc: 0.4125\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2009 - acc: 0.9407\n",
      "Epoch 00019: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2008 - acc: 0.9407 - val_loss: 4.4999 - val_acc: 0.3951\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1845 - acc: 0.9445\n",
      "Epoch 00020: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1844 - acc: 0.9445 - val_loss: 4.5186 - val_acc: 0.3888\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9442\n",
      "Epoch 00021: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1892 - acc: 0.9442 - val_loss: 4.1726 - val_acc: 0.4258\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1661 - acc: 0.9522\n",
      "Epoch 00022: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1660 - acc: 0.9522 - val_loss: 4.7855 - val_acc: 0.3748\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9498\n",
      "Epoch 00023: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1690 - acc: 0.9498 - val_loss: 4.4109 - val_acc: 0.4086\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9552\n",
      "Epoch 00024: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1577 - acc: 0.9552 - val_loss: 4.1043 - val_acc: 0.4372\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1560 - acc: 0.9553\n",
      "Epoch 00025: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1560 - acc: 0.9553 - val_loss: 4.2924 - val_acc: 0.4191\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9564\n",
      "Epoch 00026: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1515 - acc: 0.9564 - val_loss: 4.3523 - val_acc: 0.4300\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9623\n",
      "Epoch 00027: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1338 - acc: 0.9623 - val_loss: 4.6002 - val_acc: 0.4163\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9647\n",
      "Epoch 00028: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1258 - acc: 0.9647 - val_loss: 4.7145 - val_acc: 0.4130\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9633\n",
      "Epoch 00029: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1291 - acc: 0.9633 - val_loss: 4.2771 - val_acc: 0.4284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9664\n",
      "Epoch 00030: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1245 - acc: 0.9664 - val_loss: 4.6039 - val_acc: 0.4279\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9650\n",
      "Epoch 00031: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1260 - acc: 0.9650 - val_loss: 5.5145 - val_acc: 0.3769\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9682\n",
      "Epoch 00032: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1171 - acc: 0.9682 - val_loss: 4.8877 - val_acc: 0.4191\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9705\n",
      "Epoch 00033: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1096 - acc: 0.9704 - val_loss: 4.7290 - val_acc: 0.4198\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9710\n",
      "Epoch 00034: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1080 - acc: 0.9710 - val_loss: 4.5671 - val_acc: 0.4163\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9717\n",
      "Epoch 00035: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1068 - acc: 0.9717 - val_loss: 4.8969 - val_acc: 0.4158\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9717\n",
      "Epoch 00036: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1044 - acc: 0.9717 - val_loss: 4.4022 - val_acc: 0.4246\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9703\n",
      "Epoch 00037: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1155 - acc: 0.9702 - val_loss: 4.5287 - val_acc: 0.4225\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9759\n",
      "Epoch 00038: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0928 - acc: 0.9758 - val_loss: 4.6597 - val_acc: 0.4200\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9760\n",
      "Epoch 00039: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0907 - acc: 0.9760 - val_loss: 4.5331 - val_acc: 0.4335\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9779\n",
      "Epoch 00040: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0855 - acc: 0.9779 - val_loss: 4.5014 - val_acc: 0.4272\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9795\n",
      "Epoch 00041: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0802 - acc: 0.9795 - val_loss: 4.5334 - val_acc: 0.4354\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9802\n",
      "Epoch 00042: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0771 - acc: 0.9802 - val_loss: 5.4676 - val_acc: 0.3883\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9790\n",
      "Epoch 00043: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0827 - acc: 0.9790 - val_loss: 4.7787 - val_acc: 0.4361\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9782\n",
      "Epoch 00044: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0810 - acc: 0.9782 - val_loss: 4.4162 - val_acc: 0.4486\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9798\n",
      "Epoch 00045: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0772 - acc: 0.9798 - val_loss: 4.6174 - val_acc: 0.4230\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9814\n",
      "Epoch 00046: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0713 - acc: 0.9814 - val_loss: 4.8716 - val_acc: 0.4209\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9798\n",
      "Epoch 00047: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0778 - acc: 0.9798 - val_loss: 4.8404 - val_acc: 0.4270\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9811\n",
      "Epoch 00048: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0728 - acc: 0.9811 - val_loss: 4.6342 - val_acc: 0.4309\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9819\n",
      "Epoch 00049: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0665 - acc: 0.9819 - val_loss: 5.0237 - val_acc: 0.4198\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9818\n",
      "Epoch 00050: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0732 - acc: 0.9819 - val_loss: 4.8453 - val_acc: 0.4174\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9842\n",
      "Epoch 00051: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0639 - acc: 0.9842 - val_loss: 5.4503 - val_acc: 0.3813\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9846\n",
      "Epoch 00052: val_loss did not improve from 2.55095\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0631 - acc: 0.9846 - val_loss: 4.9125 - val_acc: 0.4088\n",
      "\n",
      "1D_CNN_2_conv_custom_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 727us/sample - loss: 2.6599 - acc: 0.3225\n",
      "Loss: 2.6599495181165875 Accuracy: 0.32253376\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3728 - acc: 0.3373\n",
      "Epoch 00001: val_loss improved from inf to 2.30419, saving model to model/checkpoint/1D_CNN_3_conv_custom_DO_BN_checkpoint/001-2.3042.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 2.3726 - acc: 0.3373 - val_loss: 2.3042 - val_acc: 0.3079\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6096 - acc: 0.5194\n",
      "Epoch 00002: val_loss improved from 2.30419 to 1.81237, saving model to model/checkpoint/1D_CNN_3_conv_custom_DO_BN_checkpoint/002-1.8124.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 1.6101 - acc: 0.5194 - val_loss: 1.8124 - val_acc: 0.4619\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3035 - acc: 0.6045\n",
      "Epoch 00003: val_loss improved from 1.81237 to 1.66082, saving model to model/checkpoint/1D_CNN_3_conv_custom_DO_BN_checkpoint/003-1.6608.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 1.3037 - acc: 0.6045 - val_loss: 1.6608 - val_acc: 0.5188\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0962 - acc: 0.6627\n",
      "Epoch 00004: val_loss improved from 1.66082 to 1.58604, saving model to model/checkpoint/1D_CNN_3_conv_custom_DO_BN_checkpoint/004-1.5860.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 1.0962 - acc: 0.6627 - val_loss: 1.5860 - val_acc: 0.5467\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8924 - acc: 0.7191\n",
      "Epoch 00005: val_loss improved from 1.58604 to 1.54608, saving model to model/checkpoint/1D_CNN_3_conv_custom_DO_BN_checkpoint/005-1.5461.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.8924 - acc: 0.7191 - val_loss: 1.5461 - val_acc: 0.5651\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7602 - acc: 0.7582\n",
      "Epoch 00006: val_loss improved from 1.54608 to 1.44431, saving model to model/checkpoint/1D_CNN_3_conv_custom_DO_BN_checkpoint/006-1.4443.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.7602 - acc: 0.7582 - val_loss: 1.4443 - val_acc: 0.6133\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6363 - acc: 0.7927\n",
      "Epoch 00007: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.6362 - acc: 0.7928 - val_loss: 1.5292 - val_acc: 0.5986\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5448 - acc: 0.8214\n",
      "Epoch 00008: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.5448 - acc: 0.8214 - val_loss: 1.9801 - val_acc: 0.5330\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4722 - acc: 0.8476\n",
      "Epoch 00009: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.4721 - acc: 0.8476 - val_loss: 1.7364 - val_acc: 0.5726\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4234 - acc: 0.8605\n",
      "Epoch 00010: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.4233 - acc: 0.8605 - val_loss: 1.9207 - val_acc: 0.5406\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3701 - acc: 0.8803\n",
      "Epoch 00011: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3701 - acc: 0.8803 - val_loss: 1.9335 - val_acc: 0.5628\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3463 - acc: 0.8876\n",
      "Epoch 00012: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3463 - acc: 0.8876 - val_loss: 1.8402 - val_acc: 0.5751\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3173 - acc: 0.8965\n",
      "Epoch 00013: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3173 - acc: 0.8966 - val_loss: 1.7533 - val_acc: 0.6087\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2731 - acc: 0.9112\n",
      "Epoch 00014: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2732 - acc: 0.9112 - val_loss: 1.8016 - val_acc: 0.6056\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2663 - acc: 0.9142\n",
      "Epoch 00015: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2667 - acc: 0.9141 - val_loss: 1.7705 - val_acc: 0.6080\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.9176\n",
      "Epoch 00016: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2553 - acc: 0.9176 - val_loss: 1.7808 - val_acc: 0.6133\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.9232\n",
      "Epoch 00017: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2357 - acc: 0.9231 - val_loss: 1.9236 - val_acc: 0.5935\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2300 - acc: 0.9275\n",
      "Epoch 00018: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2300 - acc: 0.9275 - val_loss: 1.8613 - val_acc: 0.6250\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9364\n",
      "Epoch 00019: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1982 - acc: 0.9364 - val_loss: 2.3127 - val_acc: 0.5602\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9354\n",
      "Epoch 00020: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2036 - acc: 0.9354 - val_loss: 2.0278 - val_acc: 0.6003\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1963 - acc: 0.9374\n",
      "Epoch 00021: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1962 - acc: 0.9374 - val_loss: 2.3230 - val_acc: 0.5567\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1686 - acc: 0.9464\n",
      "Epoch 00022: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1685 - acc: 0.9464 - val_loss: 1.9424 - val_acc: 0.6268\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1648 - acc: 0.9474\n",
      "Epoch 00023: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1648 - acc: 0.9474 - val_loss: 2.1460 - val_acc: 0.5924\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9496\n",
      "Epoch 00024: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1620 - acc: 0.9496 - val_loss: 2.2323 - val_acc: 0.5961\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9500\n",
      "Epoch 00025: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1590 - acc: 0.9500 - val_loss: 2.2395 - val_acc: 0.5856\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9535\n",
      "Epoch 00026: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1482 - acc: 0.9535 - val_loss: 2.0461 - val_acc: 0.6257\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9532\n",
      "Epoch 00027: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1478 - acc: 0.9531 - val_loss: 2.4377 - val_acc: 0.5712\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9558\n",
      "Epoch 00028: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1426 - acc: 0.9557 - val_loss: 1.9616 - val_acc: 0.6280\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9553\n",
      "Epoch 00029: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1414 - acc: 0.9553 - val_loss: 2.0675 - val_acc: 0.6231\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1268 - acc: 0.9615\n",
      "Epoch 00030: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1269 - acc: 0.9615 - val_loss: 2.9453 - val_acc: 0.5190\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9591\n",
      "Epoch 00031: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1318 - acc: 0.9591 - val_loss: 2.1702 - val_acc: 0.6080\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9626\n",
      "Epoch 00032: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1239 - acc: 0.9626 - val_loss: 2.0533 - val_acc: 0.6196\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9654\n",
      "Epoch 00033: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1122 - acc: 0.9654 - val_loss: 2.2301 - val_acc: 0.6084\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9634\n",
      "Epoch 00034: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1233 - acc: 0.9634 - val_loss: 2.1512 - val_acc: 0.6198\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9668\n",
      "Epoch 00035: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1098 - acc: 0.9668 - val_loss: 2.1998 - val_acc: 0.6278\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9661\n",
      "Epoch 00036: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1101 - acc: 0.9661 - val_loss: 2.0900 - val_acc: 0.6215\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9673\n",
      "Epoch 00037: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1071 - acc: 0.9672 - val_loss: 2.1499 - val_acc: 0.6350\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9660\n",
      "Epoch 00038: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1133 - acc: 0.9660 - val_loss: 2.3160 - val_acc: 0.5945\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9698\n",
      "Epoch 00039: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1024 - acc: 0.9697 - val_loss: 2.4213 - val_acc: 0.6010\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9668\n",
      "Epoch 00040: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1125 - acc: 0.9668 - val_loss: 2.0857 - val_acc: 0.6294\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9725\n",
      "Epoch 00041: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0929 - acc: 0.9725 - val_loss: 2.5881 - val_acc: 0.5986\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9705\n",
      "Epoch 00042: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1018 - acc: 0.9705 - val_loss: 2.3502 - val_acc: 0.6073\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9730\n",
      "Epoch 00043: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0904 - acc: 0.9730 - val_loss: 2.0965 - val_acc: 0.6310\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9736\n",
      "Epoch 00044: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0888 - acc: 0.9736 - val_loss: 2.2352 - val_acc: 0.6252\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9723\n",
      "Epoch 00045: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0936 - acc: 0.9723 - val_loss: 2.4296 - val_acc: 0.6000\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0903 - acc: 0.9733\n",
      "Epoch 00046: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0903 - acc: 0.9733 - val_loss: 2.1784 - val_acc: 0.6362\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9741\n",
      "Epoch 00047: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0864 - acc: 0.9741 - val_loss: 2.2947 - val_acc: 0.6187\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9734\n",
      "Epoch 00048: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0897 - acc: 0.9734 - val_loss: 2.4779 - val_acc: 0.6012\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9743\n",
      "Epoch 00049: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0875 - acc: 0.9743 - val_loss: 2.1941 - val_acc: 0.6303\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9765\n",
      "Epoch 00050: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0796 - acc: 0.9766 - val_loss: 2.1387 - val_acc: 0.6478\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9785\n",
      "Epoch 00051: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0732 - acc: 0.9785 - val_loss: 2.1012 - val_acc: 0.6546\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9751\n",
      "Epoch 00052: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0847 - acc: 0.9751 - val_loss: 2.1707 - val_acc: 0.6527\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9781\n",
      "Epoch 00053: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0768 - acc: 0.9781 - val_loss: 2.4561 - val_acc: 0.6098\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9778\n",
      "Epoch 00054: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0761 - acc: 0.9778 - val_loss: 2.3836 - val_acc: 0.6191\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9783\n",
      "Epoch 00055: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0721 - acc: 0.9783 - val_loss: 2.4573 - val_acc: 0.6103\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9764\n",
      "Epoch 00056: val_loss did not improve from 1.44431\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0807 - acc: 0.9764 - val_loss: 2.5565 - val_acc: 0.6068\n",
      "\n",
      "1D_CNN_3_conv_custom_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 852us/sample - loss: 1.5859 - acc: 0.5691\n",
      "Loss: 1.5858958748394578 Accuracy: 0.569055\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1467 - acc: 0.3592\n",
      "Epoch 00001: val_loss improved from inf to 1.55041, saving model to model/checkpoint/1D_CNN_4_conv_custom_DO_BN_checkpoint/001-1.5504.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 2.1466 - acc: 0.3592 - val_loss: 1.5504 - val_acc: 0.5013\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4399 - acc: 0.5561\n",
      "Epoch 00002: val_loss improved from 1.55041 to 1.19985, saving model to model/checkpoint/1D_CNN_4_conv_custom_DO_BN_checkpoint/002-1.1998.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.4399 - acc: 0.5561 - val_loss: 1.1998 - val_acc: 0.6308\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2007 - acc: 0.6302\n",
      "Epoch 00003: val_loss improved from 1.19985 to 1.05261, saving model to model/checkpoint/1D_CNN_4_conv_custom_DO_BN_checkpoint/003-1.0526.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.2006 - acc: 0.6303 - val_loss: 1.0526 - val_acc: 0.6785\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0677 - acc: 0.6717\n",
      "Epoch 00004: val_loss improved from 1.05261 to 1.02107, saving model to model/checkpoint/1D_CNN_4_conv_custom_DO_BN_checkpoint/004-1.0211.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.0680 - acc: 0.6717 - val_loss: 1.0211 - val_acc: 0.6893\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9637 - acc: 0.7064\n",
      "Epoch 00005: val_loss improved from 1.02107 to 1.00265, saving model to model/checkpoint/1D_CNN_4_conv_custom_DO_BN_checkpoint/005-1.0026.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.9638 - acc: 0.7064 - val_loss: 1.0026 - val_acc: 0.6962\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8813 - acc: 0.7297\n",
      "Epoch 00006: val_loss improved from 1.00265 to 0.90587, saving model to model/checkpoint/1D_CNN_4_conv_custom_DO_BN_checkpoint/006-0.9059.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.8813 - acc: 0.7298 - val_loss: 0.9059 - val_acc: 0.7384\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8114 - acc: 0.7480\n",
      "Epoch 00007: val_loss did not improve from 0.90587\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.8114 - acc: 0.7480 - val_loss: 0.9344 - val_acc: 0.7338\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7384 - acc: 0.7708\n",
      "Epoch 00008: val_loss did not improve from 0.90587\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.7385 - acc: 0.7708 - val_loss: 1.2883 - val_acc: 0.6373\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6907 - acc: 0.7825\n",
      "Epoch 00009: val_loss improved from 0.90587 to 0.89851, saving model to model/checkpoint/1D_CNN_4_conv_custom_DO_BN_checkpoint/009-0.8985.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6906 - acc: 0.7825 - val_loss: 0.8985 - val_acc: 0.7372\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6246 - acc: 0.8060\n",
      "Epoch 00010: val_loss improved from 0.89851 to 0.89454, saving model to model/checkpoint/1D_CNN_4_conv_custom_DO_BN_checkpoint/010-0.8945.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6247 - acc: 0.8060 - val_loss: 0.8945 - val_acc: 0.7524\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5911 - acc: 0.8117\n",
      "Epoch 00011: val_loss did not improve from 0.89454\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5913 - acc: 0.8117 - val_loss: 0.9513 - val_acc: 0.7319\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5427 - acc: 0.8310\n",
      "Epoch 00012: val_loss improved from 0.89454 to 0.89151, saving model to model/checkpoint/1D_CNN_4_conv_custom_DO_BN_checkpoint/012-0.8915.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5427 - acc: 0.8310 - val_loss: 0.8915 - val_acc: 0.7491\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5051 - acc: 0.8402\n",
      "Epoch 00013: val_loss did not improve from 0.89151\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5051 - acc: 0.8402 - val_loss: 0.9582 - val_acc: 0.7282\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4731 - acc: 0.8508\n",
      "Epoch 00014: val_loss did not improve from 0.89151\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4732 - acc: 0.8508 - val_loss: 1.1343 - val_acc: 0.6716\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4459 - acc: 0.8590\n",
      "Epoch 00015: val_loss did not improve from 0.89151\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4458 - acc: 0.8591 - val_loss: 1.0895 - val_acc: 0.7091\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4204 - acc: 0.8657\n",
      "Epoch 00016: val_loss did not improve from 0.89151\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4206 - acc: 0.8657 - val_loss: 0.9897 - val_acc: 0.7270\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3984 - acc: 0.8723\n",
      "Epoch 00017: val_loss did not improve from 0.89151\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3984 - acc: 0.8724 - val_loss: 1.0014 - val_acc: 0.7352\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3735 - acc: 0.8805\n",
      "Epoch 00018: val_loss did not improve from 0.89151\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3735 - acc: 0.8806 - val_loss: 1.0156 - val_acc: 0.7405\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3538 - acc: 0.8882\n",
      "Epoch 00019: val_loss did not improve from 0.89151\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3539 - acc: 0.8882 - val_loss: 0.9288 - val_acc: 0.7556\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3381 - acc: 0.8923\n",
      "Epoch 00020: val_loss improved from 0.89151 to 0.88517, saving model to model/checkpoint/1D_CNN_4_conv_custom_DO_BN_checkpoint/020-0.8852.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3381 - acc: 0.8923 - val_loss: 0.8852 - val_acc: 0.7768\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3195 - acc: 0.8967\n",
      "Epoch 00021: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3195 - acc: 0.8966 - val_loss: 0.9193 - val_acc: 0.7596\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3036 - acc: 0.9020\n",
      "Epoch 00022: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3037 - acc: 0.9020 - val_loss: 0.9359 - val_acc: 0.7575\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.9067\n",
      "Epoch 00023: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2936 - acc: 0.9067 - val_loss: 1.0228 - val_acc: 0.7445\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2790 - acc: 0.9107\n",
      "Epoch 00024: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2790 - acc: 0.9107 - val_loss: 0.9485 - val_acc: 0.7596\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2657 - acc: 0.9137\n",
      "Epoch 00025: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2657 - acc: 0.9137 - val_loss: 0.9514 - val_acc: 0.7622\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2574 - acc: 0.9155\n",
      "Epoch 00026: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2574 - acc: 0.9155 - val_loss: 1.0717 - val_acc: 0.7338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2433 - acc: 0.9209\n",
      "Epoch 00027: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2433 - acc: 0.9209 - val_loss: 1.0767 - val_acc: 0.7354\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2377 - acc: 0.9237\n",
      "Epoch 00028: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2377 - acc: 0.9237 - val_loss: 1.0711 - val_acc: 0.7435\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2259 - acc: 0.9270\n",
      "Epoch 00029: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2259 - acc: 0.9270 - val_loss: 1.2333 - val_acc: 0.7100\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2262 - acc: 0.9267\n",
      "Epoch 00030: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2261 - acc: 0.9267 - val_loss: 1.3152 - val_acc: 0.6769\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2124 - acc: 0.9312\n",
      "Epoch 00031: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2125 - acc: 0.9312 - val_loss: 1.1513 - val_acc: 0.7207\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2168 - acc: 0.9310\n",
      "Epoch 00032: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2170 - acc: 0.9310 - val_loss: 1.0357 - val_acc: 0.7491\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2010 - acc: 0.9370\n",
      "Epoch 00033: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2010 - acc: 0.9370 - val_loss: 1.0946 - val_acc: 0.7396\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1972 - acc: 0.9368\n",
      "Epoch 00034: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1972 - acc: 0.9368 - val_loss: 0.9596 - val_acc: 0.7785\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1873 - acc: 0.9415\n",
      "Epoch 00035: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1872 - acc: 0.9416 - val_loss: 0.9716 - val_acc: 0.7834\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9416\n",
      "Epoch 00036: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1845 - acc: 0.9416 - val_loss: 1.1720 - val_acc: 0.7331\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1823 - acc: 0.9423\n",
      "Epoch 00037: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1823 - acc: 0.9423 - val_loss: 0.9813 - val_acc: 0.7836\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9458\n",
      "Epoch 00038: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1697 - acc: 0.9458 - val_loss: 0.9771 - val_acc: 0.7822\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1721 - acc: 0.9448\n",
      "Epoch 00039: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1721 - acc: 0.9447 - val_loss: 1.0679 - val_acc: 0.7647\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9449\n",
      "Epoch 00040: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1757 - acc: 0.9449 - val_loss: 1.0087 - val_acc: 0.7692\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1637 - acc: 0.9477\n",
      "Epoch 00041: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1637 - acc: 0.9477 - val_loss: 1.0255 - val_acc: 0.7775\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9517\n",
      "Epoch 00042: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1532 - acc: 0.9517 - val_loss: 0.9371 - val_acc: 0.7838\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1511 - acc: 0.9508\n",
      "Epoch 00043: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1512 - acc: 0.9507 - val_loss: 1.1042 - val_acc: 0.7519\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9507\n",
      "Epoch 00044: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1578 - acc: 0.9507 - val_loss: 1.1647 - val_acc: 0.7533\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9537\n",
      "Epoch 00045: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1459 - acc: 0.9537 - val_loss: 1.1400 - val_acc: 0.7519\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9550\n",
      "Epoch 00046: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1432 - acc: 0.9550 - val_loss: 0.9975 - val_acc: 0.7754\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1461 - acc: 0.9537\n",
      "Epoch 00047: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1461 - acc: 0.9537 - val_loss: 1.0185 - val_acc: 0.7806\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9562\n",
      "Epoch 00048: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1432 - acc: 0.9562 - val_loss: 1.1722 - val_acc: 0.7463\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9571\n",
      "Epoch 00049: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1338 - acc: 0.9571 - val_loss: 1.1541 - val_acc: 0.7577\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9583\n",
      "Epoch 00050: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1325 - acc: 0.9583 - val_loss: 1.2803 - val_acc: 0.7442\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9592\n",
      "Epoch 00051: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1312 - acc: 0.9592 - val_loss: 1.0380 - val_acc: 0.7741\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9584\n",
      "Epoch 00052: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1298 - acc: 0.9584 - val_loss: 1.1807 - val_acc: 0.7522\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9584\n",
      "Epoch 00053: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1326 - acc: 0.9584 - val_loss: 1.0693 - val_acc: 0.7680\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9591\n",
      "Epoch 00054: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1285 - acc: 0.9591 - val_loss: 1.1132 - val_acc: 0.7673\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9634\n",
      "Epoch 00055: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1221 - acc: 0.9634 - val_loss: 1.0123 - val_acc: 0.7885\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9613\n",
      "Epoch 00056: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1259 - acc: 0.9613 - val_loss: 1.2178 - val_acc: 0.7449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9635\n",
      "Epoch 00057: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1188 - acc: 0.9635 - val_loss: 1.0483 - val_acc: 0.7815\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9633\n",
      "Epoch 00058: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1165 - acc: 0.9633 - val_loss: 1.1864 - val_acc: 0.7510\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9617\n",
      "Epoch 00059: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1229 - acc: 0.9617 - val_loss: 1.0331 - val_acc: 0.7820\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9655\n",
      "Epoch 00060: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1121 - acc: 0.9655 - val_loss: 1.1313 - val_acc: 0.7708\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9651\n",
      "Epoch 00061: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1147 - acc: 0.9651 - val_loss: 1.0365 - val_acc: 0.7799\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9660\n",
      "Epoch 00062: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1101 - acc: 0.9660 - val_loss: 1.0671 - val_acc: 0.7736\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9680\n",
      "Epoch 00063: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1051 - acc: 0.9680 - val_loss: 1.0467 - val_acc: 0.7801\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9671\n",
      "Epoch 00064: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1035 - acc: 0.9671 - val_loss: 1.1452 - val_acc: 0.7673\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9670\n",
      "Epoch 00065: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1074 - acc: 0.9670 - val_loss: 1.1832 - val_acc: 0.7612\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9682\n",
      "Epoch 00066: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1040 - acc: 0.9682 - val_loss: 1.0815 - val_acc: 0.7722\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9687\n",
      "Epoch 00067: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1033 - acc: 0.9687 - val_loss: 1.1195 - val_acc: 0.7750\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9694\n",
      "Epoch 00068: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1025 - acc: 0.9694 - val_loss: 1.0463 - val_acc: 0.7815\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9700\n",
      "Epoch 00069: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1002 - acc: 0.9699 - val_loss: 1.1237 - val_acc: 0.7787\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9704\n",
      "Epoch 00070: val_loss did not improve from 0.88517\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0990 - acc: 0.9704 - val_loss: 1.1798 - val_acc: 0.7682\n",
      "\n",
      "1D_CNN_4_conv_custom_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 884us/sample - loss: 1.0541 - acc: 0.7173\n",
      "Loss: 1.0541436347387043 Accuracy: 0.71734166\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0914 - acc: 0.3708\n",
      "Epoch 00001: val_loss improved from inf to 1.51326, saving model to model/checkpoint/1D_CNN_5_conv_custom_DO_BN_checkpoint/001-1.5133.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 2.0914 - acc: 0.3708 - val_loss: 1.5133 - val_acc: 0.5222\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3343 - acc: 0.5870\n",
      "Epoch 00002: val_loss improved from 1.51326 to 1.12484, saving model to model/checkpoint/1D_CNN_5_conv_custom_DO_BN_checkpoint/002-1.1248.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.3343 - acc: 0.5870 - val_loss: 1.1248 - val_acc: 0.6429\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1097 - acc: 0.6561\n",
      "Epoch 00003: val_loss improved from 1.12484 to 0.88999, saving model to model/checkpoint/1D_CNN_5_conv_custom_DO_BN_checkpoint/003-0.8900.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.1100 - acc: 0.6561 - val_loss: 0.8900 - val_acc: 0.7452\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9750 - acc: 0.6989\n",
      "Epoch 00004: val_loss improved from 0.88999 to 0.87472, saving model to model/checkpoint/1D_CNN_5_conv_custom_DO_BN_checkpoint/004-0.8747.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.9750 - acc: 0.6989 - val_loss: 0.8747 - val_acc: 0.7491\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8719 - acc: 0.7319\n",
      "Epoch 00005: val_loss improved from 0.87472 to 0.86007, saving model to model/checkpoint/1D_CNN_5_conv_custom_DO_BN_checkpoint/005-0.8601.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8721 - acc: 0.7319 - val_loss: 0.8601 - val_acc: 0.7442\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7997 - acc: 0.7572\n",
      "Epoch 00006: val_loss improved from 0.86007 to 0.80683, saving model to model/checkpoint/1D_CNN_5_conv_custom_DO_BN_checkpoint/006-0.8068.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7998 - acc: 0.7572 - val_loss: 0.8068 - val_acc: 0.7605\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7438 - acc: 0.7727\n",
      "Epoch 00007: val_loss improved from 0.80683 to 0.75181, saving model to model/checkpoint/1D_CNN_5_conv_custom_DO_BN_checkpoint/007-0.7518.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7439 - acc: 0.7727 - val_loss: 0.7518 - val_acc: 0.7831\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6894 - acc: 0.7919\n",
      "Epoch 00008: val_loss improved from 0.75181 to 0.69777, saving model to model/checkpoint/1D_CNN_5_conv_custom_DO_BN_checkpoint/008-0.6978.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6895 - acc: 0.7919 - val_loss: 0.6978 - val_acc: 0.8097\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6390 - acc: 0.8064\n",
      "Epoch 00009: val_loss did not improve from 0.69777\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6390 - acc: 0.8064 - val_loss: 0.7582 - val_acc: 0.7820\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6070 - acc: 0.8153\n",
      "Epoch 00010: val_loss did not improve from 0.69777\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6070 - acc: 0.8153 - val_loss: 0.8691 - val_acc: 0.7428\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5713 - acc: 0.8256\n",
      "Epoch 00011: val_loss did not improve from 0.69777\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5712 - acc: 0.8256 - val_loss: 0.7039 - val_acc: 0.7985\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5394 - acc: 0.8332\n",
      "Epoch 00012: val_loss did not improve from 0.69777\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5395 - acc: 0.8331 - val_loss: 0.7992 - val_acc: 0.7652\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5095 - acc: 0.8419\n",
      "Epoch 00013: val_loss improved from 0.69777 to 0.66448, saving model to model/checkpoint/1D_CNN_5_conv_custom_DO_BN_checkpoint/013-0.6645.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5095 - acc: 0.8419 - val_loss: 0.6645 - val_acc: 0.8102\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4845 - acc: 0.8491\n",
      "Epoch 00014: val_loss did not improve from 0.66448\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4847 - acc: 0.8491 - val_loss: 0.7587 - val_acc: 0.7810\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4598 - acc: 0.8553\n",
      "Epoch 00015: val_loss did not improve from 0.66448\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4598 - acc: 0.8553 - val_loss: 0.7453 - val_acc: 0.8060\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4334 - acc: 0.8646\n",
      "Epoch 00016: val_loss did not improve from 0.66448\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4336 - acc: 0.8646 - val_loss: 0.8719 - val_acc: 0.7605\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4300 - acc: 0.8654\n",
      "Epoch 00017: val_loss did not improve from 0.66448\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4300 - acc: 0.8654 - val_loss: 0.6986 - val_acc: 0.8062\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3909 - acc: 0.8769\n",
      "Epoch 00018: val_loss did not improve from 0.66448\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3910 - acc: 0.8769 - val_loss: 0.7067 - val_acc: 0.8069\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3745 - acc: 0.8814\n",
      "Epoch 00019: val_loss did not improve from 0.66448\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3745 - acc: 0.8814 - val_loss: 0.7056 - val_acc: 0.8074\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3646 - acc: 0.8840\n",
      "Epoch 00020: val_loss did not improve from 0.66448\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3646 - acc: 0.8840 - val_loss: 0.7118 - val_acc: 0.8008\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3500 - acc: 0.8880\n",
      "Epoch 00021: val_loss did not improve from 0.66448\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3501 - acc: 0.8880 - val_loss: 0.7723 - val_acc: 0.7862\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3367 - acc: 0.8935\n",
      "Epoch 00022: val_loss improved from 0.66448 to 0.65226, saving model to model/checkpoint/1D_CNN_5_conv_custom_DO_BN_checkpoint/022-0.6523.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3369 - acc: 0.8934 - val_loss: 0.6523 - val_acc: 0.8202\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3189 - acc: 0.8988\n",
      "Epoch 00023: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3190 - acc: 0.8987 - val_loss: 0.6985 - val_acc: 0.8137\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3102 - acc: 0.9018\n",
      "Epoch 00024: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3102 - acc: 0.9018 - val_loss: 0.7118 - val_acc: 0.8099\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2891 - acc: 0.9068\n",
      "Epoch 00025: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2891 - acc: 0.9068 - val_loss: 0.6877 - val_acc: 0.8148\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2825 - acc: 0.9089\n",
      "Epoch 00026: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2826 - acc: 0.9088 - val_loss: 0.7435 - val_acc: 0.8027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2727 - acc: 0.9133\n",
      "Epoch 00027: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2727 - acc: 0.9133 - val_loss: 0.7267 - val_acc: 0.8143\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2630 - acc: 0.9153\n",
      "Epoch 00028: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2630 - acc: 0.9153 - val_loss: 0.7825 - val_acc: 0.8027\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2541 - acc: 0.9178\n",
      "Epoch 00029: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2542 - acc: 0.9178 - val_loss: 0.6719 - val_acc: 0.8251\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2398 - acc: 0.9215\n",
      "Epoch 00030: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2398 - acc: 0.9215 - val_loss: 0.7463 - val_acc: 0.8097\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2318 - acc: 0.9259\n",
      "Epoch 00031: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2317 - acc: 0.9259 - val_loss: 0.7218 - val_acc: 0.8171\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2269 - acc: 0.9259\n",
      "Epoch 00032: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2269 - acc: 0.9259 - val_loss: 0.7934 - val_acc: 0.8090\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2206 - acc: 0.9282\n",
      "Epoch 00033: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2206 - acc: 0.9282 - val_loss: 0.7489 - val_acc: 0.8204\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9311\n",
      "Epoch 00034: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2126 - acc: 0.9311 - val_loss: 0.6849 - val_acc: 0.8272\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9325\n",
      "Epoch 00035: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2074 - acc: 0.9325 - val_loss: 0.6809 - val_acc: 0.8290\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9357\n",
      "Epoch 00036: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1982 - acc: 0.9357 - val_loss: 0.6794 - val_acc: 0.8309\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1931 - acc: 0.9374\n",
      "Epoch 00037: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1931 - acc: 0.9374 - val_loss: 0.7410 - val_acc: 0.8090\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9393\n",
      "Epoch 00038: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1887 - acc: 0.9393 - val_loss: 0.6913 - val_acc: 0.8276\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1940 - acc: 0.9370\n",
      "Epoch 00039: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1941 - acc: 0.9370 - val_loss: 0.7943 - val_acc: 0.8050\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1871 - acc: 0.9385\n",
      "Epoch 00040: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1871 - acc: 0.9385 - val_loss: 0.7837 - val_acc: 0.8071\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9449\n",
      "Epoch 00041: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1722 - acc: 0.9450 - val_loss: 0.7352 - val_acc: 0.8197\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1725 - acc: 0.9443\n",
      "Epoch 00042: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1725 - acc: 0.9442 - val_loss: 0.8563 - val_acc: 0.7850\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1688 - acc: 0.9444\n",
      "Epoch 00043: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1687 - acc: 0.9444 - val_loss: 0.7456 - val_acc: 0.8181\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9464\n",
      "Epoch 00044: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1627 - acc: 0.9464 - val_loss: 0.7138 - val_acc: 0.8318\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9476\n",
      "Epoch 00045: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1605 - acc: 0.9476 - val_loss: 0.7985 - val_acc: 0.8071\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9516\n",
      "Epoch 00046: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1493 - acc: 0.9516 - val_loss: 0.7425 - val_acc: 0.8295\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1662 - acc: 0.9446\n",
      "Epoch 00047: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1662 - acc: 0.9446 - val_loss: 0.6809 - val_acc: 0.8328\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9529\n",
      "Epoch 00048: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1438 - acc: 0.9529 - val_loss: 0.7473 - val_acc: 0.8348\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9546\n",
      "Epoch 00049: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1389 - acc: 0.9546 - val_loss: 0.7890 - val_acc: 0.8206\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9522\n",
      "Epoch 00050: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1482 - acc: 0.9522 - val_loss: 0.7134 - val_acc: 0.8297\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9558\n",
      "Epoch 00051: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1384 - acc: 0.9558 - val_loss: 0.7379 - val_acc: 0.8330\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9574\n",
      "Epoch 00052: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1326 - acc: 0.9574 - val_loss: 0.7732 - val_acc: 0.8346\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9571\n",
      "Epoch 00053: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1358 - acc: 0.9571 - val_loss: 0.7672 - val_acc: 0.8369\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9576\n",
      "Epoch 00054: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1326 - acc: 0.9575 - val_loss: 0.7496 - val_acc: 0.8328\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9590\n",
      "Epoch 00055: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1272 - acc: 0.9590 - val_loss: 0.7899 - val_acc: 0.8253\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9584\n",
      "Epoch 00056: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1284 - acc: 0.9584 - val_loss: 0.7078 - val_acc: 0.8360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9591\n",
      "Epoch 00057: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1282 - acc: 0.9591 - val_loss: 0.7618 - val_acc: 0.8339\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9605\n",
      "Epoch 00058: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1252 - acc: 0.9605 - val_loss: 0.7810 - val_acc: 0.8293\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9608\n",
      "Epoch 00059: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1207 - acc: 0.9608 - val_loss: 0.7975 - val_acc: 0.8206\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9625\n",
      "Epoch 00060: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1185 - acc: 0.9625 - val_loss: 0.7778 - val_acc: 0.8227\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9638\n",
      "Epoch 00061: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1164 - acc: 0.9637 - val_loss: 0.7867 - val_acc: 0.8204\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9648\n",
      "Epoch 00062: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1131 - acc: 0.9648 - val_loss: 0.8037 - val_acc: 0.8183\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9653\n",
      "Epoch 00063: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1091 - acc: 0.9653 - val_loss: 0.7164 - val_acc: 0.8344\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9654\n",
      "Epoch 00064: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1115 - acc: 0.9654 - val_loss: 0.8049 - val_acc: 0.8181\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9627\n",
      "Epoch 00065: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1158 - acc: 0.9627 - val_loss: 0.7179 - val_acc: 0.8437\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9698\n",
      "Epoch 00066: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0966 - acc: 0.9698 - val_loss: 0.9472 - val_acc: 0.8004\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9652\n",
      "Epoch 00067: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1092 - acc: 0.9652 - val_loss: 0.7732 - val_acc: 0.8288\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9684\n",
      "Epoch 00068: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1030 - acc: 0.9684 - val_loss: 0.8338 - val_acc: 0.8230\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9679\n",
      "Epoch 00069: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1021 - acc: 0.9679 - val_loss: 0.7919 - val_acc: 0.8260\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9682\n",
      "Epoch 00070: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0991 - acc: 0.9682 - val_loss: 0.7743 - val_acc: 0.8339\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9676\n",
      "Epoch 00071: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1030 - acc: 0.9676 - val_loss: 0.7765 - val_acc: 0.8346\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9707\n",
      "Epoch 00072: val_loss did not improve from 0.65226\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0943 - acc: 0.9707 - val_loss: 0.8375 - val_acc: 0.8167\n",
      "\n",
      "1D_CNN_5_conv_custom_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 948us/sample - loss: 0.7541 - acc: 0.7807\n",
      "Loss: 0.7540559037452175 Accuracy: 0.78068537\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2130 - acc: 0.3274\n",
      "Epoch 00001: val_loss improved from inf to 1.51934, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/001-1.5193.hdf5\n",
      "36805/36805 [==============================] - 99s 3ms/sample - loss: 2.2129 - acc: 0.3275 - val_loss: 1.5193 - val_acc: 0.4964\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3525 - acc: 0.5717\n",
      "Epoch 00002: val_loss improved from 1.51934 to 1.00728, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/002-1.0073.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.3524 - acc: 0.5717 - val_loss: 1.0073 - val_acc: 0.6960\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0826 - acc: 0.6628\n",
      "Epoch 00003: val_loss improved from 1.00728 to 0.98286, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/003-0.9829.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.0826 - acc: 0.6628 - val_loss: 0.9829 - val_acc: 0.7058\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9247 - acc: 0.7184\n",
      "Epoch 00004: val_loss improved from 0.98286 to 0.79174, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/004-0.7917.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.9246 - acc: 0.7185 - val_loss: 0.7917 - val_acc: 0.7629\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8220 - acc: 0.7507\n",
      "Epoch 00005: val_loss improved from 0.79174 to 0.74296, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/005-0.7430.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.8220 - acc: 0.7507 - val_loss: 0.7430 - val_acc: 0.7845\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7469 - acc: 0.7745\n",
      "Epoch 00006: val_loss improved from 0.74296 to 0.65759, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/006-0.6576.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.7471 - acc: 0.7745 - val_loss: 0.6576 - val_acc: 0.8083\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6919 - acc: 0.7915\n",
      "Epoch 00007: val_loss improved from 0.65759 to 0.62183, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/007-0.6218.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.6919 - acc: 0.7915 - val_loss: 0.6218 - val_acc: 0.8258\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6380 - acc: 0.8099\n",
      "Epoch 00008: val_loss improved from 0.62183 to 0.61221, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/008-0.6122.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.6383 - acc: 0.8098 - val_loss: 0.6122 - val_acc: 0.8223\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5916 - acc: 0.8238\n",
      "Epoch 00009: val_loss did not improve from 0.61221\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5917 - acc: 0.8238 - val_loss: 0.6186 - val_acc: 0.8332\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5490 - acc: 0.8359\n",
      "Epoch 00010: val_loss improved from 0.61221 to 0.56089, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/010-0.5609.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5491 - acc: 0.8359 - val_loss: 0.5609 - val_acc: 0.8321\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5155 - acc: 0.8458\n",
      "Epoch 00011: val_loss improved from 0.56089 to 0.50477, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/011-0.5048.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5158 - acc: 0.8457 - val_loss: 0.5048 - val_acc: 0.8661\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4912 - acc: 0.8530\n",
      "Epoch 00012: val_loss did not improve from 0.50477\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4911 - acc: 0.8530 - val_loss: 0.5122 - val_acc: 0.8605\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4662 - acc: 0.8618\n",
      "Epoch 00013: val_loss did not improve from 0.50477\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4662 - acc: 0.8618 - val_loss: 0.5284 - val_acc: 0.8521\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4372 - acc: 0.8689\n",
      "Epoch 00014: val_loss improved from 0.50477 to 0.49915, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/014-0.4992.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4372 - acc: 0.8688 - val_loss: 0.4992 - val_acc: 0.8591\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4162 - acc: 0.8761\n",
      "Epoch 00015: val_loss did not improve from 0.49915\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4162 - acc: 0.8760 - val_loss: 0.5020 - val_acc: 0.8637\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4028 - acc: 0.8783\n",
      "Epoch 00016: val_loss improved from 0.49915 to 0.48382, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/016-0.4838.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4027 - acc: 0.8783 - val_loss: 0.4838 - val_acc: 0.8677\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3788 - acc: 0.8856\n",
      "Epoch 00017: val_loss improved from 0.48382 to 0.45876, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/017-0.4588.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3789 - acc: 0.8856 - val_loss: 0.4588 - val_acc: 0.8679\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3654 - acc: 0.8895\n",
      "Epoch 00018: val_loss did not improve from 0.45876\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3654 - acc: 0.8894 - val_loss: 0.5488 - val_acc: 0.8458\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3507 - acc: 0.8931\n",
      "Epoch 00019: val_loss did not improve from 0.45876\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3507 - acc: 0.8931 - val_loss: 0.6113 - val_acc: 0.8300\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3343 - acc: 0.8978\n",
      "Epoch 00020: val_loss improved from 0.45876 to 0.45062, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/020-0.4506.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3344 - acc: 0.8978 - val_loss: 0.4506 - val_acc: 0.8754\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3185 - acc: 0.9026\n",
      "Epoch 00021: val_loss did not improve from 0.45062\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3187 - acc: 0.9026 - val_loss: 0.4837 - val_acc: 0.8677\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3145 - acc: 0.9044\n",
      "Epoch 00022: val_loss did not improve from 0.45062\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3146 - acc: 0.9044 - val_loss: 0.4590 - val_acc: 0.8770\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2988 - acc: 0.9087\n",
      "Epoch 00023: val_loss did not improve from 0.45062\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2988 - acc: 0.9086 - val_loss: 0.5289 - val_acc: 0.8519\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2859 - acc: 0.9121\n",
      "Epoch 00024: val_loss improved from 0.45062 to 0.41417, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/024-0.4142.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2859 - acc: 0.9121 - val_loss: 0.4142 - val_acc: 0.8875\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2730 - acc: 0.9154\n",
      "Epoch 00025: val_loss improved from 0.41417 to 0.40890, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/025-0.4089.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2730 - acc: 0.9154 - val_loss: 0.4089 - val_acc: 0.8896\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2667 - acc: 0.9166\n",
      "Epoch 00026: val_loss did not improve from 0.40890\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2667 - acc: 0.9166 - val_loss: 0.4289 - val_acc: 0.8826\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2592 - acc: 0.9200\n",
      "Epoch 00027: val_loss did not improve from 0.40890\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2592 - acc: 0.9200 - val_loss: 0.4203 - val_acc: 0.8828\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2520 - acc: 0.9222\n",
      "Epoch 00028: val_loss did not improve from 0.40890\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2520 - acc: 0.9222 - val_loss: 0.4718 - val_acc: 0.8763\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2408 - acc: 0.9250\n",
      "Epoch 00029: val_loss did not improve from 0.40890\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2408 - acc: 0.9250 - val_loss: 0.4571 - val_acc: 0.8803\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2290 - acc: 0.9294\n",
      "Epoch 00030: val_loss improved from 0.40890 to 0.40373, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/030-0.4037.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2291 - acc: 0.9294 - val_loss: 0.4037 - val_acc: 0.8873\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2272 - acc: 0.9286\n",
      "Epoch 00031: val_loss did not improve from 0.40373\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2272 - acc: 0.9286 - val_loss: 0.4080 - val_acc: 0.8961\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9338\n",
      "Epoch 00032: val_loss improved from 0.40373 to 0.39274, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/032-0.3927.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2132 - acc: 0.9338 - val_loss: 0.3927 - val_acc: 0.8973\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9335\n",
      "Epoch 00033: val_loss did not improve from 0.39274\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2104 - acc: 0.9335 - val_loss: 0.4435 - val_acc: 0.8873\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2094 - acc: 0.9348\n",
      "Epoch 00034: val_loss did not improve from 0.39274\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2094 - acc: 0.9348 - val_loss: 0.3973 - val_acc: 0.8961\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1969 - acc: 0.9378\n",
      "Epoch 00035: val_loss did not improve from 0.39274\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1969 - acc: 0.9378 - val_loss: 0.4101 - val_acc: 0.8926\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1899 - acc: 0.9401\n",
      "Epoch 00036: val_loss did not improve from 0.39274\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1899 - acc: 0.9401 - val_loss: 0.4029 - val_acc: 0.8963\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1855 - acc: 0.9412\n",
      "Epoch 00037: val_loss did not improve from 0.39274\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1857 - acc: 0.9411 - val_loss: 0.4999 - val_acc: 0.8719\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1902 - acc: 0.9380\n",
      "Epoch 00038: val_loss improved from 0.39274 to 0.38009, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/038-0.3801.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1903 - acc: 0.9379 - val_loss: 0.3801 - val_acc: 0.8973\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9455\n",
      "Epoch 00039: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1747 - acc: 0.9455 - val_loss: 0.4221 - val_acc: 0.8894\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9471\n",
      "Epoch 00040: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1689 - acc: 0.9471 - val_loss: 0.3916 - val_acc: 0.9010\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9493\n",
      "Epoch 00041: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1644 - acc: 0.9493 - val_loss: 0.4242 - val_acc: 0.8938\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1637 - acc: 0.9481\n",
      "Epoch 00042: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1637 - acc: 0.9481 - val_loss: 0.4531 - val_acc: 0.8821\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1565 - acc: 0.9500\n",
      "Epoch 00043: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1565 - acc: 0.9500 - val_loss: 0.4156 - val_acc: 0.8919\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9528\n",
      "Epoch 00044: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1532 - acc: 0.9528 - val_loss: 0.4586 - val_acc: 0.8821\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9515\n",
      "Epoch 00045: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1480 - acc: 0.9516 - val_loss: 0.4501 - val_acc: 0.8905\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9518\n",
      "Epoch 00046: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1482 - acc: 0.9518 - val_loss: 0.4061 - val_acc: 0.8933\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1423 - acc: 0.9545\n",
      "Epoch 00047: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1425 - acc: 0.9545 - val_loss: 0.4722 - val_acc: 0.8852\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9543\n",
      "Epoch 00048: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1430 - acc: 0.9543 - val_loss: 0.3961 - val_acc: 0.8966\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9573\n",
      "Epoch 00049: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1328 - acc: 0.9573 - val_loss: 0.3885 - val_acc: 0.8991\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9588\n",
      "Epoch 00050: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1302 - acc: 0.9588 - val_loss: 0.4587 - val_acc: 0.8966\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9576\n",
      "Epoch 00051: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1335 - acc: 0.9575 - val_loss: 0.4352 - val_acc: 0.8961\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9575\n",
      "Epoch 00052: val_loss did not improve from 0.38009\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1317 - acc: 0.9575 - val_loss: 0.4602 - val_acc: 0.8838\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9613\n",
      "Epoch 00053: val_loss improved from 0.38009 to 0.37743, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/053-0.3774.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1247 - acc: 0.9613 - val_loss: 0.3774 - val_acc: 0.9068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9611\n",
      "Epoch 00054: val_loss did not improve from 0.37743\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1209 - acc: 0.9611 - val_loss: 0.4015 - val_acc: 0.8991\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9604\n",
      "Epoch 00055: val_loss did not improve from 0.37743\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1212 - acc: 0.9604 - val_loss: 0.4612 - val_acc: 0.8919\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9634\n",
      "Epoch 00056: val_loss did not improve from 0.37743\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1136 - acc: 0.9634 - val_loss: 0.3892 - val_acc: 0.8975\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9636\n",
      "Epoch 00057: val_loss did not improve from 0.37743\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1142 - acc: 0.9636 - val_loss: 0.4184 - val_acc: 0.9022\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9634\n",
      "Epoch 00058: val_loss improved from 0.37743 to 0.36875, saving model to model/checkpoint/1D_CNN_6_conv_custom_DO_BN_checkpoint/058-0.3688.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1136 - acc: 0.9634 - val_loss: 0.3688 - val_acc: 0.9075\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9642\n",
      "Epoch 00059: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1097 - acc: 0.9642 - val_loss: 0.5384 - val_acc: 0.8672\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9649\n",
      "Epoch 00060: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1086 - acc: 0.9648 - val_loss: 0.3969 - val_acc: 0.9080\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9677\n",
      "Epoch 00061: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1039 - acc: 0.9677 - val_loss: 0.4433 - val_acc: 0.8977\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9640\n",
      "Epoch 00062: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1124 - acc: 0.9639 - val_loss: 0.4068 - val_acc: 0.9066\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9677\n",
      "Epoch 00063: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1022 - acc: 0.9677 - val_loss: 0.4220 - val_acc: 0.8994\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9689\n",
      "Epoch 00064: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0967 - acc: 0.9689 - val_loss: 0.4175 - val_acc: 0.9036\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9690\n",
      "Epoch 00065: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0958 - acc: 0.9690 - val_loss: 0.4559 - val_acc: 0.8931\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9695\n",
      "Epoch 00066: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0957 - acc: 0.9695 - val_loss: 0.4150 - val_acc: 0.8998\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9694\n",
      "Epoch 00067: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0966 - acc: 0.9694 - val_loss: 0.4130 - val_acc: 0.9087\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9714\n",
      "Epoch 00068: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0884 - acc: 0.9714 - val_loss: 0.4880 - val_acc: 0.8898\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9703\n",
      "Epoch 00069: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0931 - acc: 0.9703 - val_loss: 0.4718 - val_acc: 0.8949\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9716\n",
      "Epoch 00070: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0887 - acc: 0.9716 - val_loss: 0.4177 - val_acc: 0.9038\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9720\n",
      "Epoch 00071: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0901 - acc: 0.9719 - val_loss: 0.4356 - val_acc: 0.9043\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9730\n",
      "Epoch 00072: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0864 - acc: 0.9729 - val_loss: 0.4324 - val_acc: 0.9068\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9718\n",
      "Epoch 00073: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0872 - acc: 0.9718 - val_loss: 0.4757 - val_acc: 0.8945\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9724\n",
      "Epoch 00074: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0890 - acc: 0.9724 - val_loss: 0.4003 - val_acc: 0.9075\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9744\n",
      "Epoch 00075: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0799 - acc: 0.9744 - val_loss: 0.4576 - val_acc: 0.8973\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9731\n",
      "Epoch 00076: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0823 - acc: 0.9731 - val_loss: 0.3944 - val_acc: 0.9094\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9755\n",
      "Epoch 00077: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0774 - acc: 0.9755 - val_loss: 0.3943 - val_acc: 0.9068\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9767\n",
      "Epoch 00078: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0750 - acc: 0.9767 - val_loss: 0.4889 - val_acc: 0.8854\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9708\n",
      "Epoch 00079: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0960 - acc: 0.9707 - val_loss: 0.4867 - val_acc: 0.8887\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9771\n",
      "Epoch 00080: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0735 - acc: 0.9771 - val_loss: 0.5293 - val_acc: 0.8854\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9772\n",
      "Epoch 00081: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0726 - acc: 0.9771 - val_loss: 0.4405 - val_acc: 0.8973\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9743\n",
      "Epoch 00082: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0801 - acc: 0.9743 - val_loss: 0.5069 - val_acc: 0.8952\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9774\n",
      "Epoch 00083: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0696 - acc: 0.9774 - val_loss: 0.4499 - val_acc: 0.8977\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9778\n",
      "Epoch 00084: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0694 - acc: 0.9778 - val_loss: 0.4318 - val_acc: 0.9031\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9793\n",
      "Epoch 00085: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0662 - acc: 0.9793 - val_loss: 0.3971 - val_acc: 0.9092\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9758\n",
      "Epoch 00086: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0756 - acc: 0.9758 - val_loss: 0.4368 - val_acc: 0.9019\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9785\n",
      "Epoch 00087: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0684 - acc: 0.9785 - val_loss: 0.4273 - val_acc: 0.9054\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9794\n",
      "Epoch 00088: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0644 - acc: 0.9794 - val_loss: 0.4405 - val_acc: 0.9061\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9793\n",
      "Epoch 00089: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0649 - acc: 0.9793 - val_loss: 0.4153 - val_acc: 0.9052\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9755\n",
      "Epoch 00090: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0729 - acc: 0.9755 - val_loss: 0.4244 - val_acc: 0.9052\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9807\n",
      "Epoch 00091: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0607 - acc: 0.9807 - val_loss: 0.4634 - val_acc: 0.8975\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9818\n",
      "Epoch 00092: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0585 - acc: 0.9817 - val_loss: 0.5622 - val_acc: 0.8838\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9782\n",
      "Epoch 00093: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0710 - acc: 0.9781 - val_loss: 0.4124 - val_acc: 0.9073\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9797\n",
      "Epoch 00094: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0660 - acc: 0.9796 - val_loss: 0.4284 - val_acc: 0.9106\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9800\n",
      "Epoch 00095: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0645 - acc: 0.9800 - val_loss: 0.4515 - val_acc: 0.9012\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9811\n",
      "Epoch 00096: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0576 - acc: 0.9811 - val_loss: 0.4822 - val_acc: 0.8952\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9825\n",
      "Epoch 00097: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0580 - acc: 0.9825 - val_loss: 0.4231 - val_acc: 0.9082\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9821\n",
      "Epoch 00098: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0574 - acc: 0.9821 - val_loss: 0.4244 - val_acc: 0.9099\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9797\n",
      "Epoch 00099: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0610 - acc: 0.9797 - val_loss: 0.4839 - val_acc: 0.9050\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9805\n",
      "Epoch 00100: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0622 - acc: 0.9805 - val_loss: 0.5044 - val_acc: 0.9033\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9827\n",
      "Epoch 00101: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0580 - acc: 0.9827 - val_loss: 0.4334 - val_acc: 0.9066\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9826\n",
      "Epoch 00102: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0544 - acc: 0.9826 - val_loss: 0.4227 - val_acc: 0.9031\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9820\n",
      "Epoch 00103: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0577 - acc: 0.9820 - val_loss: 0.4159 - val_acc: 0.9113\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9824\n",
      "Epoch 00104: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0569 - acc: 0.9824 - val_loss: 0.4363 - val_acc: 0.9085\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9852\n",
      "Epoch 00105: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0493 - acc: 0.9852 - val_loss: 0.3963 - val_acc: 0.9103\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9823\n",
      "Epoch 00106: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0558 - acc: 0.9823 - val_loss: 0.3998 - val_acc: 0.9138\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9823\n",
      "Epoch 00107: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0578 - acc: 0.9822 - val_loss: 0.4159 - val_acc: 0.9131\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9822\n",
      "Epoch 00108: val_loss did not improve from 0.36875\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0566 - acc: 0.9822 - val_loss: 0.4166 - val_acc: 0.9064\n",
      "\n",
      "1D_CNN_6_conv_custom_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 987us/sample - loss: 0.4597 - acc: 0.8827\n",
      "Loss: 0.45965244111489906 Accuracy: 0.88265836\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2683 - acc: 0.3092\n",
      "Epoch 00001: val_loss improved from inf to 1.47777, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/001-1.4778.hdf5\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 2.2682 - acc: 0.3092 - val_loss: 1.4778 - val_acc: 0.5386\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3631 - acc: 0.5650\n",
      "Epoch 00002: val_loss improved from 1.47777 to 0.98671, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/002-0.9867.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.3631 - acc: 0.5651 - val_loss: 0.9867 - val_acc: 0.6869\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0193 - acc: 0.6808\n",
      "Epoch 00003: val_loss improved from 0.98671 to 0.84917, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/003-0.8492.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.0194 - acc: 0.6808 - val_loss: 0.8492 - val_acc: 0.7452\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8302 - acc: 0.7455\n",
      "Epoch 00004: val_loss improved from 0.84917 to 0.61397, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/004-0.6140.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.8302 - acc: 0.7455 - val_loss: 0.6140 - val_acc: 0.8188\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6994 - acc: 0.7843\n",
      "Epoch 00005: val_loss did not improve from 0.61397\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6994 - acc: 0.7843 - val_loss: 0.8136 - val_acc: 0.7529\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6139 - acc: 0.8151\n",
      "Epoch 00006: val_loss improved from 0.61397 to 0.51014, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/006-0.5101.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6138 - acc: 0.8152 - val_loss: 0.5101 - val_acc: 0.8491\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5438 - acc: 0.8350\n",
      "Epoch 00007: val_loss improved from 0.51014 to 0.47205, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/007-0.4720.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5439 - acc: 0.8350 - val_loss: 0.4720 - val_acc: 0.8714\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4935 - acc: 0.8512\n",
      "Epoch 00008: val_loss improved from 0.47205 to 0.42089, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/008-0.4209.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4935 - acc: 0.8512 - val_loss: 0.4209 - val_acc: 0.8793\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4457 - acc: 0.8670\n",
      "Epoch 00009: val_loss improved from 0.42089 to 0.39466, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/009-0.3947.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4457 - acc: 0.8671 - val_loss: 0.3947 - val_acc: 0.8912\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4065 - acc: 0.8750\n",
      "Epoch 00010: val_loss improved from 0.39466 to 0.33201, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/010-0.3320.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4065 - acc: 0.8750 - val_loss: 0.3320 - val_acc: 0.9103\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3755 - acc: 0.8853\n",
      "Epoch 00011: val_loss did not improve from 0.33201\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3754 - acc: 0.8853 - val_loss: 0.3491 - val_acc: 0.9038\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3509 - acc: 0.8939\n",
      "Epoch 00012: val_loss did not improve from 0.33201\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3510 - acc: 0.8939 - val_loss: 0.3471 - val_acc: 0.9117\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3308 - acc: 0.8992\n",
      "Epoch 00013: val_loss improved from 0.33201 to 0.30743, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/013-0.3074.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3308 - acc: 0.8992 - val_loss: 0.3074 - val_acc: 0.9096\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3097 - acc: 0.9073\n",
      "Epoch 00014: val_loss improved from 0.30743 to 0.29814, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/014-0.2981.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3097 - acc: 0.9073 - val_loss: 0.2981 - val_acc: 0.9213\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2891 - acc: 0.9118\n",
      "Epoch 00015: val_loss did not improve from 0.29814\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2891 - acc: 0.9118 - val_loss: 0.3135 - val_acc: 0.9131\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2731 - acc: 0.9160\n",
      "Epoch 00016: val_loss improved from 0.29814 to 0.27006, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/016-0.2701.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2732 - acc: 0.9160 - val_loss: 0.2701 - val_acc: 0.9222\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2641 - acc: 0.9189\n",
      "Epoch 00017: val_loss improved from 0.27006 to 0.25519, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/017-0.2552.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2641 - acc: 0.9189 - val_loss: 0.2552 - val_acc: 0.9304\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.9238\n",
      "Epoch 00018: val_loss improved from 0.25519 to 0.25469, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/018-0.2547.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2470 - acc: 0.9238 - val_loss: 0.2547 - val_acc: 0.9322\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2330 - acc: 0.9290\n",
      "Epoch 00019: val_loss did not improve from 0.25469\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2330 - acc: 0.9290 - val_loss: 0.3078 - val_acc: 0.9143\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2262 - acc: 0.9302\n",
      "Epoch 00020: val_loss did not improve from 0.25469\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2263 - acc: 0.9301 - val_loss: 0.2650 - val_acc: 0.9257\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2157 - acc: 0.9339\n",
      "Epoch 00021: val_loss did not improve from 0.25469\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2157 - acc: 0.9339 - val_loss: 0.2836 - val_acc: 0.9168\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2016 - acc: 0.9366\n",
      "Epoch 00022: val_loss did not improve from 0.25469\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2015 - acc: 0.9366 - val_loss: 0.2873 - val_acc: 0.9208\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1991 - acc: 0.9381\n",
      "Epoch 00023: val_loss improved from 0.25469 to 0.24210, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/023-0.2421.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1992 - acc: 0.9380 - val_loss: 0.2421 - val_acc: 0.9334\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1899 - acc: 0.9410\n",
      "Epoch 00024: val_loss did not improve from 0.24210\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1899 - acc: 0.9410 - val_loss: 0.2798 - val_acc: 0.9224\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1777 - acc: 0.9446\n",
      "Epoch 00025: val_loss did not improve from 0.24210\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1777 - acc: 0.9446 - val_loss: 0.2484 - val_acc: 0.9373\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9462\n",
      "Epoch 00026: val_loss did not improve from 0.24210\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1715 - acc: 0.9462 - val_loss: 0.2553 - val_acc: 0.9273\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1686 - acc: 0.9473\n",
      "Epoch 00027: val_loss improved from 0.24210 to 0.23932, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/027-0.2393.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1686 - acc: 0.9473 - val_loss: 0.2393 - val_acc: 0.9338\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9504\n",
      "Epoch 00028: val_loss improved from 0.23932 to 0.21700, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/028-0.2170.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1581 - acc: 0.9504 - val_loss: 0.2170 - val_acc: 0.9436\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9517\n",
      "Epoch 00029: val_loss did not improve from 0.21700\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1547 - acc: 0.9517 - val_loss: 0.2539 - val_acc: 0.9283\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9533\n",
      "Epoch 00030: val_loss did not improve from 0.21700\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1507 - acc: 0.9533 - val_loss: 0.2522 - val_acc: 0.9329\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1467 - acc: 0.9546\n",
      "Epoch 00031: val_loss did not improve from 0.21700\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1467 - acc: 0.9546 - val_loss: 0.2210 - val_acc: 0.9453\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1365 - acc: 0.9576\n",
      "Epoch 00032: val_loss did not improve from 0.21700\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1366 - acc: 0.9576 - val_loss: 0.2695 - val_acc: 0.9297\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9561\n",
      "Epoch 00033: val_loss did not improve from 0.21700\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1361 - acc: 0.9561 - val_loss: 0.2395 - val_acc: 0.9313\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9617\n",
      "Epoch 00034: val_loss improved from 0.21700 to 0.21503, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/034-0.2150.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1217 - acc: 0.9617 - val_loss: 0.2150 - val_acc: 0.9467\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9616\n",
      "Epoch 00035: val_loss did not improve from 0.21503\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1238 - acc: 0.9616 - val_loss: 0.2506 - val_acc: 0.9292\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9628\n",
      "Epoch 00036: val_loss did not improve from 0.21503\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1198 - acc: 0.9628 - val_loss: 0.2528 - val_acc: 0.9304\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9615\n",
      "Epoch 00037: val_loss did not improve from 0.21503\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1200 - acc: 0.9616 - val_loss: 0.2219 - val_acc: 0.9415\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9660\n",
      "Epoch 00038: val_loss did not improve from 0.21503\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1092 - acc: 0.9660 - val_loss: 0.2563 - val_acc: 0.9341\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9642\n",
      "Epoch 00039: val_loss did not improve from 0.21503\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1093 - acc: 0.9642 - val_loss: 0.2502 - val_acc: 0.9364\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9655\n",
      "Epoch 00040: val_loss did not improve from 0.21503\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1097 - acc: 0.9655 - val_loss: 0.2715 - val_acc: 0.9308\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9664\n",
      "Epoch 00041: val_loss improved from 0.21503 to 0.20305, saving model to model/checkpoint/1D_CNN_7_conv_custom_DO_BN_checkpoint/041-0.2031.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1059 - acc: 0.9663 - val_loss: 0.2031 - val_acc: 0.9467\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9682\n",
      "Epoch 00042: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1005 - acc: 0.9682 - val_loss: 0.3256 - val_acc: 0.9220\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9694\n",
      "Epoch 00043: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0954 - acc: 0.9694 - val_loss: 0.2799 - val_acc: 0.9234\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9670\n",
      "Epoch 00044: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1036 - acc: 0.9670 - val_loss: 0.2167 - val_acc: 0.9448\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9699\n",
      "Epoch 00045: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0918 - acc: 0.9699 - val_loss: 0.2283 - val_acc: 0.9392\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9727\n",
      "Epoch 00046: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0865 - acc: 0.9727 - val_loss: 0.2226 - val_acc: 0.9434\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9748\n",
      "Epoch 00047: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0818 - acc: 0.9748 - val_loss: 0.2450 - val_acc: 0.9413\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9734\n",
      "Epoch 00048: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0823 - acc: 0.9734 - val_loss: 0.2235 - val_acc: 0.9401\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9741\n",
      "Epoch 00049: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0831 - acc: 0.9741 - val_loss: 0.2287 - val_acc: 0.9413\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9753\n",
      "Epoch 00050: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0783 - acc: 0.9753 - val_loss: 0.2203 - val_acc: 0.9467\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9754\n",
      "Epoch 00051: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0776 - acc: 0.9754 - val_loss: 0.2340 - val_acc: 0.9453\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9751\n",
      "Epoch 00052: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0766 - acc: 0.9751 - val_loss: 0.2429 - val_acc: 0.9373\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9768\n",
      "Epoch 00053: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0744 - acc: 0.9767 - val_loss: 0.2413 - val_acc: 0.9362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9757\n",
      "Epoch 00054: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0751 - acc: 0.9757 - val_loss: 0.2438 - val_acc: 0.9408\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9780\n",
      "Epoch 00055: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0697 - acc: 0.9780 - val_loss: 0.2574 - val_acc: 0.9304\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9769\n",
      "Epoch 00056: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0721 - acc: 0.9769 - val_loss: 0.2430 - val_acc: 0.9401\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9736\n",
      "Epoch 00057: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0810 - acc: 0.9736 - val_loss: 0.2260 - val_acc: 0.9474\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9787\n",
      "Epoch 00058: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0708 - acc: 0.9787 - val_loss: 0.2231 - val_acc: 0.9443\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9804\n",
      "Epoch 00059: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0622 - acc: 0.9804 - val_loss: 0.2370 - val_acc: 0.9429\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9810\n",
      "Epoch 00060: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0618 - acc: 0.9810 - val_loss: 0.2103 - val_acc: 0.9476\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9818\n",
      "Epoch 00061: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0588 - acc: 0.9818 - val_loss: 0.3697 - val_acc: 0.9166\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9823\n",
      "Epoch 00062: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0552 - acc: 0.9823 - val_loss: 0.3183 - val_acc: 0.9278\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9825\n",
      "Epoch 00063: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0570 - acc: 0.9825 - val_loss: 0.2616 - val_acc: 0.9427\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9827\n",
      "Epoch 00064: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0570 - acc: 0.9827 - val_loss: 0.2317 - val_acc: 0.9422\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9826\n",
      "Epoch 00065: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0548 - acc: 0.9826 - val_loss: 0.2161 - val_acc: 0.9504\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9836\n",
      "Epoch 00066: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0504 - acc: 0.9836 - val_loss: 0.3395 - val_acc: 0.9311\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9824\n",
      "Epoch 00067: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0562 - acc: 0.9824 - val_loss: 0.2335 - val_acc: 0.9443\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9820\n",
      "Epoch 00068: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0549 - acc: 0.9820 - val_loss: 0.2508 - val_acc: 0.9385\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9841\n",
      "Epoch 00069: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0510 - acc: 0.9841 - val_loss: 0.2347 - val_acc: 0.9441\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9851\n",
      "Epoch 00070: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0463 - acc: 0.9851 - val_loss: 0.2481 - val_acc: 0.9453\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9845\n",
      "Epoch 00071: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0500 - acc: 0.9845 - val_loss: 0.2536 - val_acc: 0.9369\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9852\n",
      "Epoch 00072: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0479 - acc: 0.9852 - val_loss: 0.2920 - val_acc: 0.9341\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9843\n",
      "Epoch 00073: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0499 - acc: 0.9843 - val_loss: 0.2806 - val_acc: 0.9369\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9866\n",
      "Epoch 00074: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0437 - acc: 0.9866 - val_loss: 0.2431 - val_acc: 0.9455\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9859\n",
      "Epoch 00075: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0447 - acc: 0.9859 - val_loss: 0.3208 - val_acc: 0.9341\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9857\n",
      "Epoch 00076: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0439 - acc: 0.9857 - val_loss: 0.2711 - val_acc: 0.9371\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9880\n",
      "Epoch 00077: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0396 - acc: 0.9880 - val_loss: 0.2394 - val_acc: 0.9443\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9870\n",
      "Epoch 00078: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0439 - acc: 0.9870 - val_loss: 0.2402 - val_acc: 0.9467\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9856\n",
      "Epoch 00079: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0448 - acc: 0.9856 - val_loss: 0.2413 - val_acc: 0.9457\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9870\n",
      "Epoch 00080: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0401 - acc: 0.9870 - val_loss: 0.2668 - val_acc: 0.9427\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9878\n",
      "Epoch 00081: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0392 - acc: 0.9878 - val_loss: 0.3091 - val_acc: 0.9329\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9851\n",
      "Epoch 00082: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0481 - acc: 0.9851 - val_loss: 0.2759 - val_acc: 0.9408\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9887\n",
      "Epoch 00083: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0376 - acc: 0.9887 - val_loss: 0.2445 - val_acc: 0.9490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9868\n",
      "Epoch 00084: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0403 - acc: 0.9868 - val_loss: 0.2813 - val_acc: 0.9404\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9896\n",
      "Epoch 00085: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0350 - acc: 0.9896 - val_loss: 0.2928 - val_acc: 0.9373\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9844\n",
      "Epoch 00086: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0477 - acc: 0.9844 - val_loss: 0.2309 - val_acc: 0.9483\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9906\n",
      "Epoch 00087: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0319 - acc: 0.9906 - val_loss: 0.2641 - val_acc: 0.9415\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9892\n",
      "Epoch 00088: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0341 - acc: 0.9892 - val_loss: 0.2395 - val_acc: 0.9455\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9903\n",
      "Epoch 00089: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0319 - acc: 0.9903 - val_loss: 0.2228 - val_acc: 0.9511\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9903\n",
      "Epoch 00090: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0330 - acc: 0.9903 - val_loss: 0.2635 - val_acc: 0.9420\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9892\n",
      "Epoch 00091: val_loss did not improve from 0.20305\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0356 - acc: 0.9892 - val_loss: 0.2459 - val_acc: 0.9425\n",
      "\n",
      "1D_CNN_7_conv_custom_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2338 - acc: 0.9373\n",
      "Loss: 0.23377935187281848 Accuracy: 0.93727934\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2547 - acc: 0.3224\n",
      "Epoch 00001: val_loss improved from inf to 1.45089, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/001-1.4509.hdf5\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 2.2546 - acc: 0.3224 - val_loss: 1.4509 - val_acc: 0.5344\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2286 - acc: 0.6094\n",
      "Epoch 00002: val_loss improved from 1.45089 to 0.74118, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/002-0.7412.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 1.2287 - acc: 0.6094 - val_loss: 0.7412 - val_acc: 0.7857\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8554 - acc: 0.7336\n",
      "Epoch 00003: val_loss improved from 0.74118 to 0.56571, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/003-0.5657.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.8554 - acc: 0.7336 - val_loss: 0.5657 - val_acc: 0.8372\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6454 - acc: 0.8015\n",
      "Epoch 00004: val_loss improved from 0.56571 to 0.38759, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/004-0.3876.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.6453 - acc: 0.8016 - val_loss: 0.3876 - val_acc: 0.8868\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5240 - acc: 0.8385\n",
      "Epoch 00005: val_loss improved from 0.38759 to 0.31807, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/005-0.3181.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.5240 - acc: 0.8386 - val_loss: 0.3181 - val_acc: 0.9143\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4390 - acc: 0.8645\n",
      "Epoch 00006: val_loss improved from 0.31807 to 0.29986, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/006-0.2999.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4390 - acc: 0.8645 - val_loss: 0.2999 - val_acc: 0.9133\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3764 - acc: 0.8826\n",
      "Epoch 00007: val_loss did not improve from 0.29986\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3765 - acc: 0.8826 - val_loss: 0.3151 - val_acc: 0.9122\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3373 - acc: 0.8969\n",
      "Epoch 00008: val_loss did not improve from 0.29986\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3375 - acc: 0.8968 - val_loss: 0.3170 - val_acc: 0.9110\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3050 - acc: 0.9061\n",
      "Epoch 00009: val_loss improved from 0.29986 to 0.23533, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/009-0.2353.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3050 - acc: 0.9061 - val_loss: 0.2353 - val_acc: 0.9311\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2725 - acc: 0.9137\n",
      "Epoch 00010: val_loss improved from 0.23533 to 0.22846, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/010-0.2285.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2725 - acc: 0.9137 - val_loss: 0.2285 - val_acc: 0.9317\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2567 - acc: 0.9209\n",
      "Epoch 00011: val_loss improved from 0.22846 to 0.19524, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/011-0.1952.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2567 - acc: 0.9209 - val_loss: 0.1952 - val_acc: 0.9450\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2294 - acc: 0.9283\n",
      "Epoch 00012: val_loss improved from 0.19524 to 0.18452, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/012-0.1845.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2294 - acc: 0.9283 - val_loss: 0.1845 - val_acc: 0.9476\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9333\n",
      "Epoch 00013: val_loss did not improve from 0.18452\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2140 - acc: 0.9333 - val_loss: 0.2414 - val_acc: 0.9329\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9373\n",
      "Epoch 00014: val_loss did not improve from 0.18452\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2021 - acc: 0.9372 - val_loss: 0.1919 - val_acc: 0.9429\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1897 - acc: 0.9406\n",
      "Epoch 00015: val_loss improved from 0.18452 to 0.17477, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/015-0.1748.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1897 - acc: 0.9406 - val_loss: 0.1748 - val_acc: 0.9462\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1776 - acc: 0.9446\n",
      "Epoch 00016: val_loss did not improve from 0.17477\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1777 - acc: 0.9446 - val_loss: 0.1763 - val_acc: 0.9492\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1676 - acc: 0.9461\n",
      "Epoch 00017: val_loss improved from 0.17477 to 0.17247, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/017-0.1725.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1676 - acc: 0.9461 - val_loss: 0.1725 - val_acc: 0.9495\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9522\n",
      "Epoch 00018: val_loss did not improve from 0.17247\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1558 - acc: 0.9522 - val_loss: 0.1815 - val_acc: 0.9411\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9541\n",
      "Epoch 00019: val_loss improved from 0.17247 to 0.16118, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/019-0.1612.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1440 - acc: 0.9541 - val_loss: 0.1612 - val_acc: 0.9560\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9562\n",
      "Epoch 00020: val_loss did not improve from 0.16118\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1387 - acc: 0.9562 - val_loss: 0.1909 - val_acc: 0.9418\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9590\n",
      "Epoch 00021: val_loss did not improve from 0.16118\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1290 - acc: 0.9590 - val_loss: 0.1957 - val_acc: 0.9460\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9603\n",
      "Epoch 00022: val_loss improved from 0.16118 to 0.15825, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/022-0.1582.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1262 - acc: 0.9603 - val_loss: 0.1582 - val_acc: 0.9541\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9622\n",
      "Epoch 00023: val_loss did not improve from 0.15825\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1204 - acc: 0.9622 - val_loss: 0.1635 - val_acc: 0.9497\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9641\n",
      "Epoch 00024: val_loss did not improve from 0.15825\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1108 - acc: 0.9641 - val_loss: 0.1825 - val_acc: 0.9511\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9660\n",
      "Epoch 00025: val_loss improved from 0.15825 to 0.15467, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/025-0.1547.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1071 - acc: 0.9660 - val_loss: 0.1547 - val_acc: 0.9550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9678\n",
      "Epoch 00026: val_loss did not improve from 0.15467\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1007 - acc: 0.9678 - val_loss: 0.1641 - val_acc: 0.9532\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9685\n",
      "Epoch 00027: val_loss improved from 0.15467 to 0.14992, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/027-0.1499.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0992 - acc: 0.9685 - val_loss: 0.1499 - val_acc: 0.9564\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9695\n",
      "Epoch 00028: val_loss improved from 0.14992 to 0.14742, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/028-0.1474.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0958 - acc: 0.9695 - val_loss: 0.1474 - val_acc: 0.9562\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9732\n",
      "Epoch 00029: val_loss did not improve from 0.14742\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0862 - acc: 0.9731 - val_loss: 0.1499 - val_acc: 0.9602\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9704\n",
      "Epoch 00030: val_loss did not improve from 0.14742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0889 - acc: 0.9704 - val_loss: 0.1480 - val_acc: 0.9543\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9733\n",
      "Epoch 00031: val_loss did not improve from 0.14742\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0818 - acc: 0.9733 - val_loss: 0.2150 - val_acc: 0.9425\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9771\n",
      "Epoch 00032: val_loss did not improve from 0.14742\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0757 - acc: 0.9771 - val_loss: 0.1515 - val_acc: 0.9569\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9764\n",
      "Epoch 00033: val_loss did not improve from 0.14742\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0747 - acc: 0.9764 - val_loss: 0.1680 - val_acc: 0.9504\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9742\n",
      "Epoch 00034: val_loss did not improve from 0.14742\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0814 - acc: 0.9742 - val_loss: 0.1578 - val_acc: 0.9585\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9771\n",
      "Epoch 00035: val_loss improved from 0.14742 to 0.14002, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/035-0.1400.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0726 - acc: 0.9771 - val_loss: 0.1400 - val_acc: 0.9611\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9802\n",
      "Epoch 00036: val_loss did not improve from 0.14002\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0621 - acc: 0.9801 - val_loss: 0.1426 - val_acc: 0.9597\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9781\n",
      "Epoch 00037: val_loss improved from 0.14002 to 0.13363, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/037-0.1336.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0674 - acc: 0.9781 - val_loss: 0.1336 - val_acc: 0.9627\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9783\n",
      "Epoch 00038: val_loss did not improve from 0.13363\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0698 - acc: 0.9783 - val_loss: 0.1445 - val_acc: 0.9578\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9812\n",
      "Epoch 00039: val_loss did not improve from 0.13363\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0603 - acc: 0.9812 - val_loss: 0.1542 - val_acc: 0.9550\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9837\n",
      "Epoch 00040: val_loss did not improve from 0.13363\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0527 - acc: 0.9838 - val_loss: 0.1597 - val_acc: 0.9553\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9833\n",
      "Epoch 00041: val_loss did not improve from 0.13363\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0538 - acc: 0.9833 - val_loss: 0.1454 - val_acc: 0.9590\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9844\n",
      "Epoch 00042: val_loss did not improve from 0.13363\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0488 - acc: 0.9843 - val_loss: 0.1427 - val_acc: 0.9627\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9823\n",
      "Epoch 00043: val_loss did not improve from 0.13363\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0541 - acc: 0.9823 - val_loss: 0.1378 - val_acc: 0.9644\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9847\n",
      "Epoch 00044: val_loss improved from 0.13363 to 0.13223, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/044-0.1322.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0479 - acc: 0.9847 - val_loss: 0.1322 - val_acc: 0.9620\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9866\n",
      "Epoch 00045: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0440 - acc: 0.9866 - val_loss: 0.2081 - val_acc: 0.9464\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9814\n",
      "Epoch 00046: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0585 - acc: 0.9814 - val_loss: 0.1547 - val_acc: 0.9585\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9847\n",
      "Epoch 00047: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0485 - acc: 0.9847 - val_loss: 0.1534 - val_acc: 0.9592\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9868\n",
      "Epoch 00048: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0429 - acc: 0.9868 - val_loss: 0.1707 - val_acc: 0.9569\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9877\n",
      "Epoch 00049: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0401 - acc: 0.9877 - val_loss: 0.1949 - val_acc: 0.9527\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9835\n",
      "Epoch 00050: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0529 - acc: 0.9835 - val_loss: 0.1384 - val_acc: 0.9606\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9883\n",
      "Epoch 00051: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0376 - acc: 0.9883 - val_loss: 0.1945 - val_acc: 0.9520\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9902\n",
      "Epoch 00052: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0331 - acc: 0.9902 - val_loss: 0.1518 - val_acc: 0.9632\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9864\n",
      "Epoch 00053: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0432 - acc: 0.9864 - val_loss: 0.1540 - val_acc: 0.9606\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9874\n",
      "Epoch 00054: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0400 - acc: 0.9874 - val_loss: 0.1337 - val_acc: 0.9623\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9875\n",
      "Epoch 00055: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0411 - acc: 0.9875 - val_loss: 0.1866 - val_acc: 0.9534\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9888\n",
      "Epoch 00056: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0382 - acc: 0.9888 - val_loss: 0.1638 - val_acc: 0.9599\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9897\n",
      "Epoch 00057: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0350 - acc: 0.9897 - val_loss: 0.1595 - val_acc: 0.9609\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9904\n",
      "Epoch 00058: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0306 - acc: 0.9903 - val_loss: 0.2226 - val_acc: 0.9481\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9867\n",
      "Epoch 00059: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0434 - acc: 0.9867 - val_loss: 0.1470 - val_acc: 0.9618\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9921\n",
      "Epoch 00060: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0268 - acc: 0.9921 - val_loss: 0.2199 - val_acc: 0.9488\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9919\n",
      "Epoch 00061: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0272 - acc: 0.9919 - val_loss: 0.2225 - val_acc: 0.9464\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9919\n",
      "Epoch 00062: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0286 - acc: 0.9919 - val_loss: 0.1716 - val_acc: 0.9588\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9905\n",
      "Epoch 00063: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0304 - acc: 0.9904 - val_loss: 0.2879 - val_acc: 0.9383\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9876\n",
      "Epoch 00064: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0382 - acc: 0.9876 - val_loss: 0.1406 - val_acc: 0.9627\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9876\n",
      "Epoch 00065: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0411 - acc: 0.9876 - val_loss: 0.1462 - val_acc: 0.9648\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9934\n",
      "Epoch 00066: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0228 - acc: 0.9934 - val_loss: 0.1540 - val_acc: 0.9620\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9934\n",
      "Epoch 00067: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0232 - acc: 0.9934 - val_loss: 0.1458 - val_acc: 0.9662\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9915\n",
      "Epoch 00068: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0282 - acc: 0.9915 - val_loss: 0.1690 - val_acc: 0.9611\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9924\n",
      "Epoch 00069: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0241 - acc: 0.9924 - val_loss: 0.1570 - val_acc: 0.9585\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9929\n",
      "Epoch 00070: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0242 - acc: 0.9929 - val_loss: 0.1368 - val_acc: 0.9630\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9930\n",
      "Epoch 00071: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0232 - acc: 0.9930 - val_loss: 0.1677 - val_acc: 0.9616\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9915\n",
      "Epoch 00072: val_loss did not improve from 0.13223\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0281 - acc: 0.9914 - val_loss: 0.2338 - val_acc: 0.9450\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9871\n",
      "Epoch 00073: val_loss improved from 0.13223 to 0.12621, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/073-0.1262.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0429 - acc: 0.9871 - val_loss: 0.1262 - val_acc: 0.9660\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9945\n",
      "Epoch 00074: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0186 - acc: 0.9944 - val_loss: 0.1355 - val_acc: 0.9676\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9918\n",
      "Epoch 00075: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0286 - acc: 0.9918 - val_loss: 0.1580 - val_acc: 0.9616\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9940\n",
      "Epoch 00076: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0200 - acc: 0.9940 - val_loss: 0.2272 - val_acc: 0.9502\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9875\n",
      "Epoch 00077: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0392 - acc: 0.9875 - val_loss: 0.1321 - val_acc: 0.9667\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9922\n",
      "Epoch 00078: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0261 - acc: 0.9922 - val_loss: 0.1498 - val_acc: 0.9648\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9954\n",
      "Epoch 00079: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0157 - acc: 0.9954 - val_loss: 0.1465 - val_acc: 0.9667\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9954\n",
      "Epoch 00080: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0161 - acc: 0.9954 - val_loss: 0.1937 - val_acc: 0.9546\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9940\n",
      "Epoch 00081: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0193 - acc: 0.9940 - val_loss: 0.1553 - val_acc: 0.9637\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9903\n",
      "Epoch 00082: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0316 - acc: 0.9903 - val_loss: 0.1669 - val_acc: 0.9599\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9921\n",
      "Epoch 00083: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0260 - acc: 0.9920 - val_loss: 0.1866 - val_acc: 0.9555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9933\n",
      "Epoch 00084: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0226 - acc: 0.9933 - val_loss: 0.1736 - val_acc: 0.9592\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9912\n",
      "Epoch 00085: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0280 - acc: 0.9912 - val_loss: 0.1801 - val_acc: 0.9602\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9955\n",
      "Epoch 00086: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0165 - acc: 0.9954 - val_loss: 0.1420 - val_acc: 0.9660\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9934\n",
      "Epoch 00087: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0220 - acc: 0.9933 - val_loss: 0.1858 - val_acc: 0.9574\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9902\n",
      "Epoch 00088: val_loss did not improve from 0.12621\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0333 - acc: 0.9901 - val_loss: 0.1908 - val_acc: 0.9532\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9905\n",
      "Epoch 00089: val_loss improved from 0.12621 to 0.12482, saving model to model/checkpoint/1D_CNN_8_conv_custom_DO_BN_checkpoint/089-0.1248.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0310 - acc: 0.9905 - val_loss: 0.1248 - val_acc: 0.9679\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9965\n",
      "Epoch 00090: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0135 - acc: 0.9965 - val_loss: 0.1375 - val_acc: 0.9658\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9959\n",
      "Epoch 00091: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0133 - acc: 0.9959 - val_loss: 0.1915 - val_acc: 0.9606\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9956\n",
      "Epoch 00092: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0154 - acc: 0.9956 - val_loss: 0.2014 - val_acc: 0.9553\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9951\n",
      "Epoch 00093: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0164 - acc: 0.9951 - val_loss: 0.1331 - val_acc: 0.9648\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9961\n",
      "Epoch 00094: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0143 - acc: 0.9961 - val_loss: 0.2135 - val_acc: 0.9539\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9938\n",
      "Epoch 00095: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0197 - acc: 0.9938 - val_loss: 0.2032 - val_acc: 0.9583\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9895\n",
      "Epoch 00096: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0342 - acc: 0.9895 - val_loss: 0.1883 - val_acc: 0.9574\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9960\n",
      "Epoch 00097: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0134 - acc: 0.9960 - val_loss: 0.1513 - val_acc: 0.9660\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9952\n",
      "Epoch 00098: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0155 - acc: 0.9952 - val_loss: 0.1895 - val_acc: 0.9595\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9964\n",
      "Epoch 00099: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0122 - acc: 0.9964 - val_loss: 0.1924 - val_acc: 0.9585\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9940\n",
      "Epoch 00100: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0198 - acc: 0.9940 - val_loss: 0.1546 - val_acc: 0.9637\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9961\n",
      "Epoch 00101: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0141 - acc: 0.9961 - val_loss: 0.1429 - val_acc: 0.9660\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9948\n",
      "Epoch 00102: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0174 - acc: 0.9948 - val_loss: 0.1471 - val_acc: 0.9660\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9943\n",
      "Epoch 00103: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0182 - acc: 0.9943 - val_loss: 0.2091 - val_acc: 0.9548\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9956\n",
      "Epoch 00104: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0137 - acc: 0.9955 - val_loss: 0.1458 - val_acc: 0.9665\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9934\n",
      "Epoch 00105: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0211 - acc: 0.9934 - val_loss: 0.1756 - val_acc: 0.9609\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9965\n",
      "Epoch 00106: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0129 - acc: 0.9965 - val_loss: 0.2347 - val_acc: 0.9567\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9925\n",
      "Epoch 00107: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0242 - acc: 0.9925 - val_loss: 0.1515 - val_acc: 0.9641\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9966\n",
      "Epoch 00108: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0125 - acc: 0.9965 - val_loss: 0.1630 - val_acc: 0.9625\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9907\n",
      "Epoch 00109: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0315 - acc: 0.9907 - val_loss: 0.1382 - val_acc: 0.9669\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9972\n",
      "Epoch 00110: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0097 - acc: 0.9972 - val_loss: 0.1676 - val_acc: 0.9627\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9968\n",
      "Epoch 00111: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0112 - acc: 0.9968 - val_loss: 0.1961 - val_acc: 0.9548\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9971\n",
      "Epoch 00112: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0109 - acc: 0.9971 - val_loss: 0.1467 - val_acc: 0.9693\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9946\n",
      "Epoch 00113: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0180 - acc: 0.9946 - val_loss: 0.1859 - val_acc: 0.9599\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9956\n",
      "Epoch 00114: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0141 - acc: 0.9956 - val_loss: 0.1573 - val_acc: 0.9632\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9974\n",
      "Epoch 00115: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0092 - acc: 0.9974 - val_loss: 0.1700 - val_acc: 0.9651\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9962\n",
      "Epoch 00116: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0123 - acc: 0.9962 - val_loss: 0.2165 - val_acc: 0.9557\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9955\n",
      "Epoch 00117: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0151 - acc: 0.9955 - val_loss: 0.1885 - val_acc: 0.9569\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9937\n",
      "Epoch 00118: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0200 - acc: 0.9937 - val_loss: 0.1564 - val_acc: 0.9613\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9969\n",
      "Epoch 00119: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0097 - acc: 0.9969 - val_loss: 0.1601 - val_acc: 0.9646\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9965\n",
      "Epoch 00120: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0108 - acc: 0.9965 - val_loss: 0.1716 - val_acc: 0.9637\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9957\n",
      "Epoch 00121: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0144 - acc: 0.9957 - val_loss: 0.1633 - val_acc: 0.9627\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9972\n",
      "Epoch 00122: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0102 - acc: 0.9972 - val_loss: 0.1656 - val_acc: 0.9634\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9959\n",
      "Epoch 00123: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0141 - acc: 0.9959 - val_loss: 0.1876 - val_acc: 0.9597\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9952\n",
      "Epoch 00124: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0148 - acc: 0.9952 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9942\n",
      "Epoch 00125: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0191 - acc: 0.9942 - val_loss: 0.1446 - val_acc: 0.9660\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9969\n",
      "Epoch 00126: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0098 - acc: 0.9969 - val_loss: 0.1636 - val_acc: 0.9620\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9973\n",
      "Epoch 00127: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0097 - acc: 0.9973 - val_loss: 0.1784 - val_acc: 0.9623\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9972\n",
      "Epoch 00128: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0096 - acc: 0.9972 - val_loss: 0.1984 - val_acc: 0.9599\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9945\n",
      "Epoch 00129: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0176 - acc: 0.9945 - val_loss: 0.1880 - val_acc: 0.9632\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9971\n",
      "Epoch 00130: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0096 - acc: 0.9971 - val_loss: 0.1568 - val_acc: 0.9679\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9953\n",
      "Epoch 00131: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0143 - acc: 0.9953 - val_loss: 0.1649 - val_acc: 0.9653\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9979\n",
      "Epoch 00132: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0072 - acc: 0.9979 - val_loss: 0.1773 - val_acc: 0.9625\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9962\n",
      "Epoch 00133: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0123 - acc: 0.9962 - val_loss: 0.1849 - val_acc: 0.9618\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9971\n",
      "Epoch 00134: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0100 - acc: 0.9971 - val_loss: 0.1456 - val_acc: 0.9669\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9963\n",
      "Epoch 00135: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0114 - acc: 0.9963 - val_loss: 0.1924 - val_acc: 0.9590\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9959\n",
      "Epoch 00136: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0137 - acc: 0.9959 - val_loss: 0.1941 - val_acc: 0.9606\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9976\n",
      "Epoch 00137: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0086 - acc: 0.9976 - val_loss: 0.1428 - val_acc: 0.9690\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9969\n",
      "Epoch 00138: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0102 - acc: 0.9969 - val_loss: 0.2105 - val_acc: 0.9599\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9969\n",
      "Epoch 00139: val_loss did not improve from 0.12482\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0093 - acc: 0.9969 - val_loss: 0.2693 - val_acc: 0.9506\n",
      "\n",
      "1D_CNN_8_conv_custom_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1842 - acc: 0.9553\n",
      "Loss: 0.1841527407607383 Accuracy: 0.9553479\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8299 - acc: 0.4602\n",
      "Epoch 00001: val_loss improved from inf to 0.95912, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/001-0.9591.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 1.8298 - acc: 0.4603 - val_loss: 0.9591 - val_acc: 0.7275\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7763 - acc: 0.7567\n",
      "Epoch 00002: val_loss improved from 0.95912 to 0.41526, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/002-0.4153.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.7763 - acc: 0.7567 - val_loss: 0.4153 - val_acc: 0.8821\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5221 - acc: 0.8384\n",
      "Epoch 00003: val_loss improved from 0.41526 to 0.32517, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/003-0.3252.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.5222 - acc: 0.8383 - val_loss: 0.3252 - val_acc: 0.9022\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4087 - acc: 0.8721\n",
      "Epoch 00004: val_loss did not improve from 0.32517\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4087 - acc: 0.8721 - val_loss: 0.3583 - val_acc: 0.8903\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3304 - acc: 0.8988\n",
      "Epoch 00005: val_loss improved from 0.32517 to 0.22594, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/005-0.2259.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.3304 - acc: 0.8988 - val_loss: 0.2259 - val_acc: 0.9357\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2836 - acc: 0.9104\n",
      "Epoch 00006: val_loss improved from 0.22594 to 0.21395, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/006-0.2140.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2836 - acc: 0.9104 - val_loss: 0.2140 - val_acc: 0.9357\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2518 - acc: 0.9220\n",
      "Epoch 00007: val_loss improved from 0.21395 to 0.18651, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/007-0.1865.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2518 - acc: 0.9220 - val_loss: 0.1865 - val_acc: 0.9471\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2160 - acc: 0.9322\n",
      "Epoch 00008: val_loss improved from 0.18651 to 0.18650, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/008-0.1865.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2161 - acc: 0.9322 - val_loss: 0.1865 - val_acc: 0.9471\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1963 - acc: 0.9389\n",
      "Epoch 00009: val_loss improved from 0.18650 to 0.18547, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/009-0.1855.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1963 - acc: 0.9389 - val_loss: 0.1855 - val_acc: 0.9432\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1807 - acc: 0.9440\n",
      "Epoch 00010: val_loss improved from 0.18547 to 0.16925, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/010-0.1692.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1807 - acc: 0.9440 - val_loss: 0.1692 - val_acc: 0.9518\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9503\n",
      "Epoch 00011: val_loss improved from 0.16925 to 0.16452, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/011-0.1645.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1589 - acc: 0.9503 - val_loss: 0.1645 - val_acc: 0.9525\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9546\n",
      "Epoch 00012: val_loss did not improve from 0.16452\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1441 - acc: 0.9546 - val_loss: 0.2194 - val_acc: 0.9324\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9576\n",
      "Epoch 00013: val_loss did not improve from 0.16452\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1320 - acc: 0.9576 - val_loss: 0.1682 - val_acc: 0.9483\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9598\n",
      "Epoch 00014: val_loss improved from 0.16452 to 0.14562, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/014-0.1456.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1261 - acc: 0.9598 - val_loss: 0.1456 - val_acc: 0.9576\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9642\n",
      "Epoch 00015: val_loss did not improve from 0.14562\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1136 - acc: 0.9642 - val_loss: 0.1735 - val_acc: 0.9455\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9655\n",
      "Epoch 00016: val_loss did not improve from 0.14562\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1097 - acc: 0.9655 - val_loss: 0.1515 - val_acc: 0.9557\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9651\n",
      "Epoch 00017: val_loss improved from 0.14562 to 0.13066, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/017-0.1307.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1106 - acc: 0.9651 - val_loss: 0.1307 - val_acc: 0.9613\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9721\n",
      "Epoch 00018: val_loss did not improve from 0.13066\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0864 - acc: 0.9722 - val_loss: 0.1327 - val_acc: 0.9606\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9744\n",
      "Epoch 00019: val_loss did not improve from 0.13066\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0799 - acc: 0.9744 - val_loss: 0.1602 - val_acc: 0.9543\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9733\n",
      "Epoch 00020: val_loss did not improve from 0.13066\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0830 - acc: 0.9733 - val_loss: 0.1758 - val_acc: 0.9483\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9762\n",
      "Epoch 00021: val_loss did not improve from 0.13066\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0756 - acc: 0.9762 - val_loss: 0.1426 - val_acc: 0.9574\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9787\n",
      "Epoch 00022: val_loss did not improve from 0.13066\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0679 - acc: 0.9787 - val_loss: 0.1585 - val_acc: 0.9525\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9792\n",
      "Epoch 00023: val_loss did not improve from 0.13066\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0645 - acc: 0.9792 - val_loss: 0.1329 - val_acc: 0.9602\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9815\n",
      "Epoch 00024: val_loss did not improve from 0.13066\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0589 - acc: 0.9815 - val_loss: 0.1325 - val_acc: 0.9585\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9800\n",
      "Epoch 00025: val_loss improved from 0.13066 to 0.12496, saving model to model/checkpoint/1D_CNN_9_conv_custom_DO_BN_checkpoint/025-0.1250.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0637 - acc: 0.9800 - val_loss: 0.1250 - val_acc: 0.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9845\n",
      "Epoch 00026: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0510 - acc: 0.9845 - val_loss: 0.1415 - val_acc: 0.9618\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9843\n",
      "Epoch 00027: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0499 - acc: 0.9843 - val_loss: 0.1334 - val_acc: 0.9606\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9864\n",
      "Epoch 00028: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0450 - acc: 0.9863 - val_loss: 0.1381 - val_acc: 0.9604\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9850\n",
      "Epoch 00029: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0477 - acc: 0.9850 - val_loss: 0.1473 - val_acc: 0.9590\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9857\n",
      "Epoch 00030: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0480 - acc: 0.9857 - val_loss: 0.1334 - val_acc: 0.9618\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9840\n",
      "Epoch 00031: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0499 - acc: 0.9840 - val_loss: 0.1454 - val_acc: 0.9623\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9892\n",
      "Epoch 00032: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0348 - acc: 0.9892 - val_loss: 0.1391 - val_acc: 0.9639\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9883\n",
      "Epoch 00033: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0366 - acc: 0.9883 - val_loss: 0.2359 - val_acc: 0.9387\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9888\n",
      "Epoch 00034: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0368 - acc: 0.9888 - val_loss: 0.1374 - val_acc: 0.9616\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9918\n",
      "Epoch 00035: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0284 - acc: 0.9918 - val_loss: 0.1498 - val_acc: 0.9590\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9864\n",
      "Epoch 00036: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0445 - acc: 0.9864 - val_loss: 0.1485 - val_acc: 0.9576\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9919\n",
      "Epoch 00037: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0266 - acc: 0.9919 - val_loss: 0.1275 - val_acc: 0.9634\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9931\n",
      "Epoch 00038: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0249 - acc: 0.9931 - val_loss: 0.1558 - val_acc: 0.9602\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9924\n",
      "Epoch 00039: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0256 - acc: 0.9924 - val_loss: 0.1743 - val_acc: 0.9571\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9919\n",
      "Epoch 00040: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0270 - acc: 0.9919 - val_loss: 0.1988 - val_acc: 0.9490\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9894\n",
      "Epoch 00041: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0364 - acc: 0.9894 - val_loss: 0.1477 - val_acc: 0.9620\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9923\n",
      "Epoch 00042: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0269 - acc: 0.9923 - val_loss: 0.1917 - val_acc: 0.9543\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9946\n",
      "Epoch 00043: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0189 - acc: 0.9946 - val_loss: 0.1699 - val_acc: 0.9609\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9937\n",
      "Epoch 00044: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0217 - acc: 0.9937 - val_loss: 0.1941 - val_acc: 0.9548\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9924\n",
      "Epoch 00045: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0244 - acc: 0.9924 - val_loss: 0.1557 - val_acc: 0.9620\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9955\n",
      "Epoch 00046: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0161 - acc: 0.9955 - val_loss: 0.1996 - val_acc: 0.9504\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9923\n",
      "Epoch 00047: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0238 - acc: 0.9923 - val_loss: 0.1384 - val_acc: 0.9630\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9931\n",
      "Epoch 00048: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0222 - acc: 0.9931 - val_loss: 0.1529 - val_acc: 0.9604\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9948\n",
      "Epoch 00049: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0181 - acc: 0.9948 - val_loss: 0.1693 - val_acc: 0.9618\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9947\n",
      "Epoch 00050: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0173 - acc: 0.9947 - val_loss: 0.1644 - val_acc: 0.9634\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9938\n",
      "Epoch 00051: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0195 - acc: 0.9938 - val_loss: 0.1767 - val_acc: 0.9595\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9934\n",
      "Epoch 00052: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0207 - acc: 0.9934 - val_loss: 0.1506 - val_acc: 0.9609\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9926\n",
      "Epoch 00053: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0243 - acc: 0.9926 - val_loss: 0.1449 - val_acc: 0.9630\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9967\n",
      "Epoch 00054: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0125 - acc: 0.9967 - val_loss: 0.1499 - val_acc: 0.9627\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9953\n",
      "Epoch 00055: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0154 - acc: 0.9953 - val_loss: 0.1539 - val_acc: 0.9658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9956\n",
      "Epoch 00056: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0162 - acc: 0.9956 - val_loss: 0.1676 - val_acc: 0.9620\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9947\n",
      "Epoch 00057: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0173 - acc: 0.9947 - val_loss: 0.2065 - val_acc: 0.9541\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9929\n",
      "Epoch 00058: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0225 - acc: 0.9929 - val_loss: 0.1499 - val_acc: 0.9632\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9957\n",
      "Epoch 00059: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0139 - acc: 0.9957 - val_loss: 0.1911 - val_acc: 0.9543\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9968\n",
      "Epoch 00060: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0114 - acc: 0.9968 - val_loss: 0.1568 - val_acc: 0.9648\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9962\n",
      "Epoch 00061: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0139 - acc: 0.9962 - val_loss: 0.1844 - val_acc: 0.9602\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9910\n",
      "Epoch 00062: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0302 - acc: 0.9910 - val_loss: 0.1599 - val_acc: 0.9595\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9961\n",
      "Epoch 00063: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0121 - acc: 0.9961 - val_loss: 0.1383 - val_acc: 0.9623\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9968\n",
      "Epoch 00064: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0115 - acc: 0.9968 - val_loss: 0.1834 - val_acc: 0.9555\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9977\n",
      "Epoch 00065: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0090 - acc: 0.9977 - val_loss: 0.1436 - val_acc: 0.9632\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9970\n",
      "Epoch 00066: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0107 - acc: 0.9970 - val_loss: 0.2622 - val_acc: 0.9502\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9905\n",
      "Epoch 00067: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0306 - acc: 0.9905 - val_loss: 0.1676 - val_acc: 0.9604\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9968\n",
      "Epoch 00068: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0113 - acc: 0.9968 - val_loss: 0.1482 - val_acc: 0.9630\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9972\n",
      "Epoch 00069: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0095 - acc: 0.9972 - val_loss: 0.1475 - val_acc: 0.9653\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9975\n",
      "Epoch 00070: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0086 - acc: 0.9975 - val_loss: 0.1792 - val_acc: 0.9599\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9952\n",
      "Epoch 00071: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0153 - acc: 0.9952 - val_loss: 0.1758 - val_acc: 0.9618\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9965\n",
      "Epoch 00072: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0108 - acc: 0.9965 - val_loss: 0.1395 - val_acc: 0.9637\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9959\n",
      "Epoch 00073: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0144 - acc: 0.9959 - val_loss: 0.1599 - val_acc: 0.9653\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 00074: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0106 - acc: 0.9968 - val_loss: 0.1849 - val_acc: 0.9571\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9940\n",
      "Epoch 00075: val_loss did not improve from 0.12496\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0190 - acc: 0.9940 - val_loss: 0.1316 - val_acc: 0.9697\n",
      "\n",
      "1D_CNN_9_conv_custom_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1864 - acc: 0.9470\n",
      "Loss: 0.18635888525042082 Accuracy: 0.9470405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model_name = '1D_CNN_custom_ch_128_DO_BN_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_ch_128_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_1_conv_custom_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 644us/sample - loss: 2.3072 - acc: 0.2771\n",
      "Loss: 2.3071924338335807 Accuracy: 0.27705088\n",
      "\n",
      "1D_CNN_2_conv_custom_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 941us/sample - loss: 2.6599 - acc: 0.3225\n",
      "Loss: 2.6599495181165875 Accuracy: 0.32253376\n",
      "\n",
      "1D_CNN_3_conv_custom_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.5859 - acc: 0.5691\n",
      "Loss: 1.5858958748394578 Accuracy: 0.569055\n",
      "\n",
      "1D_CNN_4_conv_custom_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.0541 - acc: 0.7173\n",
      "Loss: 1.0541436347387043 Accuracy: 0.71734166\n",
      "\n",
      "1D_CNN_5_conv_custom_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.7541 - acc: 0.7807\n",
      "Loss: 0.7540559037452175 Accuracy: 0.78068537\n",
      "\n",
      "1D_CNN_6_conv_custom_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4597 - acc: 0.8827\n",
      "Loss: 0.45965244111489906 Accuracy: 0.88265836\n",
      "\n",
      "1D_CNN_7_conv_custom_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2338 - acc: 0.9373\n",
      "Loss: 0.23377935187281848 Accuracy: 0.93727934\n",
      "\n",
      "1D_CNN_8_conv_custom_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1842 - acc: 0.9553\n",
      "Loss: 0.1841527407607383 Accuracy: 0.9553479\n",
      "\n",
      "1D_CNN_9_conv_custom_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1864 - acc: 0.9470\n",
      "Loss: 0.18635888525042082 Accuracy: 0.9470405\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model_name = '1D_CNN_custom_ch_128_DO_BN_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
