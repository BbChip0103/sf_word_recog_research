{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_ch_128_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=128, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=128*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 3,805,712\n",
      "Trainable params: 3,804,944\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,461,392\n",
      "Trainable params: 1,460,368\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 1,221,008\n",
      "Trainable params: 1,219,472\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 1,009,296\n",
      "Trainable params: 1,007,248\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 1,158,032\n",
      "Trainable params: 1,155,472\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,429,648\n",
      "Trainable params: 1,426,576\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 7, 512)            2048      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 2,075,280\n",
      "Trainable params: 2,071,184\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model = build_1d_cnn_custom_ch_128_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.9471 - acc: 0.3479\n",
      "Epoch 00001: val_loss improved from inf to 2.45734, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_3_conv_checkpoint/001-2.4573.hdf5\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 2.9472 - acc: 0.3479 - val_loss: 2.4573 - val_acc: 0.4230\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0840 - acc: 0.5232\n",
      "Epoch 00002: val_loss did not improve from 2.45734\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 2.0843 - acc: 0.5231 - val_loss: 2.5963 - val_acc: 0.4486\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7805 - acc: 0.6082\n",
      "Epoch 00003: val_loss improved from 2.45734 to 2.18789, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_3_conv_checkpoint/003-2.1879.hdf5\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 1.7803 - acc: 0.6083 - val_loss: 2.1879 - val_acc: 0.5267\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5520 - acc: 0.6710\n",
      "Epoch 00004: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 1.5520 - acc: 0.6710 - val_loss: 2.1951 - val_acc: 0.5425\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3396 - acc: 0.7272\n",
      "Epoch 00005: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 1.3396 - acc: 0.7272 - val_loss: 2.3900 - val_acc: 0.5302\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1987 - acc: 0.7682\n",
      "Epoch 00006: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 1.1986 - acc: 0.7681 - val_loss: 2.3352 - val_acc: 0.5565\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1163 - acc: 0.7932\n",
      "Epoch 00007: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 1.1166 - acc: 0.7932 - val_loss: 2.6426 - val_acc: 0.5181\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0345 - acc: 0.8183\n",
      "Epoch 00008: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 1.0344 - acc: 0.8183 - val_loss: 2.3899 - val_acc: 0.5672\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9626 - acc: 0.8405\n",
      "Epoch 00009: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.9625 - acc: 0.8406 - val_loss: 2.5151 - val_acc: 0.5726\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9480 - acc: 0.8474\n",
      "Epoch 00010: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.9479 - acc: 0.8474 - val_loss: 2.4675 - val_acc: 0.5807\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8780 - acc: 0.8666\n",
      "Epoch 00011: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.8779 - acc: 0.8666 - val_loss: 2.8523 - val_acc: 0.5537\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8469 - acc: 0.8787\n",
      "Epoch 00012: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.8468 - acc: 0.8787 - val_loss: 2.3730 - val_acc: 0.6108\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8454 - acc: 0.8802\n",
      "Epoch 00013: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.8453 - acc: 0.8802 - val_loss: 2.7548 - val_acc: 0.5649\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8172 - acc: 0.8899\n",
      "Epoch 00014: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.8172 - acc: 0.8898 - val_loss: 2.9764 - val_acc: 0.5558\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8020 - acc: 0.8942\n",
      "Epoch 00015: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.8020 - acc: 0.8942 - val_loss: 2.8361 - val_acc: 0.5791\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7744 - acc: 0.9038\n",
      "Epoch 00016: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.7748 - acc: 0.9037 - val_loss: 2.6489 - val_acc: 0.5963\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7727 - acc: 0.9059\n",
      "Epoch 00017: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.7731 - acc: 0.9059 - val_loss: 2.7008 - val_acc: 0.5986\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7771 - acc: 0.9038\n",
      "Epoch 00018: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.7774 - acc: 0.9038 - val_loss: 2.7009 - val_acc: 0.6089\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7579 - acc: 0.9102\n",
      "Epoch 00019: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.7579 - acc: 0.9103 - val_loss: 2.8044 - val_acc: 0.5989\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7358 - acc: 0.9166\n",
      "Epoch 00020: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.7358 - acc: 0.9166 - val_loss: 2.9042 - val_acc: 0.5947\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7406 - acc: 0.9158\n",
      "Epoch 00021: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.7406 - acc: 0.9157 - val_loss: 2.8125 - val_acc: 0.6084\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7419 - acc: 0.9154\n",
      "Epoch 00022: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.7419 - acc: 0.9153 - val_loss: 2.9545 - val_acc: 0.5949\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7283 - acc: 0.9204\n",
      "Epoch 00023: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.7286 - acc: 0.9203 - val_loss: 2.8568 - val_acc: 0.6068\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7197 - acc: 0.9226\n",
      "Epoch 00024: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.7197 - acc: 0.9226 - val_loss: 3.5204 - val_acc: 0.5590\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7352 - acc: 0.9202\n",
      "Epoch 00025: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.7351 - acc: 0.9203 - val_loss: 2.8261 - val_acc: 0.6124\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6990 - acc: 0.9300\n",
      "Epoch 00026: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6989 - acc: 0.9300 - val_loss: 2.8518 - val_acc: 0.6254\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6936 - acc: 0.9306\n",
      "Epoch 00027: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.6940 - acc: 0.9306 - val_loss: 3.1895 - val_acc: 0.5947\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6967 - acc: 0.9310\n",
      "Epoch 00028: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6966 - acc: 0.9310 - val_loss: 3.0920 - val_acc: 0.5933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6897 - acc: 0.9324\n",
      "Epoch 00029: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6897 - acc: 0.9324 - val_loss: 2.8556 - val_acc: 0.6245\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6954 - acc: 0.9311\n",
      "Epoch 00030: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6958 - acc: 0.9310 - val_loss: 2.9910 - val_acc: 0.6152\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6891 - acc: 0.9325\n",
      "Epoch 00031: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6891 - acc: 0.9325 - val_loss: 3.0555 - val_acc: 0.6164\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6965 - acc: 0.9307\n",
      "Epoch 00032: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6968 - acc: 0.9307 - val_loss: 3.0375 - val_acc: 0.6077\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6733 - acc: 0.9368\n",
      "Epoch 00033: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6732 - acc: 0.9367 - val_loss: 2.9627 - val_acc: 0.6103\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6766 - acc: 0.9361\n",
      "Epoch 00034: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6768 - acc: 0.9360 - val_loss: 2.8923 - val_acc: 0.6194\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6820 - acc: 0.9361\n",
      "Epoch 00035: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6819 - acc: 0.9361 - val_loss: 2.9711 - val_acc: 0.6166\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6623 - acc: 0.9408\n",
      "Epoch 00036: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6622 - acc: 0.9408 - val_loss: 3.1000 - val_acc: 0.6182\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6763 - acc: 0.9374\n",
      "Epoch 00037: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.6763 - acc: 0.9374 - val_loss: 3.0006 - val_acc: 0.6117\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6745 - acc: 0.9382\n",
      "Epoch 00038: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.6744 - acc: 0.9382 - val_loss: 2.9941 - val_acc: 0.6306\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6700 - acc: 0.9379\n",
      "Epoch 00039: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6699 - acc: 0.9379 - val_loss: 3.2645 - val_acc: 0.6096\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6509 - acc: 0.9448\n",
      "Epoch 00040: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6509 - acc: 0.9447 - val_loss: 3.0757 - val_acc: 0.6147\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6704 - acc: 0.9393\n",
      "Epoch 00041: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.6703 - acc: 0.9393 - val_loss: 3.0696 - val_acc: 0.6324\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6598 - acc: 0.9427\n",
      "Epoch 00042: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6597 - acc: 0.9427 - val_loss: 3.1817 - val_acc: 0.6124\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6524 - acc: 0.9445\n",
      "Epoch 00043: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.6528 - acc: 0.9445 - val_loss: 3.1436 - val_acc: 0.6122\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5367 - acc: 0.9438\n",
      "Epoch 00044: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.5366 - acc: 0.9438 - val_loss: 2.7895 - val_acc: 0.6049\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1800 - acc: 0.9560\n",
      "Epoch 00045: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.1800 - acc: 0.9560 - val_loss: 2.5422 - val_acc: 0.6136\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9701\n",
      "Epoch 00046: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.1122 - acc: 0.9701 - val_loss: 2.5149 - val_acc: 0.6201\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9760\n",
      "Epoch 00047: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0894 - acc: 0.9760 - val_loss: 2.2895 - val_acc: 0.6655\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9797\n",
      "Epoch 00048: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0765 - acc: 0.9797 - val_loss: 2.4929 - val_acc: 0.6436\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9804\n",
      "Epoch 00049: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0730 - acc: 0.9804 - val_loss: 2.4299 - val_acc: 0.6406\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9785\n",
      "Epoch 00050: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0779 - acc: 0.9785 - val_loss: 2.7954 - val_acc: 0.6217\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9813\n",
      "Epoch 00051: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0704 - acc: 0.9813 - val_loss: 2.5544 - val_acc: 0.6357\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9830\n",
      "Epoch 00052: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0625 - acc: 0.9830 - val_loss: 2.4287 - val_acc: 0.6578\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9820\n",
      "Epoch 00053: val_loss did not improve from 2.18789\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 0.0680 - acc: 0.9820 - val_loss: 2.7336 - val_acc: 0.6236\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 2.3083 - acc: 0.4793\n",
      "Loss: 2.308270645488212 Accuracy: 0.4793354\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1245 - acc: 0.3927\n",
      "Epoch 00001: val_loss improved from inf to 1.40104, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_4_conv_checkpoint/001-1.4010.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 2.1244 - acc: 0.3927 - val_loss: 1.4010 - val_acc: 0.5791\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4225 - acc: 0.5751\n",
      "Epoch 00002: val_loss improved from 1.40104 to 1.24511, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_4_conv_checkpoint/002-1.2451.hdf5\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 1.4226 - acc: 0.5750 - val_loss: 1.2451 - val_acc: 0.6173\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1731 - acc: 0.6508\n",
      "Epoch 00003: val_loss improved from 1.24511 to 1.07850, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_4_conv_checkpoint/003-1.0785.hdf5\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 1.1730 - acc: 0.6508 - val_loss: 1.0785 - val_acc: 0.6695\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0156 - acc: 0.6946\n",
      "Epoch 00004: val_loss improved from 1.07850 to 1.03576, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_4_conv_checkpoint/004-1.0358.hdf5\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 1.0156 - acc: 0.6946 - val_loss: 1.0358 - val_acc: 0.6974\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8755 - acc: 0.7315\n",
      "Epoch 00005: val_loss improved from 1.03576 to 0.93700, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_4_conv_checkpoint/005-0.9370.hdf5\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.8755 - acc: 0.7315 - val_loss: 0.9370 - val_acc: 0.7282\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7760 - acc: 0.7630\n",
      "Epoch 00006: val_loss did not improve from 0.93700\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.7762 - acc: 0.7629 - val_loss: 1.0292 - val_acc: 0.7165\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7052 - acc: 0.7842\n",
      "Epoch 00007: val_loss improved from 0.93700 to 0.91374, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_4_conv_checkpoint/007-0.9137.hdf5\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.7052 - acc: 0.7842 - val_loss: 0.9137 - val_acc: 0.7386\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6281 - acc: 0.8054\n",
      "Epoch 00008: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.6281 - acc: 0.8054 - val_loss: 0.9650 - val_acc: 0.7438\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5624 - acc: 0.8217\n",
      "Epoch 00009: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.5624 - acc: 0.8217 - val_loss: 0.9750 - val_acc: 0.7342\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5092 - acc: 0.8373\n",
      "Epoch 00010: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.5092 - acc: 0.8373 - val_loss: 0.9363 - val_acc: 0.7545\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4364 - acc: 0.8606\n",
      "Epoch 00011: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.4364 - acc: 0.8606 - val_loss: 0.9654 - val_acc: 0.7470\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4058 - acc: 0.8707\n",
      "Epoch 00012: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.4058 - acc: 0.8707 - val_loss: 1.0645 - val_acc: 0.7272\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3827 - acc: 0.8771\n",
      "Epoch 00013: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.3828 - acc: 0.8771 - val_loss: 1.0634 - val_acc: 0.7303\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3486 - acc: 0.8864\n",
      "Epoch 00014: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.3486 - acc: 0.8863 - val_loss: 1.0326 - val_acc: 0.7375\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3164 - acc: 0.8986\n",
      "Epoch 00015: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.3163 - acc: 0.8986 - val_loss: 1.0816 - val_acc: 0.7452\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2844 - acc: 0.9070\n",
      "Epoch 00016: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2845 - acc: 0.9070 - val_loss: 1.1239 - val_acc: 0.7345\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2747 - acc: 0.9110\n",
      "Epoch 00017: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2747 - acc: 0.9110 - val_loss: 0.9536 - val_acc: 0.7713\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2592 - acc: 0.9159\n",
      "Epoch 00018: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2593 - acc: 0.9159 - val_loss: 1.1916 - val_acc: 0.7286\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2461 - acc: 0.9221\n",
      "Epoch 00019: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2461 - acc: 0.9221 - val_loss: 1.1410 - val_acc: 0.7449\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2236 - acc: 0.9273\n",
      "Epoch 00020: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2236 - acc: 0.9272 - val_loss: 0.9822 - val_acc: 0.7720\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2082 - acc: 0.9320\n",
      "Epoch 00021: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2084 - acc: 0.9319 - val_loss: 1.0899 - val_acc: 0.7494\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2058 - acc: 0.9330\n",
      "Epoch 00022: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2064 - acc: 0.9329 - val_loss: 1.0879 - val_acc: 0.7570\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1954 - acc: 0.9383\n",
      "Epoch 00023: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1955 - acc: 0.9383 - val_loss: 1.1095 - val_acc: 0.7510\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9415\n",
      "Epoch 00024: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1780 - acc: 0.9415 - val_loss: 1.1738 - val_acc: 0.7480\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9450\n",
      "Epoch 00025: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1729 - acc: 0.9450 - val_loss: 1.1143 - val_acc: 0.7622\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9472\n",
      "Epoch 00026: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1656 - acc: 0.9472 - val_loss: 1.1969 - val_acc: 0.7473\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1564 - acc: 0.9510\n",
      "Epoch 00027: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1564 - acc: 0.9509 - val_loss: 1.0318 - val_acc: 0.7794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1477 - acc: 0.9520\n",
      "Epoch 00028: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1478 - acc: 0.9520 - val_loss: 1.0868 - val_acc: 0.7706\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9499\n",
      "Epoch 00029: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1569 - acc: 0.9498 - val_loss: 1.2454 - val_acc: 0.7426\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9508\n",
      "Epoch 00030: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.1521 - acc: 0.9508 - val_loss: 1.1187 - val_acc: 0.7636\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9569\n",
      "Epoch 00031: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1362 - acc: 0.9569 - val_loss: 1.0767 - val_acc: 0.7803\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9571\n",
      "Epoch 00032: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1340 - acc: 0.9570 - val_loss: 1.1330 - val_acc: 0.7736\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9612\n",
      "Epoch 00033: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1245 - acc: 0.9612 - val_loss: 1.1207 - val_acc: 0.7747\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9605\n",
      "Epoch 00034: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1241 - acc: 0.9605 - val_loss: 1.1383 - val_acc: 0.7745\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9631\n",
      "Epoch 00035: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1198 - acc: 0.9631 - val_loss: 1.0987 - val_acc: 0.7766\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9637\n",
      "Epoch 00036: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1160 - acc: 0.9636 - val_loss: 1.1258 - val_acc: 0.7775\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9654\n",
      "Epoch 00037: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1146 - acc: 0.9654 - val_loss: 1.2040 - val_acc: 0.7680\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9674\n",
      "Epoch 00038: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1100 - acc: 0.9674 - val_loss: 1.1523 - val_acc: 0.7820\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9680\n",
      "Epoch 00039: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1061 - acc: 0.9680 - val_loss: 1.0848 - val_acc: 0.7757\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9672\n",
      "Epoch 00040: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1066 - acc: 0.9672 - val_loss: 1.1448 - val_acc: 0.7778\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9671\n",
      "Epoch 00041: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1061 - acc: 0.9671 - val_loss: 1.2162 - val_acc: 0.7633\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9708\n",
      "Epoch 00042: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0953 - acc: 0.9707 - val_loss: 1.1843 - val_acc: 0.7694\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9688\n",
      "Epoch 00043: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1016 - acc: 0.9688 - val_loss: 1.2776 - val_acc: 0.7680\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9710\n",
      "Epoch 00044: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0951 - acc: 0.9710 - val_loss: 1.2388 - val_acc: 0.7701\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9733\n",
      "Epoch 00045: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0895 - acc: 0.9733 - val_loss: 1.3221 - val_acc: 0.7556\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9713\n",
      "Epoch 00046: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0967 - acc: 0.9713 - val_loss: 1.1409 - val_acc: 0.7873\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9735\n",
      "Epoch 00047: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0884 - acc: 0.9735 - val_loss: 1.1898 - val_acc: 0.7810\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9744\n",
      "Epoch 00048: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0834 - acc: 0.9744 - val_loss: 1.3283 - val_acc: 0.7598\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9755\n",
      "Epoch 00049: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0848 - acc: 0.9754 - val_loss: 1.2768 - val_acc: 0.7647\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9761\n",
      "Epoch 00050: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0829 - acc: 0.9761 - val_loss: 1.2042 - val_acc: 0.7706\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9742\n",
      "Epoch 00051: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0875 - acc: 0.9742 - val_loss: 1.2794 - val_acc: 0.7636\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9784\n",
      "Epoch 00052: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0723 - acc: 0.9783 - val_loss: 1.2394 - val_acc: 0.7824\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9745\n",
      "Epoch 00053: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0905 - acc: 0.9745 - val_loss: 1.1906 - val_acc: 0.7827\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9792\n",
      "Epoch 00054: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0695 - acc: 0.9792 - val_loss: 1.2260 - val_acc: 0.7838\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9769\n",
      "Epoch 00055: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0790 - acc: 0.9769 - val_loss: 1.2711 - val_acc: 0.7699\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9779\n",
      "Epoch 00056: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.0744 - acc: 0.9779 - val_loss: 1.2717 - val_acc: 0.7782\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9765\n",
      "Epoch 00057: val_loss did not improve from 0.91374\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0799 - acc: 0.9765 - val_loss: 1.1898 - val_acc: 0.7822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 1.0380 - acc: 0.6993\n",
      "Loss: 1.037950282366724 Accuracy: 0.6992731\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9655 - acc: 0.4276\n",
      "Epoch 00001: val_loss improved from inf to 1.15920, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_5_conv_checkpoint/001-1.1592.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 1.9654 - acc: 0.4276 - val_loss: 1.1592 - val_acc: 0.6546\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2432 - acc: 0.6240\n",
      "Epoch 00002: val_loss improved from 1.15920 to 0.97649, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_5_conv_checkpoint/002-0.9765.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 1.2433 - acc: 0.6240 - val_loss: 0.9765 - val_acc: 0.6958\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0251 - acc: 0.6909\n",
      "Epoch 00003: val_loss improved from 0.97649 to 0.94422, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_5_conv_checkpoint/003-0.9442.hdf5\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 1.0255 - acc: 0.6908 - val_loss: 0.9442 - val_acc: 0.7209\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9059 - acc: 0.7268\n",
      "Epoch 00004: val_loss improved from 0.94422 to 0.86630, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_5_conv_checkpoint/004-0.8663.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.9059 - acc: 0.7267 - val_loss: 0.8663 - val_acc: 0.7466\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8124 - acc: 0.7571\n",
      "Epoch 00005: val_loss improved from 0.86630 to 0.82652, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_5_conv_checkpoint/005-0.8265.hdf5\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.8124 - acc: 0.7571 - val_loss: 0.8265 - val_acc: 0.7598\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7373 - acc: 0.7762\n",
      "Epoch 00006: val_loss improved from 0.82652 to 0.78857, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_5_conv_checkpoint/006-0.7886.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.7372 - acc: 0.7762 - val_loss: 0.7886 - val_acc: 0.7738\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6620 - acc: 0.8010\n",
      "Epoch 00007: val_loss improved from 0.78857 to 0.71034, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_5_conv_checkpoint/007-0.7103.hdf5\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.6620 - acc: 0.8009 - val_loss: 0.7103 - val_acc: 0.7973\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6034 - acc: 0.8144\n",
      "Epoch 00008: val_loss did not improve from 0.71034\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.6035 - acc: 0.8144 - val_loss: 0.7330 - val_acc: 0.7973\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5589 - acc: 0.8301\n",
      "Epoch 00009: val_loss improved from 0.71034 to 0.69123, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_5_conv_checkpoint/009-0.6912.hdf5\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.5589 - acc: 0.8302 - val_loss: 0.6912 - val_acc: 0.8018\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5241 - acc: 0.8390\n",
      "Epoch 00010: val_loss did not improve from 0.69123\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.5244 - acc: 0.8389 - val_loss: 0.7519 - val_acc: 0.7887\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4830 - acc: 0.8500\n",
      "Epoch 00011: val_loss improved from 0.69123 to 0.68642, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_5_conv_checkpoint/011-0.6864.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.4830 - acc: 0.8499 - val_loss: 0.6864 - val_acc: 0.8078\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4416 - acc: 0.8618\n",
      "Epoch 00012: val_loss improved from 0.68642 to 0.66920, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_5_conv_checkpoint/012-0.6692.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.4416 - acc: 0.8618 - val_loss: 0.6692 - val_acc: 0.8206\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4143 - acc: 0.8690\n",
      "Epoch 00013: val_loss improved from 0.66920 to 0.64792, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_5_conv_checkpoint/013-0.6479.hdf5\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.4143 - acc: 0.8690 - val_loss: 0.6479 - val_acc: 0.8272\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3850 - acc: 0.8776\n",
      "Epoch 00014: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.3853 - acc: 0.8775 - val_loss: 0.6661 - val_acc: 0.8141\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3568 - acc: 0.8880\n",
      "Epoch 00015: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.3568 - acc: 0.8880 - val_loss: 0.7093 - val_acc: 0.8160\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3279 - acc: 0.8954\n",
      "Epoch 00016: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.3282 - acc: 0.8954 - val_loss: 0.6968 - val_acc: 0.8171\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3104 - acc: 0.9021\n",
      "Epoch 00017: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.3107 - acc: 0.9020 - val_loss: 0.7469 - val_acc: 0.8116\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2897 - acc: 0.9060\n",
      "Epoch 00018: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2896 - acc: 0.9060 - val_loss: 0.7485 - val_acc: 0.8088\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2633 - acc: 0.9147\n",
      "Epoch 00019: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.2636 - acc: 0.9146 - val_loss: 0.8179 - val_acc: 0.7948\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2635 - acc: 0.9155\n",
      "Epoch 00020: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2636 - acc: 0.9154 - val_loss: 0.8269 - val_acc: 0.8036\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2395 - acc: 0.9229\n",
      "Epoch 00021: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.2395 - acc: 0.9228 - val_loss: 0.7014 - val_acc: 0.8223\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2291 - acc: 0.9263\n",
      "Epoch 00022: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2291 - acc: 0.9263 - val_loss: 0.8783 - val_acc: 0.7908\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9277\n",
      "Epoch 00023: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.2231 - acc: 0.9277 - val_loss: 0.7258 - val_acc: 0.8237\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2012 - acc: 0.9339\n",
      "Epoch 00024: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2012 - acc: 0.9339 - val_loss: 0.7683 - val_acc: 0.8104\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1895 - acc: 0.9390\n",
      "Epoch 00025: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1895 - acc: 0.9391 - val_loss: 0.7346 - val_acc: 0.8276\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1856 - acc: 0.9393\n",
      "Epoch 00026: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.1858 - acc: 0.9393 - val_loss: 0.6903 - val_acc: 0.8402\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9411\n",
      "Epoch 00027: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1780 - acc: 0.9410 - val_loss: 0.9311 - val_acc: 0.7897\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1814 - acc: 0.9411\n",
      "Epoch 00028: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1814 - acc: 0.9411 - val_loss: 0.7098 - val_acc: 0.8316\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9500\n",
      "Epoch 00029: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1536 - acc: 0.9500 - val_loss: 0.7578 - val_acc: 0.8314\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9454\n",
      "Epoch 00030: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.1653 - acc: 0.9454 - val_loss: 0.7296 - val_acc: 0.8369\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9535\n",
      "Epoch 00031: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1425 - acc: 0.9534 - val_loss: 0.7036 - val_acc: 0.8367\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1443 - acc: 0.9537\n",
      "Epoch 00032: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.1445 - acc: 0.9536 - val_loss: 0.7180 - val_acc: 0.8393\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1418 - acc: 0.9543\n",
      "Epoch 00033: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1417 - acc: 0.9543 - val_loss: 0.7474 - val_acc: 0.8362\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9610\n",
      "Epoch 00034: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.1213 - acc: 0.9610 - val_loss: 0.7575 - val_acc: 0.8288\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9563\n",
      "Epoch 00035: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1321 - acc: 0.9563 - val_loss: 0.7890 - val_acc: 0.8318\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9604\n",
      "Epoch 00036: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1252 - acc: 0.9604 - val_loss: 0.7027 - val_acc: 0.8402\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9602\n",
      "Epoch 00037: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1216 - acc: 0.9601 - val_loss: 0.7413 - val_acc: 0.8446\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9615\n",
      "Epoch 00038: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.1210 - acc: 0.9615 - val_loss: 0.7370 - val_acc: 0.8374\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9599\n",
      "Epoch 00039: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1260 - acc: 0.9599 - val_loss: 0.8141 - val_acc: 0.8293\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9639\n",
      "Epoch 00040: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.1154 - acc: 0.9639 - val_loss: 0.7899 - val_acc: 0.8414\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9646\n",
      "Epoch 00041: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1125 - acc: 0.9645 - val_loss: 0.9354 - val_acc: 0.8013\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9655\n",
      "Epoch 00042: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.1123 - acc: 0.9655 - val_loss: 0.7440 - val_acc: 0.8425\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9675\n",
      "Epoch 00043: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1030 - acc: 0.9675 - val_loss: 0.7705 - val_acc: 0.8397\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9711\n",
      "Epoch 00044: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0902 - acc: 0.9711 - val_loss: 0.7338 - val_acc: 0.8516\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9678\n",
      "Epoch 00045: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0995 - acc: 0.9678 - val_loss: 0.8471 - val_acc: 0.8234\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9733\n",
      "Epoch 00046: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0875 - acc: 0.9733 - val_loss: 1.0759 - val_acc: 0.7883\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9674\n",
      "Epoch 00047: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1045 - acc: 0.9674 - val_loss: 0.8172 - val_acc: 0.8348\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9720\n",
      "Epoch 00048: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0899 - acc: 0.9720 - val_loss: 0.7560 - val_acc: 0.8453\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9728\n",
      "Epoch 00049: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0876 - acc: 0.9728 - val_loss: 1.0720 - val_acc: 0.7862\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9757\n",
      "Epoch 00050: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0789 - acc: 0.9757 - val_loss: 0.9189 - val_acc: 0.8253\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9745\n",
      "Epoch 00051: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0815 - acc: 0.9745 - val_loss: 0.7580 - val_acc: 0.8512\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9732\n",
      "Epoch 00052: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0829 - acc: 0.9732 - val_loss: 0.7292 - val_acc: 0.8474\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9745\n",
      "Epoch 00053: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0784 - acc: 0.9745 - val_loss: 0.7521 - val_acc: 0.8481\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9737\n",
      "Epoch 00054: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0852 - acc: 0.9737 - val_loss: 0.7872 - val_acc: 0.8439\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9776\n",
      "Epoch 00055: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0725 - acc: 0.9776 - val_loss: 0.7369 - val_acc: 0.8514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9773\n",
      "Epoch 00056: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0725 - acc: 0.9773 - val_loss: 0.7958 - val_acc: 0.8442\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9776\n",
      "Epoch 00057: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0734 - acc: 0.9776 - val_loss: 0.7434 - val_acc: 0.8502\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9758\n",
      "Epoch 00058: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0781 - acc: 0.9758 - val_loss: 0.8579 - val_acc: 0.8316\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9777\n",
      "Epoch 00059: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0712 - acc: 0.9776 - val_loss: 0.7877 - val_acc: 0.8479\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9760\n",
      "Epoch 00060: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0779 - acc: 0.9759 - val_loss: 0.8479 - val_acc: 0.8334\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9793\n",
      "Epoch 00061: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0676 - acc: 0.9793 - val_loss: 0.8763 - val_acc: 0.8293\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9793\n",
      "Epoch 00062: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0684 - acc: 0.9792 - val_loss: 0.8552 - val_acc: 0.8402\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9797\n",
      "Epoch 00063: val_loss did not improve from 0.64792\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0663 - acc: 0.9796 - val_loss: 0.8008 - val_acc: 0.8481\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd8lEX+x9+zSUhvJBAggKFJCZ1QFAUERRDBgoqcWE4Fu8dP5Q7LKYpn987DemADGyhgBUVQYlBBCT30DgkhBUhISN3d7++PySabZNOzJMC8X6/ntdnnmWfm++xu5jPznZnvKBHBYDAYDIaqsDS0AQaDwWA4MzCCYTAYDIZqYQTDYDAYDNXCCIbBYDAYqoURDIPBYDBUCyMYBoPBYKgWRjAMBoPBUC2MYBgMBoOhWhjBMBgMBkO18GxoA+qT8PBwiYqKamgzDAaD4Yxh3bp16SLSrDppzyrBiIqKIj4+vqHNMBgMhjMGpdTB6qY1LimDwWAwVAu3CYZSqo1SaqVSaptSaqtS6m8u0iil1Cyl1B6l1GalVF+na7cqpXYXHbe6y06DwWAwVA93uqSswMMisl4pFQisU0otF5FtTmlGA52KjoHA28BApVRT4CkgBpCie78RkRNutNdgMBgMleA2wRCRZCC56O8spdR2IBJwFoyrgHmiY6yvUUqFKKVaAsOA5SJyHEAptRwYBXxWUzsKCwtJTEwkLy+vTs9zruLj40Pr1q3x8vJqaFMMBkMDc1oGvZVSUUAf4I8ylyKBw07vE4vOVXS+xiQmJhIYGEhUVBRKqdpkcc4iIhw7dozExETatWvX0OYYDIYGxu2D3kqpAGARMFVETroh/ylKqXilVHxaWlq563l5eYSFhRmxqAVKKcLCwkzvzGAwAG4WDKWUF1osPhGRxS6SJAFtnN63LjpX0flyiMhsEYkRkZhmzVxPJTZiUXvMZ2cwGBy4c5aUAt4DtovIvytI9g1wS9FsqUFAZtHYxzJgpFIqVCkVCowsOlfviAj5+UewWjPdkb3BYDCcNbizhzEYuBkYrpTaWHRcoZS6Wyl1d1GapcA+YA8wB7gXoGiweyawtuh4xjEAXt8opSgoOIrVWu/eMgAyMjJ46623anXvFVdcQUZGRrXTz5gxg1deeaVWZRkMBkNVuHOW1K9Apf6MotlR91Vw7X3gfTeYVg6lPBGxuiVvh2Dce++95a5ZrVY8PSv+CpYuXeoWmwwGg6E2mJXegFIeiNjckvf06dPZu3cvvXv3Ztq0acTGxnLxxRczbtw4unXrBsDVV19Nv379iI6OZvbs2cX3RkVFkZ6ezoEDB+jatSuTJ08mOjqakSNHkpubW2m5GzduZNCgQfTs2ZNrrrmGEyf0EpZZs2bRrVs3evbsyY033gjAL7/8Qu/evenduzd9+vQhKyvLLZ+FwWA4szmrYklVxe7dU8nO3ljuvN2eA4DF4lfjPAMCetOp02sVXn/hhRdISEhg40ZdbmxsLOvXrychIaF4qur7779P06ZNyc3NpX///owfP56wsLAytu/ms88+Y86cOdxwww0sWrSISZMmVVjuLbfcwuuvv87QoUN58sknefrpp3nttdd44YUX2L9/P97e3sXurldeeYU333yTwYMHk52djY+PT40/B4PBcPZjehiA9pzJaSttwIABpdY1zJo1i169ejFo0CAOHz7M7t27y93Trl07evfuDUC/fv04cOBAhflnZmaSkZHB0KFDAbj11luJi4sDoGfPntx00018/PHHxe6wwYMH89BDDzFr1iwyMjIqdZMZDIZzl3OqZqioJ5CbewCb7SQBAT1Pix3+/v7Ff8fGxrJixQpWr16Nn58fw4YNc7nuwdvbu/hvDw+PKl1SFbFkyRLi4uL49ttv+de//sWWLVuYPn06Y8aMYenSpQwePJhly5bRpUuXWuVvMBjOXkwPA8cYhnsGvQMDAysdE8jMzCQ0NBQ/Pz927NjBmjVr6lxmcHAwoaGhrFq1CoCPPvqIoUOHYrfbOXz4MJdccgkvvvgimZmZZGdns3fvXnr06ME//vEP+vfvz44dO+psg8FgOPs4p3oYFaGUB2BHxI5S9auhYWFhDB48mO7duzN69GjGjBlT6vqoUaN455136Nq1K507d2bQoEH1Uu7cuXO5++67ycnJoX379nzwwQfYbDYmTZpEZmYmIsKDDz5ISEgI//znP1m5ciUWi4Xo6GhGjx5dLzYYDIazC6Vntp4dxMTESNkNlLZv307Xrl0rva+gIJX8/EP4+/fCYjFB9spSnc/QYDCcmSil1olITHXSGpcUjh4GbptaazAYDGcDRjAoEQy9hYfBYDAYXGEEA3AM5ZgehsFgMFSMEQyMS8pgMBiqgxEMnAXDuKQMBoOhIoxgoIMPgulhGAwGQ2UYwYCitReq0QhGQEBAjc4bDAbD6cAIRhG6l2FcUgaDwVARRjCKcFeI8+nTp/Pmm28Wv3dscpSdnc2IESPo27cvPXr04Ouvv652niLCtGnT6N69Oz169GDBggUAJCcnM2TIEHr37k337t1ZtWoVNpuN2267rTjtf/7zn3p/RoPBcG5wboUGmToVNpYPbw7gY8vRQWtrGuK8d294reLw5hMmTGDq1Kncd5/eJ+rzzz9n2bJl+Pj48OWXXxIUFER6ejqDBg1i3Lhx1dpDe/HixWzcuJFNmzaRnp5O//79GTJkCJ9++imXX345jz/+ODabjZycHDZu3EhSUhIJCQkANdrBz2AwGJxxm2Aopd4HrgRSRaS7i+vTgJuc7OgKNBOR40qpA0AWYAOs1V22XkeDwQ1hUvr06UNqaipHjhwhLS2N0NBQ2rRpQ2FhIY899hhxcXFYLBaSkpJISUmhRYsWVeb566+/MnHiRDw8PIiIiGDo0KGsXbuW/v37c/vtt1NYWMjVV19N7969ad++Pfv27eOBBx5gzJgxjBw5st6f0WAwnBu4s4fxIfAGMM/VRRF5GXgZQCk1Fvi/Mvt2XyIi6fVqUSU9gYLcfdhspwgI6FGvRQJcf/31LFy4kKNHjzJhwgQAPvnkE9LS0li3bh1eXl5ERUW5DGteE4YMGUJcXBxLlizhtttu46GHHuKWW25h06ZNLFu2jHfeeYfPP/+c998/LTvfGgyGswy3jWGISBxwvMqEmonAZ+6ypTq4c1/vCRMmMH/+fBYuXMj1118P6LDmzZs3x8vLi5UrV3Lw4MFq53fxxRezYMECbDYbaWlpxMXFMWDAAA4ePEhERASTJ0/mzjvvZP369aSnp2O32xk/fjzPPvss69evd8szGgyGs58GH8NQSvkBo4D7nU4L8KNSSoD/ichslzfXqx0egA0RqdY4Qk2Ijo4mKyuLyMhIWrZsCcBNN93E2LFj6dGjBzExMTXasOiaa65h9erV9OrVC6UUL730Ei1atGDu3Lm8/PLLeHl5ERAQwLx580hKSuKvf/0rdrsdgOeff75en81gMJw7uDW8uVIqCvjO1RiGU5oJwCQRGet0LlJEkpRSzYHlwANFPRZX908BpgC0bdu2X9mWenVDcxcUpJCffxh//95YLA2uo40KE97cYDh7OdPCm99IGXeUiCQVvaYCXwIDKrpZRGaLSIyIxDRr1qwOZjgi1jaOxXsGg8HQ2GhQwVBKBQNDga+dzvkrpQIdfwMjgQT322ICEBoMBkNluHNa7WfAMCBcKZUIPAV4AYjIO0XJrgF+FJFTTrdGAF8WjSN4Ap+KyA/usrPEXkc8KbPa22AwGFzhNsEQkYnVSPMhevqt87l9QC/3WFUxpodhMBgMldMYxjAaBSbEucFgMFSOEYwiTIhzg8FgqBwjGMU4Por6FYyMjAzeeuutWt17xRVXmNhPBoOh0WAEowg9yF7/q70rEwyrtfKyli5dSkhISL3aYzAYDLXFCIYT7ghxPn36dPbu3Uvv3r2ZNm0asbGxXHzxxYwbN45u3boBcPXVV9OvXz+io6OZPbtkUXtUVBTp6ekcOHCArl27MnnyZKKjoxk5ciS5ubnlyvr2228ZOHAgffr04dJLLyUlJQWA7Oxs/vrXv9KjRw969uzJokWLAPjhhx/o27cvvXr1YsSIEfX63AaD4ezjnFrSXEl0cwBstvYopbDUQEariG7OCy+8QEJCAhuLCo6NjWX9+vUkJCTQrl07AN5//32aNm1Kbm4u/fv3Z/z48YSFhZXKZ/fu3Xz22WfMmTOHG264gUWLFjFp0qRSaS666CLWrFmDUop3332Xl156iVdffZWZM2cSHBzMli1bADhx4gRpaWlMnjyZuLg42rVrx/Hj1Q37ZTAYzlXOKcGoCqUU7gyV4mDAgAHFYgEwa9YsvvzySwAOHz7M7t27ywlGu3bt6N27NwD9+vXjwIED5fJNTExkwoQJJCcnU1BQUFzGihUrmD9/fnG60NBQvv32W4YMGVKcpmnTpvX6jAaD4ezjnBKMynoCALm5ydhsuQQEVBj6ql7w9/cv/js2NpYVK1awevVq/Pz8GDZsmMsw597e3sV/e3h4uHRJPfDAAzz00EOMGzeO2NhYZsyY4Rb7DQbDuYkZw3DCHft6BwYGkpWVVeH1zMxMQkND8fPzY8eOHaxZs6bWZWVmZhIZGQnA3Llzi89fdtllpbaJPXHiBIMGDSIuLo79+/cDGJeUwWCoEiMYTjgGvevTLRUWFsbgwYPp3r0706ZNK3d91KhRWK1WunbtyvTp0xk0aFCty5oxYwbXX389/fr1Izw8vPj8E088wYkTJ+jevTu9evVi5cqVNGvWjNmzZ3PttdfSq1ev4o2dDAaDoSLcGt78dBMTEyPx8fGlztUkNHd+fjIFBUkEBPQpXvltMOHNDYazmTMtvHmjwaz2NhgMhooxguGECUBoMBgMFWMEwwkT4txgMBgqxgiGE6aHYTAYDBVjBMOJkoFu08MwGAyGshjBKIUZ9DYYDIaKcJtgKKXeV0qlKqVc7setlBqmlMpUSm0sOp50ujZKKbVTKbVHKTXdXTaWt6lxuKQCAgIatHyDwWBwhTt7GB8Co6pIs0pEehcdzwAoXWu/CYwGugETlVLd3GhnMTrEuYcZ9DYYDAYXuE0wRCQOqE28iQHAHhHZJyIFwHzgqno1rhLqO8T59OnTS4XlmDFjBq+88grZ2dmMGDGCvn370qNHD77++usq86ooDLqrMOUVhTQ3GAyG2tLQwQcvUEptAo4Aj4jIViASOOyUJhEYWB+FTf1hKhuPVhLfHLDZTqGUBYvFt1p59m7Rm9dGVRzVcMKECUydOpX77rsPgM8//5xly5bh4+PDl19+SVBQEOnp6QwaNIhx48YV9XJc4yoMut1udxmm3FVIc4PBYKgLDSkY64HzRCRbKXUF8BXQqaaZKKWmAFMA2rZtW2ejdIVdf+FS+vTpQ2pqKkeOHCEtLY3Q0FDatGlDYWEhjz32GHFxcVgsFpKSkkhJSaFFixYV5uUqDHpaWprLMOWuQpobDAZDXWgwwRCRk05/L1VKvaWUCgeSgDZOSVsXnason9nAbNCxpCors7KegIPc3D3Y7fn4+0dXmba6XH/99SxcuJCjR48WB/n75JNPSEtLY926dXh5eREVFeUyrLmD6oZBNxgMBnfRYNNqlVItVJH/RSk1oMiWY8BaoJNSqp1SqglwI/DN6bOs/vf1njBhAvPnz2fhwoVcf/31gA5F3rx5c7y8vFi5ciUHDx6sNI+KwqBXFKbcVUhzg8FgqAvunFb7GbAa6KyUSlRK3aGUulspdXdRkuuAhKIxjFnAjaKxAvcDy4DtwOdFYxunBXfs6x0dHU1WVhaRkZG0bNkSgJtuuon4+Hh69OjBvHnz6NKlS6V5VBQGvaIw5a5CmhsMBkNdMOHNy5Cff4SCgiMEBPRFKbOuEUx4c4PhbMaEN68DJsS5wWAwuMYIRhkay2pvg8FgaGycE4JRE7ebCXFemrPJZWkwGOrGWS8YPj4+HDt2rAYVnyNirelhiAjHjh3Dx8enoU0xGAyNgIZe6e12WrduTWJiImlpadVKb7cXUlCQjpcXeHj4u9m6xo+Pjw+tW7duaDMMBkMj4KwXDC8vr+JV0NUhP/8oq1f3olOnN4mMvNeNlhkMBsOZxVnvkqopXl46hIbVmtHAlhgMBkPjwghGGSwWbywWX6xWszLaYDAYnDGC4QJPzxAKC41gGAwGgzNGMFzg6RlqehgGg8FQBiMYLtCCYcYwDAaDwRkjGC7w8jI9DIPBYCiLEQwXeHqGGMEwGAyGMhjBcIFxSRkMBkN5jGC4QAtGJiL2hjbFYDAYGg1GMFzg6RkKCFZrZkObYjAYDI0GIxgu8PQMATDjGAaDweCEO7dofV8plaqUSqjg+k1Kqc1KqS1Kqd+VUr2crh0oOr9RKRXv6n53YsKDGAwGQ3nc2cP4EBhVyfX9wFAR6QHMBGaXuX6JiPSu7taB9Yl2SZkehsFgMDjjtmi1IhKnlIqq5PrvTm/XAI0mhrbDJWXCgxgMBkMJjWUM4w7ge6f3AvyolFqnlJpyuo0p6WEYl5TBYDA4aPD9MJRSl6AF4yKn0xeJSJJSqjmwXCm1Q0TiKrh/CjAFoG3btvVik5dXGKAoKEiql/wMBoPhbKBBexhKqZ7Au8BVInLMcV5EkopeU4EvgQEV5SEis0UkRkRimjVrVi92eXj44efXlZMn19ZLfgaDwXA20GCCoZRqCywGbhaRXU7n/ZVSgY6/gZGAy5lW7iQoaCAnT66pwV7gBoPBcHbjNpeUUuozYBgQrpRKBJ4CvABE5B3gSSAMeEspBWAtmhEVAXxZdM4T+FREfnCXnRURFDSIo0c/IC9vH76+HU538QaDwdDocOcsqYlVXL8TuNPF+X1Ar/J3nF6CggYCcPLkH0YwDAaDgcYzS6rR4ecXjcXiz8mTaxraFIPBYGgUGMGoAIvFk8DAGE6e/KOhTTEYDIZGgRGMSggKGkR29gZstryGNsVgMBgaHCMYeXkwbRp89VW5S0FBAxEpJDt7YwMYZjAYDI0LIxje3vDpp7BgQblLJQPfZhzDYDAYjGAoBcOHw88/Q5k1F97erfD2bkNWlhnHMBgMBiMYoAUjNRW2bi13ybGAz2AwGM51jGCAFgzQvYwyBAUNIi/vAAUFKafZKIPBYGhcGMEAOO88aN/epWAEBpYs4DMYDIZzGSMYDoYPh9hYsNlKnQ4M7ItSnkYwDAbDOY8RDAfDh0NmJmzYUOq0h4cf/v49zTiGwWA45zGC4eCSS/RrBeMYWVlrEbGVu2YwGAznCtUSDKXU35RSQUrznlJqvVJqpLuNO620aAHdulUgGAOx2bI4dWp7AxhmMJxlFBTAsGHw4481vzcnB+bMKec6NpweqtvDuF1ETqL3pggFbgZecJtVDcXw4bBqlf5BOxEUNAjArMcwGOqDzZvhl19cRleokoULYcoU+OG073hgoPqCoYperwA+EpGtTufOHkaM0C2YP/8sddrXtxOenqFm4NtgqA/WFu1kuWlTze/duVO/fv11/dljqDbVFYx1Sqkf0YKxrGhHPLv7zGoghg7VK7/LuKWUUmYBn8FQXzgEY/NmsNewGtlVtDnnt9/W/F5DnamuYNwBTAf6i0gOeue8v7rNqoYiNBT69oWffip3KTBwIKdObcVqzWoAwwyGs4j4eN0wy86GAwdqdu/OnTr+29Gj5TwBBvdTXcG4ANgpIhlKqUnAE0BmVTcppd5XSqUqpVzuyV00iD5LKbVHKbVZKdXX6dqtSqndRcet1bSz7gwfDqtXa9eUE3ocw05W1trTZorBcNZx6pQOwXP55fp9TdxSdjvs3g1/+Qt4eBi3VANQXcF4G8hRSvUCHgb2AvOqcd+HwKhKro8GOhUdU4rKQSnVFL0H+EBgAPCUUiq0mrbWjeHDobAQfvut1Ong4AuwWHxIS1t4WswwGM5KNmzQFf9tt+leRk0EIzFRb0cwcKB2HxvBOO1UVzCsIiLAVcAbIvImEFjVTSISBxyvJMlVwDzRrAFClFItgcuB5SJyXEROAMupXHjqj4suAk/PcuMYnp7BNGt2HSkpn2CznTotphgMZx2O8YuhQ6FTJz2OUV0c4xedO8NVV8H27brHYThtVFcwspRSj6Kn0y5RSlnQ4xh1JRI47PQ+sehcRefdT0CAbsG4WI/RsuVkbLaTpKZ+cVpMMRjOOtauhdat9bqnXr1q1sNwCMb552vBANPLOM1UVzAmAPno9RhHgdbAy26zqgYopaYopeKVUvFpaWn1k+nw4XpgLrP0ME1w8MX4+nYmOXlO/ZRjMJxrxMdD//767549Yd8+OHmyevfu3An+/tCypQ4Y2qsXfPON+2w1lMOzOolE5KhS6hOgv1LqSuBPEanOGEZVJAFtnN63LjqXBAwrcz62AttmA7MBYmJixFWaGjN8OMycCUuW6AG2IpRStGx5J/v2TePUqa34+0fXS3EGw9mCYw8y5WqVVkYGtt17Sb72QY78CSHhF9IWb3wSEuDCC8slLyyE9HTIzwerFQrX51LYZgwF6xSZmZDRaTqZi1aQMTObUwTQpImeQOV8lD1nsej8nA+7Hby8tCfaceTkQFpa6SM/X9+vlD4sFv28IjoPx9/e3uDnV3L4+up7c3JKjrw8bZuvrz78/HS5mZlw/DgcO6ZfK9JSu73ksNmgWbPaLWupKUqk6jpWKXUDukcRi16wdzEwTUSqHAFWSkUB34lIdxfXxgD3o9d3DARmiciAokHvdYBj1tR6oJ+IVDYeQkxMjMTHx1f5PFWSnw/R0XrK3+OPwxNP6F8UUFCQxurVkURG3kfHjv+pe1kGg5uw23Wl5orcXF0JpqZCRoaukK1WXfk4/i4sLH3k5elJTqdO6Urv1Cl9b3q6Po4d04fFAk2blhwhIboiPLQrl6RUL2xl2qktg08R1c2fyEhdQR49CsnJOs9qVE9uJzRUV8g+PqUFwm4vEQ7HK5SIQ25uiUB4e+vOkUNEvL11QInc3JJ0hYX6s3J8bmFhEBhY/jsU0ZPELJaSIyQEXq6lz0cptU5EYqqTtlo9DOBx9BqM1KICmgErgEoFQyn1GbqnEK6USkTPfPICEJF3gKVosdgD5FC0tkNEjiulZgKOOazPVCUW9Yq3t+46P/ggPPMMfPcdzJsH0dE0adKM8PCrOXp0Hu3aPY+Hh89pM8vQuBHRFXBqaknF4lzBOCpiR2WcnKzHbPfs0cfevfqn17IltGqlX1u00JWJI9/UVF3R22zlK6qCAl1Z5eWVtJw9PUtasb6+Om16OmTVYTlRkya68vP3h+BgXZl26wbh4bqSs9ngxAndQj5+HJKSdLohrfbSNvVr2v57Kq06+pNxQjhw13McaDGMA76D2bxZp4uKgkGD9PNHROiK2lMK8brzVryuG4fXpBsJCYHgICFk9AWE9OuA35efUFhY8hm4OgoKtG1leyEWS/nvxtdXP1dYWHFbsU6/C5c9rjOQ6vYwtohID6f3FmCT87nGQL31MJxZvBjuvls3fZ59Fh56iOMZP7F580i6dv2UiIiJ9VueoVEgAgcPwsaNJUdyMjRvrisyxyGilxVs3QoJCboyrgkWi3bHd+yo9/CyWuHIEV3WkSNaIHx9dcXZvLk+wsO1EJR1hTRpoitXR0Xo6Vm6FZubW+K+aNasJL/Q0BJXjIdHyd9eXqUPRyvZs7rNzLJcey1s2VJ6ZtPQobqG/v33yu/dvl2r0scfw003lZy/7z748EP9wfv61tKwcxt39DB+UEotAz4rej8B3Ts4+7n2Wj3V9q67YNo0sNkI/fs0fHzakZz8rhGMRoDVqqfoHz6sXxMTdas2OVlXmM4Vq82mW+AOl0Furn7vqHQdZGWV+I+V0jM527TRZfzxh27lOwgM1B7Mq6+G7t0hMrLEz+04nCtiR8UcEaFb097eFT+bzabTnlYyM7VvqX37+s03Pl7/LznTqxe8/37l/jMoiSF1/vmlz191Fbz1FqxYAWPH1q+9hnJUd9B7mlJqPDC46NRsEfnSfWY1Mpo31z2Na6+FZ55BTZxIy5Z3sH//E+Tm7sXXt0NDW3jWkJdXMuDneM3OLu1qyc3VgrBvnz4OHtSi4UxAgHbrOFwODteNxaJb4cHB2t3ja83CZ/3vWIYPA2/vYteBjw/06AG9e2sR8PcvnX9hoW792+16lqi7XA6nXSwAHnhAR4NNTq4/A1JStNo6Zkg56NVLD4bs26e7WRXhPKXWmWHDIChIT681guF2qt25FJFFwCI32tK4UQpeew26doX/+z9afPo6+/c/RXLyu7Rv/3xDW9eoycnR7pXCwhIfsdWq65AdO0ofx6s5UhUWphvAMTFwww3Qrp127bRurY+goGoa98r/YMk0uGYhjB9f7Wfy8tI9ibOO/HwddjwrS7uPeveun3wdC/Ziyng+evbUr5s3Vy0YERFa6Z1p0gRGj9bBCBukO3ZuUalgKKWyAFeDHAoQEanuv+XZwXnnwT//CY89hvfKyYRFjiE5+QOiop7BYqmPdYxnLlar7hGkpsKhQ3qKn+PYvbvywKIREdClC1x/PbRtq8XAMUukaVPt8nH45h2vdR2ILGb9ev365581EoyzluXLS0bEf/mlfgXDYtHBPZ3p3l2f37RJ9+ArYteu8r0LB+PGwYIFuoxBg+rHXoNLKhUMEaky/Mc5x8MPw9y5cP/9tIx9iWPHviEt7QsiIv5S9b1nMIWFsH9/yYwex3HggBaJ48fLT4Fs1057HG68UfcGmjQpme/u5aUHWzt31qLQYDgE4w+z1wkAixbpVnxwsBaMv/2tfvKNj9eD1mV9e76+WgiqWkSwaxdceaXra6NGadFZssQIhpup7XyHc5cmTeCNN+Cyywh7bwv+V3Tn4MGZNG8+AaXO/O6w3a7/N9eu1RNTduzQr3v2lB4nCAjQHoQuXbQb2XnWTatW2v9fbbdQQ5GVpR/Wy0tXaOe6S6OwUI8FjBunPwfHnhOVDUZXBxH9g6qowu/Zs8Rl5YrMTO2/rKiH0bQpXHCBFoyZM+tmq6FSjGDUhksvhRtuQL3wAu2veJUtOfeRmjqfiIibqr63kZGaqqeMrllTcpw4oa95empR6NoVrrlG9wY6ddLnmjU7TXPLt2/XXZEWLeo/702bdGUooS6sAAAgAElEQVQ2fjzMnw/btmmlO1eJjdVf/vjx+vXDD/V84bp+JocO6WllZQe8HfTqBZ9/rqeluWplVDTg7cyYMfDYY3qwrFWrutnbWBDREwICAhrakmLq2HQ4h/n3v8HTk6ZPL8HfrwcHDjyN3W6t+r4GIjNTu+nnzdOzg0eO1HVwRITemmDGDP1/PX48vPuuXlOQk6Pr68WL4bnn4NZbdQSH5s1Pk1jY7TpMy5Qp7snf4Y665x79eq67pRYt0i6jkSP1+gjQbqm6UtGAt4NevfRrRZFrnaPUVsSYMfp16Vky23/TJrj4Yj2AN3asFvNGsOzdCEZtiYyEGTNQS5bSbX5nck/tJjX104a2CtC9hi++gPvv1+6iFi106ICBA3Wl//rreoB69GiteytW6AZlQgLMmQN33KHXFdTbwHJt2bxZx4n48Uc9t7a+WbdOr767+GLdizmXd3Cz2eDLL3XF6+urF4i0aVN/guHlVTIjqizVEQyLpfJ1IT166OlxS5bUzVZ3kJJS/co+MxOmTtWTA3bu1AsT//gDLrlEC+4nn2jXYQNhXFJ14W9/g23b8P/P+/TcEsKeJ56mefO/YLGc3o/1yBG931NsrD62bdPn/f31/+IVV+ixhs6d9dGxYx1W655OVqzQr/n5WjQqm0VTG9av1/+YSsGAAed2D+O333RLwzFTTCndy/jxx2rFtsiz5rH68Gp+O/wb0c2iubrL1SjHPfHx+odY0QrFyEgt2BUNfO/aVfUKR6W02H38MeTnszp1Pcv2LiPUJ5Rm/s0I9wsn3C+cgCYBWO1WbHYbVrsVq92Kj6cPzf2bE+4XjoelZAwrpzCHXcd2sT1tOzuP7cTH04fOYZ3pHN6ZDqEd8PbU9uQW5nIw8yD7T+wnKSuJgZED6RFR5MbbuFG74p54Ap56CgAR4UDGAdoGty0pTwQ+/RQeeUQLzN1368gSTZvqIFEff6xbd5MmaXfAL79Aq1aICIknE0nOTmZA5IBKv6P64EyoNhovnp7af9O1K6F//ztdEjNI++wNInpPdVuRBQV6IHrNGvj1V33s36+v+fvrxvItt+ieRd++jaCXUBeWL9d+67Q0PRhbB8EQEfYc38Oe43sY0X4ETfKtWlmvuUYnGDAA/vUv7TMuO5OnAuxiJ6cwB4VCKVX8Wmgr5GT+yVKHRVkI9Q0lxCeEUJ9QgryDSlVO1SGnMIetqVvZmraVI1lHOJp9tPg4kXeCNkFt6BzWmS7hXegcrl8j/CNKKu4ypGSnsPLASgpthdy0aC0WHx/dunAwdKiuqHbs4HP7FpbvXU6QdxAhPiEE+wQT7B3MgYwDrDywkjWJa8i35RffOqLdCF4f/TpdA6J0D2PSpIofTKnivTEy8zL5M+lPVieuZnXianYf282HaRYuqmz8wsGYMexa+D8enX0pi4//Ws1P1ckMFOF+4UQERJBdkM3BjINI0aoChSr+G8CiLESFRJFTmMPR7KPl8hrUehCT+05mwttx+FutyLMz2TTkfD6zbmTB1gUczDxIM79mXHn+lYzrPI7LFm/C//EZ+nf43XfQr19JZr6+MHkyebfexNqF/2Xt7BlsfaIHWwe1Z9uxnWQVZNHcvzkpj6TU+JlrSrViSZ0puCWWVDWRr77CPnE81iCF1/ersfStYICvJnmK3tEyLk43VDZt0mOQjh5p8+Y60oLj6N27aoGwix2LOgM8kXl5unU1ebKes7t0qW551aBrlHYqjZ/2/8TyvctZsX8FhzIPAXB9t+v5rM1UPC4YrN0wV1+tXRlXXgm//EJS7w7M2zQPq92KUgqLsqBQ5FpzOXzyMAczDnIo8xCHTx6mwFZQq8dTKCKDIukS3oUuYV3o2qwrncM642HxICMvgxO5J8jIy+BY7jF2pO9gc8pm9hzfU6rSCvEJoUVAC1oEtCDYO5iDmQfZdWwXOYUl+9GH+YbRvXn34iPUJ5RfD/3Kzwd+ZlvatuJ01+734aPMEfh9+V2Jkbt3I+efz5Mvj+bZU98T6hNKvi2/VP4WZaFPiz4MixrGJVGXcEGbC5ifMJ/Hf36c7IJspvpfypOP/kDgj7El4yIu2P3Qrfwl52PWtRQEQaGIbh5NRl4GBcmJrCv4K61fe7/C+1NPpfL0iif43/o5+Cov/n7JP5k6aCoFtgLSc9JJz0knLSeNUwWn8LR4Fh8eFg9yC3NJPZVKyqkUUrJTSDmVgq+XL13Du9I1vCtdwrvQKawTBbYCdh3bxc70nexI38Hu47vx8/KjXUg72oW2o11IO5r7N+e7Xd8xZ/0ctqdvJzAfxua2YZ0cYWeoDU+LJyM7jGRk+5H8eeRPluxaQmZ+Jj6FMKSgBVEXjyUioAUR/hFEBERgURbWJK7h10O/si55XfHvrXk2RNvDiB4+geiIHkQ3i+aithdV2DiojJrEkjKCUY+c+Pm/+E2YileON5aPPq1Vi1hEi8Pnn+tj3z593rFBWe/e+jUmRruWKvp9ZOVnEXcwjm1p29hzfA97T+xlz/E9HD55mPPDzmdk+5Fc3vFyhp43FP8m1WtR1xoRvXpvwwb9cI7XAQOKN8DJys9i8fbFRAREMKrjKFi5Ug94f/utdklddx2sXEnmoD68+NuLeHt4M6rjKGJaxZRqqZ8qOMVXO75i3uZ5rNi3ArvYCfEJYXi74Vza7lJST6Uy45cZ3OkzmNnTf0MdPKhXC6alQfPmbHnxIUZ7LiApK6ncY1iUhVaBrWgb3FYfQW0J9wsHtBALgojgafEk2CeYIO8ggryDCGwSiCDFIpCRl8Hx3OMcyDzA9rTt7EjfQVaB6/CxCkXHph3pEdGDns170iOiB92bd6dNUBt8vcoH27OLncSTiexM38n29O1sTd3KltQtJKQmFJfh5+XHxW0vZni74QxvN5xVcR/x8I5Z9PNpxzf3/UbLwJYAFFjzufPWUD46P5c7+tzB22PexsvDq7gHlZmfSVPfpoT4hJSzI+1UGo/+9CjvbXiPVrmevHPbIsZ2GefyGXem7+SStwdSmJXJA4Me5IJeVzIgcgDBPsFs2xrLwE8uoZv/ecT9Y2exG8iZeZvmcd/S+8gtzOWu5Eie/NVCxJb9Lss6XYgIv/1nKnNWzeLrmAD6+LRj4mdbuHbU/xH+7L+L0xXu282qa/rxTY8mrLywJcmnUkjPSS/VMGji0YSYVjFc1OYiBrcdzKDWg2j+0WI9WePee/U0/zrMQjGC0UCICFuW9aHdI9sJ3Fqg/ZZPP13lPPaCAu1a+v57HZVhzx49DX7ECB324oor9NhsZdjsNuKPxPPj3h9Zvm85qxNXYy2atRXmG0bHph3p0LQDbYLasPHoRn45+At51jyaeDThgtYX4OflR05hTqkj35ZPga2AfKt+FYTIwEjaBrflvJDzaBvUlsigSEJ9QotdFME+wbQMaEmob2iJcVOm6NF00D2E6Gjw80NWryb+ty+Ynb6M+Vvnk12gB7YnRE/gjfUtCH/pDT0arxSEh/PL/WO5pfWfJJ5MRES3RJv6NmVkh5EMPW8oaxLXsGj7IrILsokKiWJSj0mM6zyOvi37lhKVJ35+gn+t+hfT1vnw4lenUEXfz8oLW3L1pekEhDRn6V+WEt08GhEpFgNHq7S+ERGOZB1h5zEdYC/Up8h15RtKYJPAGruuKirj8LqfSf3kf/S8bTpNejmtuJ42jW+X/oeJN/nQ1Lcp3078lvNCzuPaBdey8sBKZv4ZwOPfZhZ/TtXmzz/549qB3H1PazZaE5k6cCovXvYiTTyaFCfZnrad4fOGYy8o4Of/HCf6ydf1bA0HsbEsvvcSxk+AO/rcwZyxc4pb0Ta7jUd/epSXf3+ZYVHDeGfMO3Sev1zHwtq5s/JpuO5GRC9UDA7W/mOAv/4VPvoIVq/W4xq5udo1sHevHucpCo1itVs5lnOMlFMp5Fnz6BnREx9PF9soTJsGr7wCr74KDz1Ua1ONYDQgx479QMK60fR7L4aAz+O1m+Pjj8vFwDl+XM9k+v57PbZ76pR2Jw0dJoy97iQDLjlKvpf2Twd6BzLkvCEENCk/H/tAxgHmrJvD+xvf52j2URSKPi37MLL9SC7rcBl9W/Z12QLMLcxl1aFV/Lj3R+IOxiEIfl5++Hv54+flh6+XL94e3nh7eNPEowlNPJogCElZScUumaSsJOxSPuaHQjGw9UCu7HQlVyb50fMvD6HuuguZMoXENkFsPL6dDbvjWLzkFTa10C3eCdETuKPPHcQeiOXpX54mJFd4e0cHxi/eQb41nyfu78qrLfbTIawjH13zEZ2admL5vuX8sOcHftjzAymnUgjyDuKGbjdwc6+buajtRRW63kSEB/4awZvt0nhu+HM8evGjzE+Yz61f3ETHTAvfP72XtsFta/kLaKTYbHoVdHy8FuAJE/QgbOfO0KEDdO7Mxg+e58pPryQzP5NWga3Yf2I/7wXcxM0PfagHnjt1qlmZt90GixaRf3Af0/6Yyet/vk7/Vv1ZcN0C2oW2Y2vqVkbMGwHAzzevoNuE+/VMtT/+KFn7MXs23HUXTyy+n39tfoN3xrzDXTF3cTL/JDctvonvdn3HPTH38N9R/8XLw0sP6LVvrweI/+//6vUjrBGOHvLcuXpQEfRuU92767pg3TrdO/jgA92LrmhRY2XY7bpFuXixrkxqGdrGCEYDk5BwLcePfc+g9dNp8vdn9T/kV19Bly5kZcETr+3gra0zsZ63DItF8GoCTbzA0wtyrTnkWfPK5ell8WJw28Fc3uFyLu9wOYdPHuZ/6/7H97u/RynFmE5jmNh9Ipe2v5Rm/s1Oy3Na7VZSslPIzM8kIy+DzLxMMvMz2Zm+kyW7l7D2iJ5/3zrHiw5dLmBLWgLHc3V0QYWi76kg7tygmPjVXoL9S+KDJOz5jdtevoh1reC6btexM30nW1K3cPdaeGXmGvz7DCxlh13s7Dm+p0I3TTkKCrAH+HPLP87nE89tXNftOhZuW8jFHu35+l/7CN13pOou3emiPlZaA7z9tq6g3nxTh/r97391C/eKK/Qg65w5cOedHMk6wtjPxrL3+F4WT1jM8LyWuqVcdL3apKfraa533KHLBBZvX8ztX98OwIxhM3hu1XN4Wjz5+daf6RLeRU+h7tNHrz2Ij9eL+B5+GN5+G9vJTMZ9fjXL9y7nw6s/5LlVz7EjfQezRs/i3v73li67Wze9eM8xy84dFBToWZIjRmh3aVmuvx5+/ll/1j5OvYNly3QokwEDtDj+8596k7bakpurhWn3bh2npxaL/GoiGLprf5Yc/fr1k8ZAbu5hiYsLlI0bLxd7bKxIs2aSG9Rcpj+5Wrz/MlF4SonHP/1k7Hu3yX1L7pf7nY5Hlj0ir/z2iny86WNZsXeFJKQkyIq9K2Taj9Ok59s9hRkUHy1faSlP/vykHMo41NCPXB67XZInjJH3+3nItbNHyMA5A2XyN5PlzT/flN8P/S5Z+VkiX3yht6H44YfS9y5cKAUW5NmPJovXM14S8XKEfLdmnk47c2bdbVu3TgSkYMGnMvbTscIM5LrPr5PcuJ91GV99Vfcy6orNJvLWWyLBwSJvvlm3vI4e1fkMHy5it+tzqakijzwi4usr4ump3xdRaCuUjNwM/cZuF2neXGTSpJqV+dJL+rNMSCh1et/xfdJ/dn9hBtLq1VayM31n6ft++UXEw0Nk/Hhd9pVXivTsKSIiJ3JPSMdZHYUZSMgLIbJ873LXZT/yiIiXl8jJkzWzWUQkLU1kwgSRe+/V30FF3Huvfj4PD5GlS0tfS0rSn+kjj7i+d/Jkfe+oUSJWa81tLEtqqkh8fK1vB+KlmnWsWytwYBSwE70F63QX1/8DbCw6dgEZTtdsTte+qU55jUUwREQOH54lK1ciG7Z8JlMeWyh+48cVCYW/3Dz3H5KanVp1Ji44cvKIzNs4T77e8bUUWAvq2ep65NNP9c/r+ecrTpOXJ9K0qciNN5Y+f/fdIgEBIgUFcuDEATmRe0KfHzRIJCam7rbNmaNt27NHcgtz5cc9P4rNbhPJydH/6I89Vvcy6sL+/bpyB/05hISIHDtW+/wmTdIV6Pbt5a8lJ4ts2FD5/dddJ9KmTYnYOMjN1d9hWaxWkXbtRIYOdZldvjVf3l77tuw7vs91eS+/rJ/91VdFzj9fl1/EttRtMmnxJNmVvqtie1eu1PcvWlT5c5Vl1SqRyEgtAiByzz3ln1lE5L339PX77hPp00fEz0/kjz9Krj/9tL6+e7frck6eFHnlFZHjx2tmn5toFIIBeAB7gfZAE2AT0K2S9A8A7zu9z65pmY1FMI5mpcijC96TiAcHC48GCjMQy+N+MuHStpL67fyGNs/9JCWJhIbqCr6wsPK0998v4u0tcuJEybmOHXXLsizPP69/socPlz6/bZtI//4iTz5ZdXkiuiIIDnZdGfTtKzJiRNV5uANHr8LfXyQwUGT2bJGNG0WUqri1WhU/F/WaHn+89na9/rrOY19RBV9YqHs94eEiHTpoG51ZskSnX7CgduXZ7SLXXKMrboul5gJeUKC/39tvr156m03kued0eR066B7oP/6hn+HRR0unXbNGpEkTkUsv1Z9DcrIWx/BwkZ079bnISJHLL6+ZzQ1IYxGMC4BlTu8fBR6tJP3vwGVO788YwSi0FcqvB3+VJ356Qjq9FCM8pYQZiHqklUQ9MFiemHejZJ88pltLHTu6bpXVhOxs3RpujNjtIldcoV0dO3dWnT4+Xv8M33lHv9+/X7//73/Lp922TV9zdtH8/rvupfj762uDBons3Vt5mQMHigwb5vra3XeLBAWVd0d89JEWsXXrqn6mmnDkiHaBPfqo7j2ByGWXiRw8WJLmttt0JbV/f83yzs8X6dJFV2h1+b1s3qzt+uADLQZdu+r3Q4aItGqlv+u5c0vSX3GFSIsWuvzakpGh/1dA5MMPa37/DTeIhIWJ/Pln5elSUnTlDtoVlZmpz9vtInfdpc+/8II+l5ysn7ddO5H09JI8du0SadZMJCpK/zYbi1uzmjQWwbgOeNfp/c3AGxWkPQ9IBjyczlmBeGANcHV1yjzdghGfFC83fHGDBD8frAXiKYtw+2AJH/+MPPnWesnKssuePY/IypXIiRNxIsuWSZ398MeOibRvL9KjR8OLxvr1+h/z8st15dG/v66gKqrwXWG3i3Tvrit6kRJ30datrtN26iQycqR+/+23urLq2FGLxPz5umUZGKgreFcUFor4+Ig89JDr6x98oMvftq3k3Ny5upXv4aFf77mnbi6i1FQtTG3aiDi2E/f0FOnXT/cqyvZ8Dh3SNlc2jpCdXb539dxzOu/vvqu9rSJaPJs21UIK+jv46itt59Gj2vXkcOFs364/oyefrFuZIlqoBg2quVCKiKxdK9KyZcn3Vdb9k5wsMm2abmh4e+sGS9nP3WoVmThRP9usWSKDB2v306ZNrstzNFratKleT7eRcCYKxj+A18uciyx6bQ8cADpUcO+UImGJb9u2bf1/mi7Ye3yv3LjwRmEG0vTFpjL033dI4MAvxDPwuDz1VOkOhNWaLb//fp788UdXsdnytT/Wx8f1P0FGRnl3izM2m269eXrqr+7ee+v70arPli26EgkL00IxZIgWjquv1pVFZQOGZXnlFf0827frVl7Llq7dRSL6n9zLS+Q//9EVeEyMbiU6OHBA5KKLdH5/+Uv5gc8tW/S1jz92nf/WraVbtR9/rCudSy/VlcyDD2o3SViYrtxr8px2u8j77+vPzctL5PrrRf79b5Hffqta/KdP13atX18+z2ef1TYppV0j0dF6DMTXV7t26oNbb9VuxtdeK99zKCzU34tjzMXDQyQxsX7KrQsZGSXfV/PmIvPmafF98EH9P2ixiNx0k+uxHQcFBSJjxpQIe2VutmXL9Pf68sv1/yxupLEIRrVdUsAG4MJK8voQuK6qMt3dw0g7lSZ/+/5v4vWMl/g+6yt/+/pxuezKTAHt5SgzIaSY9PQlsnIlsn//TP2D9fcXGTeuJEFqqnZJBAXpH/KXX7rOyDGY9tZbIg8/rP/++uv6f9Cq2L1buxxatara/VMdjh7Vlczf/64rvJtvrjjtr7+W/PNefrlIVlb5NFar7sV5eGgxc3YfzJ1bvgfhjM2meyj33KN7LBaLyCWXiJw6VZJm06YSUYqJ0TN7qmLbNi2qoO+t6MdSERkZWqQuu6zk3KlTWmBBzyp66indc7n6apELLtDPfqieZtAVFFTtYlq4UH92EyfWT5n1xfr1+h8UtKh6eurxjV2VDJw7k5OjJ2a8+GLVaU+cqLix00hpLILhCewD2jkNeke7SNelqAehnM6FAt5Ff4cDuysbMHcc7hKMrPwsmfnLTAl6PkgsT1tk8jeT5YsfkqRFC92Ie+21qmfHJSTcILGx3nLq1E79wwORd98VmTpVZ6KUbnH2768rqbfeKp3B99/rNDffrH+QeXl6hkZY2OltzR0+LHLeebpcV26j2jJ2rP4cQLcEK8Jq1a6b22+vugL75hvtbujeXY8ViOjWpZ9f5V/Y8OFauDw8RC6+WLt7ymK3a7dXZKS2edy48i3VggI96HzffbrlGRqqv/Oa9Eqcee01XdayZXqMo08f/Zt48cXGU0llZOjZU40Nm01/9o8+qnuhhmIahWBoO7iiaLrsXuDxonPPAOOc0swAXihz34XAliKR2QLcUZ3y6lsw8q358sYfb0jEyxHCDOSqz66SLUe3ynPP6Tq9c2ft4agOeXlHJC4uWDZsGC72vLySgUMPD5FbbimpbLKz9eCqY4aG3a7dV02b6vnozi3dHTt05Td8eO0rIVckJGjX2T/+IfLjjyXuktRUPUYRGFined8uWbSopOeQlFR/+f70k+7RtW+vZ/lcdJHIhRdWfs+jj2o7Lryw6rn8p06J/Otf+jPx8NA9k08/1e6wkBCdj7e3duk4u85qQ36+fo5OnbSLJShID0IbDHWg0QjG6T7qUzAWJCyQ9v9tL8xAhnwwRH4/9Lukp+shBNA91JquC0pMfFtWrkSSk+fque+PPloyVdGZwkKRKVN0QTffrFvUwcGu53W/+66UmslRV377TbeEg4J0q9hR4Q0frn3jPj7Vc8HUlPx83Wvp1q3+816zRj9Tq1ZaYB94oPL0Bw5on7xjxkx1SEnRPQnHHP7wcD27afFi126z2jJ/vhQPPFfmezcYqokRjDpgtVll6vdThRlIr7d7ydJdS8Vut8uRI9oT4+Ul8sYbtfMA2O02WbfuAlm1Kkzy89OqSqz98I5Wd0VjFXa77g14empXRV1cE0uXlsw62r9fV3RLl+oZRT176gq97KrW+mTZMpHYWPfkvXmzHndxTA91F3v3iqxeXT8reF1ht+vZYc7rVgyGOmAEo5bkFOTItQuuFWYgDy59UKw2/U9vs+nxVV9f3VitC1lZWyQ21lO2b7+tejcsXFj1PPTjx/UccNB+smefrbmf9uOPtej07Vux66Sx+Mlry+7ddZ8SazCcZRjBqAWp2alywbsXiJqh5N+//7vUtf/+V4onJ9UHe/c+KitXIseP/1w/GYrowcbZs/UgraNXMnSo9qcXVBJCxGrVIRhAzwaqiRvGYDCc8dREMEy0WmDP8T2M/mQ0hzMP8/G1H3Ndt5Lok1u36t0SL7tM7/VTh31KirHZclm7tjtKedCv3zo8PQPrnqkz+/frzeLnztWba7RtqyNr3nmnjgDqSPPBB/Dhh3D4sN7s6ZNPSkfWNBgMZz0mvHkNOJZzjC5vdkFE+GbiN1zY5sLia/n5Ogrx0aOwZYveErW+yMj4hY0bRxAePpbo6EUod2ybarfrrUdffVVvGh8UpGPzb9umQy8rBZdfrkNQX3ON3rXJYDCcU9REMM6AzZ3dS5hfGDOGzmD1HatLiQXA44/D5s3w3nv1KxYAISFD6djxVdLTv+LgwWfrN3MHFguMHQuxsTr2/ujRel+E/fth5kw4eFDv4HTddUYsDAZDlZzzPYyK+OknuPRSvW3uW2/VS5blEBF27LiNlJR5dO/+NeHhrvc8rleys8HPr3425TEYDGc8podRRwoK9O6SnTvrLXPdhVKK889/h8DAGLZvn8SpU9vdV5iDgAAjFgaDoVaYmsMF69ZBYqL22vj5ubcsDw9foqMXY7H4kpBwFYWFGe4t0GAwGGqJEQwXxMXp16FDT095Pj5tiI5eRF7efrZtm4DNVn5Pb4PBYGhojGC4YNUq6NKl/ge6KyMk5CLOP/9/nDjxI1u2XInVmn36CjcYDIZqYASjDDYb/PorXHzx6S+7Zcvb6dLlQzIyVrJ580jjnjIYDI0KIxhlSEiAzEwYMqRhym/R4laioz8nKyueTZsuoaAgtWEMMRgMhjIYwSiDY/yiIXoYDpo1G0/37t+Qk7OTDRuGkJeX2HDGGAwGQxFGMMqwapWOpHHeeQ1rR1jYKHr2XEZBwRHWrx/IiROxDWuQwWA45zGC4YSI7mE0ZO/CmZCQi+nTZxUeHgFs2jSc/fufxG63NrRZBoPhHMUIhhN79kBKSsONX7giIKAX/fqto0WLWzl4cCabNl1CXt7hhjbLYDCcg7hVMJRSo5RSO5VSe5RS011cv00plaaU2lh03Ol07Val1O6i41Z32ulg1Sr92lh6GA48PQPo0uUDunb9mOzsjcTH9yI9/duGNstgMJxjuE0wlFIewJvAaKAbMFEp1c1F0gUi0rvoeLfo3qbAU8BAYADwlFIq1F22OoiLg/BwvQajMRIRcRP9+m3Ax6cdCQlXkZj4ekObZDAYziHc2cMYAOwRkX0iUgDMB66q5r2XA8tF5LiInACWA6PcZGcxq1bp3kV97HnhLvz8OtKnzyrCwsaxZ8+D7NnzCCL2hjbLYDCcA7hTMCIBZ2d7YtG5soxXSm1WSi1USrWp4b31RlIS7NvXuMYvKsLDw4/u3RcRGXk/iYmvsm3bjSaciMFgcDsNPVrJFBIAABQnSURBVOj9LRAlIj3RvYi5Nc1AKTVFKRWvlIpPS0urtSGNdfyiIpTyoGPHWXTo8AppaV+wadOlFBYea2izDAbDWYw7BSMJaOP0vnXRuWJE5JiI5Be9fRfoV917nfKYLSIxIhLTrFmzWhsbFweBgdCrV62zOO0opWjT5mG6ddMrw9evH0xu7r6GNstgMJyluFMw1gKdlFLtlFJNgBuBb5wTKKVaOr0dBzg2hFgGjFRKhRYNdo8sOuc2Vq2CCy8ET093luIemje/nl69VlBYmMr69Rdw8uTahjbJYDCchbhNMETECtyPrui3A5+LyFal1DNKKcfWcg8qpbYqpTYBDwK3Fd17HJiJFp21wDNF59zCsWM6htSZMH5RESEhF9Gnz+94ePixceMw0tO/a2iTDAbDWYbZohX45hu46qrGtcq7tuTnH2XLlivJzt5Ap05vEhl5d0ObZDAYGjFmi9YaEhcH3t7Qv39DW1J3vL1b0Lt3LE2bjmL37nvYseMOCgpSGtosg8FwFmAEAz1+MWAA+Pg0tCX1g6dnAN27f02bNn8nJWUef/xxPocOvYLdXtDQphkMhjOYc14w8vPP/PELV1gsnnTo8CL9+ycQHHwR+/ZNY+3a7qSnf8fZ5IY0GAynj3NeMLy9IT0dHn64oS1xD35+nenZcwk9eiwFLCQkjGXLlrHk5u5vaNMMBsMZxjkvGAC+vhDq9khVDUtY2Gj6999Chw6vkJERy9q10Rw8+LxxUxkMhmpjBOMcwmLxok2bhxkwYDtNm45m//7HiI/vTUbGLw1tmsFgOAMwgnEO4uPThu7dF9GjxxLs9jw2bhzG9u23kJ9/tKFNMxgMjRgjGOcwYWFX0L9/Am3bPk5q6gL+/LMziYmvm139DAaDS4xgnON4ePjRvv2z9O+/haCggezZ8yDr1/cnM3N1Q5tmMBgaGUYwDAD4+Z1Pz57L6NbtCwoK0tiw4UJ27LiTgoL0hjbNYDA0EoxgGIpRStG8+XUMGLCDNm2mkZIylz//7MyRI3PMJk0Gg8EIhqE8np4BdOjwEjExG/H3786uXVNYv/5CsrLWN7RpBoOhATGCYagQf/9oeveOpUuXeeTl7Wfdun5s2DCM5OQPsFqzGto8g8FwmjGCYagUpRQtWtzMgAE7iYqaSUFBEjt33s7vv7dg+/abOXHiZxNqxGA4RzDhzQ01QkQ4eXI1R4/OJTV1ATZbJv7+3Wnd+iEiIv6CxeLd0CYaDIYaYMKbG9yGUorg4Avp3Pl/XHhhMp07fwAodu68ndWrz+PAgZkUFNR+b3WDwdB4MYJhqDUeHr60bHkbMTGb6NlzOYGBfTlw4EnWrGnH/v0zsFqzG9pEg8FQj7hVMJRSo5RSO5VSe5RS011cf0gptU0ptVkp9ZNS6jynazal1Mai45uy9xoaD0opmja9lJ49l9K//1bCwq7g4MGn+fPPThw5MtusHDcYzhLcNoahlPIAdgGXAYnovbknisg2pzSXAH+ISI5S6h5gmIhMKLqWLSIBNSnTjGE0HjIz17B37yOcPPkbfn7diIy8H4vFt1QaP78uBAcPaiALDQYD1GwMw9ONdgwA9ojIviKj5gNXAcWCISIrndKvASa50R7DaSQ4eBB9+qwiPf1L9u2bzu7d97pMFxp6KVFRzxAcfMFpttBgMNQUdwpGJHDY6X0iMLCS9HcA3zu991FKxQNW4AUR+ar+TTS4E6UUzZpdS1jYOPLzE8tctZOe/jWHDr3Ahg0X0rTpaKKiniEoqFoNHYPB0AC4UzCqjVJqEhADDHU6fZ6IJCml2gM/K6W2iMheF/dOAaYAtG3b9rTYa6gZFosnvr5R5c63afN/tGo1haSkNzh06CXWr+9PUND/t3fvwXFV9wHHv799ah/alWTZRpYwNrac8LYhY/wghEdoKO2E/kGnJCTDdNKmndIpmXaa4mn6YqaTYfqADkka0kBDGiZJoZBQmDYxBpymBYMNBvzAIMCxLcuWLWm12pVW+7i//nGPxdoYe+1I3l3r95m5s3vPvXv3/Oxr//bec+45q0ml1pBKrSKdXk002n3mK2yMOa6ZbMNYDfy1qn7Kra8DUNWvHrPfJ4H7gU+o6uCHHOs7wFOq+tiJvtPaMJpXuZylv/9rDA09zdjYFlQnAYhGe0gkLqGlZTEtLYtoaVlMLLaYROJSAoFwnWttTPM7lTaMmUwYIfxG7+uBfvxG78+q6vaqfVYAjwE3qurbVeXtwLiqTopIJ/ACcHN1g/nxWMI4O3jeJLnca2SzL5LNvsj4+C4Khfcol0em9olGe+jp+WO6un6XUOiU+kYYY6o0RMJwFbkJuA8IAg+p6t+KyN3AZlV9UkSeAS4BBtxH9qjqp0VkDfAA4OF3/b1PVR882fdZwji7lcujFAq7yed3sn//Nxkd3Ugo1M6CBX9AT88fEYnMq3cVjWk6DZMwzjRLGLNLNruJPXvu4fDhHxEIRGlru562tk/Q1nYNyeQKAoGGaKIzpqE1SrdaY2ZUKnUlF1/8OOPju+jv/xrDw+sZHn4agGCwlVRqDS0tiwiHO4lE5hIOdxIOzyMeX0Y0ei4iNtCBMafCEoZpevH4R+jtvR+AyckDjI5uJJPZyOjo/5HLvUqpNARUjvpMIJAgkbiAePxCWloWU6nkKJeHKZWGKJeHEQlz3nlfob39ujpEZExjsltS5qyn6lEuZyiVDlMsHmB8/E3y+R2Mj+8gn99OsbifQCBGKNRBODyHcLiDiYl3mZzcw9y5t7BkyT/Q0vLBLtuVSgHVEqFQax2iMmZ62C0pY6qIBAiHOwiHO4jHl9HWdvVR2z2v9IEuupXKBHv3/j179nyVoaGnWbhwHd3dd5DLvUoms5FM5nmy2U2A0NX1Oyxc+OXjJhVjziZ2hWHMCRQKv+Cdd/6UQ4cerSoN0Np6BW1tn6BUGuHgwe8Cyvz5t7Nw4V3E40vrVV1jTpn1kjJmmo2MPMfo6M9obV1JOr2WUCg1ta1Q2MPevX/H/v3/gmqJZHI5nlegUsnjeXkqlTwiQYLBNKHQ+0sqtYYFC37PugOburKEYUwdTE4OsG/ffeRyrxEMJqaWQCABVCiXR6uWIXK5rYhEmDfvM/T03Elr6wrAv0XmP7j4v2SzLxMKpYnHlxGLLSMW66WlZdFpdRlWVVTL9oS8OYq1YRhTB9FoF0uW3FPz/vn8m/T338+BAw9z8ODDpFJrCQTCZLMv4XnjAEQiC6hU8lQqo1OfEwm5LsKdhEJz3PsORMKIBPFnFggCHsXiAJOT/UxO9lMs7sfziiQSl5BOr3Hjdq0mFluCiEzzn4Y5G9kVhjF1ViplOHDgQQYGvk0gkCCdXks6vdY9R9KDqlIqHWZi4i3Gx99iYqKPUmmQUmmIUunwVFdgzysBFVT9BYRI5Byi0e6pRSTM2NjLZLObqFTGAAgGk4RCcwiF2qaWYDABiEsk/hIOd9LaejnJ5OXE48tcYjLNzm5JGWNOSLVCPr+DbPYF8vntlMuZo5ZKJQ/o1KLqUSoN4nkFAAKBOMnkclKp1XR03EA6/XGCwfgHvqdcHiWXe51IpOtDr2QKhX0MDn6f4eH/IpG4mM7Om0mnr7ZbZ2eIJQxjzLTzvDLj4zvJ5V5hbOwVxsa2MDb2MqpFRKKk01fR0XEDwNT2QuH9GQmi0R7a2q6lre1aUqlVZLMvcPDg98hkngeUePwiCoV38LwCwWCaOXNuYs6cXyMS6XZXQa3u9cgVkJkOljCMMWdEpZInk/kfRkZ+ysjIevL5bQC0tCwmmbyc1tYrSCYvpVDYQybzHJnM85RKh6Y+H4stZf78zzFv3m3E40upVPKMjDzD4cM/ZmjoPymVDh/3e1taFpFIXEYyuZxk8jJisaV43gTlcpZKJetex/C8Ap436V4LiASJRM4hEulyr+cAFcbH32Zi4sjSRyiUpr39k7S330As1nvabTyqiudNEAjETnoMzyvXZfwzSxjGmLooFgddo3zHcberKvn8drLZF0kmL6G1deWH/kfq3zbbRqk0TKWSo1IZo1LJUSodIpd7g3z+NcbH38If1PpkAgQCLaiWUS1+6F7hcCex2FKKxYMUCu8BEI0udInj/GNr6NqLSnheCdUSqkWKxUMUi/uZnNxPsTiA540TDLYSiy0jHu8lFuslGj2XYnE/ExN9Lln1US4Pk0hcRGvrlaRSq0ilVpFIXIBIENWK+44yAMFgfNrGQrOEYYyZFSqVcfL5bRQKuwkGkwSDKUKhFMFgyq3HEIlO/XJXVcrlDMXiAMXiAYrFAUCIxXqJxZYSDrdPHXti4h2Gh9czMrKeTOZZyuXMh9QigEiYQCCMSJhweC6RSBfR6AIikS7C4U6Kxf1TVzGFwm78JCdEo+dWffcccrmtZLMvUi4Pu2MH3b4f/H86EIi7GBNEoz2sWPGz0/oztG61xphZIRiMk0qtJJVaWdP+IkI43E443E4iceEJ943FltDdvYTu7t9H1Zv6dX/08UKn/Evf8yaZnBwgEjmHYLDlA9tVlYmJPjd52Juuq3TIdZsOA4rnjburLn8JBGKnVIfTZQnDGGNOQiSASGRajhUIRI87x/373yXE473E473T8n3TySYEMMYYU5MZTRgicqOI7BKRPhG56zjboyLyQ7d9k4gsqtq2zpXvEpFPzWQ9jTHGnNyMJQzxHwP9OvCrwIXAZ0Tk2JuGXwBGVHUpcC9wj/vshcCtwEXAjcA3xB4rNcaYuprJK4yVQJ+qvqt+P7YfADcfs8/NwMPu/WPA9eL3sbsZ+IGqTqrqe0CfO54xxpg6mcmE0Q3srVrf58qOu4/6XRBGgTk1ftYYY8wZ1PSN3iLyRRHZLCKbDx06dPIPGGOMOS0zmTD6gXOr1ntc2XH3EZEQkAaGavwsAKr6LVX9mKp+bO7cudNUdWOMMceayYTxMtArIovF78B8K/DkMfs8Cdzu3t8CPKv+o+dPAre6XlSLgV7gpRmsqzHGmJOYsQf3VLUsIn8I/AT/+faHVHW7iNwNbFbVJ4EHgX8TkT5gGD+p4Pb7d2AHUAbuUH+A/xPasmXLYRH5xWlWuRM4/khnzcNiaAwWQ2OwGGpzXq07nlVjSf0yRGRzreOpNCqLoTFYDI3BYph+Td/obYwx5sywhGGMMaYmljDe9616V2AaWAyNwWJoDBbDNLM2DGOMMTWxKwxjjDE1mfUJ42Qj6jYqEXlIRAZFZFtVWYeIrBeRt91r+4mOUU8icq6IPCciO0Rku4jc6cqbJgYAEWkRkZdE5DUXx9+48sVuBOY+NyLz9EymMENEJCgir4rIU269qeoPICK7ReQNEdkqIptdWbOdT20i8piIvCkiO0VkdSPFMKsTRo0j6jaq7+CP5FvtLmCDqvYCG9x6oyoDf6KqFwKrgDvcn30zxQAwCVynqpcBy4EbRWQV/sjL97qRmEfwR2ZuZHcCO6vWm63+R1yrqsuruqI22/n0T8B/q+pHgcvw/04aJwZVnbULsBr4SdX6OmBdvet1CvVfBGyrWt8FdLn3XcCuetfxFGL5MXBDk8cQB14BrsR/2Crkyo86zxptwR96ZwNwHfAUIM1U/6o4dgOdx5Q1zfmEPzTSe7i25UaMYVZfYXD2jYo7X1UH3PsDwPx6VqZWbuKsFcAmmjAGdztnKzAIrAfeATL6/iTQjX5e3Qd8GfDc+hyaq/5HKPBTEdkiIl90Zc10Pi0GDgH/6m4PfltEEjRQDLM9YZy11P850vBd4EQkCfwH8CVVzVZva5YYVLWiqsvxf6mvBD5a5yrVTER+HRhU1S31rss0uEpVL8e/xXyHiFxdvbEJzqcQcDnwz6q6AshzzO2nescw2xNGzaPiNomDItIF4F4H61yfExKRMH6yeERVH3fFTRVDNVXNAM/h38JpcyMwQ2OfV2uBT4vIbvxJzq7Dv4/eLPWfoqr97nUQeAI/eTfT+bQP2Keqm9z6Y/gJpGFimO0Jo5YRdZtJ9ei/t+O3CzQkN7Pig8BOVf3Hqk1NEwOAiMwVkTb3PobfDrMTP3Hc4nZr2DhUdZ2q9qjqIvzz/1lVvY0mqf8RIpIQkdYj74FfAbbRROeTqh4A9orIR1zR9fgDsDZODPVu6Kn3AtwEvIV/3/nP612fU6j394EBoIT/y+QL+PeeNwBvA88AHfWu5wnqfxX+pfXrwFa33NRMMbg4LgVedXFsA/7SlZ+PPyR/H/AoEK13XWuI5RrgqWasv6vva27ZfuTfchOeT8uBze58+hHQ3kgx2JPexhhjajLbb0kZY4ypkSUMY4wxNbGEYYwxpiaWMIwxxtTEEoYxxpiaWMIwpgGIyDVHRoo1plFZwjDGGFMTSxjGnAIR+Zyb/2KriDzgBh7Mici9bj6MDSIy1+27XEReFJHXReSJI/MYiMhSEXnGzaHxiogscYdPVs2F8Ih7Gt6YhmEJw5gaicgFwG8Ba9UfbLAC3AYkgM2qehGwEfgr95HvAn+mqpcCb1SVPwJ8Xf05NNbgP7EP/oi9X8Kfm+V8/HGejGkYoZPvYoxxrgeuAF52P/5j+APBecAP3T7fAx4XkTTQpqobXfnDwKNuvKNuVX0CQFULAO54L6nqPre+FX++k5/PfFjG1MYShjG1E+BhVV13VKHIXxyz3+mOtzNZ9b6C/fs0DcZuSRlTuw3ALSIyD6bmiz4P/9/RkZFdPwv8XFVHgRER+bgr/zywUVXHgH0i8hvuGFERiZ/RKIw5TfYLxpgaqeoOEfkK/qxuAfyRgu/An+hmpds2iN/OAf5Q1N90CeFd4Ldd+eeBB0TkbneM3zyDYRhz2my0WmN+SSKSU9VkvethzEyzW1LGGGNqYlcYxhhjamJXGMYYY2piCcMYY0xNLGEYY4ypiSUMY4wxNbGEYYwxpiaWMIwxxtTk/wFzNj1bHb9N0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.7460 - acc: 0.7919\n",
      "Loss: 0.7460220728831622 Accuracy: 0.79190034\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9291 - acc: 0.4110\n",
      "Epoch 00001: val_loss improved from inf to 1.05946, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/001-1.0595.hdf5\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 1.9292 - acc: 0.4109 - val_loss: 1.0595 - val_acc: 0.6893\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1581 - acc: 0.6403\n",
      "Epoch 00002: val_loss improved from 1.05946 to 0.81392, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/002-0.8139.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 1.1581 - acc: 0.6403 - val_loss: 0.8139 - val_acc: 0.7575\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9250 - acc: 0.7176\n",
      "Epoch 00003: val_loss improved from 0.81392 to 0.76920, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/003-0.7692.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.9250 - acc: 0.7176 - val_loss: 0.7692 - val_acc: 0.7738\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7753 - acc: 0.7650\n",
      "Epoch 00004: val_loss improved from 0.76920 to 0.65346, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/004-0.6535.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.7754 - acc: 0.7650 - val_loss: 0.6535 - val_acc: 0.8006\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6857 - acc: 0.7919\n",
      "Epoch 00005: val_loss improved from 0.65346 to 0.58129, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/005-0.5813.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.6857 - acc: 0.7919 - val_loss: 0.5813 - val_acc: 0.8381\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6082 - acc: 0.8169\n",
      "Epoch 00006: val_loss improved from 0.58129 to 0.56671, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/006-0.5667.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.6082 - acc: 0.8169 - val_loss: 0.5667 - val_acc: 0.8477\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5542 - acc: 0.8326\n",
      "Epoch 00007: val_loss improved from 0.56671 to 0.49913, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/007-0.4991.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.5542 - acc: 0.8325 - val_loss: 0.4991 - val_acc: 0.8628\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5073 - acc: 0.8473\n",
      "Epoch 00008: val_loss improved from 0.49913 to 0.45830, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/008-0.4583.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.5072 - acc: 0.8473 - val_loss: 0.4583 - val_acc: 0.8724\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4682 - acc: 0.8590\n",
      "Epoch 00009: val_loss improved from 0.45830 to 0.43772, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/009-0.4377.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.4685 - acc: 0.8590 - val_loss: 0.4377 - val_acc: 0.8775\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4259 - acc: 0.8715\n",
      "Epoch 00010: val_loss did not improve from 0.43772\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.4259 - acc: 0.8715 - val_loss: 0.4700 - val_acc: 0.8691\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4054 - acc: 0.8767\n",
      "Epoch 00011: val_loss did not improve from 0.43772\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.4054 - acc: 0.8766 - val_loss: 0.5928 - val_acc: 0.8332\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3751 - acc: 0.8861\n",
      "Epoch 00012: val_loss improved from 0.43772 to 0.41656, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/012-0.4166.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.3751 - acc: 0.8862 - val_loss: 0.4166 - val_acc: 0.8882\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3443 - acc: 0.8956\n",
      "Epoch 00013: val_loss did not improve from 0.41656\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.3444 - acc: 0.8956 - val_loss: 0.4894 - val_acc: 0.8686\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3295 - acc: 0.8977\n",
      "Epoch 00014: val_loss did not improve from 0.41656\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.3295 - acc: 0.8977 - val_loss: 0.4767 - val_acc: 0.8728\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3081 - acc: 0.9050\n",
      "Epoch 00015: val_loss did not improve from 0.41656\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.3081 - acc: 0.9050 - val_loss: 0.4754 - val_acc: 0.8768\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2872 - acc: 0.9092\n",
      "Epoch 00016: val_loss did not improve from 0.41656\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2873 - acc: 0.9091 - val_loss: 0.5022 - val_acc: 0.8728\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2776 - acc: 0.9135\n",
      "Epoch 00017: val_loss improved from 0.41656 to 0.37128, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/017-0.3713.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2779 - acc: 0.9134 - val_loss: 0.3713 - val_acc: 0.8984\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2603 - acc: 0.9182\n",
      "Epoch 00018: val_loss did not improve from 0.37128\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2605 - acc: 0.9181 - val_loss: 0.4239 - val_acc: 0.8849\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2490 - acc: 0.9223\n",
      "Epoch 00019: val_loss improved from 0.37128 to 0.36939, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/019-0.3694.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2492 - acc: 0.9223 - val_loss: 0.3694 - val_acc: 0.9017\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2318 - acc: 0.9263\n",
      "Epoch 00020: val_loss did not improve from 0.36939\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.2318 - acc: 0.9263 - val_loss: 0.3967 - val_acc: 0.9008\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9329\n",
      "Epoch 00021: val_loss improved from 0.36939 to 0.35976, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/021-0.3598.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.2109 - acc: 0.9329 - val_loss: 0.3598 - val_acc: 0.8998\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2058 - acc: 0.9334\n",
      "Epoch 00022: val_loss did not improve from 0.35976\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.2060 - acc: 0.9334 - val_loss: 0.3905 - val_acc: 0.9005\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9357\n",
      "Epoch 00023: val_loss did not improve from 0.35976\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2059 - acc: 0.9356 - val_loss: 0.4176 - val_acc: 0.8884\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2014 - acc: 0.9354\n",
      "Epoch 00024: val_loss did not improve from 0.35976\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2014 - acc: 0.9354 - val_loss: 0.3834 - val_acc: 0.8994\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1773 - acc: 0.9415\n",
      "Epoch 00025: val_loss did not improve from 0.35976\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1773 - acc: 0.9415 - val_loss: 0.4101 - val_acc: 0.9026\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1697 - acc: 0.9447\n",
      "Epoch 00026: val_loss improved from 0.35976 to 0.35314, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_6_conv_checkpoint/026-0.3531.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1697 - acc: 0.9447 - val_loss: 0.3531 - val_acc: 0.9099\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9482\n",
      "Epoch 00027: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1636 - acc: 0.9482 - val_loss: 0.3664 - val_acc: 0.9175\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9492\n",
      "Epoch 00028: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1577 - acc: 0.9492 - val_loss: 0.4082 - val_acc: 0.8949\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9510\n",
      "Epoch 00029: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1516 - acc: 0.9510 - val_loss: 0.4186 - val_acc: 0.9038\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1418 - acc: 0.9544\n",
      "Epoch 00030: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1418 - acc: 0.9544 - val_loss: 0.3615 - val_acc: 0.9108\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9545\n",
      "Epoch 00031: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1380 - acc: 0.9545 - val_loss: 0.3949 - val_acc: 0.9003\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9580\n",
      "Epoch 00032: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1316 - acc: 0.9580 - val_loss: 0.3682 - val_acc: 0.9129\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9604\n",
      "Epoch 00033: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1252 - acc: 0.9604 - val_loss: 0.4408 - val_acc: 0.8901\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9602\n",
      "Epoch 00034: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1187 - acc: 0.9602 - val_loss: 0.3712 - val_acc: 0.9101\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9628\n",
      "Epoch 00035: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1136 - acc: 0.9628 - val_loss: 0.3993 - val_acc: 0.9052\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9605\n",
      "Epoch 00036: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1193 - acc: 0.9605 - val_loss: 0.4563 - val_acc: 0.8994\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9639\n",
      "Epoch 00037: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1090 - acc: 0.9638 - val_loss: 0.4232 - val_acc: 0.9101\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9645\n",
      "Epoch 00038: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1081 - acc: 0.9645 - val_loss: 0.4297 - val_acc: 0.9080\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9662\n",
      "Epoch 00039: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1039 - acc: 0.9662 - val_loss: 0.4379 - val_acc: 0.8961\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9677\n",
      "Epoch 00040: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0964 - acc: 0.9677 - val_loss: 0.4169 - val_acc: 0.9054\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9712\n",
      "Epoch 00041: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0892 - acc: 0.9713 - val_loss: 0.3970 - val_acc: 0.9106\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9704\n",
      "Epoch 00042: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0892 - acc: 0.9704 - val_loss: 0.4155 - val_acc: 0.9085\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.9721\n",
      "Epoch 00043: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0883 - acc: 0.9720 - val_loss: 0.4337 - val_acc: 0.9071\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9696\n",
      "Epoch 00044: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0955 - acc: 0.9695 - val_loss: 0.5301 - val_acc: 0.8898\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9692\n",
      "Epoch 00045: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0942 - acc: 0.9691 - val_loss: 0.4178 - val_acc: 0.9110\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9712\n",
      "Epoch 00046: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0902 - acc: 0.9713 - val_loss: 0.3827 - val_acc: 0.9164\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9771\n",
      "Epoch 00047: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0717 - acc: 0.9771 - val_loss: 0.4707 - val_acc: 0.9008\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9754\n",
      "Epoch 00048: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0744 - acc: 0.9753 - val_loss: 0.4045 - val_acc: 0.9117\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9714\n",
      "Epoch 00049: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0848 - acc: 0.9714 - val_loss: 0.3625 - val_acc: 0.9220\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9735\n",
      "Epoch 00050: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0836 - acc: 0.9735 - val_loss: 0.3686 - val_acc: 0.9201\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9777\n",
      "Epoch 00051: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0696 - acc: 0.9777 - val_loss: 0.4087 - val_acc: 0.9143\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9721\n",
      "Epoch 00052: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0893 - acc: 0.9722 - val_loss: 0.4363 - val_acc: 0.9052\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9796\n",
      "Epoch 00053: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0615 - acc: 0.9796 - val_loss: 0.3781 - val_acc: 0.9173\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9779\n",
      "Epoch 00054: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0654 - acc: 0.9779 - val_loss: 0.4342 - val_acc: 0.9050\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9768\n",
      "Epoch 00055: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0729 - acc: 0.9767 - val_loss: 0.3958 - val_acc: 0.9187\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9771\n",
      "Epoch 00056: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0718 - acc: 0.9771 - val_loss: 0.3861 - val_acc: 0.9192\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9815\n",
      "Epoch 00057: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0575 - acc: 0.9815 - val_loss: 0.3859 - val_acc: 0.9178\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9814\n",
      "Epoch 00058: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0572 - acc: 0.9814 - val_loss: 0.3977 - val_acc: 0.9189\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9824\n",
      "Epoch 00059: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0553 - acc: 0.9823 - val_loss: 0.4399 - val_acc: 0.9173\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9776\n",
      "Epoch 00060: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0709 - acc: 0.9775 - val_loss: 0.4644 - val_acc: 0.9087\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9800\n",
      "Epoch 00061: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0624 - acc: 0.9800 - val_loss: 0.4700 - val_acc: 0.9115\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9849\n",
      "Epoch 00062: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0487 - acc: 0.9849 - val_loss: 0.4393 - val_acc: 0.9110\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9842\n",
      "Epoch 00063: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0507 - acc: 0.9842 - val_loss: 0.4072 - val_acc: 0.9201\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9787\n",
      "Epoch 00064: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0665 - acc: 0.9787 - val_loss: 0.3915 - val_acc: 0.9180\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9830\n",
      "Epoch 00065: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0541 - acc: 0.9830 - val_loss: 0.3960 - val_acc: 0.9208\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9825\n",
      "Epoch 00066: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0563 - acc: 0.9825 - val_loss: 0.4361 - val_acc: 0.9080\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9832\n",
      "Epoch 00067: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0558 - acc: 0.9832 - val_loss: 0.4530 - val_acc: 0.9061\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9841\n",
      "Epoch 00068: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0545 - acc: 0.9841 - val_loss: 0.4143 - val_acc: 0.9182\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9863\n",
      "Epoch 00069: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0420 - acc: 0.9863 - val_loss: 0.4191 - val_acc: 0.9196\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9858\n",
      "Epoch 00070: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0435 - acc: 0.9858 - val_loss: 0.4292 - val_acc: 0.9136\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9842\n",
      "Epoch 00071: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0485 - acc: 0.9842 - val_loss: 0.4829 - val_acc: 0.9040\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9813\n",
      "Epoch 00072: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0607 - acc: 0.9813 - val_loss: 0.3740 - val_acc: 0.9231\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9882\n",
      "Epoch 00073: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0379 - acc: 0.9882 - val_loss: 0.4375 - val_acc: 0.9099\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9865\n",
      "Epoch 00074: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.0431 - acc: 0.9865 - val_loss: 0.4175 - val_acc: 0.9178\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9862\n",
      "Epoch 00075: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0438 - acc: 0.9861 - val_loss: 0.5355 - val_acc: 0.9003\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9812\n",
      "Epoch 00076: val_loss did not improve from 0.35314\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0595 - acc: 0.9812 - val_loss: 0.5145 - val_acc: 0.9071\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.4125 - acc: 0.8891\n",
      "Loss: 0.4124893016037787 Accuracy: 0.88909656\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9654 - acc: 0.4007\n",
      "Epoch 00001: val_loss improved from inf to 1.13805, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/001-1.1380.hdf5\n",
      "36805/36805 [==============================] - 190s 5ms/sample - loss: 1.9654 - acc: 0.4007 - val_loss: 1.1380 - val_acc: 0.6478\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0680 - acc: 0.6664\n",
      "Epoch 00002: val_loss improved from 1.13805 to 0.69274, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/002-0.6927.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 1.0679 - acc: 0.6664 - val_loss: 0.6927 - val_acc: 0.8001\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7787 - acc: 0.7608\n",
      "Epoch 00003: val_loss improved from 0.69274 to 0.54919, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/003-0.5492.hdf5\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.7788 - acc: 0.7607 - val_loss: 0.5492 - val_acc: 0.8463\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6240 - acc: 0.8124\n",
      "Epoch 00004: val_loss improved from 0.54919 to 0.49154, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/004-0.4915.hdf5\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.6240 - acc: 0.8124 - val_loss: 0.4915 - val_acc: 0.8614\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5228 - acc: 0.8424\n",
      "Epoch 00005: val_loss improved from 0.49154 to 0.38428, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/005-0.3843.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.5227 - acc: 0.8424 - val_loss: 0.3843 - val_acc: 0.8989\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4477 - acc: 0.8649\n",
      "Epoch 00006: val_loss improved from 0.38428 to 0.34861, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/006-0.3486.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.4477 - acc: 0.8649 - val_loss: 0.3486 - val_acc: 0.9031\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4013 - acc: 0.8775\n",
      "Epoch 00007: val_loss improved from 0.34861 to 0.32018, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/007-0.3202.hdf5\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.4014 - acc: 0.8774 - val_loss: 0.3202 - val_acc: 0.9124\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3565 - acc: 0.8911\n",
      "Epoch 00008: val_loss improved from 0.32018 to 0.27567, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/008-0.2757.hdf5\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.3566 - acc: 0.8911 - val_loss: 0.2757 - val_acc: 0.9285\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3217 - acc: 0.9005\n",
      "Epoch 00009: val_loss did not improve from 0.27567\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.3218 - acc: 0.9005 - val_loss: 0.3186 - val_acc: 0.9113\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2929 - acc: 0.9105\n",
      "Epoch 00010: val_loss improved from 0.27567 to 0.26962, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/010-0.2696.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.2930 - acc: 0.9105 - val_loss: 0.2696 - val_acc: 0.9252\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2721 - acc: 0.9158\n",
      "Epoch 00011: val_loss did not improve from 0.26962\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.2722 - acc: 0.9157 - val_loss: 0.3542 - val_acc: 0.9106\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2511 - acc: 0.9225\n",
      "Epoch 00012: val_loss did not improve from 0.26962\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.2512 - acc: 0.9225 - val_loss: 0.2732 - val_acc: 0.9210\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2323 - acc: 0.9285\n",
      "Epoch 00013: val_loss improved from 0.26962 to 0.24583, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/013-0.2458.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.2322 - acc: 0.9285 - val_loss: 0.2458 - val_acc: 0.9324\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2065 - acc: 0.9365\n",
      "Epoch 00014: val_loss improved from 0.24583 to 0.23488, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/014-0.2349.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.2065 - acc: 0.9365 - val_loss: 0.2349 - val_acc: 0.9348\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1966 - acc: 0.9383\n",
      "Epoch 00015: val_loss did not improve from 0.23488\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.1967 - acc: 0.9382 - val_loss: 0.2542 - val_acc: 0.9366\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1888 - acc: 0.9410\n",
      "Epoch 00016: val_loss improved from 0.23488 to 0.22937, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/016-0.2294.hdf5\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.1889 - acc: 0.9409 - val_loss: 0.2294 - val_acc: 0.9352\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1761 - acc: 0.9444\n",
      "Epoch 00017: val_loss improved from 0.22937 to 0.21381, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/017-0.2138.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1761 - acc: 0.9444 - val_loss: 0.2138 - val_acc: 0.9411\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9497\n",
      "Epoch 00018: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1605 - acc: 0.9497 - val_loss: 0.2276 - val_acc: 0.9399\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9504\n",
      "Epoch 00019: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1552 - acc: 0.9503 - val_loss: 0.2426 - val_acc: 0.9357\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9532\n",
      "Epoch 00020: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.1458 - acc: 0.9532 - val_loss: 0.2365 - val_acc: 0.9378\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9558\n",
      "Epoch 00021: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1425 - acc: 0.9558 - val_loss: 0.2359 - val_acc: 0.9387\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9595\n",
      "Epoch 00022: val_loss improved from 0.21381 to 0.20371, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/022-0.2037.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1250 - acc: 0.9595 - val_loss: 0.2037 - val_acc: 0.9443\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9594\n",
      "Epoch 00023: val_loss improved from 0.20371 to 0.20060, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/023-0.2006.hdf5\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.1249 - acc: 0.9594 - val_loss: 0.2006 - val_acc: 0.9490\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9633\n",
      "Epoch 00024: val_loss did not improve from 0.20060\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.1130 - acc: 0.9632 - val_loss: 0.2850 - val_acc: 0.9299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9609\n",
      "Epoch 00025: val_loss did not improve from 0.20060\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1220 - acc: 0.9609 - val_loss: 0.2344 - val_acc: 0.9390\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9649\n",
      "Epoch 00026: val_loss did not improve from 0.20060\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1079 - acc: 0.9649 - val_loss: 0.2077 - val_acc: 0.9474\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9683\n",
      "Epoch 00027: val_loss did not improve from 0.20060\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0978 - acc: 0.9683 - val_loss: 0.2316 - val_acc: 0.9434\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9706\n",
      "Epoch 00028: val_loss did not improve from 0.20060\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0963 - acc: 0.9705 - val_loss: 0.2186 - val_acc: 0.9462\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9684\n",
      "Epoch 00029: val_loss did not improve from 0.20060\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0995 - acc: 0.9684 - val_loss: 0.2203 - val_acc: 0.9450\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9724\n",
      "Epoch 00030: val_loss did not improve from 0.20060\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0850 - acc: 0.9724 - val_loss: 0.2420 - val_acc: 0.9355\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9741\n",
      "Epoch 00031: val_loss did not improve from 0.20060\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0826 - acc: 0.9741 - val_loss: 0.2383 - val_acc: 0.9432\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9733\n",
      "Epoch 00032: val_loss did not improve from 0.20060\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0846 - acc: 0.9733 - val_loss: 0.2563 - val_acc: 0.9399\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9747\n",
      "Epoch 00033: val_loss improved from 0.20060 to 0.19710, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/033-0.1971.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0773 - acc: 0.9747 - val_loss: 0.1971 - val_acc: 0.9506\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9748\n",
      "Epoch 00034: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0749 - acc: 0.9748 - val_loss: 0.2545 - val_acc: 0.9397\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9785\n",
      "Epoch 00035: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0687 - acc: 0.9785 - val_loss: 0.2207 - val_acc: 0.9513\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9770\n",
      "Epoch 00036: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0713 - acc: 0.9770 - val_loss: 0.2574 - val_acc: 0.9373\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9780\n",
      "Epoch 00037: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0680 - acc: 0.9780 - val_loss: 0.2000 - val_acc: 0.9504\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9787\n",
      "Epoch 00038: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0637 - acc: 0.9786 - val_loss: 0.2060 - val_acc: 0.9520\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9775\n",
      "Epoch 00039: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0679 - acc: 0.9775 - val_loss: 0.2048 - val_acc: 0.9511\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9837\n",
      "Epoch 00040: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0508 - acc: 0.9837 - val_loss: 0.2124 - val_acc: 0.9485\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9825\n",
      "Epoch 00041: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0538 - acc: 0.9825 - val_loss: 0.2047 - val_acc: 0.9502\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9837\n",
      "Epoch 00042: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0507 - acc: 0.9837 - val_loss: 0.2098 - val_acc: 0.9434\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9829\n",
      "Epoch 00043: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0531 - acc: 0.9829 - val_loss: 0.2045 - val_acc: 0.9534\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9835\n",
      "Epoch 00044: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0512 - acc: 0.9835 - val_loss: 0.2016 - val_acc: 0.9532\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9866\n",
      "Epoch 00045: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0439 - acc: 0.9866 - val_loss: 0.1997 - val_acc: 0.9520\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9835\n",
      "Epoch 00046: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0502 - acc: 0.9834 - val_loss: 0.2201 - val_acc: 0.9462\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9834\n",
      "Epoch 00047: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0519 - acc: 0.9834 - val_loss: 0.2148 - val_acc: 0.9527\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9872\n",
      "Epoch 00048: val_loss did not improve from 0.19710\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0394 - acc: 0.9872 - val_loss: 0.2244 - val_acc: 0.9518\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9876\n",
      "Epoch 00049: val_loss improved from 0.19710 to 0.19339, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/049-0.1934.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0382 - acc: 0.9876 - val_loss: 0.1934 - val_acc: 0.9539\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9882\n",
      "Epoch 00050: val_loss improved from 0.19339 to 0.19287, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/050-0.1929.hdf5\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0358 - acc: 0.9882 - val_loss: 0.1929 - val_acc: 0.9567\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9875\n",
      "Epoch 00051: val_loss did not improve from 0.19287\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0386 - acc: 0.9875 - val_loss: 0.2021 - val_acc: 0.9541\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9851\n",
      "Epoch 00052: val_loss did not improve from 0.19287\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0464 - acc: 0.9851 - val_loss: 0.2417 - val_acc: 0.9474\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9881\n",
      "Epoch 00053: val_loss did not improve from 0.19287\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0355 - acc: 0.9881 - val_loss: 0.2202 - val_acc: 0.9485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9845\n",
      "Epoch 00054: val_loss did not improve from 0.19287\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0501 - acc: 0.9845 - val_loss: 0.1992 - val_acc: 0.9543\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9887\n",
      "Epoch 00055: val_loss did not improve from 0.19287\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0370 - acc: 0.9887 - val_loss: 0.2148 - val_acc: 0.9518\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9899\n",
      "Epoch 00056: val_loss did not improve from 0.19287\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0320 - acc: 0.9899 - val_loss: 0.2059 - val_acc: 0.9569\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9892\n",
      "Epoch 00057: val_loss did not improve from 0.19287\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0336 - acc: 0.9892 - val_loss: 0.2593 - val_acc: 0.9464\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9864\n",
      "Epoch 00058: val_loss did not improve from 0.19287\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0431 - acc: 0.9864 - val_loss: 0.2014 - val_acc: 0.9532\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9922\n",
      "Epoch 00059: val_loss did not improve from 0.19287\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0260 - acc: 0.9922 - val_loss: 0.2479 - val_acc: 0.9478\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9883\n",
      "Epoch 00060: val_loss did not improve from 0.19287\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0365 - acc: 0.9883 - val_loss: 0.2064 - val_acc: 0.9555\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9921\n",
      "Epoch 00061: val_loss did not improve from 0.19287\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0258 - acc: 0.9920 - val_loss: 0.2213 - val_acc: 0.9534\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9874\n",
      "Epoch 00062: val_loss did not improve from 0.19287\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0377 - acc: 0.9874 - val_loss: 0.2157 - val_acc: 0.9534\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9888\n",
      "Epoch 00063: val_loss improved from 0.19287 to 0.19131, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_7_conv_checkpoint/063-0.1913.hdf5\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0353 - acc: 0.9888 - val_loss: 0.1913 - val_acc: 0.9590\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9907\n",
      "Epoch 00064: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0289 - acc: 0.9907 - val_loss: 0.2642 - val_acc: 0.9453\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9902\n",
      "Epoch 00065: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0323 - acc: 0.9902 - val_loss: 0.2322 - val_acc: 0.9536\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9899\n",
      "Epoch 00066: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0314 - acc: 0.9898 - val_loss: 0.2345 - val_acc: 0.9506\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9915\n",
      "Epoch 00067: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0279 - acc: 0.9915 - val_loss: 0.2295 - val_acc: 0.9527\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9902\n",
      "Epoch 00068: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0315 - acc: 0.9901 - val_loss: 0.2217 - val_acc: 0.9550\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9909\n",
      "Epoch 00069: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0301 - acc: 0.9908 - val_loss: 0.2129 - val_acc: 0.9550\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9878\n",
      "Epoch 00070: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0392 - acc: 0.9878 - val_loss: 0.2016 - val_acc: 0.9564\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9936\n",
      "Epoch 00071: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0202 - acc: 0.9936 - val_loss: 0.2130 - val_acc: 0.9567\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9930\n",
      "Epoch 00072: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0221 - acc: 0.9930 - val_loss: 0.2314 - val_acc: 0.9518\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9890\n",
      "Epoch 00073: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0361 - acc: 0.9890 - val_loss: 0.2562 - val_acc: 0.9457\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9938\n",
      "Epoch 00074: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0205 - acc: 0.9938 - val_loss: 0.2082 - val_acc: 0.9546\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9912\n",
      "Epoch 00075: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0292 - acc: 0.9912 - val_loss: 0.2128 - val_acc: 0.9518\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9920\n",
      "Epoch 00076: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0248 - acc: 0.9920 - val_loss: 0.2383 - val_acc: 0.9502\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9925\n",
      "Epoch 00077: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0227 - acc: 0.9925 - val_loss: 0.2401 - val_acc: 0.9550\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9928\n",
      "Epoch 00078: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0234 - acc: 0.9928 - val_loss: 0.2164 - val_acc: 0.9581\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9935\n",
      "Epoch 00079: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0205 - acc: 0.9935 - val_loss: 0.2455 - val_acc: 0.9506\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9914\n",
      "Epoch 00080: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0258 - acc: 0.9913 - val_loss: 0.2424 - val_acc: 0.9502\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9928\n",
      "Epoch 00081: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0233 - acc: 0.9927 - val_loss: 0.2418 - val_acc: 0.9483\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9908\n",
      "Epoch 00082: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0293 - acc: 0.9907 - val_loss: 0.2110 - val_acc: 0.9541\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9920\n",
      "Epoch 00083: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0255 - acc: 0.9920 - val_loss: 0.2145 - val_acc: 0.9590\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9947\n",
      "Epoch 00084: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0165 - acc: 0.9947 - val_loss: 0.2144 - val_acc: 0.9569\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9948\n",
      "Epoch 00085: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0173 - acc: 0.9948 - val_loss: 0.2349 - val_acc: 0.9518\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9941\n",
      "Epoch 00086: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0186 - acc: 0.9941 - val_loss: 0.2207 - val_acc: 0.9522\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9908\n",
      "Epoch 00087: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0291 - acc: 0.9907 - val_loss: 0.2520 - val_acc: 0.9502\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9918\n",
      "Epoch 00088: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0265 - acc: 0.9918 - val_loss: 0.2175 - val_acc: 0.9560\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9957\n",
      "Epoch 00089: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0144 - acc: 0.9957 - val_loss: 0.1951 - val_acc: 0.9611\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9952\n",
      "Epoch 00090: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0159 - acc: 0.9952 - val_loss: 0.2067 - val_acc: 0.9588\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9957\n",
      "Epoch 00091: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0158 - acc: 0.9957 - val_loss: 0.2424 - val_acc: 0.9543\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9940\n",
      "Epoch 00092: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0202 - acc: 0.9940 - val_loss: 0.2116 - val_acc: 0.9585\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9939\n",
      "Epoch 00093: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0186 - acc: 0.9939 - val_loss: 0.2504 - val_acc: 0.9506\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9951\n",
      "Epoch 00094: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0156 - acc: 0.9951 - val_loss: 0.2166 - val_acc: 0.9571\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9943\n",
      "Epoch 00095: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0168 - acc: 0.9943 - val_loss: 0.3141 - val_acc: 0.9343\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9929\n",
      "Epoch 00096: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0235 - acc: 0.9929 - val_loss: 0.2594 - val_acc: 0.9511\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9957\n",
      "Epoch 00097: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0140 - acc: 0.9957 - val_loss: 0.2300 - val_acc: 0.9525\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9955\n",
      "Epoch 00098: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0145 - acc: 0.9954 - val_loss: 0.3051 - val_acc: 0.9401\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9925\n",
      "Epoch 00099: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0241 - acc: 0.9925 - val_loss: 0.2692 - val_acc: 0.9485\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9919\n",
      "Epoch 00100: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0246 - acc: 0.9919 - val_loss: 0.2515 - val_acc: 0.9543\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9937\n",
      "Epoch 00101: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0196 - acc: 0.9937 - val_loss: 0.2196 - val_acc: 0.9567\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9966\n",
      "Epoch 00102: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0106 - acc: 0.9966 - val_loss: 0.2751 - val_acc: 0.9481\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9959\n",
      "Epoch 00103: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0131 - acc: 0.9959 - val_loss: 0.2310 - val_acc: 0.9599\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9957\n",
      "Epoch 00104: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0138 - acc: 0.9957 - val_loss: 0.2467 - val_acc: 0.9576\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9945\n",
      "Epoch 00105: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0176 - acc: 0.9945 - val_loss: 0.2317 - val_acc: 0.9557\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9948\n",
      "Epoch 00106: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0166 - acc: 0.9948 - val_loss: 0.2312 - val_acc: 0.9578\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9957\n",
      "Epoch 00107: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0135 - acc: 0.9957 - val_loss: 0.2961 - val_acc: 0.9436\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9953\n",
      "Epoch 00108: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0147 - acc: 0.9953 - val_loss: 0.2684 - val_acc: 0.9513\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9923\n",
      "Epoch 00109: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0247 - acc: 0.9922 - val_loss: 0.2386 - val_acc: 0.9499\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9939\n",
      "Epoch 00110: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0191 - acc: 0.9939 - val_loss: 0.1971 - val_acc: 0.9581\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9957\n",
      "Epoch 00111: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0143 - acc: 0.9957 - val_loss: 0.2381 - val_acc: 0.9536\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9967\n",
      "Epoch 00112: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0111 - acc: 0.9966 - val_loss: 0.2498 - val_acc: 0.9522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9956\n",
      "Epoch 00113: val_loss did not improve from 0.19131\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0150 - acc: 0.9956 - val_loss: 0.2291 - val_acc: 0.9585\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.2200 - acc: 0.9477\n",
      "Loss: 0.21995471964125074 Accuracy: 0.94766355\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7818 - acc: 0.4594\n",
      "Epoch 00001: val_loss improved from inf to 0.85323, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/001-0.8532.hdf5\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 1.7818 - acc: 0.4594 - val_loss: 0.8532 - val_acc: 0.7489\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8436 - acc: 0.7397\n",
      "Epoch 00002: val_loss improved from 0.85323 to 0.45377, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/002-0.4538.hdf5\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.8438 - acc: 0.7397 - val_loss: 0.4538 - val_acc: 0.8749\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5914 - acc: 0.8187\n",
      "Epoch 00003: val_loss improved from 0.45377 to 0.40569, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/003-0.4057.hdf5\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 0.5915 - acc: 0.8186 - val_loss: 0.4057 - val_acc: 0.8810\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4504 - acc: 0.8619\n",
      "Epoch 00004: val_loss improved from 0.40569 to 0.28470, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/004-0.2847.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.4504 - acc: 0.8619 - val_loss: 0.2847 - val_acc: 0.9192\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3748 - acc: 0.8857\n",
      "Epoch 00005: val_loss improved from 0.28470 to 0.26790, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/005-0.2679.hdf5\n",
      "36805/36805 [==============================] - 187s 5ms/sample - loss: 0.3748 - acc: 0.8857 - val_loss: 0.2679 - val_acc: 0.9196\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3241 - acc: 0.9007\n",
      "Epoch 00006: val_loss did not improve from 0.26790\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.3242 - acc: 0.9007 - val_loss: 0.3039 - val_acc: 0.9136\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2889 - acc: 0.9105\n",
      "Epoch 00007: val_loss improved from 0.26790 to 0.22224, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/007-0.2222.hdf5\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 0.2890 - acc: 0.9105 - val_loss: 0.2222 - val_acc: 0.9406\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2561 - acc: 0.9208\n",
      "Epoch 00008: val_loss improved from 0.22224 to 0.19750, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/008-0.1975.hdf5\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.2561 - acc: 0.9208 - val_loss: 0.1975 - val_acc: 0.9457\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9314\n",
      "Epoch 00009: val_loss did not improve from 0.19750\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 0.2198 - acc: 0.9313 - val_loss: 0.2507 - val_acc: 0.9336\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2062 - acc: 0.9352\n",
      "Epoch 00010: val_loss did not improve from 0.19750\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.2063 - acc: 0.9352 - val_loss: 0.1991 - val_acc: 0.9446\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9419\n",
      "Epoch 00011: val_loss did not improve from 0.19750\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1845 - acc: 0.9419 - val_loss: 0.2011 - val_acc: 0.9464\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1685 - acc: 0.9464\n",
      "Epoch 00012: val_loss did not improve from 0.19750\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.1689 - acc: 0.9463 - val_loss: 0.2019 - val_acc: 0.9427\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9488\n",
      "Epoch 00013: val_loss improved from 0.19750 to 0.15324, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/013-0.1532.hdf5\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 0.1634 - acc: 0.9488 - val_loss: 0.1532 - val_acc: 0.9555\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9535\n",
      "Epoch 00014: val_loss improved from 0.15324 to 0.14512, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/014-0.1451.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1454 - acc: 0.9535 - val_loss: 0.1451 - val_acc: 0.9585\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9598\n",
      "Epoch 00015: val_loss did not improve from 0.14512\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.1277 - acc: 0.9598 - val_loss: 0.1472 - val_acc: 0.9578\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9593\n",
      "Epoch 00016: val_loss did not improve from 0.14512\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1272 - acc: 0.9594 - val_loss: 0.1531 - val_acc: 0.9590\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9630\n",
      "Epoch 00017: val_loss improved from 0.14512 to 0.13672, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/017-0.1367.hdf5\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.1135 - acc: 0.9630 - val_loss: 0.1367 - val_acc: 0.9588\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9649\n",
      "Epoch 00018: val_loss improved from 0.13672 to 0.12979, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/018-0.1298.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1087 - acc: 0.9649 - val_loss: 0.1298 - val_acc: 0.9648\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9690\n",
      "Epoch 00019: val_loss did not improve from 0.12979\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.0990 - acc: 0.9689 - val_loss: 0.1520 - val_acc: 0.9569\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9690\n",
      "Epoch 00020: val_loss did not improve from 0.12979\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0949 - acc: 0.9689 - val_loss: 0.1666 - val_acc: 0.9502\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9705\n",
      "Epoch 00021: val_loss did not improve from 0.12979\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0957 - acc: 0.9705 - val_loss: 0.1473 - val_acc: 0.9639\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9730\n",
      "Epoch 00022: val_loss did not improve from 0.12979\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0824 - acc: 0.9730 - val_loss: 0.1422 - val_acc: 0.9637\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9745\n",
      "Epoch 00023: val_loss did not improve from 0.12979\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 0.0771 - acc: 0.9745 - val_loss: 0.1556 - val_acc: 0.9574\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9776\n",
      "Epoch 00024: val_loss did not improve from 0.12979\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0712 - acc: 0.9775 - val_loss: 0.1414 - val_acc: 0.9644\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9756\n",
      "Epoch 00025: val_loss did not improve from 0.12979\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.0748 - acc: 0.9756 - val_loss: 0.1308 - val_acc: 0.9655\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9807\n",
      "Epoch 00026: val_loss did not improve from 0.12979\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0616 - acc: 0.9807 - val_loss: 0.1803 - val_acc: 0.9506\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9812\n",
      "Epoch 00027: val_loss improved from 0.12979 to 0.12572, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/027-0.1257.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0593 - acc: 0.9812 - val_loss: 0.1257 - val_acc: 0.9683\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9821\n",
      "Epoch 00028: val_loss did not improve from 0.12572\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0557 - acc: 0.9821 - val_loss: 0.1695 - val_acc: 0.9588\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9839\n",
      "Epoch 00029: val_loss did not improve from 0.12572\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 0.0536 - acc: 0.9838 - val_loss: 0.1663 - val_acc: 0.9548\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9777\n",
      "Epoch 00030: val_loss did not improve from 0.12572\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0659 - acc: 0.9777 - val_loss: 0.1539 - val_acc: 0.9606\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9826\n",
      "Epoch 00031: val_loss did not improve from 0.12572\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0552 - acc: 0.9826 - val_loss: 0.1817 - val_acc: 0.9560\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9866\n",
      "Epoch 00032: val_loss did not improve from 0.12572\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0436 - acc: 0.9866 - val_loss: 0.1588 - val_acc: 0.9609\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9884\n",
      "Epoch 00033: val_loss did not improve from 0.12572\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 0.0392 - acc: 0.9884 - val_loss: 0.1745 - val_acc: 0.9599\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9812\n",
      "Epoch 00034: val_loss did not improve from 0.12572\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0591 - acc: 0.9812 - val_loss: 0.1385 - val_acc: 0.9639\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9868\n",
      "Epoch 00035: val_loss improved from 0.12572 to 0.11743, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/035-0.1174.hdf5\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.0415 - acc: 0.9868 - val_loss: 0.1174 - val_acc: 0.9688\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9884\n",
      "Epoch 00036: val_loss did not improve from 0.11743\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0366 - acc: 0.9884 - val_loss: 0.1416 - val_acc: 0.9660\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9895\n",
      "Epoch 00037: val_loss did not improve from 0.11743\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0342 - acc: 0.9894 - val_loss: 0.1357 - val_acc: 0.9630\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9855\n",
      "Epoch 00038: val_loss improved from 0.11743 to 0.11675, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_8_conv_checkpoint/038-0.1167.hdf5\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0446 - acc: 0.9854 - val_loss: 0.1167 - val_acc: 0.9688\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9880\n",
      "Epoch 00039: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 0.0381 - acc: 0.9880 - val_loss: 0.1438 - val_acc: 0.9639\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9887\n",
      "Epoch 00040: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0346 - acc: 0.9887 - val_loss: 0.1374 - val_acc: 0.9688\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9911\n",
      "Epoch 00041: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.0285 - acc: 0.9911 - val_loss: 0.1585 - val_acc: 0.9571\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9885\n",
      "Epoch 00042: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0382 - acc: 0.9885 - val_loss: 0.1540 - val_acc: 0.9630\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9925\n",
      "Epoch 00043: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0246 - acc: 0.9924 - val_loss: 0.1602 - val_acc: 0.9637\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9904\n",
      "Epoch 00044: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0304 - acc: 0.9904 - val_loss: 0.1342 - val_acc: 0.9686\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9902\n",
      "Epoch 00045: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.0323 - acc: 0.9902 - val_loss: 0.1576 - val_acc: 0.9625\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9948\n",
      "Epoch 00046: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0190 - acc: 0.9948 - val_loss: 0.1338 - val_acc: 0.9655\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9928\n",
      "Epoch 00047: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0234 - acc: 0.9928 - val_loss: 0.1703 - val_acc: 0.9583\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9897\n",
      "Epoch 00048: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0325 - acc: 0.9897 - val_loss: 0.1363 - val_acc: 0.9641\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9919\n",
      "Epoch 00049: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0254 - acc: 0.9919 - val_loss: 0.1446 - val_acc: 0.9672\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9942\n",
      "Epoch 00050: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0201 - acc: 0.9942 - val_loss: 0.1398 - val_acc: 0.9688\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9939\n",
      "Epoch 00051: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.0205 - acc: 0.9939 - val_loss: 0.1531 - val_acc: 0.9625\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9904\n",
      "Epoch 00052: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0301 - acc: 0.9904 - val_loss: 0.1506 - val_acc: 0.9627\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9915\n",
      "Epoch 00053: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0278 - acc: 0.9915 - val_loss: 0.1610 - val_acc: 0.9655\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9947\n",
      "Epoch 00054: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0176 - acc: 0.9947 - val_loss: 0.1502 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9949\n",
      "Epoch 00055: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0166 - acc: 0.9949 - val_loss: 0.1561 - val_acc: 0.9634\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9926\n",
      "Epoch 00056: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0235 - acc: 0.9926 - val_loss: 0.1954 - val_acc: 0.9525\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9900\n",
      "Epoch 00057: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 0.0325 - acc: 0.9900 - val_loss: 0.1341 - val_acc: 0.9667\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9915\n",
      "Epoch 00058: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0258 - acc: 0.9915 - val_loss: 0.1357 - val_acc: 0.9667\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9959\n",
      "Epoch 00059: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0142 - acc: 0.9959 - val_loss: 0.1286 - val_acc: 0.9690\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9927\n",
      "Epoch 00060: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0239 - acc: 0.9927 - val_loss: 0.2030 - val_acc: 0.9644\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9952\n",
      "Epoch 00061: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 0.0161 - acc: 0.9952 - val_loss: 0.1390 - val_acc: 0.9697\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9962\n",
      "Epoch 00062: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0129 - acc: 0.9963 - val_loss: 0.2211 - val_acc: 0.9581\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9955\n",
      "Epoch 00063: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0146 - acc: 0.9955 - val_loss: 0.1608 - val_acc: 0.9658\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9946\n",
      "Epoch 00064: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0168 - acc: 0.9946 - val_loss: 0.1459 - val_acc: 0.9669\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9948\n",
      "Epoch 00065: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 0.0165 - acc: 0.9948 - val_loss: 0.1522 - val_acc: 0.9672\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9900\n",
      "Epoch 00066: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0321 - acc: 0.9900 - val_loss: 0.1342 - val_acc: 0.9718\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9971\n",
      "Epoch 00067: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0102 - acc: 0.9971 - val_loss: 0.1560 - val_acc: 0.9639\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9970\n",
      "Epoch 00068: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0108 - acc: 0.9970 - val_loss: 0.1218 - val_acc: 0.9709\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9962\n",
      "Epoch 00069: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.0117 - acc: 0.9962 - val_loss: 0.1606 - val_acc: 0.9641\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9937\n",
      "Epoch 00070: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 181s 5ms/sample - loss: 0.0195 - acc: 0.9937 - val_loss: 0.1585 - val_acc: 0.9627\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9951\n",
      "Epoch 00071: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0158 - acc: 0.9951 - val_loss: 0.1204 - val_acc: 0.9725\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9968\n",
      "Epoch 00072: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 0.0105 - acc: 0.9968 - val_loss: 0.1528 - val_acc: 0.9695\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9958\n",
      "Epoch 00073: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.0130 - acc: 0.9958 - val_loss: 0.1647 - val_acc: 0.9592\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9930\n",
      "Epoch 00074: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0231 - acc: 0.9929 - val_loss: 0.1405 - val_acc: 0.9658\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9955\n",
      "Epoch 00075: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.0144 - acc: 0.9955 - val_loss: 0.1422 - val_acc: 0.9683\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9974\n",
      "Epoch 00076: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0098 - acc: 0.9974 - val_loss: 0.1442 - val_acc: 0.9697\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9974\n",
      "Epoch 00077: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0092 - acc: 0.9974 - val_loss: 0.1694 - val_acc: 0.9658\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9949\n",
      "Epoch 00078: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0165 - acc: 0.9949 - val_loss: 0.1527 - val_acc: 0.9667\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9964\n",
      "Epoch 00079: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.0114 - acc: 0.9964 - val_loss: 0.2026 - val_acc: 0.9588\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9970\n",
      "Epoch 00080: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0105 - acc: 0.9970 - val_loss: 0.1636 - val_acc: 0.9672\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9961\n",
      "Epoch 00081: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0117 - acc: 0.9961 - val_loss: 0.2135 - val_acc: 0.9602\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9963\n",
      "Epoch 00082: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.0118 - acc: 0.9963 - val_loss: 0.1540 - val_acc: 0.9660\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9962\n",
      "Epoch 00083: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0120 - acc: 0.9962 - val_loss: 0.1693 - val_acc: 0.9646\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9976\n",
      "Epoch 00084: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0083 - acc: 0.9976 - val_loss: 0.1687 - val_acc: 0.9641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9937\n",
      "Epoch 00085: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0217 - acc: 0.9937 - val_loss: 0.1446 - val_acc: 0.9688\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9957\n",
      "Epoch 00086: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 0.0155 - acc: 0.9956 - val_loss: 0.1955 - val_acc: 0.9639\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9950\n",
      "Epoch 00087: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 0.0157 - acc: 0.9949 - val_loss: 0.1566 - val_acc: 0.9665\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9966\n",
      "Epoch 00088: val_loss did not improve from 0.11675\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0118 - acc: 0.9966 - val_loss: 0.1516 - val_acc: 0.9674\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.1543 - acc: 0.9585\n",
      "Loss: 0.15429694436660746 Accuracy: 0.95846313\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3547 - acc: 0.5981\n",
      "Epoch 00001: val_loss improved from inf to 0.43562, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_9_conv_checkpoint/001-0.4356.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 1.3547 - acc: 0.5980 - val_loss: 0.4356 - val_acc: 0.8710\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5306 - acc: 0.8347\n",
      "Epoch 00002: val_loss improved from 0.43562 to 0.31164, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_9_conv_checkpoint/002-0.3116.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.5305 - acc: 0.8347 - val_loss: 0.3116 - val_acc: 0.9087\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3638 - acc: 0.8866\n",
      "Epoch 00003: val_loss improved from 0.31164 to 0.24181, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_9_conv_checkpoint/003-0.2418.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.3639 - acc: 0.8866 - val_loss: 0.2418 - val_acc: 0.9283\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2917 - acc: 0.9087\n",
      "Epoch 00004: val_loss did not improve from 0.24181\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.2917 - acc: 0.9087 - val_loss: 0.2663 - val_acc: 0.9185\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2434 - acc: 0.9227\n",
      "Epoch 00005: val_loss improved from 0.24181 to 0.17047, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_9_conv_checkpoint/005-0.1705.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.2433 - acc: 0.9227 - val_loss: 0.1705 - val_acc: 0.9478\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9370\n",
      "Epoch 00006: val_loss improved from 0.17047 to 0.15709, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_9_conv_checkpoint/006-0.1571.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1984 - acc: 0.9370 - val_loss: 0.1571 - val_acc: 0.9513\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1723 - acc: 0.9461\n",
      "Epoch 00007: val_loss improved from 0.15709 to 0.14724, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_9_conv_checkpoint/007-0.1472.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1724 - acc: 0.9461 - val_loss: 0.1472 - val_acc: 0.9567\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9509\n",
      "Epoch 00008: val_loss improved from 0.14724 to 0.14185, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_9_conv_checkpoint/008-0.1418.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1576 - acc: 0.9509 - val_loss: 0.1418 - val_acc: 0.9585\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9571\n",
      "Epoch 00009: val_loss did not improve from 0.14185\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1357 - acc: 0.9570 - val_loss: 0.1864 - val_acc: 0.9450\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9603\n",
      "Epoch 00010: val_loss did not improve from 0.14185\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1243 - acc: 0.9602 - val_loss: 0.1495 - val_acc: 0.9585\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9625\n",
      "Epoch 00011: val_loss did not improve from 0.14185\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.1182 - acc: 0.9625 - val_loss: 0.1447 - val_acc: 0.9576\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9655\n",
      "Epoch 00012: val_loss improved from 0.14185 to 0.14139, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_9_conv_checkpoint/012-0.1414.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1046 - acc: 0.9654 - val_loss: 0.1414 - val_acc: 0.9606\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9695\n",
      "Epoch 00013: val_loss improved from 0.14139 to 0.11160, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_9_conv_checkpoint/013-0.1116.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0921 - acc: 0.9695 - val_loss: 0.1116 - val_acc: 0.9683\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9749\n",
      "Epoch 00014: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0783 - acc: 0.9749 - val_loss: 0.1337 - val_acc: 0.9623\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9739\n",
      "Epoch 00015: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0819 - acc: 0.9739 - val_loss: 0.1699 - val_acc: 0.9525\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9777\n",
      "Epoch 00016: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0701 - acc: 0.9777 - val_loss: 0.1349 - val_acc: 0.9646\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9780\n",
      "Epoch 00017: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0706 - acc: 0.9779 - val_loss: 0.1222 - val_acc: 0.9662\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9757\n",
      "Epoch 00018: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0749 - acc: 0.9757 - val_loss: 0.1304 - val_acc: 0.9611\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9812\n",
      "Epoch 00019: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0572 - acc: 0.9812 - val_loss: 0.1234 - val_acc: 0.9665\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9834\n",
      "Epoch 00020: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0499 - acc: 0.9834 - val_loss: 0.1348 - val_acc: 0.9625\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9841\n",
      "Epoch 00021: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0502 - acc: 0.9841 - val_loss: 0.1255 - val_acc: 0.9660\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9871\n",
      "Epoch 00022: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0416 - acc: 0.9871 - val_loss: 0.1463 - val_acc: 0.9583\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9846\n",
      "Epoch 00023: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0484 - acc: 0.9846 - val_loss: 0.1398 - val_acc: 0.9644\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9870\n",
      "Epoch 00024: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0418 - acc: 0.9870 - val_loss: 0.1251 - val_acc: 0.9674\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9861\n",
      "Epoch 00025: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0439 - acc: 0.9861 - val_loss: 0.1267 - val_acc: 0.9662\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9881\n",
      "Epoch 00026: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0378 - acc: 0.9881 - val_loss: 0.1185 - val_acc: 0.9676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9897\n",
      "Epoch 00027: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0325 - acc: 0.9896 - val_loss: 0.1461 - val_acc: 0.9634\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9890\n",
      "Epoch 00028: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0353 - acc: 0.9890 - val_loss: 0.1197 - val_acc: 0.9651\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9894\n",
      "Epoch 00029: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0341 - acc: 0.9894 - val_loss: 0.1397 - val_acc: 0.9632\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9926\n",
      "Epoch 00030: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0248 - acc: 0.9926 - val_loss: 0.1447 - val_acc: 0.9613\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9922\n",
      "Epoch 00031: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0254 - acc: 0.9922 - val_loss: 0.1628 - val_acc: 0.9590\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9893\n",
      "Epoch 00032: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0357 - acc: 0.9893 - val_loss: 0.1346 - val_acc: 0.9669\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9938\n",
      "Epoch 00033: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0215 - acc: 0.9938 - val_loss: 0.1334 - val_acc: 0.9681\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9905\n",
      "Epoch 00034: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0311 - acc: 0.9905 - val_loss: 0.1146 - val_acc: 0.9693\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9949\n",
      "Epoch 00035: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0178 - acc: 0.9949 - val_loss: 0.1249 - val_acc: 0.9667\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9902\n",
      "Epoch 00036: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0329 - acc: 0.9902 - val_loss: 0.1187 - val_acc: 0.9700\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9948\n",
      "Epoch 00037: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0160 - acc: 0.9948 - val_loss: 0.1268 - val_acc: 0.9702\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9944\n",
      "Epoch 00038: val_loss did not improve from 0.11160\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0197 - acc: 0.9944 - val_loss: 0.1557 - val_acc: 0.9634\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9935\n",
      "Epoch 00039: val_loss improved from 0.11160 to 0.10050, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_BN_9_conv_checkpoint/039-0.1005.hdf5\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0211 - acc: 0.9935 - val_loss: 0.1005 - val_acc: 0.9751\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9940\n",
      "Epoch 00040: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0212 - acc: 0.9940 - val_loss: 0.1021 - val_acc: 0.9711\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9964\n",
      "Epoch 00041: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0138 - acc: 0.9963 - val_loss: 0.1116 - val_acc: 0.9716\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9911\n",
      "Epoch 00042: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0285 - acc: 0.9911 - val_loss: 0.1310 - val_acc: 0.9702\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9954\n",
      "Epoch 00043: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0151 - acc: 0.9954 - val_loss: 0.1353 - val_acc: 0.9690\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9972\n",
      "Epoch 00044: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0101 - acc: 0.9971 - val_loss: 0.1341 - val_acc: 0.9700\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9934\n",
      "Epoch 00045: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0203 - acc: 0.9934 - val_loss: 0.1422 - val_acc: 0.9665\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9956\n",
      "Epoch 00046: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0135 - acc: 0.9956 - val_loss: 0.1332 - val_acc: 0.9697\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9953\n",
      "Epoch 00047: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0158 - acc: 0.9953 - val_loss: 0.1164 - val_acc: 0.9716\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9945\n",
      "Epoch 00048: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0174 - acc: 0.9945 - val_loss: 0.1345 - val_acc: 0.9690\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9955\n",
      "Epoch 00049: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0135 - acc: 0.9955 - val_loss: 0.1343 - val_acc: 0.9718\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9962\n",
      "Epoch 00050: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0124 - acc: 0.9962 - val_loss: 0.2088 - val_acc: 0.9546\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9939\n",
      "Epoch 00051: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0204 - acc: 0.9939 - val_loss: 0.1453 - val_acc: 0.9695\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9970\n",
      "Epoch 00052: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0108 - acc: 0.9970 - val_loss: 0.1742 - val_acc: 0.9616\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9963\n",
      "Epoch 00053: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0124 - acc: 0.9963 - val_loss: 0.1450 - val_acc: 0.9686\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9962\n",
      "Epoch 00054: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0129 - acc: 0.9961 - val_loss: 0.2014 - val_acc: 0.9536\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9930\n",
      "Epoch 00055: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0233 - acc: 0.9930 - val_loss: 0.1193 - val_acc: 0.9716\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9977\n",
      "Epoch 00056: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0081 - acc: 0.9977 - val_loss: 0.1225 - val_acc: 0.9730\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9982\n",
      "Epoch 00057: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0066 - acc: 0.9982 - val_loss: 0.1815 - val_acc: 0.9592\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9958\n",
      "Epoch 00058: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0142 - acc: 0.9958 - val_loss: 0.1215 - val_acc: 0.9704\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9945\n",
      "Epoch 00059: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0164 - acc: 0.9945 - val_loss: 0.1331 - val_acc: 0.9667\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9979\n",
      "Epoch 00060: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0082 - acc: 0.9979 - val_loss: 0.1338 - val_acc: 0.9690\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9952\n",
      "Epoch 00061: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0166 - acc: 0.9952 - val_loss: 0.1346 - val_acc: 0.9693\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9957\n",
      "Epoch 00062: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0138 - acc: 0.9957 - val_loss: 0.1187 - val_acc: 0.9730\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9980\n",
      "Epoch 00063: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0067 - acc: 0.9980 - val_loss: 0.1187 - val_acc: 0.9755\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9975\n",
      "Epoch 00064: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0089 - acc: 0.9975 - val_loss: 0.1558 - val_acc: 0.9683\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9969\n",
      "Epoch 00065: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0098 - acc: 0.9969 - val_loss: 0.1964 - val_acc: 0.9632\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9978\n",
      "Epoch 00066: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 184s 5ms/sample - loss: 0.0079 - acc: 0.9978 - val_loss: 0.1347 - val_acc: 0.9718\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9961\n",
      "Epoch 00067: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0129 - acc: 0.9960 - val_loss: 0.1168 - val_acc: 0.9732\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9946\n",
      "Epoch 00068: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0179 - acc: 0.9946 - val_loss: 0.1194 - val_acc: 0.9713\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9981\n",
      "Epoch 00069: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0064 - acc: 0.9981 - val_loss: 0.1196 - val_acc: 0.9709\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9973\n",
      "Epoch 00070: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0078 - acc: 0.9973 - val_loss: 0.1207 - val_acc: 0.9727\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9974\n",
      "Epoch 00071: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0093 - acc: 0.9973 - val_loss: 0.1546 - val_acc: 0.9655\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9950\n",
      "Epoch 00072: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0152 - acc: 0.9950 - val_loss: 0.1107 - val_acc: 0.9732\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9980\n",
      "Epoch 00073: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0065 - acc: 0.9980 - val_loss: 0.1136 - val_acc: 0.9746\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9976\n",
      "Epoch 00074: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0070 - acc: 0.9976 - val_loss: 0.1280 - val_acc: 0.9713\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9970\n",
      "Epoch 00075: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0094 - acc: 0.9970 - val_loss: 0.1328 - val_acc: 0.9709\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9973\n",
      "Epoch 00076: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0089 - acc: 0.9973 - val_loss: 0.1607 - val_acc: 0.9672\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9977\n",
      "Epoch 00077: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0073 - acc: 0.9977 - val_loss: 0.1116 - val_acc: 0.9739\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9983\n",
      "Epoch 00078: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0059 - acc: 0.9982 - val_loss: 0.1846 - val_acc: 0.9676\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9946\n",
      "Epoch 00079: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0181 - acc: 0.9946 - val_loss: 0.1140 - val_acc: 0.9746\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9987\n",
      "Epoch 00080: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0050 - acc: 0.9988 - val_loss: 0.1193 - val_acc: 0.9751\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9992\n",
      "Epoch 00081: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0027 - acc: 0.9992 - val_loss: 0.1128 - val_acc: 0.9776\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9982\n",
      "Epoch 00082: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0069 - acc: 0.9982 - val_loss: 0.1299 - val_acc: 0.9679\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9951\n",
      "Epoch 00083: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0157 - acc: 0.9951 - val_loss: 0.1241 - val_acc: 0.9725\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9986\n",
      "Epoch 00084: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0052 - acc: 0.9986 - val_loss: 0.1172 - val_acc: 0.9730\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9989\n",
      "Epoch 00085: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0044 - acc: 0.9989 - val_loss: 0.1387 - val_acc: 0.9690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9982\n",
      "Epoch 00086: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0061 - acc: 0.9982 - val_loss: 0.1376 - val_acc: 0.9720\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9978\n",
      "Epoch 00087: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0075 - acc: 0.9978 - val_loss: 0.1303 - val_acc: 0.9727\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9952\n",
      "Epoch 00088: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0166 - acc: 0.9952 - val_loss: 0.1496 - val_acc: 0.9690\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9988\n",
      "Epoch 00089: val_loss did not improve from 0.10050\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0039 - acc: 0.9988 - val_loss: 0.1171 - val_acc: 0.9753\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.1336 - acc: 0.9628\n",
      "Loss: 0.1335519655773016 Accuracy: 0.9628245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    base = '1D_CNN_custom_ch_128_DO_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_ch_128_DO_BN(conv_num=i)\n",
    "        \n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "    \n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_42_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 16)           3805712     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Concatenate)           (None, 16)           0           sequential_7[1][0]               \n",
      "                                                                 sequential_7[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,805,712\n",
      "Trainable params: 3,804,944\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 2.3083 - acc: 0.4793\n",
      "Loss: 2.308270645488212 Accuracy: 0.4793354\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_45_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 16)           1461392     lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Concatenate)           (None, 16)           0           sequential_8[1][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,461,392\n",
      "Trainable params: 1,460,368\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 1.0380 - acc: 0.6993\n",
      "Loss: 1.037950282366724 Accuracy: 0.6992731\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_49_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 16)           1221008     lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Concatenate)           (None, 16)           0           sequential_9[1][0]               \n",
      "                                                                 sequential_9[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,221,008\n",
      "Trainable params: 1,219,472\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.7460 - acc: 0.7919\n",
      "Loss: 0.7460220728831622 Accuracy: 0.79190034\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_54_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 16)           1009296     lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Concatenate)          (None, 16)           0           sequential_10[1][0]              \n",
      "                                                                 sequential_10[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,009,296\n",
      "Trainable params: 1,007,248\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.4125 - acc: 0.8891\n",
      "Loss: 0.4124893016037787 Accuracy: 0.88909656\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_60_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 16)           1158032     lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Concatenate)          (None, 16)           0           sequential_11[1][0]              \n",
      "                                                                 sequential_11[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,158,032\n",
      "Trainable params: 1,155,472\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.2200 - acc: 0.9477\n",
      "Loss: 0.21995471964125074 Accuracy: 0.94766355\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_67_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 16)           1429648     lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Concatenate)          (None, 16)           0           sequential_12[1][0]              \n",
      "                                                                 sequential_12[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,429,648\n",
      "Trainable params: 1,426,576\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 3ms/sample - loss: 0.1543 - acc: 0.9585\n",
      "Loss: 0.15429694436660746 Accuracy: 0.95846313\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_9_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_75_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 16)           2075280     lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Concatenate)          (None, 16)           0           sequential_13[1][0]              \n",
      "                                                                 sequential_13[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,075,280\n",
      "Trainable params: 2,071,184\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.1336 - acc: 0.9628\n",
      "Loss: 0.1335519655773016 Accuracy: 0.9628245\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_ch_128_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_42_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 16)           3805712     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Concatenate)           (None, 16)           0           sequential_7[1][0]               \n",
      "                                                                 sequential_7[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,805,712\n",
      "Trainable params: 3,804,944\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 3.2002 - acc: 0.5720\n",
      "Loss: 3.2002359900766693 Accuracy: 0.5719626\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_45_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 16)           1461392     lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Concatenate)           (None, 16)           0           sequential_8[1][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,461,392\n",
      "Trainable params: 1,460,368\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 1.4094 - acc: 0.7371\n",
      "Loss: 1.4094071193895112 Accuracy: 0.73707163\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_49_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 16)           1221008     lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Concatenate)           (None, 16)           0           sequential_9[1][0]               \n",
      "                                                                 sequential_9[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,221,008\n",
      "Trainable params: 1,219,472\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 1.0535 - acc: 0.7985\n",
      "Loss: 1.0535073165705395 Accuracy: 0.7985462\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_54_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 16)           1009296     lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Concatenate)          (None, 16)           0           sequential_10[1][0]              \n",
      "                                                                 sequential_10[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,009,296\n",
      "Trainable params: 1,007,248\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 3ms/sample - loss: 0.6015 - acc: 0.8762\n",
      "Loss: 0.6015227081619691 Accuracy: 0.87622017\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_60_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 16)           1158032     lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Concatenate)          (None, 16)           0           sequential_11[1][0]              \n",
      "                                                                 sequential_11[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,158,032\n",
      "Trainable params: 1,155,472\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.2589 - acc: 0.9443\n",
      "Loss: 0.2589215408353017 Accuracy: 0.9443406\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_67_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 16)           1429648     lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Concatenate)          (None, 16)           0           sequential_12[1][0]              \n",
      "                                                                 sequential_12[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,429,648\n",
      "Trainable params: 1,426,576\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.1845 - acc: 0.9562\n",
      "Loss: 0.18449534986763882 Accuracy: 0.9561786\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_BN_9_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_75_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 16)           2075280     lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Concatenate)          (None, 16)           0           sequential_13[1][0]              \n",
      "                                                                 sequential_13[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,075,280\n",
      "Trainable params: 2,071,184\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.1422 - acc: 0.9674\n",
      "Loss: 0.14216666200990294 Accuracy: 0.9673936\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_ch_128_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
