{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_ch_128_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=128, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=128*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.75))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 3,804,176\n",
      "Trainable params: 3,804,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,459,344\n",
      "Trainable params: 1,459,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 1,217,936\n",
      "Trainable params: 1,217,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 1,005,200\n",
      "Trainable params: 1,005,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 1,152,912\n",
      "Trainable params: 1,152,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,423,504\n",
      "Trainable params: 1,423,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 2,067,088\n",
      "Trainable params: 2,067,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model = build_1d_cnn_custom_ch_128_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0638 - acc: 0.3529\n",
      "Epoch 00001: val_loss improved from inf to 1.58022, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/001-1.5802.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 2.0637 - acc: 0.3529 - val_loss: 1.5802 - val_acc: 0.5222\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4536 - acc: 0.5498\n",
      "Epoch 00002: val_loss improved from 1.58022 to 1.43361, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/002-1.4336.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 1.4535 - acc: 0.5499 - val_loss: 1.4336 - val_acc: 0.5616\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2374 - acc: 0.6176\n",
      "Epoch 00003: val_loss improved from 1.43361 to 1.35414, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/003-1.3541.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 1.2373 - acc: 0.6177 - val_loss: 1.3541 - val_acc: 0.5826\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0884 - acc: 0.6644\n",
      "Epoch 00004: val_loss improved from 1.35414 to 1.28220, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/004-1.2822.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 1.0884 - acc: 0.6644 - val_loss: 1.2822 - val_acc: 0.6024\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9544 - acc: 0.7050\n",
      "Epoch 00005: val_loss improved from 1.28220 to 1.27018, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/005-1.2702.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.9543 - acc: 0.7050 - val_loss: 1.2702 - val_acc: 0.6112\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8549 - acc: 0.7341\n",
      "Epoch 00006: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.8548 - acc: 0.7341 - val_loss: 1.2863 - val_acc: 0.6182\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7592 - acc: 0.7634\n",
      "Epoch 00007: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.7593 - acc: 0.7633 - val_loss: 1.3458 - val_acc: 0.6124\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6821 - acc: 0.7871\n",
      "Epoch 00008: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.6821 - acc: 0.7871 - val_loss: 1.3250 - val_acc: 0.6294\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6125 - acc: 0.8096\n",
      "Epoch 00009: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.6125 - acc: 0.8096 - val_loss: 1.3135 - val_acc: 0.6336\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5509 - acc: 0.8255\n",
      "Epoch 00010: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.5509 - acc: 0.8255 - val_loss: 1.3429 - val_acc: 0.6310\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5001 - acc: 0.8410\n",
      "Epoch 00011: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.5001 - acc: 0.8411 - val_loss: 1.3561 - val_acc: 0.6357\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4538 - acc: 0.8567\n",
      "Epoch 00012: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.4537 - acc: 0.8567 - val_loss: 1.3960 - val_acc: 0.6357\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4132 - acc: 0.8701\n",
      "Epoch 00013: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.4132 - acc: 0.8701 - val_loss: 1.4278 - val_acc: 0.6373\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3765 - acc: 0.8809\n",
      "Epoch 00014: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.3765 - acc: 0.8809 - val_loss: 1.4591 - val_acc: 0.6369\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3605 - acc: 0.8841\n",
      "Epoch 00015: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.3605 - acc: 0.8840 - val_loss: 1.5271 - val_acc: 0.6334\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3210 - acc: 0.8989\n",
      "Epoch 00016: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.3211 - acc: 0.8988 - val_loss: 1.5169 - val_acc: 0.6394\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2981 - acc: 0.9051\n",
      "Epoch 00017: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.2981 - acc: 0.9051 - val_loss: 1.5699 - val_acc: 0.6320\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2826 - acc: 0.9103\n",
      "Epoch 00018: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.2826 - acc: 0.9103 - val_loss: 1.5258 - val_acc: 0.6392\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2606 - acc: 0.9164\n",
      "Epoch 00019: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.2606 - acc: 0.9164 - val_loss: 1.6047 - val_acc: 0.6429\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2449 - acc: 0.9233\n",
      "Epoch 00020: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.2449 - acc: 0.9233 - val_loss: 1.5820 - val_acc: 0.6515\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2317 - acc: 0.9266\n",
      "Epoch 00021: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.2317 - acc: 0.9266 - val_loss: 1.5847 - val_acc: 0.6518\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2215 - acc: 0.9305\n",
      "Epoch 00022: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.2216 - acc: 0.9304 - val_loss: 1.5785 - val_acc: 0.6539\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2062 - acc: 0.9355\n",
      "Epoch 00023: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.2061 - acc: 0.9355 - val_loss: 1.6484 - val_acc: 0.6536\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1966 - acc: 0.9385\n",
      "Epoch 00024: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.1966 - acc: 0.9385 - val_loss: 1.6301 - val_acc: 0.6578\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1838 - acc: 0.9428\n",
      "Epoch 00025: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.1838 - acc: 0.9428 - val_loss: 1.6596 - val_acc: 0.6529\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1796 - acc: 0.9428\n",
      "Epoch 00026: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.1797 - acc: 0.9428 - val_loss: 1.8159 - val_acc: 0.6438\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9465\n",
      "Epoch 00027: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1742 - acc: 0.9465 - val_loss: 1.6694 - val_acc: 0.6578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9490\n",
      "Epoch 00028: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1623 - acc: 0.9491 - val_loss: 1.7071 - val_acc: 0.6571\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9536\n",
      "Epoch 00029: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1521 - acc: 0.9535 - val_loss: 1.7172 - val_acc: 0.6608\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9520\n",
      "Epoch 00030: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1548 - acc: 0.9519 - val_loss: 1.7172 - val_acc: 0.6697\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1514 - acc: 0.9522\n",
      "Epoch 00031: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1514 - acc: 0.9522 - val_loss: 1.7387 - val_acc: 0.6695\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9568\n",
      "Epoch 00032: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1400 - acc: 0.9569 - val_loss: 1.7299 - val_acc: 0.6744\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9586\n",
      "Epoch 00033: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1354 - acc: 0.9586 - val_loss: 1.7500 - val_acc: 0.6639\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9609\n",
      "Epoch 00034: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1303 - acc: 0.9609 - val_loss: 1.7249 - val_acc: 0.6739\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9612\n",
      "Epoch 00035: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1311 - acc: 0.9612 - val_loss: 1.7410 - val_acc: 0.6730\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9626\n",
      "Epoch 00036: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1235 - acc: 0.9626 - val_loss: 1.7669 - val_acc: 0.6697\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9655\n",
      "Epoch 00037: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1200 - acc: 0.9655 - val_loss: 1.8104 - val_acc: 0.6667\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9637\n",
      "Epoch 00038: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1225 - acc: 0.9637 - val_loss: 1.7582 - val_acc: 0.6720\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9676\n",
      "Epoch 00039: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1090 - acc: 0.9676 - val_loss: 1.7843 - val_acc: 0.6739\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9645\n",
      "Epoch 00040: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1177 - acc: 0.9645 - val_loss: 1.6907 - val_acc: 0.6841\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9679\n",
      "Epoch 00041: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1093 - acc: 0.9679 - val_loss: 1.7570 - val_acc: 0.6799\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9693\n",
      "Epoch 00042: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1065 - acc: 0.9693 - val_loss: 1.7756 - val_acc: 0.6795\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9693\n",
      "Epoch 00043: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1060 - acc: 0.9693 - val_loss: 1.7798 - val_acc: 0.6797\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9713\n",
      "Epoch 00044: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1011 - acc: 0.9713 - val_loss: 1.8045 - val_acc: 0.6755\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9712\n",
      "Epoch 00045: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1007 - acc: 0.9712 - val_loss: 1.8419 - val_acc: 0.6760\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9720\n",
      "Epoch 00046: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0979 - acc: 0.9719 - val_loss: 1.7977 - val_acc: 0.6778\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9732\n",
      "Epoch 00047: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0931 - acc: 0.9732 - val_loss: 1.9089 - val_acc: 0.6716\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9707\n",
      "Epoch 00048: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0986 - acc: 0.9707 - val_loss: 1.8795 - val_acc: 0.6795\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9732\n",
      "Epoch 00049: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0934 - acc: 0.9732 - val_loss: 1.8487 - val_acc: 0.6778\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9745\n",
      "Epoch 00050: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0896 - acc: 0.9745 - val_loss: 1.8116 - val_acc: 0.6806\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9743\n",
      "Epoch 00051: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.0885 - acc: 0.9743 - val_loss: 1.8189 - val_acc: 0.6785\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9748\n",
      "Epoch 00052: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0878 - acc: 0.9748 - val_loss: 1.7756 - val_acc: 0.6869\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9767\n",
      "Epoch 00053: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.0840 - acc: 0.9767 - val_loss: 1.8771 - val_acc: 0.6855\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9772\n",
      "Epoch 00054: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.0844 - acc: 0.9772 - val_loss: 1.9159 - val_acc: 0.6695\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9766\n",
      "Epoch 00055: val_loss did not improve from 1.27018\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.0829 - acc: 0.9766 - val_loss: 1.8833 - val_acc: 0.6788\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.3620 - acc: 0.5755\n",
      "Loss: 1.3620327086958681 Accuracy: 0.5754933\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0154 - acc: 0.3494\n",
      "Epoch 00001: val_loss improved from inf to 1.51401, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_4_conv_checkpoint/001-1.5140.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 2.0154 - acc: 0.3494 - val_loss: 1.5140 - val_acc: 0.5253\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3993 - acc: 0.5606\n",
      "Epoch 00002: val_loss improved from 1.51401 to 1.34496, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_4_conv_checkpoint/002-1.3450.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 1.3993 - acc: 0.5606 - val_loss: 1.3450 - val_acc: 0.5921\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1809 - acc: 0.6350\n",
      "Epoch 00003: val_loss improved from 1.34496 to 1.09781, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_4_conv_checkpoint/003-1.0978.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 1.1809 - acc: 0.6350 - val_loss: 1.0978 - val_acc: 0.6641\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0338 - acc: 0.6829\n",
      "Epoch 00004: val_loss improved from 1.09781 to 1.04916, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_4_conv_checkpoint/004-1.0492.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 1.0337 - acc: 0.6829 - val_loss: 1.0492 - val_acc: 0.6825\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9207 - acc: 0.7188\n",
      "Epoch 00005: val_loss improved from 1.04916 to 0.94601, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_4_conv_checkpoint/005-0.9460.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.9207 - acc: 0.7188 - val_loss: 0.9460 - val_acc: 0.7123\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8216 - acc: 0.7516\n",
      "Epoch 00006: val_loss improved from 0.94601 to 0.91712, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_4_conv_checkpoint/006-0.9171.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.8216 - acc: 0.7516 - val_loss: 0.9171 - val_acc: 0.7198\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7351 - acc: 0.7735\n",
      "Epoch 00007: val_loss improved from 0.91712 to 0.84328, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_4_conv_checkpoint/007-0.8433.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.7351 - acc: 0.7735 - val_loss: 0.8433 - val_acc: 0.7508\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6581 - acc: 0.7969\n",
      "Epoch 00008: val_loss did not improve from 0.84328\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.6581 - acc: 0.7969 - val_loss: 0.8580 - val_acc: 0.7433\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6007 - acc: 0.8138\n",
      "Epoch 00009: val_loss improved from 0.84328 to 0.84234, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_4_conv_checkpoint/009-0.8423.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.6007 - acc: 0.8139 - val_loss: 0.8423 - val_acc: 0.7484\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5513 - acc: 0.8295\n",
      "Epoch 00010: val_loss improved from 0.84234 to 0.83654, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_4_conv_checkpoint/010-0.8365.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.5512 - acc: 0.8295 - val_loss: 0.8365 - val_acc: 0.7563\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5006 - acc: 0.8437\n",
      "Epoch 00011: val_loss did not improve from 0.83654\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.5005 - acc: 0.8437 - val_loss: 0.8434 - val_acc: 0.7629\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4566 - acc: 0.8565\n",
      "Epoch 00012: val_loss improved from 0.83654 to 0.80985, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_4_conv_checkpoint/012-0.8099.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.4566 - acc: 0.8565 - val_loss: 0.8099 - val_acc: 0.7612\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4240 - acc: 0.8667\n",
      "Epoch 00013: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.4240 - acc: 0.8667 - val_loss: 0.8341 - val_acc: 0.7608\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3878 - acc: 0.8766\n",
      "Epoch 00014: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.3879 - acc: 0.8766 - val_loss: 0.8338 - val_acc: 0.7643\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3572 - acc: 0.8863\n",
      "Epoch 00015: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.3573 - acc: 0.8862 - val_loss: 0.8646 - val_acc: 0.7643\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3443 - acc: 0.8876\n",
      "Epoch 00016: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.3443 - acc: 0.8876 - val_loss: 0.8323 - val_acc: 0.7768\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3158 - acc: 0.8989\n",
      "Epoch 00017: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.3158 - acc: 0.8989 - val_loss: 0.8452 - val_acc: 0.7720\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.9042\n",
      "Epoch 00018: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2969 - acc: 0.9042 - val_loss: 0.8793 - val_acc: 0.7661\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2823 - acc: 0.9092\n",
      "Epoch 00019: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2822 - acc: 0.9092 - val_loss: 0.9012 - val_acc: 0.7645\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2701 - acc: 0.9127\n",
      "Epoch 00020: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2701 - acc: 0.9127 - val_loss: 0.8578 - val_acc: 0.7771\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2572 - acc: 0.9155\n",
      "Epoch 00021: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2572 - acc: 0.9155 - val_loss: 0.8748 - val_acc: 0.7796\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2385 - acc: 0.9211\n",
      "Epoch 00022: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2385 - acc: 0.9212 - val_loss: 0.9243 - val_acc: 0.7759\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2372 - acc: 0.9238\n",
      "Epoch 00023: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2372 - acc: 0.9238 - val_loss: 0.9210 - val_acc: 0.7787\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2291 - acc: 0.9260\n",
      "Epoch 00024: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2291 - acc: 0.9260 - val_loss: 0.8835 - val_acc: 0.7864\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2114 - acc: 0.9290\n",
      "Epoch 00025: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2114 - acc: 0.9290 - val_loss: 0.8891 - val_acc: 0.7845\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2031 - acc: 0.9340\n",
      "Epoch 00026: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2031 - acc: 0.9340 - val_loss: 0.8891 - val_acc: 0.7855\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2058 - acc: 0.9334\n",
      "Epoch 00027: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2058 - acc: 0.9334 - val_loss: 0.9172 - val_acc: 0.7841\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9360\n",
      "Epoch 00028: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1946 - acc: 0.9360 - val_loss: 0.8678 - val_acc: 0.7913\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1902 - acc: 0.9385\n",
      "Epoch 00029: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1902 - acc: 0.9385 - val_loss: 0.9511 - val_acc: 0.7871\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1803 - acc: 0.9411\n",
      "Epoch 00030: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1803 - acc: 0.9411 - val_loss: 0.9400 - val_acc: 0.7850\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1744 - acc: 0.9433\n",
      "Epoch 00031: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1744 - acc: 0.9432 - val_loss: 0.8916 - val_acc: 0.7932\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9428\n",
      "Epoch 00032: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1768 - acc: 0.9428 - val_loss: 0.9050 - val_acc: 0.7934\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1662 - acc: 0.9467\n",
      "Epoch 00033: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1661 - acc: 0.9467 - val_loss: 0.9065 - val_acc: 0.7836\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9479\n",
      "Epoch 00034: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1609 - acc: 0.9479 - val_loss: 0.9355 - val_acc: 0.7862\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9482\n",
      "Epoch 00035: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1589 - acc: 0.9482 - val_loss: 0.9458 - val_acc: 0.7906\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9509\n",
      "Epoch 00036: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1516 - acc: 0.9509 - val_loss: 0.9503 - val_acc: 0.7922\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1518 - acc: 0.9511\n",
      "Epoch 00037: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1518 - acc: 0.9511 - val_loss: 0.9369 - val_acc: 0.7918\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9548\n",
      "Epoch 00038: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1410 - acc: 0.9548 - val_loss: 0.9850 - val_acc: 0.7894\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9529\n",
      "Epoch 00039: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1490 - acc: 0.9529 - val_loss: 0.9716 - val_acc: 0.7908\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9556\n",
      "Epoch 00040: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1400 - acc: 0.9556 - val_loss: 0.9270 - val_acc: 0.7950\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9564\n",
      "Epoch 00041: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1374 - acc: 0.9564 - val_loss: 0.9903 - val_acc: 0.7987\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9553\n",
      "Epoch 00042: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1362 - acc: 0.9553 - val_loss: 0.9527 - val_acc: 0.7922\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9543\n",
      "Epoch 00043: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1412 - acc: 0.9543 - val_loss: 0.9398 - val_acc: 0.7973\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9603\n",
      "Epoch 00044: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1292 - acc: 0.9603 - val_loss: 0.9577 - val_acc: 0.7983\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9607\n",
      "Epoch 00045: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1249 - acc: 0.9607 - val_loss: 0.9924 - val_acc: 0.7904\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9600\n",
      "Epoch 00046: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1246 - acc: 0.9600 - val_loss: 0.9475 - val_acc: 0.7997\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9602\n",
      "Epoch 00047: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1255 - acc: 0.9602 - val_loss: 0.9598 - val_acc: 0.7957\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9623\n",
      "Epoch 00048: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1220 - acc: 0.9623 - val_loss: 0.9625 - val_acc: 0.8022\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9613\n",
      "Epoch 00049: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1239 - acc: 0.9613 - val_loss: 0.9490 - val_acc: 0.8032\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9627\n",
      "Epoch 00050: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1204 - acc: 0.9626 - val_loss: 0.9519 - val_acc: 0.8048\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9613\n",
      "Epoch 00051: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1210 - acc: 0.9613 - val_loss: 0.9693 - val_acc: 0.7973\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9639\n",
      "Epoch 00052: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1151 - acc: 0.9639 - val_loss: 0.9263 - val_acc: 0.8164\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9655\n",
      "Epoch 00053: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1118 - acc: 0.9655 - val_loss: 0.9596 - val_acc: 0.7969\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9671\n",
      "Epoch 00054: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1087 - acc: 0.9671 - val_loss: 0.9815 - val_acc: 0.7999\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9660\n",
      "Epoch 00055: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1093 - acc: 0.9660 - val_loss: 0.9469 - val_acc: 0.8041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9654\n",
      "Epoch 00056: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1106 - acc: 0.9654 - val_loss: 1.0180 - val_acc: 0.8025\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9664\n",
      "Epoch 00057: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1068 - acc: 0.9664 - val_loss: 0.9937 - val_acc: 0.8076\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9667\n",
      "Epoch 00058: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1057 - acc: 0.9667 - val_loss: 0.9931 - val_acc: 0.8039\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9684\n",
      "Epoch 00059: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1027 - acc: 0.9684 - val_loss: 0.9687 - val_acc: 0.7978\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9682\n",
      "Epoch 00060: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1038 - acc: 0.9682 - val_loss: 0.9593 - val_acc: 0.8013\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9670\n",
      "Epoch 00061: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1048 - acc: 0.9670 - val_loss: 0.9539 - val_acc: 0.8099\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9698\n",
      "Epoch 00062: val_loss did not improve from 0.80985\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0973 - acc: 0.9698 - val_loss: 0.9884 - val_acc: 0.8099\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.9251 - acc: 0.7371\n",
      "Loss: 0.9251436805056634 Accuracy: 0.73707163\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0040 - acc: 0.3450\n",
      "Epoch 00001: val_loss improved from inf to 1.43436, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/001-1.4344.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 2.0039 - acc: 0.3450 - val_loss: 1.4344 - val_acc: 0.5539\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3547 - acc: 0.5701\n",
      "Epoch 00002: val_loss improved from 1.43436 to 1.09884, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/002-1.0988.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 1.3546 - acc: 0.5701 - val_loss: 1.0988 - val_acc: 0.6627\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1123 - acc: 0.6554\n",
      "Epoch 00003: val_loss improved from 1.09884 to 0.99178, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/003-0.9918.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 1.1123 - acc: 0.6555 - val_loss: 0.9918 - val_acc: 0.6988\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9603 - acc: 0.7045\n",
      "Epoch 00004: val_loss improved from 0.99178 to 0.87703, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/004-0.8770.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.9603 - acc: 0.7045 - val_loss: 0.8770 - val_acc: 0.7459\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8581 - acc: 0.7388\n",
      "Epoch 00005: val_loss improved from 0.87703 to 0.78681, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/005-0.7868.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.8580 - acc: 0.7388 - val_loss: 0.7868 - val_acc: 0.7657\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7705 - acc: 0.7655\n",
      "Epoch 00006: val_loss did not improve from 0.78681\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.7706 - acc: 0.7655 - val_loss: 0.8176 - val_acc: 0.7510\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7069 - acc: 0.7855\n",
      "Epoch 00007: val_loss improved from 0.78681 to 0.75546, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/007-0.7555.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.7069 - acc: 0.7855 - val_loss: 0.7555 - val_acc: 0.7720\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6464 - acc: 0.8053\n",
      "Epoch 00008: val_loss improved from 0.75546 to 0.67435, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/008-0.6744.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.6464 - acc: 0.8053 - val_loss: 0.6744 - val_acc: 0.8130\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5960 - acc: 0.8191\n",
      "Epoch 00009: val_loss improved from 0.67435 to 0.64331, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/009-0.6433.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.5959 - acc: 0.8191 - val_loss: 0.6433 - val_acc: 0.8192\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5463 - acc: 0.8345\n",
      "Epoch 00010: val_loss improved from 0.64331 to 0.62897, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/010-0.6290.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.5463 - acc: 0.8345 - val_loss: 0.6290 - val_acc: 0.8176\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5078 - acc: 0.8471\n",
      "Epoch 00011: val_loss improved from 0.62897 to 0.60903, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/011-0.6090.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.5078 - acc: 0.8471 - val_loss: 0.6090 - val_acc: 0.8253\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4757 - acc: 0.8550\n",
      "Epoch 00012: val_loss improved from 0.60903 to 0.60034, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/012-0.6003.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.4758 - acc: 0.8550 - val_loss: 0.6003 - val_acc: 0.8248\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4417 - acc: 0.8653\n",
      "Epoch 00013: val_loss improved from 0.60034 to 0.57182, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/013-0.5718.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.4417 - acc: 0.8653 - val_loss: 0.5718 - val_acc: 0.8407\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8762\n",
      "Epoch 00014: val_loss did not improve from 0.57182\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.4124 - acc: 0.8762 - val_loss: 0.5850 - val_acc: 0.8374\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3812 - acc: 0.8825\n",
      "Epoch 00015: val_loss did not improve from 0.57182\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.3812 - acc: 0.8825 - val_loss: 0.6088 - val_acc: 0.8316\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3556 - acc: 0.8889\n",
      "Epoch 00016: val_loss improved from 0.57182 to 0.56592, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/016-0.5659.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.3556 - acc: 0.8890 - val_loss: 0.5659 - val_acc: 0.8477\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3266 - acc: 0.8977\n",
      "Epoch 00017: val_loss did not improve from 0.56592\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.3267 - acc: 0.8977 - val_loss: 0.6122 - val_acc: 0.8397\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3075 - acc: 0.9045\n",
      "Epoch 00018: val_loss improved from 0.56592 to 0.55074, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_5_conv_checkpoint/018-0.5507.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.3076 - acc: 0.9045 - val_loss: 0.5507 - val_acc: 0.8512\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2889 - acc: 0.9103\n",
      "Epoch 00019: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2894 - acc: 0.9103 - val_loss: 0.5898 - val_acc: 0.8418\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2770 - acc: 0.9107\n",
      "Epoch 00020: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2770 - acc: 0.9107 - val_loss: 0.5558 - val_acc: 0.8565\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2597 - acc: 0.9166\n",
      "Epoch 00021: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2597 - acc: 0.9166 - val_loss: 0.5856 - val_acc: 0.8491\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2446 - acc: 0.9216\n",
      "Epoch 00022: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2446 - acc: 0.9216 - val_loss: 0.5595 - val_acc: 0.8607\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2333 - acc: 0.9241\n",
      "Epoch 00023: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2333 - acc: 0.9241 - val_loss: 0.5974 - val_acc: 0.8481\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9321\n",
      "Epoch 00024: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2163 - acc: 0.9321 - val_loss: 0.5578 - val_acc: 0.8623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9344\n",
      "Epoch 00025: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2107 - acc: 0.9344 - val_loss: 0.5685 - val_acc: 0.8560\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2007 - acc: 0.9361\n",
      "Epoch 00026: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2007 - acc: 0.9361 - val_loss: 0.7530 - val_acc: 0.8348\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1928 - acc: 0.9383\n",
      "Epoch 00027: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1927 - acc: 0.9383 - val_loss: 0.6064 - val_acc: 0.8565\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1823 - acc: 0.9411\n",
      "Epoch 00028: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1823 - acc: 0.9411 - val_loss: 0.6169 - val_acc: 0.8530\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9432\n",
      "Epoch 00029: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1759 - acc: 0.9432 - val_loss: 0.5856 - val_acc: 0.8563\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9461\n",
      "Epoch 00030: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1679 - acc: 0.9461 - val_loss: 0.5829 - val_acc: 0.8640\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1646 - acc: 0.9471\n",
      "Epoch 00031: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1646 - acc: 0.9471 - val_loss: 0.6159 - val_acc: 0.8546\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9496\n",
      "Epoch 00032: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1613 - acc: 0.9496 - val_loss: 0.6355 - val_acc: 0.8565\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9513\n",
      "Epoch 00033: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1478 - acc: 0.9513 - val_loss: 0.6157 - val_acc: 0.8570\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1518 - acc: 0.9514\n",
      "Epoch 00034: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1518 - acc: 0.9514 - val_loss: 0.6930 - val_acc: 0.8397\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1453 - acc: 0.9527\n",
      "Epoch 00035: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1453 - acc: 0.9528 - val_loss: 0.6494 - val_acc: 0.8488\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9551\n",
      "Epoch 00036: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1390 - acc: 0.9551 - val_loss: 0.5996 - val_acc: 0.8675\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9577\n",
      "Epoch 00037: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1326 - acc: 0.9577 - val_loss: 0.6184 - val_acc: 0.8647\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9573\n",
      "Epoch 00038: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1318 - acc: 0.9573 - val_loss: 0.6384 - val_acc: 0.8644\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9583\n",
      "Epoch 00039: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1295 - acc: 0.9583 - val_loss: 0.6236 - val_acc: 0.8621\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9595- ETA: 5s - loss: - ETA: 1s - loss: 0.1259 - acc\n",
      "Epoch 00040: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1257 - acc: 0.9595 - val_loss: 0.7263 - val_acc: 0.8551\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9626\n",
      "Epoch 00041: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1210 - acc: 0.9626 - val_loss: 0.6311 - val_acc: 0.8668\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9616\n",
      "Epoch 00042: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1196 - acc: 0.9616 - val_loss: 0.6427 - val_acc: 0.8654\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9618\n",
      "Epoch 00043: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1211 - acc: 0.9618 - val_loss: 0.6386 - val_acc: 0.8665\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9631\n",
      "Epoch 00044: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1154 - acc: 0.9631 - val_loss: 0.6624 - val_acc: 0.8651\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9644\n",
      "Epoch 00045: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1117 - acc: 0.9644 - val_loss: 0.6371 - val_acc: 0.8670\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9656\n",
      "Epoch 00046: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1072 - acc: 0.9656 - val_loss: 0.6357 - val_acc: 0.8616\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9661\n",
      "Epoch 00047: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1092 - acc: 0.9661 - val_loss: 0.6531 - val_acc: 0.8719\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9655\n",
      "Epoch 00048: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1107 - acc: 0.9655 - val_loss: 0.6613 - val_acc: 0.8717\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9683\n",
      "Epoch 00049: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1021 - acc: 0.9683 - val_loss: 0.6158 - val_acc: 0.8747\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9688\n",
      "Epoch 00050: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0996 - acc: 0.9688 - val_loss: 0.6676 - val_acc: 0.8726\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9664\n",
      "Epoch 00051: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1039 - acc: 0.9664 - val_loss: 0.6526 - val_acc: 0.8670\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9695\n",
      "Epoch 00052: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0985 - acc: 0.9695 - val_loss: 0.6423 - val_acc: 0.8728\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9704\n",
      "Epoch 00053: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0965 - acc: 0.9703 - val_loss: 0.6848 - val_acc: 0.8558\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9688\n",
      "Epoch 00054: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1028 - acc: 0.9688 - val_loss: 0.6514 - val_acc: 0.8717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9684\n",
      "Epoch 00055: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0984 - acc: 0.9684 - val_loss: 0.6470 - val_acc: 0.8728\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9709\n",
      "Epoch 00056: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0914 - acc: 0.9709 - val_loss: 0.6293 - val_acc: 0.8644\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9691\n",
      "Epoch 00057: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0977 - acc: 0.9691 - val_loss: 0.6271 - val_acc: 0.8689\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9720\n",
      "Epoch 00058: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0900 - acc: 0.9720 - val_loss: 0.6206 - val_acc: 0.8756\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9718\n",
      "Epoch 00059: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0900 - acc: 0.9718 - val_loss: 0.6107 - val_acc: 0.8726\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9733\n",
      "Epoch 00060: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0840 - acc: 0.9733 - val_loss: 0.6597 - val_acc: 0.8735\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9737\n",
      "Epoch 00061: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0854 - acc: 0.9737 - val_loss: 0.6767 - val_acc: 0.8728\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9742\n",
      "Epoch 00062: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0847 - acc: 0.9742 - val_loss: 0.6909 - val_acc: 0.8654\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9754\n",
      "Epoch 00063: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0798 - acc: 0.9754 - val_loss: 0.6838 - val_acc: 0.8784\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9726\n",
      "Epoch 00064: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0871 - acc: 0.9726 - val_loss: 0.6657 - val_acc: 0.8742\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9741\n",
      "Epoch 00065: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0846 - acc: 0.9741 - val_loss: 0.6357 - val_acc: 0.8784\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9753\n",
      "Epoch 00066: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0815 - acc: 0.9753 - val_loss: 0.6531 - val_acc: 0.8770\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9759\n",
      "Epoch 00067: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0780 - acc: 0.9759 - val_loss: 0.6218 - val_acc: 0.8758\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9763\n",
      "Epoch 00068: val_loss did not improve from 0.55074\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0799 - acc: 0.9763 - val_loss: 0.6377 - val_acc: 0.8768\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.6811 - acc: 0.8104\n",
      "Loss: 0.6811446335951983 Accuracy: 0.8103842\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1591 - acc: 0.2885\n",
      "Epoch 00001: val_loss improved from inf to 1.48551, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/001-1.4855.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 2.1591 - acc: 0.2885 - val_loss: 1.4855 - val_acc: 0.5411\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4754 - acc: 0.5201\n",
      "Epoch 00002: val_loss improved from 1.48551 to 1.21475, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/002-1.2147.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 1.4753 - acc: 0.5201 - val_loss: 1.2147 - val_acc: 0.6331\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2185 - acc: 0.6103\n",
      "Epoch 00003: val_loss improved from 1.21475 to 1.10783, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/003-1.1078.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 1.2184 - acc: 0.6103 - val_loss: 1.1078 - val_acc: 0.6434\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0239 - acc: 0.6809\n",
      "Epoch 00004: val_loss improved from 1.10783 to 0.83924, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/004-0.8392.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 1.0240 - acc: 0.6809 - val_loss: 0.8392 - val_acc: 0.7587\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8738 - acc: 0.7325\n",
      "Epoch 00005: val_loss improved from 0.83924 to 0.73524, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/005-0.7352.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.8737 - acc: 0.7325 - val_loss: 0.7352 - val_acc: 0.7731\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7806 - acc: 0.7626\n",
      "Epoch 00006: val_loss improved from 0.73524 to 0.68818, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/006-0.6882.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.7806 - acc: 0.7625 - val_loss: 0.6882 - val_acc: 0.7994\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6991 - acc: 0.7876\n",
      "Epoch 00007: val_loss improved from 0.68818 to 0.55678, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/007-0.5568.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.6991 - acc: 0.7876 - val_loss: 0.5568 - val_acc: 0.8477\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6317 - acc: 0.8096\n",
      "Epoch 00008: val_loss did not improve from 0.55678\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.6317 - acc: 0.8096 - val_loss: 0.5732 - val_acc: 0.8432\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5879 - acc: 0.8241\n",
      "Epoch 00009: val_loss improved from 0.55678 to 0.47775, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/009-0.4778.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.5879 - acc: 0.8241 - val_loss: 0.4778 - val_acc: 0.8689\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5377 - acc: 0.8391\n",
      "Epoch 00010: val_loss improved from 0.47775 to 0.45026, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/010-0.4503.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.5377 - acc: 0.8391 - val_loss: 0.4503 - val_acc: 0.8782\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5026 - acc: 0.8495\n",
      "Epoch 00011: val_loss improved from 0.45026 to 0.43197, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/011-0.4320.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.5026 - acc: 0.8495 - val_loss: 0.4320 - val_acc: 0.8812\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4696 - acc: 0.8583\n",
      "Epoch 00012: val_loss improved from 0.43197 to 0.40570, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/012-0.4057.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.4696 - acc: 0.8583 - val_loss: 0.4057 - val_acc: 0.8856\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4461 - acc: 0.8654\n",
      "Epoch 00013: val_loss improved from 0.40570 to 0.39562, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/013-0.3956.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.4462 - acc: 0.8654 - val_loss: 0.3956 - val_acc: 0.8898\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4185 - acc: 0.8751\n",
      "Epoch 00014: val_loss improved from 0.39562 to 0.37591, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/014-0.3759.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.4185 - acc: 0.8750 - val_loss: 0.3759 - val_acc: 0.8942\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3892 - acc: 0.8805\n",
      "Epoch 00015: val_loss did not improve from 0.37591\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.3893 - acc: 0.8805 - val_loss: 0.3951 - val_acc: 0.8898\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3771 - acc: 0.8862\n",
      "Epoch 00016: val_loss did not improve from 0.37591\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.3771 - acc: 0.8862 - val_loss: 0.4040 - val_acc: 0.8868\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3546 - acc: 0.8927\n",
      "Epoch 00017: val_loss improved from 0.37591 to 0.33975, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/017-0.3398.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.3545 - acc: 0.8927 - val_loss: 0.3398 - val_acc: 0.9092\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3348 - acc: 0.8971\n",
      "Epoch 00018: val_loss did not improve from 0.33975\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.3348 - acc: 0.8971 - val_loss: 0.3478 - val_acc: 0.9064\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3210 - acc: 0.9016\n",
      "Epoch 00019: val_loss did not improve from 0.33975\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.3211 - acc: 0.9016 - val_loss: 0.3471 - val_acc: 0.9075\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3064 - acc: 0.9060\n",
      "Epoch 00020: val_loss did not improve from 0.33975\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.3064 - acc: 0.9060 - val_loss: 0.3629 - val_acc: 0.9008\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2913 - acc: 0.9111\n",
      "Epoch 00021: val_loss improved from 0.33975 to 0.32629, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/021-0.3263.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.2913 - acc: 0.9112 - val_loss: 0.3263 - val_acc: 0.9119\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2846 - acc: 0.9116\n",
      "Epoch 00022: val_loss did not improve from 0.32629\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.2846 - acc: 0.9116 - val_loss: 0.3510 - val_acc: 0.9029\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2691 - acc: 0.9154\n",
      "Epoch 00023: val_loss improved from 0.32629 to 0.31775, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/023-0.3177.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.2691 - acc: 0.9154 - val_loss: 0.3177 - val_acc: 0.9115\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2567 - acc: 0.9190\n",
      "Epoch 00024: val_loss did not improve from 0.31775\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.2567 - acc: 0.9190 - val_loss: 0.3241 - val_acc: 0.9159\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2469 - acc: 0.9226\n",
      "Epoch 00025: val_loss improved from 0.31775 to 0.31453, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/025-0.3145.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.2469 - acc: 0.9226 - val_loss: 0.3145 - val_acc: 0.9175\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.9268\n",
      "Epoch 00026: val_loss improved from 0.31453 to 0.31084, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/026-0.3108.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.2356 - acc: 0.9268 - val_loss: 0.3108 - val_acc: 0.9192\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2323 - acc: 0.9276\n",
      "Epoch 00027: val_loss improved from 0.31084 to 0.30831, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/027-0.3083.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.2322 - acc: 0.9276 - val_loss: 0.3083 - val_acc: 0.9182\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9298\n",
      "Epoch 00028: val_loss did not improve from 0.30831\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.2198 - acc: 0.9298 - val_loss: 0.3273 - val_acc: 0.9229\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2114 - acc: 0.9336\n",
      "Epoch 00029: val_loss improved from 0.30831 to 0.30002, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/029-0.3000.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.2115 - acc: 0.9336 - val_loss: 0.3000 - val_acc: 0.9257\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2103 - acc: 0.9338\n",
      "Epoch 00030: val_loss improved from 0.30002 to 0.29440, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/030-0.2944.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.2104 - acc: 0.9338 - val_loss: 0.2944 - val_acc: 0.9250\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9362\n",
      "Epoch 00031: val_loss did not improve from 0.29440\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1976 - acc: 0.9363 - val_loss: 0.3342 - val_acc: 0.9259\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9376\n",
      "Epoch 00032: val_loss did not improve from 0.29440\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1947 - acc: 0.9376 - val_loss: 0.3089 - val_acc: 0.9257\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1861 - acc: 0.9407\n",
      "Epoch 00033: val_loss did not improve from 0.29440\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1861 - acc: 0.9407 - val_loss: 0.3117 - val_acc: 0.9210\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9411\n",
      "Epoch 00034: val_loss did not improve from 0.29440\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1828 - acc: 0.9411 - val_loss: 0.3023 - val_acc: 0.9276\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9451\n",
      "Epoch 00035: val_loss did not improve from 0.29440\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1698 - acc: 0.9451 - val_loss: 0.3546 - val_acc: 0.9185\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9464\n",
      "Epoch 00036: val_loss did not improve from 0.29440\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1677 - acc: 0.9464 - val_loss: 0.3037 - val_acc: 0.9257\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9470\n",
      "Epoch 00037: val_loss did not improve from 0.29440\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1608 - acc: 0.9470 - val_loss: 0.3019 - val_acc: 0.9255\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9486\n",
      "Epoch 00038: val_loss did not improve from 0.29440\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1591 - acc: 0.9486 - val_loss: 0.2962 - val_acc: 0.9283\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9486\n",
      "Epoch 00039: val_loss improved from 0.29440 to 0.29071, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/039-0.2907.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1546 - acc: 0.9486 - val_loss: 0.2907 - val_acc: 0.9269\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9492\n",
      "Epoch 00040: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1500 - acc: 0.9492 - val_loss: 0.3200 - val_acc: 0.9234\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9532\n",
      "Epoch 00041: val_loss did not improve from 0.29071\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1422 - acc: 0.9532 - val_loss: 0.3170 - val_acc: 0.9203\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1427 - acc: 0.9539\n",
      "Epoch 00042: val_loss improved from 0.29071 to 0.28556, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_6_conv_checkpoint/042-0.2856.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1427 - acc: 0.9539 - val_loss: 0.2856 - val_acc: 0.9317\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9568\n",
      "Epoch 00043: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1311 - acc: 0.9569 - val_loss: 0.2964 - val_acc: 0.9315\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9569\n",
      "Epoch 00044: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1325 - acc: 0.9569 - val_loss: 0.3130 - val_acc: 0.9290\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9589\n",
      "Epoch 00045: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1226 - acc: 0.9589 - val_loss: 0.3095 - val_acc: 0.9327\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9585\n",
      "Epoch 00046: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1245 - acc: 0.9585 - val_loss: 0.2990 - val_acc: 0.9287\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9614\n",
      "Epoch 00047: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1205 - acc: 0.9614 - val_loss: 0.2975 - val_acc: 0.9329\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9629\n",
      "Epoch 00048: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1147 - acc: 0.9629 - val_loss: 0.3049 - val_acc: 0.9234\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9608\n",
      "Epoch 00049: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1188 - acc: 0.9608 - val_loss: 0.3047 - val_acc: 0.9276\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9639\n",
      "Epoch 00050: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1086 - acc: 0.9639 - val_loss: 0.2952 - val_acc: 0.9292\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9642\n",
      "Epoch 00051: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1076 - acc: 0.9642 - val_loss: 0.3054 - val_acc: 0.9306\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9649\n",
      "Epoch 00052: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1069 - acc: 0.9649 - val_loss: 0.3201 - val_acc: 0.9238\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9652\n",
      "Epoch 00053: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1065 - acc: 0.9652 - val_loss: 0.3306 - val_acc: 0.9227\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9661\n",
      "Epoch 00054: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1029 - acc: 0.9661 - val_loss: 0.3269 - val_acc: 0.9234\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9676\n",
      "Epoch 00055: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1004 - acc: 0.9676 - val_loss: 0.3047 - val_acc: 0.9345\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9682\n",
      "Epoch 00056: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0956 - acc: 0.9682 - val_loss: 0.3086 - val_acc: 0.9283\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9686\n",
      "Epoch 00057: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0958 - acc: 0.9686 - val_loss: 0.3160 - val_acc: 0.9297\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9687\n",
      "Epoch 00058: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0939 - acc: 0.9687 - val_loss: 0.2999 - val_acc: 0.9322\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9718\n",
      "Epoch 00059: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0863 - acc: 0.9718 - val_loss: 0.3159 - val_acc: 0.9273\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9709\n",
      "Epoch 00060: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0896 - acc: 0.9709 - val_loss: 0.2998 - val_acc: 0.9311\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9708\n",
      "Epoch 00061: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0895 - acc: 0.9708 - val_loss: 0.3110 - val_acc: 0.9324\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9724\n",
      "Epoch 00062: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0818 - acc: 0.9724 - val_loss: 0.3227 - val_acc: 0.9338\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9725\n",
      "Epoch 00063: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0852 - acc: 0.9725 - val_loss: 0.3009 - val_acc: 0.9324\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9720\n",
      "Epoch 00064: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0838 - acc: 0.9720 - val_loss: 0.3109 - val_acc: 0.9306\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9727\n",
      "Epoch 00065: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0817 - acc: 0.9727 - val_loss: 0.3125 - val_acc: 0.9315\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9751\n",
      "Epoch 00066: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0761 - acc: 0.9751 - val_loss: 0.3190 - val_acc: 0.9334\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9740\n",
      "Epoch 00067: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0784 - acc: 0.9740 - val_loss: 0.3008 - val_acc: 0.9369\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9751\n",
      "Epoch 00068: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0747 - acc: 0.9751 - val_loss: 0.3155 - val_acc: 0.9348\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9759\n",
      "Epoch 00069: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0742 - acc: 0.9759 - val_loss: 0.3347 - val_acc: 0.9348\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9763\n",
      "Epoch 00070: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0719 - acc: 0.9763 - val_loss: 0.3554 - val_acc: 0.9338\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9751\n",
      "Epoch 00071: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0733 - acc: 0.9751 - val_loss: 0.3191 - val_acc: 0.9345\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9772\n",
      "Epoch 00072: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0699 - acc: 0.9772 - val_loss: 0.3127 - val_acc: 0.9304\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9772\n",
      "Epoch 00073: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0709 - acc: 0.9772 - val_loss: 0.3154 - val_acc: 0.9350\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9789\n",
      "Epoch 00074: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0651 - acc: 0.9789 - val_loss: 0.3402 - val_acc: 0.9306\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9778\n",
      "Epoch 00075: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0666 - acc: 0.9778 - val_loss: 0.3145 - val_acc: 0.9331\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9780\n",
      "Epoch 00076: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0681 - acc: 0.9780 - val_loss: 0.3600 - val_acc: 0.9348\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9786\n",
      "Epoch 00077: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0633 - acc: 0.9786 - val_loss: 0.3101 - val_acc: 0.9359\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9779\n",
      "Epoch 00078: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0686 - acc: 0.9779 - val_loss: 0.3404 - val_acc: 0.9311\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9789\n",
      "Epoch 00079: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0637 - acc: 0.9789 - val_loss: 0.3288 - val_acc: 0.9371\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9803\n",
      "Epoch 00080: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0608 - acc: 0.9803 - val_loss: 0.3202 - val_acc: 0.9376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9800\n",
      "Epoch 00081: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0615 - acc: 0.9800 - val_loss: 0.3298 - val_acc: 0.9322\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9807\n",
      "Epoch 00082: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0607 - acc: 0.9807 - val_loss: 0.3329 - val_acc: 0.9355\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9798\n",
      "Epoch 00083: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0606 - acc: 0.9798 - val_loss: 0.3545 - val_acc: 0.9331\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9788\n",
      "Epoch 00084: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0610 - acc: 0.9788 - val_loss: 0.3464 - val_acc: 0.9343\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9800\n",
      "Epoch 00085: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0611 - acc: 0.9800 - val_loss: 0.3216 - val_acc: 0.9338\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9824\n",
      "Epoch 00086: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0553 - acc: 0.9824 - val_loss: 0.3756 - val_acc: 0.9297\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9820\n",
      "Epoch 00087: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0547 - acc: 0.9820 - val_loss: 0.3159 - val_acc: 0.9338\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9817\n",
      "Epoch 00088: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0574 - acc: 0.9817 - val_loss: 0.3282 - val_acc: 0.9348\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9823\n",
      "Epoch 00089: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0536 - acc: 0.9822 - val_loss: 0.3505 - val_acc: 0.9341\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9805\n",
      "Epoch 00090: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0584 - acc: 0.9805 - val_loss: 0.3447 - val_acc: 0.9343\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9823\n",
      "Epoch 00091: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0552 - acc: 0.9823 - val_loss: 0.3200 - val_acc: 0.9380\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9831\n",
      "Epoch 00092: val_loss did not improve from 0.28556\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0515 - acc: 0.9831 - val_loss: 0.3386 - val_acc: 0.9345\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3464 - acc: 0.9067\n",
      "Loss: 0.3463953990678797 Accuracy: 0.9067497\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2630 - acc: 0.2517\n",
      "Epoch 00001: val_loss improved from inf to 1.49391, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/001-1.4939.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 2.2629 - acc: 0.2517 - val_loss: 1.4939 - val_acc: 0.5192\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5172 - acc: 0.4947\n",
      "Epoch 00002: val_loss improved from 1.49391 to 1.17407, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/002-1.1741.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 1.5171 - acc: 0.4947 - val_loss: 1.1741 - val_acc: 0.6392\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2460 - acc: 0.5947\n",
      "Epoch 00003: val_loss improved from 1.17407 to 0.93336, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/003-0.9334.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 1.2460 - acc: 0.5947 - val_loss: 0.9334 - val_acc: 0.7219\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0232 - acc: 0.6732\n",
      "Epoch 00004: val_loss improved from 0.93336 to 0.72016, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/004-0.7202.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 1.0232 - acc: 0.6733 - val_loss: 0.7202 - val_acc: 0.8109\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8357 - acc: 0.7388\n",
      "Epoch 00005: val_loss improved from 0.72016 to 0.57633, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/005-0.5763.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.8358 - acc: 0.7388 - val_loss: 0.5763 - val_acc: 0.8376\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6915 - acc: 0.7889- ETA: 1s - loss: 0.6927 - acc: \n",
      "Epoch 00006: val_loss improved from 0.57633 to 0.47159, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/006-0.4716.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.6914 - acc: 0.7889 - val_loss: 0.4716 - val_acc: 0.8672\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5907 - acc: 0.8186\n",
      "Epoch 00007: val_loss improved from 0.47159 to 0.38360, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/007-0.3836.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.5907 - acc: 0.8187 - val_loss: 0.3836 - val_acc: 0.8901\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5246 - acc: 0.8406\n",
      "Epoch 00008: val_loss improved from 0.38360 to 0.34288, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/008-0.3429.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.5245 - acc: 0.8406 - val_loss: 0.3429 - val_acc: 0.9061\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8567\n",
      "Epoch 00009: val_loss improved from 0.34288 to 0.30198, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/009-0.3020.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.4647 - acc: 0.8567 - val_loss: 0.3020 - val_acc: 0.9196\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4167 - acc: 0.8709\n",
      "Epoch 00010: val_loss improved from 0.30198 to 0.27923, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/010-0.2792.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.4167 - acc: 0.8709 - val_loss: 0.2792 - val_acc: 0.9241\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3888 - acc: 0.8786\n",
      "Epoch 00011: val_loss did not improve from 0.27923\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.3889 - acc: 0.8785 - val_loss: 0.3080 - val_acc: 0.9166\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3663 - acc: 0.8879\n",
      "Epoch 00012: val_loss improved from 0.27923 to 0.25155, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/012-0.2516.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.3662 - acc: 0.8879 - val_loss: 0.2516 - val_acc: 0.9285\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3376 - acc: 0.8947\n",
      "Epoch 00013: val_loss improved from 0.25155 to 0.23974, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/013-0.2397.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.3376 - acc: 0.8947 - val_loss: 0.2397 - val_acc: 0.9322\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3179 - acc: 0.9009\n",
      "Epoch 00014: val_loss improved from 0.23974 to 0.23166, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/014-0.2317.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.3180 - acc: 0.9009 - val_loss: 0.2317 - val_acc: 0.9364\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2964 - acc: 0.9082\n",
      "Epoch 00015: val_loss improved from 0.23166 to 0.21238, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/015-0.2124.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2965 - acc: 0.9082 - val_loss: 0.2124 - val_acc: 0.9425\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2732 - acc: 0.9152\n",
      "Epoch 00016: val_loss improved from 0.21238 to 0.21213, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/016-0.2121.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2733 - acc: 0.9151 - val_loss: 0.2121 - val_acc: 0.9390\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2625 - acc: 0.9174\n",
      "Epoch 00017: val_loss improved from 0.21213 to 0.19719, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/017-0.1972.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2625 - acc: 0.9174 - val_loss: 0.1972 - val_acc: 0.9471\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2476 - acc: 0.9223\n",
      "Epoch 00018: val_loss improved from 0.19719 to 0.19387, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/018-0.1939.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2476 - acc: 0.9223 - val_loss: 0.1939 - val_acc: 0.9474\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2378 - acc: 0.9253\n",
      "Epoch 00019: val_loss did not improve from 0.19387\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2378 - acc: 0.9253 - val_loss: 0.2039 - val_acc: 0.9441\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9283\n",
      "Epoch 00020: val_loss did not improve from 0.19387\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2249 - acc: 0.9283 - val_loss: 0.2029 - val_acc: 0.9434\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2097 - acc: 0.9342\n",
      "Epoch 00021: val_loss improved from 0.19387 to 0.17616, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/021-0.1762.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2097 - acc: 0.9342 - val_loss: 0.1762 - val_acc: 0.9488\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2038 - acc: 0.9364\n",
      "Epoch 00022: val_loss improved from 0.17616 to 0.16493, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/022-0.1649.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2038 - acc: 0.9364 - val_loss: 0.1649 - val_acc: 0.9553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9372\n",
      "Epoch 00023: val_loss improved from 0.16493 to 0.15783, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/023-0.1578.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1976 - acc: 0.9372 - val_loss: 0.1578 - val_acc: 0.9550\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1901 - acc: 0.9388\n",
      "Epoch 00024: val_loss did not improve from 0.15783\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1901 - acc: 0.9388 - val_loss: 0.1594 - val_acc: 0.9550\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9402\n",
      "Epoch 00025: val_loss did not improve from 0.15783\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1846 - acc: 0.9402 - val_loss: 0.1652 - val_acc: 0.9548\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1779 - acc: 0.9433\n",
      "Epoch 00026: val_loss did not improve from 0.15783\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1778 - acc: 0.9433 - val_loss: 0.1628 - val_acc: 0.9557\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9474\n",
      "Epoch 00027: val_loss did not improve from 0.15783\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1682 - acc: 0.9474 - val_loss: 0.1587 - val_acc: 0.9599\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1648 - acc: 0.9470\n",
      "Epoch 00028: val_loss did not improve from 0.15783\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1648 - acc: 0.9470 - val_loss: 0.1903 - val_acc: 0.9448\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1611 - acc: 0.9483\n",
      "Epoch 00029: val_loss improved from 0.15783 to 0.15476, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/029-0.1548.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1611 - acc: 0.9483 - val_loss: 0.1548 - val_acc: 0.9560\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9515\n",
      "Epoch 00030: val_loss did not improve from 0.15476\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1516 - acc: 0.9516 - val_loss: 0.1565 - val_acc: 0.9609\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9531\n",
      "Epoch 00031: val_loss did not improve from 0.15476\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1465 - acc: 0.9531 - val_loss: 0.1670 - val_acc: 0.9511\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9530\n",
      "Epoch 00032: val_loss improved from 0.15476 to 0.14815, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/032-0.1482.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1444 - acc: 0.9530 - val_loss: 0.1482 - val_acc: 0.9569\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1418 - acc: 0.9536\n",
      "Epoch 00033: val_loss did not improve from 0.14815\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1418 - acc: 0.9536 - val_loss: 0.1650 - val_acc: 0.9527\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9558\n",
      "Epoch 00034: val_loss did not improve from 0.14815\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1338 - acc: 0.9558 - val_loss: 0.1546 - val_acc: 0.9602\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9549\n",
      "Epoch 00035: val_loss did not improve from 0.14815\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1355 - acc: 0.9549 - val_loss: 0.1589 - val_acc: 0.9609\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9585-\n",
      "Epoch 00036: val_loss improved from 0.14815 to 0.13799, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_7_conv_checkpoint/036-0.1380.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1284 - acc: 0.9585 - val_loss: 0.1380 - val_acc: 0.9627\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9603\n",
      "Epoch 00037: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1218 - acc: 0.9603 - val_loss: 0.1500 - val_acc: 0.9616\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9610\n",
      "Epoch 00038: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1200 - acc: 0.9610 - val_loss: 0.1472 - val_acc: 0.9606\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9613\n",
      "Epoch 00039: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1157 - acc: 0.9613 - val_loss: 0.1523 - val_acc: 0.9623\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9622\n",
      "Epoch 00040: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1128 - acc: 0.9622 - val_loss: 0.1653 - val_acc: 0.9592\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9634\n",
      "Epoch 00041: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1081 - acc: 0.9634 - val_loss: 0.1470 - val_acc: 0.9595\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9649\n",
      "Epoch 00042: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1058 - acc: 0.9649 - val_loss: 0.1581 - val_acc: 0.9595\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9657\n",
      "Epoch 00043: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1019 - acc: 0.9657 - val_loss: 0.1480 - val_acc: 0.9653\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9664\n",
      "Epoch 00044: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1022 - acc: 0.9664 - val_loss: 0.1805 - val_acc: 0.9511\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9693\n",
      "Epoch 00045: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0946 - acc: 0.9694 - val_loss: 0.1456 - val_acc: 0.9632\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9665\n",
      "Epoch 00046: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0999 - acc: 0.9665 - val_loss: 0.1728 - val_acc: 0.9583\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9683\n",
      "Epoch 00047: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0921 - acc: 0.9683 - val_loss: 0.1449 - val_acc: 0.9639\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9697\n",
      "Epoch 00048: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0884 - acc: 0.9697 - val_loss: 0.1598 - val_acc: 0.9620\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9712\n",
      "Epoch 00049: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0877 - acc: 0.9712 - val_loss: 0.1577 - val_acc: 0.9613\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9722\n",
      "Epoch 00050: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0837 - acc: 0.9722 - val_loss: 0.1699 - val_acc: 0.9623\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9720\n",
      "Epoch 00051: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0834 - acc: 0.9720 - val_loss: 0.1640 - val_acc: 0.9588\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9719\n",
      "Epoch 00052: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0848 - acc: 0.9719 - val_loss: 0.1474 - val_acc: 0.9667\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9749\n",
      "Epoch 00053: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0775 - acc: 0.9749 - val_loss: 0.1702 - val_acc: 0.9616\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9735\n",
      "Epoch 00054: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0789 - acc: 0.9735 - val_loss: 0.1694 - val_acc: 0.9606\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9739\n",
      "Epoch 00055: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0768 - acc: 0.9739 - val_loss: 0.1679 - val_acc: 0.9655\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9764\n",
      "Epoch 00056: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0711 - acc: 0.9764 - val_loss: 0.1972 - val_acc: 0.9569\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9753\n",
      "Epoch 00057: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0713 - acc: 0.9753 - val_loss: 0.1466 - val_acc: 0.9639\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9762\n",
      "Epoch 00058: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0690 - acc: 0.9762 - val_loss: 0.1545 - val_acc: 0.9637\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9769\n",
      "Epoch 00059: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0699 - acc: 0.9769 - val_loss: 0.1565 - val_acc: 0.9653\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9755\n",
      "Epoch 00060: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0698 - acc: 0.9755 - val_loss: 0.1542 - val_acc: 0.9639\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9777\n",
      "Epoch 00061: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0657 - acc: 0.9776 - val_loss: 0.1691 - val_acc: 0.9609\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9780\n",
      "Epoch 00062: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0633 - acc: 0.9780 - val_loss: 0.1650 - val_acc: 0.9625\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9802\n",
      "Epoch 00063: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0603 - acc: 0.9802 - val_loss: 0.1695 - val_acc: 0.9625\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9786\n",
      "Epoch 00064: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0621 - acc: 0.9786 - val_loss: 0.1518 - val_acc: 0.9627\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9799\n",
      "Epoch 00065: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0610 - acc: 0.9799 - val_loss: 0.1891 - val_acc: 0.9604\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9799\n",
      "Epoch 00066: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0615 - acc: 0.9799 - val_loss: 0.1673 - val_acc: 0.9632\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9809\n",
      "Epoch 00067: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0572 - acc: 0.9809 - val_loss: 0.1684 - val_acc: 0.9611\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9796\n",
      "Epoch 00068: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0604 - acc: 0.9796 - val_loss: 0.1732 - val_acc: 0.9604\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9809\n",
      "Epoch 00069: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0568 - acc: 0.9809 - val_loss: 0.1677 - val_acc: 0.9637\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9806\n",
      "Epoch 00070: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0560 - acc: 0.9806 - val_loss: 0.1711 - val_acc: 0.9644\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9823\n",
      "Epoch 00071: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0541 - acc: 0.9823 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9815\n",
      "Epoch 00072: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0544 - acc: 0.9815 - val_loss: 0.1607 - val_acc: 0.9651\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9815\n",
      "Epoch 00073: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0542 - acc: 0.9815 - val_loss: 0.1585 - val_acc: 0.9646\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9830\n",
      "Epoch 00074: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0498 - acc: 0.9830 - val_loss: 0.1773 - val_acc: 0.9634\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9830\n",
      "Epoch 00075: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0517 - acc: 0.9830 - val_loss: 0.1827 - val_acc: 0.9611\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9831\n",
      "Epoch 00076: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0499 - acc: 0.9831 - val_loss: 0.1659 - val_acc: 0.9625\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9830\n",
      "Epoch 00077: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0512 - acc: 0.9830 - val_loss: 0.1776 - val_acc: 0.9618\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9826\n",
      "Epoch 00078: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0492 - acc: 0.9826 - val_loss: 0.1839 - val_acc: 0.9620\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9842\n",
      "Epoch 00079: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0495 - acc: 0.9842 - val_loss: 0.1729 - val_acc: 0.9616\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9855\n",
      "Epoch 00080: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0435 - acc: 0.9855 - val_loss: 0.1696 - val_acc: 0.9634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9845\n",
      "Epoch 00081: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0447 - acc: 0.9845 - val_loss: 0.1591 - val_acc: 0.9644\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9856\n",
      "Epoch 00082: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0441 - acc: 0.9856 - val_loss: 0.1677 - val_acc: 0.9660\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9847\n",
      "Epoch 00083: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0453 - acc: 0.9847 - val_loss: 0.1556 - val_acc: 0.9634\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9860\n",
      "Epoch 00084: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0405 - acc: 0.9860 - val_loss: 0.1692 - val_acc: 0.9648\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9861\n",
      "Epoch 00085: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0420 - acc: 0.9861 - val_loss: 0.1888 - val_acc: 0.9630\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9867\n",
      "Epoch 00086: val_loss did not improve from 0.13799\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0406 - acc: 0.9867 - val_loss: 0.1674 - val_acc: 0.9665\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1737 - acc: 0.9508\n",
      "Loss: 0.1737203850305464 Accuracy: 0.95077884\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1899 - acc: 0.2811\n",
      "Epoch 00001: val_loss improved from inf to 1.30519, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/001-1.3052.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 2.1898 - acc: 0.2812 - val_loss: 1.3052 - val_acc: 0.5977\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3064 - acc: 0.5710\n",
      "Epoch 00002: val_loss improved from 1.30519 to 0.80767, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/002-0.8077.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 1.3064 - acc: 0.5710 - val_loss: 0.8077 - val_acc: 0.7603\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9832 - acc: 0.6802\n",
      "Epoch 00003: val_loss improved from 0.80767 to 0.57397, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/003-0.5740.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.9833 - acc: 0.6802 - val_loss: 0.5740 - val_acc: 0.8283\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7730 - acc: 0.7505\n",
      "Epoch 00004: val_loss improved from 0.57397 to 0.47827, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/004-0.4783.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.7730 - acc: 0.7505 - val_loss: 0.4783 - val_acc: 0.8640\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6178 - acc: 0.8026\n",
      "Epoch 00005: val_loss improved from 0.47827 to 0.33724, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/005-0.3372.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.6177 - acc: 0.8026 - val_loss: 0.3372 - val_acc: 0.8980\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5244 - acc: 0.8349\n",
      "Epoch 00006: val_loss improved from 0.33724 to 0.27736, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/006-0.2774.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.5243 - acc: 0.8349 - val_loss: 0.2774 - val_acc: 0.9206\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4431 - acc: 0.8600\n",
      "Epoch 00007: val_loss improved from 0.27736 to 0.23790, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/007-0.2379.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.4430 - acc: 0.8600 - val_loss: 0.2379 - val_acc: 0.9299\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3875 - acc: 0.8772\n",
      "Epoch 00008: val_loss improved from 0.23790 to 0.19807, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/008-0.1981.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.3874 - acc: 0.8772 - val_loss: 0.1981 - val_acc: 0.9434\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3498 - acc: 0.8897\n",
      "Epoch 00009: val_loss did not improve from 0.19807\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.3498 - acc: 0.8897 - val_loss: 0.2190 - val_acc: 0.9380\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3226 - acc: 0.9000\n",
      "Epoch 00010: val_loss improved from 0.19807 to 0.17441, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/010-0.1744.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.3226 - acc: 0.9000 - val_loss: 0.1744 - val_acc: 0.9515\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2882 - acc: 0.9097- ETA: 3s - loss: 0.\n",
      "Epoch 00011: val_loss did not improve from 0.17441\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2883 - acc: 0.9097 - val_loss: 0.1975 - val_acc: 0.9376\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2799 - acc: 0.9132\n",
      "Epoch 00012: val_loss improved from 0.17441 to 0.16457, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/012-0.1646.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2799 - acc: 0.9132 - val_loss: 0.1646 - val_acc: 0.9562\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2527 - acc: 0.9209\n",
      "Epoch 00013: val_loss did not improve from 0.16457\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2527 - acc: 0.9209 - val_loss: 0.1771 - val_acc: 0.9488\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2377 - acc: 0.9249\n",
      "Epoch 00014: val_loss improved from 0.16457 to 0.14729, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/014-0.1473.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2377 - acc: 0.9249 - val_loss: 0.1473 - val_acc: 0.9560\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2252 - acc: 0.9280\n",
      "Epoch 00015: val_loss improved from 0.14729 to 0.14253, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/015-0.1425.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2252 - acc: 0.9280 - val_loss: 0.1425 - val_acc: 0.9571\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9336\n",
      "Epoch 00016: val_loss did not improve from 0.14253\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2086 - acc: 0.9336 - val_loss: 0.1597 - val_acc: 0.9509\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9353\n",
      "Epoch 00017: val_loss did not improve from 0.14253\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2023 - acc: 0.9353 - val_loss: 0.1428 - val_acc: 0.9616\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9401\n",
      "Epoch 00018: val_loss improved from 0.14253 to 0.12187, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/018-0.1219.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1886 - acc: 0.9401 - val_loss: 0.1219 - val_acc: 0.9623\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1774 - acc: 0.9431\n",
      "Epoch 00019: val_loss did not improve from 0.12187\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1774 - acc: 0.9431 - val_loss: 0.1230 - val_acc: 0.9653\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9453\n",
      "Epoch 00020: val_loss did not improve from 0.12187\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1737 - acc: 0.9453 - val_loss: 0.1250 - val_acc: 0.9662\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9481\n",
      "Epoch 00021: val_loss did not improve from 0.12187\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1599 - acc: 0.9481 - val_loss: 0.1232 - val_acc: 0.9641\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9519\n",
      "Epoch 00022: val_loss improved from 0.12187 to 0.10646, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/022-0.1065.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1530 - acc: 0.9519 - val_loss: 0.1065 - val_acc: 0.9681\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1470 - acc: 0.9536\n",
      "Epoch 00023: val_loss did not improve from 0.10646\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1470 - acc: 0.9536 - val_loss: 0.1181 - val_acc: 0.9648\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9550\n",
      "Epoch 00024: val_loss did not improve from 0.10646\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1407 - acc: 0.9550 - val_loss: 0.1117 - val_acc: 0.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9556  ETA: 11s \n",
      "Epoch 00025: val_loss did not improve from 0.10646\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1372 - acc: 0.9556 - val_loss: 0.1173 - val_acc: 0.9630\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9598\n",
      "Epoch 00026: val_loss did not improve from 0.10646\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1276 - acc: 0.9598 - val_loss: 0.1070 - val_acc: 0.9665\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9589\n",
      "Epoch 00027: val_loss did not improve from 0.10646\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1257 - acc: 0.9589 - val_loss: 0.1179 - val_acc: 0.9648\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9616\n",
      "Epoch 00028: val_loss did not improve from 0.10646\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1182 - acc: 0.9616 - val_loss: 0.1119 - val_acc: 0.9669\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9634\n",
      "Epoch 00029: val_loss did not improve from 0.10646\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1142 - acc: 0.9634 - val_loss: 0.1104 - val_acc: 0.9679\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9639\n",
      "Epoch 00030: val_loss improved from 0.10646 to 0.10213, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/030-0.1021.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1102 - acc: 0.9639 - val_loss: 0.1021 - val_acc: 0.9704\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9660\n",
      "Epoch 00031: val_loss did not improve from 0.10213\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1040 - acc: 0.9660 - val_loss: 0.1135 - val_acc: 0.9667\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9674\n",
      "Epoch 00032: val_loss did not improve from 0.10213\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1013 - acc: 0.9674 - val_loss: 0.1071 - val_acc: 0.9686\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0983 - acc: 0.9677\n",
      "Epoch 00033: val_loss did not improve from 0.10213\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0983 - acc: 0.9677 - val_loss: 0.1173 - val_acc: 0.9646\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9701\n",
      "Epoch 00034: val_loss did not improve from 0.10213\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0927 - acc: 0.9701 - val_loss: 0.1022 - val_acc: 0.9700\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9702\n",
      "Epoch 00035: val_loss improved from 0.10213 to 0.09856, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/035-0.0986.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0883 - acc: 0.9702 - val_loss: 0.0986 - val_acc: 0.9739\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9700\n",
      "Epoch 00036: val_loss did not improve from 0.09856\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0897 - acc: 0.9700 - val_loss: 0.1162 - val_acc: 0.9662\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9720\n",
      "Epoch 00037: val_loss improved from 0.09856 to 0.08727, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_8_conv_checkpoint/037-0.0873.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0856 - acc: 0.9720 - val_loss: 0.0873 - val_acc: 0.9758\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9739\n",
      "Epoch 00038: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0805 - acc: 0.9739 - val_loss: 0.1250 - val_acc: 0.9716\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9733\n",
      "Epoch 00039: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0790 - acc: 0.9733 - val_loss: 0.1085 - val_acc: 0.9700\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9737\n",
      "Epoch 00040: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0785 - acc: 0.9737 - val_loss: 0.1026 - val_acc: 0.9716\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9744\n",
      "Epoch 00041: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0750 - acc: 0.9744 - val_loss: 0.1138 - val_acc: 0.9674\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9758\n",
      "Epoch 00042: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0724 - acc: 0.9758 - val_loss: 0.1092 - val_acc: 0.9711\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9768\n",
      "Epoch 00043: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0707 - acc: 0.9768 - val_loss: 0.1080 - val_acc: 0.9683\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9778\n",
      "Epoch 00044: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0662 - acc: 0.9778 - val_loss: 0.1164 - val_acc: 0.9723\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9767\n",
      "Epoch 00045: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0698 - acc: 0.9767 - val_loss: 0.1055 - val_acc: 0.9704\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9793- ETA: \n",
      "Epoch 00046: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0620 - acc: 0.9794 - val_loss: 0.1023 - val_acc: 0.9720\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9788\n",
      "Epoch 00047: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0647 - acc: 0.9788 - val_loss: 0.1065 - val_acc: 0.9683\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9805\n",
      "Epoch 00048: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0587 - acc: 0.9805 - val_loss: 0.1044 - val_acc: 0.9725\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9805- \n",
      "Epoch 00049: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0587 - acc: 0.9805 - val_loss: 0.1004 - val_acc: 0.9730\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9814\n",
      "Epoch 00050: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0573 - acc: 0.9814 - val_loss: 0.1059 - val_acc: 0.9711\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9820\n",
      "Epoch 00051: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0548 - acc: 0.9820 - val_loss: 0.0992 - val_acc: 0.9727\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9810\n",
      "Epoch 00052: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0554 - acc: 0.9810 - val_loss: 0.1107 - val_acc: 0.9727\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9836- ETA: 4s - loss\n",
      "Epoch 00053: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0496 - acc: 0.9836 - val_loss: 0.1150 - val_acc: 0.9681\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9828\n",
      "Epoch 00054: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0517 - acc: 0.9828 - val_loss: 0.1051 - val_acc: 0.9720\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9828\n",
      "Epoch 00055: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0496 - acc: 0.9828 - val_loss: 0.1032 - val_acc: 0.9741\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9838\n",
      "Epoch 00056: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0491 - acc: 0.9838 - val_loss: 0.1152 - val_acc: 0.9700\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9843\n",
      "Epoch 00057: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0472 - acc: 0.9843 - val_loss: 0.1115 - val_acc: 0.9711\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9846\n",
      "Epoch 00058: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0456 - acc: 0.9846 - val_loss: 0.1183 - val_acc: 0.9683\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9859\n",
      "Epoch 00059: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0443 - acc: 0.9859 - val_loss: 0.1125 - val_acc: 0.9709\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9843\n",
      "Epoch 00060: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0482 - acc: 0.9843 - val_loss: 0.1012 - val_acc: 0.9723\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9848\n",
      "Epoch 00061: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0437 - acc: 0.9848 - val_loss: 0.1057 - val_acc: 0.9697\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9855\n",
      "Epoch 00062: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0418 - acc: 0.9855 - val_loss: 0.1511 - val_acc: 0.9655\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9863\n",
      "Epoch 00063: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0400 - acc: 0.9863 - val_loss: 0.1288 - val_acc: 0.9697\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9850\n",
      "Epoch 00064: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0429 - acc: 0.9850 - val_loss: 0.1023 - val_acc: 0.9732\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9876\n",
      "Epoch 00065: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0386 - acc: 0.9876 - val_loss: 0.1197 - val_acc: 0.9716\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9869\n",
      "Epoch 00066: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0387 - acc: 0.9869 - val_loss: 0.1190 - val_acc: 0.9709\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9885\n",
      "Epoch 00067: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0334 - acc: 0.9885 - val_loss: 0.1189 - val_acc: 0.9711\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9875\n",
      "Epoch 00068: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0376 - acc: 0.9875 - val_loss: 0.1123 - val_acc: 0.9709\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9867\n",
      "Epoch 00069: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0379 - acc: 0.9867 - val_loss: 0.1135 - val_acc: 0.9700\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9885\n",
      "Epoch 00070: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0353 - acc: 0.9885 - val_loss: 0.1248 - val_acc: 0.9704\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9884\n",
      "Epoch 00071: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0322 - acc: 0.9884 - val_loss: 0.1161 - val_acc: 0.9709\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9884\n",
      "Epoch 00072: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0343 - acc: 0.9884 - val_loss: 0.1245 - val_acc: 0.9732\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9894\n",
      "Epoch 00073: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0314 - acc: 0.9894 - val_loss: 0.1208 - val_acc: 0.9732\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9883- ETA: 2s - loss: 0.033\n",
      "Epoch 00074: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0333 - acc: 0.9883 - val_loss: 0.1193 - val_acc: 0.9716\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9896\n",
      "Epoch 00075: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0308 - acc: 0.9896 - val_loss: 0.1131 - val_acc: 0.9734\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9897\n",
      "Epoch 00076: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0312 - acc: 0.9897 - val_loss: 0.1103 - val_acc: 0.9725\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9907\n",
      "Epoch 00077: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0274 - acc: 0.9907 - val_loss: 0.1241 - val_acc: 0.9709\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9906\n",
      "Epoch 00078: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0274 - acc: 0.9906 - val_loss: 0.1312 - val_acc: 0.9709\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9906\n",
      "Epoch 00079: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0285 - acc: 0.9906 - val_loss: 0.1489 - val_acc: 0.9702\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9906\n",
      "Epoch 00080: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0298 - acc: 0.9906 - val_loss: 0.1521 - val_acc: 0.9711\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9908\n",
      "Epoch 00081: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0276 - acc: 0.9908 - val_loss: 0.1164 - val_acc: 0.9739\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9919\n",
      "Epoch 00082: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0241 - acc: 0.9919 - val_loss: 0.1347 - val_acc: 0.9718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9911\n",
      "Epoch 00083: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0258 - acc: 0.9911 - val_loss: 0.1452 - val_acc: 0.9711\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9923\n",
      "Epoch 00084: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0256 - acc: 0.9923 - val_loss: 0.1469 - val_acc: 0.9679\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9914\n",
      "Epoch 00085: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0261 - acc: 0.9914 - val_loss: 0.1283 - val_acc: 0.9700\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9916\n",
      "Epoch 00086: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0267 - acc: 0.9916 - val_loss: 0.1272 - val_acc: 0.9734\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9933\n",
      "Epoch 00087: val_loss did not improve from 0.08727\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0208 - acc: 0.9933 - val_loss: 0.1404 - val_acc: 0.9725\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1344 - acc: 0.9610\n",
      "Loss: 0.1344477171204048 Accuracy: 0.9609553\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8336 - acc: 0.3963\n",
      "Epoch 00001: val_loss improved from inf to 0.85812, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/001-0.8581.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 1.8336 - acc: 0.3963 - val_loss: 0.8581 - val_acc: 0.7289\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8779 - acc: 0.7151\n",
      "Epoch 00002: val_loss improved from 0.85812 to 0.60062, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/002-0.6006.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.8779 - acc: 0.7151 - val_loss: 0.6006 - val_acc: 0.8083\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6274 - acc: 0.8005\n",
      "Epoch 00003: val_loss improved from 0.60062 to 0.34585, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/003-0.3459.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.6273 - acc: 0.8006 - val_loss: 0.3459 - val_acc: 0.8917\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4705 - acc: 0.8512\n",
      "Epoch 00004: val_loss improved from 0.34585 to 0.27010, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/004-0.2701.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.4706 - acc: 0.8512 - val_loss: 0.2701 - val_acc: 0.9171\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3839 - acc: 0.8796\n",
      "Epoch 00005: val_loss improved from 0.27010 to 0.22303, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/005-0.2230.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.3838 - acc: 0.8796 - val_loss: 0.2230 - val_acc: 0.9283\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3301 - acc: 0.8980\n",
      "Epoch 00006: val_loss improved from 0.22303 to 0.20089, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/006-0.2009.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.3300 - acc: 0.8980 - val_loss: 0.2009 - val_acc: 0.9357\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2804 - acc: 0.9112\n",
      "Epoch 00007: val_loss improved from 0.20089 to 0.18945, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/007-0.1895.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2804 - acc: 0.9112 - val_loss: 0.1895 - val_acc: 0.9392\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2512 - acc: 0.9217\n",
      "Epoch 00008: val_loss improved from 0.18945 to 0.16272, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/008-0.1627.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2512 - acc: 0.9217 - val_loss: 0.1627 - val_acc: 0.9492\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2233 - acc: 0.9298\n",
      "Epoch 00009: val_loss improved from 0.16272 to 0.13796, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/009-0.1380.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2232 - acc: 0.9298 - val_loss: 0.1380 - val_acc: 0.9611\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2042 - acc: 0.9355\n",
      "Epoch 00010: val_loss improved from 0.13796 to 0.13511, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/010-0.1351.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2042 - acc: 0.9355 - val_loss: 0.1351 - val_acc: 0.9583\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1876 - acc: 0.9400\n",
      "Epoch 00011: val_loss did not improve from 0.13511\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1877 - acc: 0.9400 - val_loss: 0.1437 - val_acc: 0.9576\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9441\n",
      "Epoch 00012: val_loss did not improve from 0.13511\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1793 - acc: 0.9441 - val_loss: 0.1669 - val_acc: 0.9464\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9503\n",
      "Epoch 00013: val_loss did not improve from 0.13511\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1549 - acc: 0.9503 - val_loss: 0.1450 - val_acc: 0.9592\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9542\n",
      "Epoch 00014: val_loss did not improve from 0.13511\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1455 - acc: 0.9542 - val_loss: 0.1355 - val_acc: 0.9585\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9579\n",
      "Epoch 00015: val_loss improved from 0.13511 to 0.12898, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/015-0.1290.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1333 - acc: 0.9579 - val_loss: 0.1290 - val_acc: 0.9592\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9581\n",
      "Epoch 00016: val_loss improved from 0.12898 to 0.12151, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/016-0.1215.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1264 - acc: 0.9581 - val_loss: 0.1215 - val_acc: 0.9648\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.9616\n",
      "Epoch 00017: val_loss did not improve from 0.12151\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1185 - acc: 0.9616 - val_loss: 0.1288 - val_acc: 0.9632\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9642\n",
      "Epoch 00018: val_loss improved from 0.12151 to 0.11084, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/018-0.1108.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1110 - acc: 0.9642 - val_loss: 0.1108 - val_acc: 0.9693\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9674\n",
      "Epoch 00019: val_loss improved from 0.11084 to 0.10576, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/019-0.1058.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1015 - acc: 0.9674 - val_loss: 0.1058 - val_acc: 0.9679\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0983 - acc: 0.9682\n",
      "Epoch 00020: val_loss did not improve from 0.10576\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0982 - acc: 0.9682 - val_loss: 0.1149 - val_acc: 0.9662\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9687\n",
      "Epoch 00021: val_loss did not improve from 0.10576\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0946 - acc: 0.9687 - val_loss: 0.1187 - val_acc: 0.9651\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9719\n",
      "Epoch 00022: val_loss did not improve from 0.10576\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0855 - acc: 0.9719 - val_loss: 0.1143 - val_acc: 0.9676\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9730\n",
      "Epoch 00023: val_loss improved from 0.10576 to 0.09367, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/023-0.0937.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0806 - acc: 0.9730 - val_loss: 0.0937 - val_acc: 0.9718\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9735\n",
      "Epoch 00024: val_loss did not improve from 0.09367\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0790 - acc: 0.9735 - val_loss: 0.1276 - val_acc: 0.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9748\n",
      "Epoch 00025: val_loss did not improve from 0.09367\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0767 - acc: 0.9748 - val_loss: 0.1204 - val_acc: 0.9662\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9768\n",
      "Epoch 00026: val_loss did not improve from 0.09367\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0706 - acc: 0.9768 - val_loss: 0.1201 - val_acc: 0.9681\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9786\n",
      "Epoch 00027: val_loss did not improve from 0.09367\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0636 - acc: 0.9786 - val_loss: 0.1146 - val_acc: 0.9693\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9802\n",
      "Epoch 00028: val_loss did not improve from 0.09367\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0611 - acc: 0.9802 - val_loss: 0.1041 - val_acc: 0.9716\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9803\n",
      "Epoch 00029: val_loss did not improve from 0.09367\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0580 - acc: 0.9803 - val_loss: 0.1066 - val_acc: 0.9713\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9807\n",
      "Epoch 00030: val_loss did not improve from 0.09367\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0576 - acc: 0.9807 - val_loss: 0.1020 - val_acc: 0.9711\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9813\n",
      "Epoch 00031: val_loss did not improve from 0.09367\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0556 - acc: 0.9813 - val_loss: 0.1125 - val_acc: 0.9716\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9826\n",
      "Epoch 00032: val_loss did not improve from 0.09367\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0525 - acc: 0.9826 - val_loss: 0.1189 - val_acc: 0.9702\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9840\n",
      "Epoch 00033: val_loss did not improve from 0.09367\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0473 - acc: 0.9840 - val_loss: 0.1219 - val_acc: 0.9702\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9836\n",
      "Epoch 00034: val_loss improved from 0.09367 to 0.09300, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_075_DO_9_conv_checkpoint/034-0.0930.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0498 - acc: 0.9836 - val_loss: 0.0930 - val_acc: 0.9744\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9849\n",
      "Epoch 00035: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0476 - acc: 0.9849 - val_loss: 0.1094 - val_acc: 0.9704\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9855\n",
      "Epoch 00036: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0431 - acc: 0.9855 - val_loss: 0.1167 - val_acc: 0.9730\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9849\n",
      "Epoch 00037: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0459 - acc: 0.9849 - val_loss: 0.1148 - val_acc: 0.9718\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9866\n",
      "Epoch 00038: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0403 - acc: 0.9866 - val_loss: 0.1170 - val_acc: 0.9690\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9885\n",
      "Epoch 00039: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0358 - acc: 0.9885 - val_loss: 0.1191 - val_acc: 0.9693\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9872\n",
      "Epoch 00040: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0416 - acc: 0.9872 - val_loss: 0.1217 - val_acc: 0.9706\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9876\n",
      "Epoch 00041: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0357 - acc: 0.9876 - val_loss: 0.1105 - val_acc: 0.9716\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9867\n",
      "Epoch 00042: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0399 - acc: 0.9867 - val_loss: 0.1051 - val_acc: 0.9718\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9889\n",
      "Epoch 00043: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0323 - acc: 0.9889 - val_loss: 0.1353 - val_acc: 0.9702\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9887\n",
      "Epoch 00044: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0349 - acc: 0.9888 - val_loss: 0.1120 - val_acc: 0.9725\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9901\n",
      "Epoch 00045: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0319 - acc: 0.9901 - val_loss: 0.1229 - val_acc: 0.9753\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9908\n",
      "Epoch 00046: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0285 - acc: 0.9908 - val_loss: 0.1451 - val_acc: 0.9681\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9902\n",
      "Epoch 00047: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0303 - acc: 0.9902 - val_loss: 0.1361 - val_acc: 0.9695\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9911\n",
      "Epoch 00048: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0301 - acc: 0.9911 - val_loss: 0.1421 - val_acc: 0.9704\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9890\n",
      "Epoch 00049: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0330 - acc: 0.9890 - val_loss: 0.1401 - val_acc: 0.9732\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9915\n",
      "Epoch 00050: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0270 - acc: 0.9915 - val_loss: 0.1275 - val_acc: 0.9704\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9929\n",
      "Epoch 00051: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0238 - acc: 0.9929 - val_loss: 0.1384 - val_acc: 0.9723\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9912\n",
      "Epoch 00052: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0280 - acc: 0.9912 - val_loss: 0.1424 - val_acc: 0.9693\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9921\n",
      "Epoch 00053: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0243 - acc: 0.9921 - val_loss: 0.1692 - val_acc: 0.9674\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9921\n",
      "Epoch 00054: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0246 - acc: 0.9921 - val_loss: 0.1284 - val_acc: 0.9688\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9930\n",
      "Epoch 00055: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0213 - acc: 0.9930 - val_loss: 0.1358 - val_acc: 0.9718\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9932\n",
      "Epoch 00056: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0218 - acc: 0.9932 - val_loss: 0.1536 - val_acc: 0.9704\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9922\n",
      "Epoch 00057: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0226 - acc: 0.9922 - val_loss: 0.1682 - val_acc: 0.9674\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9931\n",
      "Epoch 00058: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0224 - acc: 0.9931 - val_loss: 0.1258 - val_acc: 0.9711\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9936\n",
      "Epoch 00059: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0211 - acc: 0.9936 - val_loss: 0.1451 - val_acc: 0.9697\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9909\n",
      "Epoch 00060: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0285 - acc: 0.9909 - val_loss: 0.1473 - val_acc: 0.9706\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9935\n",
      "Epoch 00061: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0194 - acc: 0.9935 - val_loss: 0.1526 - val_acc: 0.9688\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9945\n",
      "Epoch 00062: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0181 - acc: 0.9945 - val_loss: 0.1412 - val_acc: 0.9709\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9933\n",
      "Epoch 00063: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0207 - acc: 0.9933 - val_loss: 0.1717 - val_acc: 0.9706\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9937\n",
      "Epoch 00064: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0196 - acc: 0.9937 - val_loss: 0.1448 - val_acc: 0.9734\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9938\n",
      "Epoch 00065: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0181 - acc: 0.9938 - val_loss: 0.1400 - val_acc: 0.9720\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9946\n",
      "Epoch 00066: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0175 - acc: 0.9946 - val_loss: 0.1405 - val_acc: 0.9716\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9948\n",
      "Epoch 00067: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0159 - acc: 0.9948 - val_loss: 0.1536 - val_acc: 0.9723\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9938\n",
      "Epoch 00068: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0206 - acc: 0.9938 - val_loss: 0.1499 - val_acc: 0.9725\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9945\n",
      "Epoch 00069: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0173 - acc: 0.9945 - val_loss: 0.1398 - val_acc: 0.9713\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9949\n",
      "Epoch 00070: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0168 - acc: 0.9949 - val_loss: 0.1317 - val_acc: 0.9716\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9961\n",
      "Epoch 00071: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0130 - acc: 0.9961 - val_loss: 0.1510 - val_acc: 0.9711\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9948\n",
      "Epoch 00072: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0179 - acc: 0.9948 - val_loss: 0.1435 - val_acc: 0.9725\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9942\n",
      "Epoch 00073: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0173 - acc: 0.9942 - val_loss: 0.1551 - val_acc: 0.9690\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9955\n",
      "Epoch 00074: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0153 - acc: 0.9955 - val_loss: 0.1581 - val_acc: 0.9674\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9954\n",
      "Epoch 00075: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0150 - acc: 0.9954 - val_loss: 0.1505 - val_acc: 0.9720\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9951\n",
      "Epoch 00076: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0170 - acc: 0.9951 - val_loss: 0.1685 - val_acc: 0.9704\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9951\n",
      "Epoch 00077: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0169 - acc: 0.9951 - val_loss: 0.1440 - val_acc: 0.9693\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9954\n",
      "Epoch 00078: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0143 - acc: 0.9954 - val_loss: 0.1726 - val_acc: 0.9706\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9964\n",
      "Epoch 00079: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0118 - acc: 0.9964 - val_loss: 0.1384 - val_acc: 0.9727\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9949\n",
      "Epoch 00080: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0174 - acc: 0.9949 - val_loss: 0.1563 - val_acc: 0.9697\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9954\n",
      "Epoch 00081: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0137 - acc: 0.9954 - val_loss: 0.1416 - val_acc: 0.9751\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9963\n",
      "Epoch 00082: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0115 - acc: 0.9963 - val_loss: 0.1819 - val_acc: 0.9758\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9964\n",
      "Epoch 00083: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0128 - acc: 0.9964 - val_loss: 0.1517 - val_acc: 0.9758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9952\n",
      "Epoch 00084: val_loss did not improve from 0.09300\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0155 - acc: 0.9952 - val_loss: 0.1313 - val_acc: 0.9727\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1569 - acc: 0.9570\n",
      "Loss: 0.15691328315714206 Accuracy: 0.9570094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    base = '1D_CNN_custom_ch_128_DO_075_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_ch_128_DO(conv_num=i)\n",
    "\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 3,804,176\n",
      "Trainable params: 3,804,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.3620 - acc: 0.5755\n",
      "Loss: 1.3620327086958681 Accuracy: 0.5754933\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,459,344\n",
      "Trainable params: 1,459,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.9251 - acc: 0.7371\n",
      "Loss: 0.9251436805056634 Accuracy: 0.73707163\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 1,217,936\n",
      "Trainable params: 1,217,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.6811 - acc: 0.8104\n",
      "Loss: 0.6811446335951983 Accuracy: 0.8103842\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 1,005,200\n",
      "Trainable params: 1,005,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3464 - acc: 0.9067\n",
      "Loss: 0.3463953990678797 Accuracy: 0.9067497\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 1,152,912\n",
      "Trainable params: 1,152,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1737 - acc: 0.9508\n",
      "Loss: 0.1737203850305464 Accuracy: 0.95077884\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,423,504\n",
      "Trainable params: 1,423,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1344 - acc: 0.9610\n",
      "Loss: 0.1344477171204048 Accuracy: 0.9609553\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 2,067,088\n",
      "Trainable params: 2,067,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1569 - acc: 0.9570\n",
      "Loss: 0.15691328315714206 Accuracy: 0.9570094\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_ch_128_DO_075_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 3,804,176\n",
      "Trainable params: 3,804,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.1086 - acc: 0.6476\n",
      "Loss: 2.1086193520455843 Accuracy: 0.6475597\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,459,344\n",
      "Trainable params: 1,459,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.1177 - acc: 0.7803\n",
      "Loss: 1.1176786813409159 Accuracy: 0.78027\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 1,217,936\n",
      "Trainable params: 1,217,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.8258 - acc: 0.8386\n",
      "Loss: 0.8258459256816876 Accuracy: 0.8386293\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 1,005,200\n",
      "Trainable params: 1,005,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3846 - acc: 0.9130\n",
      "Loss: 0.38458654764045497 Accuracy: 0.91298026\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 1,152,912\n",
      "Trainable params: 1,152,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.1858 - acc: 0.9576\n",
      "Loss: 0.185761561138538 Accuracy: 0.9576324\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,423,504\n",
      "Trainable params: 1,423,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.1969 - acc: 0.9618\n",
      "Loss: 0.19691558386261312 Accuracy: 0.9617861\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_075_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 2,067,088\n",
      "Trainable params: 2,067,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.1983 - acc: 0.9645\n",
      "Loss: 0.19834257886027082 Accuracy: 0.964486\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
