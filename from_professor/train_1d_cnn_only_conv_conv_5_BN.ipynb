{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_only_conv_conv_5_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=8, strides=1, padding='valid', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=8*(2**(i+1)), strides=1, padding='valid'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 42656)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 42656)             170624    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                682512    \n",
      "=================================================================\n",
      "Total params: 853,216\n",
      "Trainable params: 767,888\n",
      "Non-trainable params: 85,328\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 28416)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 28416)             113664    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                454672    \n",
      "=================================================================\n",
      "Total params: 569,136\n",
      "Trainable params: 512,256\n",
      "Non-trainable params: 56,880\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1772, 32)          2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 1772, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1772, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 591, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18912)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 18912)             75648     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                302608    \n",
      "=================================================================\n",
      "Total params: 381,776\n",
      "Trainable params: 343,840\n",
      "Non-trainable params: 37,936\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 1772, 32)          2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 1772, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1772, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 591, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 587, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 587, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 587, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 196, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                200720    \n",
      "=================================================================\n",
      "Total params: 264,976\n",
      "Trainable params: 239,648\n",
      "Non-trainable params: 25,328\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 1772, 32)          2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 1772, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1772, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 591, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 587, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 587, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 587, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 196, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 192, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 192, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 192, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                131088    \n",
      "=================================================================\n",
      "Total params: 219,536\n",
      "Trainable params: 202,656\n",
      "Non-trainable params: 16,880\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 1772, 32)          2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 1772, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1772, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 591, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 587, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 587, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 587, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 196, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 192, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 192, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 192, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 60, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 60, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 5120)              20480     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                81936     \n",
      "=================================================================\n",
      "Total params: 323,216\n",
      "Trainable params: 311,968\n",
      "Non-trainable params: 11,248\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 1772, 32)          2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 1772, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 1772, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 591, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 587, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 587, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 587, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 196, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 192, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 192, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 192, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 60, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 60, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 16, 512)           655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16, 512)           2048      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 16, 512)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 6, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                49168     \n",
      "=================================================================\n",
      "Total params: 940,176\n",
      "Trainable params: 932,000\n",
      "Non-trainable params: 8,176\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 1772, 32)          2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 1772, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1772, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 591, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 587, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 587, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 587, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 196, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 192, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 192, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 192, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 60, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 60, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 16, 512)           655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 16, 512)           2048      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16, 512)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 6, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 2, 1024)           2622464   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 2, 1024)           4096      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 2, 1024)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 3,525,776\n",
      "Trainable params: 3,519,648\n",
      "Non-trainable params: 6,128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 9):\n",
    "    model = build_1d_cnn_only_conv_conv_5_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7607 - acc: 0.2316\n",
      "Epoch 00001: val_loss improved from inf to 2.51668, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_1_conv_checkpoint/001-2.5167.hdf5\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 2.7607 - acc: 0.2316 - val_loss: 2.5167 - val_acc: 0.2304\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0492 - acc: 0.3849\n",
      "Epoch 00002: val_loss improved from 2.51668 to 2.49848, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_1_conv_checkpoint/002-2.4985.hdf5\n",
      "36805/36805 [==============================] - 9s 252us/sample - loss: 2.0495 - acc: 0.3848 - val_loss: 2.4985 - val_acc: 0.3096\n",
      "Epoch 3/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7090 - acc: 0.4774\n",
      "Epoch 00003: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 250us/sample - loss: 1.7091 - acc: 0.4773 - val_loss: 2.5328 - val_acc: 0.3068\n",
      "Epoch 4/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 1.4980 - acc: 0.5389\n",
      "Epoch 00004: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 250us/sample - loss: 1.4990 - acc: 0.5388 - val_loss: 2.5765 - val_acc: 0.3093\n",
      "Epoch 5/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 1.3321 - acc: 0.5881\n",
      "Epoch 00005: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 249us/sample - loss: 1.3339 - acc: 0.5878 - val_loss: 2.5862 - val_acc: 0.3068\n",
      "Epoch 6/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 1.1977 - acc: 0.6280\n",
      "Epoch 00006: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 251us/sample - loss: 1.1985 - acc: 0.6276 - val_loss: 2.7489 - val_acc: 0.2772\n",
      "Epoch 7/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 1.0952 - acc: 0.6593\n",
      "Epoch 00007: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 250us/sample - loss: 1.0967 - acc: 0.6589 - val_loss: 2.7805 - val_acc: 0.3089\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0027 - acc: 0.6914\n",
      "Epoch 00008: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 246us/sample - loss: 1.0030 - acc: 0.6913 - val_loss: 2.7349 - val_acc: 0.3133\n",
      "Epoch 9/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.9327 - acc: 0.7120\n",
      "Epoch 00009: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.9336 - acc: 0.7118 - val_loss: 2.9120 - val_acc: 0.3047\n",
      "Epoch 10/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.8639 - acc: 0.7321\n",
      "Epoch 00010: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 244us/sample - loss: 0.8647 - acc: 0.7319 - val_loss: 2.9190 - val_acc: 0.3098\n",
      "Epoch 11/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8083 - acc: 0.7522\n",
      "Epoch 00011: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.8087 - acc: 0.7521 - val_loss: 3.2562 - val_acc: 0.2791\n",
      "Epoch 12/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.7615 - acc: 0.7681\n",
      "Epoch 00012: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 247us/sample - loss: 0.7625 - acc: 0.7678 - val_loss: 3.1279 - val_acc: 0.2828\n",
      "Epoch 13/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.7109 - acc: 0.7835\n",
      "Epoch 00013: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 250us/sample - loss: 0.7124 - acc: 0.7831 - val_loss: 3.1152 - val_acc: 0.2849\n",
      "Epoch 14/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.6573 - acc: 0.8051\n",
      "Epoch 00014: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 248us/sample - loss: 0.6581 - acc: 0.8045 - val_loss: 3.1751 - val_acc: 0.2986\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6301 - acc: 0.8127\n",
      "Epoch 00015: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 249us/sample - loss: 0.6302 - acc: 0.8126 - val_loss: 3.3798 - val_acc: 0.2874\n",
      "Epoch 16/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.5980 - acc: 0.8215\n",
      "Epoch 00016: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 247us/sample - loss: 0.5985 - acc: 0.8213 - val_loss: 3.6317 - val_acc: 0.2756\n",
      "Epoch 17/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.5602 - acc: 0.8352\n",
      "Epoch 00017: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 248us/sample - loss: 0.5608 - acc: 0.8348 - val_loss: 3.2959 - val_acc: 0.2991\n",
      "Epoch 18/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5365 - acc: 0.8414\n",
      "Epoch 00018: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 249us/sample - loss: 0.5369 - acc: 0.8413 - val_loss: 3.3690 - val_acc: 0.3056\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5071 - acc: 0.8525\n",
      "Epoch 00019: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 250us/sample - loss: 0.5072 - acc: 0.8524 - val_loss: 3.4561 - val_acc: 0.2991\n",
      "Epoch 20/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.4860 - acc: 0.8611\n",
      "Epoch 00020: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.4866 - acc: 0.8607 - val_loss: 3.4539 - val_acc: 0.2921\n",
      "Epoch 21/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.4612 - acc: 0.8672\n",
      "Epoch 00021: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.4614 - acc: 0.8672 - val_loss: 3.4566 - val_acc: 0.3031\n",
      "Epoch 22/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.4374 - acc: 0.8750\n",
      "Epoch 00022: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.4376 - acc: 0.8748 - val_loss: 3.5831 - val_acc: 0.2881\n",
      "Epoch 23/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.4193 - acc: 0.8803\n",
      "Epoch 00023: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 249us/sample - loss: 0.4191 - acc: 0.8804 - val_loss: 3.6714 - val_acc: 0.2979\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4135 - acc: 0.8821\n",
      "Epoch 00024: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 249us/sample - loss: 0.4138 - acc: 0.8820 - val_loss: 3.9235 - val_acc: 0.2642\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3900 - acc: 0.8916\n",
      "Epoch 00025: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 250us/sample - loss: 0.3901 - acc: 0.8916 - val_loss: 3.6121 - val_acc: 0.2895\n",
      "Epoch 26/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.3732 - acc: 0.8971\n",
      "Epoch 00026: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.3729 - acc: 0.8972 - val_loss: 3.8483 - val_acc: 0.2867\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3543 - acc: 0.9028\n",
      "Epoch 00027: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.3543 - acc: 0.9028 - val_loss: 3.7105 - val_acc: 0.3019\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3494 - acc: 0.9048\n",
      "Epoch 00028: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 247us/sample - loss: 0.3496 - acc: 0.9047 - val_loss: 3.8074 - val_acc: 0.2900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3342 - acc: 0.9082\n",
      "Epoch 00029: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 253us/sample - loss: 0.3349 - acc: 0.9081 - val_loss: 3.8228 - val_acc: 0.2888\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3219 - acc: 0.9140\n",
      "Epoch 00030: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 257us/sample - loss: 0.3221 - acc: 0.9139 - val_loss: 3.8941 - val_acc: 0.2851\n",
      "Epoch 31/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.3086 - acc: 0.9163\n",
      "Epoch 00031: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 249us/sample - loss: 0.3094 - acc: 0.9160 - val_loss: 3.9942 - val_acc: 0.2695\n",
      "Epoch 32/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.3068 - acc: 0.9143\n",
      "Epoch 00032: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 248us/sample - loss: 0.3066 - acc: 0.9144 - val_loss: 3.8918 - val_acc: 0.2993\n",
      "Epoch 33/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2824 - acc: 0.9253\n",
      "Epoch 00033: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 250us/sample - loss: 0.2828 - acc: 0.9252 - val_loss: 3.9962 - val_acc: 0.2874\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2877 - acc: 0.9211\n",
      "Epoch 00034: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 248us/sample - loss: 0.2879 - acc: 0.9210 - val_loss: 3.9758 - val_acc: 0.3012\n",
      "Epoch 35/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2723 - acc: 0.9282\n",
      "Epoch 00035: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 250us/sample - loss: 0.2727 - acc: 0.9281 - val_loss: 4.1859 - val_acc: 0.2725\n",
      "Epoch 36/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.2686 - acc: 0.9282\n",
      "Epoch 00036: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 248us/sample - loss: 0.2687 - acc: 0.9281 - val_loss: 4.0694 - val_acc: 0.3058\n",
      "Epoch 37/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.2660 - acc: 0.9280\n",
      "Epoch 00037: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 246us/sample - loss: 0.2660 - acc: 0.9279 - val_loss: 4.1487 - val_acc: 0.2895\n",
      "Epoch 38/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2445 - acc: 0.9379\n",
      "Epoch 00038: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 249us/sample - loss: 0.2449 - acc: 0.9377 - val_loss: 4.0808 - val_acc: 0.3044\n",
      "Epoch 39/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2411 - acc: 0.9379\n",
      "Epoch 00039: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 240us/sample - loss: 0.2411 - acc: 0.9379 - val_loss: 4.2812 - val_acc: 0.2756\n",
      "Epoch 40/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.2397 - acc: 0.9377\n",
      "Epoch 00040: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.2400 - acc: 0.9376 - val_loss: 4.1690 - val_acc: 0.3007\n",
      "Epoch 41/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2380 - acc: 0.9400\n",
      "Epoch 00041: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 241us/sample - loss: 0.2382 - acc: 0.9399 - val_loss: 4.2553 - val_acc: 0.2930\n",
      "Epoch 42/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2252 - acc: 0.9423\n",
      "Epoch 00042: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 244us/sample - loss: 0.2255 - acc: 0.9422 - val_loss: 4.1662 - val_acc: 0.2986\n",
      "Epoch 43/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9412\n",
      "Epoch 00043: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 241us/sample - loss: 0.2215 - acc: 0.9411 - val_loss: 4.3186 - val_acc: 0.2872\n",
      "Epoch 44/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2164 - acc: 0.9431\n",
      "Epoch 00044: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.2170 - acc: 0.9429 - val_loss: 4.2450 - val_acc: 0.3068\n",
      "Epoch 45/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2070 - acc: 0.9482\n",
      "Epoch 00045: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 241us/sample - loss: 0.2074 - acc: 0.9481 - val_loss: 4.8139 - val_acc: 0.2581\n",
      "Epoch 46/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2067 - acc: 0.9468\n",
      "Epoch 00046: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 246us/sample - loss: 0.2069 - acc: 0.9466 - val_loss: 4.4889 - val_acc: 0.2795\n",
      "Epoch 47/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9498\n",
      "Epoch 00047: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 244us/sample - loss: 0.1971 - acc: 0.9497 - val_loss: 4.4105 - val_acc: 0.2914\n",
      "Epoch 48/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2063 - acc: 0.9454\n",
      "Epoch 00048: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 246us/sample - loss: 0.2070 - acc: 0.9452 - val_loss: 4.4760 - val_acc: 0.2968\n",
      "Epoch 49/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9489\n",
      "Epoch 00049: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 240us/sample - loss: 0.2001 - acc: 0.9488 - val_loss: 4.3996 - val_acc: 0.2923\n",
      "Epoch 50/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1924 - acc: 0.9514\n",
      "Epoch 00050: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 243us/sample - loss: 0.1926 - acc: 0.9513 - val_loss: 4.4645 - val_acc: 0.2833\n",
      "Epoch 51/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1915 - acc: 0.9534\n",
      "Epoch 00051: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 242us/sample - loss: 0.1915 - acc: 0.9533 - val_loss: 4.6430 - val_acc: 0.2805\n",
      "Epoch 52/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9554\n",
      "Epoch 00052: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 236us/sample - loss: 0.1783 - acc: 0.9553 - val_loss: 4.4742 - val_acc: 0.3031\n",
      "Epoch 53/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.1787 - acc: 0.9552\n",
      "Epoch 00053: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 250us/sample - loss: 0.1795 - acc: 0.9550 - val_loss: 4.6563 - val_acc: 0.2805\n",
      "Epoch 54/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9589\n",
      "Epoch 00054: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 246us/sample - loss: 0.1683 - acc: 0.9587 - val_loss: 4.6003 - val_acc: 0.2928\n",
      "Epoch 55/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1711 - acc: 0.9573\n",
      "Epoch 00055: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.1715 - acc: 0.9572 - val_loss: 4.5526 - val_acc: 0.2944\n",
      "Epoch 56/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1665 - acc: 0.9593\n",
      "Epoch 00056: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 247us/sample - loss: 0.1665 - acc: 0.9594 - val_loss: 4.6221 - val_acc: 0.2986\n",
      "Epoch 57/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1649 - acc: 0.9586\n",
      "Epoch 00057: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 249us/sample - loss: 0.1651 - acc: 0.9585 - val_loss: 4.6425 - val_acc: 0.2996\n",
      "Epoch 58/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.1655 - acc: 0.9595\n",
      "Epoch 00058: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 244us/sample - loss: 0.1663 - acc: 0.9594 - val_loss: 4.7085 - val_acc: 0.2856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9568\n",
      "Epoch 00059: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 247us/sample - loss: 0.1694 - acc: 0.9567 - val_loss: 4.6363 - val_acc: 0.2933\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1571 - acc: 0.9622\n",
      "Epoch 00060: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 246us/sample - loss: 0.1573 - acc: 0.9621 - val_loss: 4.7318 - val_acc: 0.2898\n",
      "Epoch 61/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9622\n",
      "Epoch 00061: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.1533 - acc: 0.9622 - val_loss: 4.7492 - val_acc: 0.2926\n",
      "Epoch 62/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1471 - acc: 0.9648\n",
      "Epoch 00062: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 242us/sample - loss: 0.1479 - acc: 0.9647 - val_loss: 4.7752 - val_acc: 0.2888\n",
      "Epoch 63/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9629\n",
      "Epoch 00063: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 240us/sample - loss: 0.1456 - acc: 0.9629 - val_loss: 4.7344 - val_acc: 0.2909\n",
      "Epoch 64/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1467 - acc: 0.9634\n",
      "Epoch 00064: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 242us/sample - loss: 0.1471 - acc: 0.9634 - val_loss: 4.8335 - val_acc: 0.2940\n",
      "Epoch 65/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1446 - acc: 0.9633\n",
      "Epoch 00065: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 239us/sample - loss: 0.1447 - acc: 0.9632 - val_loss: 4.9463 - val_acc: 0.2669\n",
      "Epoch 66/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9658\n",
      "Epoch 00066: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 242us/sample - loss: 0.1409 - acc: 0.9657 - val_loss: 5.0588 - val_acc: 0.2821\n",
      "Epoch 67/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9641\n",
      "Epoch 00067: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 236us/sample - loss: 0.1446 - acc: 0.9639 - val_loss: 4.8515 - val_acc: 0.2900\n",
      "Epoch 68/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1564 - acc: 0.9605\n",
      "Epoch 00068: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 241us/sample - loss: 0.1570 - acc: 0.9604 - val_loss: 4.9025 - val_acc: 0.2893\n",
      "Epoch 69/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1348 - acc: 0.9665\n",
      "Epoch 00069: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 240us/sample - loss: 0.1353 - acc: 0.9665 - val_loss: 4.9134 - val_acc: 0.2998\n",
      "Epoch 70/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9664\n",
      "Epoch 00070: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 242us/sample - loss: 0.1354 - acc: 0.9663 - val_loss: 4.9682 - val_acc: 0.2802\n",
      "Epoch 71/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9685\n",
      "Epoch 00071: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 239us/sample - loss: 0.1295 - acc: 0.9684 - val_loss: 5.0100 - val_acc: 0.2819\n",
      "Epoch 72/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9674\n",
      "Epoch 00072: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 240us/sample - loss: 0.1272 - acc: 0.9674 - val_loss: 4.9591 - val_acc: 0.2947\n",
      "Epoch 73/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9702\n",
      "Epoch 00073: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 240us/sample - loss: 0.1263 - acc: 0.9700 - val_loss: 4.8754 - val_acc: 0.2858\n",
      "Epoch 74/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9670\n",
      "Epoch 00074: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 242us/sample - loss: 0.1302 - acc: 0.9668 - val_loss: 4.9906 - val_acc: 0.2746\n",
      "Epoch 75/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9700\n",
      "Epoch 00075: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 247us/sample - loss: 0.1250 - acc: 0.9700 - val_loss: 4.9861 - val_acc: 0.2902\n",
      "Epoch 76/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9696\n",
      "Epoch 00076: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.1247 - acc: 0.9696 - val_loss: 4.9054 - val_acc: 0.2884\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9710\n",
      "Epoch 00077: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 249us/sample - loss: 0.1216 - acc: 0.9709 - val_loss: 4.9936 - val_acc: 0.2900\n",
      "Epoch 78/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9663\n",
      "Epoch 00078: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 244us/sample - loss: 0.1343 - acc: 0.9662 - val_loss: 5.0627 - val_acc: 0.3021\n",
      "Epoch 79/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9732\n",
      "Epoch 00079: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.1144 - acc: 0.9732 - val_loss: 5.1189 - val_acc: 0.2837\n",
      "Epoch 80/500\n",
      "36608/36805 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9699\n",
      "Epoch 00080: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 249us/sample - loss: 0.1200 - acc: 0.9698 - val_loss: 5.0818 - val_acc: 0.2905\n",
      "Epoch 81/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9710\n",
      "Epoch 00081: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.1205 - acc: 0.9708 - val_loss: 5.0547 - val_acc: 0.2856\n",
      "Epoch 82/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9707\n",
      "Epoch 00082: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 244us/sample - loss: 0.1186 - acc: 0.9706 - val_loss: 5.1889 - val_acc: 0.2788\n",
      "Epoch 83/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9715\n",
      "Epoch 00083: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 238us/sample - loss: 0.1171 - acc: 0.9715 - val_loss: 5.1955 - val_acc: 0.2816\n",
      "Epoch 84/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9713\n",
      "Epoch 00084: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 243us/sample - loss: 0.1171 - acc: 0.9712 - val_loss: 5.2351 - val_acc: 0.2725\n",
      "Epoch 85/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9740\n",
      "Epoch 00085: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 242us/sample - loss: 0.1093 - acc: 0.9739 - val_loss: 5.2494 - val_acc: 0.2819\n",
      "Epoch 86/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9735\n",
      "Epoch 00086: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 238us/sample - loss: 0.1136 - acc: 0.9734 - val_loss: 5.1757 - val_acc: 0.2770\n",
      "Epoch 87/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9704\n",
      "Epoch 00087: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 241us/sample - loss: 0.1224 - acc: 0.9704 - val_loss: 5.5186 - val_acc: 0.2669\n",
      "Epoch 88/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9759\n",
      "Epoch 00088: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 241us/sample - loss: 0.1020 - acc: 0.9759 - val_loss: 5.2728 - val_acc: 0.2781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9740\n",
      "Epoch 00089: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 243us/sample - loss: 0.1080 - acc: 0.9738 - val_loss: 5.1433 - val_acc: 0.2886\n",
      "Epoch 90/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9722\n",
      "Epoch 00090: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 240us/sample - loss: 0.1109 - acc: 0.9723 - val_loss: 5.1509 - val_acc: 0.2837\n",
      "Epoch 91/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9767\n",
      "Epoch 00091: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 238us/sample - loss: 0.0989 - acc: 0.9766 - val_loss: 5.2089 - val_acc: 0.2807\n",
      "Epoch 92/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9744\n",
      "Epoch 00092: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 242us/sample - loss: 0.1057 - acc: 0.9744 - val_loss: 5.4494 - val_acc: 0.2728\n",
      "Epoch 93/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9742\n",
      "Epoch 00093: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 238us/sample - loss: 0.1083 - acc: 0.9742 - val_loss: 5.2261 - val_acc: 0.2956\n",
      "Epoch 94/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9778\n",
      "Epoch 00094: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 236us/sample - loss: 0.0946 - acc: 0.9778 - val_loss: 5.1872 - val_acc: 0.2958\n",
      "Epoch 95/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9763\n",
      "Epoch 00095: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 238us/sample - loss: 0.1024 - acc: 0.9761 - val_loss: 5.4176 - val_acc: 0.2867\n",
      "Epoch 96/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9742\n",
      "Epoch 00096: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 242us/sample - loss: 0.1066 - acc: 0.9742 - val_loss: 5.3197 - val_acc: 0.2905\n",
      "Epoch 97/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9750\n",
      "Epoch 00097: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 245us/sample - loss: 0.1006 - acc: 0.9750 - val_loss: 5.3105 - val_acc: 0.2898\n",
      "Epoch 98/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9758\n",
      "Epoch 00098: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 241us/sample - loss: 0.1026 - acc: 0.9757 - val_loss: 5.8761 - val_acc: 0.2595\n",
      "Epoch 99/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9773\n",
      "Epoch 00099: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 243us/sample - loss: 0.0975 - acc: 0.9773 - val_loss: 5.4249 - val_acc: 0.2816\n",
      "Epoch 100/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9759\n",
      "Epoch 00100: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 244us/sample - loss: 0.0965 - acc: 0.9758 - val_loss: 5.3146 - val_acc: 0.2884\n",
      "Epoch 101/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9748\n",
      "Epoch 00101: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 241us/sample - loss: 0.1023 - acc: 0.9747 - val_loss: 5.4887 - val_acc: 0.2744\n",
      "Epoch 102/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9761\n",
      "Epoch 00102: val_loss did not improve from 2.49848\n",
      "36805/36805 [==============================] - 9s 240us/sample - loss: 0.0997 - acc: 0.9760 - val_loss: 5.5645 - val_acc: 0.2840\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 228us/sample - loss: 2.5952 - acc: 0.2735\n",
      "Loss: 2.59520444057936 Accuracy: 0.27352026\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.3130 - acc: 0.3191\n",
      "Epoch 00001: val_loss improved from inf to 2.00829, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_2_conv_checkpoint/001-2.0083.hdf5\n",
      "36805/36805 [==============================] - 14s 380us/sample - loss: 2.3125 - acc: 0.3190 - val_loss: 2.0083 - val_acc: 0.3690\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5752 - acc: 0.5185\n",
      "Epoch 00002: val_loss improved from 2.00829 to 1.82772, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_2_conv_checkpoint/002-1.8277.hdf5\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 1.5757 - acc: 0.5184 - val_loss: 1.8277 - val_acc: 0.4577\n",
      "Epoch 3/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2231 - acc: 0.6229\n",
      "Epoch 00003: val_loss did not improve from 1.82772\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 1.2233 - acc: 0.6229 - val_loss: 1.8483 - val_acc: 0.4691\n",
      "Epoch 4/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9726 - acc: 0.7014\n",
      "Epoch 00004: val_loss did not improve from 1.82772\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.9728 - acc: 0.7013 - val_loss: 1.8314 - val_acc: 0.4833\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7867 - acc: 0.7634\n",
      "Epoch 00005: val_loss improved from 1.82772 to 1.72196, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_2_conv_checkpoint/005-1.7220.hdf5\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.7867 - acc: 0.7633 - val_loss: 1.7220 - val_acc: 0.5148\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6487 - acc: 0.8127\n",
      "Epoch 00006: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 320us/sample - loss: 0.6485 - acc: 0.8127 - val_loss: 1.8552 - val_acc: 0.5031\n",
      "Epoch 7/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5356 - acc: 0.8525\n",
      "Epoch 00007: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.5357 - acc: 0.8525 - val_loss: 1.8944 - val_acc: 0.5010\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4582 - acc: 0.8747\n",
      "Epoch 00008: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 322us/sample - loss: 0.4584 - acc: 0.8746 - val_loss: 1.8380 - val_acc: 0.5164\n",
      "Epoch 9/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3812 - acc: 0.9042\n",
      "Epoch 00009: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 319us/sample - loss: 0.3814 - acc: 0.9041 - val_loss: 2.0390 - val_acc: 0.4717\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3269 - acc: 0.9217\n",
      "Epoch 00010: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 311us/sample - loss: 0.3273 - acc: 0.9216 - val_loss: 2.0690 - val_acc: 0.4838\n",
      "Epoch 11/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2878 - acc: 0.9344\n",
      "Epoch 00011: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 317us/sample - loss: 0.2880 - acc: 0.9343 - val_loss: 1.9918 - val_acc: 0.4962\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2442 - acc: 0.9485\n",
      "Epoch 00012: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.2445 - acc: 0.9485 - val_loss: 2.0939 - val_acc: 0.4969\n",
      "Epoch 13/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2103 - acc: 0.9591\n",
      "Epoch 00013: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 318us/sample - loss: 0.2104 - acc: 0.9590 - val_loss: 2.2476 - val_acc: 0.4857\n",
      "Epoch 14/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9639\n",
      "Epoch 00014: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 319us/sample - loss: 0.1921 - acc: 0.9638 - val_loss: 2.1160 - val_acc: 0.5015\n",
      "Epoch 15/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9705\n",
      "Epoch 00015: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.1682 - acc: 0.9704 - val_loss: 2.1630 - val_acc: 0.4997\n",
      "Epoch 16/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9736\n",
      "Epoch 00016: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 317us/sample - loss: 0.1512 - acc: 0.9736 - val_loss: 2.1660 - val_acc: 0.5076\n",
      "Epoch 17/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9765\n",
      "Epoch 00017: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 312us/sample - loss: 0.1375 - acc: 0.9764 - val_loss: 2.2578 - val_acc: 0.4978\n",
      "Epoch 18/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9790\n",
      "Epoch 00018: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 310us/sample - loss: 0.1323 - acc: 0.9788 - val_loss: 2.2620 - val_acc: 0.5125\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9819\n",
      "Epoch 00019: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 315us/sample - loss: 0.1145 - acc: 0.9819 - val_loss: 2.3918 - val_acc: 0.4950\n",
      "Epoch 20/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9855\n",
      "Epoch 00020: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 319us/sample - loss: 0.1033 - acc: 0.9855 - val_loss: 2.3924 - val_acc: 0.4973\n",
      "Epoch 21/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9865\n",
      "Epoch 00021: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 312us/sample - loss: 0.0930 - acc: 0.9865 - val_loss: 2.6717 - val_acc: 0.4656\n",
      "Epoch 22/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9866\n",
      "Epoch 00022: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0878 - acc: 0.9865 - val_loss: 2.7732 - val_acc: 0.4568\n",
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9878\n",
      "Epoch 00023: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 315us/sample - loss: 0.0832 - acc: 0.9877 - val_loss: 2.5717 - val_acc: 0.4948\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9895\n",
      "Epoch 00024: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 312us/sample - loss: 0.0748 - acc: 0.9895 - val_loss: 2.6321 - val_acc: 0.4826\n",
      "Epoch 25/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9895\n",
      "Epoch 00025: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0727 - acc: 0.9895 - val_loss: 3.0741 - val_acc: 0.4377\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9921\n",
      "Epoch 00026: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 310us/sample - loss: 0.0633 - acc: 0.9920 - val_loss: 2.5608 - val_acc: 0.4899\n",
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9910\n",
      "Epoch 00027: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.0631 - acc: 0.9910 - val_loss: 2.6191 - val_acc: 0.5001\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9929\n",
      "Epoch 00028: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 312us/sample - loss: 0.0559 - acc: 0.9929 - val_loss: 2.5752 - val_acc: 0.5083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9917\n",
      "Epoch 00029: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0579 - acc: 0.9917 - val_loss: 2.6710 - val_acc: 0.4971\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9916\n",
      "Epoch 00030: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0568 - acc: 0.9915 - val_loss: 2.7366 - val_acc: 0.4864\n",
      "Epoch 31/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9938\n",
      "Epoch 00031: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0491 - acc: 0.9939 - val_loss: 2.9385 - val_acc: 0.4766\n",
      "Epoch 32/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9943\n",
      "Epoch 00032: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 315us/sample - loss: 0.0445 - acc: 0.9942 - val_loss: 3.0990 - val_acc: 0.4561\n",
      "Epoch 33/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9924\n",
      "Epoch 00033: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 317us/sample - loss: 0.0504 - acc: 0.9924 - val_loss: 3.1714 - val_acc: 0.4449\n",
      "Epoch 34/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9940\n",
      "Epoch 00034: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0439 - acc: 0.9940 - val_loss: 2.9277 - val_acc: 0.4782\n",
      "Epoch 35/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9939\n",
      "Epoch 00035: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0445 - acc: 0.9939 - val_loss: 3.0037 - val_acc: 0.4663\n",
      "Epoch 36/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9941\n",
      "Epoch 00036: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 312us/sample - loss: 0.0417 - acc: 0.9940 - val_loss: 2.9873 - val_acc: 0.4843\n",
      "Epoch 37/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9943\n",
      "Epoch 00037: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0420 - acc: 0.9942 - val_loss: 2.8734 - val_acc: 0.4861\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9947\n",
      "Epoch 00038: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 315us/sample - loss: 0.0397 - acc: 0.9946 - val_loss: 3.4017 - val_acc: 0.4454\n",
      "Epoch 39/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9952\n",
      "Epoch 00039: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 312us/sample - loss: 0.0362 - acc: 0.9952 - val_loss: 2.9440 - val_acc: 0.4875\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9952\n",
      "Epoch 00040: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0351 - acc: 0.9951 - val_loss: 3.2609 - val_acc: 0.4649\n",
      "Epoch 41/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9948\n",
      "Epoch 00041: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 312us/sample - loss: 0.0398 - acc: 0.9948 - val_loss: 2.9414 - val_acc: 0.4915\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9954\n",
      "Epoch 00042: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.0350 - acc: 0.9954 - val_loss: 3.1025 - val_acc: 0.4810\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9956\n",
      "Epoch 00043: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0324 - acc: 0.9956 - val_loss: 3.5263 - val_acc: 0.4372\n",
      "Epoch 44/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9965\n",
      "Epoch 00044: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 315us/sample - loss: 0.0287 - acc: 0.9964 - val_loss: 3.1842 - val_acc: 0.4747\n",
      "Epoch 45/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9928\n",
      "Epoch 00045: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 312us/sample - loss: 0.0413 - acc: 0.9928 - val_loss: 3.2660 - val_acc: 0.4568\n",
      "Epoch 46/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9963\n",
      "Epoch 00046: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 312us/sample - loss: 0.0285 - acc: 0.9963 - val_loss: 3.1575 - val_acc: 0.4826\n",
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9957\n",
      "Epoch 00047: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 315us/sample - loss: 0.0295 - acc: 0.9957 - val_loss: 3.1600 - val_acc: 0.4775\n",
      "Epoch 48/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9971\n",
      "Epoch 00048: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 317us/sample - loss: 0.0256 - acc: 0.9971 - val_loss: 3.3246 - val_acc: 0.4631\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9961\n",
      "Epoch 00049: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.0288 - acc: 0.9960 - val_loss: 3.4612 - val_acc: 0.4493\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9960\n",
      "Epoch 00050: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.0289 - acc: 0.9960 - val_loss: 3.1240 - val_acc: 0.4792\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9962\n",
      "Epoch 00051: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.0276 - acc: 0.9961 - val_loss: 3.3916 - val_acc: 0.4580\n",
      "Epoch 52/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9963\n",
      "Epoch 00052: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 312us/sample - loss: 0.0276 - acc: 0.9963 - val_loss: 3.4166 - val_acc: 0.4696\n",
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9968\n",
      "Epoch 00053: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 312us/sample - loss: 0.0247 - acc: 0.9968 - val_loss: 3.3602 - val_acc: 0.4645\n",
      "Epoch 54/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9966\n",
      "Epoch 00054: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 317us/sample - loss: 0.0247 - acc: 0.9966 - val_loss: 3.2521 - val_acc: 0.4812\n",
      "Epoch 55/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9938\n",
      "Epoch 00055: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.0369 - acc: 0.9938 - val_loss: 3.6184 - val_acc: 0.4405\n",
      "Epoch 56/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9966\n",
      "Epoch 00056: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 318us/sample - loss: 0.0250 - acc: 0.9965 - val_loss: 3.4507 - val_acc: 0.4542\n",
      "Epoch 57/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9966\n",
      "Epoch 00057: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 317us/sample - loss: 0.0248 - acc: 0.9965 - val_loss: 3.3436 - val_acc: 0.4656\n",
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9972\n",
      "Epoch 00058: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.0221 - acc: 0.9972 - val_loss: 3.3027 - val_acc: 0.4794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9974\n",
      "Epoch 00059: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0213 - acc: 0.9974 - val_loss: 3.3266 - val_acc: 0.4799\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9963\n",
      "Epoch 00060: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 311us/sample - loss: 0.0243 - acc: 0.9963 - val_loss: 3.5309 - val_acc: 0.4610\n",
      "Epoch 61/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9965\n",
      "Epoch 00061: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 311us/sample - loss: 0.0240 - acc: 0.9964 - val_loss: 3.3580 - val_acc: 0.4759\n",
      "Epoch 62/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9965\n",
      "Epoch 00062: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 310us/sample - loss: 0.0233 - acc: 0.9964 - val_loss: 3.3431 - val_acc: 0.4663\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9962\n",
      "Epoch 00063: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0258 - acc: 0.9961 - val_loss: 3.7384 - val_acc: 0.4382\n",
      "Epoch 64/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9971\n",
      "Epoch 00064: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0213 - acc: 0.9971 - val_loss: 3.3541 - val_acc: 0.4759\n",
      "Epoch 65/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9963\n",
      "Epoch 00065: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 317us/sample - loss: 0.0234 - acc: 0.9963 - val_loss: 3.3211 - val_acc: 0.4698\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9973\n",
      "Epoch 00066: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0199 - acc: 0.9973 - val_loss: 3.6008 - val_acc: 0.4531\n",
      "Epoch 67/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9985\n",
      "Epoch 00067: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0166 - acc: 0.9984 - val_loss: 3.5511 - val_acc: 0.4694\n",
      "Epoch 68/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9964\n",
      "Epoch 00068: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 318us/sample - loss: 0.0224 - acc: 0.9963 - val_loss: 3.4855 - val_acc: 0.4778\n",
      "Epoch 69/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9973\n",
      "Epoch 00069: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 315us/sample - loss: 0.0191 - acc: 0.9972 - val_loss: 3.4884 - val_acc: 0.4743\n",
      "Epoch 70/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9977\n",
      "Epoch 00070: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 315us/sample - loss: 0.0178 - acc: 0.9977 - val_loss: 3.5639 - val_acc: 0.4612\n",
      "Epoch 71/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9983\n",
      "Epoch 00071: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0166 - acc: 0.9983 - val_loss: 3.5383 - val_acc: 0.4635\n",
      "Epoch 72/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9958\n",
      "Epoch 00072: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 315us/sample - loss: 0.0284 - acc: 0.9957 - val_loss: 3.4763 - val_acc: 0.4747\n",
      "Epoch 73/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9955\n",
      "Epoch 00073: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0247 - acc: 0.9955 - val_loss: 3.5303 - val_acc: 0.4575\n",
      "Epoch 74/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9968\n",
      "Epoch 00074: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.0208 - acc: 0.9968 - val_loss: 3.5929 - val_acc: 0.4587\n",
      "Epoch 75/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9969\n",
      "Epoch 00075: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 317us/sample - loss: 0.0198 - acc: 0.9969 - val_loss: 3.6002 - val_acc: 0.4724\n",
      "Epoch 76/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9982\n",
      "Epoch 00076: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0152 - acc: 0.9982 - val_loss: 3.5363 - val_acc: 0.4743\n",
      "Epoch 77/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9973\n",
      "Epoch 00077: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0182 - acc: 0.9973 - val_loss: 3.8880 - val_acc: 0.4496\n",
      "Epoch 78/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9969\n",
      "Epoch 00078: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0209 - acc: 0.9968 - val_loss: 3.8774 - val_acc: 0.4500\n",
      "Epoch 79/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9965\n",
      "Epoch 00079: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 317us/sample - loss: 0.0209 - acc: 0.9965 - val_loss: 3.6840 - val_acc: 0.4696\n",
      "Epoch 80/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9974\n",
      "Epoch 00080: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0193 - acc: 0.9973 - val_loss: 3.8029 - val_acc: 0.4661\n",
      "Epoch 81/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9962\n",
      "Epoch 00081: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.0222 - acc: 0.9962 - val_loss: 3.6469 - val_acc: 0.4687\n",
      "Epoch 82/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9979\n",
      "Epoch 00082: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 308us/sample - loss: 0.0171 - acc: 0.9979 - val_loss: 3.8857 - val_acc: 0.4521\n",
      "Epoch 83/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9966\n",
      "Epoch 00083: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0198 - acc: 0.9966 - val_loss: 3.6593 - val_acc: 0.4673\n",
      "Epoch 84/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9956\n",
      "Epoch 00084: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0253 - acc: 0.9955 - val_loss: 3.8986 - val_acc: 0.4465\n",
      "Epoch 85/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9977\n",
      "Epoch 00085: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 307us/sample - loss: 0.0174 - acc: 0.9977 - val_loss: 3.7060 - val_acc: 0.4566\n",
      "Epoch 86/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9974\n",
      "Epoch 00086: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0172 - acc: 0.9974 - val_loss: 3.6453 - val_acc: 0.4691\n",
      "Epoch 87/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9982\n",
      "Epoch 00087: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 310us/sample - loss: 0.0144 - acc: 0.9982 - val_loss: 3.6793 - val_acc: 0.4712\n",
      "Epoch 88/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9978\n",
      "Epoch 00088: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 309us/sample - loss: 0.0156 - acc: 0.9978 - val_loss: 3.9380 - val_acc: 0.4575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9979\n",
      "Epoch 00089: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 315us/sample - loss: 0.0143 - acc: 0.9979 - val_loss: 3.7664 - val_acc: 0.4661\n",
      "Epoch 90/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9976\n",
      "Epoch 00090: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 318us/sample - loss: 0.0160 - acc: 0.9976 - val_loss: 3.7145 - val_acc: 0.4631\n",
      "Epoch 91/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9969\n",
      "Epoch 00091: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.0191 - acc: 0.9968 - val_loss: 4.4437 - val_acc: 0.4312\n",
      "Epoch 92/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9959\n",
      "Epoch 00092: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0203 - acc: 0.9959 - val_loss: 4.0582 - val_acc: 0.4375\n",
      "Epoch 93/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9969\n",
      "Epoch 00093: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.0182 - acc: 0.9968 - val_loss: 3.8784 - val_acc: 0.4663\n",
      "Epoch 94/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9952\n",
      "Epoch 00094: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 316us/sample - loss: 0.0247 - acc: 0.9951 - val_loss: 3.8558 - val_acc: 0.4684\n",
      "Epoch 95/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9971\n",
      "Epoch 00095: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 312us/sample - loss: 0.0176 - acc: 0.9971 - val_loss: 3.7080 - val_acc: 0.4724\n",
      "Epoch 96/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9974\n",
      "Epoch 00096: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 313us/sample - loss: 0.0176 - acc: 0.9973 - val_loss: 3.8256 - val_acc: 0.4680\n",
      "Epoch 97/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9976\n",
      "Epoch 00097: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 309us/sample - loss: 0.0154 - acc: 0.9976 - val_loss: 3.7266 - val_acc: 0.4750\n",
      "Epoch 98/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9977\n",
      "Epoch 00098: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0169 - acc: 0.9976 - val_loss: 3.8597 - val_acc: 0.4654\n",
      "Epoch 99/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9984\n",
      "Epoch 00099: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0140 - acc: 0.9983 - val_loss: 4.2952 - val_acc: 0.4335\n",
      "Epoch 100/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9970\n",
      "Epoch 00100: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 12s 314us/sample - loss: 0.0177 - acc: 0.9970 - val_loss: 3.7659 - val_acc: 0.4745\n",
      "Epoch 101/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9982\n",
      "Epoch 00101: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 311us/sample - loss: 0.0147 - acc: 0.9982 - val_loss: 3.7945 - val_acc: 0.4719\n",
      "Epoch 102/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9983\n",
      "Epoch 00102: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 309us/sample - loss: 0.0128 - acc: 0.9983 - val_loss: 3.7400 - val_acc: 0.4782\n",
      "Epoch 103/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9976\n",
      "Epoch 00103: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 311us/sample - loss: 0.0157 - acc: 0.9975 - val_loss: 3.9733 - val_acc: 0.4647\n",
      "Epoch 104/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9970\n",
      "Epoch 00104: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 308us/sample - loss: 0.0166 - acc: 0.9969 - val_loss: 3.7768 - val_acc: 0.4789\n",
      "Epoch 105/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9968\n",
      "Epoch 00105: val_loss did not improve from 1.72196\n",
      "36805/36805 [==============================] - 11s 312us/sample - loss: 0.0173 - acc: 0.9967 - val_loss: 3.8611 - val_acc: 0.4663\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 238us/sample - loss: 1.8383 - acc: 0.4665\n",
      "Loss: 1.8382519834633309 Accuracy: 0.46645898\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.1143 - acc: 0.3638\n",
      "Epoch 00001: val_loss improved from inf to 1.82696, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_3_conv_checkpoint/001-1.8270.hdf5\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 2.1134 - acc: 0.3640 - val_loss: 1.8270 - val_acc: 0.4144\n",
      "Epoch 2/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 1.3911 - acc: 0.5698\n",
      "Epoch 00002: val_loss improved from 1.82696 to 1.48652, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_3_conv_checkpoint/002-1.4865.hdf5\n",
      "36805/36805 [==============================] - 14s 370us/sample - loss: 1.3912 - acc: 0.5700 - val_loss: 1.4865 - val_acc: 0.5511\n",
      "Epoch 3/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0953 - acc: 0.6568- ETA: 0s - loss: 1.0961 - acc\n",
      "Epoch 00003: val_loss improved from 1.48652 to 1.38188, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_3_conv_checkpoint/003-1.3819.hdf5\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 1.0956 - acc: 0.6566 - val_loss: 1.3819 - val_acc: 0.5819\n",
      "Epoch 4/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.8903 - acc: 0.7274\n",
      "Epoch 00004: val_loss improved from 1.38188 to 1.35211, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_3_conv_checkpoint/004-1.3521.hdf5\n",
      "36805/36805 [==============================] - 14s 372us/sample - loss: 0.8908 - acc: 0.7274 - val_loss: 1.3521 - val_acc: 0.5921\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7345 - acc: 0.7781\n",
      "Epoch 00005: val_loss did not improve from 1.35211\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.7342 - acc: 0.7782 - val_loss: 1.3581 - val_acc: 0.5982\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6130 - acc: 0.8192\n",
      "Epoch 00006: val_loss improved from 1.35211 to 1.34548, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_3_conv_checkpoint/006-1.3455.hdf5\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.6131 - acc: 0.8193 - val_loss: 1.3455 - val_acc: 0.6161\n",
      "Epoch 7/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5096 - acc: 0.8547\n",
      "Epoch 00007: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 373us/sample - loss: 0.5095 - acc: 0.8548 - val_loss: 1.3711 - val_acc: 0.6094\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4307 - acc: 0.8835\n",
      "Epoch 00008: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 367us/sample - loss: 0.4304 - acc: 0.8836 - val_loss: 1.4165 - val_acc: 0.6014\n",
      "Epoch 9/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3579 - acc: 0.9094\n",
      "Epoch 00009: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.3580 - acc: 0.9093 - val_loss: 1.4112 - val_acc: 0.6140\n",
      "Epoch 10/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3059 - acc: 0.9258\n",
      "Epoch 00010: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 370us/sample - loss: 0.3060 - acc: 0.9257 - val_loss: 1.4552 - val_acc: 0.6056\n",
      "Epoch 11/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2627 - acc: 0.9409\n",
      "Epoch 00011: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 375us/sample - loss: 0.2628 - acc: 0.9408 - val_loss: 1.4243 - val_acc: 0.6152\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9530\n",
      "Epoch 00012: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 370us/sample - loss: 0.2249 - acc: 0.9530 - val_loss: 1.4003 - val_acc: 0.6280\n",
      "Epoch 13/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9628\n",
      "Epoch 00013: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.1944 - acc: 0.9629 - val_loss: 1.4533 - val_acc: 0.6219\n",
      "Epoch 14/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9693\n",
      "Epoch 00014: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 374us/sample - loss: 0.1679 - acc: 0.9693 - val_loss: 1.7332 - val_acc: 0.5809\n",
      "Epoch 15/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9745\n",
      "Epoch 00015: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.1492 - acc: 0.9744 - val_loss: 1.5304 - val_acc: 0.6222\n",
      "Epoch 16/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9788\n",
      "Epoch 00016: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.1335 - acc: 0.9788 - val_loss: 1.6213 - val_acc: 0.6103\n",
      "Epoch 17/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9818\n",
      "Epoch 00017: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.1190 - acc: 0.9817 - val_loss: 1.6285 - val_acc: 0.6215\n",
      "Epoch 18/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9839\n",
      "Epoch 00018: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 365us/sample - loss: 0.1071 - acc: 0.9839 - val_loss: 1.5997 - val_acc: 0.6243\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9860\n",
      "Epoch 00019: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0981 - acc: 0.9860 - val_loss: 1.6956 - val_acc: 0.6096\n",
      "Epoch 20/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9880\n",
      "Epoch 00020: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 367us/sample - loss: 0.0869 - acc: 0.9880 - val_loss: 1.7363 - val_acc: 0.6168\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9885\n",
      "Epoch 00021: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.0847 - acc: 0.9884 - val_loss: 1.6792 - val_acc: 0.6194\n",
      "Epoch 22/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9908\n",
      "Epoch 00022: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0729 - acc: 0.9907 - val_loss: 1.8811 - val_acc: 0.5968\n",
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9914\n",
      "Epoch 00023: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.0681 - acc: 0.9913 - val_loss: 1.7317 - val_acc: 0.6166\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9925\n",
      "Epoch 00024: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.0642 - acc: 0.9924 - val_loss: 1.7198 - val_acc: 0.6208\n",
      "Epoch 25/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9937\n",
      "Epoch 00025: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0563 - acc: 0.9937 - val_loss: 1.7727 - val_acc: 0.6171\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9932\n",
      "Epoch 00026: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 365us/sample - loss: 0.0573 - acc: 0.9932 - val_loss: 1.8198 - val_acc: 0.6184\n",
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9931\n",
      "Epoch 00027: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 367us/sample - loss: 0.0553 - acc: 0.9930 - val_loss: 1.8086 - val_acc: 0.6254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9942\n",
      "Epoch 00028: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0513 - acc: 0.9941 - val_loss: 1.8511 - val_acc: 0.6147\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9939\n",
      "Epoch 00029: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 370us/sample - loss: 0.0493 - acc: 0.9939 - val_loss: 1.8649 - val_acc: 0.6161\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9951\n",
      "Epoch 00030: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 365us/sample - loss: 0.0453 - acc: 0.9951 - val_loss: 1.9468 - val_acc: 0.6175\n",
      "Epoch 31/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9953\n",
      "Epoch 00031: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0418 - acc: 0.9953 - val_loss: 1.9269 - val_acc: 0.6173\n",
      "Epoch 32/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9954\n",
      "Epoch 00032: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.0418 - acc: 0.9953 - val_loss: 1.8727 - val_acc: 0.6157\n",
      "Epoch 33/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9958\n",
      "Epoch 00033: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0375 - acc: 0.9958 - val_loss: 1.9094 - val_acc: 0.6161\n",
      "Epoch 34/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9954\n",
      "Epoch 00034: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0384 - acc: 0.9954 - val_loss: 2.2269 - val_acc: 0.5812\n",
      "Epoch 35/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9968\n",
      "Epoch 00035: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0331 - acc: 0.9967 - val_loss: 1.9995 - val_acc: 0.6147\n",
      "Epoch 36/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9945\n",
      "Epoch 00036: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 367us/sample - loss: 0.0388 - acc: 0.9945 - val_loss: 1.9589 - val_acc: 0.6138\n",
      "Epoch 37/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9972\n",
      "Epoch 00037: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0311 - acc: 0.9972 - val_loss: 1.9579 - val_acc: 0.6198\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9961\n",
      "Epoch 00038: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0343 - acc: 0.9961 - val_loss: 2.2379 - val_acc: 0.5882\n",
      "Epoch 39/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9968\n",
      "Epoch 00039: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.0305 - acc: 0.9968 - val_loss: 2.0219 - val_acc: 0.6136\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9966\n",
      "Epoch 00040: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 365us/sample - loss: 0.0297 - acc: 0.9966 - val_loss: 2.0533 - val_acc: 0.6080\n",
      "Epoch 41/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9964\n",
      "Epoch 00041: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 365us/sample - loss: 0.0314 - acc: 0.9963 - val_loss: 2.2212 - val_acc: 0.5984\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9960\n",
      "Epoch 00042: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0326 - acc: 0.9960 - val_loss: 2.1348 - val_acc: 0.6101\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9972\n",
      "Epoch 00043: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.0269 - acc: 0.9972 - val_loss: 2.3684 - val_acc: 0.5858\n",
      "Epoch 44/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9957\n",
      "Epoch 00044: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.0314 - acc: 0.9956 - val_loss: 2.0711 - val_acc: 0.6168\n",
      "Epoch 45/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9967\n",
      "Epoch 00045: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0281 - acc: 0.9967 - val_loss: 2.1429 - val_acc: 0.6042\n",
      "Epoch 46/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9966\n",
      "Epoch 00046: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0273 - acc: 0.9966 - val_loss: 2.1918 - val_acc: 0.6070\n",
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9972\n",
      "Epoch 00047: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0244 - acc: 0.9971 - val_loss: 2.1395 - val_acc: 0.6126\n",
      "Epoch 48/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9974\n",
      "Epoch 00048: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 365us/sample - loss: 0.0234 - acc: 0.9974 - val_loss: 2.1585 - val_acc: 0.6080\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9970\n",
      "Epoch 00049: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.0249 - acc: 0.9969 - val_loss: 2.1855 - val_acc: 0.6131\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9968\n",
      "Epoch 00050: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 362us/sample - loss: 0.0256 - acc: 0.9968 - val_loss: 2.1691 - val_acc: 0.6094\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9974\n",
      "Epoch 00051: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 365us/sample - loss: 0.0226 - acc: 0.9974 - val_loss: 2.2157 - val_acc: 0.6024\n",
      "Epoch 52/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9969\n",
      "Epoch 00052: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0233 - acc: 0.9969 - val_loss: 2.2780 - val_acc: 0.5991\n",
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9980\n",
      "Epoch 00053: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 372us/sample - loss: 0.0202 - acc: 0.9979 - val_loss: 2.2293 - val_acc: 0.6063\n",
      "Epoch 54/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9972\n",
      "Epoch 00054: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.0235 - acc: 0.9971 - val_loss: 2.2421 - val_acc: 0.6087\n",
      "Epoch 55/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9959\n",
      "Epoch 00055: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 367us/sample - loss: 0.0272 - acc: 0.9959 - val_loss: 2.2190 - val_acc: 0.6089\n",
      "Epoch 56/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9978\n",
      "Epoch 00056: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0189 - acc: 0.9978 - val_loss: 2.3382 - val_acc: 0.6005\n",
      "Epoch 57/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9980\n",
      "Epoch 00057: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0194 - acc: 0.9980 - val_loss: 2.2581 - val_acc: 0.6061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9984\n",
      "Epoch 00058: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 372us/sample - loss: 0.0174 - acc: 0.9984 - val_loss: 2.3120 - val_acc: 0.6042\n",
      "Epoch 59/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9977\n",
      "Epoch 00059: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.0185 - acc: 0.9976 - val_loss: 2.3249 - val_acc: 0.6000\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9980\n",
      "Epoch 00060: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 363us/sample - loss: 0.0186 - acc: 0.9980 - val_loss: 2.2623 - val_acc: 0.6087\n",
      "Epoch 61/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9980\n",
      "Epoch 00061: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0169 - acc: 0.9980 - val_loss: 2.2448 - val_acc: 0.6122\n",
      "Epoch 62/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9985\n",
      "Epoch 00062: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0153 - acc: 0.9984 - val_loss: 2.2465 - val_acc: 0.6147\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9965- ETA: 1s -\n",
      "Epoch 00063: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 367us/sample - loss: 0.0228 - acc: 0.9965 - val_loss: 2.3996 - val_acc: 0.5912\n",
      "Epoch 64/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9980\n",
      "Epoch 00064: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0188 - acc: 0.9980 - val_loss: 2.3646 - val_acc: 0.6052\n",
      "Epoch 65/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9978\n",
      "Epoch 00065: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0182 - acc: 0.9977 - val_loss: 2.4138 - val_acc: 0.6056\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9981- ETA: 0s - loss: 0.0163 - acc\n",
      "Epoch 00066: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.0170 - acc: 0.9980 - val_loss: 2.5192 - val_acc: 0.5919\n",
      "Epoch 67/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9957\n",
      "Epoch 00067: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.0245 - acc: 0.9957 - val_loss: 2.3992 - val_acc: 0.6021\n",
      "Epoch 68/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9975- ETA: 0s - loss: 0.0192\n",
      "Epoch 00068: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 363us/sample - loss: 0.0185 - acc: 0.9975 - val_loss: 2.3329 - val_acc: 0.6049\n",
      "Epoch 69/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9976\n",
      "Epoch 00069: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 370us/sample - loss: 0.0174 - acc: 0.9976 - val_loss: 2.4137 - val_acc: 0.6094\n",
      "Epoch 70/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9980\n",
      "Epoch 00070: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0153 - acc: 0.9980 - val_loss: 2.8635 - val_acc: 0.5577\n",
      "Epoch 71/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9986\n",
      "Epoch 00071: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0143 - acc: 0.9986 - val_loss: 2.3816 - val_acc: 0.6059\n",
      "Epoch 72/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9975\n",
      "Epoch 00072: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.0188 - acc: 0.9974 - val_loss: 2.4211 - val_acc: 0.6054\n",
      "Epoch 73/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9977\n",
      "Epoch 00073: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 367us/sample - loss: 0.0174 - acc: 0.9977 - val_loss: 2.5545 - val_acc: 0.5924\n",
      "Epoch 74/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9981\n",
      "Epoch 00074: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 362us/sample - loss: 0.0153 - acc: 0.9981 - val_loss: 2.4624 - val_acc: 0.6033\n",
      "Epoch 75/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9981\n",
      "Epoch 00075: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.0159 - acc: 0.9980 - val_loss: 2.4174 - val_acc: 0.5975\n",
      "Epoch 76/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9975\n",
      "Epoch 00076: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 362us/sample - loss: 0.0177 - acc: 0.9975 - val_loss: 2.4412 - val_acc: 0.5986\n",
      "Epoch 77/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9979\n",
      "Epoch 00077: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 370us/sample - loss: 0.0157 - acc: 0.9979 - val_loss: 2.4400 - val_acc: 0.6024\n",
      "Epoch 78/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9981\n",
      "Epoch 00078: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 367us/sample - loss: 0.0149 - acc: 0.9981 - val_loss: 2.4368 - val_acc: 0.6000\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9976\n",
      "Epoch 00079: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.0178 - acc: 0.9976 - val_loss: 2.4806 - val_acc: 0.6012\n",
      "Epoch 80/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9978\n",
      "Epoch 00080: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 367us/sample - loss: 0.0171 - acc: 0.9977 - val_loss: 2.5527 - val_acc: 0.5993\n",
      "Epoch 81/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9977\n",
      "Epoch 00081: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0171 - acc: 0.9976 - val_loss: 2.4607 - val_acc: 0.6052\n",
      "Epoch 82/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9981\n",
      "Epoch 00082: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0171 - acc: 0.9981 - val_loss: 2.4669 - val_acc: 0.6017\n",
      "Epoch 83/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9990\n",
      "Epoch 00083: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.0131 - acc: 0.9990 - val_loss: 2.6000 - val_acc: 0.5947\n",
      "Epoch 84/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9970\n",
      "Epoch 00084: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 370us/sample - loss: 0.0192 - acc: 0.9970 - val_loss: 2.5697 - val_acc: 0.5968\n",
      "Epoch 85/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9988\n",
      "Epoch 00085: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 370us/sample - loss: 0.0121 - acc: 0.9987 - val_loss: 2.6408 - val_acc: 0.5875\n",
      "Epoch 86/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9974\n",
      "Epoch 00086: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 367us/sample - loss: 0.0180 - acc: 0.9974 - val_loss: 2.5304 - val_acc: 0.5919\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9985\n",
      "Epoch 00087: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.0128 - acc: 0.9985 - val_loss: 2.4456 - val_acc: 0.6052\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9988\n",
      "Epoch 00088: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.0125 - acc: 0.9987 - val_loss: 2.5020 - val_acc: 0.6045\n",
      "Epoch 89/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9977- ETA: 1s - loss: 0.\n",
      "Epoch 00089: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0168 - acc: 0.9976 - val_loss: 2.5783 - val_acc: 0.5986\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9973\n",
      "Epoch 00090: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.0158 - acc: 0.9972 - val_loss: 2.5127 - val_acc: 0.6019\n",
      "Epoch 91/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9974\n",
      "Epoch 00091: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.0150 - acc: 0.9973 - val_loss: 2.6058 - val_acc: 0.5961\n",
      "Epoch 92/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9985\n",
      "Epoch 00092: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 367us/sample - loss: 0.0125 - acc: 0.9985 - val_loss: 2.5276 - val_acc: 0.6052\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9985\n",
      "Epoch 00093: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 367us/sample - loss: 0.0119 - acc: 0.9985 - val_loss: 2.4973 - val_acc: 0.6077\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9991\n",
      "Epoch 00094: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0102 - acc: 0.9991 - val_loss: 2.5643 - val_acc: 0.6052\n",
      "Epoch 95/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9983\n",
      "Epoch 00095: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 370us/sample - loss: 0.0145 - acc: 0.9982 - val_loss: 2.6292 - val_acc: 0.6026\n",
      "Epoch 96/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9981\n",
      "Epoch 00096: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 365us/sample - loss: 0.0133 - acc: 0.9981 - val_loss: 2.6845 - val_acc: 0.5942\n",
      "Epoch 97/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9982\n",
      "Epoch 00097: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0142 - acc: 0.9981 - val_loss: 2.6393 - val_acc: 0.5875\n",
      "Epoch 98/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9975\n",
      "Epoch 00098: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.0173 - acc: 0.9975 - val_loss: 2.5889 - val_acc: 0.5991\n",
      "Epoch 99/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9982\n",
      "Epoch 00099: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0138 - acc: 0.9982 - val_loss: 2.5642 - val_acc: 0.6019\n",
      "Epoch 100/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9984\n",
      "Epoch 00100: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0129 - acc: 0.9984 - val_loss: 2.6412 - val_acc: 0.5896\n",
      "Epoch 101/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9987\n",
      "Epoch 00101: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 368us/sample - loss: 0.0111 - acc: 0.9987 - val_loss: 2.6904 - val_acc: 0.5898\n",
      "Epoch 102/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9987\n",
      "Epoch 00102: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.0111 - acc: 0.9987 - val_loss: 2.6090 - val_acc: 0.5993\n",
      "Epoch 103/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9976\n",
      "Epoch 00103: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 371us/sample - loss: 0.0146 - acc: 0.9976 - val_loss: 2.7122 - val_acc: 0.5851\n",
      "Epoch 104/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9982\n",
      "Epoch 00104: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 366us/sample - loss: 0.0131 - acc: 0.9982 - val_loss: 2.6331 - val_acc: 0.6017\n",
      "Epoch 105/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9984\n",
      "Epoch 00105: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 14s 369us/sample - loss: 0.0126 - acc: 0.9984 - val_loss: 2.7795 - val_acc: 0.5884\n",
      "Epoch 106/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9983\n",
      "Epoch 00106: val_loss did not improve from 1.34548\n",
      "36805/36805 [==============================] - 13s 365us/sample - loss: 0.0135 - acc: 0.9982 - val_loss: 2.8325 - val_acc: 0.5863\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 264us/sample - loss: 1.3988 - acc: 0.6004\n",
      "Loss: 1.3988319131815545 Accuracy: 0.60041535\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.0018 - acc: 0.3888\n",
      "Epoch 00001: val_loss improved from inf to 1.97506, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_4_conv_checkpoint/001-1.9751.hdf5\n",
      "36805/36805 [==============================] - 21s 568us/sample - loss: 2.0012 - acc: 0.3891 - val_loss: 1.9751 - val_acc: 0.3811\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3355 - acc: 0.5917\n",
      "Epoch 00002: val_loss improved from 1.97506 to 1.30175, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_4_conv_checkpoint/002-1.3018.hdf5\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 1.3355 - acc: 0.5917 - val_loss: 1.3018 - val_acc: 0.6091\n",
      "Epoch 3/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1143 - acc: 0.6600\n",
      "Epoch 00003: val_loss improved from 1.30175 to 1.20963, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_4_conv_checkpoint/003-1.2096.hdf5\n",
      "36805/36805 [==============================] - 16s 421us/sample - loss: 1.1150 - acc: 0.6600 - val_loss: 1.2096 - val_acc: 0.6452\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9618 - acc: 0.7076\n",
      "Epoch 00004: val_loss did not improve from 1.20963\n",
      "36805/36805 [==============================] - 16s 426us/sample - loss: 0.9619 - acc: 0.7075 - val_loss: 1.2264 - val_acc: 0.6420\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8488 - acc: 0.7442\n",
      "Epoch 00005: val_loss did not improve from 1.20963\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.8491 - acc: 0.7440 - val_loss: 1.2304 - val_acc: 0.6536\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7511 - acc: 0.7722\n",
      "Epoch 00006: val_loss improved from 1.20963 to 1.15264, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_4_conv_checkpoint/006-1.1526.hdf5\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.7510 - acc: 0.7722 - val_loss: 1.1526 - val_acc: 0.6662\n",
      "Epoch 7/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.6669 - acc: 0.8011\n",
      "Epoch 00007: val_loss did not improve from 1.15264\n",
      "36805/36805 [==============================] - 16s 421us/sample - loss: 0.6671 - acc: 0.8010 - val_loss: 1.1574 - val_acc: 0.6681\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5930 - acc: 0.8251\n",
      "Epoch 00008: val_loss did not improve from 1.15264\n",
      "36805/36805 [==============================] - 15s 421us/sample - loss: 0.5932 - acc: 0.8250 - val_loss: 1.1654 - val_acc: 0.6688\n",
      "Epoch 9/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.5205 - acc: 0.8479\n",
      "Epoch 00009: val_loss did not improve from 1.15264\n",
      "36805/36805 [==============================] - 15s 419us/sample - loss: 0.5209 - acc: 0.8477 - val_loss: 1.1754 - val_acc: 0.6648\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4635 - acc: 0.8678\n",
      "Epoch 00010: val_loss did not improve from 1.15264\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.4634 - acc: 0.8678 - val_loss: 1.2068 - val_acc: 0.6636\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4062 - acc: 0.8853\n",
      "Epoch 00011: val_loss did not improve from 1.15264\n",
      "36805/36805 [==============================] - 15s 421us/sample - loss: 0.4064 - acc: 0.8853 - val_loss: 1.3145 - val_acc: 0.6457\n",
      "Epoch 12/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3589 - acc: 0.9016\n",
      "Epoch 00012: val_loss did not improve from 1.15264\n",
      "36805/36805 [==============================] - 15s 419us/sample - loss: 0.3588 - acc: 0.9017 - val_loss: 1.3226 - val_acc: 0.6406\n",
      "Epoch 13/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.9140\n",
      "Epoch 00013: val_loss did not improve from 1.15264\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.3256 - acc: 0.9140 - val_loss: 1.1861 - val_acc: 0.6730\n",
      "Epoch 14/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2811 - acc: 0.9286\n",
      "Epoch 00014: val_loss improved from 1.15264 to 1.14976, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_4_conv_checkpoint/014-1.1498.hdf5\n",
      "36805/36805 [==============================] - 16s 422us/sample - loss: 0.2810 - acc: 0.9286 - val_loss: 1.1498 - val_acc: 0.6865\n",
      "Epoch 15/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2507 - acc: 0.9402\n",
      "Epoch 00015: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.2514 - acc: 0.9400 - val_loss: 1.3476 - val_acc: 0.6471\n",
      "Epoch 16/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2242 - acc: 0.9490\n",
      "Epoch 00016: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 422us/sample - loss: 0.2244 - acc: 0.9489 - val_loss: 1.2655 - val_acc: 0.6632\n",
      "Epoch 17/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9545\n",
      "Epoch 00017: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 419us/sample - loss: 0.2006 - acc: 0.9545 - val_loss: 1.2814 - val_acc: 0.6769\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1782 - acc: 0.9626\n",
      "Epoch 00018: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 422us/sample - loss: 0.1783 - acc: 0.9626 - val_loss: 1.3195 - val_acc: 0.6618\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9661\n",
      "Epoch 00019: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.1668 - acc: 0.9661 - val_loss: 1.2687 - val_acc: 0.6797\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9727\n",
      "Epoch 00020: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.1443 - acc: 0.9726 - val_loss: 1.2860 - val_acc: 0.6730\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9761\n",
      "Epoch 00021: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.1334 - acc: 0.9760 - val_loss: 1.2573 - val_acc: 0.6830\n",
      "Epoch 22/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9790\n",
      "Epoch 00022: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.1213 - acc: 0.9791 - val_loss: 1.4036 - val_acc: 0.6585\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9815\n",
      "Epoch 00023: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 431us/sample - loss: 0.1100 - acc: 0.9815 - val_loss: 1.3788 - val_acc: 0.6676\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9836\n",
      "Epoch 00024: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 419us/sample - loss: 0.1024 - acc: 0.9836 - val_loss: 1.3916 - val_acc: 0.6737\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9861\n",
      "Epoch 00025: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 422us/sample - loss: 0.0956 - acc: 0.9860 - val_loss: 1.4693 - val_acc: 0.6615\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9843\n",
      "Epoch 00026: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.0928 - acc: 0.9842 - val_loss: 1.5365 - val_acc: 0.6550\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9879\n",
      "Epoch 00027: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 417us/sample - loss: 0.0825 - acc: 0.9879 - val_loss: 1.4242 - val_acc: 0.6678\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9899\n",
      "Epoch 00028: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.0742 - acc: 0.9898 - val_loss: 1.4797 - val_acc: 0.6669\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9884\n",
      "Epoch 00029: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.0744 - acc: 0.9884 - val_loss: 1.4417 - val_acc: 0.6706\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9887\n",
      "Epoch 00030: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.0732 - acc: 0.9886 - val_loss: 1.4340 - val_acc: 0.6688\n",
      "Epoch 31/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9911\n",
      "Epoch 00031: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 416us/sample - loss: 0.0670 - acc: 0.9911 - val_loss: 1.4483 - val_acc: 0.6692\n",
      "Epoch 32/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9927\n",
      "Epoch 00032: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.0587 - acc: 0.9927 - val_loss: 1.4785 - val_acc: 0.6725\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9926\n",
      "Epoch 00033: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 415us/sample - loss: 0.0578 - acc: 0.9926 - val_loss: 1.7795 - val_acc: 0.6313\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9932\n",
      "Epoch 00034: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 416us/sample - loss: 0.0533 - acc: 0.9931 - val_loss: 1.7636 - val_acc: 0.6226\n",
      "Epoch 35/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9904\n",
      "Epoch 00035: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.0612 - acc: 0.9903 - val_loss: 1.7488 - val_acc: 0.6294\n",
      "Epoch 36/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9919\n",
      "Epoch 00036: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 416us/sample - loss: 0.0569 - acc: 0.9919 - val_loss: 1.5214 - val_acc: 0.6664\n",
      "Epoch 37/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9938\n",
      "Epoch 00037: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 414us/sample - loss: 0.0476 - acc: 0.9937 - val_loss: 1.5859 - val_acc: 0.6660\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9934\n",
      "Epoch 00038: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 414us/sample - loss: 0.0488 - acc: 0.9934 - val_loss: 1.7440 - val_acc: 0.6401\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9947\n",
      "Epoch 00039: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.0459 - acc: 0.9946 - val_loss: 1.6297 - val_acc: 0.6597\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9941\n",
      "Epoch 00040: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 417us/sample - loss: 0.0453 - acc: 0.9940 - val_loss: 1.6169 - val_acc: 0.6646\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9942\n",
      "Epoch 00041: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.0437 - acc: 0.9942 - val_loss: 1.5702 - val_acc: 0.6702\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9939\n",
      "Epoch 00042: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.0420 - acc: 0.9939 - val_loss: 1.5455 - val_acc: 0.6860\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9952\n",
      "Epoch 00043: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.0392 - acc: 0.9952 - val_loss: 1.7672 - val_acc: 0.6462\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9952\n",
      "Epoch 00044: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 426us/sample - loss: 0.0377 - acc: 0.9952 - val_loss: 1.7026 - val_acc: 0.6590\n",
      "Epoch 45/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9928\n",
      "Epoch 00045: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.0446 - acc: 0.9928 - val_loss: 1.6458 - val_acc: 0.6723\n",
      "Epoch 46/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9933-\n",
      "Epoch 00046: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 424us/sample - loss: 0.0435 - acc: 0.9933 - val_loss: 1.5343 - val_acc: 0.6818\n",
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9959\n",
      "Epoch 00047: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.0332 - acc: 0.9959 - val_loss: 1.6561 - val_acc: 0.6702\n",
      "Epoch 48/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9956\n",
      "Epoch 00048: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.0344 - acc: 0.9955 - val_loss: 1.6162 - val_acc: 0.6695\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9940\n",
      "Epoch 00049: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.0385 - acc: 0.9940 - val_loss: 2.0108 - val_acc: 0.6217\n",
      "Epoch 50/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9950\n",
      "Epoch 00050: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 418us/sample - loss: 0.0337 - acc: 0.9950 - val_loss: 1.7242 - val_acc: 0.6583\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9966\n",
      "Epoch 00051: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 417us/sample - loss: 0.0295 - acc: 0.9966 - val_loss: 1.6906 - val_acc: 0.6723\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9961\n",
      "Epoch 00052: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.0327 - acc: 0.9961 - val_loss: 1.8753 - val_acc: 0.6336\n",
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9966\n",
      "Epoch 00053: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 415us/sample - loss: 0.0286 - acc: 0.9966 - val_loss: 1.7404 - val_acc: 0.6608\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9952\n",
      "Epoch 00054: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 422us/sample - loss: 0.0326 - acc: 0.9952 - val_loss: 1.7670 - val_acc: 0.6534\n",
      "Epoch 55/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9954\n",
      "Epoch 00055: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 421us/sample - loss: 0.0330 - acc: 0.9954 - val_loss: 1.8768 - val_acc: 0.6469\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9962\n",
      "Epoch 00056: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 422us/sample - loss: 0.0271 - acc: 0.9962 - val_loss: 1.6930 - val_acc: 0.6758\n",
      "Epoch 57/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9966\n",
      "Epoch 00057: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 421us/sample - loss: 0.0275 - acc: 0.9966 - val_loss: 1.7136 - val_acc: 0.6690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9958\n",
      "Epoch 00058: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 419us/sample - loss: 0.0296 - acc: 0.9958 - val_loss: 1.7674 - val_acc: 0.6580\n",
      "Epoch 59/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9944\n",
      "Epoch 00059: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.0318 - acc: 0.9944 - val_loss: 1.7627 - val_acc: 0.6774\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9943\n",
      "Epoch 00060: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.0341 - acc: 0.9942 - val_loss: 1.7708 - val_acc: 0.6615\n",
      "Epoch 61/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9957\n",
      "Epoch 00061: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 424us/sample - loss: 0.0304 - acc: 0.9956 - val_loss: 1.6651 - val_acc: 0.6921\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9960\n",
      "Epoch 00062: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 422us/sample - loss: 0.0267 - acc: 0.9960 - val_loss: 1.7177 - val_acc: 0.6734\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9969\n",
      "Epoch 00063: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 422us/sample - loss: 0.0242 - acc: 0.9968 - val_loss: 1.8237 - val_acc: 0.6699\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9959\n",
      "Epoch 00064: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.0277 - acc: 0.9958 - val_loss: 1.8685 - val_acc: 0.6622\n",
      "Epoch 65/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9958\n",
      "Epoch 00065: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.0277 - acc: 0.9958 - val_loss: 1.8000 - val_acc: 0.6632\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9964\n",
      "Epoch 00066: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.0257 - acc: 0.9964 - val_loss: 1.8329 - val_acc: 0.6620\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9961\n",
      "Epoch 00067: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 422us/sample - loss: 0.0261 - acc: 0.9960 - val_loss: 1.7760 - val_acc: 0.6706\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9951\n",
      "Epoch 00068: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 421us/sample - loss: 0.0299 - acc: 0.9951 - val_loss: 1.9285 - val_acc: 0.6571\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9964\n",
      "Epoch 00069: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.0241 - acc: 0.9963 - val_loss: 1.7793 - val_acc: 0.6797\n",
      "Epoch 70/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9970\n",
      "Epoch 00070: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.0238 - acc: 0.9969 - val_loss: 1.8356 - val_acc: 0.6692\n",
      "Epoch 71/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9966\n",
      "Epoch 00071: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 417us/sample - loss: 0.0258 - acc: 0.9966 - val_loss: 1.7933 - val_acc: 0.6734\n",
      "Epoch 72/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9966\n",
      "Epoch 00072: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.0249 - acc: 0.9965 - val_loss: 1.8673 - val_acc: 0.6732\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9971\n",
      "Epoch 00073: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 415us/sample - loss: 0.0227 - acc: 0.9971 - val_loss: 1.8019 - val_acc: 0.6734\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9958\n",
      "Epoch 00074: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 424us/sample - loss: 0.0258 - acc: 0.9958 - val_loss: 1.8790 - val_acc: 0.6608\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9969\n",
      "Epoch 00075: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 422us/sample - loss: 0.0216 - acc: 0.9969 - val_loss: 1.9007 - val_acc: 0.6567\n",
      "Epoch 76/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9962\n",
      "Epoch 00076: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 416us/sample - loss: 0.0256 - acc: 0.9961 - val_loss: 1.8730 - val_acc: 0.6685\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9961\n",
      "Epoch 00077: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 424us/sample - loss: 0.0246 - acc: 0.9961 - val_loss: 1.8107 - val_acc: 0.6692\n",
      "Epoch 78/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9982\n",
      "Epoch 00078: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 418us/sample - loss: 0.0184 - acc: 0.9981 - val_loss: 1.8989 - val_acc: 0.6660\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9951\n",
      "Epoch 00079: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 424us/sample - loss: 0.0289 - acc: 0.9951 - val_loss: 1.9954 - val_acc: 0.6473\n",
      "Epoch 80/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9972\n",
      "Epoch 00080: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 414us/sample - loss: 0.0223 - acc: 0.9971 - val_loss: 1.8395 - val_acc: 0.6739\n",
      "Epoch 81/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9967\n",
      "Epoch 00081: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.0245 - acc: 0.9966 - val_loss: 1.8718 - val_acc: 0.6746\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9973\n",
      "Epoch 00082: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 421us/sample - loss: 0.0206 - acc: 0.9972 - val_loss: 1.8524 - val_acc: 0.6688\n",
      "Epoch 83/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9953\n",
      "Epoch 00083: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.0251 - acc: 0.9953 - val_loss: 2.1073 - val_acc: 0.6317\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9975\n",
      "Epoch 00084: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.0194 - acc: 0.9974 - val_loss: 1.9722 - val_acc: 0.6564\n",
      "Epoch 85/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9970\n",
      "Epoch 00085: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 428us/sample - loss: 0.0205 - acc: 0.9970 - val_loss: 1.8816 - val_acc: 0.6632\n",
      "Epoch 86/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9984\n",
      "Epoch 00086: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.0166 - acc: 0.9984 - val_loss: 1.9134 - val_acc: 0.6725\n",
      "Epoch 87/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9963\n",
      "Epoch 00087: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.0228 - acc: 0.9963 - val_loss: 1.9548 - val_acc: 0.6615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9971\n",
      "Epoch 00088: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.0196 - acc: 0.9971 - val_loss: 1.9036 - val_acc: 0.6639\n",
      "Epoch 89/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9965\n",
      "Epoch 00089: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.0217 - acc: 0.9965 - val_loss: 1.8996 - val_acc: 0.6681\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9976\n",
      "Epoch 00090: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.0192 - acc: 0.9976 - val_loss: 1.8892 - val_acc: 0.6706\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9976\n",
      "Epoch 00091: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 424us/sample - loss: 0.0207 - acc: 0.9976 - val_loss: 2.1261 - val_acc: 0.6485\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9956\n",
      "Epoch 00092: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 430us/sample - loss: 0.0278 - acc: 0.9955 - val_loss: 2.0040 - val_acc: 0.6594\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9960\n",
      "Epoch 00093: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 430us/sample - loss: 0.0226 - acc: 0.9960 - val_loss: 1.9034 - val_acc: 0.6706\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9980\n",
      "Epoch 00094: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 0.0169 - acc: 0.9980 - val_loss: 1.9793 - val_acc: 0.6671\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9981\n",
      "Epoch 00095: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 0.0183 - acc: 0.9980 - val_loss: 1.9954 - val_acc: 0.6650\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9961\n",
      "Epoch 00096: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 0.0223 - acc: 0.9961 - val_loss: 2.1184 - val_acc: 0.6490\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9965\n",
      "Epoch 00097: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 430us/sample - loss: 0.0226 - acc: 0.9965 - val_loss: 1.9141 - val_acc: 0.6734\n",
      "Epoch 98/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9978\n",
      "Epoch 00098: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 0.0179 - acc: 0.9977 - val_loss: 2.1998 - val_acc: 0.6478\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9962\n",
      "Epoch 00099: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 428us/sample - loss: 0.0225 - acc: 0.9962 - val_loss: 1.9452 - val_acc: 0.6774\n",
      "Epoch 100/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9977\n",
      "Epoch 00100: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 430us/sample - loss: 0.0173 - acc: 0.9976 - val_loss: 1.9799 - val_acc: 0.6720\n",
      "Epoch 101/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9973\n",
      "Epoch 00101: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 428us/sample - loss: 0.0169 - acc: 0.9972 - val_loss: 2.0972 - val_acc: 0.6601\n",
      "Epoch 102/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9959\n",
      "Epoch 00102: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 0.0239 - acc: 0.9958 - val_loss: 1.9558 - val_acc: 0.6690\n",
      "Epoch 103/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9945\n",
      "Epoch 00103: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 0.0318 - acc: 0.9945 - val_loss: 1.9406 - val_acc: 0.6704\n",
      "Epoch 104/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9983\n",
      "Epoch 00104: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 430us/sample - loss: 0.0151 - acc: 0.9982 - val_loss: 2.2025 - val_acc: 0.6438\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9980\n",
      "Epoch 00105: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 0.0159 - acc: 0.9980 - val_loss: 1.9124 - val_acc: 0.6741\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9970\n",
      "Epoch 00106: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.0192 - acc: 0.9970 - val_loss: 2.0161 - val_acc: 0.6627\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9977\n",
      "Epoch 00107: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 0.0169 - acc: 0.9976 - val_loss: 1.9930 - val_acc: 0.6699\n",
      "Epoch 108/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9963\n",
      "Epoch 00108: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 431us/sample - loss: 0.0222 - acc: 0.9963 - val_loss: 1.9641 - val_acc: 0.6711\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9968\n",
      "Epoch 00109: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 430us/sample - loss: 0.0198 - acc: 0.9968 - val_loss: 2.0118 - val_acc: 0.6634\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9972\n",
      "Epoch 00110: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 430us/sample - loss: 0.0175 - acc: 0.9971 - val_loss: 1.9759 - val_acc: 0.6753\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9950\n",
      "Epoch 00111: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.0291 - acc: 0.9950 - val_loss: 2.0268 - val_acc: 0.6688\n",
      "Epoch 112/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9978\n",
      "Epoch 00112: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.0159 - acc: 0.9978 - val_loss: 2.0269 - val_acc: 0.6606\n",
      "Epoch 113/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9973\n",
      "Epoch 00113: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.0179 - acc: 0.9973 - val_loss: 1.9622 - val_acc: 0.6774\n",
      "Epoch 114/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9970\n",
      "Epoch 00114: val_loss did not improve from 1.14976\n",
      "36805/36805 [==============================] - 16s 428us/sample - loss: 0.0187 - acc: 0.9970 - val_loss: 1.9676 - val_acc: 0.6685\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 289us/sample - loss: 1.2236 - acc: 0.6644\n",
      "Loss: 1.223611071424197 Accuracy: 0.66438216\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8214 - acc: 0.4364\n",
      "Epoch 00001: val_loss improved from inf to 1.67338, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_5_conv_checkpoint/001-1.6734.hdf5\n",
      "36805/36805 [==============================] - 25s 675us/sample - loss: 1.8215 - acc: 0.4364 - val_loss: 1.6734 - val_acc: 0.4279\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1892 - acc: 0.6377\n",
      "Epoch 00002: val_loss improved from 1.67338 to 1.12687, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_5_conv_checkpoint/002-1.1269.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.1894 - acc: 0.6377 - val_loss: 1.1269 - val_acc: 0.6573\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9936 - acc: 0.6988\n",
      "Epoch 00003: val_loss improved from 1.12687 to 1.01178, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_5_conv_checkpoint/003-1.0118.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9936 - acc: 0.6988 - val_loss: 1.0118 - val_acc: 0.6997\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8567 - acc: 0.7445\n",
      "Epoch 00004: val_loss improved from 1.01178 to 0.90483, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_5_conv_checkpoint/004-0.9048.hdf5\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.8566 - acc: 0.7445 - val_loss: 0.9048 - val_acc: 0.7282\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7544 - acc: 0.7773\n",
      "Epoch 00005: val_loss did not improve from 0.90483\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.7546 - acc: 0.7773 - val_loss: 1.0355 - val_acc: 0.6976\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6710 - acc: 0.8029\n",
      "Epoch 00006: val_loss improved from 0.90483 to 0.88017, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_5_conv_checkpoint/006-0.8802.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.6711 - acc: 0.8028 - val_loss: 0.8802 - val_acc: 0.7447\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6000 - acc: 0.8239\n",
      "Epoch 00007: val_loss improved from 0.88017 to 0.82646, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_5_conv_checkpoint/007-0.8265.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.6003 - acc: 0.8238 - val_loss: 0.8265 - val_acc: 0.7517\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5354 - acc: 0.8435\n",
      "Epoch 00008: val_loss improved from 0.82646 to 0.77475, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_5_conv_checkpoint/008-0.7747.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.5355 - acc: 0.8435 - val_loss: 0.7747 - val_acc: 0.7750\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4741 - acc: 0.8626\n",
      "Epoch 00009: val_loss did not improve from 0.77475\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4741 - acc: 0.8626 - val_loss: 0.7962 - val_acc: 0.7692\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4277 - acc: 0.8766\n",
      "Epoch 00010: val_loss improved from 0.77475 to 0.73975, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_5_conv_checkpoint/010-0.7398.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4278 - acc: 0.8766 - val_loss: 0.7398 - val_acc: 0.7855\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3781 - acc: 0.8934\n",
      "Epoch 00011: val_loss did not improve from 0.73975\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.3781 - acc: 0.8934 - val_loss: 0.7499 - val_acc: 0.7887\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3389 - acc: 0.9054\n",
      "Epoch 00012: val_loss improved from 0.73975 to 0.72262, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_5_conv_checkpoint/012-0.7226.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3391 - acc: 0.9054 - val_loss: 0.7226 - val_acc: 0.7983\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3015 - acc: 0.9183\n",
      "Epoch 00013: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3017 - acc: 0.9182 - val_loss: 0.7369 - val_acc: 0.7966\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9286\n",
      "Epoch 00014: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2708 - acc: 0.9286 - val_loss: 0.7469 - val_acc: 0.7913\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2372 - acc: 0.9380\n",
      "Epoch 00015: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2372 - acc: 0.9381 - val_loss: 0.7495 - val_acc: 0.7945\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9479\n",
      "Epoch 00016: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2110 - acc: 0.9479 - val_loss: 0.7921 - val_acc: 0.7817\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9533\n",
      "Epoch 00017: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.1920 - acc: 0.9533 - val_loss: 0.8344 - val_acc: 0.7808\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1665 - acc: 0.9612\n",
      "Epoch 00018: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.1665 - acc: 0.9611 - val_loss: 1.1119 - val_acc: 0.7035\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9658\n",
      "Epoch 00019: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.1525 - acc: 0.9658 - val_loss: 0.7855 - val_acc: 0.7962\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9698\n",
      "Epoch 00020: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.1393 - acc: 0.9698 - val_loss: 0.8205 - val_acc: 0.7948\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9718\n",
      "Epoch 00021: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.1338 - acc: 0.9718 - val_loss: 0.7764 - val_acc: 0.7922\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9774\n",
      "Epoch 00022: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.1120 - acc: 0.9774 - val_loss: 0.8868 - val_acc: 0.7701\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9782\n",
      "Epoch 00023: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.1093 - acc: 0.9781 - val_loss: 1.0501 - val_acc: 0.7349\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9815\n",
      "Epoch 00024: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0974 - acc: 0.9814 - val_loss: 0.7843 - val_acc: 0.8032\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9820\n",
      "Epoch 00025: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.0934 - acc: 0.9819 - val_loss: 0.8446 - val_acc: 0.7969\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9825\n",
      "Epoch 00026: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0897 - acc: 0.9825 - val_loss: 0.7587 - val_acc: 0.8139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9873\n",
      "Epoch 00027: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0745 - acc: 0.9873 - val_loss: 1.1511 - val_acc: 0.7312\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9886\n",
      "Epoch 00028: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.0698 - acc: 0.9886 - val_loss: 0.8190 - val_acc: 0.8083\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9883\n",
      "Epoch 00029: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0686 - acc: 0.9882 - val_loss: 0.9057 - val_acc: 0.7815\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9894\n",
      "Epoch 00030: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.0648 - acc: 0.9893 - val_loss: 0.9062 - val_acc: 0.7843\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9909\n",
      "Epoch 00031: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.0576 - acc: 0.9909 - val_loss: 0.8148 - val_acc: 0.8062\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9929\n",
      "Epoch 00032: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.0514 - acc: 0.9929 - val_loss: 1.0276 - val_acc: 0.7577\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9904\n",
      "Epoch 00033: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0574 - acc: 0.9904 - val_loss: 0.9663 - val_acc: 0.7752\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9921\n",
      "Epoch 00034: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.0512 - acc: 0.9921 - val_loss: 0.9723 - val_acc: 0.7834\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9910\n",
      "Epoch 00035: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0512 - acc: 0.9910 - val_loss: 0.7994 - val_acc: 0.8125\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9929\n",
      "Epoch 00036: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.0461 - acc: 0.9929 - val_loss: 0.8303 - val_acc: 0.8143\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9912\n",
      "Epoch 00037: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.0507 - acc: 0.9911 - val_loss: 0.8449 - val_acc: 0.8085\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9926\n",
      "Epoch 00038: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.0459 - acc: 0.9926 - val_loss: 0.8342 - val_acc: 0.8146\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9929\n",
      "Epoch 00039: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.0454 - acc: 0.9928 - val_loss: 0.8447 - val_acc: 0.8102\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9940\n",
      "Epoch 00040: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.0404 - acc: 0.9940 - val_loss: 0.8414 - val_acc: 0.8178\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9961\n",
      "Epoch 00041: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.0349 - acc: 0.9960 - val_loss: 0.8441 - val_acc: 0.8118\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9923\n",
      "Epoch 00042: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0425 - acc: 0.9922 - val_loss: 0.8055 - val_acc: 0.8255\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9906\n",
      "Epoch 00043: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.0498 - acc: 0.9906 - val_loss: 0.8670 - val_acc: 0.8057\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9952\n",
      "Epoch 00044: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0333 - acc: 0.9952 - val_loss: 0.9318 - val_acc: 0.7952\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9960\n",
      "Epoch 00045: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0300 - acc: 0.9960 - val_loss: 1.0047 - val_acc: 0.7950\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9940\n",
      "Epoch 00046: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0364 - acc: 0.9940 - val_loss: 0.8529 - val_acc: 0.8176\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9962\n",
      "Epoch 00047: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0289 - acc: 0.9963 - val_loss: 0.8162 - val_acc: 0.8274\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9953\n",
      "Epoch 00048: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.0318 - acc: 0.9952 - val_loss: 0.7991 - val_acc: 0.8293\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9958\n",
      "Epoch 00049: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0302 - acc: 0.9957 - val_loss: 0.8632 - val_acc: 0.8125\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9911\n",
      "Epoch 00050: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0429 - acc: 0.9910 - val_loss: 0.8663 - val_acc: 0.8141\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9958\n",
      "Epoch 00051: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.0291 - acc: 0.9958 - val_loss: 0.8309 - val_acc: 0.8218\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9962\n",
      "Epoch 00052: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0271 - acc: 0.9962 - val_loss: 0.9656 - val_acc: 0.8020\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9953\n",
      "Epoch 00053: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0286 - acc: 0.9952 - val_loss: 0.8513 - val_acc: 0.8130\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9918\n",
      "Epoch 00054: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0415 - acc: 0.9918 - val_loss: 0.9581 - val_acc: 0.8050\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9972\n",
      "Epoch 00055: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.0223 - acc: 0.9971 - val_loss: 0.8751 - val_acc: 0.8218\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9953\n",
      "Epoch 00056: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0298 - acc: 0.9953 - val_loss: 0.8753 - val_acc: 0.8157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9940\n",
      "Epoch 00057: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.0340 - acc: 0.9940 - val_loss: 1.1029 - val_acc: 0.7845\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9978\n",
      "Epoch 00058: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.0202 - acc: 0.9978 - val_loss: 0.9062 - val_acc: 0.8027\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9946\n",
      "Epoch 00059: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.0297 - acc: 0.9946 - val_loss: 0.9891 - val_acc: 0.7980\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9944\n",
      "Epoch 00060: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.0311 - acc: 0.9943 - val_loss: 1.0001 - val_acc: 0.7985\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9973\n",
      "Epoch 00061: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.0221 - acc: 0.9973 - val_loss: 0.8999 - val_acc: 0.8169\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9964\n",
      "Epoch 00062: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.0241 - acc: 0.9964 - val_loss: 0.9152 - val_acc: 0.8116\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9961\n",
      "Epoch 00063: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.0256 - acc: 0.9960 - val_loss: 0.9950 - val_acc: 0.7929\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9952\n",
      "Epoch 00064: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.0276 - acc: 0.9952 - val_loss: 1.1214 - val_acc: 0.7869\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9955\n",
      "Epoch 00065: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.0266 - acc: 0.9955 - val_loss: 0.9457 - val_acc: 0.8137\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9986\n",
      "Epoch 00066: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.0179 - acc: 0.9985 - val_loss: 1.0017 - val_acc: 0.8069\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9940\n",
      "Epoch 00067: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.0318 - acc: 0.9940 - val_loss: 1.0109 - val_acc: 0.7945\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9975\n",
      "Epoch 00068: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.0187 - acc: 0.9974 - val_loss: 1.0728 - val_acc: 0.7978\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9942\n",
      "Epoch 00069: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.0304 - acc: 0.9942 - val_loss: 1.0270 - val_acc: 0.8022\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9959\n",
      "Epoch 00070: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.0257 - acc: 0.9958 - val_loss: 1.0974 - val_acc: 0.7894\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9950\n",
      "Epoch 00071: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.0272 - acc: 0.9950 - val_loss: 0.8637 - val_acc: 0.8260\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9977\n",
      "Epoch 00072: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.0176 - acc: 0.9977 - val_loss: 1.0955 - val_acc: 0.7976\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9953\n",
      "Epoch 00073: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.0255 - acc: 0.9953 - val_loss: 1.1191 - val_acc: 0.7813\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9973\n",
      "Epoch 00074: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.0194 - acc: 0.9973 - val_loss: 1.0152 - val_acc: 0.7952\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9955\n",
      "Epoch 00075: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.0252 - acc: 0.9955 - val_loss: 0.9229 - val_acc: 0.8209\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9984\n",
      "Epoch 00076: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.0161 - acc: 0.9983 - val_loss: 0.9344 - val_acc: 0.8255\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9966\n",
      "Epoch 00077: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.0217 - acc: 0.9966 - val_loss: 0.9077 - val_acc: 0.8260\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9963\n",
      "Epoch 00078: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.0222 - acc: 0.9963 - val_loss: 1.2487 - val_acc: 0.7727\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9971\n",
      "Epoch 00079: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.0208 - acc: 0.9970 - val_loss: 0.9419 - val_acc: 0.8227\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9963\n",
      "Epoch 00080: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.0238 - acc: 0.9963 - val_loss: 0.9988 - val_acc: 0.8097\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9947\n",
      "Epoch 00081: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.0273 - acc: 0.9947 - val_loss: 0.9840 - val_acc: 0.7992\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9983\n",
      "Epoch 00082: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.0152 - acc: 0.9983 - val_loss: 0.9921 - val_acc: 0.8130\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9967\n",
      "Epoch 00083: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.0204 - acc: 0.9967 - val_loss: 1.0364 - val_acc: 0.7980\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9965\n",
      "Epoch 00084: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.0204 - acc: 0.9965 - val_loss: 0.9421 - val_acc: 0.8146\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9969\n",
      "Epoch 00085: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.0199 - acc: 0.9969 - val_loss: 0.9416 - val_acc: 0.8174\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9983\n",
      "Epoch 00086: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.0149 - acc: 0.9983 - val_loss: 1.2093 - val_acc: 0.7822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9967\n",
      "Epoch 00087: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.0210 - acc: 0.9966 - val_loss: 1.0026 - val_acc: 0.8102\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9965\n",
      "Epoch 00088: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.0210 - acc: 0.9964 - val_loss: 1.1040 - val_acc: 0.7950\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9933\n",
      "Epoch 00089: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.0328 - acc: 0.9932 - val_loss: 0.9985 - val_acc: 0.8185\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9961\n",
      "Epoch 00090: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.0221 - acc: 0.9961 - val_loss: 1.1589 - val_acc: 0.7789\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9969\n",
      "Epoch 00091: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.0183 - acc: 0.9969 - val_loss: 0.9477 - val_acc: 0.8195\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9972\n",
      "Epoch 00092: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.0179 - acc: 0.9972 - val_loss: 1.1751 - val_acc: 0.7841\n",
      "Epoch 93/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9966\n",
      "Epoch 00093: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.0204 - acc: 0.9966 - val_loss: 1.0224 - val_acc: 0.8071\n",
      "Epoch 94/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9956\n",
      "Epoch 00094: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.0235 - acc: 0.9956 - val_loss: 0.9251 - val_acc: 0.8295\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9956\n",
      "Epoch 00095: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.0223 - acc: 0.9955 - val_loss: 0.9740 - val_acc: 0.8169\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9972\n",
      "Epoch 00096: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.0179 - acc: 0.9971 - val_loss: 0.9263 - val_acc: 0.8290\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9975\n",
      "Epoch 00097: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.0160 - acc: 0.9974 - val_loss: 0.9637 - val_acc: 0.8188\n",
      "Epoch 98/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9950\n",
      "Epoch 00098: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.0233 - acc: 0.9950 - val_loss: 0.9505 - val_acc: 0.8276\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9962\n",
      "Epoch 00099: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.0201 - acc: 0.9961 - val_loss: 1.0730 - val_acc: 0.8022\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9959\n",
      "Epoch 00100: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.0210 - acc: 0.9959 - val_loss: 0.9729 - val_acc: 0.8125\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9957\n",
      "Epoch 00101: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.0212 - acc: 0.9956 - val_loss: 0.9616 - val_acc: 0.8232\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9961\n",
      "Epoch 00102: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.0208 - acc: 0.9961 - val_loss: 0.9478 - val_acc: 0.8185\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9953\n",
      "Epoch 00103: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.0235 - acc: 0.9953 - val_loss: 0.9696 - val_acc: 0.8220\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9950\n",
      "Epoch 00104: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.0237 - acc: 0.9949 - val_loss: 0.9423 - val_acc: 0.8258\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9962\n",
      "Epoch 00105: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.0209 - acc: 0.9962 - val_loss: 0.9642 - val_acc: 0.8188\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9980\n",
      "Epoch 00106: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.0145 - acc: 0.9980 - val_loss: 1.0275 - val_acc: 0.8120\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9968\n",
      "Epoch 00107: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.0182 - acc: 0.9968 - val_loss: 1.0554 - val_acc: 0.8081\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9986\n",
      "Epoch 00108: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.0126 - acc: 0.9986 - val_loss: 1.2159 - val_acc: 0.7911\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9967\n",
      "Epoch 00109: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.0190 - acc: 0.9967 - val_loss: 0.9533 - val_acc: 0.8281\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9985\n",
      "Epoch 00110: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.0124 - acc: 0.9985 - val_loss: 0.9673 - val_acc: 0.8276\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9977\n",
      "Epoch 00111: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.0151 - acc: 0.9977 - val_loss: 1.0240 - val_acc: 0.8150\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9976\n",
      "Epoch 00112: val_loss did not improve from 0.72262\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.0154 - acc: 0.9976 - val_loss: 0.9416 - val_acc: 0.8290\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 347us/sample - loss: 0.8096 - acc: 0.7674\n",
      "Loss: 0.8095521053173584 Accuracy: 0.7673936\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7542 - acc: 0.4614\n",
      "Epoch 00001: val_loss improved from inf to 1.35724, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/001-1.3572.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.7544 - acc: 0.4613 - val_loss: 1.3572 - val_acc: 0.5851\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0309 - acc: 0.6893\n",
      "Epoch 00002: val_loss improved from 1.35724 to 0.93583, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/002-0.9358.hdf5\n",
      "36805/36805 [==============================] - 19s 504us/sample - loss: 1.0310 - acc: 0.6893 - val_loss: 0.9358 - val_acc: 0.7251\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7779 - acc: 0.7731\n",
      "Epoch 00003: val_loss improved from 0.93583 to 0.71711, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/003-0.7171.hdf5\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.7779 - acc: 0.7731 - val_loss: 0.7171 - val_acc: 0.7945\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6166 - acc: 0.8233\n",
      "Epoch 00004: val_loss improved from 0.71711 to 0.61722, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/004-0.6172.hdf5\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.6166 - acc: 0.8232 - val_loss: 0.6172 - val_acc: 0.8290\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5023 - acc: 0.8574\n",
      "Epoch 00005: val_loss improved from 0.61722 to 0.60262, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/005-0.6026.hdf5\n",
      "36805/36805 [==============================] - 19s 508us/sample - loss: 0.5024 - acc: 0.8573 - val_loss: 0.6026 - val_acc: 0.8300\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4252 - acc: 0.8771\n",
      "Epoch 00006: val_loss improved from 0.60262 to 0.50759, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/006-0.5076.hdf5\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.4253 - acc: 0.8770 - val_loss: 0.5076 - val_acc: 0.8556\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3655 - acc: 0.8952\n",
      "Epoch 00007: val_loss did not improve from 0.50759\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.3656 - acc: 0.8952 - val_loss: 0.5826 - val_acc: 0.8181\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3133 - acc: 0.9113\n",
      "Epoch 00008: val_loss improved from 0.50759 to 0.42444, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/008-0.4244.hdf5\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.3134 - acc: 0.9113 - val_loss: 0.4244 - val_acc: 0.8847\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2730 - acc: 0.9240\n",
      "Epoch 00009: val_loss improved from 0.42444 to 0.40650, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/009-0.4065.hdf5\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.2730 - acc: 0.9239 - val_loss: 0.4065 - val_acc: 0.8882\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2393 - acc: 0.9341\n",
      "Epoch 00010: val_loss improved from 0.40650 to 0.39059, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/010-0.3906.hdf5\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.2393 - acc: 0.9341 - val_loss: 0.3906 - val_acc: 0.8921\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2057 - acc: 0.9437\n",
      "Epoch 00011: val_loss did not improve from 0.39059\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.2059 - acc: 0.9436 - val_loss: 0.4552 - val_acc: 0.8644\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1891 - acc: 0.9485\n",
      "Epoch 00012: val_loss improved from 0.39059 to 0.38731, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/012-0.3873.hdf5\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.1893 - acc: 0.9485 - val_loss: 0.3873 - val_acc: 0.8942\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1646 - acc: 0.9569\n",
      "Epoch 00013: val_loss did not improve from 0.38731\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.1646 - acc: 0.9569 - val_loss: 0.3967 - val_acc: 0.8919\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9645\n",
      "Epoch 00014: val_loss improved from 0.38731 to 0.38517, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/014-0.3852.hdf5\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.1411 - acc: 0.9645 - val_loss: 0.3852 - val_acc: 0.8994\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1327 - acc: 0.9668\n",
      "Epoch 00015: val_loss did not improve from 0.38517\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.1328 - acc: 0.9668 - val_loss: 0.4160 - val_acc: 0.8901\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9723\n",
      "Epoch 00016: val_loss improved from 0.38517 to 0.37309, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/016-0.3731.hdf5\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.1153 - acc: 0.9723 - val_loss: 0.3731 - val_acc: 0.9003\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9749\n",
      "Epoch 00017: val_loss did not improve from 0.37309\n",
      "36805/36805 [==============================] - 19s 505us/sample - loss: 0.1075 - acc: 0.9748 - val_loss: 0.4203 - val_acc: 0.8835\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9776\n",
      "Epoch 00018: val_loss did not improve from 0.37309\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.0962 - acc: 0.9776 - val_loss: 0.3920 - val_acc: 0.8880\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9821\n",
      "Epoch 00019: val_loss improved from 0.37309 to 0.35390, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/019-0.3539.hdf5\n",
      "36805/36805 [==============================] - 19s 503us/sample - loss: 0.0825 - acc: 0.9821 - val_loss: 0.3539 - val_acc: 0.9064\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9862\n",
      "Epoch 00020: val_loss did not improve from 0.35390\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0691 - acc: 0.9861 - val_loss: 0.3849 - val_acc: 0.8903\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9829\n",
      "Epoch 00021: val_loss did not improve from 0.35390\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0775 - acc: 0.9828 - val_loss: 0.3812 - val_acc: 0.8945\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9853\n",
      "Epoch 00022: val_loss did not improve from 0.35390\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.0696 - acc: 0.9852 - val_loss: 0.3966 - val_acc: 0.8970\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9890\n",
      "Epoch 00023: val_loss improved from 0.35390 to 0.35071, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_6_conv_checkpoint/023-0.3507.hdf5\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0566 - acc: 0.9890 - val_loss: 0.3507 - val_acc: 0.9115\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9930\n",
      "Epoch 00024: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0435 - acc: 0.9930 - val_loss: 0.3904 - val_acc: 0.9003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9924\n",
      "Epoch 00025: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.0444 - acc: 0.9924 - val_loss: 0.4832 - val_acc: 0.8747\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9902\n",
      "Epoch 00026: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0484 - acc: 0.9902 - val_loss: 0.3901 - val_acc: 0.8961\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9936\n",
      "Epoch 00027: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0363 - acc: 0.9936 - val_loss: 0.4786 - val_acc: 0.8877\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9907\n",
      "Epoch 00028: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0479 - acc: 0.9907 - val_loss: 0.4392 - val_acc: 0.8903\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9931\n",
      "Epoch 00029: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 502us/sample - loss: 0.0379 - acc: 0.9931 - val_loss: 0.4100 - val_acc: 0.9031\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9952\n",
      "Epoch 00030: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.0315 - acc: 0.9952 - val_loss: 0.4699 - val_acc: 0.8805\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9908\n",
      "Epoch 00031: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0424 - acc: 0.9908 - val_loss: 0.3852 - val_acc: 0.8996\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9926\n",
      "Epoch 00032: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0380 - acc: 0.9926 - val_loss: 0.3945 - val_acc: 0.9012\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9971\n",
      "Epoch 00033: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0236 - acc: 0.9970 - val_loss: 0.4093 - val_acc: 0.9001\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9925\n",
      "Epoch 00034: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0377 - acc: 0.9924 - val_loss: 0.4192 - val_acc: 0.8947\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9942\n",
      "Epoch 00035: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0314 - acc: 0.9941 - val_loss: 0.3939 - val_acc: 0.9057\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9955\n",
      "Epoch 00036: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0267 - acc: 0.9955 - val_loss: 0.3978 - val_acc: 0.9012\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9975\n",
      "Epoch 00037: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0198 - acc: 0.9975 - val_loss: 0.4374 - val_acc: 0.8984\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9970\n",
      "Epoch 00038: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.0209 - acc: 0.9970 - val_loss: 0.4934 - val_acc: 0.8870\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9924\n",
      "Epoch 00039: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.0355 - acc: 0.9924 - val_loss: 0.4733 - val_acc: 0.8912\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9954\n",
      "Epoch 00040: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0255 - acc: 0.9954 - val_loss: 0.3919 - val_acc: 0.9078\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9957\n",
      "Epoch 00041: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0243 - acc: 0.9957 - val_loss: 0.4580 - val_acc: 0.8891\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9911\n",
      "Epoch 00042: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0377 - acc: 0.9911 - val_loss: 0.3724 - val_acc: 0.9108\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9984\n",
      "Epoch 00043: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.0146 - acc: 0.9984 - val_loss: 0.3878 - val_acc: 0.9131\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9983\n",
      "Epoch 00044: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0136 - acc: 0.9983 - val_loss: 0.4230 - val_acc: 0.9005\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9982\n",
      "Epoch 00045: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0148 - acc: 0.9982 - val_loss: 0.4857 - val_acc: 0.8842\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9918\n",
      "Epoch 00046: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.0355 - acc: 0.9918 - val_loss: 0.4182 - val_acc: 0.9054\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9972\n",
      "Epoch 00047: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0178 - acc: 0.9972 - val_loss: 0.4440 - val_acc: 0.8961\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9942\n",
      "Epoch 00048: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0262 - acc: 0.9942 - val_loss: 0.5066 - val_acc: 0.8896\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9987\n",
      "Epoch 00049: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0118 - acc: 0.9987 - val_loss: 0.3977 - val_acc: 0.9126\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9962\n",
      "Epoch 00050: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0214 - acc: 0.9961 - val_loss: 0.4296 - val_acc: 0.8982\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9954\n",
      "Epoch 00051: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0216 - acc: 0.9954 - val_loss: 0.4211 - val_acc: 0.9036\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9953\n",
      "Epoch 00052: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0215 - acc: 0.9953 - val_loss: 0.4330 - val_acc: 0.9038\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9967\n",
      "Epoch 00053: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0178 - acc: 0.9967 - val_loss: 0.3903 - val_acc: 0.9129\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9962\n",
      "Epoch 00054: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.0207 - acc: 0.9961 - val_loss: 0.4818 - val_acc: 0.8996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9910\n",
      "Epoch 00055: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.0367 - acc: 0.9910 - val_loss: 0.4200 - val_acc: 0.9001\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9979\n",
      "Epoch 00056: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.0132 - acc: 0.9979 - val_loss: 0.3867 - val_acc: 0.9103\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9987\n",
      "Epoch 00057: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0107 - acc: 0.9988 - val_loss: 0.3963 - val_acc: 0.9089\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9985\n",
      "Epoch 00058: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0115 - acc: 0.9985 - val_loss: 0.4617 - val_acc: 0.8994\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9986\n",
      "Epoch 00059: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0114 - acc: 0.9986 - val_loss: 0.4999 - val_acc: 0.8954\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9925\n",
      "Epoch 00060: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.0313 - acc: 0.9924 - val_loss: 0.3987 - val_acc: 0.9131\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9939\n",
      "Epoch 00061: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0264 - acc: 0.9939 - val_loss: 0.4019 - val_acc: 0.9103\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9973\n",
      "Epoch 00062: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0146 - acc: 0.9972 - val_loss: 0.3876 - val_acc: 0.9092\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9973\n",
      "Epoch 00063: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0145 - acc: 0.9973 - val_loss: 0.3638 - val_acc: 0.9175\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9984\n",
      "Epoch 00064: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0105 - acc: 0.9984 - val_loss: 0.4620 - val_acc: 0.9003\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9928\n",
      "Epoch 00065: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0290 - acc: 0.9928 - val_loss: 0.3783 - val_acc: 0.9166\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9987\n",
      "Epoch 00066: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0090 - acc: 0.9987 - val_loss: 0.3987 - val_acc: 0.9152\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9947\n",
      "Epoch 00067: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0225 - acc: 0.9946 - val_loss: 0.4133 - val_acc: 0.9110\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9974\n",
      "Epoch 00068: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0136 - acc: 0.9974 - val_loss: 0.4025 - val_acc: 0.9164\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9956\n",
      "Epoch 00069: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0202 - acc: 0.9956 - val_loss: 0.4106 - val_acc: 0.9089\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9974\n",
      "Epoch 00070: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0140 - acc: 0.9974 - val_loss: 0.4164 - val_acc: 0.9092\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9978\n",
      "Epoch 00071: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0123 - acc: 0.9978 - val_loss: 0.4071 - val_acc: 0.9108\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9984\n",
      "Epoch 00072: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0100 - acc: 0.9983 - val_loss: 0.4414 - val_acc: 0.9047\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9936\n",
      "Epoch 00073: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0244 - acc: 0.9936 - val_loss: 0.4037 - val_acc: 0.9119\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9991\n",
      "Epoch 00074: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0092 - acc: 0.9991 - val_loss: 0.4427 - val_acc: 0.9080\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9986\n",
      "Epoch 00075: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0093 - acc: 0.9986 - val_loss: 0.4356 - val_acc: 0.9057\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9984\n",
      "Epoch 00076: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.0106 - acc: 0.9983 - val_loss: 0.4042 - val_acc: 0.9138\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9935\n",
      "Epoch 00077: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.0259 - acc: 0.9935 - val_loss: 0.4465 - val_acc: 0.9024\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9991\n",
      "Epoch 00078: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0074 - acc: 0.9991 - val_loss: 0.3862 - val_acc: 0.9175\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9996\n",
      "Epoch 00079: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.0052 - acc: 0.9996 - val_loss: 0.3916 - val_acc: 0.9119\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9925\n",
      "Epoch 00080: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 502us/sample - loss: 0.0275 - acc: 0.9924 - val_loss: 0.3903 - val_acc: 0.9140\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9975\n",
      "Epoch 00081: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.0130 - acc: 0.9974 - val_loss: 0.4374 - val_acc: 0.9054\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9920\n",
      "Epoch 00082: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0302 - acc: 0.9920 - val_loss: 0.4283 - val_acc: 0.9075\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9994\n",
      "Epoch 00083: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0068 - acc: 0.9994 - val_loss: 0.3710 - val_acc: 0.9206\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9990\n",
      "Epoch 00084: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0069 - acc: 0.9990 - val_loss: 0.4426 - val_acc: 0.9064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9969\n",
      "Epoch 00085: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0149 - acc: 0.9969 - val_loss: 0.4298 - val_acc: 0.9110\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9967\n",
      "Epoch 00086: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0146 - acc: 0.9967 - val_loss: 0.5531 - val_acc: 0.8854\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9963\n",
      "Epoch 00087: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0145 - acc: 0.9963 - val_loss: 0.4211 - val_acc: 0.9057\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9994\n",
      "Epoch 00088: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0055 - acc: 0.9994 - val_loss: 0.4519 - val_acc: 0.9092\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9959\n",
      "Epoch 00089: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0167 - acc: 0.9958 - val_loss: 0.4291 - val_acc: 0.9066\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9970\n",
      "Epoch 00090: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.0127 - acc: 0.9970 - val_loss: 0.3641 - val_acc: 0.9227\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9987\n",
      "Epoch 00091: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0078 - acc: 0.9988 - val_loss: 0.4372 - val_acc: 0.9101\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9977\n",
      "Epoch 00092: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0113 - acc: 0.9977 - val_loss: 0.4475 - val_acc: 0.9001\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9991\n",
      "Epoch 00093: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.0075 - acc: 0.9991 - val_loss: 0.4027 - val_acc: 0.9117\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9978\n",
      "Epoch 00094: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.0117 - acc: 0.9978 - val_loss: 0.4334 - val_acc: 0.9071\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9956\n",
      "Epoch 00095: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0167 - acc: 0.9956 - val_loss: 0.3935 - val_acc: 0.9152\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9995\n",
      "Epoch 00096: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0051 - acc: 0.9995 - val_loss: 0.4128 - val_acc: 0.9152\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9976\n",
      "Epoch 00097: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0115 - acc: 0.9975 - val_loss: 0.4044 - val_acc: 0.9164\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9945\n",
      "Epoch 00098: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0208 - acc: 0.9945 - val_loss: 0.4062 - val_acc: 0.9166\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9960\n",
      "Epoch 00099: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0158 - acc: 0.9960 - val_loss: 0.3972 - val_acc: 0.9175\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9989\n",
      "Epoch 00100: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0072 - acc: 0.9989 - val_loss: 0.4022 - val_acc: 0.9154\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9995\n",
      "Epoch 00101: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0044 - acc: 0.9995 - val_loss: 0.4424 - val_acc: 0.9066\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9972\n",
      "Epoch 00102: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.0116 - acc: 0.9971 - val_loss: 0.4277 - val_acc: 0.9113\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9947\n",
      "Epoch 00103: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.0193 - acc: 0.9947 - val_loss: 0.4121 - val_acc: 0.9175\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9962\n",
      "Epoch 00104: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0143 - acc: 0.9962 - val_loss: 0.4101 - val_acc: 0.9175\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9994\n",
      "Epoch 00105: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0052 - acc: 0.9993 - val_loss: 0.4563 - val_acc: 0.9078\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9945\n",
      "Epoch 00106: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.0204 - acc: 0.9945 - val_loss: 0.4076 - val_acc: 0.9150\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9995\n",
      "Epoch 00107: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.0048 - acc: 0.9995 - val_loss: 0.3940 - val_acc: 0.9166\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9996\n",
      "Epoch 00108: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0046 - acc: 0.9995 - val_loss: 0.4452 - val_acc: 0.9085\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9965\n",
      "Epoch 00109: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0135 - acc: 0.9965 - val_loss: 0.4145 - val_acc: 0.9145\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9994\n",
      "Epoch 00110: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.0055 - acc: 0.9994 - val_loss: 0.4784 - val_acc: 0.9031\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9976\n",
      "Epoch 00111: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.0114 - acc: 0.9976 - val_loss: 0.4903 - val_acc: 0.9005\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9980\n",
      "Epoch 00112: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.0097 - acc: 0.9979 - val_loss: 0.5459 - val_acc: 0.8954\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9960\n",
      "Epoch 00113: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0145 - acc: 0.9960 - val_loss: 0.4537 - val_acc: 0.9059\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9987\n",
      "Epoch 00114: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.0069 - acc: 0.9987 - val_loss: 0.4144 - val_acc: 0.9152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9968\n",
      "Epoch 00115: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0124 - acc: 0.9968 - val_loss: 0.4547 - val_acc: 0.9108\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9990\n",
      "Epoch 00116: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.0060 - acc: 0.9990 - val_loss: 0.5192 - val_acc: 0.9029\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9976\n",
      "Epoch 00117: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.0107 - acc: 0.9975 - val_loss: 0.4789 - val_acc: 0.9040\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9960\n",
      "Epoch 00118: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.0163 - acc: 0.9960 - val_loss: 0.4022 - val_acc: 0.9208\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9995\n",
      "Epoch 00119: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.0042 - acc: 0.9995 - val_loss: 0.4064 - val_acc: 0.9203\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9992\n",
      "Epoch 00120: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.0054 - acc: 0.9991 - val_loss: 0.4581 - val_acc: 0.9057\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9952\n",
      "Epoch 00121: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.0178 - acc: 0.9952 - val_loss: 0.4458 - val_acc: 0.9078\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9992\n",
      "Epoch 00122: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.0052 - acc: 0.9992 - val_loss: 0.4339 - val_acc: 0.9138\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9975\n",
      "Epoch 00123: val_loss did not improve from 0.35071\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0121 - acc: 0.9975 - val_loss: 0.4059 - val_acc: 0.9164\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 389us/sample - loss: 0.4269 - acc: 0.8860\n",
      "Loss: 0.42686391343456437 Accuracy: 0.8859813\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3252 - acc: 0.5886\n",
      "Epoch 00001: val_loss improved from inf to 1.17442, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_7_conv_checkpoint/001-1.1744.hdf5\n",
      "36805/36805 [==============================] - 35s 955us/sample - loss: 1.3252 - acc: 0.5886 - val_loss: 1.1744 - val_acc: 0.6259\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6259 - acc: 0.8135\n",
      "Epoch 00002: val_loss improved from 1.17442 to 0.52369, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_7_conv_checkpoint/002-0.5237.hdf5\n",
      "36805/36805 [==============================] - 20s 543us/sample - loss: 0.6260 - acc: 0.8134 - val_loss: 0.5237 - val_acc: 0.8418\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4275 - acc: 0.8737\n",
      "Epoch 00003: val_loss improved from 0.52369 to 0.43235, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_7_conv_checkpoint/003-0.4324.hdf5\n",
      "36805/36805 [==============================] - 20s 542us/sample - loss: 0.4275 - acc: 0.8737 - val_loss: 0.4324 - val_acc: 0.8672\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3122 - acc: 0.9092\n",
      "Epoch 00004: val_loss improved from 0.43235 to 0.34397, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_7_conv_checkpoint/004-0.3440.hdf5\n",
      "36805/36805 [==============================] - 20s 547us/sample - loss: 0.3122 - acc: 0.9092 - val_loss: 0.3440 - val_acc: 0.8984\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2456 - acc: 0.9283\n",
      "Epoch 00005: val_loss improved from 0.34397 to 0.31192, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_7_conv_checkpoint/005-0.3119.hdf5\n",
      "36805/36805 [==============================] - 20s 542us/sample - loss: 0.2456 - acc: 0.9283 - val_loss: 0.3119 - val_acc: 0.9036\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9428\n",
      "Epoch 00006: val_loss improved from 0.31192 to 0.31121, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_7_conv_checkpoint/006-0.3112.hdf5\n",
      "36805/36805 [==============================] - 20s 546us/sample - loss: 0.1956 - acc: 0.9428 - val_loss: 0.3112 - val_acc: 0.8980\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9570\n",
      "Epoch 00007: val_loss did not improve from 0.31121\n",
      "36805/36805 [==============================] - 20s 542us/sample - loss: 0.1545 - acc: 0.9570 - val_loss: 0.3225 - val_acc: 0.9022\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9659\n",
      "Epoch 00008: val_loss improved from 0.31121 to 0.30547, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_7_conv_checkpoint/008-0.3055.hdf5\n",
      "36805/36805 [==============================] - 20s 544us/sample - loss: 0.1248 - acc: 0.9659 - val_loss: 0.3055 - val_acc: 0.9129\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9706\n",
      "Epoch 00009: val_loss improved from 0.30547 to 0.26341, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_7_conv_checkpoint/009-0.2634.hdf5\n",
      "36805/36805 [==============================] - 20s 547us/sample - loss: 0.1082 - acc: 0.9706 - val_loss: 0.2634 - val_acc: 0.9227\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9794\n",
      "Epoch 00010: val_loss did not improve from 0.26341\n",
      "36805/36805 [==============================] - 20s 545us/sample - loss: 0.0838 - acc: 0.9794 - val_loss: 0.3037 - val_acc: 0.9182\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9833\n",
      "Epoch 00011: val_loss improved from 0.26341 to 0.24403, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_7_conv_checkpoint/011-0.2440.hdf5\n",
      "36805/36805 [==============================] - 20s 549us/sample - loss: 0.0716 - acc: 0.9833 - val_loss: 0.2440 - val_acc: 0.9287\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9876\n",
      "Epoch 00012: val_loss did not improve from 0.24403\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0575 - acc: 0.9876 - val_loss: 0.2785 - val_acc: 0.9171\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9907\n",
      "Epoch 00013: val_loss did not improve from 0.24403\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0449 - acc: 0.9907 - val_loss: 0.2775 - val_acc: 0.9213\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9892\n",
      "Epoch 00014: val_loss did not improve from 0.24403\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.0477 - acc: 0.9892 - val_loss: 0.2815 - val_acc: 0.9182\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9920\n",
      "Epoch 00015: val_loss did not improve from 0.24403\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.0373 - acc: 0.9920 - val_loss: 0.2684 - val_acc: 0.9269\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9933\n",
      "Epoch 00016: val_loss did not improve from 0.24403\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0354 - acc: 0.9933 - val_loss: 0.2702 - val_acc: 0.9252\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9937\n",
      "Epoch 00017: val_loss did not improve from 0.24403\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.0320 - acc: 0.9937 - val_loss: 0.2644 - val_acc: 0.9264\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9956\n",
      "Epoch 00018: val_loss did not improve from 0.24403\n",
      "36805/36805 [==============================] - 20s 542us/sample - loss: 0.0260 - acc: 0.9956 - val_loss: 0.2546 - val_acc: 0.9324\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9959\n",
      "Epoch 00019: val_loss did not improve from 0.24403\n",
      "36805/36805 [==============================] - 20s 542us/sample - loss: 0.0226 - acc: 0.9958 - val_loss: 0.2975 - val_acc: 0.9238\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9890\n",
      "Epoch 00020: val_loss improved from 0.24403 to 0.24369, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_7_conv_checkpoint/020-0.2437.hdf5\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0432 - acc: 0.9890 - val_loss: 0.2437 - val_acc: 0.9301\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9975\n",
      "Epoch 00021: val_loss did not improve from 0.24369\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.0154 - acc: 0.9974 - val_loss: 0.2633 - val_acc: 0.9224\n",
      "Epoch 22/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 00022: val_loss did not improve from 0.24369\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.0343 - acc: 0.9917 - val_loss: 0.2556 - val_acc: 0.9290\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9985\n",
      "Epoch 00023: val_loss improved from 0.24369 to 0.20956, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_7_conv_checkpoint/023-0.2096.hdf5\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0112 - acc: 0.9985 - val_loss: 0.2096 - val_acc: 0.9413\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9983\n",
      "Epoch 00024: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 537us/sample - loss: 0.0123 - acc: 0.9983 - val_loss: 0.2608 - val_acc: 0.9327\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9973\n",
      "Epoch 00025: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 532us/sample - loss: 0.0163 - acc: 0.9973 - val_loss: 0.3447 - val_acc: 0.9138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9946\n",
      "Epoch 00026: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 542us/sample - loss: 0.0233 - acc: 0.9946 - val_loss: 0.2675 - val_acc: 0.9299\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9965\n",
      "Epoch 00027: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 534us/sample - loss: 0.0175 - acc: 0.9965 - val_loss: 0.2733 - val_acc: 0.9238\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9967\n",
      "Epoch 00028: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0162 - acc: 0.9967 - val_loss: 0.2592 - val_acc: 0.9352\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9944\n",
      "Epoch 00029: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0233 - acc: 0.9944 - val_loss: 0.2373 - val_acc: 0.9378\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9964\n",
      "Epoch 00030: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 533us/sample - loss: 0.0176 - acc: 0.9964 - val_loss: 0.2409 - val_acc: 0.9378\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9992\n",
      "Epoch 00031: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 537us/sample - loss: 0.0067 - acc: 0.9992 - val_loss: 0.2699 - val_acc: 0.9306\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9945\n",
      "Epoch 00032: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.0237 - acc: 0.9945 - val_loss: 0.2406 - val_acc: 0.9399\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9988\n",
      "Epoch 00033: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.0077 - acc: 0.9988 - val_loss: 0.2316 - val_acc: 0.9408\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9975- ETA: 1s - los\n",
      "Epoch 00034: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 537us/sample - loss: 0.0108 - acc: 0.9975 - val_loss: 0.3151 - val_acc: 0.9161\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9951\n",
      "Epoch 00035: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 534us/sample - loss: 0.0199 - acc: 0.9951 - val_loss: 0.2370 - val_acc: 0.9394\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9981\n",
      "Epoch 00036: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.0103 - acc: 0.9981 - val_loss: 0.2698 - val_acc: 0.9343\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9990\n",
      "Epoch 00037: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 534us/sample - loss: 0.0061 - acc: 0.9990 - val_loss: 0.2406 - val_acc: 0.9406\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9990\n",
      "Epoch 00038: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0064 - acc: 0.9989 - val_loss: 0.2840 - val_acc: 0.9264\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9941\n",
      "Epoch 00039: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0226 - acc: 0.9940 - val_loss: 0.3090 - val_acc: 0.9266\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9950\n",
      "Epoch 00040: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0182 - acc: 0.9950 - val_loss: 0.2473 - val_acc: 0.9406\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9996\n",
      "Epoch 00041: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0040 - acc: 0.9996 - val_loss: 0.2325 - val_acc: 0.9401\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9959\n",
      "Epoch 00042: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.0161 - acc: 0.9959 - val_loss: 0.2337 - val_acc: 0.9406\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9995\n",
      "Epoch 00043: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0043 - acc: 0.9995 - val_loss: 0.2985 - val_acc: 0.9308\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9926\n",
      "Epoch 00044: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0267 - acc: 0.9925 - val_loss: 0.2252 - val_acc: 0.9432\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9980\n",
      "Epoch 00045: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0099 - acc: 0.9980 - val_loss: 0.2207 - val_acc: 0.9425\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9992\n",
      "Epoch 00046: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 535us/sample - loss: 0.0051 - acc: 0.9992 - val_loss: 0.2178 - val_acc: 0.9464\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9990\n",
      "Epoch 00047: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.0052 - acc: 0.9990 - val_loss: 0.3345 - val_acc: 0.9178\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9979- ETA: 1s - \n",
      "Epoch 00048: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0096 - acc: 0.9979 - val_loss: 0.3256 - val_acc: 0.9259\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9929\n",
      "Epoch 00049: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.0248 - acc: 0.9929 - val_loss: 0.2378 - val_acc: 0.9399\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9992\n",
      "Epoch 00050: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 542us/sample - loss: 0.0047 - acc: 0.9992 - val_loss: 0.2496 - val_acc: 0.9392\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 00051: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 530us/sample - loss: 0.0032 - acc: 0.9996 - val_loss: 0.2189 - val_acc: 0.9476\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9995\n",
      "Epoch 00052: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0038 - acc: 0.9994 - val_loss: 0.2786 - val_acc: 0.9341\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9951\n",
      "Epoch 00053: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 534us/sample - loss: 0.0170 - acc: 0.9950 - val_loss: 0.3385 - val_acc: 0.9243\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9957\n",
      "Epoch 00054: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 0.0164 - acc: 0.9957 - val_loss: 0.2493 - val_acc: 0.9378\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9993\n",
      "Epoch 00055: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 530us/sample - loss: 0.0043 - acc: 0.9993 - val_loss: 0.2654 - val_acc: 0.9373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9993\n",
      "Epoch 00056: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0042 - acc: 0.9993 - val_loss: 0.2463 - val_acc: 0.9390\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9996\n",
      "Epoch 00057: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 545us/sample - loss: 0.0029 - acc: 0.9996 - val_loss: 0.3239 - val_acc: 0.9292\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9964\n",
      "Epoch 00058: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.0134 - acc: 0.9964 - val_loss: 0.3047 - val_acc: 0.9336\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9986\n",
      "Epoch 00059: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0063 - acc: 0.9986 - val_loss: 0.3571 - val_acc: 0.9194\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9951\n",
      "Epoch 00060: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0183 - acc: 0.9951 - val_loss: 0.2295 - val_acc: 0.9467\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9996\n",
      "Epoch 00061: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0031 - acc: 0.9996 - val_loss: 0.2402 - val_acc: 0.9443\n",
      "Epoch 62/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9936\n",
      "Epoch 00062: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 543us/sample - loss: 0.0220 - acc: 0.9936 - val_loss: 0.2352 - val_acc: 0.9436\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9993\n",
      "Epoch 00063: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0049 - acc: 0.9993 - val_loss: 0.2272 - val_acc: 0.9434\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9986\n",
      "Epoch 00064: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.0056 - acc: 0.9986 - val_loss: 0.2370 - val_acc: 0.9448\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9999\n",
      "Epoch 00065: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0017 - acc: 0.9998 - val_loss: 0.2632 - val_acc: 0.9406\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9963\n",
      "Epoch 00066: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 530us/sample - loss: 0.0130 - acc: 0.9963 - val_loss: 0.2417 - val_acc: 0.9443\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9995\n",
      "Epoch 00067: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.0037 - acc: 0.9995 - val_loss: 0.2746 - val_acc: 0.9371\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9959\n",
      "Epoch 00068: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 533us/sample - loss: 0.0158 - acc: 0.9958 - val_loss: 0.2829 - val_acc: 0.9369\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9982\n",
      "Epoch 00069: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 533us/sample - loss: 0.0073 - acc: 0.9982 - val_loss: 0.2229 - val_acc: 0.9448\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 00070: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0030 - acc: 0.9996 - val_loss: 0.2488 - val_acc: 0.9399\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9996\n",
      "Epoch 00071: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.0028 - acc: 0.9996 - val_loss: 0.2845 - val_acc: 0.9371\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9959\n",
      "Epoch 00072: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.0149 - acc: 0.9959 - val_loss: 0.2801 - val_acc: 0.9376\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9968\n",
      "Epoch 00073: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 535us/sample - loss: 0.0115 - acc: 0.9968 - val_loss: 0.2544 - val_acc: 0.9429\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9991\n",
      "Epoch 00074: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 524us/sample - loss: 0.0049 - acc: 0.9991 - val_loss: 0.2696 - val_acc: 0.9378\n",
      "Epoch 75/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9967\n",
      "Epoch 00075: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0135 - acc: 0.9967 - val_loss: 0.2385 - val_acc: 0.9422\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 00076: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.0030 - acc: 0.9996 - val_loss: 0.2394 - val_acc: 0.9432\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9997\n",
      "Epoch 00077: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 532us/sample - loss: 0.0018 - acc: 0.9997 - val_loss: 0.2227 - val_acc: 0.9464\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9989\n",
      "Epoch 00078: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0049 - acc: 0.9989 - val_loss: 0.3327 - val_acc: 0.9317\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9958\n",
      "Epoch 00079: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 533us/sample - loss: 0.0135 - acc: 0.9958 - val_loss: 0.2439 - val_acc: 0.9436\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9996\n",
      "Epoch 00080: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 533us/sample - loss: 0.0026 - acc: 0.9996 - val_loss: 0.2451 - val_acc: 0.9415\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9990\n",
      "Epoch 00081: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 543us/sample - loss: 0.0044 - acc: 0.9990 - val_loss: 0.2363 - val_acc: 0.9478\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 00082: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 533us/sample - loss: 0.0018 - acc: 0.9997 - val_loss: 0.2704 - val_acc: 0.9399\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9967\n",
      "Epoch 00083: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0137 - acc: 0.9967 - val_loss: 0.2629 - val_acc: 0.9387\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9992\n",
      "Epoch 00084: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0042 - acc: 0.9992 - val_loss: 0.2345 - val_acc: 0.9504\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9992\n",
      "Epoch 00085: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 533us/sample - loss: 0.0039 - acc: 0.9992 - val_loss: 0.2846 - val_acc: 0.9380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9987\n",
      "Epoch 00086: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 524us/sample - loss: 0.0057 - acc: 0.9987 - val_loss: 0.2420 - val_acc: 0.9460\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9985\n",
      "Epoch 00087: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0062 - acc: 0.9985 - val_loss: 0.3599 - val_acc: 0.9248\n",
      "Epoch 88/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9977\n",
      "Epoch 00088: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0093 - acc: 0.9977 - val_loss: 0.2889 - val_acc: 0.9331\n",
      "Epoch 89/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9970\n",
      "Epoch 00089: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0113 - acc: 0.9970 - val_loss: 0.2326 - val_acc: 0.9476\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 00090: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 525us/sample - loss: 0.0018 - acc: 0.9997 - val_loss: 0.2618 - val_acc: 0.9422\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9963\n",
      "Epoch 00091: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 523us/sample - loss: 0.0135 - acc: 0.9963 - val_loss: 0.2278 - val_acc: 0.9502\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9997\n",
      "Epoch 00092: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 535us/sample - loss: 0.0026 - acc: 0.9996 - val_loss: 0.2467 - val_acc: 0.9450\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9969\n",
      "Epoch 00093: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0118 - acc: 0.9969 - val_loss: 0.2878 - val_acc: 0.9313\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 00094: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0017 - acc: 0.9997 - val_loss: 0.2184 - val_acc: 0.9490\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9997\n",
      "Epoch 00095: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.0019 - acc: 0.9997 - val_loss: 0.2573 - val_acc: 0.9460\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9985\n",
      "Epoch 00096: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0055 - acc: 0.9985 - val_loss: 0.2531 - val_acc: 0.9418\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9993\n",
      "Epoch 00097: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 0.0033 - acc: 0.9993 - val_loss: 0.2318 - val_acc: 0.9511\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9997\n",
      "Epoch 00098: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0023 - acc: 0.9997 - val_loss: 0.2499 - val_acc: 0.9483\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9972\n",
      "Epoch 00099: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.0097 - acc: 0.9972 - val_loss: 0.2494 - val_acc: 0.9478\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9995\n",
      "Epoch 00100: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0025 - acc: 0.9995 - val_loss: 0.2401 - val_acc: 0.9499\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9989\n",
      "Epoch 00101: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0039 - acc: 0.9989 - val_loss: 0.4160 - val_acc: 0.9117\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9977\n",
      "Epoch 00102: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 0.0081 - acc: 0.9977 - val_loss: 0.3143 - val_acc: 0.9336\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9989\n",
      "Epoch 00103: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 532us/sample - loss: 0.0047 - acc: 0.9989 - val_loss: 0.2534 - val_acc: 0.9476\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9994\n",
      "Epoch 00104: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0031 - acc: 0.9994 - val_loss: 0.2913 - val_acc: 0.9436\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9985\n",
      "Epoch 00105: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0051 - acc: 0.9985 - val_loss: 0.3280 - val_acc: 0.9341\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9991\n",
      "Epoch 00106: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 530us/sample - loss: 0.0038 - acc: 0.9991 - val_loss: 0.2685 - val_acc: 0.9429\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9969\n",
      "Epoch 00107: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0114 - acc: 0.9969 - val_loss: 0.2404 - val_acc: 0.9474\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9996\n",
      "Epoch 00108: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 532us/sample - loss: 0.0023 - acc: 0.9996 - val_loss: 0.2526 - val_acc: 0.9443\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 00109: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.2463 - val_acc: 0.9481\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9980\n",
      "Epoch 00110: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.0073 - acc: 0.9979 - val_loss: 0.2519 - val_acc: 0.9441\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9973\n",
      "Epoch 00111: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 0.0082 - acc: 0.9973 - val_loss: 0.2968 - val_acc: 0.9352\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9981\n",
      "Epoch 00112: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0072 - acc: 0.9981 - val_loss: 0.2596 - val_acc: 0.9439\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9997\n",
      "Epoch 00113: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.0019 - acc: 0.9996 - val_loss: 0.2570 - val_acc: 0.9439\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9974\n",
      "Epoch 00114: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0095 - acc: 0.9974 - val_loss: 0.2615 - val_acc: 0.9420\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9986\n",
      "Epoch 00115: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 523us/sample - loss: 0.0077 - acc: 0.9986 - val_loss: 0.2429 - val_acc: 0.9464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 00116: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0032 - acc: 0.9992 - val_loss: 0.2246 - val_acc: 0.9476\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9998\n",
      "Epoch 00117: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 525us/sample - loss: 0.0012 - acc: 0.9997 - val_loss: 0.2360 - val_acc: 0.9455\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9970\n",
      "Epoch 00118: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0096 - acc: 0.9970 - val_loss: 0.2423 - val_acc: 0.9481\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 00119: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 530us/sample - loss: 0.0016 - acc: 0.9997 - val_loss: 0.2343 - val_acc: 0.9522\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9989\n",
      "Epoch 00120: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0047 - acc: 0.9988 - val_loss: 0.2688 - val_acc: 0.9436\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9984\n",
      "Epoch 00121: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0066 - acc: 0.9984 - val_loss: 0.2461 - val_acc: 0.9467\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 00122: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 530us/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.2243 - val_acc: 0.9502\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 00123: val_loss did not improve from 0.20956\n",
      "36805/36805 [==============================] - 19s 530us/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.2283 - val_acc: 0.9488\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 392us/sample - loss: 0.2964 - acc: 0.9167\n",
      "Loss: 0.29638943925793915 Accuracy: 0.9167186\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9832 - acc: 0.6940\n",
      "Epoch 00001: val_loss improved from inf to 0.70580, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/001-0.7058.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.9833 - acc: 0.6940 - val_loss: 0.7058 - val_acc: 0.7747\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4011 - acc: 0.8733\n",
      "Epoch 00002: val_loss improved from 0.70580 to 0.39309, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/002-0.3931.hdf5\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.4012 - acc: 0.8733 - val_loss: 0.3931 - val_acc: 0.8749\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2656 - acc: 0.9168\n",
      "Epoch 00003: val_loss improved from 0.39309 to 0.36484, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/003-0.3648.hdf5\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.2657 - acc: 0.9168 - val_loss: 0.3648 - val_acc: 0.8819\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9384\n",
      "Epoch 00004: val_loss improved from 0.36484 to 0.30520, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/004-0.3052.hdf5\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 0.1965 - acc: 0.9384 - val_loss: 0.3052 - val_acc: 0.9050\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9602\n",
      "Epoch 00005: val_loss did not improve from 0.30520\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 0.1331 - acc: 0.9601 - val_loss: 0.3100 - val_acc: 0.9024\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9653\n",
      "Epoch 00006: val_loss did not improve from 0.30520\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.1131 - acc: 0.9652 - val_loss: 0.3415 - val_acc: 0.8956\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9762\n",
      "Epoch 00007: val_loss did not improve from 0.30520\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.0813 - acc: 0.9761 - val_loss: 0.3177 - val_acc: 0.9110\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9792\n",
      "Epoch 00008: val_loss improved from 0.30520 to 0.28824, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/008-0.2882.hdf5\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 0.0716 - acc: 0.9792 - val_loss: 0.2882 - val_acc: 0.9136\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9830\n",
      "Epoch 00009: val_loss improved from 0.28824 to 0.28786, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/009-0.2879.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 0.0597 - acc: 0.9830 - val_loss: 0.2879 - val_acc: 0.9194\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9841\n",
      "Epoch 00010: val_loss improved from 0.28786 to 0.27411, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/010-0.2741.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 0.0545 - acc: 0.9841 - val_loss: 0.2741 - val_acc: 0.9180\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9903\n",
      "Epoch 00011: val_loss did not improve from 0.27411\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0350 - acc: 0.9903 - val_loss: 0.3175 - val_acc: 0.9115\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9915\n",
      "Epoch 00012: val_loss did not improve from 0.27411\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 0.0310 - acc: 0.9915 - val_loss: 0.4769 - val_acc: 0.8838\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9834\n",
      "Epoch 00013: val_loss did not improve from 0.27411\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 0.0551 - acc: 0.9834 - val_loss: 0.3258 - val_acc: 0.9152\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9905\n",
      "Epoch 00014: val_loss improved from 0.27411 to 0.27124, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/014-0.2712.hdf5\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.0324 - acc: 0.9905 - val_loss: 0.2712 - val_acc: 0.9273\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9932\n",
      "Epoch 00015: val_loss did not improve from 0.27124\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 0.0247 - acc: 0.9931 - val_loss: 0.3718 - val_acc: 0.9122\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9870\n",
      "Epoch 00016: val_loss did not improve from 0.27124\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 0.0421 - acc: 0.9869 - val_loss: 0.2934 - val_acc: 0.9215\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9909\n",
      "Epoch 00017: val_loss did not improve from 0.27124\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.0325 - acc: 0.9909 - val_loss: 0.4012 - val_acc: 0.9022\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9936\n",
      "Epoch 00018: val_loss improved from 0.27124 to 0.24011, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/018-0.2401.hdf5\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 0.0228 - acc: 0.9936 - val_loss: 0.2401 - val_acc: 0.9357\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9923\n",
      "Epoch 00019: val_loss did not improve from 0.24011\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 0.0273 - acc: 0.9922 - val_loss: 0.2668 - val_acc: 0.9329\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9888\n",
      "Epoch 00020: val_loss did not improve from 0.24011\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 0.0392 - acc: 0.9888 - val_loss: 0.2651 - val_acc: 0.9315\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9979\n",
      "Epoch 00021: val_loss did not improve from 0.24011\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 0.0106 - acc: 0.9978 - val_loss: 0.3073 - val_acc: 0.9252\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9894\n",
      "Epoch 00022: val_loss did not improve from 0.24011\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 0.0377 - acc: 0.9894 - val_loss: 0.2712 - val_acc: 0.9322\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9981\n",
      "Epoch 00023: val_loss did not improve from 0.24011\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.0096 - acc: 0.9981 - val_loss: 0.2512 - val_acc: 0.9362\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9943\n",
      "Epoch 00024: val_loss did not improve from 0.24011\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0178 - acc: 0.9943 - val_loss: 0.3327 - val_acc: 0.9208\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9919\n",
      "Epoch 00025: val_loss did not improve from 0.24011\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 0.0276 - acc: 0.9919 - val_loss: 0.2409 - val_acc: 0.9385\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9908\n",
      "Epoch 00026: val_loss improved from 0.24011 to 0.23412, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/026-0.2341.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 0.0298 - acc: 0.9908 - val_loss: 0.2341 - val_acc: 0.9362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9968\n",
      "Epoch 00027: val_loss did not improve from 0.23412\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 0.0134 - acc: 0.9967 - val_loss: 0.2781 - val_acc: 0.9324\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9936\n",
      "Epoch 00028: val_loss improved from 0.23412 to 0.23071, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/028-0.2307.hdf5\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 0.0212 - acc: 0.9936 - val_loss: 0.2307 - val_acc: 0.9390\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9989\n",
      "Epoch 00029: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 0.0054 - acc: 0.9989 - val_loss: 0.2370 - val_acc: 0.9401\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9943\n",
      "Epoch 00030: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 0.0194 - acc: 0.9943 - val_loss: 0.2683 - val_acc: 0.9322\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9939\n",
      "Epoch 00031: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0188 - acc: 0.9939 - val_loss: 0.3379 - val_acc: 0.9215\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9968\n",
      "Epoch 00032: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 0.0113 - acc: 0.9968 - val_loss: 0.3406 - val_acc: 0.9271\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9961\n",
      "Epoch 00033: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 0.0134 - acc: 0.9961 - val_loss: 0.3096 - val_acc: 0.9322\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9945\n",
      "Epoch 00034: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0174 - acc: 0.9945 - val_loss: 0.2598 - val_acc: 0.9390\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9953\n",
      "Epoch 00035: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.0168 - acc: 0.9953 - val_loss: 0.2774 - val_acc: 0.9366\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9987\n",
      "Epoch 00036: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0060 - acc: 0.9986 - val_loss: 0.2929 - val_acc: 0.9315\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9924\n",
      "Epoch 00037: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0236 - acc: 0.9924 - val_loss: 0.2723 - val_acc: 0.9343\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9981\n",
      "Epoch 00038: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0076 - acc: 0.9981 - val_loss: 0.2868 - val_acc: 0.9341\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9937\n",
      "Epoch 00039: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 0.0205 - acc: 0.9937 - val_loss: 0.3292 - val_acc: 0.9236\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9987\n",
      "Epoch 00040: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0056 - acc: 0.9987 - val_loss: 0.2700 - val_acc: 0.9387\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9961\n",
      "Epoch 00041: val_loss did not improve from 0.23071\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.0126 - acc: 0.9961 - val_loss: 0.3971 - val_acc: 0.9150\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9958\n",
      "Epoch 00042: val_loss improved from 0.23071 to 0.22553, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/042-0.2255.hdf5\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0146 - acc: 0.9958 - val_loss: 0.2255 - val_acc: 0.9457\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9982\n",
      "Epoch 00043: val_loss did not improve from 0.22553\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0070 - acc: 0.9982 - val_loss: 0.3235 - val_acc: 0.9238\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9976\n",
      "Epoch 00044: val_loss did not improve from 0.22553\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 0.0083 - acc: 0.9976 - val_loss: 0.2417 - val_acc: 0.9457\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9956\n",
      "Epoch 00045: val_loss did not improve from 0.22553\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0142 - acc: 0.9956 - val_loss: 0.3310 - val_acc: 0.9313\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9941\n",
      "Epoch 00046: val_loss did not improve from 0.22553\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0215 - acc: 0.9940 - val_loss: 0.2399 - val_acc: 0.9441\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9973\n",
      "Epoch 00047: val_loss did not improve from 0.22553\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0105 - acc: 0.9973 - val_loss: 0.2378 - val_acc: 0.9464\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9992\n",
      "Epoch 00048: val_loss did not improve from 0.22553\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0037 - acc: 0.9992 - val_loss: 0.2568 - val_acc: 0.9422\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9974\n",
      "Epoch 00049: val_loss did not improve from 0.22553\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0088 - acc: 0.9974 - val_loss: 0.3301 - val_acc: 0.9273\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9985\n",
      "Epoch 00050: val_loss did not improve from 0.22553\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0060 - acc: 0.9984 - val_loss: 0.2912 - val_acc: 0.9350\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9935\n",
      "Epoch 00051: val_loss did not improve from 0.22553\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0209 - acc: 0.9935 - val_loss: 0.2455 - val_acc: 0.9450\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9992\n",
      "Epoch 00052: val_loss did not improve from 0.22553\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0036 - acc: 0.9991 - val_loss: 0.2547 - val_acc: 0.9434\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9929\n",
      "Epoch 00053: val_loss did not improve from 0.22553\n",
      "36805/36805 [==============================] - 22s 587us/sample - loss: 0.0237 - acc: 0.9929 - val_loss: 0.2279 - val_acc: 0.9474\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 00054: val_loss improved from 0.22553 to 0.22515, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/054-0.2252.hdf5\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0042 - acc: 0.9990 - val_loss: 0.2252 - val_acc: 0.9488\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00055: val_loss did not improve from 0.22515\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0021 - acc: 0.9996 - val_loss: 0.2699 - val_acc: 0.9392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9960\n",
      "Epoch 00056: val_loss did not improve from 0.22515\n",
      "36805/36805 [==============================] - 22s 587us/sample - loss: 0.0156 - acc: 0.9960 - val_loss: 0.2303 - val_acc: 0.9434\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9982\n",
      "Epoch 00057: val_loss did not improve from 0.22515\n",
      "36805/36805 [==============================] - 22s 586us/sample - loss: 0.0061 - acc: 0.9982 - val_loss: 0.2854 - val_acc: 0.9376\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9965\n",
      "Epoch 00058: val_loss did not improve from 0.22515\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0113 - acc: 0.9965 - val_loss: 0.2843 - val_acc: 0.9352\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9984\n",
      "Epoch 00059: val_loss did not improve from 0.22515\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0057 - acc: 0.9984 - val_loss: 0.3290 - val_acc: 0.9301\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9987\n",
      "Epoch 00060: val_loss did not improve from 0.22515\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0051 - acc: 0.9987 - val_loss: 0.2528 - val_acc: 0.9471\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9944\n",
      "Epoch 00061: val_loss did not improve from 0.22515\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0187 - acc: 0.9944 - val_loss: 0.2742 - val_acc: 0.9373\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9979\n",
      "Epoch 00062: val_loss did not improve from 0.22515\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0082 - acc: 0.9979 - val_loss: 0.2355 - val_acc: 0.9460\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 00063: val_loss did not improve from 0.22515\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 0.0019 - acc: 0.9995 - val_loss: 0.2424 - val_acc: 0.9495\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9964\n",
      "Epoch 00064: val_loss did not improve from 0.22515\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.0122 - acc: 0.9964 - val_loss: 0.2620 - val_acc: 0.9448\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9984\n",
      "Epoch 00065: val_loss did not improve from 0.22515\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0057 - acc: 0.9984 - val_loss: 0.3394 - val_acc: 0.9297\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9960\n",
      "Epoch 00066: val_loss did not improve from 0.22515\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.0138 - acc: 0.9960 - val_loss: 0.2612 - val_acc: 0.9439\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 00067: val_loss improved from 0.22515 to 0.21946, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/067-0.2195.hdf5\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 0.0032 - acc: 0.9992 - val_loss: 0.2195 - val_acc: 0.9481\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 00068: val_loss did not improve from 0.21946\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 0.0017 - acc: 0.9996 - val_loss: 0.2563 - val_acc: 0.9457\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9946\n",
      "Epoch 00069: val_loss did not improve from 0.21946\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0182 - acc: 0.9946 - val_loss: 0.2498 - val_acc: 0.9441\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9994\n",
      "Epoch 00070: val_loss improved from 0.21946 to 0.21497, saving model to model/checkpoint/1D_CNN_only_conv_conv_5_BN_8_conv_checkpoint/070-0.2150.hdf5\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.0024 - acc: 0.9994 - val_loss: 0.2150 - val_acc: 0.9504\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 00071: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0030 - acc: 0.9993 - val_loss: 0.2607 - val_acc: 0.9418\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9951\n",
      "Epoch 00072: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 0.0185 - acc: 0.9951 - val_loss: 0.2497 - val_acc: 0.9436\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9995\n",
      "Epoch 00073: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0021 - acc: 0.9995 - val_loss: 0.2417 - val_acc: 0.9483\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9988\n",
      "Epoch 00074: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 587us/sample - loss: 0.0047 - acc: 0.9988 - val_loss: 0.2899 - val_acc: 0.9399\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9952\n",
      "Epoch 00075: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0156 - acc: 0.9952 - val_loss: 0.2307 - val_acc: 0.9502\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9993\n",
      "Epoch 00076: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0034 - acc: 0.9993 - val_loss: 0.2411 - val_acc: 0.9492\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9972\n",
      "Epoch 00077: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 587us/sample - loss: 0.0106 - acc: 0.9972 - val_loss: 0.2441 - val_acc: 0.9436\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 00078: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0026 - acc: 0.9993 - val_loss: 0.2964 - val_acc: 0.9399\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9981\n",
      "Epoch 00079: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0063 - acc: 0.9981 - val_loss: 0.2736 - val_acc: 0.9420\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9995\n",
      "Epoch 00080: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0023 - acc: 0.9995 - val_loss: 0.2498 - val_acc: 0.9474\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 00081: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0015 - acc: 0.9996 - val_loss: 0.2720 - val_acc: 0.9448\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9958\n",
      "Epoch 00082: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0153 - acc: 0.9958 - val_loss: 0.2465 - val_acc: 0.9478\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9982\n",
      "Epoch 00083: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 586us/sample - loss: 0.0060 - acc: 0.9982 - val_loss: 0.2939 - val_acc: 0.9376\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9995\n",
      "Epoch 00084: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0024 - acc: 0.9995 - val_loss: 0.2380 - val_acc: 0.9488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9977\n",
      "Epoch 00085: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0075 - acc: 0.9977 - val_loss: 0.3712 - val_acc: 0.9241\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9961\n",
      "Epoch 00086: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0126 - acc: 0.9961 - val_loss: 0.3487 - val_acc: 0.9297\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9986\n",
      "Epoch 00087: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0052 - acc: 0.9986 - val_loss: 0.2497 - val_acc: 0.9509\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 00088: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0050 - acc: 0.9987 - val_loss: 0.2748 - val_acc: 0.9429\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9976\n",
      "Epoch 00089: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0082 - acc: 0.9976 - val_loss: 0.2580 - val_acc: 0.9469\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9987\n",
      "Epoch 00090: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0036 - acc: 0.9988 - val_loss: 0.2685 - val_acc: 0.9448\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9980\n",
      "Epoch 00091: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0059 - acc: 0.9980 - val_loss: 0.2886 - val_acc: 0.9434\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9978\n",
      "Epoch 00092: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0067 - acc: 0.9978 - val_loss: 0.2780 - val_acc: 0.9427\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9990\n",
      "Epoch 00093: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0031 - acc: 0.9990 - val_loss: 0.2446 - val_acc: 0.9539\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9992\n",
      "Epoch 00094: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.0040 - acc: 0.9992 - val_loss: 0.2504 - val_acc: 0.9492\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9983\n",
      "Epoch 00095: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0058 - acc: 0.9983 - val_loss: 0.3613 - val_acc: 0.9308\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9977\n",
      "Epoch 00096: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 0.0080 - acc: 0.9977 - val_loss: 0.2493 - val_acc: 0.9483\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 00097: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.0030 - acc: 0.9991 - val_loss: 0.2532 - val_acc: 0.9532\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9990\n",
      "Epoch 00098: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0034 - acc: 0.9990 - val_loss: 0.3440 - val_acc: 0.9311\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9974\n",
      "Epoch 00099: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0088 - acc: 0.9974 - val_loss: 0.2912 - val_acc: 0.9401\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 00100: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0029 - acc: 0.9993 - val_loss: 0.2519 - val_acc: 0.9504\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9985\n",
      "Epoch 00101: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0052 - acc: 0.9985 - val_loss: 0.3336 - val_acc: 0.9385\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9983\n",
      "Epoch 00102: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0060 - acc: 0.9983 - val_loss: 0.2381 - val_acc: 0.9504\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9987\n",
      "Epoch 00103: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0046 - acc: 0.9987 - val_loss: 0.2409 - val_acc: 0.9492\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 00104: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0025 - acc: 0.9994 - val_loss: 0.2645 - val_acc: 0.9446\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9977\n",
      "Epoch 00105: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0078 - acc: 0.9977 - val_loss: 0.3248 - val_acc: 0.9352\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 00106: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0061 - acc: 0.9980 - val_loss: 0.3308 - val_acc: 0.9366\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9981\n",
      "Epoch 00107: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0059 - acc: 0.9980 - val_loss: 0.2683 - val_acc: 0.9476\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9975\n",
      "Epoch 00108: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0081 - acc: 0.9975 - val_loss: 0.2654 - val_acc: 0.9455\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9995\n",
      "Epoch 00109: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0022 - acc: 0.9995 - val_loss: 0.2695 - val_acc: 0.9436\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9993\n",
      "Epoch 00110: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0023 - acc: 0.9993 - val_loss: 0.2397 - val_acc: 0.9539\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 00111: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0019 - acc: 0.9996 - val_loss: 0.2937 - val_acc: 0.9404\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9971\n",
      "Epoch 00112: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0090 - acc: 0.9971 - val_loss: 0.2650 - val_acc: 0.9488\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 00113: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0028 - acc: 0.9992 - val_loss: 0.2858 - val_acc: 0.9455\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 00114: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0012 - acc: 0.9997 - val_loss: 0.2913 - val_acc: 0.9441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 00115: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0011 - acc: 0.9998 - val_loss: 0.2976 - val_acc: 0.9432\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9975\n",
      "Epoch 00116: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0076 - acc: 0.9975 - val_loss: 0.3773 - val_acc: 0.9273\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9982\n",
      "Epoch 00117: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0057 - acc: 0.9982 - val_loss: 0.2945 - val_acc: 0.9415\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9986\n",
      "Epoch 00118: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 0.0043 - acc: 0.9986 - val_loss: 0.3126 - val_acc: 0.9420\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 00119: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0061 - acc: 0.9980 - val_loss: 0.3109 - val_acc: 0.9429\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9991\n",
      "Epoch 00120: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0027 - acc: 0.9991 - val_loss: 0.2652 - val_acc: 0.9504\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9993\n",
      "Epoch 00121: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0026 - acc: 0.9993 - val_loss: 0.2891 - val_acc: 0.9490\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9961\n",
      "Epoch 00122: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 0.0144 - acc: 0.9961 - val_loss: 0.2823 - val_acc: 0.9481\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9991\n",
      "Epoch 00123: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0036 - acc: 0.9991 - val_loss: 0.2394 - val_acc: 0.9529\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.6257e-04 - acc: 0.9999\n",
      "Epoch 00124: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 6.6276e-04 - acc: 0.9999 - val_loss: 0.2427 - val_acc: 0.9522\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9996\n",
      "Epoch 00125: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0024 - acc: 0.9995 - val_loss: 0.2792 - val_acc: 0.9499\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9965\n",
      "Epoch 00126: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 587us/sample - loss: 0.0126 - acc: 0.9965 - val_loss: 0.2763 - val_acc: 0.9471\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 00127: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0017 - acc: 0.9996 - val_loss: 0.2532 - val_acc: 0.9525\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 00128: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0016 - acc: 0.9996 - val_loss: 0.2594 - val_acc: 0.9518\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 00129: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0016 - acc: 0.9996 - val_loss: 0.2675 - val_acc: 0.9481\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9987\n",
      "Epoch 00130: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0052 - acc: 0.9987 - val_loss: 0.2853 - val_acc: 0.9499\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9984\n",
      "Epoch 00131: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 591us/sample - loss: 0.0062 - acc: 0.9984 - val_loss: 0.2841 - val_acc: 0.9469\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9995\n",
      "Epoch 00132: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0021 - acc: 0.9995 - val_loss: 0.2890 - val_acc: 0.9422\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9985\n",
      "Epoch 00133: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0055 - acc: 0.9984 - val_loss: 0.3018 - val_acc: 0.9469\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9975\n",
      "Epoch 00134: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0087 - acc: 0.9975 - val_loss: 0.2332 - val_acc: 0.9502\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 00135: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0012 - acc: 0.9997 - val_loss: 0.2354 - val_acc: 0.9485\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 00136: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0022 - acc: 0.9993 - val_loss: 0.2403 - val_acc: 0.9548\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9978\n",
      "Epoch 00137: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0075 - acc: 0.9978 - val_loss: 0.2312 - val_acc: 0.9539\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 00138: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 585us/sample - loss: 0.0034 - acc: 0.9991 - val_loss: 0.3017 - val_acc: 0.9390\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9972\n",
      "Epoch 00139: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0104 - acc: 0.9972 - val_loss: 0.2672 - val_acc: 0.9499\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 00140: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0020 - acc: 0.9995 - val_loss: 0.2484 - val_acc: 0.9534\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.7571e-04 - acc: 0.9999\n",
      "Epoch 00141: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 4.7585e-04 - acc: 0.9999 - val_loss: 0.2377 - val_acc: 0.9548\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.3206e-04 - acc: 0.9999\n",
      "Epoch 00142: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 5.3209e-04 - acc: 0.9999 - val_loss: 0.2614 - val_acc: 0.9492\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.5457e-04 - acc: 0.9999\n",
      "Epoch 00143: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 6.2821e-04 - acc: 0.9999 - val_loss: 0.2365 - val_acc: 0.9555\n",
      "Epoch 144/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9971\n",
      "Epoch 00144: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 587us/sample - loss: 0.0113 - acc: 0.9971 - val_loss: 0.2679 - val_acc: 0.9506\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9981\n",
      "Epoch 00145: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 587us/sample - loss: 0.0079 - acc: 0.9981 - val_loss: 0.2637 - val_acc: 0.9492\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9988\n",
      "Epoch 00146: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 586us/sample - loss: 0.0045 - acc: 0.9988 - val_loss: 0.2493 - val_acc: 0.9509\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.2699e-04 - acc: 0.9998\n",
      "Epoch 00147: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 9.2807e-04 - acc: 0.9998 - val_loss: 0.2344 - val_acc: 0.9546\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.7468e-04 - acc: 1.0000\n",
      "Epoch 00148: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 3.9289e-04 - acc: 1.0000 - val_loss: 0.2381 - val_acc: 0.9560\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 00149: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0037 - acc: 0.9991 - val_loss: 0.2330 - val_acc: 0.9522\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.5468e-04 - acc: 0.9999\n",
      "Epoch 00150: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 7.5459e-04 - acc: 0.9999 - val_loss: 0.2480 - val_acc: 0.9532\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 00151: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 586us/sample - loss: 0.0015 - acc: 0.9996 - val_loss: 0.2524 - val_acc: 0.9506\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9983\n",
      "Epoch 00152: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0056 - acc: 0.9982 - val_loss: 0.4034 - val_acc: 0.9280\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9970\n",
      "Epoch 00153: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 587us/sample - loss: 0.0110 - acc: 0.9969 - val_loss: 0.2541 - val_acc: 0.9513\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9978\n",
      "Epoch 00154: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0079 - acc: 0.9978 - val_loss: 0.2617 - val_acc: 0.9499\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 00155: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 585us/sample - loss: 0.0012 - acc: 0.9997 - val_loss: 0.2547 - val_acc: 0.9515\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.5637e-04 - acc: 0.9998\n",
      "Epoch 00156: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 7.5627e-04 - acc: 0.9998 - val_loss: 0.2503 - val_acc: 0.9522\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.9887e-04 - acc: 0.9999\n",
      "Epoch 00157: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 5.9889e-04 - acc: 0.9999 - val_loss: 0.2484 - val_acc: 0.9536\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9991\n",
      "Epoch 00158: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.0026 - acc: 0.9991 - val_loss: 0.2756 - val_acc: 0.9476\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 00159: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0019 - acc: 0.9995 - val_loss: 0.2381 - val_acc: 0.9541\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.5579e-04 - acc: 0.9999\n",
      "Epoch 00160: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 4.5594e-04 - acc: 0.9999 - val_loss: 0.2503 - val_acc: 0.9543\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9979\n",
      "Epoch 00161: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0079 - acc: 0.9979 - val_loss: 0.3195 - val_acc: 0.9364\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9990\n",
      "Epoch 00162: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0040 - acc: 0.9990 - val_loss: 0.2534 - val_acc: 0.9488\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9989\n",
      "Epoch 00163: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 589us/sample - loss: 0.0052 - acc: 0.9988 - val_loss: 0.2665 - val_acc: 0.9492\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9990\n",
      "Epoch 00164: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 594us/sample - loss: 0.0044 - acc: 0.9990 - val_loss: 0.2818 - val_acc: 0.9488\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.8135e-04 - acc: 0.9998\n",
      "Epoch 00165: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 9.8122e-04 - acc: 0.9998 - val_loss: 0.2570 - val_acc: 0.9529\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.6041e-04 - acc: 0.9999\n",
      "Epoch 00166: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 6.6032e-04 - acc: 0.9999 - val_loss: 0.2591 - val_acc: 0.9527\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.8231e-04 - acc: 1.0000\n",
      "Epoch 00167: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 2.8244e-04 - acc: 1.0000 - val_loss: 0.2502 - val_acc: 0.9550\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9970\n",
      "Epoch 00168: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 592us/sample - loss: 0.0102 - acc: 0.9970 - val_loss: 0.3680 - val_acc: 0.9315\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9988\n",
      "Epoch 00169: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 593us/sample - loss: 0.0043 - acc: 0.9988 - val_loss: 0.2437 - val_acc: 0.9529\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 00170: val_loss did not improve from 0.21497\n",
      "36805/36805 [==============================] - 22s 590us/sample - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2357 - val_acc: 0.9511\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 444us/sample - loss: 0.3343 - acc: 0.9238\n",
      "Loss: 0.33425746609767276 Accuracy: 0.92377985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 9):\n",
    "    base = '1D_CNN_only_conv_conv_5_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_only_conv_conv_5_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_only_conv_conv_5_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 42656)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 42656)             170624    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                682512    \n",
      "=================================================================\n",
      "Total params: 853,216\n",
      "Trainable params: 767,888\n",
      "Non-trainable params: 85,328\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 337us/sample - loss: 2.5952 - acc: 0.2735\n",
      "Loss: 2.59520444057936 Accuracy: 0.27352026\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_37 (Conv1D)           (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 28416)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 28416)             113664    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                454672    \n",
      "=================================================================\n",
      "Total params: 569,136\n",
      "Trainable params: 512,256\n",
      "Non-trainable params: 56,880\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 362us/sample - loss: 1.8383 - acc: 0.4665\n",
      "Loss: 1.8382519834633309 Accuracy: 0.46645898\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_39 (Conv1D)           (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 1772, 32)          2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 1772, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 1772, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 591, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 18912)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 18912)             75648     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                302608    \n",
      "=================================================================\n",
      "Total params: 381,776\n",
      "Trainable params: 343,840\n",
      "Non-trainable params: 37,936\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 407us/sample - loss: 1.3988 - acc: 0.6004\n",
      "Loss: 1.3988319131815545 Accuracy: 0.60041535\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 1772, 32)          2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 1772, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 1772, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 591, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 587, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 587, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 587, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 196, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                200720    \n",
      "=================================================================\n",
      "Total params: 264,976\n",
      "Trainable params: 239,648\n",
      "Non-trainable params: 25,328\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 426us/sample - loss: 1.2236 - acc: 0.6644\n",
      "Loss: 1.223611071424197 Accuracy: 0.66438216\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1772, 32)          2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 1772, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1772, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 591, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 587, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 587, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 587, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 196, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 192, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 192, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 192, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                131088    \n",
      "=================================================================\n",
      "Total params: 219,536\n",
      "Trainable params: 202,656\n",
      "Non-trainable params: 16,880\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 494us/sample - loss: 0.8096 - acc: 0.7674\n",
      "Loss: 0.8095521053173584 Accuracy: 0.7673936\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 1772, 32)          2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 1772, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 1772, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 591, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 587, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 587, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 587, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 196, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 192, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 192, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 192, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 60, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 60, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 5120)              20480     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                81936     \n",
      "=================================================================\n",
      "Total params: 323,216\n",
      "Trainable params: 311,968\n",
      "Non-trainable params: 11,248\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 481us/sample - loss: 0.4269 - acc: 0.8860\n",
      "Loss: 0.42686391343456437 Accuracy: 0.8859813\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 1772, 32)          2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 1772, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 1772, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 591, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 587, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 587, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 587, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 196, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 192, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 192, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 192, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 60, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 60, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 16, 512)           655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 16, 512)           2048      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 16, 512)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 6, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                49168     \n",
      "=================================================================\n",
      "Total params: 940,176\n",
      "Trainable params: 932,000\n",
      "Non-trainable params: 8,176\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 489us/sample - loss: 0.2964 - acc: 0.9167\n",
      "Loss: 0.29638943925793915 Accuracy: 0.9167186\n",
      "\n",
      "1D_CNN_only_conv_conv_5_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_64 (Conv1D)           (None, 15996, 8)          48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 15996, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 15996, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5332, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 5328, 16)          656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 5328, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 5328, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1776, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 1772, 32)          2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 1772, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 1772, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 591, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 587, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 587, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 587, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 196, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 192, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 192, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 192, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 60, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 60, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 16, 512)           655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 16, 512)           2048      \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 16, 512)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 6, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 2, 1024)           2622464   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 2, 1024)           4096      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 2, 1024)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 3,525,776\n",
      "Trainable params: 3,519,648\n",
      "Non-trainable params: 6,128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 527us/sample - loss: 0.3343 - acc: 0.9238\n",
      "Loss: 0.33425746609767276 Accuracy: 0.92377985\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_only_conv_conv_5_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 9):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
