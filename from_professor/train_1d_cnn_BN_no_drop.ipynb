{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "import scipy.io as sio\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(wav):\n",
    "    wav = sklearn.preprocessing.maxabs_scale(wav)\n",
    "    wav_mfcc = librosa.feature.mfcc(y=wav, n_mfcc=13)\n",
    "    wav_mfcc_std = StandardScaler().fit_transform(wav_mfcc)\n",
    "    wav_mfcc_std_mean = wav_mfcc_std.mean(axis=1)\n",
    "\n",
    "    features = np.concatenate([wav_mfcc_std_mean])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batchnorm_cnn_no_do(conv_num=1, fcn_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D(kernel_size=25, filters=8, strides=1, padding='valid', input_shape=input_shape))  \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4, strides=4, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=25, filters=8*(2**(i+1)), strides=1, padding='valid'))  \n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=4, strides=4, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for i in range(fcn_num):\n",
    "        model.add(Dense(1024/(2**i)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = build_cnn(conv_num=3, fcn_num=1)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7882 - acc: 0.4384\n",
      "Epoch 00001: val_loss improved from inf to 1.51294, saving model to model/checkpoint/1D_CNN_BN_NO_DO_1_conv_1_fcn_checkpoint/01-1.5129.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 1.7882 - acc: 0.4384 - val_loss: 1.5129 - val_acc: 0.5071\n",
      "Epoch 2/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9615 - acc: 0.7100\n",
      "Epoch 00002: val_loss improved from 1.51294 to 1.16865, saving model to model/checkpoint/1D_CNN_BN_NO_DO_1_conv_1_fcn_checkpoint/02-1.1687.hdf5\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.9617 - acc: 0.7099 - val_loss: 1.1687 - val_acc: 0.6331\n",
      "Epoch 3/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6112 - acc: 0.8350\n",
      "Epoch 00003: val_loss improved from 1.16865 to 1.13870, saving model to model/checkpoint/1D_CNN_BN_NO_DO_1_conv_1_fcn_checkpoint/03-1.1387.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.6112 - acc: 0.8350 - val_loss: 1.1387 - val_acc: 0.6380\n",
      "Epoch 4/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3811 - acc: 0.9155\n",
      "Epoch 00004: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 0.3811 - acc: 0.9155 - val_loss: 1.2391 - val_acc: 0.6268\n",
      "Epoch 5/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2422 - acc: 0.9579\n",
      "Epoch 00005: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.2424 - acc: 0.9579 - val_loss: 1.2871 - val_acc: 0.6084\n",
      "Epoch 6/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1789 - acc: 0.9727\n",
      "Epoch 00006: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 428us/sample - loss: 0.1792 - acc: 0.9726 - val_loss: 1.4030 - val_acc: 0.5970\n",
      "Epoch 7/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9848\n",
      "Epoch 00007: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 431us/sample - loss: 0.1320 - acc: 0.9847 - val_loss: 1.4271 - val_acc: 0.6021\n",
      "Epoch 8/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9887\n",
      "Epoch 00008: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 0.1038 - acc: 0.9887 - val_loss: 1.4459 - val_acc: 0.5993\n",
      "Epoch 9/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9913\n",
      "Epoch 00009: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.0892 - acc: 0.9913 - val_loss: 1.4858 - val_acc: 0.5970\n",
      "Epoch 10/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9937\n",
      "Epoch 00010: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 0.0672 - acc: 0.9937 - val_loss: 1.4991 - val_acc: 0.5956\n",
      "Epoch 11/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9934\n",
      "Epoch 00011: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.0607 - acc: 0.9934 - val_loss: 1.6372 - val_acc: 0.5886\n",
      "Epoch 12/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9949\n",
      "Epoch 00012: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.0513 - acc: 0.9949 - val_loss: 1.6864 - val_acc: 0.5945\n",
      "Epoch 13/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9910\n",
      "Epoch 00013: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 426us/sample - loss: 0.0664 - acc: 0.9910 - val_loss: 1.6055 - val_acc: 0.5914\n",
      "Epoch 14/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9925\n",
      "Epoch 00014: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.0553 - acc: 0.9925 - val_loss: 1.9298 - val_acc: 0.5570\n",
      "Epoch 15/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9965\n",
      "Epoch 00015: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.0370 - acc: 0.9965 - val_loss: 1.5665 - val_acc: 0.6143\n",
      "Epoch 16/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9971\n",
      "Epoch 00016: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 424us/sample - loss: 0.0306 - acc: 0.9970 - val_loss: 1.7467 - val_acc: 0.5984\n",
      "Epoch 17/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9896\n",
      "Epoch 00017: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.0648 - acc: 0.9896 - val_loss: 2.1217 - val_acc: 0.5418\n",
      "Epoch 18/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9942\n",
      "Epoch 00018: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.0455 - acc: 0.9942 - val_loss: 1.6643 - val_acc: 0.6014\n",
      "Epoch 19/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9968\n",
      "Epoch 00019: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 15s 419us/sample - loss: 0.0315 - acc: 0.9968 - val_loss: 1.6348 - val_acc: 0.6278\n",
      "Epoch 20/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9923\n",
      "Epoch 00020: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 15s 419us/sample - loss: 0.0494 - acc: 0.9922 - val_loss: 1.6957 - val_acc: 0.6010\n",
      "Epoch 21/200\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9959\n",
      "Epoch 00021: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 15s 419us/sample - loss: 0.0372 - acc: 0.9958 - val_loss: 1.6923 - val_acc: 0.5991\n",
      "Epoch 22/200\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9983\n",
      "Epoch 00022: val_loss did not improve from 1.13870\n",
      "36805/36805 [==============================] - 15s 421us/sample - loss: 0.0204 - acc: 0.9983 - val_loss: 1.5833 - val_acc: 0.6320\n",
      "Epoch 23/200\n",
      "21312/36805 [================>.............] - ETA: 6s - loss: 0.0122 - acc: 0.9992"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    for j in range(1, 3):\n",
    "        model = build_batchnorm_cnn_no_do(conv_num=i, fcn_num=j)\n",
    "#         model.summary()\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "        model_path = 'model/checkpoint/1D_CNN_BN_NO_DO_{}_conv_{}_fcn_checkpoint/'.format(i, j)\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        model_filename = model_path+'{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "        checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                       verbose=1, save_best_only=True)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "        hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=200, \n",
    "                         validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                         callbacks = [checkpointer, early_stopping])\n",
    "        print()\n",
    "        print('{} Conv {} FCN BN NO_DO Model'.format(i, j))\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "        ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "        ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "        ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.set_ylabel('loss')\n",
    "        ax.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        png_path = 'visualization/learning_curve/'\n",
    "        filename = '1D_BN_CNN_NO_DO_{}_conv_{}_fcn'.format(i, j)+'.png'\n",
    "        os.makedirs(png_path, exist_ok=True)\n",
    "        fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "        del(model)\n",
    "        \n",
    "        model_path = 'model/checkpoint/1D_CNN_BN_NO_DO_{}_conv_{}_fcn_checkpoint/'.format(i, j)\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "        model = load_model(model_filename)\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "        print()\n",
    "        \n",
    "        del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Conv 1 FCN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 15976, 8)          208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 15976, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 15976, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 3994, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 31952)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              32719872  \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 32,740,608\n",
      "Trainable params: 32,738,544\n",
      "Non-trainable params: 2,064\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 393us/sample - loss: 1.2586 - acc: 0.5979\n",
      "Loss: 1.2586488517521575 Accuracy: 0.59792316\n",
      "\n",
      "1 Conv 2 FCN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 15976, 8)          208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 15976, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15976, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 3994, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 31952)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              32719872  \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 33,259,264\n",
      "Trainable params: 33,256,176\n",
      "Non-trainable params: 3,088\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 393us/sample - loss: 1.1918 - acc: 0.6243\n",
      "Loss: 1.1917862831494024 Accuracy: 0.62429905\n",
      "\n",
      "2 Conv 1 FCN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 15976, 8)          208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 15976, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 15976, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 3994, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 3970, 16)          3216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 3970, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 3970, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 993, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 15888)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              16270336  \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 16,294,352\n",
      "Trainable params: 16,292,256\n",
      "Non-trainable params: 2,096\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 409us/sample - loss: 1.1099 - acc: 0.6328\n",
      "Loss: 1.1099013542708083 Accuracy: 0.6328141\n",
      "\n",
      "2 Conv 2 FCN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 15976, 8)          208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 15976, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15976, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 3994, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 3970, 16)          3216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 3970, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 3970, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 993, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 15888)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              16270336  \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 16,813,008\n",
      "Trainable params: 16,809,888\n",
      "Non-trainable params: 3,120\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 452us/sample - loss: 0.9466 - acc: 0.7130\n",
      "Loss: 0.9465943889083149 Accuracy: 0.7129803\n",
      "\n",
      "3 Conv 1 FCN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 15976, 8)          208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 15976, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 15976, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 3994, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 3970, 16)          3216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 3970, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 3970, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 993, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 969, 32)           12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 969, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 969, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 243, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 7776)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              7963648   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 8,000,624\n",
      "Trainable params: 7,998,464\n",
      "Non-trainable params: 2,160\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 490us/sample - loss: 0.6070 - acc: 0.8110\n",
      "Loss: 0.607030159761106 Accuracy: 0.81100726\n",
      "\n",
      "3 Conv 2 FCN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 15976, 8)          208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 15976, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 15976, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 3994, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 3970, 16)          3216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 3970, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 3970, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 993, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 969, 32)           12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 969, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 969, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 243, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 7776)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              7963648   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 8,519,280\n",
      "Trainable params: 8,516,096\n",
      "Non-trainable params: 3,184\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 504us/sample - loss: 0.6167 - acc: 0.8087\n",
      "Loss: 0.6166827474303954 Accuracy: 0.80872273\n",
      "\n",
      "4 Conv 1 FCN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 15976, 8)          208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 15976, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 15976, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 3994, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 3970, 16)          3216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 3970, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 3970, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 993, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 969, 32)           12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 969, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 969, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 243, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 219, 64)           51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 219, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 219, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 55, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3520)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1024)              3605504   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 3,694,000\n",
      "Trainable params: 3,691,712\n",
      "Non-trainable params: 2,288\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 482us/sample - loss: 0.3698 - acc: 0.8841\n",
      "Loss: 0.36977876381463104 Accuracy: 0.8841122\n",
      "\n",
      "4 Conv 2 FCN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_16 (Conv1D)           (None, 15976, 8)          208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 15976, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 15976, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 3994, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 3970, 16)          3216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 3970, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 3970, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 993, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 969, 32)           12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 969, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 969, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 243, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 219, 64)           51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 219, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 219, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 55, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3520)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1024)              3605504   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 4,212,656\n",
      "Trainable params: 4,209,344\n",
      "Non-trainable params: 3,312\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 547us/sample - loss: 0.4475 - acc: 0.8814\n",
      "Loss: 0.44751486263294954 Accuracy: 0.88141227\n",
      "\n",
      "5 Conv 1 FCN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 15976, 8)          208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 15976, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 15976, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 3994, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 3970, 16)          3216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 3970, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 3970, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 993, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 969, 32)           12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 969, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 969, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 243, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 219, 64)           51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 219, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 219, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 55, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 31, 128)           204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 1,343,536\n",
      "Trainable params: 1,340,992\n",
      "Non-trainable params: 2,544\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 603us/sample - loss: 0.3101 - acc: 0.9026\n",
      "Loss: 0.3101385440039115 Accuracy: 0.90259606\n",
      "\n",
      "5 Conv 2 FCN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 15976, 8)          208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 15976, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 15976, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 3994, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 3970, 16)          3216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 3970, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 3970, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 993, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 969, 32)           12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 969, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 969, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 243, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 219, 64)           51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 219, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 219, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 55, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 31, 128)           204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,862,192\n",
      "Trainable params: 1,858,624\n",
      "Non-trainable params: 3,568\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 599us/sample - loss: 0.3387 - acc: 0.9072\n",
      "Loss: 0.338706972015981 Accuracy: 0.9071651\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    for j in range(1, 3):\n",
    "        print()\n",
    "        print('{} Conv {} FCN Model'.format(i, j))\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "        model_path = 'model/checkpoint/1D_CNN_BN_NO_DO_{}_conv_{}_fcn_checkpoint/'.format(i, j)\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "  \n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "    \n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "        \n",
    "        del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
